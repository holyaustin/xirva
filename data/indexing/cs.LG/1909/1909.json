[{"id": "1909.00021", "submitter": "Javier Turek", "authors": "Javier S. Turek, Shailee Jain, Vy Vo, Mihai Capota, Alexander G. Huth,\n  Theodore L. Willke", "title": "Approximating Stacked and Bidirectional Recurrent Architectures with the\n  Delayed Recurrent Neural Network", "comments": "to be published in Proceedings of International Conference on Machine\n  Learning 2020 (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that topological enhancements to recurrent neural\nnetworks (RNNs) can increase their expressiveness and representational\ncapacity. Two popular enhancements are stacked RNNs, which increases the\ncapacity for learning non-linear functions, and bidirectional processing, which\nexploits acausal information in a sequence. In this work, we explore the\ndelayed-RNN, which is a single-layer RNN that has a delay between the input and\noutput. We prove that a weight-constrained version of the delayed-RNN is\nequivalent to a stacked-RNN. We also show that the delay gives rise to partial\nacausality, much like bidirectional networks. Synthetic experiments confirm\nthat the delayed-RNN can mimic bidirectional networks, solving some acausal\ntasks similarly, and outperforming them in others. Moreover, we show similar\nperformance to bidirectional networks in a real-world natural language\nprocessing task. These results suggest that delayed-RNNs can approximate\ntopologies including stacked RNNs, bidirectional RNNs, and stacked\nbidirectional RNNs - but with equivalent or faster runtimes for the\ndelayed-RNNs.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 18:18:04 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 05:45:08 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Turek", "Javier S.", ""], ["Jain", "Shailee", ""], ["Vo", "Vy", ""], ["Capota", "Mihai", ""], ["Huth", "Alexander G.", ""], ["Willke", "Theodore L.", ""]]}, {"id": "1909.00025", "submitter": "Sebastian Flennerhag", "authors": "Sebastian Flennerhag and Andrei A. Rusu and Razvan Pascanu and\n  Francesco Visin and Hujun Yin and Raia Hadsell", "title": "Meta-Learning with Warped Gradient Descent", "comments": "28 pages, 13 figures, 3 tables. Published as a conference paper at\n  ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning an efficient update rule from data that promotes rapid learning of\nnew tasks from the same distribution remains an open problem in meta-learning.\nTypically, previous works have approached this issue either by attempting to\ntrain a neural network that directly produces updates or by attempting to learn\nbetter initialisations or scaling factors for a gradient-based update rule.\nBoth of these approaches pose challenges. On one hand, directly producing an\nupdate forgoes a useful inductive bias and can easily lead to non-converging\nbehaviour. On the other hand, approaches that try to control a gradient-based\nupdate rule typically resort to computing gradients through the learning\nprocess to obtain their meta-gradients, leading to methods that can not scale\nbeyond few-shot task adaptation. In this work, we propose Warped Gradient\nDescent (WarpGrad), a method that intersects these approaches to mitigate their\nlimitations. WarpGrad meta-learns an efficiently parameterised preconditioning\nmatrix that facilitates gradient descent across the task distribution.\nPreconditioning arises by interleaving non-linear layers, referred to as\nwarp-layers, between the layers of a task-learner. Warp-layers are meta-learned\nwithout backpropagating through the task training process in a manner similar\nto methods that learn to directly produce updates. WarpGrad is computationally\nefficient, easy to implement, and can scale to arbitrarily large meta-learning\nproblems. We provide a geometrical interpretation of the approach and evaluate\nits effectiveness in a variety of settings, including few-shot, standard\nsupervised, continual and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 18:27:35 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 08:57:58 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Flennerhag", "Sebastian", ""], ["Rusu", "Andrei A.", ""], ["Pascanu", "Razvan", ""], ["Visin", "Francesco", ""], ["Yin", "Hujun", ""], ["Hadsell", "Raia", ""]]}, {"id": "1909.00047", "submitter": "Anis Elgabli", "authors": "Anis Elgabli, Jihong Park, Amrit S. Bedi, Mehdi Bennis, Vaneet\n  Aggarwal", "title": "GADMM: Fast and Communication Efficient Framework for Distributed\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the data is distributed across multiple servers, lowering the\ncommunication cost between the servers (or workers) while solving the\ndistributed learning problem is an important problem and is the focus of this\npaper. In particular, we propose a fast, and communication-efficient\ndecentralized framework to solve the distributed machine learning (DML)\nproblem. The proposed algorithm, Group Alternating Direction Method of\nMultipliers (GADMM) is based on the Alternating Direction Method of Multipliers\n(ADMM) framework. The key novelty in GADMM is that it solves the problem in a\ndecentralized topology where at most half of the workers are competing for the\nlimited communication resources at any given time. Moreover, each worker\nexchanges the locally trained model only with two neighboring workers, thereby\ntraining a global model with a lower amount of communication overhead in each\nexchange. We prove that GADMM converges to the optimal solution for convex loss\nfunctions, and numerically show that it converges faster and more\ncommunication-efficient than the state-of-the-art communication-efficient\nalgorithms such as the Lazily Aggregated Gradient (LAG) and dual averaging, in\nlinear and logistic regression tasks on synthetic and real datasets.\nFurthermore, we propose Dynamic GADMM (D-GADMM), a variant of GADMM, and prove\nits convergence under the time-varying network topology of the workers.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 19:39:37 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 10:18:43 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 12:06:09 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Elgabli", "Anis", ""], ["Park", "Jihong", ""], ["Bedi", "Amrit S.", ""], ["Bennis", "Mehdi", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1909.00052", "submitter": "Amey Agrawal", "authors": "Amey Agrawal, Rohit Karlupia", "title": "Learning Digital Circuits: A Journey Through Weight Invariant\n  Self-Pruning Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, in the paper \"Weight Agnostic Neural Networks\" Gaier & Ha utilized\narchitecture search to find networks where the topology completely encodes the\nknowledge. However, architecture search in topology space is expensive. We use\nthe existing framework of binarized networks to find performant topologies by\nconstraining the weights to be either, zero or one. We show that such\ntopologies achieve performance similar to standard networks while pruning more\nthan 99% weights. We further demonstrate that these topologies can perform\ntasks using constant weights without any explicit tuning. Finally, we discover\nthat in our setup each neuron acts like a NOR gate, virtually learning a\ndigital circuit. We demonstrate the efficacy of our approach on computer vision\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 20:07:39 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 18:42:12 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 22:23:59 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Agrawal", "Amey", ""], ["Karlupia", "Rohit", ""]]}, {"id": "1909.00057", "submitter": "Shaunak Mishra", "authors": "Shaunak Mishra, Jelena Gligorijevic, Narayan Bhamidipati", "title": "Learning from Multi-User Activity Trails for B2B Ad Targeting", "comments": "6 pages, accepted for AdKDD 2019 workshop held in conjunction with\n  KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online purchase decisions in organizations can go through a complex journey\nwith multiple agents involved in the decision making process. Depending on the\nproduct being purchased, and the organizational structure, the process may\ninvolve employees who first conduct market research, and then influence\ndecision makers who place the online purchase order. In such cases, the online\nactivity trail of a single individual in the organization may only provide\npartial information for predicting purchases (conversions). To refine\nconversion prediction for business-to-business (B2B) products using online\nactivity trails, we introduce the notion of relevant users in an organization\nwith respect to a given B2B advertiser, and leverage the collective activity\ntrails of such relevant users to predict conversions. In particular, our notion\nof relevant users is tied to a seed list of relevant activities for a B2B\nadvertiser, and we propose a method using distributed activity representations\nto build such a seed list. Experiments using data from Yahoo Gemini demonstrate\nthat the proposed methods can improve conversion prediction AUC by 8.8%, and\nprovide an interpretable advertiser specific list of activities useful for B2B\nad targeting.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:52:33 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Mishra", "Shaunak", ""], ["Gligorijevic", "Jelena", ""], ["Bhamidipati", "Narayan", ""]]}, {"id": "1909.00066", "submitter": "Amanda Coston", "authors": "Amanda Coston, Alan Mishler, Edward H. Kennedy, Alexandra Chouldechova", "title": "Counterfactual Risk Assessments, Evaluation, and Fairness", "comments": "To appear in ACM FAT* 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic risk assessments are increasingly used to help humans make\ndecisions in high-stakes settings, such as medicine, criminal justice and\neducation. In each of these cases, the purpose of the risk assessment tool is\nto inform actions, such as medical treatments or release conditions, often with\nthe aim of reducing the likelihood of an adverse event such as hospital\nreadmission or recidivism. Problematically, most tools are trained and\nevaluated on historical data in which the outcomes observed depend on the\nhistorical decision-making policy. These tools thus reflect risk under the\nhistorical policy, rather than under the different decision options that the\ntool is intended to inform. Even when tools are constructed to predict risk\nunder a specific decision, they are often improperly evaluated as predictors of\nthe target outcome.\n  Focusing on the evaluation task, in this paper we define counterfactual\nanalogues of common predictive performance and algorithmic fairness metrics\nthat we argue are better suited for the decision-making context. We introduce a\nnew method for estimating the proposed metrics using doubly robust estimation.\nWe provide theoretical results that show that only under strong conditions can\nfairness according to the standard metric and the counterfactual metric\nsimultaneously hold. Consequently, fairness-promoting methods that target\nparity in a standard fairness metric may --- and as we show empirically, do ---\ninduce greater imbalance in the counterfactual analogue. We provide empirical\ncomparisons on both synthetic data and a real world child welfare dataset to\ndemonstrate how the proposed method improves upon standard practice.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 20:47:20 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 15:15:16 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 14:08:46 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Coston", "Amanda", ""], ["Mishler", "Alan", ""], ["Kennedy", "Edward H.", ""], ["Chouldechova", "Alexandra", ""]]}, {"id": "1909.00084", "submitter": "Subru Krishnan", "authors": "Ashvin Agrawal, Rony Chatterjee, Carlo Curino, Avrilia Floratou, Neha\n  Gowdal, Matteo Interlandi, Alekh Jindal, Kostantinos Karanasos, Subru\n  Krishnan, Brian Kroth, Jyoti Leeka, Kwanghyun Park, Hiren Patel, Olga Poppe,\n  Fotis Psallidas, Raghu Ramakrishnan, Abhishek Roy, Karla Saur, Rathijit Sen,\n  Markus Weimer, Travis Wright, Yiwen Zhu", "title": "Cloudy with high chance of DBMS: A 10-year prediction for\n  Enterprise-Grade ML", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning (ML) has proven itself in high-value web applications such\nas search ranking and is emerging as a powerful tool in a much broader range of\nenterprise scenarios including voice recognition and conversational\nunderstanding for customer support, autotuning for videoconferencing,\nintelligent feedback loops in large-scale sysops, manufacturing and autonomous\nvehicle management, complex financial predictions, just to name a few.\nMeanwhile, as the value of data is increasingly recognized and monetized,\nconcerns about securing valuable data and risks to individual privacy have been\ngrowing. Consequently, rigorous data management has emerged as a key\nrequirement in enterprise settings. How will these trends (ML growing\npopularity, and stricter data governance) intersect? What are the unmet\nrequirements for applying ML in enterprise settings? What are the technical\nchallenges for the DB community to solve? In this paper, we present our vision\nof how ML and database systems are likely to come together, and early steps we\ntake towards making this vision a reality.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 22:37:15 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 23:48:38 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Agrawal", "Ashvin", ""], ["Chatterjee", "Rony", ""], ["Curino", "Carlo", ""], ["Floratou", "Avrilia", ""], ["Gowdal", "Neha", ""], ["Interlandi", "Matteo", ""], ["Jindal", "Alekh", ""], ["Karanasos", "Kostantinos", ""], ["Krishnan", "Subru", ""], ["Kroth", "Brian", ""], ["Leeka", "Jyoti", ""], ["Park", "Kwanghyun", ""], ["Patel", "Hiren", ""], ["Poppe", "Olga", ""], ["Psallidas", "Fotis", ""], ["Ramakrishnan", "Raghu", ""], ["Roy", "Abhishek", ""], ["Saur", "Karla", ""], ["Sen", "Rathijit", ""], ["Weimer", "Markus", ""], ["Wright", "Travis", ""], ["Zhu", "Yiwen", ""]]}, {"id": "1909.00088", "submitter": "Steven Y. Feng", "authors": "Steven Y. Feng, Aaron W. Li and Jesse Hoey", "title": "Keep Calm and Switch On! Preserving Sentiment and Fluency in Semantic\n  Text Exchange", "comments": "EMNLP-IJCNLP 2019; Code available at\n  https://github.com/styfeng/SMERTI", "journal-ref": null, "doi": "10.18653/v1/D19-1272", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel method for measurably adjusting the\nsemantics of text while preserving its sentiment and fluency, a task we call\nsemantic text exchange. This is useful for text data augmentation and the\nsemantic correction of text generated by chatbots and virtual assistants. We\nintroduce a pipeline called SMERTI that combines entity replacement, similarity\nmasking, and text infilling. We measure our pipeline's success by its Semantic\nText Exchange Score (STES): the ability to preserve the original text's\nsentiment and fluency while adjusting semantic content. We propose to use\nmasking (replacement) rate threshold as an adjustable parameter to control the\namount of semantic change in the text. Our experiments demonstrate that SMERTI\ncan outperform baseline models on Yelp reviews, Amazon reviews, and news\nheadlines.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 23:10:28 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 07:59:38 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Feng", "Steven Y.", ""], ["Li", "Aaron W.", ""], ["Hoey", "Jesse", ""]]}, {"id": "1909.00102", "submitter": "Alexander Hanbo Li", "authors": "Alexander Hanbo Li, Abhinav Sethy", "title": "Knowledge Enhanced Attention for Robust Natural Language Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models have been very successful at achieving high accuracy on\nnatural language inference (NLI) tasks. However, as demonstrated in recent\nliterature, when tested on some simple adversarial examples, most of the models\nsuffer a significant drop in performance. This raises the concern about the\nrobustness of NLI models. In this paper, we propose to make NLI models robust\nby incorporating external knowledge to the attention mechanism using a simple\ntransformation. We apply the new attention to two popular types of NLI models:\none is Transformer encoder, and the other is a decomposable model, and show\nthat our method can significantly improve their robustness. Moreover, when\ncombined with BERT pretraining, our method achieves the human-level performance\non the adversarial SNLI data set.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 01:04:58 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Sethy", "Abhinav", ""]]}, {"id": "1909.00105", "submitter": "Bodhisattwa Prasad Majumder", "authors": "Bodhisattwa Prasad Majumder, Shuyang Li, Jianmo Ni, Julian McAuley", "title": "Generating Personalized Recipes from Historical User Preferences", "comments": "Accepted in EMNLP 2019. Data and codes are available at\n  https://github.com/majumderb/recipe-personalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to recipe generation are unable to create recipes for\nusers with culinary preferences but incomplete knowledge of ingredients in\nspecific dishes. We propose a new task of personalized recipe generation to\nhelp these users: expanding a name and incomplete ingredient details into\ncomplete natural-text instructions aligned with the user's historical\npreferences. We attend on technique- and recipe-level representations of a\nuser's previously consumed recipes, fusing these 'user-aware' representations\nin an attention fusion layer to control recipe text generation. Experiments on\na new dataset of 180K recipes and 700K interactions show our model's ability to\ngenerate plausible and personalized recipes compared to non-personalized\nbaselines.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 01:50:42 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Majumder", "Bodhisattwa Prasad", ""], ["Li", "Shuyang", ""], ["Ni", "Jianmo", ""], ["McAuley", "Julian", ""]]}, {"id": "1909.00109", "submitter": "Daniel Andor", "authors": "Daniel Andor, Luheng He, Kenton Lee, Emily Pitler", "title": "Giving BERT a Calculator: Finding Operations and Arguments with Reading\n  Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension models have been successfully applied to extractive\ntext answers, but it is unclear how best to generalize these models to\nabstractive numerical answers. We enable a BERT-based reading comprehension\nmodel to perform lightweight numerical reasoning. We augment the model with a\npredefined set of executable 'programs' which encompass simple arithmetic as\nwell as extraction. Rather than having to learn to manipulate numbers directly,\nthe model can pick a program and execute it. On the recent Discrete Reasoning\nOver Passages (DROP) dataset, designed to challenge reading comprehension\nmodels, we show a 33% absolute improvement by adding shallow programs. The\nmodel can learn to predict new operations when appropriate in a math word\nproblem setting (Roy and Roth, 2015) with very few training examples.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 02:30:24 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 21:55:23 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Andor", "Daniel", ""], ["He", "Luheng", ""], ["Lee", "Kenton", ""], ["Pitler", "Emily", ""]]}, {"id": "1909.00116", "submitter": "Dong Xia", "authors": "Dong Xia and Ming Yuan", "title": "Statistical Inferences of Linear Forms for Noisy Matrix Completion", "comments": "Minor typos are corrected; real data examples are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a flexible framework for making inferences about general linear\nforms of a large matrix based on noisy observations of a subset of its entries.\nIn particular, under mild regularity conditions, we develop a universal\nprocedure to construct asymptotically normal estimators of its linear forms\nthrough double-sample debiasing and low-rank projection whenever an entry-wise\nconsistent estimator of the matrix is available. These estimators allow us to\nsubsequently construct confidence intervals for and test hypotheses about the\nlinear forms. Our proposal was motivated by a careful perturbation analysis of\nthe empirical singular spaces under the noisy matrix completion model which\nmight be of independent interest. The practical merits of our proposed\ninference procedure are demonstrated on both simulated and real-world data\nexamples.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 03:30:07 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 08:49:01 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Xia", "Dong", ""], ["Yuan", "Ming", ""]]}, {"id": "1909.00122", "submitter": "Shen Yan", "authors": "Shen Yan, Biyi Fang, Faen Zhang, Yu Zheng, Xiao Zeng, Hui Xu, Mi Zhang", "title": "HM-NAS: Efficient Neural Architecture Search via Hierarchical Masking", "comments": "9 pages, 6 figures, 6 tables. Nominated for ICCV 2019 Neural\n  Architects Workshop Best Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of automatic methods, often referred to as Neural Architecture Search\n(NAS), in designing neural network architectures has recently drawn\nconsiderable attention. In this work, we present an efficient NAS approach,\nnamed HM- NAS, that generalizes existing weight sharing based NAS approaches.\nExisting weight sharing based NAS approaches still adopt hand-designed\nheuristics to generate architecture candidates. As a consequence, the space of\narchitecture candidates is constrained in a subset of all possible\narchitectures, making the architecture search results sub-optimal. HM-NAS\naddresses this limitation via two innovations. First, HM-NAS incorporates a\nmulti-level architecture encoding scheme to enable searching for more flexible\nnetwork architectures. Second, it discards the hand-designed heuristics and\nincorporates a hierarchical masking scheme that automatically learns and\ndetermines the optimal architecture. Compared to state-of-the-art weight\nsharing based approaches, HM-NAS is able to achieve better architecture search\nperformance and competitive model evaluation accuracy. Without the constraint\nimposed by the hand-designed heuristics, our searched networks contain more\nflexible and meaningful architectures that existing weight sharing based NAS\napproaches are not able to discover.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 04:02:16 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 08:33:25 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Yan", "Shen", ""], ["Fang", "Biyi", ""], ["Zhang", "Faen", ""], ["Zheng", "Yu", ""], ["Zeng", "Xiao", ""], ["Xu", "Hui", ""], ["Zhang", "Mi", ""]]}, {"id": "1909.00124", "submitter": "Hao Wang", "authors": "Hao Wang, Bing Liu, Chaozhuo Li, Yan Yang, and Tianrui Li", "title": "Learning with Noisy Labels for Sentence-level Sentiment Classification", "comments": "to appear in EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) can fit (or even over-fit) the training data very\nwell. If a DNN model is trained using data with noisy labels and tested on data\nwith clean labels, the model may perform poorly. This paper studies the problem\nof learning with noisy labels for sentence-level sentiment classification. We\npropose a novel DNN model called NetAb (as shorthand for convolutional neural\nNetworks with Ab-networks) to handle noisy labels during training. NetAb\nconsists of two convolutional neural networks, one with a noise transition\nlayer for dealing with the input noisy labels and the other for predicting\n'clean' labels. We train the two networks using their respective loss functions\nin a mutual reinforcement manner. Experimental results demonstrate the\neffectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 04:18:50 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Hao", ""], ["Liu", "Bing", ""], ["Li", "Chaozhuo", ""], ["Yang", "Yan", ""], ["Li", "Tianrui", ""]]}, {"id": "1909.00126", "submitter": "Tao Li", "authors": "Tao Li, Vivek Gupta, Maitrey Mehta, Vivek Srikumar", "title": "A Logic-Driven Framework for Consistency of Neural Models", "comments": "Accepted in EMNLP 2019; Extra footnote after camera ready; Addressing\n  R-fuzzy and S-fuzzy logic + extra acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural models show remarkable accuracy on individual predictions, their\ninternal beliefs can be inconsistent across examples. In this paper, we\nformalize such inconsistency as a generalization of prediction error. We\npropose a learning framework for constraining models using logic rules to\nregularize them away from inconsistency. Our framework can leverage both\nlabeled and unlabeled examples and is directly compatible with off-the-shelf\nlearning schemes without model redesign. We instantiate our framework on\nnatural language inference, where experiments show that enforcing invariants\nstated in logic can help make the predictions of neural models both accurate\nand consistent.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 04:38:06 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 01:17:57 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 00:20:14 GMT"}, {"version": "v4", "created": "Fri, 13 Sep 2019 03:52:50 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Li", "Tao", ""], ["Gupta", "Vivek", ""], ["Mehta", "Maitrey", ""], ["Srikumar", "Vivek", ""]]}, {"id": "1909.00131", "submitter": "Prathyusha Jwalapuram", "authors": "Prathyusha Jwalapuram, Shafiq Joty, Irina Temnikova and Preslav Nakov", "title": "Evaluating Pronominal Anaphora in Machine Translation: An Evaluation\n  Measure and a Test Suite", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing neural revolution in machine translation has made it easier to\nmodel larger contexts beyond the sentence-level, which can potentially help\nresolve some discourse-level ambiguities such as pronominal anaphora, thus\nenabling better translations. Unfortunately, even when the resulting\nimprovements are seen as substantial by humans, they remain virtually unnoticed\nby traditional automatic evaluation measures like BLEU, as only a few words end\nup being affected. Thus, specialized evaluation measures are needed. With this\naim in mind, we contribute an extensive, targeted dataset that can be used as a\ntest suite for pronoun translation, covering multiple source languages and\ndifferent pronoun errors drawn from real system translations, for English. We\nfurther propose an evaluation measure to differentiate good and bad pronoun\ntranslations. We also conduct a user study to report correlations with human\njudgments.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 05:28:51 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Jwalapuram", "Prathyusha", ""], ["Joty", "Shafiq", ""], ["Temnikova", "Irina", ""], ["Nakov", "Preslav", ""]]}, {"id": "1909.00141", "submitter": "Deren Lei", "authors": "Siyao Li, Deren Lei, Pengda Qin, William Yang Wang", "title": "Deep Reinforcement Learning with Distributional Semantic Rewards for\n  Abstractive Summarization", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has been a commonly-used strategy for the\nabstractive summarization task to address both the exposure bias and\nnon-differentiable task issues. However, the conventional reward Rouge-L simply\nlooks for exact n-grams matches between candidates and annotated references,\nwhich inevitably makes the generated sentences repetitive and incoherent. In\nthis paper, instead of Rouge-L, we explore the practicability of utilizing the\ndistributional semantics to measure the matching degrees. With distributional\nsemantics, sentence-level evaluation can be obtained, and semantically-correct\nphrases can also be generated without being limited to the surface form of the\nreference sentences. Human judgments on Gigaword and CNN/Daily Mail datasets\nshow that our proposed distributional semantics reward (DSR) has distinct\nsuperiority in capturing the lexical and compositional diversity of natural\nlanguage.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 06:13:33 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 23:30:26 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Li", "Siyao", ""], ["Lei", "Deren", ""], ["Qin", "Pengda", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.00145", "submitter": "Jinhui Xiong", "authors": "Jinhui Xiong, Peter Richt\\'arik, Wolfgang Heidrich", "title": "Stochastic Convolutional Sparse Coding", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art methods for Convolutional Sparse Coding usually employ\nFourier-domain solvers in order to speed up the convolution operators. However,\nthis approach is not without shortcomings. For example, Fourier-domain\nrepresentations implicitly assume circular boundary conditions and make it hard\nto fully exploit the sparsity of the problem as well as the small spatial\nsupport of the filters. In this work, we propose a novel stochastic\nspatial-domain solver, in which a randomized subsampling strategy is introduced\nduring the learning sparse codes. Afterwards, we extend the proposed strategy\nin conjunction with online learning, scaling the CSC model up to very large\nsample sizes. In both cases, we show experimentally that the proposed\nsubsampling strategy, with a reasonable selection of the subsampling rate,\noutperforms the state-of-the-art frequency-domain solvers in terms of execution\ntime without losing the learning quality. Finally, we evaluate the\neffectiveness of the over-complete dictionary learned from large-scale\ndatasets, which demonstrates an improved sparse representation of the natural\nimages on account of more abundant learned image features.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 06:37:08 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Xiong", "Jinhui", ""], ["Richt\u00e1rik", "Peter", ""], ["Heidrich", "Wolfgang", ""]]}, {"id": "1909.00153", "submitter": "Phillip Keung", "authors": "Phillip Keung, Yichao Lu, Vikas Bhardwaj", "title": "Adversarial Learning with Contextual Embeddings for Zero-resource\n  Cross-lingual Classification and NER", "comments": "In EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual word embeddings (e.g. GPT, BERT, ELMo, etc.) have demonstrated\nstate-of-the-art performance on various NLP tasks. Recent work with the\nmultilingual version of BERT has shown that the model performs very well in\nzero-shot and zero-resource cross-lingual settings, where only labeled English\ndata is used to finetune the model. We improve upon multilingual BERT's\nzero-resource cross-lingual performance via adversarial learning. We report the\nmagnitude of the improvement on the multilingual MLDoc text classification and\nCoNLL 2002/2003 named entity recognition tasks. Furthermore, we show that\nlanguage-adversarial training encourages BERT to align the embeddings of\nEnglish documents and their translations, which may be the cause of the\nobserved performance gains.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 06:59:46 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 06:02:01 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 20:09:25 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Keung", "Phillip", ""], ["Lu", "Yichao", ""], ["Bhardwaj", "Vikas", ""]]}, {"id": "1909.00154", "submitter": "Francisco Pereira", "authors": "Francisco C. Pereira", "title": "Rethinking travel behavior modeling representations through embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of travel behavior embeddings, a method for\nre-representing discrete variables that are typically used in travel demand\nmodeling, such as mode, trip purpose, education level, family type or\noccupation. This re-representation process essentially maps those variables\ninto a latent space called the \\emph{embedding space}. The benefit of this is\nthat such spaces allow for richer nuances than the typical transformations used\nin categorical variables (e.g. dummy encoding, contrasted encoding, principal\ncomponents analysis). While the usage of latent variable representations is not\nnew per se in travel demand modeling, the idea presented here brings several\ninnovations: it is an entirely data driven algorithm; it is informative and\nconsistent, since the latent space can be visualized and interpreted based on\ndistances between different categories; it preserves interpretability of\ncoefficients, despite being based on Neural Network principles; and it is\ntransferrable, in that embeddings learned from one dataset can be reused for\nother ones, as long as travel behavior keeps consistent between the datasets.\n  The idea is strongly inspired on natural language processing techniques,\nnamely the word2vec algorithm. Such algorithm is behind recent developments\nsuch as in automatic translation or next word prediction. Our method is\ndemonstrated using a model choice model, and shows improvements of up to 60\\%\nwith respect to initial likelihood, and up to 20% with respect to likelihood of\nthe corresponding traditional model (i.e. using dummy variables) in\nout-of-sample evaluation. We provide a new Python package, called PyTre (PYthon\nTRavel Embeddings), that others can straightforwardly use to replicate our\nresults or improve their own models. Our experiments are themselves based on an\nopen dataset (swissmetro).\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 07:05:43 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Pereira", "Francisco C.", ""]]}, {"id": "1909.00160", "submitter": "Soumya Sharma", "authors": "Soumya Sharma, Bishal Santra, Abhik Jana, T.Y.S.S. Santosh, Niloy\n  Ganguly and Pawan Goyal", "title": "Incorporating Domain Knowledge into Medical NLI using Knowledge Graphs", "comments": "EMNLP 2019 accepted short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, biomedical version of embeddings obtained from language models such\nas BioELMo have shown state-of-the-art results for the textual inference task\nin the medical domain. In this paper, we explore how to incorporate structured\ndomain knowledge, available in the form of a knowledge graph (UMLS), for the\nMedical NLI task. Specifically, we experiment with fusing embeddings obtained\nfrom knowledge graph with the state-of-the-art approaches for NLI task (ESIM\nmodel). We also experiment with fusing the domain-specific sentiment\ninformation for the task. Experiments conducted on MedNLI dataset clearly show\nthat this strategy improves the baseline BioELMo architecture for the Medical\nNLI task.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 07:41:42 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Sharma", "Soumya", ""], ["Santra", "Bishal", ""], ["Jana", "Abhik", ""], ["Santosh", "T. Y. S. S.", ""], ["Ganguly", "Niloy", ""], ["Goyal", "Pawan", ""]]}, {"id": "1909.00182", "submitter": "Aojun Zhou", "authors": "Zhuoran Yu, Aojun Zhou, Yukun Ma, Yudian Li, Xiaohan Zhang, Ping Luo", "title": "Scale Calibrated Training: Improving Generalization of Deep Networks via\n  Scale-Specific Normalization", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard convolutional neural networks(CNNs) require consistent image\nresolutions in both training and testing phase. However, in practice, testing\nwith smaller image sizes is necessary for fast inference. We show that\ntrivially evaluating low-resolution images on networks trained with\nhigh-resolution images results in a catastrophic accuracy drop in standard CNN\narchitectures. We propose a novel training regime called Scale calibrated\nTraining(SCT) which allows networks to learn from various scales of input\nsimultaneously. By taking advantages of SCT, single network can provide decent\naccuracy at test time in response to multiple test scales. In our analysis, we\nsurprisingly find that vanilla batch normalization can lead to sub-optimal\nperformance in SCT. Therefore, a novel normalization scheme called\nScale-Specific Batch Normalization is equipped to SCT in replacement of batch\nnormalization. Experiment results show that SCT improves accuracy of single\nResnet-50 on ImageNet by 1.7% and 11.5% accuracy when testing on image sizes of\n224 and 128 respectively.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 10:01:37 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 15:09:01 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Yu", "Zhuoran", ""], ["Zhou", "Aojun", ""], ["Ma", "Yukun", ""], ["Li", "Yudian", ""], ["Zhang", "Xiaohan", ""], ["Luo", "Ping", ""]]}, {"id": "1909.00183", "submitter": "Muhammed Tarik Altuncu", "authors": "M. Tarik Altuncu, Eloise Sorin, Joshua D. Symons, Erik Mayer, Sophia\n  N. Yaliraki, Francesca Toni, Mauricio Barahona", "title": "Extracting information from free text through unsupervised graph-based\n  clustering: an application to patient incident records", "comments": "To appear as a book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large volume of text in electronic healthcare records often remains\nunderused due to a lack of methodologies to extract interpretable content. Here\nwe present an unsupervised framework for the analysis of free text that\ncombines text-embedding with paragraph vectors and graph-theoretical multiscale\ncommunity detection. We analyse text from a corpus of patient incident reports\nfrom the National Health Service in England to find content-based clusters of\nreports in an unsupervised manner and at different levels of resolution. Our\nunsupervised method extracts groups with high intrinsic textual consistency and\ncompares well against categories hand-coded by healthcare personnel. We also\nshow how to use our content-driven clusters to improve the supervised\nprediction of the degree of harm of the incident based on the text of the\nreport. Finally, we discuss future directions to monitor reports over time, and\nto detect emerging trends outside pre-existing categories.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 10:03:11 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Altuncu", "M. Tarik", ""], ["Sorin", "Eloise", ""], ["Symons", "Joshua D.", ""], ["Mayer", "Erik", ""], ["Yaliraki", "Sophia N.", ""], ["Toni", "Francesca", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1909.00215", "submitter": "Yi-Ting Yeh", "authors": "Yi-Ting Yeh, Yun-Nung Chen", "title": "QAInfomax: Learning Robust Question Answering System by Mutual\n  Information Maximization", "comments": "EMNLP 2019 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard accuracy metrics indicate that modern reading comprehension systems\nhave achieved strong performance in many question answering datasets. However,\nthe extent these systems truly understand language remains unknown, and\nexisting systems are not good at distinguishing distractor sentences, which\nlook related but do not actually answer the question. To address this problem,\nwe propose QAInfomax as a regularizer in reading comprehension systems by\nmaximizing mutual information among passages, a question, and its answer.\nQAInfomax helps regularize the model to not simply learn the superficial\ncorrelation for answering questions. The experiments show that our proposed\nQAInfomax achieves the state-of-the-art performance on the benchmark\nAdversarial-SQuAD dataset.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 13:50:28 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yeh", "Yi-Ting", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1909.00216", "submitter": "Francesco Giannini", "authors": "Francesco Giannini and Marco Maggini", "title": "Conditions for Unnecessary Logical Constraints in Kernel Machines", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30484-3_49", "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main property of support vector machines consists in the fact that only a\nsmall portion of the training data is significant to determine the maximum\nmargin separating hyperplane in the feature space, the so called support\nvectors. In a similar way, in the general scheme of learning from constraints,\nwhere possibly several constraints are considered, some of them may turn out to\nbe unnecessary with respect to the learning optimization, even if they are\nactive for a given optimal solution. In this paper we extend the definition of\nsupport vector to support constraint and we provide some criteria to determine\nwhich constraints can be removed from the learning problem still yielding the\nsame optimal solutions. In particular, we discuss the case of logical\nconstraints expressed by Lukasiewicz logic, where both inferential and\nalgebraic arguments can be considered. Some theoretical results that\ncharacterize the concept of unnecessary constraint are proved and explained by\nmeans of examples.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 14:00:04 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 13:38:07 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Giannini", "Francesco", ""], ["Maggini", "Marco", ""]]}, {"id": "1909.00218", "submitter": "Eyke H\\\"ullermeier", "authors": "Vu-Linh Nguyen, S\\'ebastien Destercke, Eyke H\\\"ullermeier", "title": "Epistemic Uncertainty Sampling", "comments": "Draft version of a paper to be published in the proceedings of DS\n  2019, 22nd International Conference on Discovery Science, Split, Croatia,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various strategies for active learning have been proposed in the machine\nlearning literature. In uncertainty sampling, which is among the most popular\napproaches, the active learner sequentially queries the label of those\ninstances for which its current prediction is maximally uncertain. The\npredictions as well as the measures used to quantify the degree of uncertainty,\nsuch as entropy, are almost exclusively of a probabilistic nature. In this\npaper, we advocate a distinction between two different types of uncertainty,\nreferred to as epistemic and aleatoric, in the context of active learning.\nRoughly speaking, these notions capture the reducible and the irreducible part\nof the total uncertainty in a prediction, respectively. We conjecture that, in\nuncertainty sampling, the usefulness of an instance is better reflected by its\nepistemic than by its aleatoric uncertainty. This leads us to suggest the\nprinciple of \"epistemic uncertainty sampling\", which we instantiate by means of\na concrete approach for measuring epistemic and aleatoric uncertainty. In\nexperimental studies, epistemic uncertainty sampling does indeed show promising\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 14:04:10 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Nguyen", "Vu-Linh", ""], ["Destercke", "S\u00e9bastien", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1909.00230", "submitter": "Cong Fu", "authors": "Cong Fu, Tong Chen, Meng Qu, Woojeong Jin, Xiang Ren", "title": "Collaborative Policy Learning for Open Knowledge Graph Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been a surge of interests in interpretable graph\nreasoning methods. However, these models often suffer from limited performance\nwhen working on sparse and incomplete graphs, due to the lack of evidential\npaths that can reach target entities. Here we study open knowledge graph\nreasoning---a task that aims to reason for missing facts over a graph augmented\nby a background text corpus. A key challenge of the task is to filter out\n\"irrelevant\" facts extracted from corpus, in order to maintain an effective\nsearch space during path inference. We propose a novel reinforcement learning\nframework to train two collaborative agents jointly, i.e., a multi-hop graph\nreasoner and a fact extractor. The fact extraction agent generates fact triples\nfrom corpora to enrich the graph on the fly; while the reasoning agent provides\nfeedback to the fact extractor and guides it towards promoting facts that are\nhelpful for the interpretable reasoning. Experiments on two public datasets\ndemonstrate the effectiveness of the proposed approach. Source code and\ndatasets used in this paper can be downloaded at\nhttps://github.com/shanzhenren/CPL\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 15:46:05 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Fu", "Cong", ""], ["Chen", "Tong", ""], ["Qu", "Meng", ""], ["Jin", "Woojeong", ""], ["Ren", "Xiang", ""]]}, {"id": "1909.00240", "submitter": "Muhammad Usman Ghani", "authors": "Muhammad Usman Ghani and W. Clem Karl", "title": "Integrating Data and Image Domain Deep Learning for Limited Angle\n  Tomography using Consensus Equilibrium", "comments": "Accepted for publication in proceedings of IEEE ICCV Workshop on\n  Learning for Computational Imaging (ICCVW-LCI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computed Tomography (CT) is a non-invasive imaging modality with applications\nranging from healthcare to security. It reconstructs cross-sectional images of\nan object using a collection of projection data collected at different angles.\nConventional methods, such as FBP, require that the projection data be\nuniformly acquired over the complete angular range. In some applications, it is\nnot possible to acquire such data. Security is one such domain where\nnon-rotational scanning configurations are being developed which violate the\ncomplete data assumption. Conventional methods produce images from such data\nthat are filled with artifacts. The recent success of deep learning (DL)\nmethods has inspired researchers to post-process these artifact laden images\nusing deep neural networks (DNNs). This approach has seen limited success on\nreal CT problems. Another approach has been to pre-process the incomplete data\nusing DNNs aiming to avoid the creation of artifacts altogether. Due to\nimperfections in the learning process, this approach can still leave\nperceptible residual artifacts. In this work, we aim to combine the power of\ndeep learning in both the data and image domains through a two-step process\nbased on the consensus equilibrium (CE) framework. Specifically, we use\nconditional generative adversarial networks (cGANs) in both the data and the\nimage domain for enhanced performance and efficient computation and combine\nthem through a consensus process. We demonstrate the effectiveness of our\napproach on a real security CT dataset for a challenging 90 degree\nlimited-angle problem. The same framework can be applied to other limited data\nproblems arising in applications such as electron microscopy, non-destructive\nevaluation, and medical imaging.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 16:46:12 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ghani", "Muhammad Usman", ""], ["Karl", "W. Clem", ""]]}, {"id": "1909.00252", "submitter": "Orion Weller", "authors": "Orion Weller and Kevin Seppi", "title": "Humor Detection: A Transformer Gets the Last Laugh", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much previous work has been done in attempting to identify humor in text. In\nthis paper we extend that capability by proposing a new task: assessing whether\nor not a joke is humorous. We present a novel way of approaching this problem\nby building a model that learns to identify humorous jokes based on ratings\ngleaned from Reddit pages, consisting of almost 16,000 labeled instances. Using\nthese ratings to determine the level of humor, we then employ a Transformer\narchitecture for its advantages in learning from sentence context. We\ndemonstrate the effectiveness of this approach and show results that are\ncomparable to human performance. We further demonstrate our model's increased\ncapabilities on humor identification problems, such as the previously created\ndatasets for short jokes and puns. These experiments show that this method\noutperforms all previous work done on these tasks, with an F-measure of 93.1%\nfor the Puns dataset and 98.6% on the Short Jokes dataset.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 18:01:29 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Weller", "Orion", ""], ["Seppi", "Kevin", ""]]}, {"id": "1909.00259", "submitter": "Hiroyuki Shindo", "authors": "Hiroyuki Shindo, Yuji Matsumoto", "title": "Gated Graph Recursive Neural Networks for Molecular Property Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecule property prediction is a fundamental problem for computer-aided drug\ndiscovery and materials science. Quantum-chemical simulations such as density\nfunctional theory (DFT) have been widely used for calculating the molecule\nproperties, however, because of the heavy computational cost, it is difficult\nto search a huge number of potential chemical compounds. Machine learning\nmethods for molecular modeling are attractive alternatives, however, the\ndevelopment of expressive, accurate, and scalable graph neural networks for\nlearning molecular representations is still challenging. In this work, we\npropose a simple and powerful graph neural networks for molecular property\nprediction. We model a molecular as a directed complete graph in which each\natom has a spatial position, and introduce a recursive neural network with\nsimple gating function. We also feed input embeddings for every layers as skip\nconnections to accelerate the training. Experimental results show that our\nmodel achieves the state-of-the-art performance on the standard benchmark\ndataset for molecular property prediction.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 18:30:06 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 08:27:43 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shindo", "Hiroyuki", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1909.00270", "submitter": "Shima Rafiei", "authors": "Safiyeh Rezaei, Ali Emami, Hamidreza Zarrabi, Shima Rafiei, Kayvan\n  Najarian, Nader Karimi, Shadrokh Samavi, S.M.Reza Soroushmehr", "title": "Gland Segmentation in Histopathology Images Using Deep Networks and\n  Handcrafted Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histopathology images contain essential information for medical diagnosis and\nprognosis of cancerous disease. Segmentation of glands in histopathology images\nis a primary step for analysis and diagnosis of an unhealthy patient. Due to\nthe widespread application and the great success of deep neural networks in\nintelligent medical diagnosis and histopathology, we propose a modified version\nof LinkNet for gland segmentation and recognition of malignant cases. We show\nthat using specific handcrafted features such as invariant local binary pattern\ndrastically improves the system performance. The experimental results\ndemonstrate the competency of the proposed system against state-of-the-art\nmethods. We achieved the best results in testing on section B images of the\nWarwick-QU dataset and obtained comparable results on section A images.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 19:42:12 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Rezaei", "Safiyeh", ""], ["Emami", "Ali", ""], ["Zarrabi", "Hamidreza", ""], ["Rafiei", "Shima", ""], ["Najarian", "Kayvan", ""], ["Karimi", "Nader", ""], ["Samavi", "Shadrokh", ""], ["Soroushmehr", "S. M. Reza", ""]]}, {"id": "1909.00273", "submitter": "Shima Rafiei", "authors": "Zahra Sobhaninia, Shima Rafiei, Ali Emami, Nader Karimi, Kayvan\n  Najarian, Shadrokh Samavi, S.M.Reza Soroushmehr", "title": "Fetal Ultrasound Image Segmentation for Measuring Biometric Parameters\n  Using Multi-Task Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound imaging is a standard examination during pregnancy that can be\nused for measuring specific biometric parameters towards prenatal diagnosis and\nestimating gestational age. Fetal head circumference (HC) is one of the\nsignificant factors to determine the fetus growth and health. In this paper, a\nmulti-task deep convolutional neural network is proposed for automatic\nsegmentation and estimation of HC ellipse by minimizing a compound cost\nfunction composed of segmentation dice score and MSE of ellipse parameters.\nExperimental results on fetus ultrasound dataset in different trimesters of\npregnancy show that the segmentation results and the extracted HC match well\nwith the radiologist annotations. The obtained dice scores of the fetal head\nsegmentation and the accuracy of HC evaluations are comparable to the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 19:43:31 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Sobhaninia", "Zahra", ""], ["Rafiei", "Shima", ""], ["Emami", "Ali", ""], ["Karimi", "Nader", ""], ["Najarian", "Kayvan", ""], ["Samavi", "Shadrokh", ""], ["Soroushmehr", "S. M. Reza", ""]]}, {"id": "1909.00276", "submitter": "Robert Holland", "authors": "Robert Holland, Uday Patel, Phillip Lung, Elisa Chotzoglou and\n  Bernhard Kainz", "title": "Automatic Detection of Bowel Disease with Residual Networks", "comments": "Accepted to PRIME-MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crohn's disease, one of two inflammatory bowel diseases (IBD), affects\n200,000 people in the UK alone, or roughly one in every 500. We explore the\nfeasibility of deep learning algorithms for identification of terminal ileal\nCrohn's disease in Magnetic Resonance Enterography images on a small dataset.\nWe show that they provide comparable performance to the current clinical\nstandard, the MaRIA score, while requiring only a fraction of the preparation\nand inference time. Moreover, bowels are subject to high variation between\nindividuals due to the complex and free-moving anatomy. Thus we also explore\nthe effect of difficulty of the classification at hand on performance. Finally,\nwe employ soft attention mechanisms to amplify salient local features and add\ninterpretability.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 19:51:23 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Holland", "Robert", ""], ["Patel", "Uday", ""], ["Lung", "Phillip", ""], ["Chotzoglou", "Elisa", ""], ["Kainz", "Bernhard", ""]]}, {"id": "1909.00279", "submitter": "Zhichao Yang", "authors": "Zhichao Yang, Pengshan Cai, Yansong Feng, Fei Li, Weijiang Feng, Elena\n  Suet-Ying Chiu, Hong Yu", "title": "Generating Classical Chinese Poems from Vernacular Chinese", "comments": "Published in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Classical Chinese poetry is a jewel in the treasure house of Chinese culture.\nPrevious poem generation models only allow users to employ keywords to\ninterfere the meaning of generated poems, leaving the dominion of generation to\nthe model. In this paper, we propose a novel task of generating classical\nChinese poems from vernacular, which allows users to have more control over the\nsemantic of generated poems. We adapt the approach of unsupervised machine\ntranslation (UMT) to our task. We use segmentation-based padding and\nreinforcement learning to address under-translation and over-translation\nrespectively. According to experiments, our approach significantly improve the\nperplexity and BLEU compared with typical UMT models. Furthermore, we explored\nguidelines on how to write the input vernacular to generate better poems. Human\nevaluation showed our approach can generate high-quality poems which are\ncomparable to amateur poems.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 20:07:25 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yang", "Zhichao", ""], ["Cai", "Pengshan", ""], ["Feng", "Yansong", ""], ["Li", "Fei", ""], ["Feng", "Weijiang", ""], ["Chiu", "Elena Suet-Ying", ""], ["Yu", "Hong", ""]]}, {"id": "1909.00295", "submitter": "Bryan (Ning) Xia", "authors": "Bryan (Ning) Xia, Yuan Gong, Yizhe Zhang, Christian Poellabauer", "title": "Second-order Non-local Attention Networks for Person Re-identification", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts have shown promising results for person re-identification by\ndesigning part-based architectures to allow a neural network to learn\ndiscriminative representations from semantically coherent parts. Some efforts\nuse soft attention to reallocate distant outliers to their most similar parts,\nwhile others adjust part granularity to incorporate more distant positions for\nlearning the relationships. Others seek to generalize part-based methods by\nintroducing a dropout mechanism on consecutive regions of the feature map to\nenhance distant region relationships. However, only few prior efforts model the\ndistant or non-local positions of the feature map directly for the person re-ID\ntask. In this paper, we propose a novel attention mechanism to directly model\nlong-range relationships via second-order feature statistics. When combined\nwith a generalized DropBlock module, our method performs equally to or better\nthan state-of-the-art results for mainstream person re-identification datasets,\nincluding Market1501, CUHK03, and DukeMTMC-reID.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 22:50:42 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Bryan", "", "", "Ning"], ["Xia", "", ""], ["Gong", "Yuan", ""], ["Zhang", "Yizhe", ""], ["Poellabauer", "Christian", ""]]}, {"id": "1909.00300", "submitter": "Sahar Abdelnabi", "authors": "Sahar Abdelnabi and Katharina Krombholz and Mario Fritz", "title": "VisualPhishNet: Zero-Day Phishing Website Detection by Visual Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing websites are still a major threat in today's Internet ecosystem.\nDespite numerous previous efforts, similarity-based detection methods do not\noffer sufficient protection for the trusted websites - in particular against\nunseen phishing pages. This paper contributes VisualPhishNet, a new\nsimilarity-based phishing detection framework, based on a triplet Convolutional\nNeural Network (CNN). VisualPhishNet learns profiles for websites in order to\ndetect phishing websites by a similarity metric that can generalize to pages\nwith new visual appearances. We furthermore present VisualPhish, the largest\ndataset to date that facilitates visual phishing detection in an ecologically\nvalid manner. We show that our method outperforms previous visual similarity\nphishing detection approaches by a large margin while being robust against a\nrange of evasion attacks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 00:55:10 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 20:39:38 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 16:22:37 GMT"}, {"version": "v4", "created": "Sun, 5 Jul 2020 15:24:44 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Abdelnabi", "Sahar", ""], ["Krombholz", "Katharina", ""], ["Fritz", "Mario", ""]]}, {"id": "1909.00311", "submitter": "Prasanna Balaprakash", "authors": "Prasanna Balaprakash and Romain Egele and Misha Salim and Stefan Wild\n  and Venkatram Vishwanath and Fangfang Xia and Tom Brettin and Rick Stevens", "title": "Scalable Reinforcement-Learning-Based Neural Architecture Search for\n  Cancer Deep Learning Research", "comments": "SC '19: IEEE/ACM International Conference on High Performance\n  Computing, Networking, Storage and Analysis, November 17--22, 2019, Denver,\n  CO", "journal-ref": null, "doi": "10.1145/3295500.3356202", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer is a complex disease, the understanding and treatment of which are\nbeing aided through increases in the volume of collected data and in the scale\nof deployed computing power. Consequently, there is a growing need for the\ndevelopment of data-driven and, in particular, deep learning methods for\nvarious tasks such as cancer diagnosis, detection, prognosis, and prediction.\nDespite recent successes, however, designing high-performing deep learning\nmodels for nonimage and nontext cancer data is a time-consuming,\ntrial-and-error, manual task that requires both cancer domain and deep learning\nexpertise. To that end, we develop a reinforcement-learning-based neural\narchitecture search to automate deep-learning-based predictive model\ndevelopment for a class of representative cancer data. We develop custom\nbuilding blocks that allow domain experts to incorporate the\ncancer-data-specific characteristics. We show that our approach discovers deep\nneural network architectures that have significantly fewer trainable\nparameters, shorter training time, and accuracy similar to or higher than those\nof manually designed architectures. We study and demonstrate the scalability of\nour approach on up to 1,024 Intel Knights Landing nodes of the Theta\nsupercomputer at the Argonne Leadership Computing Facility.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 02:49:59 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Balaprakash", "Prasanna", ""], ["Egele", "Romain", ""], ["Salim", "Misha", ""], ["Wild", "Stefan", ""], ["Vishwanath", "Venkatram", ""], ["Xia", "Fangfang", ""], ["Brettin", "Tom", ""], ["Stevens", "Rick", ""]]}, {"id": "1909.00325", "submitter": "Luke De Oliveira", "authors": "Luke de Oliveira, Alfredo L\\'ainez Rodrigo", "title": "Repurposing Decoder-Transformer Language Models for Abstractive\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models have shown excellent fluency and performance when\napplied to abstractive summarization. Many approaches to neural abstractive\nsummarization involve the introduction of significant inductive bias,\nexemplified through the use of components such as pointer-generator\narchitectures, coverage, and partially extractive procedures, designed to mimic\nthe process by which humans summarize documents. We show that it is possible to\nattain competitive performance by instead directly viewing summarization as a\nlanguage modeling problem and effectively leveraging transfer learning. We\nintroduce a simple procedure built upon decoder-transformers to obtain highly\ncompetitive ROUGE scores for summarization performance using a language\nmodeling loss alone, with no beam-search or other decoding-time optimization,\nand instead relying on efficient nucleus sampling and greedy decoding.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 05:26:30 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["de Oliveira", "Luke", ""], ["Rodrigo", "Alfredo L\u00e1inez", ""]]}, {"id": "1909.00326", "submitter": "Shilin He", "authors": "Shilin He, Zhaopeng Tu, Xing Wang, Longyue Wang, Michael R. Lyu,\n  Shuming Shi", "title": "Towards Understanding Neural Machine Translation with Word Importance", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural machine translation (NMT) has advanced the state-of-the-art\non various language pairs, the interpretability of NMT remains unsatisfactory.\nIn this work, we propose to address this gap by focusing on understanding the\ninput-output behavior of NMT models. Specifically, we measure the word\nimportance by attributing the NMT output to every input word through a\ngradient-based method. We validate the approach on a couple of perturbation\noperations, language pairs, and model architectures, demonstrating its\nsuperiority on identifying input words with higher influence on translation\nperformance. Encouragingly, the calculated importance can serve as indicators\nof input words that are under-translated by NMT models. Furthermore, our\nanalysis reveals that words of certain syntactic categories have higher\nimportance while the categories vary across language pairs, which can inspire\nbetter design principles of NMT architectures for multi-lingual translation.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 06:04:48 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 11:57:20 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["He", "Shilin", ""], ["Tu", "Zhaopeng", ""], ["Wang", "Xing", ""], ["Wang", "Longyue", ""], ["Lyu", "Michael R.", ""], ["Shi", "Shuming", ""]]}, {"id": "1909.00331", "submitter": "Sripad Krishna Devalla", "authors": "Tan Hung Pham, Sripad Krishna Devalla, Aloysius Ang, Soh Zhi Da,\n  Alexandre H. Thiery, Craig Boote, Ching-Yu Cheng, Victor Koh, and Michael J.\n  A. Girard", "title": "Deep Learning Algorithms to Isolate and Quantify the Structures of the\n  Anterior Segment in Optical Coherence Tomography Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate isolation and quantification of intraocular dimensions in the\nanterior segment (AS) of the eye using optical coherence tomography (OCT)\nimages is important in the diagnosis and treatment of many eye diseases,\nespecially angle closure glaucoma. In this study, we developed a deep\nconvolutional neural network (DCNN) for the localization of the scleral spur,\nand the segmentation of anterior segment structures (iris, corneo-sclera shell,\nanterior chamber). With limited training data, the DCNN was able to detect the\nscleral spur on unseen ASOCT images as accurately as an experienced\nophthalmologist; and simultaneously isolated the anterior segment structures\nwith a Dice coefficient of 95.7%. We then automatically extracted eight\nclinically relevant ASOCT parameters and proposed an automated quality check\nprocess that asserts the reliability of these parameters. When combined with an\nOCT machine capable of imaging multiple radial sections, the algorithms can\nprovide a more complete objective assessment. This is an essential step toward\nproviding a robust automated framework for reliable quantification of ASOCT\nscans, for applications in the diagnosis and management of angle closure\nglaucoma.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 06:27:05 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Pham", "Tan Hung", ""], ["Devalla", "Sripad Krishna", ""], ["Ang", "Aloysius", ""], ["Da", "Soh Zhi", ""], ["Thiery", "Alexandre H.", ""], ["Boote", "Craig", ""], ["Cheng", "Ching-Yu", ""], ["Koh", "Victor", ""], ["Girard", "Michael J. A.", ""]]}, {"id": "1909.00333", "submitter": "Hangfeng He", "authors": "Hangfeng He, Qiang Ning, Dan Roth", "title": "QuASE: Question-Answer Driven Sentence Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question-answering (QA) data often encodes essential information in many\nfacets. This paper studies a natural question: Can we get supervision from QA\ndata for other tasks (typically, non-QA ones)? For example, {\\em can we use\nQAMR (Michael et al., 2017) to improve named entity recognition?} We suggest\nthat simply further pre-training BERT is often not the best option, and propose\nthe {\\em question-answer driven sentence encoding (QuASE)} framework. QuASE\nlearns representations from QA data, using BERT or other state-of-the-art\ncontextual language models. In particular, we observe the need to distinguish\nbetween two types of sentence encodings, depending on whether the target task\nis a single- or multi-sentence input; in both cases, the resulting encoding is\nshown to be an easy-to-use plugin for many downstream tasks. This work may\npoint out an alternative way to supervise NLP tasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 06:30:57 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 15:40:12 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 21:12:24 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["He", "Hangfeng", ""], ["Ning", "Qiang", ""], ["Roth", "Dan", ""]]}, {"id": "1909.00337", "submitter": "Zijun Zhang", "authors": "Zijun Zhang, Linqi Zhou, Liangke Gou, Ying Nian Wu", "title": "Neural Architecture Search for Joint Optimization of Predictive Power\n  and Biological Knowledge", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We report a neural architecture search framework, BioNAS, that is tailored\nfor biomedical researchers to easily build, evaluate, and uncover novel\nknowledge from interpretable deep learning models. The introduction of\nknowledge dissimilarity functions in BioNAS enables the joint optimization of\npredictive power and biological knowledge through searching architectures in a\nmodel space. By optimizing the consistency with existing knowledge, we\ndemonstrate that BioNAS optimal models reveal novel knowledge in both simulated\ndata and in real data of functional genomics. BioNAS provides a useful tool for\ndomain experts to inject their prior belief into automated machine learning and\ntherefore making deep learning easily accessible to practitioners. BioNAS is\navailable at https://github.com/zj-zhang/BioNAS-pub.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 07:00:21 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhang", "Zijun", ""], ["Zhou", "Linqi", ""], ["Gou", "Liangke", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1909.00349", "submitter": "Tasnim Mohiuddin", "authors": "Han Cheol Moon, Tasnim Mohiuddin, Shafiq Joty, and Xu Chi", "title": "A Unified Neural Coherence Model", "comments": "To appear at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, neural approaches to coherence modeling have achieved\nstate-of-the-art results in several evaluation tasks. However, we show that\nmost of these models often fail on harder tasks with more realistic application\nscenarios. In particular, the existing models underperform on tasks that\nrequire the model to be sensitive to local contexts such as candidate ranking\nin conversational dialogue and in machine translation. In this paper, we\npropose a unified coherence model that incorporates sentence grammar,\ninter-sentence coherence relations, and global coherence patterns into a common\nneural framework. With extensive experiments on local and global discrimination\ntasks, we demonstrate that our proposed model outperforms existing models by a\ngood margin, and establish a new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 08:16:53 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Moon", "Han Cheol", ""], ["Mohiuddin", "Tasnim", ""], ["Joty", "Shafiq", ""], ["Chi", "Xu", ""]]}, {"id": "1909.00360", "submitter": "Nicholas Cummins Dr", "authors": "Vidhyasaharan Sethu, Emily Mower Provost, Julien Epps, Carlos Busso,\n  Nicholas Cummins, Shrikanth Narayanan", "title": "The Ambiguous World of Emotion Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence and machine learning systems have demonstrated huge\nimprovements and human-level parity in a range of activities, including speech\nrecognition, face recognition and speaker verification. However, these diverse\ntasks share a key commonality that is not true in affective computing: the\nground truth information that is inferred can be unambiguously represented.\nThis observation provides some hints as to why affective computing, despite\nhaving attracted the attention of researchers for years, may not still be\nconsidered a mature field of research. A key reason for this is the lack of a\ncommon mathematical framework to describe all the relevant elements of emotion\nrepresentations. This paper proposes the AMBiguous Emotion Representation\n(AMBER) framework to address this deficiency. AMBER is a unified framework that\nexplicitly describes categorical, numerical and ordinal representations of\nemotions, including time varying representations. In addition to explaining the\ncore elements of AMBER, the paper also discusses how some of the commonly\nemployed emotion representation schemes can be viewed through the AMBER\nframework, and concludes with a discussion of how the proposed framework can be\nused to reason about current and future affective computing systems.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 09:05:58 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Sethu", "Vidhyasaharan", ""], ["Provost", "Emily Mower", ""], ["Epps", "Julien", ""], ["Busso", "Carlos", ""], ["Cummins", "Nicholas", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1909.00361", "submitter": "Yiming Cui", "authors": "Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Shijin Wang, Guoping Hu", "title": "Cross-Lingual Machine Reading Comprehension", "comments": "10 pages, accepted as a conference paper at EMNLP-IJCNLP 2019 (long\n  paper)", "journal-ref": "EMNLP 2019 1586-1595", "doi": "10.18653/v1/D19-1169", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though the community has made great progress on Machine Reading Comprehension\n(MRC) task, most of the previous works are solving English-based MRC problems,\nand there are few efforts on other languages mainly due to the lack of\nlarge-scale training data. In this paper, we propose Cross-Lingual Machine\nReading Comprehension (CLMRC) task for the languages other than English.\nFirstly, we present several back-translation approaches for CLMRC task, which\nis straightforward to adopt. However, to accurately align the answer into\nanother language is difficult and could introduce additional noise. In this\ncontext, we propose a novel model called Dual BERT, which takes advantage of\nthe large-scale training data provided by rich-resource language (such as\nEnglish) and learn the semantic relations between the passage and question in a\nbilingual context, and then utilize the learned knowledge to improve reading\ncomprehension performance of low-resource language. We conduct experiments on\ntwo Chinese machine reading comprehension datasets CMRC 2018 and DRCD. The\nresults show consistent and significant improvements over various\nstate-of-the-art systems by a large margin, which demonstrate the potentials in\nCLMRC task. Resources available: https://github.com/ymcui/Cross-Lingual-MRC\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 09:14:52 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cui", "Yiming", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""], ["Qin", "Bing", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "1909.00367", "submitter": "Gustav Zickert", "authors": "Gustav Zickert and Can Evren Yarman", "title": "Gaussian mixture model decomposition of multivariate signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a greedy variational method for decomposing a non-negative\nmultivariate signal as a weighted sum of Gaussians, which, borrowing the\nterminology from statistics, we refer to as a Gaussian mixture model. Notably,\nour method has the following features: (1) It accepts multivariate signals,\ni.e. sampled multivariate functions, histograms, time series, images, etc. as\ninput. (2) The method can handle general (i.e. ellipsoidal) Gaussians. (3) No\nprior assumption on the number of mixture components is needed. To the best of\nour knowledge, no previous method for Gaussian mixture model decomposition\nsimultaneously enjoys all these features. We also prove an upper bound, which\ncannot be improved by a global constant, for the distance from any mode of a\nGaussian mixture model to the set of corresponding means. For mixtures of\nspherical Gaussians with common variance $\\sigma^2$, the bound takes the simple\nform $\\sqrt{n}\\sigma$. We evaluate our method on one- and two-dimensional\nsignals. Finally, we discuss the relation between clustering and signal\ndecomposition, and compare our method to the baseline expectation maximization\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 09:44:46 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 10:45:01 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Zickert", "Gustav", ""], ["Yarman", "Can Evren", ""]]}, {"id": "1909.00372", "submitter": "Zitao Liu", "authors": "Zhiwei Wang, Xiaoqin Feng, Jiliang Tang, Gale Yan Huang, Zitao Liu", "title": "Deep Knowledge Tracing with Side Information", "comments": "The 20th International Conference on Artificial Intelligence in\n  Education(AIED), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring student knowledge states or skill acquisition levels known as\nknowledge tracing, is a fundamental part of intelligent tutoring systems.\nDespite its inherent challenges, recent deep neural networks based knowledge\ntracing models have achieved great success, which is largely from models'\nability to learn sequential dependencies of questions in student exercise data.\nHowever, in addition to sequential information, questions inherently exhibit\nside relations, which can enrich our understandings about student knowledge\nstates and has great potentials to advance knowledge tracing. Thus, in this\npaper, we exploit side relations to improve knowledge tracing and design a\nnovel framework DTKS. The experimental results on real education data validate\nthe effectiveness of the proposed framework and demonstrate the importance of\nside information in knowledge tracing.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 10:23:21 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Zhiwei", ""], ["Feng", "Xiaoqin", ""], ["Tang", "Jiliang", ""], ["Huang", "Gale Yan", ""], ["Liu", "Zitao", ""]]}, {"id": "1909.00384", "submitter": "Hyunjung Kwak", "authors": "Gloria Hyunjung Kwak and Pan Hui", "title": "DeepHealth: Review and challenges of artificial intelligence in health\n  informatics", "comments": "42 pages, 19 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence has provided us with an exploration of a whole new\nresearch era. As more data and better computational power become available, the\napproach is being implemented in various fields. The demand for it in health\ninformatics is also increasing, and we can expect to see the potential benefits\nof its applications in healthcare. It can help clinicians diagnose disease,\nidentify drug effects for each patient, understand the relationship between\ngenotypes and phenotypes, explore new phenotypes or treatment recommendations,\nand predict infectious disease outbreaks with high accuracy. In contrast to\ntraditional models, recent artificial intelligence approaches do not require\ndomain-specific data pre-processing, and it is expected that it will ultimately\nchange life in the future. Despite its notable advantages, there are some key\nchallenges on data (high dimensionality, heterogeneity, time dependency,\nsparsity, irregularity, lack of label, bias) and model (reliability,\ninterpretability, feasibility, security, scalability) for practical use. This\narticle presents a comprehensive review of research applying artificial\nintelligence in health informatics, focusing on the last seven years in the\nfields of medical imaging, electronic health records, genomics, sensing, and\nonline communication health, as well as challenges and promising directions for\nfuture research. We highlight ongoing popular approaches' research and identify\nseveral challenges in building models.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 11:54:38 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 05:54:41 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Kwak", "Gloria Hyunjung", ""], ["Hui", "Pan", ""]]}, {"id": "1909.00393", "submitter": "Matan Orbach", "authors": "Matan Orbach, Yonatan Bilu, Ariel Gera, Yoav Kantor, Lena Dankin,\n  Tamar Lavee, Lili Kotlerman, Shachar Mirkin, Michal Jacovi, Ranit Aharonov\n  and Noam Slonim", "title": "A Dataset of General-Purpose Rebuttal", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Natural Language Understanding, the task of response generation is usually\nfocused on responses to short texts, such as tweets or a turn in a dialog. Here\nwe present a novel task of producing a critical response to a long\nargumentative text, and suggest a method based on general rebuttal arguments to\naddress it. We do this in the context of the recently-suggested task of\nlistening comprehension over argumentative content: given a speech on some\nspecified topic, and a list of relevant arguments, the goal is to determine\nwhich of the arguments appear in the speech. The general rebuttals we describe\nhere (written in English) overcome the need for topic-specific arguments to be\nprovided, by proving to be applicable for a large set of topics. This allows\ncreating responses beyond the scope of topics for which specific arguments are\navailable. All data collected during this work is freely available for\nresearch.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 13:24:35 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Orbach", "Matan", ""], ["Bilu", "Yonatan", ""], ["Gera", "Ariel", ""], ["Kantor", "Yoav", ""], ["Dankin", "Lena", ""], ["Lavee", "Tamar", ""], ["Kotlerman", "Lili", ""], ["Mirkin", "Shachar", ""], ["Jacovi", "Michal", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "1909.00395", "submitter": "Wade Genders", "authors": "Wade Genders, Saiedeh Razavi", "title": "An Open-Source Framework for Adaptive Traffic Signal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sub-optimal control policies in transportation systems negatively impact\nmobility, the environment and human health. Developing optimal transportation\ncontrol systems at the appropriate scale can be difficult as cities'\ntransportation systems can be large, complex and stochastic. Intersection\ntraffic signal controllers are an important element of modern transportation\ninfrastructure where sub-optimal control policies can incur high costs to many\nusers. Many adaptive traffic signal controllers have been proposed by the\ncommunity but research is lacking regarding their relative performance\ndifference - which adaptive traffic signal controller is best remains an open\nquestion. This research contributes a framework for developing and evaluating\ndifferent adaptive traffic signal controller models in simulation - both\nlearning and non-learning - and demonstrates its capabilities. The framework is\nused to first, investigate the performance variance of the modelled adaptive\ntraffic signal controllers with respect to their hyperparameters and second,\nanalyze the performance differences between controllers with optimal\nhyperparameters. The proposed framework contains implementations of some of the\nmost popular adaptive traffic signal controllers from the literature;\nWebster's, Max-pressure and Self-Organizing Traffic Lights, along with deep\nQ-network and deep deterministic policy gradient reinforcement learning\ncontrollers. This framework will aid researchers by accelerating their work\nfrom a common starting point, allowing them to generate results faster with\nless effort. All framework source code is available at\nhttps://github.com/docwza/sumolights.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 13:26:49 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Genders", "Wade", ""], ["Razavi", "Saiedeh", ""]]}, {"id": "1909.00413", "submitter": "Hong-Ning Dai Prof.", "authors": "Hong-Ning Dai and Hao Wang and Guangquan Xu and Jiafu Wan and Muhammad\n  Imran", "title": "Big Data Analytics for Manufacturing Internet of Things: Opportunities,\n  Challenges and Enabling Technologies", "comments": "14 pages, 6 figures, 3 tables", "journal-ref": "Enterprise Information Systems, 2019", "doi": "10.1080/17517575.2019.1633689", "report-no": null, "categories": "cs.CY cs.AI cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent advances in information and communication technology (ICT) have\npromoted the evolution of conventional computer-aided manufacturing industry to\nsmart data-driven manufacturing. Data analytics in massive manufacturing data\ncan extract huge business values while can also result in research challenges\ndue to the heterogeneous data types, enormous volume and real-time velocity of\nmanufacturing data. This paper provides an overview on big data analytics in\nmanufacturing Internet of Things (MIoT). This paper first starts with a\ndiscussion on necessities and challenges of big data analytics in manufacturing\ndata of MIoT. Then, the enabling technologies of big data analytics of\nmanufacturing data are surveyed and discussed. Moreover, this paper also\noutlines the future directions in this promising area.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 14:53:16 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Dai", "Hong-Ning", ""], ["Wang", "Hao", ""], ["Xu", "Guangquan", ""], ["Wan", "Jiafu", ""], ["Imran", "Muhammad", ""]]}, {"id": "1909.00415", "submitter": "Giannis Karamanolakis", "authors": "Giannis Karamanolakis, Daniel Hsu, Luis Gravano", "title": "Leveraging Just a Few Keywords for Fine-Grained Aspect Detection Through\n  Weakly Supervised Co-Training", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-generated reviews can be decomposed into fine-grained segments (e.g.,\nsentences, clauses), each evaluating a different aspect of the principal entity\n(e.g., price, quality, appearance). Automatically detecting these aspects can\nbe useful for both users and downstream opinion mining applications. Current\nsupervised approaches for learning aspect classifiers require many fine-grained\naspect labels, which are labor-intensive to obtain. And, unfortunately,\nunsupervised topic models often fail to capture the aspects of interest. In\nthis work, we consider weakly supervised approaches for training aspect\nclassifiers that only require the user to provide a small set of seed words\n(i.e., weakly positive indicators) for the aspects of interest. First, we show\nthat current weakly supervised approaches do not effectively leverage the\npredictive power of seed words for aspect detection. Next, we propose a\nstudent-teacher approach that effectively leverages seed words in a\nbag-of-words classifier (teacher); in turn, we use the teacher to train a\nsecond model (student) that is potentially more powerful (e.g., a neural\nnetwork that uses pre-trained word embeddings). Finally, we show that iterative\nco-training can be used to cope with noisy seed words, leading to both improved\nteacher and student models. Our proposed approach consistently outperforms\nprevious weakly supervised approaches (by 14.1 absolute F1 points on average)\nin six different domains of product reviews and six multilingual datasets of\nrestaurant reviews.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 15:12:23 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Karamanolakis", "Giannis", ""], ["Hsu", "Daniel", ""], ["Gravano", "Luis", ""]]}, {"id": "1909.00426", "submitter": "Ikuya Yamada", "authors": "Ikuya Yamada, Koki Washio, Hiroyuki Shindo, Yuji Matsumoto", "title": "Global Entity Disambiguation with Pretrained Contextualized Embeddings\n  of Words and Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new global entity disambiguation (ED) model based on\ncontextualized embeddings of words and entities. Our model is based on a\nbidirectional transformer encoder (i.e., BERT) and produces contextualized\nembeddings for words and entities in the input text. The model is trained using\na new masked entity prediction task that aims to train the model by predicting\nrandomly masked entities in entity-annotated texts obtained from Wikipedia. We\nfurther extend the model by solving ED as a sequential decision task to capture\nglobal contextual information. We evaluate our model using six standard ED\ndatasets and achieve new state-of-the-art results on all but one dataset.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 16:29:53 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 07:39:31 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yamada", "Ikuya", ""], ["Washio", "Koki", ""], ["Shindo", "Hiroyuki", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1909.00430", "submitter": "Matan Ben Noach", "authors": "Matan Ben Noach and Yoav Goldberg", "title": "Transfer Learning Between Related Tasks Using Expected Label Proportions", "comments": "EMNLP 2019", "journal-ref": "2019 Conference on Empirical Methods in Natural Language\n  Processing and 9th International Joint Conference on Natural Language\n  Processing", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning systems thrive on abundance of labeled training data but such\ndata is not always available, calling for alternative methods of supervision.\nOne such method is expectation regularization (XR) (Mann and McCallum, 2007),\nwhere models are trained based on expected label proportions. We propose a\nnovel application of the XR framework for transfer learning between related\ntasks, where knowing the labels of task A provides an estimation of the label\nproportion of task B. We then use a model trained for A to label a large\ncorpus, and use this corpus with an XR loss to train a model for task B. To\nmake the XR framework applicable to large-scale deep-learning setups, we\npropose a stochastic batched approximation procedure. We demonstrate the\napproach on the task of Aspect-based Sentiment classification, where we\neffectively use a sentence-level sentiment predictor to train accurate\naspect-based predictor. The method improves upon fully supervised neural system\ntrained on aspect-level data, and is also cumulative with LM-based pretraining,\nas we demonstrate by improving a BERT-based Aspect-based Sentiment model.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 17:11:35 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Noach", "Matan Ben", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1909.00440", "submitter": "Abir De", "authors": "Abir De, Adish Singla, Utkarsh Upadhyay, Manuel Gomez-Rodriguez", "title": "Can A User Anticipate What Her Followers Want?", "comments": "Fixed some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whenever a social media user decides to share a story, she is typically\npleased to receive likes, comments, shares, or, more generally, feedback from\nher followers. As a result, she may feel compelled to use the feedback she\nreceives to (re-)estimate her followers' preferences and decides which stories\nto share next to receive more (positive) feedback. Under which conditions can\nshe succeed? In this work, we first look into this problem from a theoretical\nperspective and then provide a set of practical algorithms to identify and\ncharacterize such behavior in social media. More specifically, we address the\nabove problem from the viewpoint of sequential decision making and utility\nmaximization. For a wide variety of utility functions, we first show that, to\nsucceed, a user needs to actively trade off exploitation-- sharing stories\nwhich lead to more (positive) feedback--and exploration-- sharing stories to\nlearn about her followers' preferences. However, exploration is not necessary\nif a user utilizes the feedback her followers provide to other users in\naddition to the feedback she receives. Then, we develop a utility estimation\nframework for observation data, which relies on statistical hypothesis testing\nto determine whether a user utilizes the feedback she receives from each of her\nfollowers to decide what to post next. Experiments on synthetic data illustrate\nour theoretical findings and show that our estimation framework is able to\naccurately recover users' underlying utility functions. Experiments on several\nreal datasets gathered from Twitter and Reddit reveal that up to 82% (43%) of\nthe Twitter (Reddit) users in our datasets do use the feedback they receive to\ndecide what to post next.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 18:19:51 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 12:28:39 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["De", "Abir", ""], ["Singla", "Adish", ""], ["Upadhyay", "Utkarsh", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1909.00453", "submitter": "Sachin Kumar", "authors": "Sachin Kumar, Shuly Wintner, Noah A. Smith, Yulia Tsvetkov", "title": "Topics to Avoid: Demoting Latent Confounds in Text Classification", "comments": "2019 Conference on Empirical Methods in Natural Language Processing\n  (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite impressive performance on many text classification tasks, deep neural\nnetworks tend to learn frequent superficial patterns that are specific to the\ntraining data and do not always generalize well. In this work, we observe this\nlimitation with respect to the task of native language identification. We find\nthat standard text classifiers which perform well on the test set end up\nlearning topical features which are confounds of the prediction task (e.g., if\nthe input text mentions Sweden, the classifier predicts that the author's\nnative language is Swedish). We propose a method that represents the latent\ntopical confounds and a model which \"unlearns\" confounding features by\npredicting both the label of the input text and the confound; but we train the\ntwo predictors adversarially in an alternating fashion to learn a text\nrepresentation that predicts the correct label but is less prone to using\ninformation about the confound. We show that this model generalizes better and\nlearns features that are indicative of the writing style rather than the\ncontent.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 19:18:44 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 20:18:55 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kumar", "Sachin", ""], ["Wintner", "Shuly", ""], ["Smith", "Noah A.", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "1909.00482", "submitter": "Mario Amrehn", "authors": "Mario Amrehn, Stefan Steidl, Reinier Kortekaas, Maddalena Strumia,\n  Markus Weingarten, Markus Kowarschik, Andreas Maier", "title": "A Semi-Automated Usability Evaluation Framework for Interactive Image\n  Segmentation Systems", "comments": "Accepted as research article at the International Journal of\n  Biomedical Imaging, Hindawi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For complex segmentation tasks, the achievable accuracy of fully automated\nsystems is inherently limited. Specifically, when a precise segmentation result\nis desired for a small amount of given data sets, semi-automatic methods\nexhibit a clear benefit for the user. The optimization of human computer\ninteraction (HCI) is an essential part of interactive image segmentation.\nNevertheless, publications introducing novel interactive segmentation systems\n(ISS) often lack an objective comparison of HCI aspects. It is demonstrated,\nthat even when the underlying segmentation algorithm is the same throughout\ninteractive prototypes, their user experience may vary substantially. As a\nresult, users prefer simple interfaces as well as a considerable degree of\nfreedom to control each iterative step of the segmentation. In this article, an\nobjective method for the comparison of ISS is proposed, based on extensive user\nstudies. A summative qualitative content analysis is conducted via abstraction\nof visual and verbal feedback given by the participants. A direct assessment of\nthe segmentation system is executed by the users via the system usability scale\n(SUS) and AttrakDiff-2 questionnaires. Furthermore, an approximation of the\nfindings regarding usability aspects in those studies is introduced, conducted\nsolely from the system-measurable user actions during their usage of\ninteractive segmentation prototypes. The prediction of all questionnaire\nresults has an average relative error of 8.9%, which is close to the expected\nprecision of the questionnaire results themselves. This automated evaluation\nscheme may significantly reduce the resources necessary to investigate each\nvariation of a prototype's user interface (UI) features and segmentation\nmethodologies.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 22:33:06 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Amrehn", "Mario", ""], ["Steidl", "Stefan", ""], ["Kortekaas", "Reinier", ""], ["Strumia", "Maddalena", ""], ["Weingarten", "Markus", ""], ["Kowarschik", "Markus", ""], ["Maier", "Andreas", ""]]}, {"id": "1909.00489", "submitter": "Tamal Batabyal", "authors": "Aniruddha Dutta, Tamal Batabyal, Meheli Basu, Scott T. Acton", "title": "An Efficient Convolutional Neural Network for Coronary Heart Disease\n  Prediction", "comments": "Accepted in Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG physics.med-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study proposes an efficient neural network with convolutional layers to\nclassify significantly class-imbalanced clinical data. The data are curated\nfrom the National Health and Nutritional Examination Survey (NHANES) with the\ngoal of predicting the occurrence of Coronary Heart Disease (CHD). While the\nmajority of the existing machine learning models that have been used on this\nclass of data are vulnerable to class imbalance even after the adjustment of\nclass-specific weights, our simple two-layer CNN exhibits resilience to the\nimbalance with fair harmony in class-specific performance. In order to obtain\nsignificant improvement in classification accuracy under supervised learning\nsettings, it is a common practice to train a neural network architecture with a\nmassive data and thereafter, test the resulting network on a comparatively\nsmaller amount of data. However, given a highly imbalanced dataset, it is often\nchallenging to achieve a high class 1 (true CHD prediction rate) accuracy as\nthe testing data size increases. We adopt a two-step approach: first, we employ\nleast absolute shrinkage and selection operator (LASSO) based feature weight\nassessment followed by majority-voting based identification of important\nfeatures. Next, the important features are homogenized by using a fully\nconnected layer, a crucial step before passing the output of the layer to\nsuccessive convolutional stages. We also propose a training routine per epoch,\nakin to a simulated annealing process, to boost the classification accuracy.\nDespite a 35:1 (Non-CHD:CHD) ratio in the NHANES dataset, the investigation\nconfirms that our proposed CNN architecture has the classification power of 77%\nto correctly classify the presence of CHD and 81.8% the absence of CHD cases on\na testing data, which is 85.70% of the total dataset. ( (<1920\ncharacters)Please check the paper for full abstract)\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 23:23:22 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 19:56:21 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Dutta", "Aniruddha", ""], ["Batabyal", "Tamal", ""], ["Basu", "Meheli", ""], ["Acton", "Scott T.", ""]]}, {"id": "1909.00505", "submitter": "Joseph Davison", "authors": "Joshua Feldman, Joe Davison, Alexander M. Rush", "title": "Commonsense Knowledge Mining from Pretrained Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring commonsense knowledge is a key challenge in natural language\nprocessing, but due to the sparsity of training data, previous work has shown\nthat supervised methods for commonsense knowledge mining underperform when\nevaluated on novel data. In this work, we develop a method for generating\ncommonsense knowledge using a large, pre-trained bidirectional language model.\nBy transforming relational triples into masked sentences, we can use this model\nto rank a triple's validity by the estimated pointwise mutual information\nbetween the two entities. Since we do not update the weights of the\nbidirectional model, our approach is not biased by the coverage of any one\ncommonsense knowledge base. Though this method performs worse on a test set\nthan models explicitly trained on a corresponding training set, it outperforms\nthese methods when mining commonsense knowledge from new sources, suggesting\nthat unsupervised techniques may generalize better than current supervised\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 01:41:00 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Feldman", "Joshua", ""], ["Davison", "Joe", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1909.00513", "submitter": "Shengyu Zhu", "authors": "Zhitang Chen, Shengyu Zhu, Yue Liu, Tim Tse", "title": "Causal Discovery by Kernel Intrinsic Invariance Measure", "comments": "9 pages, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning based on causality, instead of association has been considered as a\nkey ingredient towards real machine intelligence. However, it is a challenging\ntask to infer causal relationship/structure among variables. In recent years,\nan Independent Mechanism (IM) principle was proposed, stating that the\nmechanism generating the cause and the one mapping the cause to the effect are\nindependent. As the conjecture, it is argued that in the causal direction, the\nconditional distributions instantiated at different value of the conditioning\nvariable have less variation than the anti-causal direction. Existing\nstate-of-the-arts simply compare the variance of the RKHS mean embedding norms\nof these conditional distributions. In this paper, we prove that this\nnorm-based approach sacrifices important information of the original\nconditional distributions. We propose a Kernel Intrinsic Invariance Measure\n(KIIM) to capture higher order statistics corresponding to the shapes of the\ndensity functions. We show our algorithm can be reduced to an\neigen-decomposition task on a kernel matrix measuring intrinsic\ndeviance/invariance. Causal directions can then be inferred by comparing the\nKIIM scores of two hypothetic directions. Experiments on synthetic and real\ndata are conducted to show the advantages of our methods over existing\nsolutions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 01:56:47 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Chen", "Zhitang", ""], ["Zhu", "Shengyu", ""], ["Liu", "Yue", ""], ["Tse", "Tim", ""]]}, {"id": "1909.00521", "submitter": "Yue Yu", "authors": "Yue Yu and Siyao Peng and Grace Hui Yang", "title": "Modeling Long-Range Context for Concurrent Dialogue Acts Recognition", "comments": "Accepted to CIKM '19", "journal-ref": null, "doi": "10.1145/3357384.3358145", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In dialogues, an utterance is a chain of consecutive sentences produced by\none speaker which ranges from a short sentence to a thousand-word post. When\nstudying dialogues at the utterance level, it is not uncommon that an utterance\nwould serve multiple functions. For instance, \"Thank you. It works great.\"\nexpresses both gratitude and positive feedback in the same utterance. Multiple\ndialogue acts (DA) for one utterance breeds complex dependencies across\ndialogue turns. Therefore, DA recognition challenges a model's predictive power\nover long utterances and complex DA context. We term this problem Concurrent\nDialogue Acts (CDA) recognition. Previous work on DA recognition either assumes\none DA per utterance or fails to realize the sequential nature of dialogues. In\nthis paper, we present an adapted Convolutional Recurrent Neural Network (CRNN)\nwhich models the interactions between utterances of long-range context. Our\nmodel significantly outperforms existing work on CDA recognition on a tech\nforum dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 03:12:19 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 13:28:58 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Yu", "Yue", ""], ["Peng", "Siyao", ""], ["Yang", "Grace Hui", ""]]}, {"id": "1909.00523", "submitter": "Zhao Zhang", "authors": "Zhao Zhang, Yan Zhang, Sheng Li, Guangcan Liu, Dan Zeng, Shuicheng Yan\n  and Meng Wang", "title": "Flexible Auto-weighted Local-coordinate Concept Factorization: A Robust\n  Framework for Unsupervised Clustering", "comments": "Accepted by IEEE Transactions on Knowledge and Data Engineering (IEEE\n  TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept Factorization (CF) and its variants may produce inaccurate\nrepresentation and clustering results due to the sensitivity to noise, hard\nconstraint on the reconstruction error and pre-obtained approximate\nsimilarities. To improve the representation ability, a novel unsupervised\nRobust Flexible Auto-weighted Local-coordinate Concept Factorization (RFA-LCF)\nframework is proposed for clustering high-dimensional data. Specifically,\nRFA-LCF integrates the robust flexible CF by clean data space recovery, robust\nsparse local-coordinate coding and adaptive weighting into a unified model.\nRFA-LCF improves the representations by enhancing the robustness of CF to noise\nand errors, providing a flexible constraint on the reconstruction error and\noptimizing the locality jointly. For robust learning, RFA-LCF clearly learns a\nsparse projection to recover the underlying clean data space, and then the\nflexible CF is performed in the projected feature space. RFA-LCF also uses a\nL2,1-norm based flexible residue to encode the mismatch between the recovered\ndata and its reconstruction, and uses the robust sparse local-coordinate coding\nto represent data using a few nearby basis concepts. For auto-weighting,\nRFA-LCF jointly preserves the manifold structures in the basis concept space\nand new coordinate space in an adaptive manner by minimizing the reconstruction\nerrors on clean data, anchor points and coordinates. By updating the\nlocal-coordinate preserving data, basis concepts and new coordinates\nalternately, the representation abilities can be potentially improved.\nExtensive results on public databases show that RFA-LCF delivers the\nstate-of-the-art clustering results compared with other related methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 03:16:01 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhang", "Zhao", ""], ["Zhang", "Yan", ""], ["Li", "Sheng", ""], ["Liu", "Guangcan", ""], ["Zeng", "Dan", ""], ["Yan", "Shuicheng", ""], ["Wang", "Meng", ""]]}, {"id": "1909.00525", "submitter": "Yiling Jia", "authors": "Yiling Jia, Nipun Batra, Hongning Wang, Kamin Whitehouse", "title": "Active Collaborative Sensing for Energy Breakdown", "comments": "12 pages, CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3357929", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residential homes constitute roughly one-fourth of the total energy usage\nworldwide. Providing appliance-level energy breakdown has been shown to induce\npositive behavioral changes that can reduce energy consumption by 15%. Existing\napproaches for energy breakdown either require hardware installation in every\ntarget home or demand a large set of energy sensor data available for model\ntraining. However, very few homes in the world have installed sub-meters\n(sensors measuring individual appliance energy); and the cost of retrofitting a\nhome with extensive sub-metering eats into the funds available for energy\nsaving retrofits. As a result, strategically deploying sensing hardware to\nmaximize the reconstruction accuracy of sub-metered readings in\nnon-instrumented homes while minimizing deployment costs becomes necessary and\npromising. In this work, we develop an active learning solution based on\nlow-rank tensor completion for energy breakdown. We propose to actively deploy\nenergy sensors to appliances from selected homes, with a goal to improve the\nprediction accuracy of the completed tensor with minimum sensor deployment\ncost. We empirically evaluate our approach on the largest public energy dataset\ncollected in Austin, Texas, USA, from 2013 to 2017. The results show that our\napproach gives better performance with a fixed number of sensors installed when\ncompared to the state-of-the-art, which is also proven by our theoretical\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 03:30:39 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Jia", "Yiling", ""], ["Batra", "Nipun", ""], ["Wang", "Hongning", ""], ["Whitehouse", "Kamin", ""]]}, {"id": "1909.00548", "submitter": "Woong Bae", "authors": "Woong Bae, Seungho Lee, Yeha Lee, Beomhee Park, Minki Chung, Kyu-Hwan\n  Jung", "title": "Resource Optimized Neural Architecture Search for 3D Medical Image\n  Segmentation", "comments": "MICCAI(International Conference on Medical Image Computing and\n  Computer Assisted Intervention) 2019 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS), a framework which automates the task of\ndesigning neural networks, has recently been actively studied in the field of\ndeep learning. However, there are only a few NAS methods suitable for 3D\nmedical image segmentation. Medical 3D images are generally very large; thus it\nis difficult to apply previous NAS methods due to their GPU computational\nburden and long training time. We propose the resource-optimized neural\narchitecture search method which can be applied to 3D medical segmentation\ntasks in a short training time (1.39 days for 1GB dataset) using a small amount\nof computation power (one RTX 2080Ti, 10.8GB GPU memory). Excellent performance\ncan also be achieved without retraining(fine-tuning) which is essential in most\nNAS methods. These advantages can be achieved by using a reinforcement\nlearning-based controller with parameter sharing and focusing on the optimal\nsearch space configuration of macro search rather than micro search. Our\nexperiments demonstrate that the proposed NAS method outperforms manually\ndesigned networks with state-of-the-art performance in 3D medical image\nsegmentation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 05:08:25 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Bae", "Woong", ""], ["Lee", "Seungho", ""], ["Lee", "Yeha", ""], ["Park", "Beomhee", ""], ["Chung", "Minki", ""], ["Jung", "Kyu-Hwan", ""]]}, {"id": "1909.00562", "submitter": "Junya Ono", "authors": "Junya Ono, Masao Utiyama, Eiichiro Sumita", "title": "Hybrid Data-Model Parallel Training for Sequence-to-Sequence Recurrent\n  Neural Network Machine Translation", "comments": "9 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduction of training time is an important issue in many tasks like patent\ntranslation involving neural networks. Data parallelism and model parallelism\nare two common approaches for reducing training time using multiple graphics\nprocessing units (GPUs) on one machine. In this paper, we propose a hybrid\ndata-model parallel approach for sequence-to-sequence (Seq2Seq) recurrent\nneural network (RNN) machine translation. We apply a model parallel approach to\nthe RNN encoder-decoder part of the Seq2Seq model and a data parallel approach\nto the attention-softmax part of the model. We achieved a speed-up of 4.13 to\n4.20 times when using 4 GPUs compared with the training speed when using 1 GPU\nwithout affecting machine translation accuracy as measured in terms of BLEU\nscores.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 06:41:34 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 06:12:02 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Ono", "Junya", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""]]}, {"id": "1909.00590", "submitter": "Hansika Hewamalage", "authors": "Hansika Hewamalage, Christoph Bergmeir, Kasun Bandara", "title": "Recurrent Neural Networks for Time Series Forecasting: Current Status\n  and Future Directions", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijforecast.2020.06.008", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNN) have become competitive forecasting methods,\nas most notably shown in the winning method of the recent M4 competition.\nHowever, established statistical models such as ETS and ARIMA gain their\npopularity not only from their high accuracy, but they are also suitable for\nnon-expert users as they are robust, efficient, and automatic. In these areas,\nRNNs have still a long way to go. We present an extensive empirical study and\nan open-source software framework of existing RNN architectures for\nforecasting, that allow us to develop guidelines and best practices for their\nuse. For example, we conclude that RNNs are capable of modelling seasonality\ndirectly if the series in the dataset possess homogeneous seasonal patterns,\notherwise we recommend a deseasonalization step. Comparisons against ETS and\nARIMA demonstrate that the implemented (semi-)automatic RNN models are no\nsilver bullets, but they are competitive alternatives in many situations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 08:20:30 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 12:32:55 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 01:12:24 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 05:46:58 GMT"}, {"version": "v5", "created": "Wed, 23 Dec 2020 01:56:57 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Hewamalage", "Hansika", ""], ["Bergmeir", "Christoph", ""], ["Bandara", "Kasun", ""]]}, {"id": "1909.00596", "submitter": "Traian Rebedea", "authors": "George-Sebastian P\\^irtoac\\u{a}, Traian Rebedea, Stefan Ruseti", "title": "Answering questions by learning to rank -- Learning to rank by answering\n  questions", "comments": "Presented at EMNLP 2019; 10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Answering multiple-choice questions in a setting in which no supporting\ndocuments are explicitly provided continues to stand as a core problem in\nnatural language processing. The contribution of this article is two-fold.\nFirst, it describes a method which can be used to semantically rank documents\nextracted from Wikipedia or similar natural language corpora. Second, we\npropose a model employing the semantic ranking that holds the first place in\ntwo of the most popular leaderboards for answering multiple-choice questions:\nARC Easy and Challenge. To achieve this, we introduce a self-attention based\nneural network that latently learns to rank documents by their importance\nrelated to a given question, whilst optimizing the objective of predicting the\ncorrect answer. These documents are considered relevant contexts for the\nunderlying question. We have published the ranked documents so that they can be\nused off-the-shelf to improve downstream decision models.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 08:36:32 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 10:09:56 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["P\u00eertoac\u0103", "George-Sebastian", ""], ["Rebedea", "Traian", ""], ["Ruseti", "Stefan", ""]]}, {"id": "1909.00617", "submitter": "Walid Abdullah Al", "authors": "Walid Abdullah Al, Il Dong Yun, Kyong Joon Lee", "title": "Reinforcement Learning-based Automatic Diagnosis of Acute Appendicitis\n  in Abdominal CT", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute appendicitis characterized by a painful inflammation of the vermiform\nappendix is one of the most common surgical emergencies. Localizing the\nappendix is challenging due to its unclear anatomy amidst the complex\ncolon-structure as observed in the conventional CT views, resulting in a\ntime-consuming diagnosis. End-to-end learning of a convolutional neural network\n(CNN) is also not likely to be useful because of the negligible size of the\nappendix compared with the abdominal CT volume. With no prior computational\napproaches to the best of our knowledge, we propose the first computerized\nautomation for acute appendicitis diagnosis. In our approach, we utilize a\nreinforcement learning agent deployed in the lower abdominal region to obtain\nthe appendix location first to reduce the search space for diagnosis. Then, we\nobtain the classification scores (i.e., the likelihood of acute appendicitis)\nfor the local neighborhood around the localized position, using a CNN trained\nonly on a small appendix patch per volume. From the spatial representation of\nthe resultant scores, we finally define a region of low-entropy (RLE) to choose\nthe optimal diagnosis score, which helps improve the classification accuracy\nshowing robustness even under high appendix localization error cases. In our\nexperiment with 319 abdominal CT volumes, the proposed RLE-based decision with\nprior localization showed significant improvement over the standard CNN-based\ndiagnosis approaches.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 09:19:33 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Al", "Walid Abdullah", ""], ["Yun", "Il Dong", ""], ["Lee", "Kyong Joon", ""]]}, {"id": "1909.00659", "submitter": "Prashant Gupta", "authors": "Prashant Gupta, Aashi Jindal, Jayadeva, and Debarka Sengupta", "title": "Guided Random Forest and its application to data approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new way of constructing an ensemble classifier, named the Guided\nRandom Forest (GRAF) in the sequel. GRAF extends the idea of building oblique\ndecision trees with localized partitioning to obtain a global partitioning. We\nshow that global partitioning bridges the gap between decision trees and\nboosting algorithms. We empirically demonstrate that global partitioning\nreduces the generalization error bound. Results on 115 benchmark datasets show\nthat GRAF yields comparable or better results on a majority of datasets. We\nalso present a new way of approximating the datasets in the framework of random\nforests.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 10:50:14 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Gupta", "Prashant", ""], ["Jindal", "Aashi", ""], ["Jayadeva", "", ""], ["Sengupta", "Debarka", ""]]}, {"id": "1909.00668", "submitter": "Daniel Murfet", "authors": "James Clift, Dmitry Doryn, Daniel Murfet, James Wallbridge", "title": "Logic and the $2$-Simplicial Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the $2$-simplicial Transformer, an extension of the Transformer\nwhich includes a form of higher-dimensional attention generalising the\ndot-product attention, and uses this attention to update entity representations\nwith tensor products of value vectors. We show that this architecture is a\nuseful inductive bias for logical reasoning in the context of deep\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 11:11:35 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Clift", "James", ""], ["Doryn", "Dmitry", ""], ["Murfet", "Daniel", ""], ["Wallbridge", "James", ""]]}, {"id": "1909.00693", "submitter": "Guillaume Metzler Mr", "authors": "R\\'emi Viola, R\\'emi Emonet, Amaury Habrard, Guillaume Metzler,\n  S\\'ebastien Riou and Marc Sebban", "title": "An Adjusted Nearest Neighbor Algorithm Maximizing the F-Measure from\n  Imbalanced Data", "comments": "In Proceedings of the 31 International Conference on Tools with\n  Artificial Intelligence (ICTAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the challenging problem of learning from imbalanced\ndata using a Nearest-Neighbor (NN) algorithm. In this setting, the minority\nexamples typically belong to the class of interest requiring the optimization\nof specific criteria, like the F-Measure. Based on simple geometrical ideas, we\nintroduce an algorithm that reweights the distance between a query sample and\nany positive training example. This leads to a modification of the Voronoi\nregions and thus of the decision boundaries of the NN algorithm. We provide a\ntheoretical justification about the weighting scheme needed to reduce the False\nNegative rate while controlling the number of False Positives. We perform an\nextensive experimental study on many public imbalanced datasets, but also on\nlarge scale non public data from the French Ministry of Economy and Finance on\na tax fraud detection task, showing that our method is very effective and,\ninterestingly, yields the best performance when combined with state of the art\nsampling methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 12:46:12 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 12:32:40 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Viola", "R\u00e9mi", ""], ["Emonet", "R\u00e9mi", ""], ["Habrard", "Amaury", ""], ["Metzler", "Guillaume", ""], ["Riou", "S\u00e9bastien", ""], ["Sebban", "Marc", ""]]}, {"id": "1909.00700", "submitter": "Zili Liu", "authors": "Zili Liu, Tu Zheng, Guodong Xu, Zheng Yang, Haifeng Liu, Deng Cai", "title": "Training-Time-Friendly Network for Real-Time Object Detection", "comments": "Accepted to AAAI2020 (8 pages, 3 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern object detectors can rarely achieve short training time, fast\ninference speed, and high accuracy at the same time. To strike a balance among\nthem, we propose the Training-Time-Friendly Network (TTFNet). In this work, we\nstart with light-head, single-stage, and anchor-free designs, which enable fast\ninference speed. Then, we focus on shortening training time. We notice that\nencoding more training samples from annotated boxes plays a similar role as\nincreasing batch size, which helps enlarge the learning rate and accelerate the\ntraining process. To this end, we introduce a novel approach using Gaussian\nkernels to encode training samples. Besides, we design the initiative sample\nweights for better information utilization. Experiments on MS COCO show that\nour TTFNet has great advantages in balancing training time, inference speed,\nand accuracy. It has reduced training time by more than seven times compared to\nprevious real-time detectors while maintaining state-of-the-art performances.\nIn addition, our super-fast version of TTFNet-18 and TTFNet-53 can outperform\nSSD300 and YOLOv3 by less than one-tenth of their training time, respectively.\nThe code has been made available at\n\\url{https://github.com/ZJULearning/ttfnet}.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 12:59:18 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 11:01:52 GMT"}, {"version": "v3", "created": "Sun, 24 Nov 2019 08:08:22 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Liu", "Zili", ""], ["Zheng", "Tu", ""], ["Xu", "Guodong", ""], ["Yang", "Zheng", ""], ["Liu", "Haifeng", ""], ["Cai", "Deng", ""]]}, {"id": "1909.00703", "submitter": "Denys Rozumnyi", "authors": "Denys Rozumnyi, Ian Cherabier, Marc Pollefeys, Martin R. Oswald", "title": "Learned Semantic Multi-Sensor Depth Map Fusion", "comments": "11 pages, 7 figures, 2 tables, accepted for the 2nd Workshop on 3D\n  Reconstruction in the Wild (3DRW2019) in conjunction with ICCV2019", "journal-ref": "2019 IEEE/CVF International Conference on Computer Vision Workshop\n  (ICCVW)", "doi": "10.1109/ICCVW.2019.00264", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volumetric depth map fusion based on truncated signed distance functions has\nbecome a standard method and is used in many 3D reconstruction pipelines. In\nthis paper, we are generalizing this classic method in multiple ways: 1)\nSemantics: Semantic information enriches the scene representation and is\nincorporated into the fusion process. 2) Multi-Sensor: Depth information can\noriginate from different sensors or algorithms with very different noise and\noutlier statistics which are considered during data fusion. 3) Scene denoising\nand completion: Sensors can fail to recover depth for certain materials and\nlight conditions, or data is missing due to occlusions. Our method denoises the\ngeometry, closes holes and computes a watertight surface for every semantic\nclass. 4) Learning: We propose a neural network reconstruction method that\nunifies all these properties within a single powerful framework. Our method\nlearns sensor or algorithm properties jointly with semantic depth fusion and\nscene completion and can also be used as an expert system, e.g. to unify the\nstrengths of various photometric stereo algorithms. Our approach is the first\nto unify all these properties. Experimental evaluations on both synthetic and\nreal data sets demonstrate clear improvements.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 13:15:24 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Rozumnyi", "Denys", ""], ["Cherabier", "Ian", ""], ["Pollefeys", "Marc", ""], ["Oswald", "Martin R.", ""]]}, {"id": "1909.00704", "submitter": "Giancarlo Ruffo", "authors": "Francesco Bergadano, Roberto Bertilone, Daniela Paolotti, Giancarlo\n  Ruffo", "title": "Learning Real Estate Automated Valuation Models from Heterogeneous Data\n  Sources", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real estate appraisal is a complex and important task, that can be made more\nprecise and faster with the help of automated valuation tools. Usually the\nvalue of some property is determined by taking into account both structural and\ngeographical characteristics. However, while geographical information is easily\nfound, obtaining significant structural information requires the intervention\nof a real estate expert, a professional appraiser. In this paper we propose a\nWeb data acquisition methodology, and a Machine Learning model, that can be\nused to automatically evaluate real estate properties. This method uses data\nfrom previous appraisal documents, from the advertised prices of similar\nproperties found via Web crawling, and from open data describing the\ncharacteristics of a corresponding geographical area. We describe a case study,\napplicable to the whole Italian territory, and initially trained on a data set\nof individual homes located in the city of Turin, and analyze prediction and\npractical applicability.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 13:16:51 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Bergadano", "Francesco", ""], ["Bertilone", "Roberto", ""], ["Paolotti", "Daniela", ""], ["Ruffo", "Giancarlo", ""]]}, {"id": "1909.00719", "submitter": "Andrew Y. K. Foong", "authors": "Andrew Y. K. Foong, David R. Burt, Yingzhen Li, Richard E. Turner", "title": "On the Expressiveness of Approximate Inference in Bayesian Neural\n  Networks", "comments": "NeurIPS 2020 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Bayesian neural networks (BNNs) hold the promise of being flexible,\nwell-calibrated statistical models, inference often requires approximations\nwhose consequences are poorly understood. We study the quality of common\nvariational methods in approximating the Bayesian predictive distribution. For\nsingle-hidden layer ReLU BNNs, we prove a fundamental limitation in\nfunction-space of two of the most commonly used distributions defined in\nweight-space: mean-field Gaussian and Monte Carlo dropout. We find there are\nsimple cases where neither method can have substantially increased uncertainty\nin between well-separated regions of low uncertainty. We provide strong\nempirical evidence that exact inference does not have this pathology, hence it\nis due to the approximation and not the model. In contrast, for deep networks,\nwe prove a universality result showing that there exist approximate posteriors\nin the above classes which provide flexible uncertainty estimates. However, we\nfind empirically that pathologies of a similar form as in the single-hidden\nlayer case can persist when performing variational inference in deeper\nnetworks. Our results motivate careful consideration of the implications of\napproximate inference methods in BNNs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 13:54:39 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 13:47:45 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 22:10:54 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 17:16:49 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Foong", "Andrew Y. K.", ""], ["Burt", "David R.", ""], ["Li", "Yingzhen", ""], ["Turner", "Richard E.", ""]]}, {"id": "1909.00732", "submitter": "Sayantan Auddy", "authors": "Sayantan Auddy, Sven Magg, Stefan Wermter", "title": "Hierarchical Control for Bipedal Locomotion using Central Pattern\n  Generators and Neural Networks", "comments": "In: Proceedings of the Joint IEEE International Conference on\n  Development and Learning and on Epigenetic Robotics (ICDL-EpiRob), Oslo,\n  Norway, Aug. 19-22, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of bipedal locomotion may be attributed to the difficulty in\nsynchronizing joint movements while at the same time achieving high-level\nobjectives such as walking in a particular direction. Artificial central\npattern generators (CPGs) can produce synchronized joint movements and have\nbeen used in the past for bipedal locomotion. However, most existing CPG-based\napproaches do not address the problem of high-level control explicitly. We\npropose a novel hierarchical control mechanism for bipedal locomotion where an\noptimized CPG network is used for joint control and a neural network acts as a\nhigh-level controller for modulating the CPG network. By separating motion\ngeneration from motion modulation, the high-level controller does not need to\ncontrol individual joints directly but instead can develop to achieve a higher\ngoal using a low-dimensional control signal. The feasibility of the\nhierarchical controller is demonstrated through simulation experiments using\nthe Neuro-Inspired Companion (NICO) robot. Experimental results demonstrate the\ncontroller's ability to function even without the availability of an exact\nrobot model.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 14:27:30 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Auddy", "Sayantan", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1909.00781", "submitter": "Umberto Michieli", "authors": "Umberto Michieli, Matteo Biasetton, Gianluca Agresti, Pietro Zanuttigh", "title": "Adversarial Learning and Self-Teaching Techniques for Domain Adaptation\n  in Semantic Segmentation", "comments": "Accepted at IEEE Transactions on Intelligent Vehicles (T-IV) 10\n  pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have been widely used in autonomous driving systems\nfor the semantic understanding of urban scenes. However, they need a huge\namount of labeled data for training, which is difficult and expensive to\nacquire. A recently proposed workaround is to train deep networks using\nsynthetic data, but the domain shift between real world and synthetic\nrepresentations limits the performance. In this work, a novel Unsupervised\nDomain Adaptation (UDA) strategy is introduced to solve this issue. The\nproposed learning strategy is driven by three components: a standard supervised\nlearning loss on labeled synthetic data; an adversarial learning module that\nexploits both labeled synthetic data and unlabeled real data; finally, a\nself-teaching strategy applied to unlabeled data. The last component exploits a\nregion growing framework guided by the segmentation confidence. Furthermore, we\nweighted this component on the basis of the class frequencies to enhance the\nperformance on less common classes. Experimental results prove the\neffectiveness of the proposed strategy in adapting a segmentation network\ntrained on synthetic datasets, like GTA5 and SYNTHIA, to real world datasets\nlike Cityscapes and Mapillary.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 16:05:05 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 15:46:24 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Michieli", "Umberto", ""], ["Biasetton", "Matteo", ""], ["Agresti", "Gianluca", ""], ["Zanuttigh", "Pietro", ""]]}, {"id": "1909.00798", "submitter": "Joseph Antony A", "authors": "Rama Sai Mamidala, Uday Uthkota, Mahamkali Bhavani Shankar, A. Joseph\n  Antony and A. V. Narasimhadhan", "title": "Dynamic Approach for Lane Detection using Google Street View and CNN", "comments": "Preprint: To be published in the proceedings of IEEE TENCON 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Lane detection algorithms have been the key enablers for a fully-assistive\nand autonomous navigation systems. In this paper, a novel and pragmatic\napproach for lane detection is proposed using a convolutional neural network\n(CNN) model based on SegNet encoder-decoder architecture. The encoder block\nrenders low-resolution feature maps of the input and the decoder block provides\npixel-wise classification from the feature maps. The proposed model has been\ntrained over 2000 image data-set and tested against their corresponding\nground-truth provided in the data-set for evaluation. To enable real-time\nnavigation, we extend our model's predictions interfacing it with the existing\nGoogle APIs evaluating the metrics of the model tuning the hyper-parameters.\nThe novelty of this approach lies in the integration of existing segNet\narchitecture with google APIs. This interface makes it handy for assistive\nrobotic systems. The observed results show that the proposed method is robust\nunder challenging occlusion conditions due to pre-processing involved and gives\nsuperior performance when compared to the existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 17:10:01 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Mamidala", "Rama Sai", ""], ["Uthkota", "Uday", ""], ["Shankar", "Mahamkali Bhavani", ""], ["Antony", "A. Joseph", ""], ["Narasimhadhan", "A. V.", ""]]}, {"id": "1909.00823", "submitter": "Md Nafee Al Islam", "authors": "Md Nafee Al Islam and Siamul Karim Khan", "title": "HishabNet: Detection, Localization and Calculation of Handwritten\n  Bengali Mathematical Expressions", "comments": "6 pages, 5 figures, This paper is under review in \"22nd International\n  Conference on Computer and Information Technology (ICCIT), 2019\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, recognition of handwritten Bengali letters and digits have captured\na lot of attention among the researchers of the AI community. In this work, we\npropose a Convolutional Neural Network (CNN) based object detection model which\ncan recognize and evaluate handwritten Bengali mathematical expressions. This\nmethod is able to detect multiple Bengali digits and operators and locate their\npositions in the image. With that information, it is able to construct numbers\nfrom series of digits and perform mathematical operations on them. For the\nobject detection task, the state-of-the-art YOLOv3 algorithm was utilized. For\ntraining and evaluating the model, we have engineered a new dataset 'Hishab'\nwhich is the first Bengali handwritten digits dataset intended for object\ndetection. The model achieved an overall validation mean average precision\n(mAP) of 98.6%. Also, the classification accuracy of the feature extractor\nbackbone CNN used in our model was tested on two publicly available Bengali\nhandwritten digits datasets: NumtaDB and CMATERdb. The backbone CNN achieved a\ntest set accuracy of 99.6252% on NumtaDB and 99.0833% on CMATERdb.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 18:28:14 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Islam", "Md Nafee Al", ""], ["Khan", "Siamul Karim", ""]]}, {"id": "1909.00835", "submitter": "Stephen Whitelam", "authors": "Stephen Whitelam, Daniel Jacobson, Isaac Tamblyn", "title": "Evolutionary reinforcement learning of dynamical large deviations", "comments": null, "journal-ref": null, "doi": "10.1063/5.0015301", "report-no": null, "categories": "cond-mat.stat-mech cs.LG cs.NE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to calculate the likelihood of dynamical large deviations using\nevolutionary reinforcement learning. An agent, a stochastic model, propagates a\ncontinuous-time Monte Carlo trajectory and receives a reward conditioned upon\nthe values of certain path-extensive quantities. Evolution produces\nprogressively fitter agents, eventually allowing the calculation of a piece of\na large-deviation rate function for a particular model and path-extensive\nquantity. For models with small state spaces the evolutionary process acts\ndirectly on rates, and for models with large state spaces the process acts on\nthe weights of a neural network that parameterizes the model's rates. This\napproach shows how path-extensive physics problems can be considered within a\nframework widely used in machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 19:07:51 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 20:42:32 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 00:46:56 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 19:21:04 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Whitelam", "Stephen", ""], ["Jacobson", "Daniel", ""], ["Tamblyn", "Isaac", ""]]}, {"id": "1909.00843", "submitter": "Sikander Randhawa", "authors": "Nicholas J. A. Harvey, Christopher Liaw, Sikander Randhawa", "title": "Simple and optimal high-probability bounds for strongly-convex\n  stochastic gradient descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider stochastic gradient descent algorithms for minimizing a\nnon-smooth, strongly-convex function. Several forms of this algorithm,\nincluding suffix averaging, are known to achieve the optimal $O(1/T)$\nconvergence rate in expectation. We consider a simple, non-uniform averaging\nstrategy of Lacoste-Julien et al. (2011) and prove that it achieves the optimal\n$O(1/T)$ convergence rate with high probability. Our proof uses a recently\ndeveloped generalization of Freedman's inequality. Finally, we compare several\nof these algorithms experimentally and show that this non-uniform averaging\nstrategy outperforms many standard techniques, and with smaller variance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 19:47:47 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Harvey", "Nicholas J. A.", ""], ["Liaw", "Christopher", ""], ["Randhawa", "Sikander", ""]]}, {"id": "1909.00848", "submitter": "Pedro H. Bugatti", "authors": "Pedro H. Bugatti, Priscila T. M. Saito, Larry S. Davis", "title": "HiCoRe: Visual Hierarchical Context-Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about images/objects and their hierarchical interactions is a key\nconcept for the next generation of computer vision approaches. Here we present\na new framework to deal with it through a visual hierarchical context-based\nreasoning. Current reasoning methods use the fine-grained labels from images'\nobjects and their interactions to predict labels to new objects. Our framework\nmodifies this current information flow. It goes beyond and is independent of\nthe fine-grained labels from the objects to define the image context. It takes\ninto account the hierarchical interactions between different abstraction levels\n(i.e. taxonomy) of information in the images and their bounding-boxes. Besides\nthese connections, it considers their intrinsic characteristics. To do so, we\nbuild and apply graphs to graph convolution networks with convolutional neural\nnetworks. We show a strong effectiveness over widely used convolutional neural\nnetworks, reaching a gain 3 times greater on well-known image datasets. We\nevaluate the capability and the behavior of our framework under different\nscenarios, considering distinct (superclass, subclass and hierarchical)\ngranularity levels. We also explore attention mechanisms through graph\nattention networks and pre-processing methods considering dimensionality\nexpansion and/or reduction of the features' representations. Further analyses\nare performed comparing supervised and semi-supervised approaches.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 19:57:05 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Bugatti", "Pedro H.", ""], ["Saito", "Priscila T. M.", ""], ["Davis", "Larry S.", ""]]}, {"id": "1909.00853", "submitter": "Branko Arsi\\'c", "authors": "Milan Ba\\v{s}i\\'c, Branko Arsi\\'c and Zoran Obradovi\\'c", "title": "Further results on structured regression for multi-scale networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Gaussian Conditional Random Fields (GCRF), as a structured regression model,\nis designed to achieve higher regression accuracy than unstructured predictors\nat the expense of execution time, taking into account the objects similarities\nand the outputs of unstructured predictors simultaneously. As most structural\nmodels, the GCRF model does not scale well with large networks. One of the\napproaches consists of performing calculations on factor graphs (if it is\npossible) rather than on the full graph, which is more computationally\nefficient. The Kronecker product of the graphs appears to be a natural choice\nfor a graph decomposition. However, this idea is not straightforwardly\napplicable for GCRF, since characterizing a Laplacian spectrum of the Kronecker\nproduct of graphs, which GCRF is based on, from spectra of its factor graphs\nhas remained an open problem. In this paper we apply new estimations for the\nLaplacian eigenvalues and eigenvectors, and achieve high prediction accuracy of\nthe proposed models, while the computational complexity of the models, compared\nto the original GCRF model, is improved from $O(n_{1}^{3}n_{2}^{3})$ to\n$O(n_{1}^{3} + n_{2}^{3})$. Furthermore, we study the GCRF model with a\nnon-Kronecker graph, where the model consists of finding the nearest Kronecker\nproduct of graph for an initial graph. Although the proposed models are more\ncomplex, they achieve high prediction accuracy too, while the execution time is\nstill much better compare to the original GCRF model. The effectiveness of the\nproposed models is characterized on three types of random networks where the\nproposed models were consistently away more accurate than the previously\npresented GCRF model for multiscale networks [Jesse Glass and Zoran Obradovic.\nStructured regression on multiscale networks. IEEE Intelligent Systems,\n32(2):23-30, 2017.].\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 20:11:11 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ba\u0161i\u0107", "Milan", ""], ["Arsi\u0107", "Branko", ""], ["Obradovi\u0107", "Zoran", ""]]}, {"id": "1909.00868", "submitter": "Bohan Li", "authors": "Bohan Li, Junxian He, Graham Neubig, Taylor Berg-Kirkpatrick, Yiming\n  Yang", "title": "A Surprisingly Effective Fix for Deep Latent Variable Modeling of Text", "comments": "EMNLP 2019 short paper. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When trained effectively, the Variational Autoencoder (VAE) is both a\npowerful language model and an effective representation learning framework. In\npractice, however, VAEs are trained with the evidence lower bound (ELBO) as a\nsurrogate objective to the intractable marginal data likelihood. This approach\nto training yields unstable results, frequently leading to a disastrous local\noptimum known as posterior collapse. In this paper, we investigate a simple fix\nfor posterior collapse which yields surprisingly effective results. The\ncombination of two known heuristics, previously considered only in isolation,\nsubstantially improves held-out likelihood, reconstruction, and latent\nrepresentation learning when compared with previous state-of-the-art methods.\nMore interestingly, while our experiments demonstrate superiority on these\nprinciple evaluations, our method obtains a worse ELBO. We use these results to\nargue that the typical surrogate objective for VAEs may not be sufficient or\nnecessarily appropriate for balancing the goals of representation learning and\ndata distribution modeling.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 21:08:00 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Li", "Bohan", ""], ["He", "Junxian", ""], ["Neubig", "Graham", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Yang", "Yiming", ""]]}, {"id": "1909.00895", "submitter": "Boyi Liu", "authors": "Boyi Liu, Lujia Wang, Ming Liu and Cheng-Zhong Xu", "title": "Federated Imitation Learning: A Privacy Considered Imitation Learning\n  Framework for Cloud Robotic Systems with Heterogeneous Sensor Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are capable of learning a new behavior by observing others perform the\nskill. Robots can also implement this by imitation learning. Furthermore, if\nwith external guidance, humans will master the new behavior more efficiently.\nSo how can robots implement this? To address the issue, we present Federated\nImitation Learning (FIL) in the paper. Firstly, a knowledge fusion algorithm\ndeployed on the cloud for fusing knowledge from local robots is presented.\nThen, effective transfer learning methods in FIL are introduced. With FIL, a\nrobot is capable of utilizing knowledge from other robots to increase its\nimitation learning. FIL considers information privacy and data heterogeneity\nwhen robots share knowledge. It is suitable to be deployed in cloud robotic\nsystems. Finally, we conduct experiments of a simplified self-driving task for\nrobots (cars). The experimental results demonstrate that FIL is capable of\nincreasing imitation learning of local robots in cloud robotic systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 00:21:43 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 08:18:19 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Liu", "Boyi", ""], ["Wang", "Lujia", ""], ["Liu", "Ming", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "1909.00900", "submitter": "Chengzhi Mao", "authors": "Chengzhi Mao, Ziyuan Zhong, Junfeng Yang, Carl Vondrick, Baishakhi Ray", "title": "Metric Learning for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are well-known to be fragile to adversarial attacks. We conduct\nan empirical analysis of deep representations under the state-of-the-art attack\nmethod called PGD, and find that the attack causes the internal representation\nto shift closer to the \"false\" class. Motivated by this observation, we propose\nto regularize the representation space under attack with metric learning to\nproduce more robust classifiers. By carefully sampling examples for metric\nlearning, our learned representation not only increases robustness, but also\ndetects previously unseen adversarial samples. Quantitative experiments show\nimprovement of robustness accuracy by up to 4% and detection efficiency by up\nto 6% according to Area Under Curve score over prior work. The code of our work\nis available at\nhttps://github.com/columbia/Metric_Learning_Adversarial_Robustness.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 00:39:40 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 00:43:15 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mao", "Chengzhi", ""], ["Zhong", "Ziyuan", ""], ["Yang", "Junfeng", ""], ["Vondrick", "Carl", ""], ["Ray", "Baishakhi", ""]]}, {"id": "1909.00907", "submitter": "Yuris Mulya Saputra", "authors": "Yuris Mulya Saputra, Dinh Thai Hoang, Diep N. Nguyen, Eryk Dutkiewicz,\n  Markus Dominik Mueck, and Srikathyayani Srikanteswara", "title": "Energy Demand Prediction with Federated Learning for Electric Vehicle\n  Networks", "comments": "6 pages, 4 figures, the paper has been accepted on IEEE GLOBECOM\n  Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose novel approaches using state-of-the-art machine\nlearning techniques, aiming at predicting energy demand for electric vehicle\n(EV) networks. These methods can learn and find the correlation of complex\nhidden features to improve the prediction accuracy. First, we propose an energy\ndemand learning (EDL)-based prediction solution in which a charging station\nprovider (CSP) gathers information from all charging stations (CSs) and then\nperforms the EDL algorithm to predict the energy demand for the considered\narea. However, this approach requires frequent data sharing between the CSs and\nthe CSP, thereby driving communication overhead and privacy issues for the EVs\nand CSs. To address this problem, we propose a federated energy demand learning\n(FEDL) approach which allows the CSs sharing their information without\nrevealing real datasets. Specifically, the CSs only need to send their trained\nmodels to the CSP for processing. In this case, we can significantly reduce the\ncommunication overhead and effectively protect data privacy for the EV users.\nTo further improve the effectiveness of the FEDL, we then introduce a novel\nclustering-based EDL approach for EV networks by grouping the CSs into clusters\nbefore applying the EDL algorithms. Through experimental results, we show that\nour proposed approaches can improve the accuracy of energy demand prediction up\nto 24.63% and decrease communication overhead by 83.4% compared with other\nbaseline machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 00:58:35 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Saputra", "Yuris Mulya", ""], ["Hoang", "Dinh Thai", ""], ["Nguyen", "Diep N.", ""], ["Dutkiewicz", "Eryk", ""], ["Mueck", "Markus Dominik", ""], ["Srikanteswara", "Srikathyayani", ""]]}, {"id": "1909.00918", "submitter": "Qi Deng", "authors": "Qi Deng and Chenghao Lan", "title": "Efficiency of Coordinate Descent Methods For Structured Nonconvex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel coordinate descent (CD) methods are proposed for minimizing nonconvex\nfunctions consisting of three terms: (i) a continuously differentiable term,\n(ii) a simple convex term, and (iii) a concave and continuous term. First, by\nextending randomized CD to nonsmooth nonconvex settings, we develop a\ncoordinate subgradient method that randomly updates block-coordinate variables\nby using block composite subgradient mapping. This method converges\nasymptotically to critical points with proven sublinear convergence rate for\ncertain optimality measures. Second, we develop a randomly permuted CD method\nwith two alternating steps: linearizing the concave part and cycling through\nvariables. We prove asymptotic convergence to critical points and sublinear\ncomplexity rate for objectives with both smooth and concave parts. Third, we\nextend accelerated coordinate descent (ACD) to nonsmooth and nonconvex\noptimization to develop a novel randomized proximal DC algorithm whereby we\nsolve the subproblem inexactly by ACD. Convergence is guaranteed with at most a\nfew number of ACD iterations for each DC subproblem, and convergence complexity\nis established for identification of some approximate critical points. Fourth,\nwe further develop the third method to minimize certain ill-conditioned\nnonconvex functions: weakly convex functions with high Lipschitz constant to\nnegative curvature ratios. We show that, under specific criteria, the ACD-based\nrandomized method has superior complexity compared to conventional gradient\nmethods. Finally, an empirical study on sparsity-inducing learning models\ndemonstrates that CD methods are superior to gradient-based methods for certain\nlarge-scale problems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 02:11:11 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Deng", "Qi", ""], ["Lan", "Chenghao", ""]]}, {"id": "1909.00925", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi, Erik T. Mueller, Christopher Larson, Tarek Lahlou", "title": "Adversarial Bootstrapping for Dialogue Model Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Open domain neural dialogue models, despite their successes, are known to\nproduce responses that lack relevance, diversity, and in many cases coherence.\nThese shortcomings stem from the limited ability of common training objectives\nto directly express these properties as well as their interplay with training\ndatasets and model architectures. Toward addressing these problems, this paper\nproposes bootstrapping a dialogue response generator with an adversarially\ntrained discriminator. The method involves training a neural generator in both\nautoregressive and traditional teacher-forcing modes, with the maximum\nlikelihood loss of the auto-regressive outputs weighted by the score from a\nmetric-based discriminator model. The discriminator input is a mixture of\nground truth labels, the teacher-forcing outputs of the generator, and\ndistractors sampled from the dataset, thereby allowing for richer feedback on\nthe autoregressive outputs of the generator. To improve the calibration of the\ndiscriminator output, we also bootstrap the discriminator with the matching of\nthe intermediate features of the ground truth and the generator's\nautoregressive output. We explore different sampling and adversarial policy\noptimization strategies during training in order to understand how to encourage\nresponse diversity without sacrificing relevance. Our experiments shows that\nadversarial bootstrapping is effective at addressing exposure bias, leading to\nimprovement in response relevance and coherence. The improvement is\ndemonstrated with the state-of-the-art results on the Movie and Ubuntu dialogue\ndatasets with respect to human evaluations and BLUE, ROGUE, and distinct n-gram\nscores.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 02:45:28 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 18:23:54 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Mueller", "Erik T.", ""], ["Larson", "Christopher", ""], ["Lahlou", "Tarek", ""]]}, {"id": "1909.00931", "submitter": "Yuki Arase", "authors": "Yuki Arase and Junichi Tsujii", "title": "Transfer Fine-Tuning: A BERT Case Study", "comments": "Accepted at the Conference on Empirical Methods in Natural Language\n  Processing (EMNLP 2019) *Retitled from \"Injecting Phrasal Paraphrase Relation\n  into Sentence Representation for Semantic Equivalence Assessment\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A semantic equivalence assessment is defined as a task that assesses semantic\nequivalence in a sentence pair by binary judgment (i.e., paraphrase\nidentification) or grading (i.e., semantic textual similarity measurement). It\nconstitutes a set of tasks crucial for research on natural language\nunderstanding. Recently, BERT realized a breakthrough in sentence\nrepresentation learning (Devlin et al., 2019), which is broadly transferable to\nvarious NLP tasks. While BERT's performance improves by increasing its model\nsize, the required computational power is an obstacle preventing practical\napplications from adopting the technology. Herein, we propose to inject phrasal\nparaphrase relations into BERT in order to generate suitable representations\nfor semantic equivalence assessment instead of increasing the model size.\nExperiments on standard natural language understanding tasks confirm that our\nmethod effectively improves a smaller BERT model while maintaining the model\nsize. The generated model exhibits superior performance compared to a larger\nBERT model on semantic equivalence assessment tasks. Furthermore, it achieves\nlarger performance gains on tasks with limited training datasets for\nfine-tuning, which is a property desirable for transfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 03:06:46 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Arase", "Yuki", ""], ["Tsujii", "Junichi", ""]]}, {"id": "1909.00949", "submitter": "Jordan Hoffmann", "authors": "Jordan Hoffmann, Louis Maestrati, Yoshihide Sawada, Jian Tang, Jean\n  Michel Sellier, Yoshua Bengio", "title": "Data-Driven Approach to Encoding and Decoding 3-D Crystal Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative models have achieved impressive results in many domains including\nimage and text generation. In the natural sciences, generative models have led\nto rapid progress in automated drug discovery. Many of the current methods\nfocus on either 1-D or 2-D representations of typically small, drug-like\nmolecules. However, many molecules require 3-D descriptors and exceed the\nchemical complexity of commonly used dataset. We present a method to encode and\ndecode the position of atoms in 3-D molecules from a dataset of nearly 50,000\nstable crystal unit cells that vary from containing 1 to over 100 atoms. We\nconstruct a smooth and continuous 3-D density representation of each crystal\nbased on the positions of different atoms. Two different neural networks were\ntrained on a dataset of over 120,000 three-dimensional samples of single and\nrepeating crystal structures, made by rotating the single unit cells. The\nfirst, an Encoder-Decoder pair, constructs a compressed latent space\nrepresentation of each molecule and then decodes this description into an\naccurate reconstruction of the input. The second network segments the resulting\noutput into atoms and assigns each atom an atomic number. By generating\ncompressed, continuous latent spaces representations of molecules we are able\nto decode random samples, interpolate between two molecules, and alter known\nmolecules.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 04:36:13 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Hoffmann", "Jordan", ""], ["Maestrati", "Louis", ""], ["Sawada", "Yoshihide", ""], ["Tang", "Jian", ""], ["Sellier", "Jean Michel", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1909.00952", "submitter": "Hilmi Enes Egilmez", "authors": "Hilmi E. Egilmez, Yung-Hsuan Chao, Antonio Ortega", "title": "Graph-based Transforms for Video Coding", "comments": "To appear in IEEE Trans. on Image Processing (14 pages)", "journal-ref": null, "doi": "10.1109/TIP.2020.3026627", "report-no": null, "categories": "eess.IV cs.LG cs.MM cs.SY eess.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many state-of-the-art compression systems, signal transformation is an\nintegral part of the encoding and decoding process, where transforms provide\ncompact representations for the signals of interest. This paper introduces a\nclass of transforms called graph-based transforms (GBTs) for video compression,\nand proposes two different techniques to design GBTs. In the first technique,\nwe formulate an optimization problem to learn graphs from data and provide\nsolutions for optimal separable and nonseparable GBT designs, called GL-GBTs.\nThe optimality of the proposed GL-GBTs is also theoretically analyzed based on\nGaussian-Markov random field (GMRF) models for intra and inter predicted block\nsignals. The second technique develops edge-adaptive GBTs (EA-GBTs) in order to\nflexibly adapt transforms to block signals with image edges (discontinuities).\nThe advantages of EA-GBTs are both theoretically and empirically demonstrated.\nOur experimental results demonstrate that the proposed transforms can\nsignificantly outperform the traditional Karhunen-Loeve transform (KLT).\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 04:53:53 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 08:44:44 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Egilmez", "Hilmi E.", ""], ["Chao", "Yung-Hsuan", ""], ["Ortega", "Antonio", ""]]}, {"id": "1909.00958", "submitter": "Yun Cheng Wang", "authors": "Fenxiao Chen, Yuncheng Wang, Bin Wang and C.-C. Jay Kuo", "title": "Graph Representation Learning: A Survey", "comments": null, "journal-ref": "APSIPA Transactions on Signal and Information Processing 9 (2020)\n  e15", "doi": "10.1017/ATSIP.2020.13", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on graph representation learning has received a lot of attention in\nrecent years since many data in real-world applications come in form of graphs.\nHigh-dimensional graph data are often in irregular form, which makes them more\ndifficult to analyze than image/video/audio data defined on regular lattices.\nVarious graph embedding techniques have been developed to convert the raw graph\ndata into a low-dimensional vector representation while preserving the\nintrinsic graph properties. In this review, we first explain the graph\nembedding task and its challenges. Next, we review a wide range of graph\nembedding techniques with insights. Then, we evaluate several state-of-the-art\nmethods against small and large datasets and compare their performance.\nFinally, potential applications and future directions are presented.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 05:21:31 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Chen", "Fenxiao", ""], ["Wang", "Yuncheng", ""], ["Wang", "Bin", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1909.00982", "submitter": "Arpita Biswas", "authors": "Arpita Biswas, Siddharth Barman, Amit Deshpande, Amit Sharma", "title": "Quantifying Infra-Marginality and Its Trade-off with Group Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In critical decision-making scenarios, optimizing accuracy can lead to a\nbiased classifier, hence past work recommends enforcing group-based fairness\nmetrics in addition to maximizing accuracy. However, doing so exposes the\nclassifier to another kind of bias called infra-marginality. This refers to\nindividual-level bias where some individuals/subgroups can be worse off than\nunder simply optimizing for accuracy. For instance, a classifier implementing\nrace-based parity may significantly disadvantage women of the advantaged race.\nTo quantify this bias, we propose a general notion of $\\eta$-infra-marginality\nthat can be used to evaluate the extent of this bias. We prove theoretically\nthat, unlike other fairness metrics, infra-marginality does not have a\ntrade-off with accuracy: high accuracy directly leads to low infra-marginality.\nThis observation is confirmed through empirical analysis on multiple simulated\nand real-world datasets. Further, we find that maximizing group fairness often\nincreases infra-marginality, suggesting the consideration of both group-level\nfairness and individual-level infra-marginality. However, measuring\ninfra-marginality requires knowledge of the true distribution of\nindividual-level outcomes correctly and explicitly. We propose a practical\nmethod to measure infra-marginality, and a simple algorithm to maximize\ngroup-wise accuracy and avoid infra-marginality.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 07:24:35 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Biswas", "Arpita", ""], ["Barman", "Siddharth", ""], ["Deshpande", "Amit", ""], ["Sharma", "Amit", ""]]}, {"id": "1909.00986", "submitter": "Robin Jia", "authors": "Robin Jia and Aditi Raghunathan and Kerem G\\\"oksel and Percy Liang", "title": "Certified Robustness to Adversarial Word Substitutions", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art NLP models can often be fooled by adversaries that apply\nseemingly innocuous label-preserving transformations (e.g., paraphrasing) to\ninput text. The number of possible transformations scales exponentially with\ntext length, so data augmentation cannot cover all transformations of an input.\nThis paper considers one exponentially large family of label-preserving\ntransformations, in which every word in the input can be replaced with a\nsimilar word. We train the first models that are provably robust to all word\nsubstitutions in this family. Our training procedure uses Interval Bound\nPropagation (IBP) to minimize an upper bound on the worst-case loss that any\ncombination of word substitutions can induce. To evaluate models' robustness to\nthese transformations, we measure accuracy on adversarially chosen word\nsubstitutions applied to test examples. Our IBP-trained models attain $75\\%$\nadversarial accuracy on both sentiment analysis on IMDB and natural language\ninference on SNLI. In comparison, on IMDB, models trained normally and ones\ntrained with data augmentation achieve adversarial accuracy of only $8\\%$ and\n$35\\%$, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 07:29:48 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Jia", "Robin", ""], ["Raghunathan", "Aditi", ""], ["G\u00f6ksel", "Kerem", ""], ["Liang", "Percy", ""]]}, {"id": "1909.00995", "submitter": "Ashkan Yousefpour", "authors": "Ashkan Yousefpour, Siddartha Devic, Brian Q. Nguyen, Aboudy Kreidieh,\n  Alan Liao, Alexandre M. Bayen, Jason P. Jue", "title": "Guardians of the Deep Fog: Failure-Resilient DNN Inference from Edge to\n  Cloud", "comments": "Accepted to ACM AIChallengeIoT 2019", "journal-ref": null, "doi": "10.1145/3363347.3363366", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partitioning and distributing deep neural networks (DNNs) over physical nodes\nsuch as edge, fog, or cloud nodes, could enhance sensor fusion, and reduce\nbandwidth and inference latency. However, when a DNN is distributed over\nphysical nodes, failure of the physical nodes causes the failure of the DNN\nunits that are placed on these nodes. The performance of the inference task\nwill be unpredictable, and most likely, poor, if the distributed DNN is not\nspecifically designed and properly trained for failures. Motivated by this, we\nintroduce deepFogGuard, a DNN architecture augmentation scheme for making the\ndistributed DNN inference task failure-resilient. To articulate deepFogGuard,\nwe introduce the elements and a model for the resiliency of distributed DNN\ninference. Inspired by the concept of residual connections in DNNs, we\nintroduce skip hyperconnections in distributed DNNs, which are the basis of\ndeepFogGuard's design to provide resiliency. Next, our extensive experiments\nusing two existing datasets for the sensing and vision applications confirm the\nability of deepFogGuard to provide resiliency for distributed DNNs in\nedge-cloud networks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 08:22:17 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 06:58:53 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Yousefpour", "Ashkan", ""], ["Devic", "Siddartha", ""], ["Nguyen", "Brian Q.", ""], ["Kreidieh", "Aboudy", ""], ["Liao", "Alan", ""], ["Bayen", "Alexandre M.", ""], ["Jue", "Jason P.", ""]]}, {"id": "1909.01019", "submitter": "Morten Kolb{\\ae}k", "authors": "Morten Kolb{\\ae}k, Zheng-Hua Tan, S{\\o}ren Holdt Jensen, Jesper Jensen", "title": "On Loss Functions for Supervised Monaural Time-Domain Speech Enhancement", "comments": "Published in the IEEE Transactions on Audio, Speech and Language\n  Processing", "journal-ref": null, "doi": "10.1109/TASLP.2020.2968738", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep learning-based speech enhancement algorithms are designed to\nminimize the mean-square error (MSE) in some transform domain between a\npredicted and a target speech signal. However, optimizing for MSE does not\nnecessarily guarantee high speech quality or intelligibility, which is the\nultimate goal of many speech enhancement algorithms. Additionally, only little\nis known about the impact of the loss function on the emerging class of\ntime-domain deep learning-based speech enhancement systems. We study how\npopular loss functions influence the performance of deep learning-based speech\nenhancement systems. First, we demonstrate that perceptually inspired loss\nfunctions might be advantageous if the receiver is the human auditory system.\nFurthermore, we show that the learning rate is a crucial design parameter even\nfor adaptive gradient-based optimizers, which has been generally overlooked in\nthe literature. Also, we found that waveform matching performance metrics must\nbe used with caution as they in certain situations can fail completely.\nFinally, we show that a loss function based on scale-invariant\nsignal-to-distortion ratio (SI-SDR) achieves good general performance across a\nrange of popular speech enhancement evaluation metrics, which suggests that\nSI-SDR is a good candidate as a general-purpose loss function for speech\nenhancement systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 09:32:11 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 10:58:32 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Kolb\u00e6k", "Morten", ""], ["Tan", "Zheng-Hua", ""], ["Jensen", "S\u00f8ren Holdt", ""], ["Jensen", "Jesper", ""]]}, {"id": "1909.01039", "submitter": "Henrich Kolkhorst", "authors": "Henrich Kolkhorst and Wolfram Burgard and Michael Tangermann", "title": "Learning User Preferences for Trajectories from Brain Signals", "comments": "The International Symposium on Robotics Research (ISRR), Hanoi,\n  Vietnam, October 2019; reformatted to two-column layout", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot motions in the presence of humans should not only be feasible and safe,\nbut also conform to human preferences. This, however, requires user feedback on\nthe robot's behavior. In this work, we propose a novel approach to leverage the\nuser's brain signals as a feedback modality in order to decode the judgment of\nrobot trajectories and rank them according to the user's preferences. We show\nthat brain signals measured using electroencephalography during observation of\na robotic arm's trajectory as well as in response to preference statements are\ninformative regarding the user's preference. Furthermore, we demonstrate that\nuser feedback from brain signals can be used to reliably infer pairwise\ntrajectory preferences as well as to retrieve the preferred observed\ntrajectories of the user with a performance comparable to explicit behavioral\nfeedback.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 10:20:50 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 17:51:42 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Kolkhorst", "Henrich", ""], ["Burgard", "Wolfram", ""], ["Tangermann", "Michael", ""]]}, {"id": "1909.01040", "submitter": "Koustav Ghosal", "authors": "Koustav Ghosal, Mukta Prasad, Aljosa Smolic", "title": "A Geometry-Sensitive Approach for Photographic Style Classification", "comments": "Irish Machine Vision and Image Processing Conference, Belfast, 2018", "journal-ref": "Irish Pattern Recognition and Classication Society (iprcs.org)\n  2018", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photographs are characterized by different compositional attributes like the\nRule of Thirds, depth of field, vanishing-lines etc. The presence or absence of\none or more of these attributes contributes to the overall artistic value of an\nimage. In this work, we analyze the ability of deep learning based methods to\nlearn such photographic style attributes. We observe that although a standard\nCNN learns the texture and appearance based features reasonably well, its\nunderstanding of global and geometric features is limited by two factors.\nFirst, the data-augmentation strategies (cropping, warping, etc.) distort the\ncomposition of a photograph and affect the performance. Secondly, the CNN\nfeatures, in principle, are translation-invariant and appearance-dependent. But\nsome geometric properties important for aesthetics, e.g. the Rule of Thirds\n(RoT), are position-dependent and appearance-invariant. Therefore, we propose a\nnovel input representation which is geometry-sensitive, position-cognizant and\nappearance-invariant. We further introduce a two-column CNN architecture that\nperforms better than the state-of-the-art (SoA) in photographic style\nclassification. From our results, we observe that the proposed network learns\nboth the geometric and appearance-based attributes better than the SoA.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 10:22:40 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ghosal", "Koustav", ""], ["Prasad", "Mukta", ""], ["Smolic", "Aljosa", ""]]}, {"id": "1909.01051", "submitter": "Pedro M. Esperan\\c{c}a", "authors": "Fabio Maria Carlucci and Pedro M Esperan\\c{c}a and Marco Singh and\n  Victor Gabillon and Antoine Yang and Hang Xu and Zewei Chen and Jun Wang", "title": "MANAS: Multi-Agent Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Neural Architecture Search (NAS) problem is typically formulated as a\ngraph search problem where the goal is to learn the optimal operations over\nedges in order to maximise a graph-level global objective. Due to the large\narchitecture parameter space, efficiency is a key bottleneck preventing NAS\nfrom its practical use. In this paper, we address the issue by framing NAS as a\nmulti-agent problem where agents control a subset of the network and coordinate\nto reach optimal architectures. We provide two distinct lightweight\nimplementations, with reduced memory requirements (1/8th of state-of-the-art),\nand performances above those of much more computationally expensive methods.\nTheoretically, we demonstrate vanishing regrets of the form O(sqrt(T)), with T\nbeing the total number of rounds. Finally, aware that random search is an,\noften ignored, effective baseline we perform additional experiments on 3\nalternative datasets and 2 network configurations, and achieve favourable\nresults in comparison.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 10:36:37 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 12:36:50 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 11:37:52 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Carlucci", "Fabio Maria", ""], ["Esperan\u00e7a", "Pedro M", ""], ["Singh", "Marco", ""], ["Gabillon", "Victor", ""], ["Yang", "Antoine", ""], ["Xu", "Hang", ""], ["Chen", "Zewei", ""], ["Wang", "Jun", ""]]}, {"id": "1909.01053", "submitter": "Michalina Strzyz", "authors": "Michalina Strzyz, David Vilares, Carlos G\\'omez-Rodr\\'iguez", "title": "Towards Making a Dependency Parser See", "comments": "Camera-ready version to appear at EMNLP 2019 (final peer-reviewed\n  manuscript). 8 pages (incl. appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore whether it is possible to leverage eye-tracking data in an RNN\ndependency parser (for English) when such information is only available during\ntraining, i.e., no aggregated or token-level gaze features are used at\ninference time. To do so, we train a multitask learning model that parses\nsentences as sequence labeling and leverages gaze features as auxiliary tasks.\nOur method also learns to train from disjoint datasets, i.e. it can be used to\ntest whether already collected gaze features are useful to improve the\nperformance on new non-gazed annotated treebanks. Accuracy gains are modest but\npositive, showing the feasibility of the approach. It can serve as a first step\ntowards architectures that can better leverage eye-tracking data or other\ncomplementary information available only for training sentences, possibly\nleading to improvements in syntactic parsing.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 10:42:35 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Strzyz", "Michalina", ""], ["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1909.01056", "submitter": "Koustav Ghosal", "authors": "Xu Zheng, Tejo Chalasani, Koustav Ghosal, Sebastian Lutz, Aljosa\n  Smolic", "title": "STaDA: Style Transfer as Data Augmentation", "comments": "14th International Conference on Computer Vision Theory and\n  Applications, 2019", "journal-ref": null, "doi": "10.5220/0007353401070114", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of training deep Convolutional Neural Networks (CNNs) heavily\ndepends on a significant amount of labelled data. Recent research has found\nthat neural style transfer algorithms can apply the artistic style of one image\nto another image without changing the latter's high-level semantic content,\nwhich makes it feasible to employ neural style transfer as a data augmentation\nmethod to add more variation to the training dataset. The contribution of this\npaper is a thorough evaluation of the effectiveness of the neural style\ntransfer as a data augmentation method for image classification tasks. We\nexplore the state-of-the-art neural style transfer algorithms and apply them as\na data augmentation method on Caltech 101 and Caltech 256 dataset, where we\nfound around 2% improvement from 83% to 85% of the image classification\naccuracy with VGG16, compared with traditional data augmentation strategies. We\nalso combine this new method with conventional data augmentation approaches to\nfurther improve the performance of image classification. This work shows the\npotential of neural style transfer in computer vision field, such as helping us\nto reduce the difficulty of collecting sufficient labelled data and improve the\nperformance of generic image-based deep learning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 10:48:42 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zheng", "Xu", ""], ["Chalasani", "Tejo", ""], ["Ghosal", "Koustav", ""], ["Lutz", "Sebastian", ""], ["Smolic", "Aljosa", ""]]}, {"id": "1909.01067", "submitter": "Habibeh Naderi", "authors": "Habibeh Naderi, Behrouz Haji Soleimani, Stan Matwin", "title": "Multimodal Deep Learning for Mental Disorders Prediction from Audio\n  Speech Samples", "comments": "arXiv admin note: text overlap with arXiv:1811.09362 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key features of mental illnesses are reflected in speech. Our research\nfocuses on designing a multimodal deep learning structure that automatically\nextracts salient features from recorded speech samples for predicting various\nmental disorders including depression, bipolar, and schizophrenia. We adopt a\nvariety of pre-trained models to extract embeddings from both audio and text\nsegments. We use several state-of-the-art embedding techniques including BERT,\nFastText, and Doc2VecC for the text representation learning and WaveNet and\nVGG-ish models for audio encoding. We also leverage huge auxiliary\nemotion-labeled text and audio corpora to train emotion-specific embeddings and\nuse transfer learning in order to address the problem of insufficient annotated\nmultimodal data available. All these embeddings are then combined into a joint\nrepresentation in a multimodal fusion layer and finally a recurrent neural\nnetwork is used to predict the mental disorder. Our results show that mental\ndisorders can be predicted with acceptable accuracy through multimodal analysis\nof clinical interviews.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 11:15:19 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 23:28:40 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 22:42:25 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 18:01:37 GMT"}, {"version": "v5", "created": "Mon, 13 Apr 2020 18:56:36 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Naderi", "Habibeh", ""], ["Soleimani", "Behrouz Haji", ""], ["Matwin", "Stan", ""]]}, {"id": "1909.01084", "submitter": "Yiwei Sun", "authors": "Yiwei Sun, Suhang Wang, Tsung-Yu Hsieh, Xianfeng Tang, Vasant Honavar", "title": "MEGAN: A Generative Adversarial Network for Multi-View Network Embedding", "comments": "Proceedings of the Twenty-Eighth International Joint Conference on\n  Artificial Intelligence, IJCAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data from many real-world applications can be naturally represented by\nmulti-view networks where the different views encode different types of\nrelationships (e.g., friendship, shared interests in music, etc.) between\nreal-world individuals or entities. There is an urgent need for methods to\nobtain low-dimensional, information preserving and typically nonlinear\nembeddings of such multi-view networks. However, most of the work on multi-view\nlearning focuses on data that lack a network structure, and most of the work on\nnetwork embeddings has focused primarily on single-view networks. Against this\nbackground, we consider the multi-view network representation learning problem,\ni.e., the problem of constructing low-dimensional information preserving\nembeddings of multi-view networks. Specifically, we investigate a novel\nGenerative Adversarial Network (GAN) framework for Multi-View Network\nEmbedding, namely MEGAN, aimed at preserving the information from the\nindividual network views, while accounting for connectivity across (and hence\ncomplementarity of and correlations between) different views. The results of\nour experiments on two real-world multi-view data sets show that the embeddings\nobtained using MEGAN outperform the state-of-the-art methods on node\nclassification, link prediction and visualization tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 01:08:26 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Sun", "Yiwei", ""], ["Wang", "Suhang", ""], ["Hsieh", "Tsung-Yu", ""], ["Tang", "Xianfeng", ""], ["Honavar", "Vasant", ""]]}, {"id": "1909.01087", "submitter": "Yucheng Lin", "authors": "Yucheng Lin, Xiaoqing Yang, Zang Li, Jieping Ye", "title": "AHINE: Adaptive Heterogeneous Information Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding is an effective way to solve the network analytics problems\nsuch as node classification, link prediction, etc. It represents network\nelements using low dimensional vectors such that the graph structural\ninformation and properties are maximumly preserved. Many prior works focused on\nembeddings for networks with the same type of edges or vertices, while some\nworks tried to generate embeddings for heterogeneous network using mechanisms\nlike specially designed meta paths. In this paper, we propose two novel\nalgorithms, GHINE (General Heterogeneous Information Network Embedding) and\nAHINE (Adaptive Heterogeneous Information Network Embedding), to compute\ndistributed representations for elements in heterogeneous networks. Specially,\nAHINE uses an adaptive deep model to learn network embeddings that maximizes\nthe likelihood of preserving the relationship chains between non-adjacent\nnodes. We apply our embeddings to a large network of points of interest (POIs)\nand achieve superior accuracy on some prediction problems on a ride-hailing\nplatform. In addition, we show that AHINE outperforms state-of-the-art methods\non a set of learning tasks on public datasets, including node labelling and\nsimilarity ranking in bibliographic networks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 04:35:10 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Lin", "Yucheng", ""], ["Yang", "Xiaoqing", ""], ["Li", "Zang", ""], ["Ye", "Jieping", ""]]}, {"id": "1909.01093", "submitter": "Zhiqiang Ma", "authors": "Azadeh Nematzadeh, Grace Bang, Xiaomo Liu, Zhiqiang Ma", "title": "Empirical Study on Detecting Controversy in Social Media", "comments": "The work is accepted by the 2nd KDD Workshop on Anomaly Detection in\n  Finance, 2019. The authors contributed equally to this work, listed in the\n  alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies and financial investors are paying increasing attention to social\nconsciousness in developing their corporate strategies and making investment\ndecisions to support a sustainable economy for the future. Public discussion on\nincidents and events -- controversies -- of companies can provide valuable\ninsights on how well the company operates with regards to social consciousness\nand indicate the company's overall operational capability. However, there are\nchallenges in evaluating the degree of a company's social consciousness and\nenvironmental sustainability due to the lack of systematic data. We introduce a\nsystem that utilizes Twitter data to detect and monitor controversial events\nand show their impact on market volatility. In our study, controversial events\nare identified from clustered tweets that share the same 5W terms and sentiment\npolarities of these clusters. Credible news links inside the event tweets are\nused to validate the truth of the event. A case study on the Starbucks\nPhiladelphia arrests shows that this method can provide the desired\nfunctionality.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 18:36:55 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Nematzadeh", "Azadeh", ""], ["Bang", "Grace", ""], ["Liu", "Xiaomo", ""], ["Ma", "Zhiqiang", ""]]}, {"id": "1909.01098", "submitter": "C\\'ecilia Ostertag", "authors": "Cecilia Ostertag, Marie Beurton-Aimar, Thierry Urruty", "title": "3DSiameseNet to Analyze Brain MRI", "comments": "published in ICPRS 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of the cognitive evolution of a person susceptible to develop a\nneurodegenerative disorder is crucial to provide an appropriate treatment as\nsoon as possible. In this paper we propose a 3D siamese network designed to\nextract features from whole-brain 3D MRI images. We show that it is possible to\nextract meaningful features using convolution layers, reducing the need of\nclassical image processing operations such as segmentation or pre-computing\nfeatures such as cortical thickness. To lead this study we used the Alzheimer's\nDisease Neuroimaging Initiative (ADNI), a public data base of 3D MRI brain\nimages. A set of 247 subjects has been extracted, all of the subjects having 2\nimages in a range of 12 months. In order to measure the evolution of the\npatients states we have compared these 2 images. Our work has been inspired at\nthe beginning by an article of Bhagwat et al. in 2018, who have proposed a\nsiamese network to predict the status of patients but without any convolutional\nlayers and reducing the MRI images to a vector of features extracted from\npredefined ROIs. We show that our network achieves an accuracy of 90\\% in the\nclassification of cognitively declining VS stable patients. This result has\nbeen obtained without the help of a cognitive score and with a small number of\npatients comparing to the current datasets size claimed in deep learning\ndomain.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 11:52:25 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ostertag", "Cecilia", ""], ["Beurton-Aimar", "Marie", ""], ["Urruty", "Thierry", ""]]}, {"id": "1909.01106", "submitter": "Yida Wang", "authors": "Yida Wang, David Joseph Tan, Nassir Navab, Federico Tombari", "title": "ForkNet: Multi-branch Volumetric Semantic Completion from a Single Depth\n  Image", "comments": "Accepted in International Conference on Computer Vision 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel model for 3D semantic completion from a single depth\nimage, based on a single encoder and three separate generators used to\nreconstruct different geometric and semantic representations of the original\nand completed scene, all sharing the same latent space. To transfer information\nbetween the geometric and semantic branches of the network, we introduce paths\nbetween them concatenating features at corresponding network layers. Motivated\nby the limited amount of training samples from real scenes, an interesting\nattribute of our architecture is the capacity to supplement the existing\ndataset by generating a new training dataset with high quality, realistic\nscenes that even includes occlusion and real noise. We build the new dataset by\nsampling the features directly from latent space which generates a pair of\npartial volumetric surface and completed volumetric semantic surface. Moreover,\nwe utilize multiple discriminators to increase the accuracy and realism of the\nreconstructions. We demonstrate the benefits of our approach on standard\nbenchmarks for the two most common completion tasks: semantic 3D scene\ncompletion and 3D object completion.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 12:04:39 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Yida", ""], ["Tan", "David Joseph", ""], ["Navab", "Nassir", ""], ["Tombari", "Federico", ""]]}, {"id": "1909.01108", "submitter": "Qiegen Liu", "authors": "Siyuan Wang, Junjie Lv, Yuanyuan Hu, Dong Liang, Minghui Zhang, Qiegen\n  Liu", "title": "Denoising Auto-encoding Priors in Undecimated Wavelet Domain for MR\n  Image Reconstruction", "comments": "10 pages, 11 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive sensing is an impressive approach for fast MRI. It aims at\nreconstructing MR image using only a few under-sampled data in k-space,\nenhancing the efficiency of the data acquisition. In this study, we propose to\nlearn priors based on undecimated wavelet transform and an iterative image\nreconstruction algorithm. At the stage of prior learning, transformed feature\nimages obtained by undecimated wavelet transform are stacked as an input of\ndenoising autoencoder network (DAE). The highly redundant and multi-scale input\nenables the correlation of feature images at different channels, which allows a\nrobust network-driven prior. At the iterative reconstruction, the transformed\nDAE prior is incorporated into the classical iterative procedure by the means\nof proximal gradient algorithm. Experimental comparisons on different sampling\ntrajectories and ratios validated the great potential of the presented\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 12:09:21 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 01:56:02 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Wang", "Siyuan", ""], ["Lv", "Junjie", ""], ["Hu", "Yuanyuan", ""], ["Liang", "Dong", ""], ["Zhang", "Minghui", ""], ["Liu", "Qiegen", ""]]}, {"id": "1909.01120", "submitter": "Saravanan Thirumuruganathan", "authors": "Riccardo Cappuzzo, Paolo Papotti, Saravanan Thirumuruganathan", "title": "Local Embeddings for Relational Data Integration", "comments": "Accepted to SIGMOD 2020 as Creating Embeddings of Heterogeneous\n  Relational Datasets for Data Integration Tasks. Code can be found at\n  https://gitlab.eurecom.fr/cappuzzo/embdi", "journal-ref": null, "doi": "10.1145/3318464.3389742", "report-no": null, "categories": "cs.DB cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based techniques have been recently used with promising results\nfor data integration problems. Some methods directly use pre-trained embeddings\nthat were trained on a large corpus such as Wikipedia. However, they may not\nalways be an appropriate choice for enterprise datasets with custom vocabulary.\nOther methods adapt techniques from natural language processing to obtain\nembeddings for the enterprise's relational data. However, this approach blindly\ntreats a tuple as a sentence, thus losing a large amount of contextual\ninformation present in the tuple.\n  We propose algorithms for obtaining local embeddings that are effective for\ndata integration tasks on relational databases. We make four major\ncontributions. First, we describe a compact graph-based representation that\nallows the specification of a rich set of relationships inherent in the\nrelational world. Second, we propose how to derive sentences from such a graph\nthat effectively \"describe\" the similarity across elements (tokens, attributes,\nrows) in the two datasets. The embeddings are learned based on such sentences.\nThird, we propose effective optimization to improve the quality of the learned\nembeddings and the performance of integration tasks. Finally, we propose a\ndiverse collection of criteria to evaluate relational embeddings and perform an\nextensive set of experiments validating them against multiple baseline methods.\nOur experiments show that our framework, EmbDI, produces meaningful results for\ndata integration tasks such as schema matching and entity resolution both in\nsupervised and unsupervised settings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 12:45:02 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 08:56:00 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Cappuzzo", "Riccardo", ""], ["Papotti", "Paolo", ""], ["Thirumuruganathan", "Saravanan", ""]]}, {"id": "1909.01132", "submitter": "Loc Tran H", "authors": "Loc Tran, Tho Quan, An Mai", "title": "PageRank algorithm for Directed Hypergraph", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last two decades, we easilly see that the World Wide Web's link\nstructure is modeled as the directed graph. In this paper, we will model the\nWorld Wide Web's link structure as the directed hypergraph. Moreover, we will\ndevelop the PageRank algorithm for this directed hypergraph. Due to the lack of\nthe World Wide Web directed hypergraph datasets, we will apply the PageRank\nalgorithm to the metabolic network which is the directed hypergraph itself. The\nexperiments show that our novel PageRank algorithm is successfully applied to\nthis metabolic network.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 04:15:25 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Tran", "Loc", ""], ["Quan", "Tho", ""], ["Mai", "An", ""]]}, {"id": "1909.01135", "submitter": "Chidimma Opara", "authors": "Chidimma Opara, Bo Wei, and Yingke Chen", "title": "HTMLPhish: Enabling Phishing Web Page Detection by Applying Deep\n  Learning Techniques on HTML Analysis", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN) 2020", "doi": "10.1109/IJCNN48605.2020.9207707", "report-no": null, "categories": "cs.CR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the development and implementation of phishing attacks require\nlittle technical skills and costs. This uprising has led to an ever-growing\nnumber of phishing attacks on the World Wide Web. Consequently, proactive\ntechniques to fight phishing attacks have become extremely necessary. In this\npaper, we propose HTMLPhish, a deep learning based data-driven end-to-end\nautomatic phishing web page classification approach. Specifically, HTMLPhish\nreceives the content of the HTML document of a web page and employs\nConvolutional Neural Networks (CNNs) to learn the semantic dependencies in the\ntextual contents of the HTML. The CNNs learn appropriate feature\nrepresentations from the HTML document embeddings without extensive manual\nfeature engineering. Furthermore, our proposed approach of the concatenation of\nthe word and character embeddings allows our model to manage new features and\nensure easy extrapolation to test data. We conduct comprehensive experiments on\na dataset of more than 50,000 HTML documents that provides a distribution of\nphishing to benign web pages obtainable in the real-world that yields over 93\npercent Accuracy and True Positive Rate. Also, HTMLPhish is a completely\nlanguage-independent and client-side strategy which can, therefore, conduct web\npage phishing detection regardless of the textual language.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 23:58:50 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 17:10:56 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 10:30:32 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Opara", "Chidimma", ""], ["Wei", "Bo", ""], ["Chen", "Yingke", ""]]}, {"id": "1909.01136", "submitter": "Binbin Xu", "authors": "Binbin Xu and C\\'edric Gil-Jardin\\'e and Frantz Thiessard and Eric\n  Tellier and Marta Avalos and Emmanuel Lagarde", "title": "Pre-training A Neural Language Model Improves The Sample Efficiency of\n  an Emergency Room Classification Model", "comments": "Version of the published manuscript", "journal-ref": "The 33rd Florida Artificial Intelligence Research Society\n  Conference, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build a French national electronic injury surveillance system based on\nemergency room visits, we aim to develop a coding system to classify their\ncauses from clinical notes in free-text. Supervised learning techniques have\nshown good results in this area but require a large amount of expert annotated\ndataset which is time consuming and costly to obtain. We hypothesize that the\nNatural Language Processing Transformer model incorporating a generative\nself-supervised pre-training step can significantly reduce the required number\nof annotated samples for supervised fine-tuning. In this preliminary study, we\ntest our hypothesis in the simplified problem of predicting whether a visit is\nthe consequence of a traumatic event or not from free-text clinical notes.\nUsing fully re-trained GPT-2 models (without OpenAI pre-trained weights), we\nassess the gain of applying a self-supervised pre-training phase with unlabeled\nnotes prior to the supervised learning task. Results show that the number of\ndata required to achieve a ginve level of performance (AUC>0.95) was reduced by\na factor of 10 when applying pre-training. Namely, for 16 times more data, the\nfully-supervised model achieved an improvement <1% in AUC. To conclude, it is\npossible to adapt a multi-purpose neural language model such as the GPT-2 to\ncreate a powerful tool for classification of free-text notes with only a small\nnumber of labeled samples.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 17:25:06 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 16:16:29 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 14:47:26 GMT"}, {"version": "v4", "created": "Thu, 24 Oct 2019 12:19:14 GMT"}, {"version": "v5", "created": "Wed, 7 Apr 2021 09:33:10 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Xu", "Binbin", ""], ["Gil-Jardin\u00e9", "C\u00e9dric", ""], ["Thiessard", "Frantz", ""], ["Tellier", "Eric", ""], ["Avalos", "Marta", ""], ["Lagarde", "Emmanuel", ""]]}, {"id": "1909.01145", "submitter": "Peng Liu", "authors": "Peng Liu, Xixin Wu, Shiyin Kang, Guangzhi Li, Dan Su, Dong Yu", "title": "Maximizing Mutual Information for Tacotron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end speech synthesis methods already achieve close-to-human quality\nperformance. However compared to HMM-based and NN-based frame-to-frame\nregression methods, they are prone to some synthesis errors, such as missing or\nrepeating words and incomplete synthesis. We attribute the comparatively high\nutterance error rate to the local information preference of conditional\nautoregressive models, and the ill-posed training objective of the model, which\ndescribes mostly the training status of the autoregressive module, but rarely\nthat of the condition module. Inspired by InfoGAN, we propose to maximize the\nmutual information between the text condition and the predicted acoustic\nfeatures to strengthen the dependency between them for CAR speech synthesis\nmodel, which would alleviate the local information preference issue and reduce\nthe utterance error rate. The training objective of maximizing mutual\ninformation can be considered as a metric of the dependency between the\nautoregressive module and the condition module. Experiment results show that\nour method can reduce the utterance error rate.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 04:03:14 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 07:24:35 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Liu", "Peng", ""], ["Wu", "Xixin", ""], ["Kang", "Shiyin", ""], ["Li", "Guangzhi", ""], ["Su", "Dan", ""], ["Yu", "Dong", ""]]}, {"id": "1909.01146", "submitter": "Jeffrey Cheng", "authors": "Jeffrey Cheng and Chris Callison-Burch", "title": "Bilingual is At Least Monolingual (BALM): A Novel Translation Algorithm\n  that Encodes Monolingual Priors", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art machine translation (MT) models do not use knowledge of any\nsingle language's structure; this is the equivalent of asking someone to\ntranslate from English to German while knowing neither language. BALM is a\nframework incorporates monolingual priors into an MT pipeline; by casting input\nand output languages into embedded space using BERT, we can solve machine\ntranslation with much simpler models. We find that English-to-German\ntranslation on the Multi30k dataset can be solved with a simple feedforward\nnetwork under the BALM framework with near-SOTA BLEU scores.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 03:16:10 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Cheng", "Jeffrey", ""], ["Callison-Burch", "Chris", ""]]}, {"id": "1909.01150", "submitter": "Lingxiao Wang", "authors": "Lingxiao Wang, Qi Cai, Zhuoran Yang, Zhaoran Wang", "title": "Neural Policy Gradient Methods: Global Optimality and Rates of\n  Convergence", "comments": "71 pages. The first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods with actor-critic schemes demonstrate tremendous\nempirical successes, especially when the actors and critics are parameterized\nby neural networks. However, it remains less clear whether such \"neural\" policy\ngradient methods converge to globally optimal policies and whether they even\nconverge at all. We answer both the questions affirmatively in the\noverparameterized regime. In detail, we prove that neural natural policy\ngradient converges to a globally optimal policy at a sublinear rate. Also, we\nshow that neural vanilla policy gradient converges sublinearly to a stationary\npoint. Meanwhile, by relating the suboptimality of the stationary points to the\nrepresentation power of neural actor and critic classes, we prove the global\noptimality of all stationary points under mild regularity conditions.\nParticularly, we show that a key to the global optimality and convergence is\nthe \"compatibility\" between the actor and critic, which is ensured by sharing\nneural architectures and random initializations across the actor and critic. To\nthe best of our knowledge, our analysis establishes the first global optimality\nand convergence guarantees for neural policy gradient methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:38:19 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 00:25:26 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 21:42:43 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Wang", "Lingxiao", ""], ["Cai", "Qi", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1909.01174", "submitter": "Alexandre Defossez", "authors": "Alexandre D\\'efossez (SIERRA, PSL, FAIR), Nicolas Usunier (FAIR),\n  L\\'eon Bottou (FAIR), Francis Bach (PSL, DI-ENS, SIERRA)", "title": "Demucs: Deep Extractor for Music Sources with extra unlabeled data\n  remixed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of source separation for music using deep learning with\nfour known sources: drums, bass, vocals and other accompaniments.\nState-of-the-art approaches predict soft masks over mixture spectrograms while\nmethods working on the waveform are lagging behind as measured on the standard\nMusDB benchmark. Our contribution is two fold. (i) We introduce a simple\nconvolutional and recurrent model that outperforms the state-of-the-art model\non waveforms, that is, Wave-U-Net, by 1.6 points of SDR (signal to distortion\nratio). (ii) We propose a new scheme to leverage unlabeled music. We train a\nfirst model to extract parts with at least one source silent in unlabeled\ntracks, for instance without bass. We remix this extract with a bass line taken\nfrom the supervised dataset to form a new weakly supervised training example.\nCombining our architecture and scheme, we show that waveform methods can play\nin the same ballpark as spectrogram ones.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 13:41:56 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["D\u00e9fossez", "Alexandre", "", "SIERRA, PSL, FAIR"], ["Usunier", "Nicolas", "", "FAIR"], ["Bottou", "L\u00e9on", "", "FAIR"], ["Bach", "Francis", "", "PSL, DI-ENS, SIERRA"]]}, {"id": "1909.01185", "submitter": "Yvan Lucas", "authors": "Yvan Lucas, Pierre-Edouard Portier, L\\'ea Laporte, Liyun He-Guelton,\n  Olivier Caelen, Michael Granitzer, Sylvie Calabretto", "title": "Towards automated feature engineering for credit card fraud detection\n  using multi-perspective HMMs", "comments": "published in the journal \"future generation computer systems\", in the\n  special issue: \"data exploration in the web 3.0 age\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and data mining techniques have been used extensively in\norder to detect credit card frauds. However, most studies consider credit card\ntransactions as isolated events and not as a sequence of transactions. In this\nframework, we model a sequence of credit card transactions from three different\nperspectives, namely (i) The sequence contains or doesn't contain a fraud (ii)\nThe sequence is obtained by fixing the card-holder or the payment terminal\n(iii) It is a sequence of spent amount or of elapsed time between the current\nand previous transactions. Combinations of the three binary perspectives give\neight sets of sequences from the (training) set of transactions. Each one of\nthese sequences is modelled with a Hidden Markov Model (HMM). Each HMM\nassociates a likelihood to a transaction given its sequence of previous\ntransactions. These likelihoods are used as additional features in a Random\nForest classifier for fraud detection. Our multiple perspectives HMM-based\napproach offers automated feature engineering to model temporal correlations so\nas to improve the effectiveness of the classification task and allows for an\nincrease in the detection of fraudulent transactions when combined with the\nstate of the art expert based feature engineering strategy for credit card\nfraud detection. In extension to previous works, we show that this approach\ngoes beyond ecommerce transactions and provides a robust feature engineering\nover different datasets, hyperparameters and classifiers. Moreover, we compare\nstrategies to deal with structural missing values.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 13:53:35 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Lucas", "Yvan", ""], ["Portier", "Pierre-Edouard", ""], ["Laporte", "L\u00e9a", ""], ["He-Guelton", "Liyun", ""], ["Caelen", "Olivier", ""], ["Granitzer", "Michael", ""], ["Calabretto", "Sylvie", ""]]}, {"id": "1909.01202", "submitter": "Karanpreet Singh", "authors": "Karanpreet Singh and Rajen Bhatt", "title": "Personalizing Smartwatch Based Activity Recognition Using Transfer\n  Learning", "comments": "6 Pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartwatches are increasingly being used to recognize human daily life\nactivities. These devices may employ different kind of machine learning (ML)\nsolutions. One of such ML models is Gradient Boosting Machine (GBM) which has\nshown an excellent performance in the literature. The GBM can be trained on\navailable data set before it is deployed on any device. However, this data set\nmay not represent every kind of human behavior in real life. For example, a ML\nmodel to detect elder and young persons running activity may give different\nresults because of differences in their activity patterns. This may result in\ndecrease in the accuracy of activity recognition. Therefore, a transfer\nlearning based method is proposed in which user-specific performance can be\nimproved significantly by doing on-device calibration of GBM by just tuning its\nparameters without retraining its estimators. Results show that this method can\nsignificantly improve the user-based accuracy for activity recognition.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:13:49 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Singh", "Karanpreet", ""], ["Bhatt", "Rajen", ""]]}, {"id": "1909.01205", "submitter": "Bram Wallace", "authors": "Bram Wallace, Bharath Hariharan", "title": "Few-Shot Generalization for Single-Image 3D Reconstruction via Priors", "comments": "To appear in ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on single-view 3D reconstruction shows impressive results, but\nhas been restricted to a few fixed categories where extensive training data is\navailable. The problem of generalizing these models to new classes with limited\ntraining data is largely open. To address this problem, we present a new model\narchitecture that reframes single-view 3D reconstruction as learnt, category\nagnostic refinement of a provided, category-specific prior. The provided prior\nshape for a novel class can be obtained from as few as one 3D shape from this\nclass. Our model can start reconstructing objects from the novel class using\nthis prior without seeing any training image for this class and without any\nretraining. Our model outperforms category-agnostic baselines and remains\ncompetitive with more sophisticated baselines that finetune on the novel\ncategories. Additionally, our network is capable of improving the\nreconstruction given multiple views despite not being trained on task of\nmulti-view reconstruction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:18:42 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Wallace", "Bram", ""], ["Hariharan", "Bharath", ""]]}, {"id": "1909.01218", "submitter": "Maximilian M\\\"uller-Eberstein", "authors": "Maximilian M\\\"uller-Eberstein and Nanne van Noord", "title": "Translating Visual Art into Music", "comments": "Accepted for ICCV 2019 Workshop on Fashion, Art and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Synesthetic Variational Autoencoder (SynVAE) introduced in this research\nis able to learn a consistent mapping between visual and auditive sensory\nmodalities in the absence of paired datasets. A quantitative evaluation on\nMNIST as well as the Behance Artistic Media dataset (BAM) shows that SynVAE is\ncapable of retaining sufficient information content during the translation\nwhile maintaining cross-modal latent space consistency. In a qualitative\nevaluation trial, human evaluators were furthermore able to match musical\nsamples with the images which generated them with accuracies of up to 73%.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:36:19 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["M\u00fcller-Eberstein", "Maximilian", ""], ["van Noord", "Nanne", ""]]}, {"id": "1909.01228", "submitter": "Md Nafee Al Islam", "authors": "Md Nafee Al Islam, Tanzil Bin Hassan, Siamul Karim Khan", "title": "A CNN-based approach to classify cricket bowlers based on their bowling\n  actions", "comments": "5 pages, 7 figures, The paper is under review in \"IEEE International\n  Conference on Robotics, Automation, Artificial-Intelligence and\n  Internet-of-Things, 2019\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advances in hardware technologies and deep learning techniques, it\nhas become feasible to apply these techniques in diverse fields. Convolutional\nNeural Network (CNN), an architecture from the field of deep learning, has\nrevolutionized Computer Vision. Sports is one of the avenues in which the use\nof computer vision is thriving. Cricket is a complex game consisting of\ndifferent types of shots, bowling actions and many other activities. Every\nbowler, in a game of cricket, bowls with a different bowling action. We\nleverage this point to identify different bowlers. In this paper, we have\nproposed a CNN model to identify eighteen different cricket bowlers based on\ntheir bowling actions using transfer learning. Additionally, we have created a\ncompletely new dataset containing 8100 images of these eighteen bowlers to\ntrain the proposed framework and evaluate its performance. We have used the\nVGG16 model pre-trained with the ImageNet dataset and added a few layers on top\nof it to build our model. After trying out different strategies, we found that\nfreezing the weights for the first 14 layers of the network and training the\nrest of the layers works best. Our approach achieves an overall average\naccuracy of 93.3% on the test set and converges to a very low cross-entropy\nloss.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:45:40 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Islam", "Md Nafee Al", ""], ["Hassan", "Tanzil Bin", ""], ["Khan", "Siamul Karim", ""]]}, {"id": "1909.01251", "submitter": "Guy W Cole", "authors": "Guy W. Cole and Sinead A. Williamson", "title": "Avoiding Resentment Via Monotonic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers that achieve demographic balance by explicitly using protected\nattributes such as race or gender are often politically or culturally\ncontroversial due to their lack of individual fairness, i.e. individuals with\nsimilar qualifications will receive different outcomes. Individually and group\nfair decision criteria can produce counter-intuitive results, e.g. that the\noptimal constrained boundary may reject intuitively better candidates due to\ndemographic imbalance in similar candidates. Both approaches can be seen as\nintroducing individual resentment, where some individuals would have received a\nbetter outcome if they either belonged to a different demographic class and had\nthe same qualifications, or if they remained in the same class but had\nobjectively worse qualifications (e.g. lower test scores). We show that both\nforms of resentment can be avoided by using monotonically constrained machine\nlearning models to create individually fair, demographically balanced\nclassifiers.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 15:28:16 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Cole", "Guy W.", ""], ["Williamson", "Sinead A.", ""]]}, {"id": "1909.01259", "submitter": "Ikuya Yamada", "authors": "Ikuya Yamada, Hiroyuki Shindo", "title": "Neural Attentive Bag-of-Entities Model for Text Classification", "comments": "Accepted to CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a Neural Attentive Bag-of-Entities model, which is a\nneural network model that performs text classification using entities in a\nknowledge base. Entities provide unambiguous and relevant semantic signals that\nare beneficial for capturing semantics in texts. We combine simple high-recall\nentity detection based on a dictionary, to detect entities in a document, with\na novel neural attention mechanism that enables the model to focus on a small\nnumber of unambiguous and relevant entities. We tested the effectiveness of our\nmodel using two standard text classification datasets (i.e., the 20 Newsgroups\nand R8 datasets) and a popular factoid question answering dataset based on a\ntrivia quiz game. As a result, our model achieved state-of-the-art results on\nall datasets. The source code of the proposed model is available online at\nhttps://github.com/wikipedia2vec/wikipedia2vec.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 15:50:34 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 10:23:49 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Yamada", "Ikuya", ""], ["Shindo", "Hiroyuki", ""]]}, {"id": "1909.01264", "submitter": "Avner May", "authors": "Avner May, Jian Zhang, Tri Dao, Christopher R\\'e", "title": "On the Downstream Performance of Compressed Word Embeddings", "comments": "NeurIPS 2019 spotlight (Conference on Neural Information Processing\n  Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressing word embeddings is important for deploying NLP models in\nmemory-constrained settings. However, understanding what makes compressed\nembeddings perform well on downstream tasks is challenging---existing measures\nof compression quality often fail to distinguish between embeddings that\nperform well and those that do not. We thus propose the eigenspace overlap\nscore as a new measure. We relate the eigenspace overlap score to downstream\nperformance by developing generalization bounds for the compressed embeddings\nin terms of this score, in the context of linear and logistic regression. We\nthen show that we can lower bound the eigenspace overlap score for a simple\nuniform quantization compression method, helping to explain the strong\nempirical performance of this method. Finally, we show that by using the\neigenspace overlap score as a selection criterion between embeddings drawn from\na representative set we compressed, we can efficiently identify the better\nperforming embedding with up to $2\\times$ lower selection error rates than the\nnext best measure of compression quality, and avoid the cost of training a\nmodel for each task of interest.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:00:18 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 22:21:42 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["May", "Avner", ""], ["Zhang", "Jian", ""], ["Dao", "Tri", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1909.01304", "submitter": "Brendon Boldt", "authors": "Brendon Boldt, Zack While, Eric Breimer", "title": "Detecting Compromised Implicit Association Test Results Using Supervised\n  Learning", "comments": "6 pages, 1 figure", "journal-ref": "2018 17th IEEE International Conference on Machine Learning and\n  Applications (ICMLA), Orlando, FL, 2018, pp. 449-453", "doi": "10.1109/ICMLA.2018.00073", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An implicit association test is a human psychological test used to measure\nsubconscious associations. While widely recognized by psychologists as an\neffective tool in measuring attitudes and biases, the validity of the results\ncan be compromised if a subject does not follow the instructions or attempts to\nmanipulate the outcome. Compared to previous work, we collect training data\nusing a more generalized methodology. We train a variety of different\nclassifiers to identify a participant's first attempt versus a second possibly\ncompromised attempt. To compromise the second attempt, participants are shown\ntheir score and are instructed to change it using one of five randomly selected\ndeception methods. Compared to previous work, our methodology demonstrates a\nmore robust and practical framework for accurately identifying a wide variety\nof deception techniques applicable to the IAT.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:52:10 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Boldt", "Brendon", ""], ["While", "Zack", ""], ["Breimer", "Eric", ""]]}, {"id": "1909.01311", "submitter": "Charlotte Frenkel", "authors": "Charlotte Frenkel, Martin Lefebvre, David Bol", "title": "Learning without feedback: Fixed random learning signals allow for\n  feedforward training of deep neural networks", "comments": "This document is the paper as accepted for publication in the\n  Frontiers in Neuroscience journal, the fully-edited paper is available at\n  https://www.frontiersin.org/articles/10.3389/fnins.2021.629892", "journal-ref": null, "doi": "10.3389/fnins.2021.629892", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the backpropagation of error algorithm enables deep neural network\ntraining, it implies (i) bidirectional synaptic weight transport and (ii)\nupdate locking until the forward and backward passes are completed. Not only do\nthese constraints preclude biological plausibility, but they also hinder the\ndevelopment of low-cost adaptive smart sensors at the edge, as they severely\nconstrain memory accesses and entail buffering overhead. In this work, we show\nthat the one-hot-encoded labels provided in supervised classification problems,\ndenoted as targets, can be viewed as a proxy for the error sign. Therefore,\ntheir fixed random projections enable a layerwise feedforward training of the\nhidden layers, thus solving the weight transport and update locking problems\nwhile relaxing the computational and memory requirements. Based on these\nobservations, we propose the direct random target projection (DRTP) algorithm\nand demonstrate that it provides a tradeoff between accuracy and computational\ncost that is suitable for adaptive edge computing devices.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:04:00 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 22:09:58 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Frenkel", "Charlotte", ""], ["Lefebvre", "Martin", ""], ["Bol", "David", ""]]}, {"id": "1909.01315", "submitter": "Minjie Wang", "authors": "Minjie Wang, Da Zheng, Zihao Ye, Quan Gan, Mufei Li, Xiang Song,\n  Jinjing Zhou, Chao Ma, Lingfan Yu, Yu Gai, Tianjun Xiao, Tong He, George\n  Karypis, Jinyang Li, Zheng Zhang", "title": "Deep Graph Library: A Graph-Centric, Highly-Performant Package for Graph\n  Neural Networks", "comments": "Major update with significantly more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancing research in the emerging field of deep graph learning requires new\ntools to support tensor computation over graphs. In this paper, we present the\ndesign principles and implementation of Deep Graph Library (DGL). DGL distills\nthe computational patterns of GNNs into a few generalized sparse tensor\noperations suitable for extensive parallelization. By advocating graph as the\ncentral programming abstraction, DGL can perform optimizations transparently.\nBy cautiously adopting a framework-neutral design, DGL allows users to easily\nport and leverage the existing components across multiple deep learning\nframeworks. Our evaluation shows that DGL significantly outperforms other\npopular GNN-oriented frameworks in both speed and memory consumption over a\nvariety of benchmarks and has little overhead for small scale workloads.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:10:28 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 15:46:13 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Wang", "Minjie", ""], ["Zheng", "Da", ""], ["Ye", "Zihao", ""], ["Gan", "Quan", ""], ["Li", "Mufei", ""], ["Song", "Xiang", ""], ["Zhou", "Jinjing", ""], ["Ma", "Chao", ""], ["Yu", "Lingfan", ""], ["Gai", "Yu", ""], ["Xiao", "Tianjun", ""], ["He", "Tong", ""], ["Karypis", "George", ""], ["Li", "Jinyang", ""], ["Zhang", "Zheng", ""]]}, {"id": "1909.01331", "submitter": "Suzan Ece Ada", "authors": "Suzan Ece Ada and Emre Ugur and H. Levent Akin", "title": "Generalization in Transfer Learning", "comments": "23 pages, 36 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents trained with deep reinforcement learning algorithms are capable of\nperforming highly complex tasks including locomotion in continuous\nenvironments. We investigate transferring the learning acquired in one task to\na set of previously unseen tasks. Generalization and overfitting in deep\nreinforcement learning are not commonly addressed in current transfer learning\nresearch. Conducting a comparative analysis without an intermediate\nregularization step results in underperforming benchmarks and inaccurate\nalgorithm comparisons due to rudimentary assessments. In this study, we propose\nregularization techniques in deep reinforcement learning for continuous control\nthrough the application of sample elimination, early stopping and maximum\nentropy regularized adversarial learning. First, the importance of the\ninclusion of training iteration number to the hyperparameters in deep transfer\nreinforcement learning will be discussed. Because source task performance is\nnot indicative of the generalization capacity of the algorithm, we start by\nacknowledging the training iteration number as a hyperparameter. In line with\nthis, we introduce an additional step of resorting to earlier snapshots of\npolicy parameters to prevent overfitting to the source task. Then, to generate\nrobust policies, we discard the samples that lead to overfitting via a method\nwe call strict clipping. Furthermore, we increase the generalization capacity\nin widely used transfer learning benchmarks by using maximum entropy\nregularization, different critic methods, and curriculum learning in an\nadversarial setup. Subsequently, we propose maximum entropy adversarial\nreinforcement learning to increase the domain randomization. Finally, we\nevaluate the robustness of these methods on simulated robots in target\nenvironments where the morphology of the robot, gravity, and tangential\nfriction coefficient of the environment are altered.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:57:07 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 07:48:49 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ada", "Suzan Ece", ""], ["Ugur", "Emre", ""], ["Akin", "H. Levent", ""]]}, {"id": "1909.01359", "submitter": "Fr\\'ed\\'eric Dreyer", "authors": "Stefano Carrazza and Fr\\'ed\\'eric A. Dreyer", "title": "Lund jet images from generative and cycle-consistent adversarial\n  networks", "comments": "11 pages, 15 figures, code available at\n  https://github.com/JetsGame/gLund and https://github.com/JetsGame/CycleJet,\n  updated to match published version", "journal-ref": null, "doi": "10.1140/epjc/s10052-019-7501-1", "report-no": "OUTP-19-09P, TIF-UNIMI-2019-14", "categories": "hep-ph cs.LG eess.IV hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generative model to simulate radiation patterns within a jet\nusing the Lund jet plane. We show that using an appropriate neural network\narchitecture with a stochastic generation of images, it is possible to\nconstruct a generative model which retrieves the underlying two-dimensional\ndistribution to within a few percent. We compare our model with several\nalternative state-of-the-art generative techniques. Finally, we show how a\nmapping can be created between different categories of jets, and use this\nmethod to retroactively change simulation settings or the underlying process on\nan existing sample. These results provide a framework for significantly\nreducing simulation times through fast inference of the neural network as well\nas for data augmentation of physical measurements.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:00:03 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 14:52:20 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Carrazza", "Stefano", ""], ["Dreyer", "Fr\u00e9d\u00e9ric A.", ""]]}, {"id": "1909.01377", "submitter": "Shaojie Bai", "authors": "Shaojie Bai, J. Zico Kolter, Vladlen Koltun", "title": "Deep Equilibrium Models", "comments": "NeurIPS 2019 Spotlight Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to modeling sequential data: the deep equilibrium\nmodel (DEQ). Motivated by an observation that the hidden layers of many\nexisting deep sequence models converge towards some fixed point, we propose the\nDEQ approach that directly finds these equilibrium points via root-finding.\nSuch a method is equivalent to running an infinite depth (weight-tied)\nfeedforward network, but has the notable advantage that we can analytically\nbackpropagate through the equilibrium point using implicit differentiation.\nUsing this approach, training and prediction in these networks require only\nconstant memory, regardless of the effective \"depth\" of the network. We\ndemonstrate how DEQs can be applied to two state-of-the-art deep sequence\nmodels: self-attention transformers and trellis networks. On large-scale\nlanguage modeling tasks, such as the WikiText-103 benchmark, we show that DEQs\n1) often improve performance over these state-of-the-art models (for similar\nparameter counts); 2) have similar computational requirements to existing\nmodels; and 3) vastly reduce memory consumption (often the bottleneck for\ntraining large sequence models), demonstrating an up-to 88% memory reduction in\nour experiments. The code is available at https://github.com/locuslab/deq .\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:02:50 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 22:25:01 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Bai", "Shaojie", ""], ["Kolter", "J. Zico", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1909.01387", "submitter": "Tom Paine", "authors": "Tom Le Paine, Caglar Gulcehre, Bobak Shahriari, Misha Denil, Matt\n  Hoffman, Hubert Soyer, Richard Tanburn, Steven Kapturowski, Neil Rabinowitz,\n  Duncan Williams, Gabriel Barth-Maron, Ziyu Wang, Nando de Freitas, Worlds\n  Team", "title": "Making Efficient Use of Demonstrations to Solve Hard Exploration\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces R2D3, an agent that makes efficient use of\ndemonstrations to solve hard exploration problems in partially observable\nenvironments with highly variable initial conditions. We also introduce a suite\nof eight tasks that combine these three properties, and show that R2D3 can\nsolve several of the tasks where other state of the art methods (both with and\nwithout demonstrations) fail to see even a single successful trajectory after\ntens of billions of steps of exploration.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:20:48 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Paine", "Tom Le", ""], ["Gulcehre", "Caglar", ""], ["Shahriari", "Bobak", ""], ["Denil", "Misha", ""], ["Hoffman", "Matt", ""], ["Soyer", "Hubert", ""], ["Tanburn", "Richard", ""], ["Kapturowski", "Steven", ""], ["Rabinowitz", "Neil", ""], ["Williams", "Duncan", ""], ["Barth-Maron", "Gabriel", ""], ["Wang", "Ziyu", ""], ["de Freitas", "Nando", ""], ["Team", "Worlds", ""]]}, {"id": "1909.01394", "submitter": "Luyao Shi", "authors": "Luyao Shi, John A. Onofrey, Enette Mae Revilla, Takuya Toyonaga, David\n  Menard, Jo-seph Ankrah, Richard E. Carson, Chi Liu, Yihuan Lu", "title": "A Novel Loss Function Incorporating Imaging Acquisition Physics for PET\n  Attenuation Map Generation using Deep Learning", "comments": "Accepted at MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In PET/CT imaging, CT is used for PET attenuation correction (AC). Mismatch\nbetween CT and PET due to patient body motion results in AC artifacts. In\naddition, artifact caused by metal, beam-hardening and count-starving in CT\nitself also introduces inaccurate AC for PET. Maximum likelihood reconstruction\nof activity and attenuation (MLAA) was proposed to solve those issues by\nsimultaneously reconstructing tracer activity ($\\lambda$-MLAA) and attenuation\nmap ($\\mu$-MLAA) based on the PET raw data only. However, $\\mu$-MLAA suffers\nfrom high noise and $\\lambda$-MLAA suffers from large bias as compared to the\nreconstruction using the CT-based attenuation map ($\\mu$-CT). Recently, a\nconvolutional neural network (CNN) was applied to predict the CT attenuation\nmap ($\\mu$-CNN) from $\\lambda$-MLAA and $\\mu$-MLAA, in which an image-domain\nloss (IM-loss) function between the $\\mu$-CNN and the ground truth $\\mu$-CT was\nused. However, IM-loss does not directly measure the AC errors according to the\nPET attenuation physics, where the line-integral projection of the attenuation\nmap ($\\mu$) along the path of the two annihilation events, instead of the $\\mu$\nitself, is used for AC. Therefore, a network trained with the IM-loss may yield\nsuboptimal performance in the $\\mu$ generation. Here, we propose a novel\nline-integral projection loss (LIP-loss) function that incorporates the PET\nattenuation physics for $\\mu$ generation. Eighty training and twenty testing\ndatasets of whole-body 18F-FDG PET and paired ground truth $\\mu$-CT were used.\nQuantitative evaluations showed that the model trained with the additional\nLIP-loss was able to significantly outperform the model trained solely based on\nthe IM-loss function.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:40:52 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Shi", "Luyao", ""], ["Onofrey", "John A.", ""], ["Revilla", "Enette Mae", ""], ["Toyonaga", "Takuya", ""], ["Menard", "David", ""], ["Ankrah", "Jo-seph", ""], ["Carson", "Richard E.", ""], ["Liu", "Chi", ""], ["Lu", "Yihuan", ""]]}, {"id": "1909.01401", "submitter": "Pengfei Sun", "authors": "Pengfei Sun and Gopala K. Anumanchipalli and Edward F. Chang", "title": "Brain2Char: A Deep Architecture for Decoding Text from Brain Recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding language representations directly from the brain can enable new\nBrain-Computer Interfaces (BCI) for high bandwidth human-human and\nhuman-machine communication. Clinically, such technologies can restore\ncommunication in people with neurological conditions affecting their ability to\nspeak. In this study, we propose a novel deep network architecture Brain2Char,\nfor directly decoding text (specifically character sequences) from direct brain\nrecordings (called Electrocorticography, ECoG). Brain2Char framework combines\nstate-of-the-art deep learning modules --- 3D Inception layers for multiband\nspatiotemporal feature extraction from neural data and bidirectional recurrent\nlayers, dilated convolution layers followed by language model weighted beam\nsearch to decode character sequences, optimizing a connectionist temporal\nclassification (CTC) loss. Additionally, given the highly non-linear\ntransformations that underlie the conversion of cortical function to character\nsequences, we perform regularizations on the network's latent representations\nmotivated by insights into cortical encoding of speech production and\nartifactual aspects specific to ECoG data acquisition. To do this, we impose\nauxiliary losses on latent representations for articulatory movements, speech\nacoustics and session specific non-linearities. In 3 participants tested here,\nBrain2Char achieves 10.6\\%, 8.5\\% and 7.0\\% Word Error Rates (WER) respectively\non vocabulary sizes ranging from 1200 to 1900 words. Brain2Char also performs\nwell when 2 participants silently mimed sentences. These results set a new\nstate-of-the-art on decoding text from brain and demonstrate the potential of\nBrain2Char as a high-performance communication BCI.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:54:43 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Sun", "Pengfei", ""], ["Anumanchipalli", "Gopala K.", ""], ["Chang", "Edward F.", ""]]}, {"id": "1909.01412", "submitter": "Youshan Zhang", "authors": "Youshan Zhang, Jiarui Xing, Miaomiao Zhang", "title": "Mixture Probabilistic Principal Geodesic Analysis", "comments": "Seventh MICCAI Workshop on Mathematical Foundations of Computational\n  Anatomy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction on Riemannian manifolds is challenging due to the\ncomplex nonlinear data structures. While probabilistic principal geodesic\nanalysis~(PPGA) has been proposed to generalize conventional principal\ncomponent analysis (PCA) onto manifolds, its effectiveness is limited to data\nwith a single modality. In this paper, we present a novel Gaussian latent\nvariable model that provides a unique way to integrate multiple PGA models into\na maximum-likelihood framework. This leads to a well-defined mixture model of\nprobabilistic principal geodesic analysis (MPPGA) on sub-populations, where\nparameters of the principal subspaces are automatically estimated by employing\nan Expectation Maximization algorithm. We further develop a mixture Bayesian\nPGA (MBPGA) model that automatically reduces data dimensionality by suppressing\nirrelevant principal geodesics. We demonstrate the advantages of our model in\nthe contexts of clustering and statistical shape analysis, using synthetic\nsphere data, real corpus callosum, and mandible data from human brain magnetic\nresonance~(MR) and CT images.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 19:22:57 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 08:23:42 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Zhang", "Youshan", ""], ["Xing", "Jiarui", ""], ["Zhang", "Miaomiao", ""]]}, {"id": "1909.01436", "submitter": "Lucas Theis", "authors": "Iryna Korshunova, Hanchen Xiong, Mateusz Fedoryszak, Lucas Theis", "title": "Discriminative Topic Modeling with Logistic LDA", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 32, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite many years of research into latent Dirichlet allocation (LDA),\napplying LDA to collections of non-categorical items is still challenging. Yet\nmany problems with much richer data share a similar structure and could benefit\nfrom the vast literature on LDA. We propose logistic LDA, a novel\ndiscriminative variant of latent Dirichlet allocation which is easy to apply to\narbitrary inputs. In particular, our model can easily be applied to groups of\nimages, arbitrary text embeddings, and integrates well with deep neural\nnetworks. Although it is a discriminative model, we show that logistic LDA can\nlearn from unlabeled data in an unsupervised manner by exploiting the group\nstructure present in the data. In contrast to other recent topic models\ndesigned to handle arbitrary inputs, our model does not sacrifice the\ninterpretability and principled motivation of LDA.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 20:25:49 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 11:12:31 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Korshunova", "Iryna", ""], ["Xiong", "Hanchen", ""], ["Fedoryszak", "Mateusz", ""], ["Theis", "Lucas", ""]]}, {"id": "1909.01440", "submitter": "Rosanne Liu", "authors": "Janice Lan, Rosanne Liu, Hattie Zhou, Jason Yosinski", "title": "LCA: Loss Change Allocation for Neural Network Training", "comments": "NeurIPS 2019 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks enjoy widespread use, but many aspects of their training,\nrepresentation, and operation are poorly understood. In particular, our view\ninto the training process is limited, with a single scalar loss being the most\ncommon viewport into this high-dimensional, dynamic process. We propose a new\nwindow into training called Loss Change Allocation (LCA), in which credit for\nchanges to the network loss is conservatively partitioned to the parameters.\nThis measurement is accomplished by decomposing the components of an\napproximate path integral along the training trajectory using a Runge-Kutta\nintegrator. This rich view shows which parameters are responsible for\ndecreasing or increasing the loss during training, or which parameters \"help\"\nor \"hurt\" the network's learning, respectively. LCA may be summed over training\niterations and/or over neurons, channels, or layers for increasingly coarse\nviews. This new measurement device produces several insights into training. (1)\nWe find that barely over 50% of parameters help during any given iteration. (2)\nSome entire layers hurt overall, moving on average against the training\ngradient, a phenomenon we hypothesize may be due to phase lag in an oscillatory\ntraining process. (3) Finally, increments in learning proceed in a synchronized\nmanner across layers, often peaking on identical iterations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 20:34:05 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 05:46:16 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Lan", "Janice", ""], ["Liu", "Rosanne", ""], ["Zhou", "Hattie", ""], ["Yosinski", "Jason", ""]]}, {"id": "1909.01459", "submitter": "Miriam Hurtado Bodell", "authors": "Miriam Hurtado Bodell, Martin Arvidsson and M{\\aa}ns Magnusson", "title": "Interpretable Word Embeddings via Informative Priors", "comments": "10 pages, 2 figures, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have demonstrated strong performance on NLP tasks. However,\nlack of interpretability and the unsupervised nature of word embeddings have\nlimited their use within computational social science and digital humanities.\nWe propose the use of informative priors to create interpretable and\ndomain-informed dimensions for probabilistic word embeddings. Experimental\nresults show that sensible priors can capture latent semantic concepts better\nthan or on-par with the current state of the art, while retaining the\nsimplicity and generalizability of using priors.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 21:20:28 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Bodell", "Miriam Hurtado", ""], ["Arvidsson", "Martin", ""], ["Magnusson", "M\u00e5ns", ""]]}, {"id": "1909.01463", "submitter": "Qunwei Li", "authors": "Baocheng Geng, Qunwei Li, Pramod K. Varshney", "title": "Prospect Theory Based Crowdsourcing for Classification in the Presence\n  of Spammers", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": "10.1109/TSP.2020.3006754", "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the $M$-ary classification problem via crowdsourcing, where crowd\nworkers respond to simple binary questions and the answers are aggregated via\ndecision fusion. The workers have a reject option to skip answering a question\nwhen they do not have the expertise, or when the confidence of answering that\nquestion correctly is low. We further consider that there are spammers in the\ncrowd who respond to the questions with random guesses. Under the payment\nmechanism that encourages the reject option, we study the behavior of honest\nworkers and spammers, whose objectives are to maximize their monetary rewards.\nTo accurately characterize human behavioral aspects, we employ prospect theory\nto model the rationality of the crowd workers, whose perception of costs and\nprobabilities are distorted based on some value and weight functions,\nrespectively. Moreover, we estimate the number of spammers and employ a\nweighted majority voting decision rule, where we assign an optimal weight for\nevery worker to maximize the system performance. The probability of correct\nclassification and asymptotic system performance are derived. We also provide\nsimulation results to demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 21:25:19 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 13:29:29 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Geng", "Baocheng", ""], ["Li", "Qunwei", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1909.01464", "submitter": "Guang Cheng", "authors": "Xingye Qiao, Jiexin Duan, Guang Cheng", "title": "Rates of Convergence for Large-scale Nearest Neighbor Classification", "comments": "Camera ready version for NeurIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbor is a popular class of classification methods with many\ndesirable properties. For a large data set which cannot be loaded into the\nmemory of a single machine due to computation, communication, privacy, or\nownership limitations, we consider the divide and conquer scheme: the entire\ndata set is divided into small subsamples, on which nearest neighbor\npredictions are made, and then a final decision is reached by aggregating the\npredictions on subsamples by majority voting. We name this method the big\nNearest Neighbor (bigNN) classifier, and provide its rates of convergence under\nminimal assumptions, in terms of both the excess risk and the classification\ninstability, which are proven to be the same rates as the oracle nearest\nneighbor classifier and cannot be improved. To significantly reduce the\nprediction time that is required for achieving the optimal rate, we also\nconsider the pre-training acceleration technique applied to the bigNN method,\nwith proven convergence rate. We find that in the distributed setting, the\noptimal choice of the neighbor $k$ should scale with both the total sample size\nand the number of partitions, and there is a theoretical upper limit for the\nlatter. Numerical studies have verified the theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 21:36:41 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 02:10:29 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Qiao", "Xingye", ""], ["Duan", "Jiexin", ""], ["Cheng", "Guang", ""]]}, {"id": "1909.01486", "submitter": "Samuel Showalter", "authors": "Samuel Showalter, Zhixin Wu", "title": "Minimizing the Societal Cost of Credit Card Fraud with Limited and\n  Imbalanced Data", "comments": "16 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has automated much of financial fraud detection, notifying\nfirms of, or even blocking, questionable transactions instantly. However, data\nimbalance starves traditionally trained models of the content necessary to\ndetect fraud. This study examines three separate factors of credit card fraud\ndetection via machine learning. First, it assesses the potential for different\nsampling methods, undersampling and Synthetic Minority Oversampling Technique\n(SMOTE), to improve algorithm performance in data-starved environments.\nAdditionally, five industry-practical machine learning algorithms are evaluated\non total fraud cost savings in addition to traditional statistical metrics.\nFinally, an ensemble of individual models is trained with a genetic algorithm\nto attempt to generate higher cost efficiency than its components. Monte Carlo\nperformance distributions discerned random undersampling outperformed SMOTE in\nlowering fraud costs, and that an ensemble was unable to outperform its\nindividual parts. Most notably,the F-1 Score, a traditional metric often used\nto measure performance with imbalanced data, was uncorrelated with derived cost\nefficiency. Assuming a realistic cost structure can be derived, cost-based\nmetrics provide an essential supplement to objective statistical evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 22:43:15 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 03:40:10 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Showalter", "Samuel", ""], ["Wu", "Zhixin", ""]]}, {"id": "1909.01492", "submitter": "Po-Sen Huang", "authors": "Po-Sen Huang, Robert Stanforth, Johannes Welbl, Chris Dyer, Dani\n  Yogatama, Sven Gowal, Krishnamurthy Dvijotham, Pushmeet Kohli", "title": "Achieving Verified Robustness to Symbol Substitutions via Interval Bound\n  Propagation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are part of many contemporary NLP systems, yet their\nempirical successes come at the price of vulnerability to adversarial attacks.\nPrevious work has used adversarial training and data augmentation to partially\nmitigate such brittleness, but these are unlikely to find worst-case\nadversaries due to the complexity of the search space arising from discrete\ntext perturbations. In this work, we approach the problem from the opposite\ndirection: to formally verify a system's robustness against a predefined class\nof adversarial attacks. We study text classification under synonym replacements\nor character flip perturbations. We propose modeling these input perturbations\nas a simplex and then using Interval Bound Propagation -- a formal model\nverification method. We modify the conventional log-likelihood training\nobjective to train models that can be efficiently verified, which would\notherwise come with exponential search complexity. The resulting models show\nonly little difference in terms of nominal accuracy, but have much improved\nverified accuracy under perturbations and come with an efficiently computable\nformal guarantee on worst case adversaries.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:03:10 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 18:21:49 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Huang", "Po-Sen", ""], ["Stanforth", "Robert", ""], ["Welbl", "Johannes", ""], ["Dyer", "Chris", ""], ["Yogatama", "Dani", ""], ["Gowal", "Sven", ""], ["Dvijotham", "Krishnamurthy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1909.01496", "submitter": "Zachary Ziegler", "authors": "Zachary M. Ziegler, Yuntian Deng, Alexander M. Rush", "title": "Neural Linguistic Steganography", "comments": "EMNLP 2019 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas traditional cryptography encrypts a secret message into an\nunintelligible form, steganography conceals that communication is taking place\nby encoding a secret message into a cover signal. Language is a particularly\npragmatic cover signal due to its benign occurrence and independence from any\none medium. Traditionally, linguistic steganography systems encode secret\nmessages in existing text via synonym substitution or word order\nrearrangements. Advances in neural language models enable previously\nimpractical generation-based techniques. We propose a steganography technique\nbased on arithmetic coding with large-scale neural language models. We find\nthat our approach can generate realistic looking cover sentences as evaluated\nby humans, while at the same time preserving security by matching the cover\nmessage distribution with the language model distribution.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:15:19 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Ziegler", "Zachary M.", ""], ["Deng", "Yuntian", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1909.01498", "submitter": "Avinash Kori", "authors": "Parth Natekar, Avinash Kori, Ganapathy Krishnamurthi", "title": "Demystifying Brain Tumour Segmentation Networks: Interpretability and\n  Uncertainty Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The accurate automatic segmentation of gliomas and its intra-tumoral\nstructures is important not only for treatment planning but also for follow-up\nevaluations. Several methods based on 2D and 3D Deep Neural Networks (DNN) have\nbeen developed to segment brain tumors and to classify different categories of\ntumors from different MRI modalities. However, these networks are often\nblack-box models and do not provide any evidence regarding the process they\ntake to perform this task. Increasing transparency and interpretability of such\ndeep learning techniques are necessary for the complete integration of such\nmethods into medical practice. In this paper, we explore various techniques to\nexplain the functional organization of brain tumor segmentation models and to\nextract visualizations of internal concepts to understand how these networks\nachieve highly accurate tumor segmentations. We use the BraTS 2018 dataset to\ntrain three different networks with standard architectures and outline\nsimilarities and differences in the process that these networks take to segment\nbrain tumors. We show that brain tumor segmentation networks learn certain\nhuman-understandable disentangled concepts on a filter level. We also show that\nthey take a top-down or hierarchical approach to localizing the different parts\nof the tumor. We then extract visualizations of some internal feature maps and\nalso provide a measure of uncertainty with regards to the outputs of the models\nto give additional qualitative evidence about the predictions of these\nnetworks. We believe that the emergence of such human-understandable\norganization and concepts might aid in the acceptance and integration of such\nmethods in medical diagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:53:11 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 06:29:21 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 03:04:49 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Natekar", "Parth", ""], ["Kori", "Avinash", ""], ["Krishnamurthi", "Ganapathy", ""]]}, {"id": "1909.01500", "submitter": "Adam Stooke", "authors": "Adam Stooke and Pieter Abbeel", "title": "rlpyt: A Research Code Base for Deep Reinforcement Learning in PyTorch", "comments": "v2: Updated learning curves for SAC and TD3, improved by\n  bootstrapping value-function when trajectory ends due to time limit, and\n  switching to newer SAC version, now referenced", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the recent advent of deep reinforcement learning for game play and\nsimulated robotic control, a multitude of new algorithms have flourished. Most\nare model-free algorithms which can be categorized into three families: deep\nQ-learning, policy gradients, and Q-value policy gradients. These have\ndeveloped along separate lines of research, such that few, if any, code bases\nincorporate all three kinds. Yet these algorithms share a great depth of common\ndeep reinforcement learning machinery. We are pleased to share rlpyt, which\nimplements all three algorithm families on top of a shared, optimized\ninfrastructure, in a single repository. It contains modular implementations of\nmany common deep RL algorithms in Python using PyTorch, a leading deep learning\nlibrary. rlpyt is designed as a high-throughput code base for small- to\nmedium-scale research in deep RL. This white paper summarizes its features,\nalgorithms implemented, and relation to prior work, and concludes with detailed\nimplementation and usage notes. rlpyt is available at\nhttps://github.com/astooke/rlpyt.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:57:13 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 06:22:31 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Stooke", "Adam", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1909.01502", "submitter": "Riley Spahn", "authors": "Mathias Lecuyer, Riley Spahn, Kiran Vodrahalli, Roxana Geambasu,\n  Daniel Hsu", "title": "Privacy Accounting and Quality Control in the Sage Differentially\n  Private ML Platform", "comments": "Extended version of a paper presented at the 27th ACM Symposium on\n  Operating Systems Principles (SOSP '19)", "journal-ref": null, "doi": "10.1145/3341301.3359639", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies increasingly expose machine learning (ML) models trained over\nsensitive user data to untrusted domains, such as end-user devices and\nwide-access model stores. We present Sage, a differentially private (DP) ML\nplatform that bounds the cumulative leakage of training data through models.\nSage builds upon the rich literature on DP ML algorithms and contributes\npragmatic solutions to two of the most pressing systems challenges of global\nDP: running out of privacy budget and the privacy-utility tradeoff. To address\nthe former, we develop block composition, a new privacy loss accounting method\nthat leverages the growing database regime of ML workloads to keep training\nmodels endlessly on a sensitive data stream while enforcing a global DP\nguarantee for the stream. To address the latter, we develop privacy-adaptive\ntraining, a process that trains a model on growing amounts of data and/or with\nincreasing privacy parameters until, with high probability, the model meets\ndeveloper-configured quality criteria. They illustrate how a systems focus on\ncharacteristics of ML workloads enables pragmatic solutions that are not\napparent when one focuses on individual algorithms, as most DP ML literature\ndoes.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 00:23:21 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 18:25:27 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Lecuyer", "Mathias", ""], ["Spahn", "Riley", ""], ["Vodrahalli", "Kiran", ""], ["Geambasu", "Roxana", ""], ["Hsu", "Daniel", ""]]}, {"id": "1909.01504", "submitter": "Arun Verma Mr.", "authors": "Arun Verma, Manjesh K. Hanawal, Arun Rajkumar, Raman Sankaran", "title": "Censored Semi-Bandits: A Framework for Resource Allocation with Censored\n  Feedback", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study censored Semi-Bandits, a novel variant of the\nsemi-bandits problem. The learner is assumed to have a fixed amount of\nresources, which it allocates to the arms at each time step. The loss observed\nfrom an arm is random and depends on the amount of resources allocated to it.\nMore specifically, the loss equals zero if the allocation for the arm exceeds a\nconstant (but unknown)threshold that can be dependent on the arm. Our goal is\nto learn a feasible allocation that minimizes the expected loss. The problem is\nchallenging because the loss distribution and threshold value of each arm are\nunknown. We study this novel setting by establishing its `equivalence' to\nMultiple-Play Multi-Armed Bandits(MP-MAB) and Combinatorial Semi-Bandits.\nExploiting these equivalences, we derive optimal algorithms for our setting\nusing existing algorithms for MP-MABand Combinatorial Semi-Bandits. Experiments\non synthetically generated data validate performance guarantees of the proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 00:25:31 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 23:54:18 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 07:56:28 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""], ["Rajkumar", "Arun", ""], ["Sankaran", "Raman", ""]]}, {"id": "1909.01505", "submitter": "Aritra Mitra", "authors": "Aritra Mitra, John A. Richards and Shreyas Sundaram", "title": "A Communication-Efficient Algorithm for Exponentially Fast Non-Bayesian\n  Learning in Networks", "comments": "To appear in the Proceedings of the Decision and Control Conference\n  (CDC), 2019, to be held in Nice, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.IT cs.LG cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple time-triggered protocol to achieve\ncommunication-efficient non-Bayesian learning over a network. Specifically, we\nconsider a scenario where a group of agents interact over a graph with the aim\nof discerning the true state of the world that generates their joint\nobservation profiles. To address this problem, we propose a novel distributed\nlearning rule wherein agents aggregate neighboring beliefs based on a\nmin-protocol, and the inter-communication intervals grow geometrically at a\nrate $a \\geq 1$. Despite such sparse communication, we show that each agent is\nstill able to rule out every false hypothesis exponentially fast with\nprobability $1$, as long as $a$ is finite. For the special case when\ncommunication occurs at every time-step, i.e., when $a=1$, we prove that the\nasymptotic learning rates resulting from our algorithm are network-structure\nindependent, and a strict improvement upon those existing in the literature. In\ncontrast, when $a>1$, our analysis reveals that the asymptotic learning rates\nvary across agents, and exhibit a non-trivial dependence on the network\ntopology coupled with the relative entropies of the agents' likelihood models.\nThis motivates us to consider the problem of allocating signal structures to\nagents to maximize appropriate performance metrics. In certain special cases,\nwe show that the eccentricity centrality and the decay centrality of the\nunderlying graph help identify optimal allocations; for more general scenarios,\nwe bound the deviation from the optimal allocation as a function of the\nparameter $a$, and the diameter of the communication graph.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 00:29:44 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Mitra", "Aritra", ""], ["Richards", "John A.", ""], ["Sundaram", "Shreyas", ""]]}, {"id": "1909.01506", "submitter": "Yinlam Chow", "authors": "Nir Levine and Yinlam Chow and Rui Shu and Ang Li and Mohammad\n  Ghavamzadeh and Hung Bui", "title": "Prediction, Consistency, Curvature: Representation Learning for\n  Locally-Linear Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world sequential decision-making problems can be formulated as\noptimal control with high-dimensional observations and unknown dynamics. A\npromising approach is to embed the high-dimensional observations into a\nlower-dimensional latent representation space, estimate the latent dynamics\nmodel, then utilize this model for control in the latent space. An important\nopen question is how to learn a representation that is amenable to existing\ncontrol algorithms? In this paper, we focus on learning representations for\nlocally-linear control algorithms, such as iterative LQR (iLQR). By formulating\nand analyzing the representation learning problem from an optimal control\nperspective, we establish three underlying principles that the learned\nrepresentation should comprise: 1) accurate prediction in the observation\nspace, 2) consistency between latent and observation space dynamics, and 3) low\ncurvature in the latent space transitions. These principles naturally\ncorrespond to a loss function that consists of three terms: prediction,\nconsistency, and curvature (PCC). Crucially, to make PCC tractable, we derive\nan amortized variational bound for the PCC loss function. Extensive experiments\non benchmark domains demonstrate that the new variational-PCC learning\nalgorithm benefits from significantly more stable and reproducible training,\nand leads to superior control performance. Further ablation studies give\nsupport to the importance of all three PCC components for learning a good\nlatent space for control.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 00:34:27 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 21:35:48 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Levine", "Nir", ""], ["Chow", "Yinlam", ""], ["Shu", "Rui", ""], ["Li", "Ang", ""], ["Ghavamzadeh", "Mohammad", ""], ["Bui", "Hung", ""]]}, {"id": "1909.01519", "submitter": "Mahammad Humayoo", "authors": "Mahammad Humayoo and Xueqi Cheng", "title": "Parameter Estimation with the Ordered $\\ell_{2}$ Regularization via an\n  Alternating Direction Method of Multipliers", "comments": null, "journal-ref": "Applied Sciences (ISSN 2076-3417; CODEN: ASPCC7)", "doi": "10.3390/app9204291", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is a popular technique in machine learning for model\nestimation and avoiding overfitting. Prior studies have found that modern\nordered regularization can be more effective in handling highly correlated,\nhigh-dimensional data than traditional regularization. The reason stems from\nthe fact that the ordered regularization can reject irrelevant variables and\nyield an accurate estimation of the parameters. How to scale up the ordered\nregularization problems when facing the large-scale training data remains an\nunanswered question. This paper explores the problem of parameter estimation\nwith the ordered $\\ell_{2}$-regularization via Alternating Direction Method of\nMultipliers (ADMM), called ADMM-O$\\ell_{2}$. The advantages of ADMM-O$\\ell_{2}$\ninclude (i) scaling up the ordered $\\ell_{2}$ to a large-scale dataset, (ii)\npredicting parameters correctly by excluding irrelevant variables\nautomatically, and (iii) having a fast convergence rate. Experiment results on\nboth synthetic data and real data indicate that ADMM-O$\\ell_{2}$ can perform\nbetter than or comparable to several state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 01:58:08 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 01:15:52 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 08:33:34 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Humayoo", "Mahammad", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1909.01520", "submitter": "Tyler Hayes", "authors": "Tyler L. Hayes and Christopher Kanan", "title": "Lifelong Machine Learning with Deep Streaming Linear Discriminant\n  Analysis", "comments": "To appear in the IEEE Conference on Computer Vision and Pattern\n  Recognition Workshop (CVPR-W) on Continual Learning in Computer Vision\n  (CLVision) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When an agent acquires new information, ideally it would immediately be\ncapable of using that information to understand its environment. This is not\npossible using conventional deep neural networks, which suffer from\ncatastrophic forgetting when they are incrementally updated, with new knowledge\noverwriting established representations. A variety of approaches have been\ndeveloped that attempt to mitigate catastrophic forgetting in the incremental\nbatch learning scenario, where a model learns from a series of large\ncollections of labeled samples. However, in this setting, inference is only\npossible after a batch has been accumulated, which prohibits many applications.\nAn alternative paradigm is online learning in a single pass through the\ntraining dataset on a resource constrained budget, which is known as streaming\nlearning. Streaming learning has been much less studied in the deep learning\ncommunity. In streaming learning, an agent learns instances one-by-one and can\nbe tested at any time, rather than only after learning a large batch. Here, we\nrevisit streaming linear discriminant analysis, which has been widely used in\nthe data mining research community. By combining streaming linear discriminant\nanalysis with deep learning, we are able to outperform both incremental batch\nlearning and streaming learning algorithms on both ImageNet ILSVRC-2012 and\nCORe50, a dataset that involves learning to classify from temporally ordered\nsamples.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 02:13:22 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 17:17:47 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 16:28:51 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Hayes", "Tyler L.", ""], ["Kanan", "Christopher", ""]]}, {"id": "1909.01525", "submitter": "Chenwei Ding", "authors": "Chenwei Ding, Mingming Gong, Kun Zhang, Dacheng Tao", "title": "Likelihood-Free Overcomplete ICA and Applications in Causal Discovery", "comments": "10 pages, 3 figures. Accepted by NeurIPS 2019 as spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery witnessed significant progress over the past decades. In\nparticular, many recent causal discovery methods make use of independent,\nnon-Gaussian noise to achieve identifiability of the causal models. Existence\nof hidden direct common causes, or confounders, generally makes causal\ndiscovery more difficult; whenever they are present, the corresponding causal\ndiscovery algorithms can be seen as extensions of overcomplete independent\ncomponent analysis (OICA). However, existing OICA algorithms usually make\nstrong parametric assumptions on the distribution of independent components,\nwhich may be violated on real data, leading to sub-optimal or even wrong\nsolutions. In addition, existing OICA algorithms rely on the Expectation\nMaximization (EM) procedure that requires computationally expensive inference\nof the posterior distribution of independent components. To tackle these\nproblems, we present a Likelihood-Free Overcomplete ICA algorithm (LFOICA) that\nestimates the mixing matrix directly by back-propagation without any explicit\nassumptions on the density function of independent components. Thanks to its\ncomputational efficiency, the proposed method makes a number of causal\ndiscovery procedures much more practically feasible. For illustrative purposes,\nwe demonstrate the computational efficiency and efficacy of our method in two\ncausal discovery tasks on both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 02:27:50 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 06:30:37 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Ding", "Chenwei", ""], ["Gong", "Mingming", ""], ["Zhang", "Kun", ""], ["Tao", "Dacheng", ""]]}, {"id": "1909.01528", "submitter": "Meng Cao", "authors": "Meng Cao, Jackie Chi Kit Cheung", "title": "Referring Expression Generation Using Entity Profiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Referring Expression Generation (REG) is the task of generating contextually\nappropriate references to entities. A limitation of existing REG systems is\nthat they rely on entity-specific supervised training, which means that they\ncannot handle entities not seen during training. In this study, we address this\nin two ways. First, we propose task setups in which we specifically test a REG\nsystem's ability to generalize to entities not seen during training. Second, we\npropose a profile-based deep neural network model, ProfileREG, which encodes\nboth the local context and an external profile of the entity to generate\nreference realizations. Our model generates tokens by learning to choose\nbetween generating pronouns, generating from a fixed vocabulary, or copying a\nword from the profile. We evaluate our model on three different splits of the\nWebNLG dataset, and show that it outperforms competitive baselines in all\nsettings according to automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 02:42:07 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Cao", "Meng", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1909.01532", "submitter": "Xin Zhong", "authors": "Yucong Shen, Xin Zhong, Frank Y. Shih", "title": "Deep Morphological Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical morphology is a theory and technique to collect features like\ngeometric and topological structures in digital images. Given a target image,\ndetermining suitable morphological operations and structuring elements is a\ncumbersome and time-consuming task. In this paper, a morphological neural\nnetwork is proposed to address this problem. Serving as a nonlinear feature\nextracting layer in deep learning frameworks, the efficiency of the proposed\nmorphological layer is confirmed analytically and empirically. With a known\ntarget, a single-filter morphological layer learns the structuring element\ncorrectly, and an adaptive layer can automatically select appropriate\nmorphological operations. For practical applications, the proposed\nmorphological neural networks are tested on several classification datasets\nrelated to shape or geometric image features, and the experimental results have\nconfirmed the high computational efficiency and high accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:03:20 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Shen", "Yucong", ""], ["Zhong", "Xin", ""], ["Shih", "Frank Y.", ""]]}, {"id": "1909.01539", "submitter": "Yang Li", "authors": "Yang Li and Thomas Strohmer", "title": "What Happens on the Edge, Stays on the Edge: Toward Compressive Deep\n  Learning", "comments": "14 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning at the edge offers great benefits such as increased privacy\nand security, low latency, and more autonomy. However, a major challenge is\nthat many devices, in particular edge devices, have very limited memory, weak\nprocessors, and scarce energy supply. We propose a hybrid hardware-software\nframework that has the potential to significantly reduce the computational\ncomplexity and memory requirements of on-device machine learning. In the first\nstep, inspired by compressive sensing, data is collected in compressed form\nsimultaneously with the sensing process. Thus this compression happens already\nat the hardware level during data acquisition. But unlike in compressive\nsensing, this compression is achieved via a projection operator that is\nspecifically tailored to the desired machine learning task. The second step\nconsists of a specially designed and trained deep network. As concrete example\nwe consider the task of image classification, although the proposed framework\nis more widely applicable. An additional benefit of our approach is that it can\nbe easily combined with existing on-device techniques. Numerical simulations\nillustrate the viability of our method.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:29:23 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Li", "Yang", ""], ["Strohmer", "Thomas", ""]]}, {"id": "1909.01541", "submitter": "Quanyu Dai", "authors": "Quanyu Dai, Xiao Shen, Xiao-Ming Wu and Dan Wang", "title": "Network Transfer Learning via Adversarial Domain Adaptation with Graph\n  Convolution", "comments": "Submitted to IEEE Transactions on Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of cross-network node classification to\novercome the insufficiency of labeled data in a single network. It aims to\nleverage the label information in a partially labeled source network to assist\nnode classification in a completely unlabeled or partially labeled target\nnetwork. Existing methods for single network learning cannot solve this problem\ndue to the domain shift across networks. Some multi-network learning methods\nheavily rely on the existence of cross-network connections, thus are\ninapplicable for this problem. To tackle this problem, we propose a novel\nnetwork transfer learning framework AdaGCN by leveraging the techniques of\nadversarial domain adaptation and graph convolution. It consists of two\ncomponents: a semi-supervised learning component and an adversarial domain\nadaptation component. The former aims to learn class discriminative node\nrepresentations with given label information of the source and target networks,\nwhile the latter contributes to mitigating the distribution divergence between\nthe source and target domains to facilitate knowledge transfer. Extensive\nempirical evaluations on real-world datasets show that AdaGCN can successfully\ntransfer class information with a low label rate on the source network and a\nsubstantial divergence between the source and target domains. Codes will be\nreleased upon acceptance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:33:10 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Dai", "Quanyu", ""], ["Shen", "Xiao", ""], ["Wu", "Xiao-Ming", ""], ["Wang", "Dan", ""]]}, {"id": "1909.01542", "submitter": "Yang Li", "authors": "Yang Li, Jianhe Yuan, Zhiqun Zhao, Hao Sun, Zhihai He", "title": "Snowball: Iterative Model Evolution and Confident Sample Discovery for\n  Semi-Supervised Learning on Very Small Labeled Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a joint sample discovery and iterative model\nevolution method for semi-supervised learning on very small labeled training\nsets. We propose a master-teacher-student model framework to provide\nmulti-layer guidance during the model evolution process with multiple\niterations and generations. The teacher model is constructed by performing an\nexponential moving average of the student models obtained from past training\nsteps. The master network combines the knowledge of the student and teacher\nmodels with additional access to newly discovered samples. The master and\nteacher models are then used to guide the training of the student network by\nenforcing the consistence between their predictions of unlabeled samples and\nevolve all models when more and more samples are discovered. Our extensive\nexperiments demonstrate that the discovering confident samples from the\nunlabeled dataset, once coupled with the above master-teacher-student network\nevolution, can significantly improve the overall semi-supervised learning\nperformance. For example, on the CIFAR-10 dataset, with a very small set of 250\nlabeled samples, our method achieves an error rate of 11.81 %, more than 38 %\nlower than the state-of-the-art method Mean-Teacher (49.91 %).\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:41:27 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Li", "Yang", ""], ["Yuan", "Jianhe", ""], ["Zhao", "Zhiqun", ""], ["Sun", "Hao", ""], ["He", "Zhihai", ""]]}, {"id": "1909.01543", "submitter": "Rui Hou", "authors": "Rui Hou, Ver\\'onica P\\'erez-Rosas, Stacy Loeb, Rada Mihalcea", "title": "Towards Automatic Detection of Misinformation in Online Medical Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a significant increase in the online sharing of\nmedical information, with videos representing a large fraction of such online\nsources. Previous studies have however shown that more than half of the\nhealth-related videos on platforms such as YouTube contain misleading\ninformation and biases. Hence, it is crucial to build computational tools that\ncan help evaluate the quality of these videos so that users can obtain accurate\ninformation to help inform their decisions. In this study, we focus on the\nautomatic detection of misinformation in YouTube videos. We select prostate\ncancer videos as our entry point to tackle this problem. The contribution of\nthis paper is twofold. First, we introduce a new dataset consisting of 250\nvideos related to prostate cancer manually annotated for misinformation.\nSecond, we explore the use of linguistic, acoustic, and user engagement\nfeatures for the development of classification models to identify\nmisinformation. Using a series of ablation experiments, we show that we can\nbuild automatic models with accuracies of up to 74%, corresponding to a 76.5%\nprecision and 73.2% recall for misinformative instances.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:41:44 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Hou", "Rui", ""], ["P\u00e9rez-Rosas", "Ver\u00f3nica", ""], ["Loeb", "Stacy", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1909.01544", "submitter": "Trung V. Phan", "authors": "Trung V. Phan, Syed Tasnimul Islam, Tri Gia Nguyen and Thomas\n  Bauschert", "title": "Q-DATA: Enhanced Traffic Flow Monitoring in Software-Defined Networks\n  applying Q-learning", "comments": "This paper has been ACCEPTED in IEEE CNSM conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-Defined Networking (SDN) introduces a centralized network control\nand management by separating the data plane from the control plane which\nfacilitates traffic flow monitoring, security analysis and policy formulation.\nHowever, it is challenging to choose a proper degree of traffic flow handling\ngranularity while proactively protecting forwarding devices from getting\noverloaded. In this paper, we propose a novel traffic flow matching control\nframework called Q-DATA that applies reinforcement learning in order to enhance\nthe traffic flow monitoring performance in SDN based networks and prevent\ntraffic forwarding performance degradation. We first describe and analyse an\nSDN-based traffic flow matching control system that applies a reinforcement\nlearning approach based on Q-learning algorithm in order to maximize the\ntraffic flow granularity. It also considers the forwarding performance status\nof the SDN switches derived from a Support Vector Machine based algorithm.\nNext, we outline the Q-DATA framework that incorporates the optimal traffic\nflow matching policy derived from the traffic flow matching control system to\nefficiently provide the most detailed traffic flow information that other\nmechanisms require. Our novel approach is realized as a REST SDN application\nand evaluated in an SDN environment. Through comprehensive experiments, the\nresults show that---compared to the default behavior of common SDN controllers\nand to our previous DATA mechanism---the new Q-DATA framework yields a\nremarkable improvement in terms of traffic forwarding performance degradation\nprotection of SDN switches while still providing the most detailed traffic flow\ninformation on demand.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:42:54 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Phan", "Trung V.", ""], ["Islam", "Syed Tasnimul", ""], ["Nguyen", "Tri Gia", ""], ["Bauschert", "Thomas", ""]]}, {"id": "1909.01571", "submitter": "JaeSung Choi", "authors": "Jaesung Choi and Pilwon Kim", "title": "Reservoir Computing based on Quenched Chaos", "comments": null, "journal-ref": null, "doi": "10.1016/j.chaos.2020.110131", "report-no": null, "categories": "nlin.CD cs.CC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing(RC) is a brain-inspired computing framework that employs\na transient dynamical system whose reaction to an input signal is transformed\nto a target output. One of the central problems in RC is to find a reliable\nreservoir with a large criticality, since computing performance of a reservoir\nis maximized near the phase transition. In this work, we propose a continuous\nreservoir that utilizes transient dynamics of coupled chaotic oscillators in a\ncritical regime where sudden amplitude death occurs. This \"explosive death\" not\nonly brings the system a large criticality which provides a variety of orbits\nfor computing, but also stabilizes them which otherwise diverge soon in chaotic\nunits. The proposed framework shows better results in tasks for signal\nreconstructions than RC based on explosive synchronization of regular phase\noscillators. We also show that the information capacity of the reservoirs can\nbe used as a predictive measure for computational capability of a reservoir at\na critical point.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 06:46:20 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Choi", "Jaesung", ""], ["Kim", "Pilwon", ""]]}, {"id": "1909.01575", "submitter": "Jacob Rafati", "authors": "Jacob Rafati and David C. Noelle", "title": "Learning sparse representations in reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms allow artificial agents to improve\ntheir selection of actions to increase rewarding experiences in their\nenvironments. Temporal Difference (TD) Learning -- a model-free RL method -- is\na leading account of the midbrain dopamine system and the basal ganglia in\nreinforcement learning. These algorithms typically learn a mapping from the\nagent's current sensed state to a selected action (known as a policy function)\nvia learning a value function (expected future rewards). TD Learning methods\nhave been very successful on a broad range of control tasks, but learning can\nbecome intractably slow as the state space of the environment grows. This has\nmotivated methods that learn internal representations of the agent's state,\neffectively reducing the size of the state space and restructuring state\nrepresentations in order to support generalization. However, TD Learning\ncoupled with an artificial neural network, as a function approximator, has been\nshown to fail to learn some fairly simple control tasks, challenging this\nexplanation of reward-based learning. We hypothesize that such failures do not\narise in the brain because of the ubiquitous presence of lateral inhibition in\nthe cortex, producing sparse distributed internal representations that support\nthe learning of expected future reward. The sparse conjunctive representations\ncan avoid catastrophic interference while still supporting generalization. We\nprovide support for this conjecture through computational simulations,\ndemonstrating the benefits of learned sparse representations for three\nproblematic classic control tasks: Puddle-world, Mountain-car, and Acrobot.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 06:58:32 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Rafati", "Jacob", ""], ["Noelle", "David C.", ""]]}, {"id": "1909.01576", "submitter": "Akihiro Yabe", "authors": "Akihiro Yabe and Takanori Maehara", "title": "Empirical Hypothesis Space Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting appropriate regularization coefficients is critical to performance\nwith respect to regularized empirical risk minimization problems. Existing\ntheoretical approaches attempt to determine the coefficients in order for\nregularized empirical objectives to be upper-bounds of true objectives,\nuniformly over a hypothesis space. Such an approach is, however, known to be\nover-conservative, especially in high-dimensional settings with large\nhypothesis space. In fact, an existing generalization error bound in\nvariance-based regularization is $O(\\sqrt{d \\log n/n})$, where $d$ is the\ndimension of hypothesis space, and thus the number of samples required for\nconvergence linearly increases with respect to $d$. This paper proposes an\nalgorithm that calculates regularization coefficient, one which results in\nfaster convergence of generalization error $O(\\sqrt{\\log n/n})$ and whose\nleading term is independent of the dimension $d$. This faster convergence\nwithout dependence on the size of the hypothesis space is achieved by means of\nempirical hypothesis space reduction, which, with high probability,\nsuccessfully reduces a hypothesis space without losing the true optimum\nsolution. Calculation of uniform upper bounds over reduced spaces, then,\nenables acceleration of the convergence of generalization error.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 07:00:26 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Yabe", "Akihiro", ""], ["Maehara", "Takanori", ""]]}, {"id": "1909.01590", "submitter": "Xiaoqing Sun", "authors": "Xiaoqing Sun, Mingkai Tong, Jiahai Yang", "title": "HinDom: A Robust Malicious Domain Detection System based on\n  Heterogeneous Information Network with Transductive Classification", "comments": "RAID2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain name system (DNS) is a crucial part of the Internet, yet has been\nwidely exploited by cyber attackers. Apart from making static methods like\nblacklists or sinkholes infeasible, some weasel attackers can even bypass\ndetection systems with machine learning based classifiers. As a solution to\nthis problem, we propose a robust domain detection system named HinDom. Instead\nof relying on manually selected features, HinDom models the DNS scene as a\nHeterogeneous Information Network (HIN) consist of clients, domains, IP\naddresses and their diverse relationships. Besides, the metapath-based\ntransductive classification method enables HinDom to detect malicious domains\nwith only a small fraction of labeled samples. So far as we know, this is the\nfirst work to apply HIN in DNS analysis. We build a prototype of HinDom and\nevaluate it in CERNET2 and TUNET. The results reveal that HinDom is accurate,\nrobust and can identify previously unknown malicious domains.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 07:30:54 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Sun", "Xiaoqing", ""], ["Tong", "Mingkai", ""], ["Yang", "Jiahai", ""]]}, {"id": "1909.01601", "submitter": "Noemi Mauro", "authors": "Liliana Ardissono and Noemi Mauro", "title": "A Compositional Model of Multi-faceted Trust for Personalized Item\n  Recommendation", "comments": null, "journal-ref": "Expert Systems with Applications, Volume 140, 2020. ISSN 0957-4174", "doi": "10.1016/j.eswa.2019.112880", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Trust-based recommender systems improve rating prediction with respect to\nCollaborative Filtering by leveraging the additional information provided by a\ntrust network among users to deal with the cold start problem. However, they\nare challenged by recent studies according to which people generally perceive\nthe usage of data about social relations as a violation of their own privacy.\nIn order to address this issue, we extend trust-based recommender systems with\nadditional evidence about trust, based on public anonymous information, and we\nmake them configurable with respect to the data that can be used in the given\napplication domain: 1 - We propose the Multi-faceted Trust Model (MTM) to\ndefine trust among users in a compositional way, possibly including or\nexcluding the types of information it contains. MTM flexibly integrates social\nlinks with public anonymous feedback received by user profiles and user\ncontributions in social networks. 2 - We propose LOCABAL+, based on MTM, which\nextends the LOCABAL trust-based recommender system with multi-faceted trust and\ntrust-based social regularization. Experiments carried out on two public\ndatasets of item reviews show that, with a minor loss of user coverage,\nLOCABAL+ outperforms state-of-the art trust-based recommender systems and\nCollaborative Filtering in accuracy, ranking of items and error minimization\nboth when it uses complete information about trust and when it ignores social\nrelations. The combination of MTM with LOCABAL+ thus represents a promising\nalternative to state-of-the-art trust-based recommender systems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 07:56:04 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Ardissono", "Liliana", ""], ["Mauro", "Noemi", ""]]}, {"id": "1909.01606", "submitter": "Hong Xu", "authors": "Alex Bozarth and Brendan Dwyer and Fei Hu and Daniel Jalova and\n  Karthik Muthuraman and Nick Pentreath and Simon Plovyt and Gabriela de\n  Queiroz and Saishruthi Swaminathan and Patrick Titzler and Xin Wu and Hong Xu\n  and Frederick R Reiss and Vijay Bommireddipalli", "title": "Model Asset eXchange: Path to Ubiquitous Deep Learning Deployment", "comments": "4 pages, 3 figures. Demo paper", "journal-ref": "Alex Bozarth et al. 2019. Model Asset eXchange: Path to Ubiquitous\n  Deep Learning Deployment. In The 28th ACM International Conference on\n  Information and Knowledge Management (CIKM '19)", "doi": "10.1145/3357384.3357860", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent trend observed in traditionally challenging fields such as computer\nvision and natural language processing has been the significant performance\ngains shown by deep learning (DL). In many different research fields, DL models\nhave been evolving rapidly and become ubiquitous. Despite researchers'\nexcitement, unfortunately, most software developers are not DL experts and\noftentimes have a difficult time following the booming DL research outputs. As\na result, it usually takes a significant amount of time for the latest superior\nDL models to prevail in industry. This issue is further exacerbated by the\ncommon use of sundry incompatible DL programming frameworks, such as\nTensorflow, PyTorch, Theano, etc. To address this issue, we propose a system,\ncalled Model Asset Exchange (MAX), that avails developers of easy access to\nstate-of-the-art DL models. Regardless of the underlying DL programming\nframeworks, it provides an open source Python library (called the MAX\nframework) that wraps DL models and unifies programming interfaces with our\nstandardized RESTful APIs. These RESTful APIs enable developers to exploit the\nwrapped DL models for inference tasks without the need to fully understand\ndifferent DL programming frameworks. Using MAX, we have wrapped and\nopen-sourced more than 30 state-of-the-art DL models from various research\nfields, including computer vision, natural language processing and signal\nprocessing, etc. In the end, we selectively demonstrate two web applications\nthat are built on top of MAX, as well as the process of adding a DL model to\nMAX.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 08:05:03 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Bozarth", "Alex", ""], ["Dwyer", "Brendan", ""], ["Hu", "Fei", ""], ["Jalova", "Daniel", ""], ["Muthuraman", "Karthik", ""], ["Pentreath", "Nick", ""], ["Plovyt", "Simon", ""], ["de Queiroz", "Gabriela", ""], ["Swaminathan", "Saishruthi", ""], ["Titzler", "Patrick", ""], ["Wu", "Xin", ""], ["Xu", "Hong", ""], ["Reiss", "Frederick R", ""], ["Bommireddipalli", "Vijay", ""]]}, {"id": "1909.01614", "submitter": "Siddharth Ramchandran", "authors": "Siddharth Ramchandran, Miika Koskinen and Harri L\\\"ahdesm\\\"aki", "title": "Latent Gaussian process with composite likelihoods and numerical\n  quadrature", "comments": null, "journal-ref": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS-2021), pp. 3718-3726. PMLR, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clinical patient records are an example of high-dimensional data that is\ntypically collected from disparate sources and comprises of multiple\nlikelihoods with noisy as well as missing values. In this work, we propose an\nunsupervised generative model that can learn a low-dimensional representation\namong the observations in a latent space, while making use of all available\ndata in a heterogeneous data setting with missing values. We improve upon the\nexisting Gaussian process latent variable model (GPLVM) by incorporating\nmultiple likelihoods and deep neural network parameterised back-constraints to\ncreate a non-linear dimensionality reduction technique for heterogeneous data.\nIn addition, we develop a variational inference method for our model that uses\nnumerical quadrature. We establish the effectiveness of our model and compare\nagainst existing GPLVM methods on a standard benchmark dataset as well as on\nclinical data of Parkinson's disease patients treated at the HUS Helsinki\nUniversity Hospital.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 08:30:22 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 11:12:01 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 18:32:04 GMT"}, {"version": "v4", "created": "Tue, 20 Apr 2021 14:57:11 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ramchandran", "Siddharth", ""], ["Koskinen", "Miika", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""]]}, {"id": "1909.01640", "submitter": "Ramtine Tofighi-Shirazi", "authors": "Ramtine Tofighi-Shirazi (TL, IF), Irina As\\u{a}voae (TL), Philippe\n  Elbaz-Vincent (IF), Thanh-Ha Le (TL)", "title": "Defeating Opaque Predicates Statically through Machine Learning and\n  Binary Analysis", "comments": null, "journal-ref": "3rd International Workshop on Software PROtection, Nov 2019,\n  London, United Kingdom", "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach that bridges binary analysis techniques with\nmachine learning classification for the purpose of providing a static and\ngeneric evaluation technique for opaque predicates, regardless of their\nconstructions. We use this technique as a static automated deobfuscation tool\nto remove the opaque predicates introduced by obfuscation mechanisms. According\nto our experimental results, our models have up to 98% accuracy at detecting\nand deob-fuscating state-of-the-art opaque predicates patterns. By contrast,\nthe leading edge deobfuscation methods based on symbolic execution show less\naccuracy mostly due to the SMT solvers constraints and the lack of scalability\nof dynamic symbolic analyses. Our approach underlines the efficiency of hybrid\nsymbolic analysis and machine learning techniques for a static and generic\ndeobfuscation methodology.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:19:14 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Tofighi-Shirazi", "Ramtine", "", "TL, IF"], ["As\u0103voae", "Irina", "", "TL"], ["Elbaz-Vincent", "Philippe", "", "IF"], ["Le", "Thanh-Ha", "", "TL"]]}, {"id": "1909.01646", "submitter": "Leonard Adolphs", "authors": "Leonard Adolphs and Thomas Hofmann", "title": "LeDeepChef: Deep Reinforcement Learning Agent for Families of Text-Based\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Reinforcement Learning (RL) approaches lead to significant achievements\nin a variety of areas in recent history, natural language tasks remained mostly\nunaffected, due to the compositional and combinatorial nature that makes them\nnotoriously hard to optimize. With the emerging field of Text-Based Games\n(TBGs), researchers try to bridge this gap. Inspired by the success of RL\nalgorithms on Atari games, the idea is to develop new methods in a restricted\ngame world and then gradually move to more complex environments. Previous work\nin the area of TBGs has mainly focused on solving individual games. We,\nhowever, consider the task of designing an agent that not just succeeds in a\nsingle game, but performs well across a whole family of games, sharing the same\ntheme. In this work, we present our deep RL agent--LeDeepChef--that shows\ngeneralization capabilities to never-before-seen games of the same family with\ndifferent environments and task descriptions. The agent participated in\nMicrosoft Research's \"First TextWorld Problems: A Language and Reinforcement\nLearning Challenge\" and outperformed all but one competitor on the final test\nset. The games from the challenge all share the same theme, namely cooking in a\nmodern house environment, but differ significantly in the arrangement of the\nrooms, the presented objects, and the specific goal (recipe to cook). To build\nan agent that achieves high scores across a whole family of games, we use an\nactor-critic framework and prune the action-space by using ideas from\nhierarchical reinforcement learning and a specialized module trained on a\nrecipe database.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:30:55 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Adolphs", "Leonard", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1909.01651", "submitter": "Leo Gautheron", "authors": "L\\'eo Gautheron (LHC), Emilie Morvant (LHC), Amaury Habrard (LHC),\n  Marc Sebban (LHC)", "title": "Metric Learning from Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key element of any machine learning algorithm is the use of a function that\nmeasures the dis/similarity between data points. Given a task, such a function\ncan be optimized with a metric learning algorithm. Although this research field\nhas received a lot of attention during the past decade, very few approaches\nhave focused on learning a metric in an imbalanced scenario where the number of\npositive examples is much smaller than the negatives. Here, we address this\nchallenging task by designing a new Mahalanobis metric learning algorithm (IML)\nwhich deals with class imbalance. The empirical study performed shows the\nefficiency of IML.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:38:58 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Gautheron", "L\u00e9o", "", "LHC"], ["Morvant", "Emilie", "", "LHC"], ["Habrard", "Amaury", "", "LHC"], ["Sebban", "Marc", "", "LHC"]]}, {"id": "1909.01683", "submitter": "Kyungchun Lee Prof.", "authors": "NhanThanh Nguyen and Kyungchun Lee", "title": "Deep Learning-Aided Tabu Search Detection for Large MIMO Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we consider the application of deep learning (DL) to tabu\nsearch (TS) detection in large multiple-input multiple-output (MIMO) systems.\nFirst, we propose a deep neural network architecture for symbol detection,\ntermed the fast-convergence sparsely connected detection network (FS-Net),\nwhich is obtained by optimizing the prior detection networks called DetNet and\nScNet. Then, we propose the DL-aided TS algorithm, in which the initial\nsolution is approximated by the proposed FS-Net. Furthermore, in this\nalgorithm, an adaptive early termination algorithm and a modified searching\nprocess are performed based on the predicted approximation error, which is\ndetermined from the FS-Net-based initial solution, so that the optimal solution\ncan be reached earlier. The simulation results show that the proposed algorithm\nachieves approximately 90% complexity reduction for a $32 \\times 32$ MIMO\nsystem with QPSK with respect to the existing TS algorithms, while maintaining\nalmost the same performance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 10:35:00 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Nguyen", "NhanThanh", ""], ["Lee", "Kyungchun", ""]]}, {"id": "1909.01688", "submitter": "Sungho Shin", "authors": "Sungho Shin, Yoonho Boo, Wonyong Sung", "title": "Knowledge distillation for optimization of quantized deep neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a very popular method for model size\nreduction. Recently, the technique is exploited for quantized deep neural\nnetworks (QDNNs) training as a way to restore the performance sacrificed by\nword-length reduction. KD, however, employs additional hyper-parameters, such\nas temperature, coefficient, and the size of teacher network for QDNN training.\nWe analyze the effect of these hyper-parameters for QDNN optimization with KD.\nWe find that these hyper-parameters are inter-related, and also introduce a\nsimple and effective technique that reduces \\textit{coefficient} during\ntraining. With KD employing the proposed hyper-parameters, we achieve the test\naccuracy of 92.7% and 67.0% on Resnet20 with 2-bit ternary weights for CIFAR-10\nand CIFAR-100 data sets, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 10:47:03 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 06:36:35 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 10:46:56 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Shin", "Sungho", ""], ["Boo", "Yoonho", ""], ["Sung", "Wonyong", ""]]}, {"id": "1909.01709", "submitter": "Niklas Heim", "authors": "Niklas Heim, James E. Avery", "title": "Adaptive Anomaly Detection in Chaotic Time Series with a Spatially Aware\n  Echo State Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work builds an automated anomaly detection method for chaotic time\nseries, and more concretely for turbulent, high-dimensional, ocean simulations.\nWe solve this task by extending the Echo State Network by spatially aware input\nmaps, such as convolutions, gradients, cosine transforms, et cetera, as well as\na spatially aware loss function. The spatial ESN is used to create predictions\nwhich reduce the detection problem to thresholding of the prediction error. We\nbenchmark our detection framework on different tasks of increasing difficulty\nto show the generality of the framework before applying it to raw climate model\noutput in the region of the Japanese ocean current Kuroshio, which exhibits a\nbimodality that is not easily detected by the naked eye. The code is available\nas an open source Python package, Torsk, available at\nhttps://github.com/nmheim/torsk, where we also provide supplementary material\nand programs that reproduce the results shown in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 13:46:07 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Heim", "Niklas", ""], ["Avery", "James E.", ""]]}, {"id": "1909.01716", "submitter": "Michihiro Yasunaga", "authors": "Michihiro Yasunaga, Jungo Kasai, Rui Zhang, Alexander R. Fabbri, Irene\n  Li, Dan Friedman, Dragomir R. Radev", "title": "ScisummNet: A Large Annotated Corpus and Content-Impact Models for\n  Scientific Paper Summarization with Citation Networks", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific article summarization is challenging: large, annotated corpora are\nnot available, and the summary should ideally include the article's impacts on\nresearch community. This paper provides novel solutions to these two\nchallenges. We 1) develop and release the first large-scale manually-annotated\ncorpus for scientific papers (on computational linguistics) by enabling faster\nannotation, and 2) propose summarization methods that integrate the authors'\noriginal highlights (abstract) and the article's actual impacts on the\ncommunity (citations), to create comprehensive, hybrid summaries. We conduct\nexperiments to demonstrate the efficacy of our corpus in training data-driven\nmodels for scientific paper summarization and the advantage of our hybrid\nsummaries over abstracts and traditional citation-based summaries. Our large\nannotated corpus and hybrid methods provide a new framework for scientific\npaper summarization research.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:04:48 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 02:51:44 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 01:32:22 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Yasunaga", "Michihiro", ""], ["Kasai", "Jungo", ""], ["Zhang", "Rui", ""], ["Fabbri", "Alexander R.", ""], ["Li", "Irene", ""], ["Friedman", "Dan", ""], ["Radev", "Dragomir R.", ""]]}, {"id": "1909.01730", "submitter": "Carl Andersson", "authors": "Carl Andersson, Ant\\^onio H. Ribeiro, Koen Tiels, Niklas Wahlstr\\\"om\n  and Thomas B. Sch\\\"on", "title": "Deep Convolutional Networks in System Identification", "comments": "Accepted to Conference on Decision and Control, The first two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.NE cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments within deep learning are relevant for nonlinear system\nidentification problems. In this paper, we establish connections between the\ndeep learning and the system identification communities. It has recently been\nshown that convolutional architectures are at least as capable as recurrent\narchitectures when it comes to sequence modeling tasks. Inspired by these\nresults we explore the explicit relationships between the recently proposed\ntemporal convolutional network (TCN) and two classic system identification\nmodel structures; Volterra series and block-oriented models. We end the paper\nwith an experimental study where we provide results on two real-world problems,\nthe well-known Silverbox dataset and a newer dataset originating from ground\nvibration experiments on an F-16 fighter aircraft.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:34:32 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 14:30:44 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Andersson", "Carl", ""], ["Ribeiro", "Ant\u00f4nio H.", ""], ["Tiels", "Koen", ""], ["Wahlstr\u00f6m", "Niklas", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1909.01735", "submitter": "Mohammad Akbari", "authors": "Mohammad Akbari and Rumi Chunara", "title": "Using Contextual Information to Improve Blood Glucose Prediction", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blood glucose value prediction is an important task in diabetes management.\nWhile it is reported that glucose concentration is sensitive to social context\nsuch as mood, physical activity, stress, diet, alongside the influence of\ndiabetes pathologies, we need more research on data and methodologies to\nincorporate and evaluate signals about such temporal context into prediction\nmodels. Person-generated data sources, such as actively contributed surveys as\nwell as passively mined data from social media offer opportunity to capture\nsuch context, however the self-reported nature and sparsity of such data mean\nthat such data are noisier and less specific than physiological measures such\nas blood glucose values themselves. Therefore, here we propose a Gaussian\nProcess model to both address these data challenges and combine blood glucose\nand latent feature representations of contextual data for a novel multi-signal\nblood glucose prediction task. We find this approach outperforms common methods\nfor multi-variate data, as well as using the blood glucose values in isolation.\nGiven a robust evaluation across two blood glucose datasets with different\nforms of contextual information, we conclude that multi-signal Gaussian\nProcesses can improve blood glucose prediction by using contextual information\nand may provide a significant shift in blood glucose prediction research and\npractice.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 11:02:52 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Akbari", "Mohammad", ""], ["Chunara", "Rumi", ""]]}, {"id": "1909.01736", "submitter": "Gregory Diamos", "authors": "Joel Hestness, Newsha Ardalani, Greg Diamos", "title": "Beyond Human-Level Accuracy: Computational Challenges in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) research yields accuracy and product improvements from\nboth model architecture changes and scale: larger data sets and models, and\nmore computation. For hardware design, it is difficult to predict DL model\nchanges. However, recent prior work shows that as dataset sizes grow, DL model\naccuracy and model size grow predictably. This paper leverages the prior work\nto project the dataset and model size growth required to advance DL accuracy\nbeyond human-level, to frontier targets defined by machine learning experts.\nDatasets will need to grow $33$--$971 \\times$, while models will need to grow\n$6.6$--$456\\times$ to achieve target accuracies.\n  We further characterize and project the computational requirements to train\nthese applications at scale. Our characterization reveals an important\nsegmentation of DL training challenges for recurrent neural networks (RNNs)\nthat contrasts with prior studies of deep convolutional networks. RNNs will\nhave comparatively moderate operational intensities and very large memory\nfootprint requirements. In contrast to emerging accelerator designs,\nlarge-scale RNN training characteristics suggest designs with significantly\nlarger memory capacity and on-chip caches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:37:37 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Hestness", "Joel", ""], ["Ardalani", "Newsha", ""], ["Diamos", "Greg", ""]]}, {"id": "1909.01757", "submitter": "Massimiliano Ruocco", "authors": "Andreas Kvistad, Massimiliano Ruocco, Eliezer de Souza da Silva,\n  Erlend Aune", "title": "Augmented Memory Networks for Streaming-Based Active One-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the major challenges in training deep architectures for predictive\ntasks is the scarcity and cost of labeled training data. Active Learning (AL)\nis one way of addressing this challenge. In stream-based AL, observations are\ncontinuously made available to the learner that have to decide whether to\nrequest a label or to make a prediction. The goal is to reduce the request rate\nwhile at the same time maximize prediction performance. In previous research,\nreinforcement learning has been used for learning the AL request/prediction\nstrategy. In our work, we propose to equip a reinforcement learning process\nwith memory augmented neural networks, to enhance the one-shot capabilities.\nMoreover, we introduce Class Margin Sampling (CMS) as an extension of the\nstandard margin sampling to the reinforcement learning setting. This strategy\naims to reduce training time and improve sample efficiency in the training\nprocess. We evaluate the proposed method on a classification task using\nempirical accuracy of label predictions and percentage of label requests. The\nresults indicates that the proposed method, by making use of the memory\naugmented networks and CMS in the training process, outperforms existing\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 12:56:50 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Kvistad", "Andreas", ""], ["Ruocco", "Massimiliano", ""], ["da Silva", "Eliezer de Souza", ""], ["Aune", "Erlend", ""]]}, {"id": "1909.01759", "submitter": "Manel Mart\\'inez-Ram\\'on", "authors": "Nestor Pereira, Miguel Angel Hombrados Herrera, Vanesssa\n  G\\'omez-Verdejo, Andrea A. Mammoli, Manel Mart\\'inez-Ram\\'on", "title": "Data Selection for Short Term load forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power load forecast with Machine Learning is a fairly mature application of\nartificial intelligence and it is indispensable in operation, control and\nplanning. Data selection techniqies have been hardly used in this application.\nHowever, the use of such techniques could be beneficial provided the assumption\nthat the data is identically distributed is clearly not true in load\nforecasting, but it is cyclostationary. In this work we present a fully\nautomatic methodology to determine what are the most adequate data to train a\npredictor which is based on a full Bayesian probabilistic model. We assess the\nperformance of the method with experiments based on real publicly available\ndata recorded from several years in the United States of America.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 21:51:48 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 19:48:59 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Pereira", "Nestor", ""], ["Herrera", "Miguel Angel Hombrados", ""], ["G\u00f3mez-Verdejo", "Vanesssa", ""], ["Mammoli", "Andrea A.", ""], ["Mart\u00ednez-Ram\u00f3n", "Manel", ""]]}, {"id": "1909.01760", "submitter": "Manisha Panta", "authors": "Duaa Alawad, Manisha Panta, Minhaz Zibran, Md Rakibul Islam", "title": "An Empirical Study of the Relationships between Code Readability and\n  Software Complexity", "comments": "7 pages, 2 figures, 3 tables", "journal-ref": "27th International Conference on Software Engineering and Data\n  Engineering (SEDE), 2018", "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Code readability and software complexity are important software quality\nmetrics that impact other software metrics such as maintainability,\nreusability, portability and reliability. This paper presents an empirical\nstudy of the relationships between code readability and program complexity. The\nresults are derived from an analysis of 35 Java programs that cover 23 distinct\ncode constructs. The analysis includes six readability metrics and two\ncomplexity metrics. Our study empirically confirms the existing wisdom that\nreadability and complexity are negatively correlated. Applying a machine\nlearning technique, we also identify and rank those code constructs that\nsubstantially affect code readability.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 20:46:38 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Alawad", "Duaa", ""], ["Panta", "Manisha", ""], ["Zibran", "Minhaz", ""], ["Islam", "Md Rakibul", ""]]}, {"id": "1909.01761", "submitter": "Yu Wang", "authors": "Yu Wang", "title": "Single Training Dimension Selection for Word Embedding with PCA", "comments": "6 pages, 5 figures, 2 tables, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a fast and reliable method based on PCA to select\nthe number of dimensions for word embeddings. First, we train one embedding\nwith a generous upper bound (e.g. 1,000) of dimensions. Then we transform the\nembeddings using PCA and incrementally remove the lesser dimensions one at a\ntime while recording the embeddings' performance on language tasks. Lastly, we\nselect the number of dimensions while balancing model size and accuracy.\nExperiments using various datasets and language tasks demonstrate that we are\nable to train 10 times fewer sets of embeddings while retaining optimal\nperformance. Researchers interested in training the best-performing embeddings\nfor downstream tasks, such as sentiment analysis, question answering and\nhypernym extraction, as well as those interested in embedding compression\nshould find the method helpful.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 23:19:41 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Wang", "Yu", ""]]}, {"id": "1909.01763", "submitter": "Yin Zhao", "authors": "Jie Zhang, Yin Zhao, Longjun Cai, Chaoping Tu, Wu Wei", "title": "Video Affective Effects Prediction with Multi-modal Fusion and Shot-Long\n  Temporal Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the emotional impact of videos using machine learning is a\nchallenging task considering the varieties of modalities, the complicated\ntemporal contex of the video as well as the time dependency of the emotional\nstates. Feature extraction, multi-modal fusion and temporal context fusion are\ncrucial stages for predicting valence and arousal values in the emotional\nimpact, but have not been successfully exploited. In this paper, we propose a\ncomprehensive framework with novel designs of modal structure and multi-modal\nfusion strategy. We select the most suitable modalities for valence and arousal\ntasks respectively and each modal feature is extracted using the\nmodality-specific pre-trained deep model on large generic dataset.\nTwo-time-scale structures, one for the intra-clip and the other for the\ninter-clip, are proposed to capture the temporal dependency of video content\nand emotion states. To combine the complementary information from multiple\nmodalities, an effective and efficient residual-based progressive training\nstrategy is proposed. Each modality is step-wisely combined into the\nmulti-modal model, responsible for completing the missing parts of features.\nWith all those improvements above, our proposed prediction framework achieves\nbetter performance on the LIRIS-ACCEDE dataset with a large margin compared to\nthe state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 07:22:20 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Zhang", "Jie", ""], ["Zhao", "Yin", ""], ["Cai", "Longjun", ""], ["Tu", "Chaoping", ""], ["Wei", "Wu", ""]]}, {"id": "1909.01779", "submitter": "Matthia Sabatelli", "authors": "Matthia Sabatelli, Gilles Louppe, Pierre Geurts, Marco A. Wiering", "title": "Approximating two value functions instead of one: towards characterizing\n  a new family of Deep Reinforcement Learning algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes one step forward towards characterizing a new family of\n\\textit{model-free} Deep Reinforcement Learning (DRL) algorithms. The aim of\nthese algorithms is to jointly learn an approximation of the state-value\nfunction ($V$), alongside an approximation of the state-action value function\n($Q$). Our analysis starts with a thorough study of the Deep Quality-Value\nLearning (DQV) algorithm, a DRL algorithm which has been shown to outperform\npopular techniques such as Deep-Q-Learning (DQN) and Double-Deep-Q-Learning\n(DDQN) \\cite{sabatelli2018deep}. Intending to investigate why DQV's learning\ndynamics allow this algorithm to perform so well, we formulate a set of\nresearch questions which help us characterize a new family of DRL algorithms.\nAmong our results, we present some specific cases in which DQV's performance\ncan get harmed and introduce a novel \\textit{off-policy} DRL algorithm, called\nDQV-Max, which can outperform DQV. We then study the behavior of the $V$ and\n$Q$ functions that are learned by DQV and DQV-Max and show that both algorithms\nmight perform so well on several DRL test-beds because they are less prone to\nsuffer from the overestimation bias of the $Q$ function.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 10:29:54 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 09:06:37 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Sabatelli", "Matthia", ""], ["Louppe", "Gilles", ""], ["Geurts", "Pierre", ""], ["Wiering", "Marco A.", ""]]}, {"id": "1909.01783", "submitter": "Giuseppe Vietri", "authors": "Seth Neel, Aaron Roth, Giuseppe Vietri, Zhiwei Steven Wu", "title": "Oracle Efficient Private Non-Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most effective algorithms for differentially private learning and\noptimization is objective perturbation. This technique augments a given\noptimization problem (e.g. deriving from an ERM problem) with a random linear\nterm, and then exactly solves it. However, to date, analyses of this approach\ncrucially rely on the convexity and smoothness of the objective function,\nlimiting its generality. We give two algorithms that extend this approach\nsubstantially. The first algorithm requires nothing except boundedness of the\nloss function, and operates over a discrete domain. Its privacy and accuracy\nguarantees hold even without assuming convexity. This gives an oracle-efficient\noptimization algorithm over arbitrary discrete domains that is comparable in\nits generality to the exponential mechanism. The second algorithm operates over\na continuous domain and requires only that the loss function be bounded and\nLipschitz in its continuous parameter. Its privacy analysis does not require\nconvexity. Its accuracy analysis does require convexity, but does not require\nsecond order conditions like smoothness. Even without convexity, this algorithm\ncan be generically used as an oracle-efficient optimization algorithm, with\naccuracy evaluated empirically. We complement our theoretical results with an\nempirical evaluation of the non-convex case, in which we use an integer program\nsolver as our optimization oracle. We find that for the problem of learning\nlinear classifiers, directly optimizing for 0/1 loss using our approach can\nout-perform the more standard approach of privately optimizing a\nconvex-surrogate loss function on the Adult dataset.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:31:11 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 18:29:31 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 15:06:40 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Neel", "Seth", ""], ["Roth", "Aaron", ""], ["Vietri", "Giuseppe", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1909.01795", "submitter": "Shaojie Tang", "authors": "Shaojie Tang", "title": "Stochastic Submodular Probing with State-Dependent Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a new stochastic submodular maximization problem with\nstate-dependent costs and rejections. The input of our problem is a budget\nconstraint $B$, and a set of items whose states (i.e., the marginal\ncontribution and the cost of an item) are drawn from a known probability\ndistribution. The only way to know the realized state of an item is to probe\nthe item. We allow rejections, i.e., after probing an item and knowing its\nactual state, we must decide immediately and irrevocably whether to add that\nitem to our solution or not. Our objective is to maximize the objective\nfunction subject to a budget constraint on the total cost of the selected\nitems. We present a constant approximate solution to this problem. We show that\nour solution is also applied to an online setting.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 22:50:51 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Tang", "Shaojie", ""]]}, {"id": "1909.01804", "submitter": "Zhanghan Ke", "authors": "Zhanghan Ke and Daoye Wang and Qiong Yan and Jimmy Ren and Rynson W.H.\n  Lau", "title": "Dual Student: Breaking the Limits of the Teacher in Semi-supervised\n  Learning", "comments": "International Conference in Computer Vision 2019 (ICCV 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, consistency-based methods have achieved state-of-the-art results in\nsemi-supervised learning (SSL). These methods always involve two roles, an\nexplicit or implicit teacher model and a student model, and penalize\npredictions under different perturbations by a consistency constraint. However,\nthe weights of these two roles are tightly coupled since the teacher is\nessentially an exponential moving average (EMA) of the student. In this work,\nwe show that the coupled EMA teacher causes a performance bottleneck. To\naddress this problem, we introduce Dual Student, which replaces the teacher\nwith another student. We also define a novel concept, stable sample, following\nwhich a stabilization constraint is designed for our structure to be trainable.\nFurther, we discuss two variants of our method, which produce even higher\nperformance. Extensive experiments show that our method improves the\nclassification performance significantly on several main SSL benchmarks.\nSpecifically, it reduces the error rate of the 13-layer CNN from 16.84% to\n12.39% on CIFAR-10 with 1k labels and from 34.10% to 31.56% on CIFAR-100 with\n10k labels. In addition, our method also achieves a clear improvement in domain\nadaptation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:32:11 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Ke", "Zhanghan", ""], ["Wang", "Daoye", ""], ["Yan", "Qiong", ""], ["Ren", "Jimmy", ""], ["Lau", "Rynson W. H.", ""]]}, {"id": "1909.01811", "submitter": "Ruomu Zou", "authors": "Ruomu Zou", "title": "A Deep, Forgetful Novelty-Seeking Movie Recommender Model", "comments": "19 pages, 14 figures, submitted as a contest entry to the S.-T. Yau\n  High School Science Award (Computer Award)", "journal-ref": null, "doi": "10.13140/RG.2.2.35255.27043", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As more and more people shift their movie watching online, competition\nbetween movie viewing websites are getting more and more intense. Therefore, it\nhas become incredibly important to accurately predict a given user's watching\nlist to maximize the chances of keeping the user on the platform. Recent\nstudies have suggested that the novelty-seeking propensity of users can impact\ntheir viewing behavior. In this paper, we aim to accurately model and describe\nthis novelty-seeking trait across many users and timestamps driven by data,\ntaking into consideration user forgetfulness. Compared to previous studies, we\npropose a more robust measure for novelty. Our model, termed Deep Forgetful\nNovelty-Seeking Model (DFNSM), leverages demographic information about users,\ngenre information about movies, and novelty-seeking traits to predict the most\nlikely next actions of a user. To evaluate the performance of our model, we\nconducted extensive experiments on a large movie rating dataset. The results\nreveal that DFNSM is very effective for movie recommendation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 12:49:38 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Zou", "Ruomu", ""]]}, {"id": "1909.01812", "submitter": "Shanshan Wu", "authors": "Shanshan Wu, Alexandros G. Dimakis, Sujay Sanghavi", "title": "Learning Distributions Generated by One-Layer ReLU Networks", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the parameters of a $d$-dimensional\nrectified Gaussian distribution from i.i.d. samples. A rectified Gaussian\ndistribution is defined by passing a standard Gaussian distribution through a\none-layer ReLU neural network. We give a simple algorithm to estimate the\nparameters (i.e., the weight matrix and bias vector of the ReLU neural network)\nup to an error $\\epsilon||W||_F$ using $\\tilde{O}(1/\\epsilon^2)$ samples and\n$\\tilde{O}(d^2/\\epsilon^2)$ time (log factors are ignored for simplicity). This\nimplies that we can estimate the distribution up to $\\epsilon$ in total\nvariation distance using $\\tilde{O}(\\kappa^2d^2/\\epsilon^2)$ samples, where\n$\\kappa$ is the condition number of the covariance matrix. Our only assumption\nis that the bias vector is non-negative. Without this non-negativity\nassumption, we show that estimating the bias vector within any error requires\nthe number of samples at least exponential in the infinity norm of the bias\nvector. Our algorithm is based on the key observation that vector norms and\npairwise angles can be estimated separately. We use a recent result on learning\nfrom truncated samples. We also prove two sample complexity lower bounds:\n$\\Omega(1/\\epsilon^2)$ samples are required to estimate the parameters up to\nerror $\\epsilon$, while $\\Omega(d/\\epsilon^2)$ samples are necessary to\nestimate the distribution up to $\\epsilon$ in total variation distance. The\nfirst lower bound implies that our algorithm is optimal for parameter\nestimation. Finally, we show an interesting connection between learning a\ntwo-layer generative model and non-negative matrix factorization. Experimental\nresults are provided to support our analysis.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 14:04:46 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 16:04:46 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Wu", "Shanshan", ""], ["Dimakis", "Alexandros G.", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1909.01815", "submitter": "Bernhard Egger", "authors": "Bernhard Egger, William A. P. Smith, Ayush Tewari, Stefanie Wuhrer,\n  Michael Zollhoefer, Thabo Beeler, Florian Bernard, Timo Bolkart, Adam\n  Kortylewski, Sami Romdhani, Christian Theobalt, Volker Blanz, Thomas Vetter", "title": "3D Morphable Face Models -- Past, Present and Future", "comments": "ACM Transactions on Graphics (TOG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a detailed survey of 3D Morphable Face Models over\nthe 20 years since they were first proposed. The challenges in building and\napplying these models, namely capture, modeling, image formation, and image\nanalysis, are still active research topics, and we review the state-of-the-art\nin each of these areas. We also look ahead, identifying unsolved challenges,\nproposing directions for future research and highlighting the broad range of\ncurrent and future applications.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:49:53 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 13:56:31 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Egger", "Bernhard", ""], ["Smith", "William A. P.", ""], ["Tewari", "Ayush", ""], ["Wuhrer", "Stefanie", ""], ["Zollhoefer", "Michael", ""], ["Beeler", "Thabo", ""], ["Bernard", "Florian", ""], ["Bolkart", "Timo", ""], ["Kortylewski", "Adam", ""], ["Romdhani", "Sami", ""], ["Theobalt", "Christian", ""], ["Blanz", "Volker", ""], ["Vetter", "Thomas", ""]]}, {"id": "1909.01821", "submitter": "Thomas Dybdahl Ahle", "authors": "Thomas D. Ahle, Jakob B. T. Knudsen", "title": "Almost Optimal Tensor Sketch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a matrix $M\\in R^{m\\otimes d^c}$ with just\n$m=O(c\\,\\lambda\\,\\varepsilon^{-2}\\text{poly}\\log1/\\varepsilon\\delta)$ rows,\nwhich preserves the norm $\\|Mx\\|_2=(1\\pm\\varepsilon)\\|x\\|_2$ of all $x$ in any\ngiven $\\lambda$ dimensional subspace of $ R^d$ with probability at least\n$1-\\delta$. This matrix can be applied to tensors $x^{(1)}\\otimes\\dots\\otimes\nx^{(c)}\\in R^{d^c}$ in $O(c\\, m \\min\\{d,m\\})$ time -- hence the name \"Tensor\nSketch\". (Here $x\\otimes y = \\text{asvec}(xy^T) = [x_1y_1,\nx_1y_2,\\dots,x_1y_m,x_2y_1,\\dots,x_ny_m]\\in R^{nm}$.)\n  This improves upon earlier Tensor Sketch constructions by Pagh and Pham~[TOCT\n2013, SIGKDD 2013] and Avron et al.~[NIPS 2014] which require\n$m=\\Omega(3^c\\lambda^2\\delta^{-1})$ rows for the same guarantees. The factors\nof $\\lambda$, $\\varepsilon^{-2}$ and $\\log1/\\delta$ can all be shown to be\nnecessary making our sketch optimal up to log factors.\n  With another construction we get $\\lambda$ times more rows $m=\\tilde\nO(c\\,\\lambda^2\\,\\varepsilon^{-2}(\\log1/\\delta)^3)$, but the matrix can be\napplied to any vector $x^{(1)}\\otimes\\dots\\otimes x^{(c)}\\in R^{d^c}$ in just\n$\\tilde O(c\\, (d+m))$ time. This matches the application time of Tensor Sketch\nwhile still improving the exponential dependencies in $c$ and $\\log1/\\delta$.\n  Technically, we show two main lemmas: (1) For many Johnson Lindenstrauss (JL)\nconstructions, if $Q,Q'\\in R^{m\\times d}$ are independent JL matrices, the\nelement-wise product $Qx \\circ Q'y$ equals $M(x\\otimes y)$ for some $M\\in\nR^{m\\times d^2}$ which is itself a JL matrix. (2) If $M^{(i)}\\in R^{m\\times\nmd}$ are independent JL matrices, then $M^{(1)}(x \\otimes (M^{(2)}y \\otimes\n\\dots)) = M(x\\otimes y\\otimes \\dots)$ for some $M\\in R^{m\\times d^c}$ which is\nitself a JL matrix. Combining these two results give an efficient sketch for\ntensors of any size.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 08:56:59 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Ahle", "Thomas D.", ""], ["Knudsen", "Jakob B. T.", ""]]}, {"id": "1909.01837", "submitter": "Siddhartha Datta", "authors": "Siddhartha Datta", "title": "DeepObfusCode: Source Code Obfuscation Through Sequence-to-Sequence\n  Networks", "comments": "Accepted in Advances in Intelligent Systems and Computing 2021 &\n  Computing Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper explores a novel methodology in source code obfuscation through the\napplication of text-based recurrent neural network (RNN) encoder-decoder models\nin ciphertext generation and key generation. Sequence-to-sequence models are\nincorporated into the model architecture to generate obfuscated code, generate\nthe deobfuscation key, and live execution. Quantitative benchmark comparison to\nexisting obfuscation methods indicate significant improvement in stealth and\nexecution cost for the proposed solution, and experiments regarding the model's\nproperties yield positive results regarding its character variation,\ndissimilarity to the original codebase, and consistent length of obfuscated\ncode.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:22:39 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 18:01:16 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 11:30:06 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Datta", "Siddhartha", ""]]}, {"id": "1909.01838", "submitter": "Matthew Jagielski", "authors": "Matthew Jagielski, Nicholas Carlini, David Berthelot, Alex Kurakin,\n  Nicolas Papernot", "title": "High Accuracy and High Fidelity Extraction of Neural Networks", "comments": "USENIX Security 2020, 18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a model extraction attack, an adversary steals a copy of a remotely\ndeployed machine learning model, given oracle prediction access. We taxonomize\nmodel extraction attacks around two objectives: *accuracy*, i.e., performing\nwell on the underlying learning task, and *fidelity*, i.e., matching the\npredictions of the remote victim classifier on any input.\n  To extract a high-accuracy model, we develop a learning-based attack\nexploiting the victim to supervise the training of an extracted model. Through\nanalytical and empirical arguments, we then explain the inherent limitations\nthat prevent any learning-based strategy from extracting a truly high-fidelity\nmodel---i.e., extracting a functionally-equivalent model whose predictions are\nidentical to those of the victim model on all possible inputs. Addressing these\nlimitations, we expand on prior work to develop the first practical\nfunctionally-equivalent extraction attack for direct extraction (i.e., without\ntraining) of a model's weights.\n  We perform experiments both on academic datasets and a state-of-the-art image\nclassifier trained with 1 billion proprietary images. In addition to broadening\nthe scope of model extraction research, our work demonstrates the practicality\nof model extraction attacks against production-grade systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:33:09 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 22:08:02 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Jagielski", "Matthew", ""], ["Carlini", "Nicholas", ""], ["Berthelot", "David", ""], ["Kurakin", "Alex", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1909.01839", "submitter": "Prashnna Gyawali", "authors": "Prashnna Kumar Gyawali, Zhiyuan Li, Cameron Knight, Sandesh Ghimire,\n  B. Milan Horacek, John Sapp and Linwei Wang", "title": "Improving Disentangled Representation Learning with the Beta Bernoulli\n  Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To improve the ability of VAE to disentangle in the latent space, existing\nworks mostly focus on enforcing independence among the learned latent factors.\nHowever, the ability of these models to disentangle often decreases as the\ncomplexity of the generative factors increases. In this paper, we investigate\nthe little-explored effect of the modeling capacity of a posterior density on\nthe disentangling ability of the VAE. We note that the independence within and\nthe complexity of the latent density are two different properties we constrain\nwhen regularizing the posterior density: while the former promotes the\ndisentangling ability of VAE, the latter -- if overly limited -- creates an\nunnecessary competition with the data reconstruction objective in VAE.\nTherefore, if we preserve the independence but allow richer modeling capacity\nin the posterior density, we will lift this competition and thereby allow\nimproved independence and data reconstruction at the same time. We investigate\nthis theoretical intuition with a VAE that utilizes a non-parametric latent\nfactor model, the Indian Buffet Process (IBP), as a latent density that is able\nto grow with the complexity of the data. Across three widely-used benchmark\ndata sets and two clinical data sets little explored for disentangled learning,\nwe qualitatively and quantitatively demonstrated the improved disentangling\nperformance of IBP-VAE over the state of the art. In the latter two clinical\ndata sets riddled with complex factors of variations, we further demonstrated\nthat unsupervised disentangling of nuisance factors via IBP-VAE -- when\ncombined with a supervised objective -- can not only improve task accuracy in\ncomparison to relevant supervised deep architectures but also facilitate\nknowledge discovery related to task decision-making. A shorter version of this\nwork will appear in the ICDM 2019 conference proceedings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:25:25 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Gyawali", "Prashnna Kumar", ""], ["Li", "Zhiyuan", ""], ["Knight", "Cameron", ""], ["Ghimire", "Sandesh", ""], ["Horacek", "B. Milan", ""], ["Sapp", "John", ""], ["Wang", "Linwei", ""]]}, {"id": "1909.01843", "submitter": "Anup Das", "authors": "Adarsha Balaji, Anup Das, Yuefeng Wu, Khanh Huynh, Francesco\n  Dell'Anna, Giacomo Indiveri, Jeffrey L. Krichmar, Nikil Dutt, Siebren\n  Schaafsma, and Francky Catthoor", "title": "Mapping Spiking Neural Networks to Neuromorphic Hardware", "comments": "14 pages, 14 images, 69 references, Accepted in IEEE Transactions on\n  Very Large Scale Integration (VLSI) Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG cs.OS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neuromorphic hardware platforms implement biological neurons and synapses to\nexecute spiking neural networks (SNNs) in an energy-efficient manner. We\npresent SpiNeMap, a design methodology to map SNNs to crossbar-based\nneuromorphic hardware, minimizing spike latency and energy consumption.\nSpiNeMap operates in two steps: SpiNeCluster and SpiNePlacer. SpiNeCluster is a\nheuristic-based clustering technique to partition SNNs into clusters of\nsynapses, where intracluster local synapses are mapped within crossbars of the\nhardware and inter-cluster global synapses are mapped to the shared\ninterconnect. SpiNeCluster minimizes the number of spikes on global synapses,\nwhich reduces spike congestion on the shared interconnect, improving\napplication performance. SpiNePlacer then finds the best placement of local and\nglobal synapses on the hardware using a meta-heuristic-based approach to\nminimize energy consumption and spike latency. We evaluate SpiNeMap using\nsynthetic and realistic SNNs on the DynapSE neuromorphic hardware. We show that\nSpiNeMap reduces average energy consumption by 45% and average spike latency by\n21%, compared to state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 14:39:47 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Balaji", "Adarsha", ""], ["Das", "Anup", ""], ["Wu", "Yuefeng", ""], ["Huynh", "Khanh", ""], ["Dell'Anna", "Francesco", ""], ["Indiveri", "Giacomo", ""], ["Krichmar", "Jeffrey L.", ""], ["Dutt", "Nikil", ""], ["Schaafsma", "Siebren", ""], ["Catthoor", "Francky", ""]]}, {"id": "1909.01844", "submitter": "Carl Jidling", "authors": "Carl Jidling, Johannes Hendriks, Thomas B. Sch\\\"on, Adrian Wills", "title": "Deep kernel learning for integral measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep kernel learning refers to a Gaussian process that incorporates neural\nnetworks to improve the modelling of complex functions. We present a method\nthat makes this approach feasible for problems where the data consists of line\nintegral measurements of the target function. The performance is illustrated on\ncomputed tomography reconstruction examples.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 14:42:07 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Jidling", "Carl", ""], ["Hendriks", "Johannes", ""], ["Sch\u00f6n", "Thomas B.", ""], ["Wills", "Adrian", ""]]}, {"id": "1909.01866", "submitter": "Jindong Gu", "authors": "Jindong Gu, Daniela Oelke", "title": "Understanding Bias in Machine Learning", "comments": null, "journal-ref": "1st Workshop on Visualization for AI Explainability in 2018 IEEE\n  Vis", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias is known to be an impediment to fair decisions in many domains such as\nhuman resources, the public sector, health care etc. Recently, hope has been\nexpressed that the use of machine learning methods for taking such decisions\nwould diminish or even resolve the problem. At the same time, machine learning\nexperts warn that machine learning models can be biased as well. In this\narticle, our goal is to explain the issue of bias in machine learning from a\ntechnical perspective and to illustrate the impact that biased data can have on\na machine learning model. To reach such a goal, we develop interactive plots to\nvisualizing the bias learned from synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 20:36:19 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Gu", "Jindong", ""], ["Oelke", "Daniela", ""]]}, {"id": "1909.01868", "submitter": "Ashutosh Tiwari Mr", "authors": "Ashutosh Tiwari, Avadh Bihari Narayan, Onkar Dikshit", "title": "Deep learning networks for selection of persistent scatterer pixels in\n  multi-temporal SAR interferometric processing", "comments": "10015 words, 11 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-temporal SAR interferometry (MT-InSAR), persistent scatterer (PS)\npixels are used to estimate geophysical parameters, essentially deformation.\nConventionally, PS pixels are selected on the basis of the estimated noise\npresent in the spatially uncorrelated phase component along with look-angle\nerror in a temporal interferometric stack. In this study, two deep learning\narchitectures, namely convolutional neural network for interferometric semantic\nsegmentation (CNN-ISS) and convolutional long short term memory network for\ninterferometric semantic segmentation (CLSTM-ISS), based on learning spatial\nand spatio-temporal behaviour respectively, were proposed for selection of PS\npixels. These networks were trained to relate the interferometric phase history\nto its classification into phase stable (PS) and phase unstable (non-PS)\nmeasurement pixels using ~10,000 real world interferometric images of different\nstudy sites containing man-made objects, forests, vegetation, uncropped land,\nwater bodies, and areas affected by lengthening, foreshortening, layover and\nshadowing. The networks were trained using training labels obtained from the\nStanford method for Persistent Scatterer Interferometry (StaMPS) algorithm.\nHowever, pixel selection results, when compared to a combination of R-index and\na classified image of the test dataset, reveal that CLSTM-ISS estimates\nimproved the classification of PS and non-PS pixels compared to those of StaMPS\nand CNN-ISS. The predicted results show that CLSTM-ISS reached an accuracy of\n93.50%, higher than that of CNN-ISS (89.21%). CLSTM-ISS also improved the\ndensity of reliable PS pixels compared to StaMPS and CNN-ISS and outperformed\nStaMPS and other conventional MT-InSAR methods in terms of computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:17:34 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 08:13:29 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 13:27:45 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Tiwari", "Ashutosh", ""], ["Narayan", "Avadh Bihari", ""], ["Dikshit", "Onkar", ""]]}, {"id": "1909.01869", "submitter": "Jay Budzik", "authors": "John Merrill, Geoff Ward, Sean Kamkar, Jay Budzik and Douglas Merrill", "title": "Generalized Integrated Gradients: A practical method for explaining\n  diverse ensembles", "comments": "38 pages, submitted to JMLR 9/3/2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Generalized Integrated Gradients (GIG), a formal extension of\nthe Integrated Gradients (IG) (Sundararajan et al., 2017) method for\nattributing credit to the input variables of a predictive model. GIG improves\nIG by explaining a broader variety of functions that arise from practical\napplications of ML in domains like financial services. GIG is constructed to\novercome limitations of Shapley (1953) and Aumann-Shapley (1974), and has\ndesirable properties when compared to other approaches. We prove GIG is the\nonly correct method, under a small set of reasonable axioms, for providing\nexplanations for mixed-type models or games. We describe the implementation,\nand present results of experiments on several datasets and systems of models.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:17:37 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 19:57:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Merrill", "John", ""], ["Ward", "Geoff", ""], ["Kamkar", "Sean", ""], ["Budzik", "Jay", ""], ["Merrill", "Douglas", ""]]}, {"id": "1909.01871", "submitter": "Khanh Nguyen", "authors": "Khanh Nguyen and Hal Daum\\'e III", "title": "Help, Anna! Visual Navigation with Natural Multimodal Assistance via\n  Retrospective Curiosity-Encouraging Imitation Learning", "comments": "In EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile agents that can leverage help from humans can potentially accomplish\nmore complex tasks than they could entirely on their own. We develop \"Help,\nAnna!\" (HANNA), an interactive photo-realistic simulator in which an agent\nfulfills object-finding tasks by requesting and interpreting natural\nlanguage-and-vision assistance. An agent solving tasks in a HANNA environment\ncan leverage simulated human assistants, called ANNA (Automatic Natural\nNavigation Assistants), which, upon request, provide natural language and\nvisual instructions to direct the agent towards the goals. To address the HANNA\nproblem, we develop a memory-augmented neural agent that hierarchically models\nmultiple levels of decision-making, and an imitation learning algorithm that\nteaches the agent to avoid repeating past mistakes while simultaneously\npredicting its own chances of making future progress. Empirically, our approach\nis able to ask for help more effectively than competitive baselines and, thus,\nattains higher task success rate on both previously seen and previously unseen\nenvironments. We publicly release code and data at\nhttps://github.com/khanhptnk/hanna . A video demo is available at\nhttps://youtu.be/18P94aaaLKg .\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:20:01 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 16:16:31 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 03:30:13 GMT"}, {"version": "v4", "created": "Tue, 8 Oct 2019 16:08:40 GMT"}, {"version": "v5", "created": "Mon, 21 Oct 2019 07:12:17 GMT"}, {"version": "v6", "created": "Fri, 22 Nov 2019 16:11:17 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Nguyen", "Khanh", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "1909.01931", "submitter": "Ilja Kuzborskij", "authors": "Ilja Kuzborskij, Csaba Szepesv\\'ari", "title": "Efron-Stein PAC-Bayesian Inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove semi-empirical concentration inequalities for random variables which\nare given as possibly nonlinear functions of independent random variables.\nThese inequalities describe concentration of random variable in terms of the\ndata/distribution-dependent Efron-Stein (ES) estimate of its variance and they\ndo not require any additional assumptions on the moments. In particular, this\nallows us to state semi-empirical Bernstein type inequalities for general\nfunctions of unbounded random variables, which gives user-friendly\nconcentration bounds for cases where related methods (e.g. bounded differences)\nmight be more challenging to apply. We extend these results to Efron-Stein\nPAC-Bayesian inequalities which hold for arbitrary probability kernels that\ndefine a random, data-dependent choice of the function of interest. Finally, we\ndemonstrate a number of applications, including PAC-Bayesian generalization\nbounds for unbounded loss functions, empirical Bernstein type generalization\nbounds, new truncation-free bounds for off-policy evaluation with Weighted\nImportance Sampling (WIS), and off-policy PAC-Bayesian learning with WIS.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 16:36:46 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 14:48:45 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kuzborskij", "Ilja", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1909.01936", "submitter": "Jarrod Olson", "authors": "Jarrod Olson and Po-Hsu Allen Chen and Marissa White and Nicole\n  Brennan and Ning Gong", "title": "State Drug Policy Effectiveness: Comparative Policy Analysis of Drug\n  Overdose Mortality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opioid overdose rates have reached an epidemic level and state-level policy\ninnovations have followed suit in an effort to prevent overdose deaths.\nState-level drug law is a set of policies that may reinforce or undermine each\nother, and analysts have a limited set of tools for handling the policy\ncollinearity using statistical methods. This paper uses a machine learning\nmethod called hierarchical clustering to empirically generate \"policy bundles\"\nby grouping states with similar sets of policies in force at a given time\ntogether for analysis in a 50-state, 10-year interrupted time series regression\nwith drug overdose deaths as the dependent variable. Policy clusters were\ngenerated from 138 binomial variables observed by state and year from the\nPrescription Drug Abuse Policy System. Clustering reduced the policies to a set\nof 10 bundles. The approach allows for ranking of the relative effect of\ndifferent bundles and is a tool to recommend those most likely to succeed. This\nstudy shows that a set of policies balancing Medication Assisted Treatment,\nNaloxone Access, Good Samaritan Laws, Medication Assisted Treatment,\nPrescription Drug Monitoring Programs and legalization of medical marijuana\nleads to a reduced number of overdose deaths, but not until its second year in\nforce.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 16:41:44 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 21:17:58 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 23:14:09 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Olson", "Jarrod", ""], ["Chen", "Po-Hsu Allen", ""], ["White", "Marissa", ""], ["Brennan", "Nicole", ""], ["Gong", "Ning", ""]]}, {"id": "1909.01940", "submitter": "Eduardo Pooch", "authors": "Eduardo H. P. Pooch, Pedro L. Ballester, Rodrigo C. Barros", "title": "Can we trust deep learning models diagnosis? The impact of domain shift\n  in chest radiograph classification", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning models become more widespread, their ability to handle\nunseen data and generalize for any scenario is yet to be challenged. In medical\nimaging, there is a high heterogeneity of distributions among images based on\nthe equipment that generates them and their parametrization. This heterogeneity\ntriggers a common issue in machine learning called domain shift, which\nrepresents the difference between the training data distribution and the\ndistribution of where a model is employed. A high domain shift tends to\nimplicate in a poor generalization performance from the models. In this work,\nwe evaluate the extent of domain shift on four of the largest datasets of chest\nradiographs. We show how training and testing with different datasets (e.g.,\ntraining in ChestX-ray14 and testing in CheXpert) drastically affects model\nperformance, posing a big question over the reliability of deep learning models\ntrained on public datasets. We also show that models trained on CheXpert and\nMIMIC-CXR generalize better to other datasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 14:03:55 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 22:50:10 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Pooch", "Eduardo H. P.", ""], ["Ballester", "Pedro L.", ""], ["Barros", "Rodrigo C.", ""]]}, {"id": "1909.01954", "submitter": "Alessandro Lameiras Koerich", "authors": "Bernardo B. Gatto, Eulanda M. dos Santos, Alessandro L. Koerich,\n  Kazuhiro Fukui, Waldir S. S. Junior", "title": "Tensor Analysis with n-Mode Generalized Difference Subspace", "comments": "Submitted to Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of multiple sensors, which produce a large amount of\nmulti-dimensional data, requires efficient representation and classification\nmethods. In this paper, we present a new method for multi-dimensional data\nclassification that relies on two premises: 1) multi-dimensional data are\nusually represented by tensors, since this brings benefits from multilinear\nalgebra and established tensor factorization methods; and 2) multilinear data\ncan be described by a subspace of a vector space. The subspace representation\nhas been employed for pattern-set recognition, and its tensor representation\ncounterpart is also available in the literature. However, traditional methods\ndo not use discriminative information of the tensors, degrading the\nclassification accuracy. In this case, generalized difference subspace (GDS)\nprovides an enhanced subspace representation by reducing data redundancy and\nrevealing discriminative structures. Since GDS does not handle tensor data, we\npropose a new projection called n-mode GDS, which efficiently handles tensor\ndata. We also introduce the n-mode Fisher score as a class separability index\nand an improved metric based on the geodesic distance for tensor data\nsimilarity. The experimental results on gesture and action recognition show\nthat the proposed method outperforms methods commonly used in the literature\nwithout relying on pre-trained models or transfer learning.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 17:26:54 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 17:41:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Gatto", "Bernardo B.", ""], ["Santos", "Eulanda M. dos", ""], ["Koerich", "Alessandro L.", ""], ["Fukui", "Kazuhiro", ""], ["Junior", "Waldir S. S.", ""]]}, {"id": "1909.01955", "submitter": "Xavier Soria Poma", "authors": "Xavier Soria, Edgar Riba and Angel D. Sappa", "title": "Dense Extreme Inception Network: Towards a Robust CNN Model for Edge\n  Detection", "comments": "WACV2020 Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a Deep Learning based edge detector, which is inspired on\nboth HED (Holistically-Nested Edge Detection) and Xception networks. The\nproposed approach generates thin edge-maps that are plausible for human eyes;\nit can be used in any edge detection task without previous training or fine\ntuning process. As a second contribution, a large dataset with carefully\nannotated edges has been generated. This dataset has been used for training the\nproposed approach as well the state-of-the-art algorithms for comparisons.\nQuantitative and qualitative evaluations have been performed on different\nbenchmarks showing improvements with the proposed method when F-measure of ODS\nand OIS are considered.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 17:27:46 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 00:08:24 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Soria", "Xavier", ""], ["Riba", "Edgar", ""], ["Sappa", "Angel D.", ""]]}, {"id": "1909.01960", "submitter": "Kristofer Schlachter", "authors": "Kristofer Schlachter, Connor DeFanti, Sebastian Herscher, Ken Perlin,\n  Jonathan Tompson", "title": "Beyond Photo Realism for Domain Adaptation from Synthetic Data", "comments": "Originally submitted for publication in November 2017", "journal-ref": null, "doi": null, "report-no": "01", "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As synthetic imagery is used more frequently in training deep models, it is\nimportant to understand how different synthesis techniques impact the\nperformance of such models. In this work, we perform a thorough evaluation of\nthe effectiveness of several different synthesis techniques and their impact on\nthe complexity of classifier domain adaptation to the \"real\" underlying data\ndistribution that they seek to replicate. In addition, we propose a novel\nlearned synthesis technique to better train classifier models than\nstate-of-the-art offline graphical methods, while using significantly less\ncomputational resources. We accomplish this by learning a generative model to\nperform shading of synthetic geometry conditioned on a \"g-buffer\"\nrepresentation of the scene to render, as well as a low sample Monte Carlo\nrendered image. The major contributions are (i) a dataset that allows\ncomparison of real and synthetic versions of the same scene, (ii) an augmented\ndata representation that boosts the stability of learning and improves the\ndatasets accuracy, (iii) three different partially differentiable rendering\ntechniques where lighting, denoising and shading are learned, and (iv) we\nimprove a state of the art generative adversarial network (GAN) approach by\nusing an ensemble of trained models to generate datasets that approach the\nperformance of training on real data and surpass the performance of the full\nglobal illumination rendering.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 17:38:05 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Schlachter", "Kristofer", ""], ["DeFanti", "Connor", ""], ["Herscher", "Sebastian", ""], ["Perlin", "Ken", ""], ["Tompson", "Jonathan", ""]]}, {"id": "1909.01961", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "A Constructive Approach for Data-Driven Randomized Learning of\n  Feedforward Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedforward neural networks with random hidden nodes suffer from a problem\nwith the generation of random weights and biases as these are difficult to set\noptimally to obtain a good projection space. Typically, random parameters are\ndrawn from an interval which is fixed before or adapted during the learning\nprocess. Due to the different functions of the weights and biases, selecting\nthem both from the same interval is not a good idea. Recently more\nsophisticated methods of random parameters generation have been developed, such\nas the data-driven method proposed in \\cite{Anon19}, where the sigmoids are\nplaced in randomly selected regions of the input space and then their slopes\nare adjusted to the local fluctuations of the target function. In this work, we\npropose an extended version of this method, which constructs iteratively the\nnetwork architecture. This method successively generates new hidden nodes and\naccepts them if the training error decreases significantly. The threshold of\nacceptance is adapted to the current training stage. At the beginning of the\ntraining process only those nodes which lead to the largest error reduction are\naccepted. Then, the threshold is reduced by half to accept those nodes which\nmodel the target function details more accurately. This leads to faster\nconvergence and more compact network architecture, as it includes only\n\"significant\" neurons. Several application examples are given which confirm\nthis thesis.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 17:38:13 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 12:08:02 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1909.01968", "submitter": "Francesco Fraternali", "authors": "Francesco Fraternali, Bharathan Balaji, Yuvraj Agarwal, Rajesh K.\n  Gupta", "title": "ACES -- Automatic Configuration of Energy Harvesting Sensors with\n  Reinforcement Learning", "comments": null, "journal-ref": "ACM Transactions on Sensor Networks, July 2020, Article No.: 36", "doi": "10.1145/3404191", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things forms the backbone of modern building applications.\nWireless sensors are being increasingly adopted for their flexibility and\nreduced cost of deployment. However, most wireless sensors are powered by\nbatteries today and large deployments are inhibited by manual battery\nreplacement. Energy harvesting sensors provide an attractive alternative, but\nthey need to provide adequate quality of service to applications given\nuncertain energy availability. We propose using reinforcement learning to\noptimize the operation of energy harvesting sensors to maximize sensing quality\nwith available energy. We present our system ACES that uses reinforcement\nlearning for periodic and event-driven sensing indoors with ambient light\nenergy harvesting. Our custom-built board uses a supercapacitor to store energy\ntemporarily, senses light, motion events and relays them using Bluetooth Low\nEnergy. Using simulations and real deployments, we show that our sensor nodes\nadapt to their lighting conditions and continuously sends measurements and\nevents across nights and weekends. We use deployment data to continually adapt\nsensing to changing environmental patterns and transfer learning to reduce the\ntraining time in real deployments. In our 60 node deployment lasting two weeks,\nwe observe a dead time of 0.1%. The periodic sensors that measure luminosity\nhave a mean sampling period of 90 seconds and the event sensors that detect\nmotion with PIR captured 86% of the events on average compared to a\nbattery-powered node.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 17:49:32 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 18:59:57 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Fraternali", "Francesco", ""], ["Balaji", "Bharathan", ""], ["Agarwal", "Yuvraj", ""], ["Gupta", "Rajesh K.", ""]]}, {"id": "1909.01978", "submitter": "Arash Ali Amini", "authors": "Arash A. Amini, Bryon Aragam and Qing Zhou", "title": "On perfectness in Gaussian graphical models", "comments": "This note is based on a result that first appeared in\n  arXiv:1711.00991v1. The original article has now been split into two parts", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing when a graphical model is perfect to a distribution is essential in\norder to relate separation in the graph to conditional independence in the\ndistribution, and this is particularly important when performing inference from\ndata. When the model is perfect, there is a one-to-one correspondence between\nconditional independence statements in the distribution and separation\nstatements in the graph. Previous work has shown that almost all models based\non linear directed acyclic graphs as well as Gaussian chain graphs are perfect,\nthe latter of which subsumes Gaussian graphical models (i.e., the undirected\nGaussian models) as a special case. However, the complexity of chain graph\nmodels leads to a proof of this result which is indirect and mired by the\ncomplications of parameterizing this general class. In this paper, we directly\napproach the problem of perfectness for the Gaussian graphical models, and\nprovide a new proof, via a more transparent parametrization, that almost all\nsuch models are perfect. Our approach is based on, and substantially extends, a\nconstruction of Ln\\v{e}ni\\v{c}ka and Mat\\'u\\v{s} showing the existence of a\nperfect Gaussian distribution for any graph.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 19:17:23 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Amini", "Arash A.", ""], ["Aragam", "Bryon", ""], ["Zhou", "Qing", ""]]}, {"id": "1909.01994", "submitter": "Jacob Rafati", "authors": "Jacob Rafati and Roummel F. Marcia", "title": "Quasi-Newton Optimization Methods For Deep Learning Applications", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.02693", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms often require solving a highly non-linear and\nnonconvex unconstrained optimization problem. Methods for solving optimization\nproblems in large-scale machine learning, such as deep learning and deep\nreinforcement learning (RL), are generally restricted to the class of\nfirst-order algorithms, like stochastic gradient descent (SGD). While SGD\niterates are inexpensive to compute, they have slow theoretical convergence\nrates. Furthermore, they require exhaustive trial-and-error to fine-tune many\nlearning parameters. Using second-order curvature information to find search\ndirections can help with more robust convergence for non-convex optimization\nproblems. However, computing Hessian matrices for large-scale problems is not\ncomputationally practical. Alternatively, quasi-Newton methods construct an\napproximate of the Hessian matrix to build a quadratic model of the objective\nfunction. Quasi-Newton methods, like SGD, require only first-order gradient\ninformation, but they can result in superlinear convergence, which makes them\nattractive alternatives to SGD. The limited-memory\nBroyden-Fletcher-Goldfarb-Shanno (L-BFGS) approach is one of the most popular\nquasi-Newton methods that construct positive definite Hessian approximations.\nIn this chapter, we propose efficient optimization methods based on L-BFGS\nquasi-Newton methods using line search and trust-region strategies. Our methods\nbridge the disparity between first- and second-order methods by using gradient\ninformation to calculate low-rank updates to Hessian approximations. We provide\nformal convergence analysis of these methods as well as empirical results on\ndeep learning applications, such as image classification tasks and deep\nreinforcement learning on a set of ATARI 2600 video games. Our results show a\nrobust convergence with preferred generalization characteristics as well as\nfast training time.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 15:52:08 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Rafati", "Jacob", ""], ["Marcia", "Roummel F.", ""]]}, {"id": "1909.02027", "submitter": "Stefan Larson", "authors": "Stefan Larson, Anish Mahendran, Joseph J. Peper, Christopher Clarke,\n  Andrew Lee, Parker Hill, Jonathan K. Kummerfeld, Kevin Leach, Michael A.\n  Laurenzano, Lingjia Tang, Jason Mars", "title": "An Evaluation Dataset for Intent Classification and Out-of-Scope\n  Prediction", "comments": "Accepted to EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialog systems need to know when a query falls outside their\nrange of supported intents, but current text classification corpora only define\nlabel sets that cover every example. We introduce a new dataset that includes\nqueries that are out-of-scope---i.e., queries that do not fall into any of the\nsystem's supported intents. This poses a new challenge because models cannot\nassume that every query at inference time belongs to a system-supported intent\nclass. Our dataset also covers 150 intent classes over 10 domains, capturing\nthe breadth that a production task-oriented agent must handle. We evaluate a\nrange of benchmark classifiers on our dataset along with several different\nout-of-scope identification schemes. We find that while the classifiers perform\nwell on in-scope intent classification, they struggle to identify out-of-scope\nqueries. Our dataset and evaluation fill an important gap in the field,\noffering a way of more rigorously and realistically benchmarking text\nclassification in task-driven dialog systems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 18:04:56 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Larson", "Stefan", ""], ["Mahendran", "Anish", ""], ["Peper", "Joseph J.", ""], ["Clarke", "Christopher", ""], ["Lee", "Andrew", ""], ["Hill", "Parker", ""], ["Kummerfeld", "Jonathan K.", ""], ["Leach", "Kevin", ""], ["Laurenzano", "Michael A.", ""], ["Tang", "Lingjia", ""], ["Mars", "Jason", ""]]}, {"id": "1909.02041", "submitter": "Lixue Cheng", "authors": "Lixue Cheng, Nikola B. Kovachki, Matthew Welborn, Thomas F. Miller III", "title": "Regression-clustering for Improved Accuracy and Training Cost with\n  Molecular-Orbital-Based Machine Learning", "comments": "31 pages, 10 figures, with an SI", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) in the representation of molecular-orbital-based (MOB)\nfeatures has been shown to be an accurate and transferable approach to the\nprediction of post-Hartree-Fock correlation energies. Previous applications of\nMOB-ML employed Gaussian Process Regression (GPR), which provides good\nprediction accuracy with small training sets; however, the cost of GPR training\nscales cubically with the amount of data and becomes a computational bottleneck\nfor large training sets. In the current work, we address this problem by\nintroducing a clustering/regression/classification implementation of MOB-ML. In\na first step, regression clustering (RC) is used to partition the training data\nto best fit an ensemble of linear regression (LR) models; in a second step,\neach cluster is regressed independently, using either LR or GPR; and in a third\nstep, a random forest classifier (RFC) is trained for the prediction of cluster\nassignments based on MOB feature values. Upon inspection, RC is found to\nrecapitulate chemically intuitive groupings of the frontier molecular orbitals,\nand the combined RC/LR/RFC and RC/GPR/RFC implementations of MOB-ML are found\nto provide good prediction accuracy with greatly reduced wall-clock training\ntimes. For a dataset of thermalized geometries of 7211 organic molecules of up\nto seven heavy atoms, both implementations reach chemical accuracy (1 kcal/mol\nerror) with only 300 training molecules, while providing 35000-fold and\n4500-fold reductions in the wall-clock training time, respectively, compared to\nMOB-ML without clustering. The resulting models are also demonstrated to retain\ntransferability for the prediction of large-molecule energies with only\nsmall-molecule training data. Finally, it is shown that capping the number of\ntraining datapoints per cluster leads to further improvements in prediction\naccuracy with negligible increases in wall-clock training time.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 18:29:30 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 14:27:03 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 17:47:18 GMT"}, {"version": "v4", "created": "Wed, 23 Oct 2019 18:24:21 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Cheng", "Lixue", ""], ["Kovachki", "Nikola B.", ""], ["Welborn", "Matthew", ""], ["Miller", "Thomas F.", "III"]]}, {"id": "1909.02059", "submitter": "Eva Sharma", "authors": "Eva Sharma, Luyang Huang, Zhe Hu and Lu Wang", "title": "An Entity-Driven Framework for Abstractive Summarization", "comments": "Proceedings of the 2019 Empirical Methods in Natural Language\n  Processing Conference and 9th International Joint Conference on Natural\n  Language Processing (EMNLP-IJCNLP-2019) (19 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive summarization systems aim to produce more coherent and concise\nsummaries than their extractive counterparts. Popular neural models have\nachieved impressive results for single-document summarization, yet their\noutputs are often incoherent and unfaithful to the input. In this paper, we\nintroduce SENECA, a novel System for ENtity-drivEn Coherent Abstractive\nsummarization framework that leverages entity information to generate\ninformative and coherent abstracts. Our framework takes a two-step approach:\n(1) an entity-aware content selection module first identifies salient sentences\nfrom the input, then (2) an abstract generation module conducts cross-sentence\ninformation compression and abstraction to generate the final summary, which is\ntrained with rewards to promote coherence, conciseness, and clarity. The two\ncomponents are further connected using reinforcement learning. Automatic\nevaluation shows that our model significantly outperforms previous\nstate-of-the-art on ROUGE and our proposed coherence measures on New York Times\nand CNN/Daily Mail datasets. Human judges further rate our system summaries as\nmore informative and coherent than those by popular summarization models.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:07:29 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Sharma", "Eva", ""], ["Huang", "Luyang", ""], ["Hu", "Zhe", ""], ["Wang", "Lu", ""]]}, {"id": "1909.02060", "submitter": "Tatsunori Hashimoto", "authors": "Yonatan Oren, Shiori Sagawa, Tatsunori B. Hashimoto, Percy Liang", "title": "Distributionally Robust Language Modeling", "comments": "Camera ready version for EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models are generally trained on data spanning a wide range of topics\n(e.g., news, reviews, fiction), but they might be applied to an a priori\nunknown target distribution (e.g., restaurant reviews). In this paper, we first\nshow that training on text outside the test distribution can degrade test\nperformance when using standard maximum likelihood (MLE) training. To remedy\nthis without the knowledge of the test distribution, we propose an approach\nwhich trains a model that performs well over a wide range of potential test\ndistributions. In particular, we derive a new distributionally robust\noptimization (DRO) procedure which minimizes the loss of the model over the\nworst-case mixture of topics with sufficient overlap with the training\ndistribution. Our approach, called topic conditional value at risk (topic\nCVaR), obtains a 5.5 point perplexity reduction over MLE when the language\nmodels are trained on a mixture of Yelp reviews and news and tested only on\nreviews.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:07:33 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Oren", "Yonatan", ""], ["Sagawa", "Shiori", ""], ["Hashimoto", "Tatsunori B.", ""], ["Liang", "Percy", ""]]}, {"id": "1909.02062", "submitter": "Basel Alyafi", "authors": "Basel Alyafi, Oliver Diaz, Robert Marti", "title": "DCGANs for Realistic Breast Mass Augmentation in X-ray Mammography", "comments": "4 pages, 4 figures, SPIE Medical Imaging 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection of breast cancer has a major contribution to curability, and\nusing mammographic images, this can be achieved non-invasively. Supervised deep\nlearning, the dominant CADe tool currently, has played a great role in object\ndetection in computer vision, but it suffers from a limiting property: the need\nof a large amount of labelled data. This becomes stricter when it comes to\nmedical datasets which require high-cost and time-consuming annotations.\nFurthermore, medical datasets are usually imbalanced, a condition that often\nhinders classifiers performance. The aim of this paper is to learn the\ndistribution of the minority class to synthesise new samples in order to\nimprove lesion detection in mammography. Deep Convolutional Generative\nAdversarial Networks (DCGANs) can efficiently generate breast masses. They are\ntrained on increasing-size subsets of one mammographic dataset and used to\ngenerate diverse and realistic breast masses. The effect of including the\ngenerated images and/or applying horizontal and vertical flipping is tested in\nan environment where a 1:10 imbalanced dataset of masses and normal tissue\npatches is classified by a fully-convolutional network. A maximum of ~ 0:09\nimprovement of F1 score is reported by using DCGANs along with flipping\naugmentation over using the original images. We show that DCGANs can be used\nfor synthesising photo-realistic breast mass patches with considerable\ndiversity. It is demonstrated that appending synthetic images in this\nenvironment, along with flipping, outperforms the traditional augmentation\nmethod of flipping solely, offering faster improvements as a function of the\ntraining set size.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:09:49 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Alyafi", "Basel", ""], ["Diaz", "Oliver", ""], ["Marti", "Robert", ""]]}, {"id": "1909.02088", "submitter": "Rohit Patra", "authors": "Arun K. Kuchibhotla and Rohit K. Patra", "title": "On Least Squares Estimation under Heteroscedastic and Heavy-Tailed\n  Errors", "comments": "49 pages, 2 figures, and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider least squares estimation in a general nonparametric regression\nmodel. The rate of convergence of the least squares estimator (LSE) for the\nunknown regression function is well studied when the errors are sub-Gaussian.\nWe find upper bounds on the rates of convergence of the LSE when the errors\nhave uniformly bounded conditional variance and have only finitely many\nmoments. We show that the interplay between the moment assumptions on the\nerror, the metric entropy of the class of functions involved, and the \"local\"\nstructure of the function class around the truth drives the rate of convergence\nof the LSE. We find sufficient conditions on the errors under which the rate of\nthe LSE matches the rate of the LSE under sub-Gaussian error. Our results are\nfinite sample and allow for heteroscedastic and heavy-tailed errors.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:21:02 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 16:58:51 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 22:02:42 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Kuchibhotla", "Arun K.", ""], ["Patra", "Rohit K.", ""]]}, {"id": "1909.02093", "submitter": "John Halloran", "authors": "John T. Halloran and David M. Rocke", "title": "Gradients of Generative Models for Improved Discriminative Analysis of\n  Tandem Mass Spectra", "comments": "13 pages. A partitioned version of this appeared in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tandem mass spectrometry (MS/MS) is a high-throughput technology used\ntoidentify the proteins in a complex biological sample, such as a drop of\nblood. A collection of spectra is generated at the output of the process, each\nspectrum of which is representative of a peptide (protein subsequence) present\nin the original complex sample. In this work, we leverage the log-likelihood\ngradients of generative models to improve the identification of such spectra.\nIn particular, we show that the gradient of a recently proposed dynamic\nBayesian network (DBN) may be naturally employed by a kernel-based\ndiscriminative classifier. The resulting Fisher kernel substantially improves\nupon recent attempts to combine generative and discriminative models for\npost-processing analysis, outperforming all other methods on the evaluated\ndatasets. We extend the improved accuracy offered by the Fisher kernel\nframework to other search algorithms by introducing Theseus, a DBN representing\na large number of widely used MS/MS scoring functions. Furthermore, with\ngradient ascent and max-product inference at hand, we use Theseus to learn\nmodel parameters without any supervision.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:29:04 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Halloran", "John T.", ""], ["Rocke", "David M.", ""]]}, {"id": "1909.02105", "submitter": "Yujia Xie", "authors": "Yujia Xie, Haoming Jiang, Feng Liu, Tuo Zhao, Hongyuan Zha", "title": "Meta Learning with Relational Information for Short Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new meta-learning method -- named HARMLESS (HAwkes\nRelational Meta LEarning method for Short Sequences) for learning heterogeneous\npoint process models from short event sequence data along with a relational\nnetwork. Specifically, we propose a hierarchical Bayesian mixture Hawkes\nprocess model, which naturally incorporates the relational information among\nsequences into point process modeling. Compared with existing methods, our\nmodel can capture the underlying mixed-community patterns of the relational\nnetwork, which simultaneously encourages knowledge sharing among sequences and\nfacilitates adaptive learning for each individual sequence. We further propose\nan efficient stochastic variational meta expectation maximization algorithm\nthat can scale to large problems. Numerical experiments on both synthetic and\nreal data show that HARMLESS outperforms existing methods in terms of\npredicting the future events.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:45:42 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Xie", "Yujia", ""], ["Jiang", "Haoming", ""], ["Liu", "Feng", ""], ["Zhao", "Tuo", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1909.02107", "submitter": "Hao-Jun Shi", "authors": "Hao-Jun Michael Shi, Dheevatsa Mudigere, Maxim Naumov, and Jiyan Yang", "title": "Compositional Embeddings Using Complementary Partitions for\n  Memory-Efficient Recommendation Systems", "comments": "11 pages, 7 figures, 1 table", "journal-ref": null, "doi": "10.1145/3394486.3403059", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning-based recommendation systems exploit hundreds to\nthousands of different categorical features, each with millions of different\ncategories ranging from clicks to posts. To respect the natural diversity\nwithin the categorical data, embeddings map each category to a unique dense\nrepresentation within an embedded space. Since each categorical feature could\ntake on as many as tens of millions of different possible categories, the\nembedding tables form the primary memory bottleneck during both training and\ninference. We propose a novel approach for reducing the embedding size in an\nend-to-end fashion by exploiting complementary partitions of the category set\nto produce a unique embedding vector for each category without explicit\ndefinition. By storing multiple smaller embedding tables based on each\ncomplementary partition and combining embeddings from each table, we define a\nunique embedding for each category at smaller memory cost. This approach may be\ninterpreted as using a specific fixed codebook to ensure uniqueness of each\ncategory's representation. Our experimental results demonstrate the\neffectiveness of our approach over the hashing trick for reducing the size of\nthe embedding tables in terms of model loss and accuracy, while retaining a\nsimilar reduction in the number of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:47:08 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 04:10:00 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Shi", "Hao-Jun Michael", ""], ["Mudigere", "Dheevatsa", ""], ["Naumov", "Maxim", ""], ["Yang", "Jiyan", ""]]}, {"id": "1909.02108", "submitter": "James Stokes", "authors": "James Stokes, Josh Izaac, Nathan Killoran, Giuseppe Carleo", "title": "Quantum Natural Gradient", "comments": "15 pages, 4 figures", "journal-ref": "Quantum 4, 269 (2020)", "doi": "10.22331/q-2020-05-25-269", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A quantum generalization of Natural Gradient Descent is presented as part of\na general-purpose optimization framework for variational quantum circuits. The\noptimization dynamics is interpreted as moving in the steepest descent\ndirection with respect to the Quantum Information Geometry, corresponding to\nthe real part of the Quantum Geometric Tensor (QGT), also known as the\nFubini-Study metric tensor. An efficient algorithm is presented for computing a\nblock-diagonal approximation to the Fubini-Study metric tensor for parametrized\nquantum circuits, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:52:32 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 16:04:25 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 16:42:28 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Stokes", "James", ""], ["Izaac", "Josh", ""], ["Killoran", "Nathan", ""], ["Carleo", "Giuseppe", ""]]}, {"id": "1909.02109", "submitter": "Yingkai Li", "authors": "Yingkai Li, Edmund Y. Lou, Liren Shan", "title": "Stochastic Linear Optimization with Adversarial Corruption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the model of stochastic bandits with adversarial corruption\n(Lykouriset al., 2018) to the stochastic linear optimization problem (Dani et\nal., 2008). Our algorithm is agnostic to the amount of corruption chosen by the\nadaptive adversary. The regret of the algorithm only increases linearly in the\namount of corruption. Our algorithm involves using L\\\"owner-John's ellipsoid\nfor exploration and dividing time horizon into epochs with exponentially\nincreasing size to limit the influence of corruption.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 20:55:00 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Li", "Yingkai", ""], ["Lou", "Edmund Y.", ""], ["Shan", "Liren", ""]]}, {"id": "1909.02115", "submitter": "Ali Sharifara", "authors": "Razieh Tavakoli, Mohammad Najafi and Ali Sharifara", "title": "Artificial Neural Networks and Adaptive Neuro-fuzzy Models for\n  Prediction of Remaining Useful Life", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The U.S. water distribution system contains thousands of miles of pipes\nconstructed from different materials, and of various sizes, and age. These\npipes suffer from physical, environmental, structural and operational stresses,\ncausing deterioration which eventually leads to their failure. Pipe\ndeterioration results in increased break rates, reduced hydraulic capacity, and\ndetrimental impacts on water quality. Therefore, it is crucial to use accurate\nmodels to forecast deterioration rates along with estimating the remaining\nuseful life of the pipes to implement essential interference plans in order to\nprevent catastrophic failures. This paper discusses a computational model that\nforecasts the RUL of water pipes by applying Artificial Neural Networks (ANNs)\nas well as Adaptive Neural Fuzzy Inference System (ANFIS). These models are\ntrained and tested acquired field data to identify the significant parameters\nthat impact the prediction of RUL. It is concluded that, on average, with\napproximately 10\\% of wall thickness loss in existing cast iron, ductile iron,\nasbestos-cement, and steel water pipes, the reduction of the remaining useful\nlife is approximately 50%\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 01:29:52 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Tavakoli", "Razieh", ""], ["Najafi", "Mohammad", ""], ["Sharifara", "Ali", ""]]}, {"id": "1909.02116", "submitter": "Jiayuan Mao", "authors": "Jiayuan Mao and Xiuming Zhang and Yikai Li and William T. Freeman and\n  Joshua B. Tenenbaum and Jiajun Wu", "title": "Program-Guided Image Manipulators", "comments": "ICCV 2019. First two authors contributed equally. Project page:\n  http://pgim.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are capable of building holistic representations for images at various\nlevels, from local objects, to pairwise relations, to global structures. The\ninterpretation of structures involves reasoning over repetition and symmetry of\nthe objects in the image. In this paper, we present the Program-Guided Image\nManipulator (PG-IM), inducing neuro-symbolic program-like representations to\nrepresent and manipulate images. Given an image, PG-IM detects repeated\npatterns, induces symbolic programs, and manipulates the image using a neural\nnetwork that is guided by the program. PG-IM learns from a single image,\nexploiting its internal statistics. Despite trained only on image inpainting,\nPG-IM is directly capable of extrapolation and regularity editing in a unified\nframework. Extensive experiments show that PG-IM achieves superior performance\non all the tasks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 21:10:47 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Mao", "Jiayuan", ""], ["Zhang", "Xiuming", ""], ["Li", "Yikai", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "1909.02117", "submitter": "Xiaotao Gu", "authors": "Xiyuan Yang, Xiaotao Gu, Sheng Lin, Siliang Tang, Yueting Zhuang, Fei\n  Wu, Zhigang Chen, Guoping Hu, Xiang Ren", "title": "Learning Dynamic Context Augmentation for Global Entity Linking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite of the recent success of collective entity linking (EL) methods,\nthese \"global\" inference methods may yield sub-optimal results when the\n\"all-mention coherence\" assumption breaks, and often suffer from high\ncomputational cost at the inference stage, due to the complex search space. In\nthis paper, we propose a simple yet effective solution, called Dynamic Context\nAugmentation (DCA), for collective EL, which requires only one pass through the\nmentions in a document. DCA sequentially accumulates context information to\nmake efficient, collective inference, and can cope with different local EL\nmodels as a plug-and-enhance module. We explore both supervised and\nreinforcement learning strategies for learning the DCA model. Extensive\nexperiments show the effectiveness of our model with different learning\nsettings, base models, decision orders and attention mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 21:13:23 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Yang", "Xiyuan", ""], ["Gu", "Xiaotao", ""], ["Lin", "Sheng", ""], ["Tang", "Siliang", ""], ["Zhuang", "Yueting", ""], ["Wu", "Fei", ""], ["Chen", "Zhigang", ""], ["Hu", "Guoping", ""], ["Ren", "Xiang", ""]]}, {"id": "1909.02119", "submitter": "Subho Sankar Banerjee", "authors": "Subho S Banerjee, Saurabh Jha, Zbigniew T. Kalbarczyk, Ravishankar K.\n  Iyer", "title": "Inductive-bias-driven Reinforcement Learning For Efficient Schedules in\n  Heterogeneous Clusters", "comments": "Scheduling, Bayesian, POMDP, Sampling, Deep Reinforcement Learning,\n  Accelerators, FPGA, GPU", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of scheduling of workloads onto heterogeneous processors (e.g.,\nCPUs, GPUs, FPGAs) is of fundamental importance in modern data centers. Current\nsystem schedulers rely on application/system-specific heuristics that have to\nbe built on a case-by-case basis. Recent work has demonstrated ML techniques\nfor automating the heuristic search by using black-box approaches which require\nsignificant training data and time, which make them challenging to use in\npractice. This paper presents Symphony, a scheduling framework that addresses\nthe challenge in two ways: (i) a domain-driven Bayesian reinforcement learning\n(RL) model for scheduling, which inherently models the resource dependencies\nidentified from the system architecture; and (ii) a sampling-based technique to\ncompute the gradients of a Bayesian model without performing full probabilistic\ninference. Together, these techniques reduce both the amount of training data\nand the time required to produce scheduling policies that significantly\noutperform black-box approaches by up to 2.2x.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 21:19:14 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 11:10:04 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Banerjee", "Subho S", ""], ["Jha", "Saurabh", ""], ["Kalbarczyk", "Zbigniew T.", ""], ["Iyer", "Ravishankar K.", ""]]}, {"id": "1909.02128", "submitter": "Yuchen Lu", "authors": "Philip Paquette, Yuchen Lu, Steven Bocco, Max O. Smith, Satya\n  Ortiz-Gagne, Jonathan K. Kummerfeld, Satinder Singh, Joelle Pineau, Aaron\n  Courville", "title": "No Press Diplomacy: Modeling Multi-Agent Gameplay", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diplomacy is a seven-player non-stochastic, non-cooperative game, where\nagents acquire resources through a mix of teamwork and betrayal. Reliance on\ntrust and coordination makes Diplomacy the first non-cooperative multi-agent\nbenchmark for complex sequential social dilemmas in a rich environment. In this\nwork, we focus on training an agent that learns to play the No Press version of\nDiplomacy where there is no dedicated communication channel between players. We\npresent DipNet, a neural-network-based policy model for No Press Diplomacy. The\nmodel was trained on a new dataset of more than 150,000 human games. Our model\nis trained by supervised learning (SL) from expert trajectories, which is then\nused to initialize a reinforcement learning (RL) agent trained through\nself-play. Both the SL and RL agents demonstrate state-of-the-art No Press\nperformance by beating popular rule-based bots.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 21:48:04 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 19:32:29 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Paquette", "Philip", ""], ["Lu", "Yuchen", ""], ["Bocco", "Steven", ""], ["Smith", "Max O.", ""], ["Ortiz-Gagne", "Satya", ""], ["Kummerfeld", "Jonathan K.", ""], ["Singh", "Satinder", ""], ["Pineau", "Joelle", ""], ["Courville", "Aaron", ""]]}, {"id": "1909.02129", "submitter": "Jialiang Zhao", "authors": "Jialiang Zhao, Jacky Liang, and Oliver Kroemer", "title": "Towards Precise Robotic Grasping by Probabilistic Post-grasp\n  Displacement Estimation", "comments": "Submitted and accepted to 12th Conference on Field and Service\n  Robotics (FSR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise robotic grasping is important for many industrial applications, such\nas assembly and palletizing, where the location of the object needs to be\ncontrolled and known. However, achieving precise grasps is challenging due to\nnoise in sensing and control, as well as unknown object properties. We propose\na method to plan robotic grasps that are both robust and precise by training\ntwo convolutional neural networks - one to predict the robustness of a grasp\nand another to predict a distribution of post-grasp object displacements. Our\nnetworks are trained with depth images in simulation on a dataset of over 1000\nindustrial parts and were successfully deployed on a real robot without having\nto be further fine-tuned. The proposed displacement estimator achieves a mean\nprediction errors of 0.68cm and 3.42deg on novel objects in real world\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 21:50:03 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Zhao", "Jialiang", ""], ["Liang", "Jacky", ""], ["Kroemer", "Oliver", ""]]}, {"id": "1909.02136", "submitter": "John Halloran", "authors": "John T. Halloran and David M. Rocke", "title": "Learning Concave Conditional Likelihood Models for Improved Analysis of\n  Tandem Mass Spectra", "comments": "16 pages. A partitioned version of this appeared in NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most widely used technology to identify the proteins present in a complex\nbiological sample is tandem mass spectrometry, which quickly produces a large\ncollection of spectra representative of the peptides (i.e., protein\nsubsequences) present in the original sample. In this work, we greatly expand\nthe parameter learning capabilities of a dynamic Bayesian network (DBN)\npeptide-scoring algorithm, Didea, by deriving emission distributions for which\nits conditional log-likelihood scoring function remains concave. We show that\nthis class of emission distributions, called Convex Virtual Emissions (CVEs),\nnaturally generalizes the log-sum-exp function while rendering both maximum\nlikelihood estimation and conditional maximum likelihood estimation concave for\na wide range of Bayesian networks. Utilizing CVEs in Didea allows efficient\nlearning of a large number of parameters while ensuring global convergence, in\nstark contrast to Didea's previous parameter learning framework (which could\nonly learn a single parameter using a costly grid search) and other trainable\nmodels (which only ensure convergence to local optima). The newly trained\nscoring function substantially outperforms the state-of-the-art in both scoring\nfunction accuracy and downstream Fisher kernel analysis. Furthermore, we\nsignificantly improve Didea's runtime performance through successive\noptimizations to its message passing schedule and derive explicit connections\nbetween Didea's new concave score and related MS/MS scoring functions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 22:27:10 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Halloran", "John T.", ""], ["Rocke", "David M.", ""]]}, {"id": "1909.02157", "submitter": "Richard Jiang", "authors": "Gary Storey, Ahmed Bouridane, Richard Jiang and Chang-tsun Li", "title": "Atypical Facial Landmark Localisation with Stacked Hourglass Networks: A\n  Study on 3D Facial Modelling for Medical Diagnosis", "comments": "In press, 2019", "journal-ref": "Deep Biometrics, Springer Book, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While facial biometrics has been widely used for identification purpose, it\nhas recently been researched as medical biometrics for a range of diseases. In\nthis chapter, we investigate the facial landmark detection for atypical 3D\nfacial modelling in facial palsy cases, while potentially such modelling can\nassist the medical diagnosis using atypical facial features. In our work, a\nstudy of landmarks localisation methods such as stacked hourglass networks is\nconducted and evaluated to ascertain their accuracy when presented with unseen\natypical faces. The evaluation highlights that the state-of-the-art stacked\nhourglass architecture outperforms other traditional methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 00:08:28 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Storey", "Gary", ""], ["Bouridane", "Ahmed", ""], ["Jiang", "Richard", ""], ["Li", "Chang-tsun", ""]]}, {"id": "1909.02159", "submitter": "Justin Chen", "authors": "Justin Chen, Christopher Eur, Greg Yang, Mengyuan Zhang", "title": "Free resolutions of function classes via order complexes", "comments": "18 pages with figures. Final journal version, to appear in Advances\n  in Applied Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AC cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Function classes are collections of Boolean functions on a finite set, which\nare fundamental objects of study in theoretical computer science. We study\nalgebraic properties of ideals associated to function classes previously\ndefined by the third author. We consider the broad family of\nintersection-closed function classes, and describe cellular free resolutions of\ntheir ideals by order complexes of the associated posets. For function classes\narising from matroids, polyhedral cell complexes, and more generally interval\nCohen-Macaulay posets, we show that the multigraded Betti numbers are pure, and\nare given combinatorially by the M\\\"obius functions. We then apply our methods\nto derive bounds on the VC dimension of some important families of function\nclasses in learning theory.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 00:17:27 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 19:30:30 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Chen", "Justin", ""], ["Eur", "Christopher", ""], ["Yang", "Greg", ""], ["Zhang", "Mengyuan", ""]]}, {"id": "1909.02180", "submitter": "Bo Wang", "authors": "Jiabin Liu, Bo Wang, Zhiquan Qi, Yingjie Tian, Yong Shi", "title": "Learning from Label Proportions with Generative Adversarial Networks", "comments": "Accepted as a conference paper at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we leverage generative adversarial networks (GANs) to derive\nan effective algorithm LLP-GAN for learning from label proportions (LLP), where\nonly the bag-level proportional information in labels is available. Endowed\nwith end-to-end structure, LLP-GAN performs approximation in the light of an\nadversarial learning mechanism, without imposing restricted assumptions on\ndistribution. Accordingly, we can directly induce the final instance-level\nclassifier upon the discriminator. Under mild assumptions, we give the explicit\ngenerative representation and prove the global optimality for LLP-GAN.\nAdditionally, compared with existing methods, our work empowers LLP solver with\ncapable scalability inheriting from deep models. Several experiments on\nbenchmark datasets demonstrate vivid advantages of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 01:55:35 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 06:44:27 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 04:43:15 GMT"}, {"version": "v4", "created": "Mon, 2 Dec 2019 09:01:27 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Liu", "Jiabin", ""], ["Wang", "Bo", ""], ["Qi", "Zhiquan", ""], ["Tian", "Yingjie", ""], ["Shi", "Yong", ""]]}, {"id": "1909.02187", "submitter": "Shiyin Lu", "authors": "Shiyin Lu, Lijun Zhang", "title": "Adaptive and Efficient Algorithms for Tracking the Best Expert", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of prediction with expert advice in\ndynamic environments. We choose tracking regret as the performance metric and\ndevelop two adaptive and efficient algorithms with data-dependent tracking\nregret bounds. The first algorithm achieves a second-order tracking regret\nbound, which improves existing first-order bounds. The second algorithm enjoys\na path-length bound, which is generally not comparable to the second-order\nbound but offers advantages in slowly moving environments. Both algorithms are\ndeveloped under the online mirror descent framework and draw inspiration from\nexisting algorithms that attain data-dependent bounds of static regret. The key\nidea is to use a clipped simplex in the updating step of online mirror descent.\nFinally, we extend our algorithms and analysis to online matrix prediction and\nprovide the first data-dependent tracking regret bound for this problem.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 02:22:24 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 07:49:32 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lu", "Shiyin", ""], ["Zhang", "Lijun", ""]]}, {"id": "1909.02190", "submitter": "Jiazhen Gu", "authors": "Jiazhen Gu, Huanlin Xu, Yangfan Zhou, Xin Wang, Hui Xu, Michael Lyu", "title": "Detecting Deep Neural Network Defects with Data Flow Analysis", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are shown to be promising solutions in many\nchallenging artificial intelligence tasks. However, it is very hard to figure\nout whether the low precision of a DNN model is an inevitable result, or caused\nby defects. This paper aims at addressing this challenging problem. We find\nthat the internal data flow footprints of a DNN model can provide insights to\nlocate the root cause effectively. We develop DeepMorph (DNN Tomography) to\nanalyze the root cause, which can guide a DNN developer to improve the model.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 02:56:33 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 14:49:21 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gu", "Jiazhen", ""], ["Xu", "Huanlin", ""], ["Zhou", "Yangfan", ""], ["Wang", "Xin", ""], ["Xu", "Hui", ""], ["Lyu", "Michael", ""]]}, {"id": "1909.02197", "submitter": "Sneha Kudugunta", "authors": "Sneha Reddy Kudugunta, Ankur Bapna, Isaac Caswell, Naveen Arivazhagan,\n  Orhan Firat", "title": "Investigating Multilingual NMT Representations at Scale", "comments": "Paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual Neural Machine Translation (NMT) models have yielded large\nempirical success in transfer learning settings. However, these black-box\nrepresentations are poorly understood, and their mode of transfer remains\nelusive. In this work, we attempt to understand massively multilingual NMT\nrepresentations (with 103 languages) using Singular Value Canonical Correlation\nAnalysis (SVCCA), a representation similarity framework that allows us to\ncompare representations across different languages, layers and models. Our\nanalysis validates several empirical results and long-standing intuitions, and\nunveils new observations regarding how representations evolve in a multilingual\ntranslation model. We draw three major conclusions from our analysis, with\nimplications on cross-lingual transfer learning: (i) Encoder representations of\ndifferent languages cluster based on linguistic similarity, (ii)\nRepresentations of a source language learned by the encoder are dependent on\nthe target language, and vice-versa, and (iii) Representations of high resource\nand/or linguistically similar languages are more robust when fine-tuning on an\narbitrary language pair, which is critical to determining how much\ncross-lingual transfer can be expected in a zero or few-shot setting. We\nfurther connect our findings with existing empirical observations in\nmultilingual NMT and transfer learning.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 03:32:48 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 23:43:09 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Kudugunta", "Sneha Reddy", ""], ["Bapna", "Ankur", ""], ["Caswell", "Isaac", ""], ["Arivazhagan", "Naveen", ""], ["Firat", "Orhan", ""]]}, {"id": "1909.02214", "submitter": "Bohan Zhuang", "authors": "Yifan Liu, Bohan Zhuang, Chunhua Shen, Hao Chen, Wei Yin", "title": "Auxiliary Learning for Deep Multi-task Learning", "comments": "First two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) is an efficient solution to solve multiple tasks\nsimultaneously in order to get better speed and performance than handling each\nsingle-task in turn. The most current methods can be categorized as either: (i)\nhard parameter sharing where a subset of the parameters is shared among tasks\nwhile other parameters are task-specific; or (ii) soft parameter sharing where\nall parameters are task-specific but they are jointly regularized. Both methods\nsuffer from limitations: the shared hidden layers of the former are difficult\nto optimize due to the competing objectives while the complexity of the latter\ngrows linearly with the increasing number of tasks. To mitigate those\ndrawbacks, this paper proposes an alternative, where we explicitly construct an\nauxiliary module to mimic the soft parameter sharing for assisting the\noptimization of the hard parameter sharing layers in the training phase. In\nparticular, the auxiliary module takes the outputs of the shared hidden layers\nas inputs and is supervised by the auxiliary task loss. During training, the\nauxiliary module is jointly optimized with the MTL network, serving as a\nregularization by introducing an inductive bias to the shared layers. In the\ntesting phase, only the original MTL network is kept. Thus our method avoids\nthe limitation of both categories. We evaluate the proposed auxiliary module on\npixel-wise prediction tasks, including semantic segmentation, depth estimation,\nand surface normal prediction with different network structures. The extensive\nexperiments over various settings verify the effectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 05:29:15 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 01:46:55 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Liu", "Yifan", ""], ["Zhuang", "Bohan", ""], ["Shen", "Chunhua", ""], ["Chen", "Hao", ""], ["Yin", "Wei", ""]]}, {"id": "1909.02218", "submitter": "Hongyang Xue", "authors": "Hongyang Xue, Wenqing Chu, Zhou Zhao, Deng Cai", "title": "A Better Way to Attend: Attention with Trees for Video Question\n  Answering", "comments": "12 pages", "journal-ref": "IEEE Transactions on Image Processing ( Volume: 27 , Issue: 11 ,\n  Nov. 2018 )", "doi": "10.1109/TIP.2018.2859820", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new attention model for video question answering. The main idea\nof the attention models is to locate on the most informative parts of the\nvisual data. The attention mechanisms are quite popular these days. However,\nmost existing visual attention mechanisms regard the question as a whole. They\nignore the word-level semantics where each word can have different attentions\nand some words need no attention. Neither do they consider the semantic\nstructure of the sentences. Although the Extended Soft Attention (E-SA) model\nfor video question answering leverages the word-level attention, it performs\npoorly on long question sentences. In this paper, we propose the heterogeneous\ntree-structured memory network (HTreeMN) for video question answering. Our\nproposed approach is based upon the syntax parse trees of the question\nsentences. The HTreeMN treats the words differently where the \\textit{visual}\nwords are processed with an attention module and the \\textit{verbal} ones not.\nIt also utilizes the semantic structure of the sentences by combining the\nneighbors based on the recursive structure of the parse trees. The\nunderstandings of the words and the videos are propagated and merged from\nleaves to the root. Furthermore, we build a hierarchical attention mechanism to\ndistill the attended features. We evaluate our approach on two datasets. The\nexperimental results show the superiority of our HTreeMN model over the other\nattention models especially on complex questions. Our code is available on\ngithub.\n  Our code is available at https://github.com/ZJULearning/TreeAttention\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 05:48:51 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Xue", "Hongyang", ""], ["Chu", "Wenqing", ""], ["Zhao", "Zhou", ""], ["Cai", "Deng", ""]]}, {"id": "1909.02244", "submitter": "Xiujun Li", "authors": "Xiujun Li and Chunyuan Li and Qiaolin Xia and Yonatan Bisk and Asli\n  Celikyilmaz and Jianfeng Gao and Noah Smith and Yejin Choi", "title": "Robust Navigation with Language Pretraining and Stochastic Sampling", "comments": "8 pages, 4 figures, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Core to the vision-and-language navigation (VLN) challenge is building robust\ninstruction representations and action decoding schemes, which can generalize\nwell to previously unseen instructions and environments. In this paper, we\nreport two simple but highly effective methods to address these challenges and\nlead to a new state-of-the-art performance. First, we adapt large-scale\npretrained language models to learn text representations that generalize better\nto previously unseen instructions. Second, we propose a stochastic sampling\nscheme to reduce the considerable gap between the expert actions in training\nand sampled actions in test, so that the agent can learn to correct its own\nmistakes during long sequential action decoding. Combining the two techniques,\nwe achieve a new state of the art on the Room-to-Room benchmark with 6%\nabsolute gain over the previous best result (47% -> 53%) on the Success Rate\nweighted by Path Length metric.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 07:31:58 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Li", "Xiujun", ""], ["Li", "Chunyuan", ""], ["Xia", "Qiaolin", ""], ["Bisk", "Yonatan", ""], ["Celikyilmaz", "Asli", ""], ["Gao", "Jianfeng", ""], ["Smith", "Noah", ""], ["Choi", "Yejin", ""]]}, {"id": "1909.02249", "submitter": "Sanjaya Lohani", "authors": "Sanjaya Lohani and Ryan T. Glasser", "title": "Generative Machine Learning for Robust Free-Space Communication", "comments": "9 pages, 5 figures", "journal-ref": "Commun Phys 3, 177 (2020)", "doi": "10.1038/s42005-020-00444-9", "report-no": null, "categories": "eess.SP cs.LG physics.optics quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realistic free-space optical communications systems suffer from turbulent\npropagation of light through the atmosphere and detector noise at the receiver,\nwhich can significantly degrade the optical mode quality of the received state,\nincrease cross-talk between modes, and correspondingly increase the symbol\nerror ratio (SER) of the system. In order to overcome these obstacles, we\ndevelop a state-of-the-art generative machine learning (GML) and convolutional\nneural network (CNN) system in combination, and demonstrate its efficacy in a\nfree-space optical (FSO) communications setting. The system corrects for the\ndistortion effects due to turbulence and reduces detector noise, resulting in\nsignificantly lowered SERs and cross-talk at the output of the receiver, while\nrequiring no feedback. This scheme is straightforward to scale, and may provide\na concrete and cost effective technique to establishing long range classical\nand quantum communication links in the near future.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 07:52:14 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Lohani", "Sanjaya", ""], ["Glasser", "Ryan T.", ""]]}, {"id": "1909.02251", "submitter": "Kei Takemura", "authors": "Kei Takemura and Shinji Ito", "title": "An Arm-Wise Randomization Approach to Combinatorial Linear Semi-Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial linear semi-bandits (CLS) are widely applicable frameworks of\nsequential decision-making, in which a learner chooses a subset of arms from a\ngiven set of arms associated with feature vectors. Existing algorithms work\npoorly for the clustered case, in which the feature vectors form several large\nclusters. This shortcoming is critical in practice because it can be found in\nmany applications, including recommender systems. In this paper, we clarify why\nsuch a shortcoming occurs, and we introduce a key technique of arm-wise\nrandomization to overcome it. We propose two algorithms with this technique:\nthe perturbed C${}^2$UCB (PC${}^2$UCB) and the Thompson sampling (TS). Our\nempirical evaluation with artificial and real-world datasets demonstrates that\nthe proposed algorithms with the arm-wise randomization technique outperform\nthe existing algorithms without this technique, especially for the clustered\ncase. Our contributions also include theoretical analyses that provide high\nprobability asymptotic regret bounds for our algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 08:04:08 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 11:40:42 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Takemura", "Kei", ""], ["Ito", "Shinji", ""]]}, {"id": "1909.02253", "submitter": "Chris Wendler", "authors": "Chris Wendler and Dan Alistarh and Markus P\\\"uschel", "title": "Powerset Convolutional Neural Networks", "comments": "Advances in Neural Information Processing Systems 32", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel class of convolutional neural networks (CNNs) for set\nfunctions, i.e., data indexed with the powerset of a finite set. The\nconvolutions are derived as linear, shift-equivariant functions for various\nnotions of shifts on set functions. The framework is fundamentally different\nfrom graph convolutions based on the Laplacian, as it provides not one but\nseveral basic shifts, one for each element in the ground set. Prototypical\nexperiments with several set function classification tasks on synthetic\ndatasets and on datasets derived from real-world hypergraphs demonstrate the\npotential of our new powerset CNNs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 08:08:40 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 21:58:31 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 08:44:00 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 10:11:40 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Wendler", "Chris", ""], ["Alistarh", "Dan", ""], ["P\u00fcschel", "Markus", ""]]}, {"id": "1909.02261", "submitter": "Olivier Goudet Dr", "authors": "Olivier Goudet, B\\'eatrice Duval, Jin-Kao Hao", "title": "Population-based Gradient Descent Weight Learning for Graph Coloring\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph coloring involves assigning colors to the vertices of a graph such that\ntwo vertices linked by an edge receive different colors. Graph coloring\nproblems are general models that are very useful to formulate many relevant\napplications and, however, are computationally difficult. In this work, a\ngeneral population-based weight learning framework for solving graph coloring\nproblems is presented. Unlike existing methods for graph coloring that are\nspecific to the considered problem, the presented work targets a generic\nobjective by introducing a unified method that can be applied to different\ngraph coloring problems. This work distinguishes itself by its solving approach\nthat formulates the search of a solution as a continuous weight tensor\noptimization problem and takes advantage of a gradient descent method computed\nin parallel on graphics processing units. The proposed approach is also\ncharacterized by its general global loss function that can easily be adapted to\ndifferent graph coloring problems. The usefulness of the proposed approach is\ndemonstrated by applying it to solve two typical graph coloring problems and\nperforming large computational studies on popular benchmarks. Improved\nbest-known results (new upper bounds) are reported for several large graphs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 08:41:11 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 17:19:12 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 08:05:02 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 14:13:42 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Goudet", "Olivier", ""], ["Duval", "B\u00e9atrice", ""], ["Hao", "Jin-Kao", ""]]}, {"id": "1909.02291", "submitter": "Yu Chen", "authors": "Yu Chen and Yingfeng Chen and Zhipeng Hu and Tianpei Yang and Changjie\n  Fan and Yang Yu and Jianye Hao", "title": "Learning Action-Transferable Policy with Action Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning (TL) is a promising way to improve the sample efficiency of\nreinforcement learning. However, how to efficiently transfer knowledge across\ntasks with different state-action spaces is investigated at an early stage.\nMost previous studies only addressed the inconsistency across different state\nspaces by learning a common feature space, without considering that similar\nactions in different action spaces of related tasks share similar semantics. In\nthis paper, we propose a method to learning action embeddings by leveraging\nthis idea, and a framework that learns both state embeddings and action\nembeddings to transfer policy across tasks with different state and action\nspaces. Our experimental results on various tasks show that the proposed method\ncan not only learn informative action embeddings but accelerate policy\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 10:02:29 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 06:19:08 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 12:24:33 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Chen", "Yu", ""], ["Chen", "Yingfeng", ""], ["Hu", "Zhipeng", ""], ["Yang", "Tianpei", ""], ["Fan", "Changjie", ""], ["Yu", "Yang", ""], ["Hao", "Jianye", ""]]}, {"id": "1909.02307", "submitter": "Laura Rettig", "authors": "Laura Rettig, Julien Audiffren, Philippe Cudr\\'e-Mauroux", "title": "Fusing Vector Space Models for Domain-Specific Applications", "comments": "ICTAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of tuning word embeddings for specific use cases and\ndomains. We propose a new method that automatically combines multiple\ndomain-specific embeddings, selected from a wide range of pre-trained\ndomain-specific embeddings, to improve their combined expressive power. Our\napproach relies on two key components: 1) a ranking function, based on a new\nembedding similarity measure, that selects the most relevant embeddings to use\ngiven a domain and 2) a dimensionality reduction method that combines the\nselected embeddings to produce a more compact and efficient encoding that\npreserves the expressiveness. We empirically show that our method produces\neffective domain-specific embeddings that consistently improve the performance\nof state-of-the-art machine learning algorithms on multiple tasks, compared to\ngeneric embeddings trained on large text corpora.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 10:34:07 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Rettig", "Laura", ""], ["Audiffren", "Julien", ""], ["Cudr\u00e9-Mauroux", "Philippe", ""]]}, {"id": "1909.02309", "submitter": "Dakuo Wang", "authors": "Dakuo Wang, Justin D. Weisz, Michael Muller, Parikshit Ram, Werner\n  Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, Alexander Gray", "title": "Human-AI Collaboration in Data Science: Exploring Data Scientists'\n  Perceptions of Automated AI", "comments": null, "journal-ref": null, "doi": "10.1145/3359313", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid advancement of artificial intelligence (AI) is changing our lives\nin many ways. One application domain is data science. New techniques in\nautomating the creation of AI, known as AutoAI or AutoML, aim to automate the\nwork practices of data scientists. AutoAI systems are capable of autonomously\ningesting and pre-processing data, engineering new features, and creating and\nscoring models based on a target objectives (e.g. accuracy or run-time\nefficiency). Though not yet widely adopted, we are interested in understanding\nhow AutoAI will impact the practice of data science. We conducted interviews\nwith 20 data scientists who work at a large, multinational technology company\nand practice data science in various business settings. Our goal is to\nunderstand their current work practices and how these practices might change\nwith AutoAI. Reactions were mixed: while informants expressed concerns about\nthe trend of automating their jobs, they also strongly felt it was inevitable.\nDespite these concerns, they remained optimistic about their future job\nsecurity due to a view that the future of data science work will be a\ncollaboration between humans and AI systems, in which both automation and human\nexpertise are indispensable.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 10:39:37 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Wang", "Dakuo", ""], ["Weisz", "Justin D.", ""], ["Muller", "Michael", ""], ["Ram", "Parikshit", ""], ["Geyer", "Werner", ""], ["Dugan", "Casey", ""], ["Tausczik", "Yla", ""], ["Samulowitz", "Horst", ""], ["Gray", "Alexander", ""]]}, {"id": "1909.02330", "submitter": "Rui (Ray) Zhang", "authors": "Rui Ray Zhang, Xingwu Liu, Yuyi Wang, Liwei Wang", "title": "McDiarmid-Type Inequalities for Graph-Dependent Variables and Stability\n  Bounds", "comments": "accepted as NeurIPS 2019 spotlight paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial assumption in most statistical learning theory is that samples are\nindependently and identically distributed (i.i.d.). However, for many real\napplications, the i.i.d. assumption does not hold. We consider learning\nproblems in which examples are dependent and their dependency relation is\ncharacterized by a graph. To establish algorithm-dependent generalization\ntheory for learning with non-i.i.d. data, we first prove novel McDiarmid-type\nconcentration inequalities for Lipschitz functions of graph-dependent random\nvariables. We show that concentration relies on the forest complexity of the\ngraph, which characterizes the strength of the dependency. We demonstrate that\nfor many types of dependent data, the forest complexity is small and thus\nimplies good concentration. Based on our new inequalities we are able to build\nstability bounds for learning from graph-dependent data.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 11:30:24 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 14:54:13 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhang", "Rui Ray", ""], ["Liu", "Xingwu", ""], ["Wang", "Yuyi", ""], ["Wang", "Liwei", ""]]}, {"id": "1909.02333", "submitter": "Tin Lai", "authors": "Tin Lai, Weiming Zhi, Fabio Ramos", "title": "Occ-Traj120: Occupancy Maps with Associated Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Trajectory modelling had been the principal research area for understanding\nand anticipating human behaviour. Predicting the dynamic path by observing the\nagent and its surrounding environment are essential for applications such as\nautonomous driving and indoor navigation suggestions. However, despite the\nnumerous researches that had been presented, most available dataset does not\ncontains any information on environmental factors---such as the occupancy\nrepresentation of the map---which arguably plays a significant role on how an\nagent chooses its trajectory.\n  We present a trajectory dataset with the corresponding occupancy\nrepresentations of different local-maps. The dataset contains more than 120\nlocally-structured maps with occupancy representation and more than 110K\ntrajectories in total. Each map has few hundred corresponding simulated\ntrajectories that navigate from a spatial location of a room to another point.\nThe dataset is freely available online.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 11:40:26 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 05:51:16 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lai", "Tin", ""], ["Zhi", "Weiming", ""], ["Ramos", "Fabio", ""]]}, {"id": "1909.02341", "submitter": "Gianluigi Pillonetto Dr.", "authors": "Mauro Bisiacco and Gianluigi Pillonetto", "title": "Kernel absolute summability is only sufficient for RKHS stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized approaches have been successfully applied to linear system\nidentification in recent years. Many of them model unknown impulse responses\nexploiting the so called Reproducing Kernel Hilbert spaces (RKHSs) that enjoy\nthe notable property of being in one-to-one correspondence with the class of\npositive semidefinite kernels. The necessary and sufficient condition for a\nRKHS to be stable, i.e. to contain only BIBO stable linear dynamic systems, has\nbeen known in the literature at least since 2006. However, an open question\nstill persists and concerns the equivalence of such condition with the absolute\nsummability of the kernel. This paper provides a definite answer to this matter\nby proving that such correspondence does not hold. A counterexample is\nintroduced that illustrates the existence of stable RKHSs that are induced by\nnon-absolutely summable kernels.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 11:57:52 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Bisiacco", "Mauro", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1909.02344", "submitter": "Xueying Shi", "authors": "Xueying Shi, Qi Dou, Cheng Xue, Jing Qin, Hao Chen, Pheng-Ann Heng", "title": "An Active Learning Approach for Reducing Annotation Cost in Skin Lesion\n  Analysis", "comments": "Accepted by MIML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated skin lesion analysis is very crucial in clinical practice, as skin\ncancer is among the most common human malignancy. Existing approaches with deep\nlearning have achieved remarkable performance on this challenging task,\nhowever, heavily relying on large-scale labelled datasets. In this paper, we\npresent a novel active learning framework for cost-effective skin lesion\nanalysis. The goal is to effectively select and utilize much fewer labelled\nsamples, while the network can still achieve state-of-the-art performance. Our\nsample selection criteria complementarily consider both informativeness and\nrepresentativeness, derived from decoupled aspects of measuring model certainty\nand covering sample diversity. To make wise use of the selected samples, we\nfurther design a simple yet effective strategy to aggregate intra-class images\nin pixel space, as a new form of data augmentation. We validate our proposed\nmethod on data of ISIC 2017 Skin Lesion Classification Challenge for two tasks.\nUsing only up to 50% of samples, our approach can achieve state-of-the-art\nperformances on both tasks, which are comparable or exceeding the accuracies\nwith full-data training, and outperform other well-known active learning\nmethods by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:00:01 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Shi", "Xueying", ""], ["Dou", "Qi", ""], ["Xue", "Cheng", ""], ["Qin", "Jing", ""], ["Chen", "Hao", ""], ["Heng", "Pheng-Ann", ""]]}, {"id": "1909.02352", "submitter": "Peilun Wu", "authors": "Peilun Wu, Hui Guo and Richard Buckland", "title": "A Transfer Learning Approach for Network Intrusion Detection", "comments": null, "journal-ref": null, "doi": "10.1109/ICBDA.2019.8713213", "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution Neural Network (ConvNet) offers a high potential to generalize\ninput data. It has been widely used in many application areas, such as visual\nimagery, where comprehensive learning datasets are available and a ConvNet\nmodel can be well trained and perform the required function effectively.\nConvNet can also be applied to network intrusion detection. However, the\ncurrently available datasets related to the network intrusion are often\ninadequate, which makes the ConvNet learning deficient, hence the trained model\nis not competent in detecting unknown intrusions. In this paper, we propose a\nConvNet model using transfer learning for network intrusion detection. The\nmodel consists of two concatenated ConvNets and is built on a two-stage\nlearning process: learning a base dataset and transferring the learned\nknowledge to the learning of the target dataset. Our experiments on the NSL-KDD\ndataset show that the proposed model can improve the detection accuracy not\nonly on the test dataset containing mostly known attacks (KDDTest+) but also on\nthe test dataset featuring many novel attacks (KDDTest-21) -- about 2.68\\%\nimprovement on KDDTest+ and 22.02\\% on KDDTest-21 can be achieved, as compared\nto the traditional ConvNet model.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:11:07 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 16:02:08 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 07:40:59 GMT"}, {"version": "v4", "created": "Wed, 18 Dec 2019 19:14:40 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Wu", "Peilun", ""], ["Guo", "Hui", ""], ["Buckland", "Richard", ""]]}, {"id": "1909.02362", "submitter": "Mehmet Emre Ozfatura", "authors": "Mehdi Salehi Heydar Abad and Emre Ozfatura and Deniz Gunduz and Ozgur\n  Ercetin", "title": "Hierarchical Federated Learning Across Heterogeneous Cellular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study collaborative machine learning (ML) across wireless devices, each\nwith its own local dataset. Offloading these datasets to a cloud or an edge\nserver to implement powerful ML solutions is often not feasible due to latency,\nbandwidth and privacy constraints. Instead, we consider federated edge learning\n(FEEL), where the devices share local updates on the model parameters rather\nthan their datasets. We consider a heterogeneous cellular network (HCN), where\nsmall cell base stations (SBSs) orchestrate FL among the mobile users (MUs)\nwithin their cells, and periodically exchange model updates with the macro base\nstation (MBS) for global consensus. We employ gradient sparsification and\nperiodic averaging to increase the communication efficiency of this\nhierarchical federated learning (FL) framework. We then show using CIFAR-10\ndataset that the proposed hierarchical learning solution can significantly\nreduce the communication latency without sacrificing the model accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:42:38 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Abad", "Mehdi Salehi Heydar", ""], ["Ozfatura", "Emre", ""], ["Gunduz", "Deniz", ""], ["Ercetin", "Ozgur", ""]]}, {"id": "1909.02363", "submitter": "Shantenu Jha", "authors": "Geoffrey Fox, Shantenu Jha", "title": "Understanding ML driven HPC: Applications and Infrastructure", "comments": "Invited talk to \"Visionary Track\" at IEEE eScience 2019. arXiv admin\n  note: text overlap with arXiv:1806.04731 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recently outlined the vision of \"Learning Everywhere\" which captures the\npossibility and impact of how learning methods and traditional HPC methods can\nbe coupled together. A primary driver of such coupling is the promise that\nMachine Learning (ML) will give major performance improvements for traditional\nHPC simulations. Motivated by this potential, the ML around HPC class of\nintegration is of particular significance. In a related follow-up paper, we\nprovided an initial taxonomy for integrating learning around HPC methods. In\nthis paper, which is part of the Learning Everywhere series, we discuss \"how\"\nlearning methods and HPC simulations are being integrated to enhance effective\nperformance of computations. This paper identifies several modes ---\nsubstitution, assimilation, and control, in which learning methods integrate\nwith HPC simulations and provide representative applications in each mode. This\npaper discusses some open research questions and we hope will motivate and\nclear the ground for MLaroundHPC benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:47:48 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Fox", "Geoffrey", ""], ["Jha", "Shantenu", ""]]}, {"id": "1909.02373", "submitter": "Yanbin Liu", "authors": "Yanbin Liu, Makoto Yamada, Yao-Hung Hubert Tsai, Tam Le, Ruslan\n  Salakhutdinov, Yi Yang", "title": "LSMI-Sinkhorn: Semi-supervised Mutual Information Estimation with\n  Optimal Transport", "comments": "ECML/PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating mutual information is an important statistics and machine learning\nproblem. To estimate the mutual information from data, a common practice is\npreparing a set of paired samples $\\{(\\mathbf{x}_i,\\mathbf{y}_i)\\}_{i=1}^n\n\\stackrel{\\mathrm{i.i.d.}}{\\sim} p(\\mathbf{x},\\mathbf{y})$. However, in many\nsituations, it is difficult to obtain a large number of data pairs. To address\nthis problem, we propose the semi-supervised Squared-loss Mutual Information\n(SMI) estimation method using a small number of paired samples and the\navailable unpaired ones. We first represent SMI through the density ratio\nfunction, where the expectation is approximated by the samples from marginals\nand its assignment parameters. The objective is formulated using the optimal\ntransport problem and quadratic programming. Then, we introduce the\nLeast-Squares Mutual Information with Sinkhorn (LSMI-Sinkhorn) algorithm for\nefficient optimization. Through experiments, we first demonstrate that the\nproposed method can estimate the SMI without a large number of paired samples.\nThen, we show the effectiveness of the proposed LSMI-Sinkhorn algorithm on\nvarious types of machine learning problems such as image matching and photo\nalbum summarization. Code can be found at\nhttps://github.com/csyanbin/LSMI-Sinkhorn.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:58:20 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 07:54:10 GMT"}, {"version": "v3", "created": "Sun, 27 Jun 2021 06:34:41 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Liu", "Yanbin", ""], ["Yamada", "Makoto", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Le", "Tam", ""], ["Salakhutdinov", "Ruslan", ""], ["Yang", "Yi", ""]]}, {"id": "1909.02384", "submitter": "Yukuan Yang", "authors": "Yukuan Yang, Shuang Wu, Lei Deng, Tianyi Yan, Yuan Xie, Guoqi Li", "title": "Training High-Performance and Large-Scale Deep Neural Networks with Full\n  8-bit Integers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) quantization converting floating-point (FP) data in\nthe network to integers (INT) is an effective way to shrink the model size for\nmemory saving and simplify the operations for compute acceleration. Recently,\nresearches on DNN quantization develop from inference to training, laying a\nfoundation for the online training on accelerators. However, existing schemes\nleaving batch normalization (BN) untouched during training are mostly\nincomplete quantization that still adopts high precision FP in some parts of\nthe data paths. Currently, there is no solution that can use only low bit-width\nINT data during the whole training process of large-scale DNNs with acceptable\naccuracy. In this work, through decomposing all the computation steps in DNNs\nand fusing three special quantization functions to satisfy the different\nprecision requirements, we propose a unified complete quantization framework\ntermed as ``WAGEUBN'' to quantize DNNs involving all data paths including W\n(Weights), A (Activation), G (Gradient), E (Error), U (Update), and BN.\nMoreover, the Momentum optimizer is also quantized to realize a completely\nquantized framework. Experiments on ResNet18/34/50 models demonstrate that\nWAGEUBN can achieve competitive accuracy on the ImageNet dataset. For the first\ntime, the study of quantization in large-scale DNNs is advanced to the full\n8-bit INT level. In this way, all the operations in the training and inference\ncan be bit-wise operations, pushing towards faster processing speed, decreased\nmemory cost, and higher energy efficiency. Our throughout quantization\nframework has great potential for future efficient portable devices with online\nlearning ability.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:17:38 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 14:31:20 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Yang", "Yukuan", ""], ["Wu", "Shuang", ""], ["Deng", "Lei", ""], ["Yan", "Tianyi", ""], ["Xie", "Yuan", ""], ["Li", "Guoqi", ""]]}, {"id": "1909.02387", "submitter": "Murat Dundar", "authors": "Murat Dundar, Bethany L. Ehlmann, Ellen K. Leask", "title": "Machine-Learning-Driven New Geologic Discoveries at Mars Rover Landing\n  Sites: Jezero and NE Syrtis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.EP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hierarchical Bayesian classifier is trained at pixel scale with spectral\ndata from the CRISM (Compact Reconnaissance Imaging Spectrometer for Mars)\nimagery. Its utility in detecting rare phases is demonstrated with new geologic\ndiscoveries near the Mars-2020 rover landing site. Akaganeite is found in\nsediments on the Jezero crater floor and in fluvial deposits at NE Syrtis.\nJarosite and silica are found on the Jezero crater floor while\nchlorite-smectite and Al phyllosilicates are found in the Jezero crater walls.\nThese detections point to a multi-stage, multi-chemistry history of water in\nJezero crater and the surrounding region and provide new information for\nguiding the Mars-2020 rover's landed exploration. In particular, the\nakaganeite, silica, and jarosite in the floor deposits suggest either a later\nepisode of salty, Fe-rich waters that post-date Jezero delta or groundwater\nalteration of portions of the Jezero sedimentary sequence.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:22:16 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Dundar", "Murat", ""], ["Ehlmann", "Bethany L.", ""], ["Leask", "Ellen K.", ""]]}, {"id": "1909.02391", "submitter": "Hee-Sun Choi Dr.", "authors": "Hee-Sun Choi, Junmo An, Jin-Gyun Kim, Jae-Yoon Jung, Juhwan Choi,\n  Grzegorz Orzechowski, Aki Mikkola, Jin Hwan Choi", "title": "Data-driven simulation for general purpose multibody dynamics using deep\n  neural networks", "comments": "32 pages, 17 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a machine learning-based simulation framework of\ngeneral-purpose multibody dynamics is introduced. The aim of the framework is\nto generate a well-trained meta-model of multibody dynamics (MBD) systems. To\nthis end, deep neural network (DNN) is employed to the framework so as to\nconstruct data-based meta-model representing multibody systems. Constructing\nwell-defined training data set with time variable is essential to get accurate\nand reliable motion data such as displacement, velocity, acceleration, and\nforces. As a result of the introduced approach, the meta-model provides motion\nestimation of system dynamics without solving the analytical equations of\nmotion. The performance of the proposed DNN meta-modeling was evaluated to\nrepresent several MBD systems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 08:47:35 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Choi", "Hee-Sun", ""], ["An", "Junmo", ""], ["Kim", "Jin-Gyun", ""], ["Jung", "Jae-Yoon", ""], ["Choi", "Juhwan", ""], ["Orzechowski", "Grzegorz", ""], ["Mikkola", "Aki", ""], ["Choi", "Jin Hwan", ""]]}, {"id": "1909.02393", "submitter": "Wil van der Aalst", "authors": "Anja F. Syring and Niek Tax and Wil M.P. van der Aalst", "title": "Evaluating Conformance Measures in Process Mining using Conformance\n  Propositions (Extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining sheds new light on the relationship between process models and\nreal-life processes. Process discovery can be used to learn process models from\nevent logs. Conformance checking is concerned with quantifying the quality of a\nbusiness process model in relation to event data that was logged during the\nexecution of the business process. There exist different categories of\nconformance measures. Recall, also called fitness, is concerned with\nquantifying how much of the behavior that was observed in the event log fits\nthe process model. Precision is concerned with quantifying how much behavior a\nprocess model allows for that was never observed in the event log.\nGeneralization is concerned with quantifying how well a process model\ngeneralizes to behavior that is possible in the business process but was never\nobserved in the event log. Many recall, precision, and generalization measures\nhave been developed throughout the years, but they are often defined in an\nad-hoc manner without formally defining the desired properties up front. To\naddress these problems, we formulate 21 conformance propositions and we use\nthese propositions to evaluate current and existing conformance measures. The\ngoal is to trigger a discussion by clearly formulating the challenges and\nrequirements (rather than proposing new measures). Additionally, this paper\nserves as an overview of the conformance checking measures that are available\nin the process mining area.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 19:04:18 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Syring", "Anja F.", ""], ["Tax", "Niek", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "1909.02398", "submitter": "Ruoyu Deng", "authors": "Ruoyu Deng, Na Ruan", "title": "FraudJudger: Real-World Data Oriented Fraud Detection on Digital Payment\n  Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated fraud behaviors detection on electronic payment platforms is a\ntough problem. Fraud users often exploit the vulnerability of payment platforms\nand the carelessness of users to defraud money, steal passwords, do money\nlaundering, etc, which causes enormous losses to digital payment platforms and\nusers. There are many challenges for fraud detection in practice. Traditional\nfraud detection methods require a large-scale manually labeled dataset, which\nis hard to obtain in reality. Manually labeled data cost tremendous human\nefforts. Besides, the continuous and rapid evolution of fraud users makes it\nhard to find new fraud patterns based on existing detection rules. In our work,\nwe propose a real-world data oriented detection paradigm which can detect fraud\nusers and upgrade its detection ability automatically. Based on the new\nparadigm, we design a novel fraud detection model, FraudJudger, to analyze\nusers behaviors on digital payment platforms and detect fraud users with fewer\nlabeled data in training. FraudJudger can learn the latent representations of\nusers from unlabeled data with the help of Adversarial Autoencoder (AAE).\nFurthermore, FraudJudger can find new fraud patterns from unknown users by\ncluster analysis. Our experiment is based on a real-world electronic payment\ndataset. Comparing with other well-known fraud detection methods, FraudJudger\ncan achieve better detection performance with only 10% labeled data.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:31:52 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Deng", "Ruoyu", ""], ["Ruan", "Na", ""]]}, {"id": "1909.02414", "submitter": "Olivier Schwander", "authors": "Daniel Brooks, Olivier Schwander, Frederic Barbaresco, Jean-Yves\n  Schneider, Matthieu Cord", "title": "Riemannian batch normalization for SPD neural networks", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance matrices have attracted attention for machine learning\napplications due to their capacity to capture interesting structure in the\ndata. The main challenge is that one needs to take into account the particular\ngeometry of the Riemannian manifold of symmetric positive definite (SPD)\nmatrices they belong to. In the context of deep networks, several architectures\nfor these matrices have recently been proposed. In our article, we introduce a\nRiemannian batch normalization (batchnorm) algorithm, which generalizes the one\nused in Euclidean nets. This novel layer makes use of geometric operations on\nthe manifold, notably the Riemannian barycenter, parallel transport and\nnon-linear structured matrix transformations. We derive a new\nmanifold-constrained gradient descent algorithm working in the space of SPD\nmatrices, allowing to learn the batchnorm layer. We validate our proposed\napproach with experiments in three different contexts on diverse data types: a\ndrone recognition dataset from radar observations, and on emotion and action\nrecognition datasets from video and motion capture data. Experiments show that\nthe Riemannian batchnorm systematically gives better classification performance\ncompared with leading methods and a remarkable robustness to lack of data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 23:03:50 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 17:13:21 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Brooks", "Daniel", ""], ["Schwander", "Olivier", ""], ["Barbaresco", "Frederic", ""], ["Schneider", "Jean-Yves", ""], ["Cord", "Matthieu", ""]]}, {"id": "1909.02425", "submitter": "Andr\\'es Camero", "authors": "Andr\\'es Camero, Jamal Toutouh, Enrique Alba", "title": "Random Error Sampling-based Recurrent Neural Network Architecture\n  Optimization", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence 96 (2020):\n  103946", "doi": "10.1016/j.engappai.2020.103946", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are good at solving prediction problems. However,\nfinding a network that suits a problem is quite hard because their performance\nis strongly affected by their architecture configuration. Automatic\narchitecture optimization methods help to find the most suitable design, but\nthey are not extensively adopted because of their high computational cost. In\nthis work, we introduce the Random Error Sampling-based Neuroevolution (RESN),\nan evolutionary algorithm that uses the mean absolute error random sampling, a\ntraining-free approach to predict the expected performance of an artificial\nneural network, to optimize the architecture of a network. We empirically\nvalidate our proposal on three prediction problems, and compare our technique\nto training-based architecture optimization techniques and to neuroevolutionary\napproaches. Our findings show that we can achieve state-of-the-art error\nperformance and that we reduce by half the time needed to perform the\noptimization.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 10:38:41 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 21:53:23 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 10:55:38 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Camero", "Andr\u00e9s", ""], ["Toutouh", "Jamal", ""], ["Alba", "Enrique", ""]]}, {"id": "1909.02436", "submitter": "Alfred Laugros", "authors": "Alfred Laugros, Alice Caplier, Matthieu Ospici", "title": "Are Adversarial Robustness and Common Perturbation Robustness\n  Independent Attributes ?", "comments": "To appear in ICCV Workshop on Real-World Recognition from Low-Quality\n  Images and Videos (RLQ) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks have been shown to be sensitive to common perturbations such\nas blur, Gaussian noise, rotations, etc. They are also vulnerable to some\nartificial malicious corruptions called adversarial examples. The adversarial\nexamples study has recently become very popular and it sometimes even reduces\nthe term \"adversarial robustness\" to the term \"robustness\". Yet, we do not know\nto what extent the adversarial robustness is related to the global robustness.\nSimilarly, we do not know if a robustness to various common perturbations such\nas translations or contrast losses for instance, could help with adversarial\ncorruptions. We intend to study the links between the robustnesses of neural\nnetworks to both perturbations. With our experiments, we provide one of the\nfirst benchmark designed to estimate the robustness of neural networks to\ncommon perturbations. We show that increasing the robustness to carefully\nselected common perturbations, can make neural networks more robust to unseen\ncommon perturbations. We also prove that adversarial robustness and robustness\nto common perturbations are independent. Our results make us believe that\nneural network robustness should be addressed in a broader sense.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 14:36:23 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 08:14:58 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Laugros", "Alfred", ""], ["Caplier", "Alice", ""], ["Ospici", "Matthieu", ""]]}, {"id": "1909.02437", "submitter": "Sharath M Shankaranarayana Mr", "authors": "Sharath M. Shankaranarayana and Davor Runje", "title": "ALIME: Autoencoder Based Approach for Local Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and especially deep learning have garneredtremendous\npopularity in recent years due to their increased performanceover other\nmethods. The availability of large amount of data has aidedin the progress of\ndeep learning. Nevertheless, deep learning models areopaque and often seen as\nblack boxes. Thus, there is an inherent need tomake the models interpretable,\nespecially so in the medical domain. Inthis work, we propose a locally\ninterpretable method, which is inspiredby one of the recent tools that has\ngained a lot of interest, called localinterpretable model-agnostic explanations\n(LIME). LIME generates singleinstance level explanation by artificially\ngenerating a dataset aroundthe instance (by randomly sampling and using\nperturbations) and thentraining a local linear interpretable model. One of the\nmajor issues inLIME is the instability in the generated explanation, which is\ncaused dueto the randomly generated dataset. Another issue in these kind of\nlocalinterpretable models is the local fidelity. We propose novel\nmodificationsto LIME by employing an autoencoder, which serves as a better\nweightingfunction for the local model. We perform extensive comparisons\nwithdifferent datasets and show that our proposed method results in\nbothimproved stability, as well as local fidelity.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 13:58:11 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Shankaranarayana", "Sharath M.", ""], ["Runje", "Davor", ""]]}, {"id": "1909.02448", "submitter": "Weizhong Wang", "authors": "Weizhong Wang, Nicholas W. Brady, Chenyao Liao, Youssef A. Fahmy,\n  Ephrem Chemali, Alan C. West, and Matthias Preindl", "title": "High-Fidelity State-of-Charge Estimation of Li-Ion Batteries Using\n  Machine Learning", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a way to augment the existing machine learning algorithm\napplied to state-of-charge estimation by introducing a form of pulse injection\nto the running battery cells. It is believed that the information contained in\nthe pulse responses can be interpreted by a machine learning algorithm whereas\nother techniques are difficult to decode due to the nonlinearity. The\nsensitivity analysis of the amplitude of the current pulse is given through\nsimulation, allowing the researchers to select the appropriate current level\nwith respect to the desired accuracy improvement. A multi-layer feedforward\nneural networks is trained to acquire the nonlinear relationship between the\npulse train and the ground-truth SoC. The experimental data is trained and the\nresults are shown to be promising with less than 2\\% SoC estimation error using\nlayer sizes in the range of 10 - 10,000 trained in 0 - 1 million epochs. The\ntesting procedure specifically designed for the proposed technique is explained\nand provided. The implementation of the proposed strategy is also discussed.\nThe detailed system layout to perform the augmented SoC estimation integrated\nin the existing active balancing hardware has also been given.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 20:04:01 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Wang", "Weizhong", ""], ["Brady", "Nicholas W.", ""], ["Liao", "Chenyao", ""], ["Fahmy", "Youssef A.", ""], ["Chemali", "Ephrem", ""], ["West", "Alan C.", ""], ["Preindl", "Matthias", ""]]}, {"id": "1909.02453", "submitter": "Marius Lindauer", "authors": "Marius Lindauer, Frank Hutter", "title": "Best Practices for Scientific Research on Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a well-performing architecture is often tedious for both DL\npractitioners and researchers, leading to tremendous interest in the automation\nof this task by means of neural architecture search (NAS). Although the\ncommunity has made major strides in developing better NAS methods, the quality\nof scientific empirical evaluations in the young field of NAS is still lacking\nbehind that of other areas of machine learning. To address this issue, we\ndescribe a set of possible issues and ways to avoid them, leading to the NAS\nbest practices checklist available at http://automl.org/nas_checklist.pdf.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 14:39:27 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 08:28:00 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 08:52:42 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Lindauer", "Marius", ""], ["Hutter", "Frank", ""]]}, {"id": "1909.02466", "submitter": "Fang Wan", "authors": "Xiaosong Zhang, Fang Wan, Chang Liu, Rongrong Ji, Qixiang Ye", "title": "FreeAnchor: Learning to Match Anchors for Visual Object Detection", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern CNN-based object detectors assign anchors for ground-truth objects\nunder the restriction of object-anchor Intersection-over-Unit (IoU). In this\nstudy, we propose a learning-to-match approach to break IoU restriction,\nallowing objects to match anchors in a flexible manner. Our approach, referred\nto as FreeAnchor, updates hand-crafted anchor assignment to \"free\" anchor\nmatching by formulating detector training as a maximum likelihood estimation\n(MLE) procedure. FreeAnchor targets at learning features which best explain a\nclass of objects in terms of both classification and localization. FreeAnchor\nis implemented by optimizing detection customized likelihood and can be fused\nwith CNN-based detectors in a plug-and-play manner. Experiments on COCO\ndemonstrate that FreeAnchor consistently outperforms their counterparts with\nsignificant margins.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 14:57:53 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 05:10:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zhang", "Xiaosong", ""], ["Wan", "Fang", ""], ["Liu", "Chang", ""], ["Ji", "Rongrong", ""], ["Ye", "Qixiang", ""]]}, {"id": "1909.02477", "submitter": "Dechun Wang", "authors": "Dechun Wang, Ning Zhang, Xinzi Sun, Pengfei Zhang, Chenxi Zhang, Yu\n  Cao, Benyuan Liu", "title": "AFP-Net: Realtime Anchor-Free Polyp Detection in Colonoscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colorectal cancer (CRC) is a common and lethal disease. Globally, CRC is the\nthird most commonly diagnosed cancer in males and the second in females. For\ncolorectal cancer, the best screening test available is the colonoscopy. During\na colonoscopic procedure, a tiny camera at the tip of the endoscope generates a\nvideo of the internal mucosa of the colon. The video data are displayed on a\nmonitor for the physician to examine the lining of the entire colon and check\nfor colorectal polyps. Detection and removal of colorectal polyps are\nassociated with a reduction in mortality from colorectal cancer. However, the\nmiss rate of polyp detection during colonoscopy procedure is often high even\nfor very experienced physicians. The reason lies in the high variation of polyp\nin terms of shape, size, textural, color and illumination. Though challenging,\nwith the great advances in object detection techniques, automated polyp\ndetection still demonstrates a great potential in reducing the false negative\nrate while maintaining a high precision. In this paper, we propose a novel\nanchor free polyp detector that can localize polyps without using predefined\nanchor boxes. To further strengthen the model, we leverage a Context\nEnhancement Module and Cosine Ground truth Projection. Our approach can respond\nin real time while achieving state-of-the-art performance with 99.36% precision\nand 96.44% recall.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 15:23:34 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 18:13:04 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 17:47:55 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Wang", "Dechun", ""], ["Zhang", "Ning", ""], ["Sun", "Xinzi", ""], ["Zhang", "Pengfei", ""], ["Zhang", "Chenxi", ""], ["Cao", "Yu", ""], ["Liu", "Benyuan", ""]]}, {"id": "1909.02480", "submitter": "Chunting Zhou", "authors": "Xuezhe Ma, Chunting Zhou, Xian Li, Graham Neubig, Eduard Hovy", "title": "FlowSeq: Non-Autoregressive Conditional Sequence Generation with\n  Generative Flow", "comments": "Accepted by EMNLP 2019 (Long Paper)", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most sequence-to-sequence (seq2seq) models are autoregressive; they generate\neach token by conditioning on previously generated tokens. In contrast,\nnon-autoregressive seq2seq models generate all tokens in one pass, which leads\nto increased efficiency through parallel processing on hardware such as GPUs.\nHowever, directly modeling the joint distribution of all tokens simultaneously\nis challenging, and even with increasingly complex model structures accuracy\nlags significantly behind autoregressive models. In this paper, we propose a\nsimple, efficient, and effective model for non-autoregressive sequence\ngeneration using latent variable models. Specifically, we turn to generative\nflow, an elegant technique to model complex distributions using neural\nnetworks, and design several layers of flow tailored for modeling the\nconditional density of sequential latent variables. We evaluate this model on\nthree neural machine translation (NMT) benchmark datasets, achieving comparable\nperformance with state-of-the-art non-autoregressive NMT models and almost\nconstant decoding time w.r.t the sequence length.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 15:32:34 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 21:57:15 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 05:37:40 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Ma", "Xuezhe", ""], ["Zhou", "Chunting", ""], ["Li", "Xian", ""], ["Neubig", "Graham", ""], ["Hovy", "Eduard", ""]]}, {"id": "1909.02487", "submitter": "David Pfau", "authors": "David Pfau, James S. Spencer, Alexander G. de G. Matthews, W. M. C.\n  Foulkes", "title": "Ab-Initio Solution of the Many-Electron Schr\\\"odinger Equation with Deep\n  Neural Networks", "comments": "Final proof for Physical Review Research", "journal-ref": "Phys. Rev. Research 2, 033429 (2020)", "doi": "10.1103/PhysRevResearch.2.033429", "report-no": null, "categories": "physics.chem-ph cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given access to accurate solutions of the many-electron Schr\\\"odinger\nequation, nearly all chemistry could be derived from first principles. Exact\nwavefunctions of interesting chemical systems are out of reach because they are\nNP-hard to compute in general, but approximations can be found using\npolynomially-scaling algorithms. The key challenge for many of these algorithms\nis the choice of wavefunction approximation, or Ansatz, which must trade off\nbetween efficiency and accuracy. Neural networks have shown impressive power as\naccurate practical function approximators and promise as a compact wavefunction\nAnsatz for spin systems, but problems in electronic structure require\nwavefunctions that obey Fermi-Dirac statistics. Here we introduce a novel deep\nlearning architecture, the Fermionic Neural Network, as a powerful wavefunction\nAnsatz for many-electron systems. The Fermionic Neural Network is able to\nachieve accuracy beyond other variational quantum Monte Carlo Ans\\\"atze on a\nvariety of atoms and small molecules. Using no data other than atomic positions\nand charges, we predict the dissociation curves of the nitrogen molecule and\nhydrogen chain, two challenging strongly-correlated systems, to significantly\nhigher accuracy than the coupled cluster method, widely considered the most\naccurate scalable method for quantum chemistry at equilibrium geometry. This\ndemonstrates that deep neural networks can improve the accuracy of variational\nquantum Monte Carlo to the point where it outperforms other ab-initio quantum\nchemistry methods, opening the possibility of accurate direct optimization of\nwavefunctions for previously intractable many-electron systems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 15:39:27 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 17:57:41 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 16:22:15 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Pfau", "David", ""], ["Spencer", "James S.", ""], ["Matthews", "Alexander G. de G.", ""], ["Foulkes", "W. M. C.", ""]]}, {"id": "1909.02496", "submitter": "Ping Li", "authors": "Hang Zhang, Martin Slawski, Ping Li", "title": "The Benefits of Diversity: Permutation Recovery in Unlabeled Sensing\n  from Multiple Measurement Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In \"Unlabeled Sensing\", one observes a set of linear measurements of an\nunderlying signal with incomplete or missing information about their ordering,\nwhich can be modeled in terms of an unknown permutation. Previous work on the\ncase of a single noisy measurement vector has exposed two main challenges: 1) a\nhigh requirement concerning the \\emph{signal-to-noise ratio} ($\\snr$), i.e.,\napproximately of the order of $n^{5}$, and 2) a massive computational burden in\nlight of NP-hardness in general.\n  In this paper, we study the case of \\emph{multiple} noisy measurement vectors\n(MMVs) resulting from a \\emph{common} permutation and investigate to what\nextent the number of MMVs $m$ facilitates permutation recovery by \"borrowing\nstrength\". The above two challenges have at least partially been resolved\nwithin our work. First, we show that a large stable rank of the signal\nsignificantly reduces the required snr which can drop from a polynomial in $n$\nfor $m = 1$ to a constant for $m = \\Omega(\\log n)$, where $m$ denotes the\nnumber of MMVs and $n$ denotes the number of measurements per MV. This bound is\nshown to be sharp and is associated with a phase transition phenomenon. Second,\nwe propose a computational scheme for recovering the unknown permutation in\npractice. For the \"oracle case\" with the known signal, the maximum likelihood\n(ML) estimator reduces to a linear assignment problem whose global optimum can\nbe obtained efficiently. For the case in which both the signal and permutation\nare unknown, the problem is reformulated as a bi-convex optimization problem\nwith an auxiliary variable, which can be solved by the Alternating Direction\nMethod of Multipliers (ADMM). Numerical experiments based on the proposed\ncomputational scheme confirm the tightness of our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 15:55:59 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 05:49:06 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Zhang", "Hang", ""], ["Slawski", "Martin", ""], ["Li", "Ping", ""]]}, {"id": "1909.02506", "submitter": "Yuan Zhou", "authors": "Kefan Dong, Jian Peng, Yining Wang, Yuan Zhou", "title": "$\\sqrt{n}$-Regret for Learning in Markov Decision Processes with\n  Function Approximation and Low Bellman Rank", "comments": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of online learning of Markov decision\nprocesses (MDPs) with very large state spaces. Under the assumptions of\nrealizable function approximation and low Bellman ranks, we develop an online\nlearning algorithm that learns the optimal value function while at the same\ntime achieving very low cumulative regret during the learning process. Our\nlearning algorithm, Adaptive Value-function Elimination (AVE), is inspired by\nthe policy elimination algorithm proposed in (Jiang et al., 2017), known as\nOLIVE. One of our key technical contributions in AVE is to formulate the\nelimination steps in OLIVE as contextual bandit problems. This technique\nenables us to apply the active elimination and expert weighting methods from\n(Dudik et al., 2011), instead of the random action exploration scheme used in\nthe original OLIVE algorithm, for more efficient exploration and better control\nof the regret incurred in each policy elimination step. To the best of our\nknowledge, this is the first $\\sqrt{n}$-regret result for reinforcement\nlearning in stochastic MDPs with general value function approximation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 16:20:41 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 21:54:55 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 17:17:19 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Dong", "Kefan", ""], ["Peng", "Jian", ""], ["Wang", "Yining", ""], ["Zhou", "Yuan", ""]]}, {"id": "1909.02518", "submitter": "Christian Richardt", "authors": "Hyeongwoo Kim, Mohamed Elgharib, Michael Zollh\\\"ofer, Hans-Peter\n  Seidel, Thabo Beeler, Christian Richardt, Christian Theobalt", "title": "Neural Style-Preserving Visual Dubbing", "comments": "SIGGRAPH Asia 2019", "journal-ref": null, "doi": "10.1145/3355089.3356500", "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dubbing is a technique for translating video content from one language to\nanother. However, state-of-the-art visual dubbing techniques directly copy\nfacial expressions from source to target actors without considering\nidentity-specific idiosyncrasies such as a unique type of smile. We present a\nstyle-preserving visual dubbing approach from single video inputs, which\nmaintains the signature style of target actors when modifying facial\nexpressions, including mouth motions, to match foreign languages. At the heart\nof our approach is the concept of motion style, in particular for facial\nexpressions, i.e., the person-specific expression change that is yet another\nessential factor beyond visual accuracy in face editing applications. Our\nmethod is based on a recurrent generative adversarial network that captures the\nspatiotemporal co-activation of facial expressions, and enables generating and\nmodifying the facial expressions of the target actor while preserving their\nstyle. We train our model with unsynchronized source and target videos in an\nunsupervised manner using cycle-consistency and mouth expression losses, and\nsynthesize photorealistic video frames using a layered neural face renderer.\nOur approach generates temporally coherent results, and handles dynamic\nbackgrounds. Our results show that our dubbing approach maintains the\nidiosyncratic style of the target actor better than previous approaches, even\nfor widely differing source and target actors.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 16:41:20 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 10:53:40 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Kim", "Hyeongwoo", ""], ["Elgharib", "Mohamed", ""], ["Zollh\u00f6fer", "Michael", ""], ["Seidel", "Hans-Peter", ""], ["Beeler", "Thabo", ""], ["Richardt", "Christian", ""], ["Theobalt", "Christian", ""]]}, {"id": "1909.02525", "submitter": "Sanjaya Lohani", "authors": "Sanjaya Lohani and Ryan T. Glasser", "title": "Coherent Optical Communications Enhanced by Machine Intelligence", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": "10.1088/2632-2153/ab9c3d", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty in discriminating between different received coherent signals is\nintegral to the operation of many free-space optical communications protocols,\nand is often difficult when the receiver measures a weak signal. Here we design\nan optical communications scheme that uses balanced homodyne detection in\ncombination with an unsupervised generative machine learning and convolutional\nneural network (CNN) system, and demonstrate its efficacy in a realistic\nsimulated coherent quadrature phase shift keyed (QPSK) communications system.\nAdditionally, we program the neural network system at the transmitter such that\nit autonomously learns to correct for the noise associated with a weak QPSK\nsignal, which is shared with the network state of the receiver prior to the\nimplementation of the communications. We find that the scheme significantly\nreduces the overall error probability of the communications system, achieving\nthe classical optimal limit. This communications design is straightforward to\nbuild, implement, and scale. We anticipate that these results will allow for a\nsignificant enhancement of current classical and quantum coherent optical\ncommunications technologies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 16:54:17 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 03:16:20 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Lohani", "Sanjaya", ""], ["Glasser", "Ryan T.", ""]]}, {"id": "1909.02526", "submitter": "Sanjaya Lohani", "authors": "Sanjaya Lohani, Erin M. Knutson, Wenlei Zhang, and Ryan T. Glasser", "title": "Dispersion Characterization and Pulse Prediction with Machine Learning", "comments": "7 pages, 5 figures", "journal-ref": "OSA Continuum 2, 3438-3445 (2019)", "doi": "10.1364/OSAC.2.003438", "report-no": null, "categories": "physics.optics cs.LG eess.SP quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we demonstrate the efficacy of neural networks in the\ncharacterization of dispersive media. We also develop a neural network to make\npredictions for input probe pulses which propagate through a nonlinear\ndispersive medium, which may be applied to predicting optimal pulse shapes for\na desired output. The setup requires only a single pulse for the probe,\nproviding considerable simplification of the current method of dispersion\ncharacterization that requires frequency scanning across the entirety of the\ngain and absorption features. We show that the trained networks are able to\npredict pulse profiles as well as dispersive features that are nearly identical\nto their experimental counterparts. We anticipate that the use of machine\nlearning in conjunction with optical communication and sensing methods, both\nclassical and quantum, can provide signal enhancement and experimental\nsimplifications even in the face of highly complex, layered nonlinear\nlight-matter interactions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 16:55:40 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lohani", "Sanjaya", ""], ["Knutson", "Erin M.", ""], ["Zhang", "Wenlei", ""], ["Glasser", "Ryan T.", ""]]}, {"id": "1909.02548", "submitter": "Mihir Chauhan", "authors": "Mihir Chauhan, Mohammad Abuzar Shaikh and Sargur N. Srihari", "title": "Explanation based Handwriting Verification", "comments": "Presented at BMVC 2019: Workshop on Interpretable and Explainable\n  Machine Vision, Cardiff, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning system have drawback that their output is not accompanied with\nex-planation. In a domain such as forensic handwriting verification it is\nessential to provideexplanation to jurors. The goal of handwriting verification\nis to find a measure of confi-dence whether the given handwritten samples are\nwritten by the same or different writer.We propose a method to generate\nexplanations for the confidence provided by convolu-tional neural network (CNN)\nwhich maps the input image to 15 annotations (features)provided by experts. Our\nsystem comprises of: (1) Feature learning network (FLN),a differentiable\nsystem, (2) Inference module for providing explanations. Furthermore,inference\nmodule provides two types of explanations: (a) Based on cosine\nsimilaritybetween categorical probabilities of each feature, (b) Based on\nLog-Likelihood Ratio(LLR) using directed probabilistic graphical model. We\nperform experiments using acombination of feature learning network (FLN) and\neach inference module. We evaluateour system using XAI-AND dataset, containing\n13700 handwritten samples and 15 cor-responding expert examined features for\neach sample. The dataset is released for publicuse and the methods can be\nextended to provide explanations on other verification taskslike face\nverification and bio-medical comparison. This dataset can serve as the basis\nand benchmark for future research in explanation based handwriting\nverification. The code is available on github.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 19:50:07 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Chauhan", "Mihir", ""], ["Shaikh", "Mohammad Abuzar", ""], ["Srihari", "Sargur N.", ""]]}, {"id": "1909.02553", "submitter": "Nathan Kallus", "authors": "Yichun Hu, Nathan Kallus, Xiaojie Mao", "title": "Smooth Contextual Bandits: Bridging the Parametric and\n  Non-differentiable Regret Regimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a nonparametric contextual bandit problem where the expected reward\nfunctions belong to a H\\\"older class with smoothness parameter $\\beta$. We show\nhow this interpolates between two extremes that were previously studied in\nisolation: non-differentiable bandits ($\\beta\\leq1$), where rate-optimal regret\nis achieved by running separate non-contextual bandits in different context\nregions, and parametric-response bandits (satisfying $\\beta=\\infty$), where\nrate-optimal regret can be achieved with minimal or no exploration due to\ninfinite extrapolatability. We develop a novel algorithm that carefully adjusts\nto all smoothness settings and we prove its regret is rate-optimal by\nestablishing matching upper and lower bounds, recovering the existing results\nat the two extremes. In this sense, our work bridges the gap between the\nexisting literature on parametric and non-differentiable contextual bandit\nproblems and between bandit algorithms that exclusively use global or local\ninformation, shedding light on the crucial interplay of complexity and regret\nin contextual bandits.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 17:51:14 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 13:12:08 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 14:36:21 GMT"}, {"version": "v4", "created": "Fri, 11 Sep 2020 12:55:27 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Hu", "Yichun", ""], ["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""]]}, {"id": "1909.02562", "submitter": "Houssem Ben Braiek", "authors": "Houssem Ben Braiek and Foutse Khomh", "title": "TFCheck : A TensorFlow Library for Detecting Training Issues in Neural\n  Network Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing inclusion of Machine Learning (ML) models in safety critical\nsystems like autonomous cars have led to the development of multiple\nmodel-based ML testing techniques. One common denominator of these testing\ntechniques is their assumption that training programs are adequate and\nbug-free. These techniques only focus on assessing the performance of the\nconstructed model using manually labeled data or automatically generated data.\nHowever, their assumptions about the training program are not always true as\ntraining programs can contain inconsistencies and bugs. In this paper, we\nexamine training issues in ML programs and propose a catalog of verification\nroutines that can be used to detect the identified issues, automatically. We\nimplemented the routines in a Tensorflow-based library named TFCheck. Using\nTFCheck, practitioners can detect the aforementioned issues automatically. To\nassess the effectiveness of TFCheck, we conducted a case study with real-world,\nmutants, and synthetic training programs. Results show that TFCheck can\nsuccessfully detect training issues in ML code implementations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:21:22 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Braiek", "Houssem Ben", ""], ["Khomh", "Foutse", ""]]}, {"id": "1909.02563", "submitter": "Houssem Ben Braiek", "authors": "Houssem Ben Braiek and Foutse khomh", "title": "DeepEvolution: A Search-Based Testing Approach for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing inclusion of Deep Learning (DL) models in safety-critical\nsystems such as autonomous vehicles have led to the development of multiple\nmodel-based DL testing techniques. One common denominator of these testing\ntechniques is the automated generation of test cases, e.g., new inputs\ntransformed from the original training data with the aim to optimize some test\nadequacy criteria. So far, the effectiveness of these approaches has been\nhindered by their reliance on random fuzzing or transformations that do not\nalways produce test cases with a good diversity. To overcome these limitations,\nwe propose, DeepEvolution, a novel search-based approach for testing DL models\nthat relies on metaheuristics to ensure a maximum diversity in generated test\ncases. We assess the effectiveness of DeepEvolution in testing computer-vision\nDL models and found that it significantly increases the neuronal coverage of\ngenerated test cases. Moreover, using DeepEvolution, we could successfully find\nseveral corner-case behaviors. Finally, DeepEvolution outperformed Tensorfuzz\n(a coverage-guided fuzzing tool developed at Google Brain) in detecting latent\ndefects introduced during the quantization of the models. These results suggest\nthat search-based approaches can help build effective testing tools for DL\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 13:42:08 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Braiek", "Houssem Ben", ""], ["khomh", "Foutse", ""]]}, {"id": "1909.02564", "submitter": "Jarom\\'ir Janisch", "authors": "Jarom\\'ir Janisch, Tom\\'a\\v{s} Pevn\\'y and Viliam Lis\\'y", "title": "Classification with Costly Features as a Sequential Decision-Making\n  Problem", "comments": null, "journal-ref": "Machine Learning (2020): 1-29", "doi": "10.1007/s10994-020-05874-8", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on a specific classification problem, where the information\nabout a sample is not readily available, but has to be acquired for a cost, and\nthere is a per-sample budget. Inspired by real-world use-cases, we analyze\naverage and hard variations of a directly specified budget. We postulate the\nproblem in its explicit formulation and then convert it into an equivalent MDP,\nthat can be solved with deep reinforcement learning. Also, we evaluate a\nreal-world inspired setting with sparse training dataset with missing features.\nThe presented method performs robustly well in all settings across several\ndistinct datasets, outperforming other prior-art algorithms. The method is\nflexible, as showcased with all mentioned modifications and can be improved\nwith any domain independent advancement in RL.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 14:46:40 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Janisch", "Jarom\u00edr", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""], ["Lis\u00fd", "Viliam", ""]]}, {"id": "1909.02583", "submitter": "Xian Yeow Lee", "authors": "Xian Yeow Lee, Sambit Ghadai, Kai Liang Tan, Chinmay Hegde, Soumik\n  Sarkar", "title": "Spatiotemporally Constrained Action Space Attacks on Deep Reinforcement\n  Learning Agents", "comments": "Version 2 with supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of Deep Reinforcement Learning (DRL) algorithms towards\nadversarial attacks in real world applications such as those deployed in\ncyber-physical systems (CPS) are of increasing concern. Numerous studies have\ninvestigated the mechanisms of attacks on the RL agent's state space.\nNonetheless, attacks on the RL agent's action space (AS) (corresponding to\nactuators in engineering systems) are equally perverse; such attacks are\nrelatively less studied in the ML literature. In this work, we first frame the\nproblem as an optimization problem of minimizing the cumulative reward of an RL\nagent with decoupled constraints as the budget of attack. We propose a\nwhite-box Myopic Action Space (MAS) attack algorithm that distributes the\nattacks across the action space dimensions. Next, we reformulate the\noptimization problem above with the same objective function, but with a\ntemporally coupled constraint on the attack budget to take into account the\napproximated dynamics of the agent. This leads to the white-box Look-ahead\nAction Space (LAS) attack algorithm that distributes the attacks across the\naction and temporal dimensions. Our results shows that using the same amount of\nresources, the LAS attack deteriorates the agent's performance significantly\nmore than the MAS attack. This reveals the possibility that with limited\nresource, an adversary can utilize the agent's dynamics to malevolently craft\nattacks that causes the agent to fail. Additionally, we leverage these attack\nstrategies as a possible tool to gain insights on the potential vulnerabilities\nof DRL agents.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 18:04:04 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 03:36:57 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Lee", "Xian Yeow", ""], ["Ghadai", "Sambit", ""], ["Tan", "Kai Liang", ""], ["Hegde", "Chinmay", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1909.02603", "submitter": "Kameron Harris", "authors": "Kameron Decker Harris", "title": "Additive function approximation in the brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many biological learning systems such as the mushroom body, hippocampus, and\ncerebellum are built from sparsely connected networks of neurons. For a new\nunderstanding of such networks, we study the function spaces induced by sparse\nrandom features and characterize what functions may and may not be learned. A\nnetwork with $d$ inputs per neuron is found to be equivalent to an additive\nmodel of order $d$, whereas with a degree distribution the network combines\nadditive terms of different orders. We identify three specific advantages of\nsparsity: additive function approximation is a powerful inductive bias that\nlimits the curse of dimensionality, sparse networks are stable to outlier noise\nin the inputs, and sparse random features are scalable. Thus, even simple brain\narchitectures can be powerful function approximators. Finally, we hope that\nthis work helps popularize kernel theories of networks among computational\nneuroscientists.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 19:07:33 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 21:41:07 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Harris", "Kameron Decker", ""]]}, {"id": "1909.02625", "submitter": "An Xu", "authors": "An Xu, Zhouyuan Huo, Heng Huang", "title": "Diversely Stale Parameters for Efficient Training of CNNs", "comments": "Layer-wise Staleness, Parallel Training, Convolutional Neural\n  Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation algorithm is the most popular algorithm training neural\nnetworks nowadays. However, it suffers from the forward locking, backward\nlocking and update locking problems, especially when a neural network is so\nlarge that its layers are distributed across multiple devices. Existing\nsolutions either can only handle one locking problem or lead to severe accuracy\nloss or memory inefficiency. Moreover, none of them consider the straggler\nproblem among devices. In this paper, we propose Layer-wise Staleness and a\nnovel efficient training algorithm, Diversely Stale Parameters (DSP), which can\naddress all these challenges without loss of accuracy nor memory issue. We also\nanalyze the convergence of DSP with two popular gradient-based methods and\nprove that both of them are guaranteed to converge to critical points for\nnon-convex problems. Finally, extensive experimental results on training deep\nconvolutional neural networks demonstrate that our proposed DSP algorithm can\nachieve significant training speedup with stronger robustness and better\ngeneralization than compared methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 20:41:06 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 17:31:57 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Xu", "An", ""], ["Huo", "Zhouyuan", ""], ["Huang", "Heng", ""]]}, {"id": "1909.02636", "submitter": "Christoph Dinh", "authors": "Christoph Dinh, John GW Samuelsson, Alexander Hunold, Matti S\n  H\\\"am\\\"al\\\"ainen, Sheraz Khan", "title": "Contextual Minimum-Norm Estimates (CMNE): A Deep Learning Method for\n  Source Estimation in Neuronal Networks", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetoencephalography (MEG) and Electroencephalography (EEG) source\nestimates have thus far mostly been derived sample by sample, i.e., independent\nof each other in time. However, neuronal assemblies are heavily interconnected,\nconstraining the temporal evolution of neural activity in space as detected by\nMEG and EEG. The observed neural currents are thus highly context dependent.\nHere, a new method is presented which integrates predictive deep learning\nnetworks with the Minimum-Norm Estimates (MNE) approach. Specifically, we\nemploy Long Short-Term Memory (LSTM) networks, a type of recurrent neural\nnetwork, for predicting brain activity. Because we use past activity (context)\nin the estimation, we call our method Contextual MNE (CMNE). We demonstrate\nthat these contextual algorithms can be used for predicting activity based on\nprevious brain states and when used in conjunction with MNE, they lead to more\naccurate source estimation. To evaluate the performance of CMNE, it was tested\non simulated and experimental data from human auditory evoked response\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 21:14:20 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Dinh", "Christoph", ""], ["Samuelsson", "John GW", ""], ["Hunold", "Alexander", ""], ["H\u00e4m\u00e4l\u00e4inen", "Matti S", ""], ["Khan", "Sheraz", ""]]}, {"id": "1909.02642", "submitter": "Anne Martel", "authors": "Linde S. Hesse, Grey Kuling, Mitko Veta, Anne L. Martel", "title": "Intensity augmentation for domain transfer of whole breast segmentation\n  in MRI", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The segmentation of the breast from the chest wall is an important first step\nin the analysis of breast magnetic resonance images. 3D U-nets have been shown\nto obtain high segmentation accuracy and appear to generalize well when trained\non one scanner type and tested on another scanner, provided that a very similar\nT1-weighted MR protocol is used. There has, however, been little work\naddressing the problem of domain adaptation when image intensities or patient\norientation differ markedly between the training set and an unseen test set. To\novercome the domain shift we propose to apply extensive intensity augmentation\nin addition to geometric augmentation during training. We explored both style\ntransfer and a novel intensity remapping approach as intensity augmentation\nstrategies. For our experiments, we trained a 3D U-net on T1-weighted scans and\ntested on T2-weighted scans. By applying intensity augmentation we increased\nsegmentation performance from a DSC of 0.71 to 0.90. This performance is very\nclose to the baseline performance of training and testing on T2-weighted scans\n(0.92). Furthermore, we applied our network to an independent test set made up\nof publicly available scans acquired using a T1-weighted TWIST sequence and a\ndifferent coil configuration. On this dataset we obtained a performance of\n0.89, close to the inter-observer variability of the ground truth segmentations\n(0.92). Our results show that using intensity augmentation in addition to\ngeometric augmentation is a suitable method to overcome the intensity domain\nshift and we expect it to be useful for a wide range of segmentation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 21:40:02 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Hesse", "Linde S.", ""], ["Kuling", "Grey", ""], ["Veta", "Mitko", ""], ["Martel", "Anne L.", ""]]}, {"id": "1909.02659", "submitter": "Shi-Xin Zhang", "authors": "Zhou-Quan Wan and Shi-Xin Zhang", "title": "Automatic Differentiation for Complex Valued SVD", "comments": "4.2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cond-mat.stat-mech cond-mat.str-el cs.LG cs.NA quant-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this note, we report the back propagation formula for complex valued\nsingular value decompositions (SVD). This formula is an important ingredient\nfor a complete automatic differentiation(AD) infrastructure in terms of complex\nnumbers, and it is also the key to understand and utilize AD in tensor\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 09:34:15 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 13:58:40 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 11:39:46 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Wan", "Zhou-Quan", ""], ["Zhang", "Shi-Xin", ""]]}, {"id": "1909.02667", "submitter": "Gautam Mantena", "authors": "Gautam Mantena, Ozlem Kalinli, Ossama Abdel-Hamid, Don McAllaster", "title": "Bandwidth Embeddings for Mixed-bandwidth Speech Recognition", "comments": "A part of this work is accepted in Interspeech 2019\n  https://interspeech2019.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of handling narrowband and wideband\nspeech by building a single acoustic model (AM), also called mixed bandwidth\nAM. In the proposed approach, an auxiliary input feature is used to provide the\nbandwidth information to the model, and bandwidth embeddings are jointly\nlearned as part of acoustic model training. Experimental evaluations show that\nusing bandwidth embeddings helps the model to handle the variability of the\nnarrow and wideband speech, and makes it possible to train a mixed-bandwidth\nAM. Furthermore, we propose to use parallel convolutional layers to handle the\nmismatch between the narrow and wideband speech better, where separate\nconvolution layers are used for each type of input speech signal. Our best\nsystem achieves 13% relative improvement on narrowband speech, while not\ndegrading on wideband speech.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 23:07:26 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Mantena", "Gautam", ""], ["Kalinli", "Ozlem", ""], ["Abdel-Hamid", "Ossama", ""], ["McAllaster", "Don", ""]]}, {"id": "1909.02682", "submitter": "Sai Qian Zhang", "authors": "Sai Qian Zhang, Qi Zhang, Jieyu Lin", "title": "Efficient Communication in Multi-Agent Reinforcement Learning via\n  Variance Based Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) has recently received considerable\nattention due to its applicability to a wide range of real-world applications.\nHowever, achieving efficient communication among agents has always been an\noverarching problem in MARL. In this work, we propose Variance Based Control\n(VBC), a simple yet efficient technique to improve communication efficiency in\nMARL. By limiting the variance of the exchanged messages between agents during\nthe training phase, the noisy component in the messages can be eliminated\neffectively, while the useful part can be preserved and utilized by the agents\nfor better performance. Our evaluation using a challenging set of StarCraft II\nbenchmarks indicates that our method achieves $2-10\\times$ lower in\ncommunication overhead than state-of-the-art MARL algorithms, while allowing\nagents to better collaborate by developing sophisticated strategies.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 00:26:05 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 15:33:40 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Zhang", "Sai Qian", ""], ["Zhang", "Qi", ""], ["Lin", "Jieyu", ""]]}, {"id": "1909.02688", "submitter": "Tingshan Liu", "authors": "Thomas L. Athey, Benjamin D. Pedigo, Tingshan Liu, Joshua T.\n  Vogelstein", "title": "AutoGMM: Automatic and Hierarchical Gaussian Mixture Modeling in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian mixture modeling is a fundamental tool in clustering, as well as\ndiscriminant analysis and semiparametric density estimation. However,\nestimating the optimal model for any given number of components is an NP-hard\nproblem, and estimating the number of components is in some respects an even\nharder problem. In R, a popular package called mclust addresses both of these\nproblems. However, Python has lacked such a package. We therefore introduce\nAutoGMM, a Python algorithm for automatic Gaussian mixture modeling, and its\nhierarchical version, HGMM. AutoGMM builds upon scikit-learn's\nAgglomerativeClustering and GaussianMixture classes, with certain modifications\nto make the results more stable. Empirically, on several different\napplications, AutoGMM performs approximately as well as mclust, and sometimes\nbetter. This package is freely available, and further shrinks the gap between\nfunctionality of R and Python for data science.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 01:45:27 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 16:14:24 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 03:29:20 GMT"}, {"version": "v4", "created": "Sat, 12 Dec 2020 16:19:50 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Athey", "Thomas L.", ""], ["Pedigo", "Benjamin D.", ""], ["Liu", "Tingshan", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1909.02702", "submitter": "Stefano Massaroli", "authors": "Stefano Massaroli, Michael Poli, Federico Califano, Angela Faragasso,\n  Jinkyoo Park, Atsushi Yamashita, Hajime Asama", "title": "Port-Hamiltonian Approach to Neural Network Training", "comments": "To appear in the Proceedings of the 58th IEEE Conference on Decision\n  and Control (CDC 2019). The first two authors contributed equally to the work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are discrete entities: subdivided into discrete layers and\nparametrized by weights which are iteratively optimized via difference\nequations. Recent work proposes networks with layer outputs which are no longer\nquantized but are solutions of an ordinary differential equation (ODE);\nhowever, these networks are still optimized via discrete methods (e.g. gradient\ndescent). In this paper, we explore a different direction: namely, we propose a\nnovel framework for learning in which the parameters themselves are solutions\nof ODEs. By viewing the optimization process as the evolution of a\nport-Hamiltonian system, we can ensure convergence to a minimum of the\nobjective function. Numerical experiments have been performed to show the\nvalidity and effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 03:31:40 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Massaroli", "Stefano", ""], ["Poli", "Michael", ""], ["Califano", "Federico", ""], ["Faragasso", "Angela", ""], ["Park", "Jinkyoo", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""]]}, {"id": "1909.02705", "submitter": "Keyu Nie", "authors": "Keyu Nie, Zezhong Zhang, Ted Tao Yuan, Rong Song, Pauline Berry Burke", "title": "Efficient Multivariate Bandit Algorithm with Path Planning", "comments": "Multi-Armed Bandit, Monte Carlo Tree Search, Decision Tree, Path\n  Planning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we solve the arms exponential exploding issue in multivariate\nMulti-Armed Bandit (Multivariate-MAB) problem when the arm dimension hierarchy\nis considered. We propose a framework called path planning (TS-PP) which\nutilizes decision graph/trees to model arm reward success rate with m-way\ndimension interaction, and adopts Thompson sampling (TS) for heuristic search\nof arm selection. Naturally, it is quite straightforward to combat the curse of\ndimensionality using a serial processes that operates sequentially by focusing\non one dimension per each process. For our best acknowledge, we are the first\nto solve Multivariate-MAB problem using graph path planning strategy and\ndeploying alike Monte-Carlo tree search ideas. Our proposed method utilizing\ntree models has advantages comparing with traditional models such as general\nlinear regression. Simulation studies validate our claim by achieving faster\nconvergence speed, better efficient optimal arm allocation and lower cumulative\nregret.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 04:16:00 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 21:00:11 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Nie", "Keyu", ""], ["Zhang", "Zezhong", ""], ["Yuan", "Ted Tao", ""], ["Song", "Rong", ""], ["Burke", "Pauline Berry", ""]]}, {"id": "1909.02707", "submitter": "Yuanhao Li", "authors": "Yuanhao Li, Badong Chen, Natsue Yoshimura, Yasuharu Koike", "title": "Restricted Minimum Error Entropy Criterion for Robust Classification", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems 2021", "doi": "10.1109/TNNLS.2021.3082571", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum error entropy (MEE) criterion has been verified as a powerful\napproach for non-Gaussian signal processing and robust machine learning.\nHowever, the implementation of MEE on robust classification is rather a vacancy\nin the literature. The original MEE only focuses on minimizing the Renyi's\nquadratic entropy of the error probability distribution function (PDF), which\ncould cause failure in noisy classification tasks. To this end, we analyze the\noptimal error distribution in the presence of outliers for those classifiers\nwith continuous errors, and introduce a simple codebook to restrict MEE so that\nit drives the error PDF towards the desired case. Half-quadratic based\noptimization and convergence analysis of the new learning criterion, called\nrestricted MEE (RMEE), are provided. Experimental results with logistic\nregression and extreme learning machine are presented to verify the desirable\nrobustness of RMEE.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 04:18:57 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 04:37:41 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 04:34:58 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2020 06:26:20 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Li", "Yuanhao", ""], ["Chen", "Badong", ""], ["Yoshimura", "Natsue", ""], ["Koike", "Yasuharu", ""]]}, {"id": "1909.02712", "submitter": "Jiaqi Zhang", "authors": "Jiaqi Zhang and Keyou You", "title": "Decentralized Stochastic Gradient Tracking for Non-convex Empirical Risk\n  Minimization", "comments": "This paper has been revised and theoretical results are improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a decentralized stochastic gradient tracking (DSGT)\nalgorithm for non-convex empirical risk minimization problems over a\npeer-to-peer network of nodes, which is in sharp contrast to the existing DSGT\nonly for convex problems. To ensure exact convergence and handle the variance\namong decentralized datasets, each node performs a stochastic gradient (SG)\ntracking step by using a mini-batch of samples, where the batch size is\ndesigned to be proportional to the size of the local dataset. We explicitly\nevaluate the convergence rate of DSGT with respect to the number of iterations\nin terms of algebraic connectivity of the network, mini-batch size, gradient\nvariance, etc. Under certain conditions, we further show that DSGT has a\nnetwork independence property in the sense that the network topology only\naffects the convergence rate up to a constant factor. Hence, the convergence\nrate of DSGT can be comparable to the centralized SGD method. Moreover, a\nlinear speedup of DSGT with respect to the number of nodes is achievable for\nsome scenarios. Numerical experiments for neural networks and logistic\nregression problems on CIFAR-10 finally illustrate the advantages of DSGT.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 05:05:45 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 05:28:08 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2020 08:38:02 GMT"}, {"version": "v4", "created": "Fri, 28 Aug 2020 11:46:28 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Zhang", "Jiaqi", ""], ["You", "Keyou", ""]]}, {"id": "1909.02729", "submitter": "Guneet Singh Dhillon", "authors": "Guneet S. Dhillon, Pratik Chaudhari, Avinash Ravichandran, Stefano\n  Soatto", "title": "A Baseline for Few-Shot Image Classification", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR), 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning a deep network trained with the standard cross-entropy loss is a\nstrong baseline for few-shot learning. When fine-tuned transductively, this\noutperforms the current state-of-the-art on standard datasets such as\nMini-ImageNet, Tiered-ImageNet, CIFAR-FS and FC-100 with the same\nhyper-parameters. The simplicity of this approach enables us to demonstrate the\nfirst few-shot learning results on the ImageNet-21k dataset. We find that using\na large number of meta-training classes results in high few-shot accuracies\neven for a large number of few-shot classes. We do not advocate our approach as\nthe solution for few-shot learning, but simply use the results to highlight\nlimitations of current benchmarks and few-shot protocols. We perform extensive\nstudies on benchmark datasets to propose a metric that quantifies the\n\"hardness\" of a few-shot episode. This metric can be used to report the\nperformance of few-shot algorithms in a more systematic way.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 06:14:03 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 02:08:39 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 03:19:17 GMT"}, {"version": "v4", "created": "Mon, 23 Mar 2020 01:37:04 GMT"}, {"version": "v5", "created": "Wed, 21 Oct 2020 21:13:04 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Dhillon", "Guneet S.", ""], ["Chaudhari", "Pratik", ""], ["Ravichandran", "Avinash", ""], ["Soatto", "Stefano", ""]]}, {"id": "1909.02742", "submitter": "Shaofeng Li", "authors": "Shaofeng Li, Minhui Xue, Benjamin Zi Hao Zhao, Haojin Zhu, Xinpeng\n  Zhang", "title": "Invisible Backdoor Attacks on Deep Neural Networks via Steganography and\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been proven vulnerable to backdoor attacks,\nwhere hidden features (patterns) trained to a normal model, which is only\nactivated by some specific input (called triggers), trick the model into\nproducing unexpected behavior. In this paper, we create covert and scattered\ntriggers for backdoor attacks, invisible backdoors, where triggers can fool\nboth DNN models and human inspection. We apply our invisible backdoors through\ntwo state-of-the-art methods of embedding triggers for backdoor attacks. The\nfirst approach on Badnets embeds the trigger into DNNs through steganography.\nThe second approach of a trojan attack uses two types of additional\nregularization terms to generate the triggers with irregular shape and size. We\nuse the Attack Success Rate and Functionality to measure the performance of our\nattacks. We introduce two novel definitions of invisibility for human\nperception; one is conceptualized by the Perceptual Adversarial Similarity\nScore (PASS) and the other is Learned Perceptual Image Patch Similarity\n(LPIPS). We show that the proposed invisible backdoors can be fairly effective\nacross various DNN models as well as four datasets MNIST, CIFAR-10, CIFAR-100,\nand GTSRB, by measuring their attack success rates for the adversary,\nfunctionality for the normal users, and invisibility scores for the\nadministrators. We finally argue that the proposed invisible backdoor attacks\ncan effectively thwart the state-of-the-art trojan backdoor detection\napproaches, such as Neural Cleanse and TABOR.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:11:26 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 03:17:24 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 04:14:46 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Shaofeng", ""], ["Xue", "Minhui", ""], ["Zhao", "Benjamin Zi Hao", ""], ["Zhu", "Haojin", ""], ["Zhang", "Xinpeng", ""]]}, {"id": "1909.02746", "submitter": "Cheolhyeong Kim", "authors": "Cheolhyeong Kim, Haeseong Moon, Hyung Ju Hwang", "title": "NEAR: Neighborhood Edge AggregatoR for Graph Classification", "comments": "11 pages, 12 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning graph-structured data with graph neural networks (GNNs) has been\nrecently emerging as an important field because of its wide applicability in\nbioinformatics, chemoinformatics, social network analysis and data mining.\nRecent GNN algorithms are based on neural message passing, which enables GNNs\nto integrate local structures and node features recursively. However, past GNN\nalgorithms based on 1-hop neighborhood neural message passing are exposed to a\nrisk of loss of information on local structures and relationships. In this\npaper, we propose Neighborhood Edge AggregatoR (NEAR), a novel framework that\naggregates relations between the nodes in the neighborhood via edges. NEAR,\nwhich can be orthogonally combined with previous GNN algorithms, gives\nintegrated information that describes which nodes in the neighborhood are\nconnected. Therefore, GNNs combined with NEAR reflect each node's local\nstructure beyond the nodes themselves. Experimental results on multiple graph\nclassification tasks show that our algorithm achieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:22:50 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Kim", "Cheolhyeong", ""], ["Moon", "Haeseong", ""], ["Hwang", "Hyung Ju", ""]]}, {"id": "1909.02747", "submitter": "Takehisa Yamakita", "authors": "Takehisa Yamakita", "title": "Eelgrass beds and oyster farming at a lagoon before and after the Great\n  East Japan Earthquake 2011: potential to apply deep learning at a coastal\n  area", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a small number of case studies of automatic land cover\nclassification on the coastal area. Here, I test extraction of seagrass beds,\nsandy area, oyster farming rafts at Mangoku-ura Lagoon, Miyagi, Japan by\ncomparing manual tracing, simple image segmentation, and image transformation\nusing deep learning. The result was used to extract the changes before and\nafter the earthquake and tsunami. The output resolution was best in the image\ntransformation method, which showed more than 69% accuracy for vegetation\nclassification by an assessment using random points on independent test data.\nThe distribution of oyster farming rafts was detected by the segmentation\nmodel. Assessment of the change before and after the earthquake by the manual\ntracing and image transformation result revealed increase of sand area and\ndecrease of the vegetation. By the segmentation model only the decrease of the\noyster farming was detected. These results demonstrate the potential to extract\nthe spatial pattern of these elements after an earthquake and tsunami. Index\nTerms: Great East Japan Earthquake of 2011, Land use land cover (LULC),\nZosteracea seagrass, cultured oyster, deep learning, Mangoku Bay\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:34:58 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Yamakita", "Takehisa", ""]]}, {"id": "1909.02749", "submitter": "Kevin Shih", "authors": "Kevin J. Shih, Aysegul Dundar, Animesh Garg, Robert Pottorf, Andrew\n  Tao, Bryan Catanzaro", "title": "Video Interpolation and Prediction with Unsupervised Landmarks", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction and interpolation for long-range video data involves the complex\ntask of modeling motion trajectories for each visible object, occlusions and\ndis-occlusions, as well as appearance changes due to viewpoint and lighting.\nOptical flow based techniques generalize but are suitable only for short\ntemporal ranges. Many methods opt to project the video frames to a low\ndimensional latent space, achieving long-range predictions. However, these\nlatent representations are often non-interpretable, and therefore difficult to\nmanipulate. This work poses video prediction and interpolation as unsupervised\nlatent structure inference followed by a temporal prediction in this latent\nspace. The latent representations capture foreground semantics without explicit\nsupervision such as keypoints or poses. Further, as each landmark can be mapped\nto a coordinate indicating where a semantic part is positioned, we can reliably\ninterpolate within the coordinate domain to achieve predictable motion\ninterpolation. Given an image decoder capable of mapping these landmarks back\nto the image domain, we are able to achieve high-quality long-range video\ninterpolation and extrapolation by operating on the landmark representation\nspace.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:40:27 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Shih", "Kevin J.", ""], ["Dundar", "Aysegul", ""], ["Garg", "Animesh", ""], ["Pottorf", "Robert", ""], ["Tao", "Andrew", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "1909.02750", "submitter": "Wenqing Su", "authors": "Wenqing Su, Xiao Guo, Hai Zhang", "title": "Differentially Private Precision Matrix Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of precision matrix estimation when the\ndataset contains sensitive information. In the differential privacy framework,\nwe develop a differentially private ridge estimator by perturbing the sample\ncovariance matrix. Then we develop a differentially private graphical lasso\nestimator by using the alternating direction method of multipliers (ADMM)\nalgorithm. The theoretical results and empirical results that show the utility\nof the proposed methods are also provided.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:46:12 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Su", "Wenqing", ""], ["Guo", "Xiao", ""], ["Zhang", "Hai", ""]]}, {"id": "1909.02768", "submitter": "Marius K\\\"oppel", "authors": "Marius K\\\"oppel, Alexander Segner, Martin Wagener, Lukas Pensel,\n  Andreas Karwath, Stefan Kramer", "title": "Pairwise Learning to Rank by Neural Networks Revisited: Reconstruction,\n  Theoretical Analysis and Practical Performance", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a pairwise learning to rank approach based on a neural net, called\nDirectRanker, that generalizes the RankNet architecture. We show mathematically\nthat our model is reflexive, antisymmetric, and transitive allowing for\nsimplified training and improved performance. Experimental results on the LETOR\nMSLR-WEB10K, MQ2007 and MQ2008 datasets show that our model outperforms\nnumerous state-of-the-art methods, while being inherently simpler in structure\nand using a pairwise approach only.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 08:42:58 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["K\u00f6ppel", "Marius", ""], ["Segner", "Alexander", ""], ["Wagener", "Martin", ""], ["Pensel", "Lukas", ""], ["Karwath", "Andreas", ""], ["Kramer", "Stefan", ""]]}, {"id": "1909.02769", "submitter": "Lior Shani", "authors": "Lior Shani and Yonathan Efroni and Shie Mannor", "title": "Adaptive Trust Region Policy Optimization: Global Convergence and Faster\n  Rates for Regularized MDPs", "comments": "Published at AAAI-2020 58 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust region policy optimization (TRPO) is a popular and empirically\nsuccessful policy search algorithm in Reinforcement Learning (RL) in which a\nsurrogate problem, that restricts consecutive policies to be 'close' to one\nanother, is iteratively solved. Nevertheless, TRPO has been considered a\nheuristic algorithm inspired by Conservative Policy Iteration (CPI). We show\nthat the adaptive scaling mechanism used in TRPO is in fact the natural \"RL\nversion\" of traditional trust-region methods from convex analysis. We first\nanalyze TRPO in the planning setting, in which we have access to the model and\nthe entire state space. Then, we consider sample-based TRPO and establish\n$\\tilde O(1/\\sqrt{N})$ convergence rate to the global optimum. Importantly, the\nadaptive scaling mechanism allows us to analyze TRPO in regularized MDPs for\nwhich we prove fast rates of $\\tilde O(1/N)$, much like results in convex\noptimization. This is the first result in RL of better rates when regularizing\nthe instantaneous cost or reward.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 08:43:38 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 17:07:53 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Shani", "Lior", ""], ["Efroni", "Yonathan", ""], ["Mannor", "Shie", ""]]}, {"id": "1909.02775", "submitter": "Ingmar Schuster", "authors": "Kashif Rasul, Ingmar Schuster, Roland Vollgraf, Urs Bergmann", "title": "Set Flow: A Permutation Invariant Normalizing Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative model that is defined on finite sets of exchangeable,\npotentially high dimensional, data. As the architecture is an extension of\nRealNVPs, it inherits all its favorable properties, such as being invertible\nand allowing for exact log-likelihood evaluation. We show that this\narchitecture is able to learn finite non-i.i.d. set data distributions, learn\nstatistical dependencies between entities of the set and is able to train and\nsample with variable set sizes in a computationally efficient manner.\nExperiments on 3D point clouds show state-of-the art likelihoods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 09:00:24 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Rasul", "Kashif", ""], ["Schuster", "Ingmar", ""], ["Vollgraf", "Roland", ""], ["Bergmann", "Urs", ""]]}, {"id": "1909.02803", "submitter": "Johannes Schneider", "authors": "Johannes Schneider and Michail Vlachos", "title": "Personalization of Deep Learning", "comments": null, "journal-ref": "3rd International Data Science Conference 2020, Austria", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss training techniques, objectives and metrics toward personalization\nof deep learning models. In machine learning, personalization addresses the\ngoal of a trained model to target a particular individual by optimizing one or\nmore performance metrics, while conforming to certain constraints. To\npersonalize, we investigate three methods of ``curriculum learning`` and two\napproaches for data grouping, i.e., augmenting the data of an individual by\nadding similar data identified with an auto-encoder. We show that both\n``curriculuum learning'' and ``personalized'' data augmentation lead to\nimproved performance on data of an individual. Mostly, this comes at the cost\nof reduced performance on a more general, broader dataset.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 10:17:25 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 10:53:26 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 21:28:27 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Schneider", "Johannes", ""], ["Vlachos", "Michail", ""]]}, {"id": "1909.02811", "submitter": "Palash Goyal", "authors": "Palash Goyal, Di Huang, Sujit Rokka Chhetri, Arquimedes Canedo, Jaya\n  Shree and Evan Patterson", "title": "Graph Representation Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning on graphs has been gaining attention due to its wide\napplicability in predicting missing links, and classifying and recommending\nnodes. Most embedding methods aim to preserve certain properties of the\noriginal graph in the low dimensional space. However, real world graphs have a\ncombination of several properties which are difficult to characterize and\ncapture by a single approach. In this work, we introduce the problem of graph\nrepresentation ensemble learning and provide a first of its kind framework to\naggregate multiple graph embedding methods efficiently. We provide analysis of\nour framework and analyze -- theoretically and empirically -- the dependence\nbetween state-of-the-art embedding methods. We test our models on the node\nclassification task on four real world graphs and show that proposed ensemble\napproaches can outperform the state-of-the-art methods by up to 8% on macro-F1.\nWe further show that the approach is even more beneficial for underrepresented\nclasses providing an improvement of up to 12%.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 10:43:05 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 08:21:13 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Goyal", "Palash", ""], ["Huang", "Di", ""], ["Chhetri", "Sujit Rokka", ""], ["Canedo", "Arquimedes", ""], ["Shree", "Jaya", ""], ["Patterson", "Evan", ""]]}, {"id": "1909.02820", "submitter": "Minyoung Kim", "authors": "Minyoung Kim, Yuting Wang, Pritish Sahu, Vladimir Pavlovic", "title": "Bayes-Factor-VAE: Hierarchical Bayesian Deep Auto-Encoder Models for\n  Factor Disentanglement", "comments": "International Conference on Computer Vision (ICCV) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a family of novel hierarchical Bayesian deep auto-encoder models\ncapable of identifying disentangled factors of variability in data. While many\nrecent attempts at factor disentanglement have focused on sophisticated\nlearning objectives within the VAE framework, their choice of a standard normal\nas the latent factor prior is both suboptimal and detrimental to performance.\nOur key observation is that the disentangled latent variables responsible for\nmajor sources of variability, the relevant factors, can be more appropriately\nmodeled using long-tail distributions. The typical Gaussian priors are, on the\nother hand, better suited for modeling of nuisance factors. Motivated by this,\nwe extend the VAE to a hierarchical Bayesian model by introducing hyper-priors\non the variances of Gaussian latent priors, mimicking an infinite mixture,\nwhile maintaining tractable learning and inference of the traditional VAEs.\nThis analysis signifies the importance of partitioning and treating in a\ndifferent manner the latent dimensions corresponding to relevant factors and\nnuisances. Our proposed models, dubbed Bayes-Factor-VAEs, are shown to\noutperform existing methods both quantitatively and qualitatively in terms of\nlatent disentanglement across several challenging benchmark tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 11:20:42 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Kim", "Minyoung", ""], ["Wang", "Yuting", ""], ["Sahu", "Pritish", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "1909.02827", "submitter": "Wissam Siblini", "authors": "Wissam Siblini, Jordan Fr\\'ery, Liyun He-Guelton, Fr\\'ed\\'eric Obl\\'e,\n  Yi-Qing Wang", "title": "Master your Metrics with Calibration", "comments": "Presented at IDA2020", "journal-ref": null, "doi": "10.1007/978-3-030-44584-3_36", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models deployed in real-world applications are often\nevaluated with precision-based metrics such as F1-score or AUC-PR (Area Under\nthe Curve of Precision Recall). Heavily dependent on the class prior, such\nmetrics make it difficult to interpret the variation of a model's performance\nover different subpopulations/subperiods in a dataset. In this paper, we\npropose a way to calibrate the metrics so that they can be made invariant to\nthe prior. We conduct a large number of experiments on balanced and imbalanced\ndata to assess the behavior of calibrated metrics and show that they improve\ninterpretability and provide a better control over what is really measured. We\ndescribe specific real-world use-cases where calibration is beneficial such as,\nfor instance, model monitoring in production, reporting, or fairness\nevaluation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 11:44:39 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 09:58:48 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Siblini", "Wissam", ""], ["Fr\u00e9ry", "Jordan", ""], ["He-Guelton", "Liyun", ""], ["Obl\u00e9", "Fr\u00e9d\u00e9ric", ""], ["Wang", "Yi-Qing", ""]]}, {"id": "1909.02829", "submitter": "Patrick Horain", "authors": "Priyadarshini Adyasha Pattanaik (INTERMEDIA), Zelong Wang (TSP),\n  Patrick Horain (INTERMEDIA)", "title": "Deep CNN frameworks comparison for malaria diagnosis", "comments": null, "journal-ref": "IMVIP 2019 Irish Machine Vision and Image Processing Conference,\n  Sep 2019, Dublin, Ireland", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare Deep Convolutional Neural Networks (DCNN) frameworks, namely\nAlexNet and VGGNet, for the classification of healthy and malaria-infected\ncells in large, grayscale, low quality and low resolution microscopic images,\nin the case only a small training set is available. Experimental results\ndeliver promising results on the path to quick, automatic and precise\nclassification in unstained images.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 11:46:04 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Pattanaik", "Priyadarshini Adyasha", "", "INTERMEDIA"], ["Wang", "Zelong", "", "TSP"], ["Horain", "Patrick", "", "INTERMEDIA"]]}, {"id": "1909.02850", "submitter": "Abigail Lee-Leon Ms", "authors": "Abigail Lee-Leon, Chau Yuen, Dorien Herremans", "title": "Doppler Invariant Demodulation for Shallow Water Acoustic Communications\n  Using Deep Belief Networks", "comments": null, "journal-ref": "Proceedings of 16th IEEE Asia Pacific Wireless Communications\n  Symposium (APWCS). 2019. Singapore", "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shallow water environments create a challenging channel for communications.\nIn this paper, we focus on the challenges posed by the frequency-selective\nsignal distortion called the Doppler effect. We explore the design and\nperformance of machine learning (ML) based demodulation methods --- (1) Deep\nBelief Network-feed forward Neural Network (DBN-NN) and (2) Deep Belief\nNetwork-Convolutional Neural Network (DBN-CNN) in the physical layer of Shallow\nWater Acoustic Communication (SWAC). The proposed method comprises of a ML\nbased feature extraction method and classification technique. First, the\nfeature extraction converts the received signals to feature images. Next, the\nclassification model correlates the images to a corresponding binary\nrepresentative. An analysis of the ML based proposed demodulation shows that\ndespite the presence of instantaneous frequencies, the performance of the\nalgorithm shows an invariance with a small 2dB error margin in terms of bit\nerror rate (BER).\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 07:54:36 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Lee-Leon", "Abigail", ""], ["Yuen", "Chau", ""], ["Herremans", "Dorien", ""]]}, {"id": "1909.02851", "submitter": "Piotr Szyma\\'nski", "authors": "Jan Mizgajski, Adrian Szymczak, Robert G{\\l}owski, Piotr Szyma\\'nski,\n  Piotr \\.Zelasko, {\\L}ukasz Augustyniak, Miko{\\l}aj Morzy, Yishay Carmiel,\n  Jeff Hodson, {\\L}ukasz W\\'ojciak, Daniel Smoczyk, Adam Wr\\'obel, Bartosz\n  Borowik, Adam Artajew, Marcin Baran, Cezary Kwiatkowski, Marzena\n  \\.Zy{\\l}a-Hoppe", "title": "Avaya Conversational Intelligence: A Real-Time System for Spoken\n  Language Understanding in Human-Human Call Center Conversations", "comments": "Accepted for Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Avaya Conversational Intelligence(ACI) is an end-to-end, cloud-based solution\nfor real-time Spoken Language Understanding for call centers. It combines large\nvocabulary, real-time speech recognition, transcript refinement, and entity and\nintent recognition in order to convert live audio into a rich, actionable\nstream of structured events. These events can be further leveraged with a\nbusiness rules engine, thus serving as a foundation for real-time supervision\nand assistance applications. After the ingestion, calls are enriched with\nunsupervised keyword extraction, abstractive summarization, and\nbusiness-defined attributes, enabling offline use cases, such as business\nintelligence, topic mining, full-text search, quality assurance, and agent\ntraining. ACI comes with a pretrained, configurable library of hundreds of\nintents and a robust intent training environment that allows for efficient,\ncost-effective creation and customization of customer-specific intents.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 22:57:10 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Mizgajski", "Jan", ""], ["Szymczak", "Adrian", ""], ["G\u0142owski", "Robert", ""], ["Szyma\u0144ski", "Piotr", ""], ["\u017belasko", "Piotr", ""], ["Augustyniak", "\u0141ukasz", ""], ["Morzy", "Miko\u0142aj", ""], ["Carmiel", "Yishay", ""], ["Hodson", "Jeff", ""], ["W\u00f3jciak", "\u0141ukasz", ""], ["Smoczyk", "Daniel", ""], ["Wr\u00f3bel", "Adam", ""], ["Borowik", "Bartosz", ""], ["Artajew", "Adam", ""], ["Baran", "Marcin", ""], ["Kwiatkowski", "Cezary", ""], ["\u017by\u0142a-Hoppe", "Marzena", ""]]}, {"id": "1909.02859", "submitter": "Khaled Koutini", "authors": "Khaled Koutini, Hamid Eghbal-zadeh and Gerhard Widmer", "title": "Receptive-field-regularized CNN variants for acoustic scene\n  classification", "comments": "Accepted at Detection and Classification of Acoustic Scenes and\n  Events 2019 (DCASE Workshop 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic scene classification and related tasks have been dominated by\nConvolutional Neural Networks (CNNs). Top-performing CNNs use mainly audio\nspectograms as input and borrow their architectural design primarily from\ncomputer vision. A recent study has shown that restricting the receptive field\n(RF) of CNNs in appropriate ways is crucial for their performance, robustness\nand generalization in audio tasks. One side effect of restricting the RF of\nCNNs is that more frequency information is lost. In this paper, we perform a\nsystematic investigation of different RF configuration for various CNN\narchitectures on the DCASE 2019 Task 1.A dataset. Second, we introduce\nFrequency Aware CNNs to compensate for the lack of frequency information caused\nby the restricted RF, and experimentally determine if and in what RF ranges\nthey yield additional improvement. The result of these investigations are\nseveral well-performing submissions to different tasks in the DCASE 2019\nChallenge.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 12:40:38 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Koutini", "Khaled", ""], ["Eghbal-zadeh", "Hamid", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1909.02869", "submitter": "Paul Primus", "authors": "Paul Primus, Hamid Eghbal-zadeh, David Eitelsebner, Khaled Koutini,\n  Andreas Arzt and Gerhard Widmer", "title": "Exploiting Parallel Audio Recordings to Enforce Device Invariance in\n  CNN-based Acoustic Scene Classification", "comments": "Published at the Workshop on Detection and Classification of Acoustic\n  Scenes and Events, 25-26 October 2019, New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution mismatches between the data seen at training and at application\ntime remain a major challenge in all application areas of machine learning. We\nstudy this problem in the context of machine listening (Task 1b of the DCASE\n2019 Challenge). We propose a novel approach to learn domain-invariant\nclassifiers in an end-to-end fashion by enforcing equal hidden layer\nrepresentations for domain-parallel samples, i.e. time-aligned recordings from\ndifferent recording devices. No classification labels are needed for our domain\nadaptation (DA) method, which makes the data collection process cheaper.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 16:19:50 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Primus", "Paul", ""], ["Eghbal-zadeh", "Hamid", ""], ["Eitelsebner", "David", ""], ["Koutini", "Khaled", ""], ["Arzt", "Andreas", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1909.02877", "submitter": "Long Yang", "authors": "Long Yang, Yu Zhang, Qian Zheng, Pengfei Li, Gang Pan", "title": "Gradient Q$(\\sigma, \\lambda)$: A Unified Algorithm with Function\n  Approximation for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Full-sampling (e.g., Q-learning) and pure-expectation (e.g., Expected Sarsa)\nalgorithms are efficient and frequently used techniques in reinforcement\nlearning. Q$(\\sigma,\\lambda)$ is the first approach unifies them with\neligibility trace through the sampling degree $\\sigma$. However, it is limited\nto the tabular case, for large-scale learning, the Q$(\\sigma,\\lambda)$ is too\nexpensive to require a huge volume of tables to accurately storage value\nfunctions. To address above problem, we propose a GQ$(\\sigma,\\lambda)$ that\nextends tabular Q$(\\sigma,\\lambda)$ with linear function approximation. We\nprove the convergence of GQ$(\\sigma,\\lambda)$. Empirical results on some\nstandard domains show that GQ$(\\sigma,\\lambda)$ with a combination of\nfull-sampling with pure-expectation reach a better performance than\nfull-sampling and pure-expectation methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 12:54:03 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Yang", "Long", ""], ["Zhang", "Yu", ""], ["Zheng", "Qian", ""], ["Li", "Pengfei", ""], ["Pan", "Gang", ""]]}, {"id": "1909.02900", "submitter": "Yann Issartel", "authors": "Yann Issartel", "title": "On the Estimation of Network Complexity: Dimension of Graphons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network complexity has been studied for over half a century and has found a\nwide range of applications. Many methods have been developed to characterize\nand estimate the complexity of networks. However, there has been little\nresearch with statistical guarantees. In this paper, we develop a statistical\ntheory of graph complexity in a general model of random graphs, the so-called\ngraphon model.\n  Given a graphon, we endow the latent space of the nodes with the neighborhood\ndistance that measures the propensity of two nodes to be connected with similar\nnodes. Our complexity index is then based on the covering number and the\nMinkowski dimension of (a purified version of) this metric space. Although the\nlatent space is not identifiable, these indices turn out to be identifiable.\nThis notion of complexity has simple interpretations on popular examples of\nrandom graphs: it matches the number of communities in stochastic block models;\nthe dimension of the Euclidean space in random geometric graphs; the regularity\nof the link function in H\\\"older graphon models.\n  From a single observation of the graph, we construct an estimator of the\nneighborhood-distance and show universal non-asymptotic bounds for its risk,\nmatching minimax lower bounds. Based on this estimated distance, we compute the\ncorresponding covering number and Minkowski dimension and we provide optimal\nnon-asymptotic error bounds for these two plug-in estimators.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 13:35:39 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 00:52:27 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Issartel", "Yann", ""]]}, {"id": "1909.02902", "submitter": "Lingbo Liu", "authors": "Lingbo Liu, Jiajie Zhen, Guanbin Li, Geng Zhan, Zhaocheng He, Bowen\n  Du, Liang Lin", "title": "Dynamic Spatial-Temporal Representation Learning for Traffic Flow\n  Prediction", "comments": "Accepted by IEEE Transactions on Intelligent Transportation Systems.\n  arXiv admin note: text overlap with arXiv:1809.00101", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a crucial component in intelligent transportation systems, traffic flow\nprediction has recently attracted widespread research interest in the field of\nartificial intelligence (AI) with the increasing availability of massive\ntraffic mobility data. Its key challenge lies in how to integrate diverse\nfactors (such as temporal rules and spatial dependencies) to infer the\nevolution trend of traffic flow. To address this problem, we propose a unified\nneural network called Attentive Traffic Flow Machine (ATFM), which can\neffectively learn the spatial-temporal feature representations of traffic flow\nwith an attention mechanism. In particular, our ATFM is composed of two\nprogressive Convolutional Long Short-Term Memory (ConvLSTM\n\\cite{xingjian2015convolutional}) units connected with a convolutional layer.\nSpecifically, the first ConvLSTM unit takes normal traffic flow features as\ninput and generates a hidden state at each time-step, which is further fed into\nthe connected convolutional layer for spatial attention map inference. The\nsecond ConvLSTM unit aims at learning the dynamic spatial-temporal\nrepresentations from the attentionally weighted traffic flow features. Further,\nwe develop two deep learning frameworks based on ATFM to predict citywide\nshort-term/long-term traffic flow by adaptively incorporating the sequential\nand periodic data as well as other external influences. Extensive experiments\non two standard benchmarks well demonstrate the superiority of the proposed\nmethod for traffic flow prediction. Moreover, to verify the generalization of\nour method, we also apply the customized framework to forecast the passenger\npickup/dropoff demands in traffic prediction and show its superior performance.\nOur code and data are available at\n{\\color{blue}\\url{https://github.com/liulingbo918/ATFM}}.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 01:41:38 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 17:10:48 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 13:08:40 GMT"}, {"version": "v4", "created": "Sat, 13 Jun 2020 01:21:01 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Liu", "Lingbo", ""], ["Zhen", "Jiajie", ""], ["Li", "Guanbin", ""], ["Zhan", "Geng", ""], ["He", "Zhaocheng", ""], ["Du", "Bowen", ""], ["Lin", "Liang", ""]]}, {"id": "1909.02918", "submitter": "Ilia Shumailov", "authors": "Yiren Zhao, Ilia Shumailov, Han Cui, Xitong Gao, Robert Mullins, Ross\n  Anderson", "title": "Blackbox Attacks on Reinforcement Learning Agents Using Approximated\n  Temporal Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recent research on reinforcement learning (RL) has suggested that trained\nagents are vulnerable to maliciously crafted adversarial samples. In this work,\nwe show how such samples can be generalised from White-box and Grey-box attacks\nto a strong Black-box case, where the attacker has no knowledge of the agents,\ntheir training parameters and their training methods. We use\nsequence-to-sequence models to predict a single action or a sequence of future\nactions that a trained agent will make. First, we show our approximation model,\nbased on time-series information from the agent, consistently predicts RL\nagents' future actions with high accuracy in a Black-box setup on a wide range\nof games and RL algorithms. Second, we find that although adversarial samples\nare transferable from the target model to our RL agents, they often outperform\nrandom Gaussian noise only marginally. This highlights a serious methodological\ndeficiency in previous work on such agents; random jamming should have been\ntaken as the baseline for evaluation. Third, we propose a novel use for\nadversarial samplesin Black-box attacks of RL agents: they can be used to\ntrigger a trained agent to misbehave after a specific time delay. This appears\nto be a genuinely new type of attack. It potentially enables an attacker to use\ndevices controlled by RL agents as time bombs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:06:21 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 19:07:45 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhao", "Yiren", ""], ["Shumailov", "Ilia", ""], ["Cui", "Han", ""], ["Gao", "Xitong", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "1909.02930", "submitter": "Michael Cochez", "authors": "Ruijie Wang, Meng Wang, Jun Liu, Michael Cochez, Stefan Decker", "title": "Structured Query Construction via Knowledge Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to facilitate the accesses of general users to knowledge graphs, an\nincreasing effort is being exerted to construct graph-structured queries of\ngiven natural language questions. At the core of the construction is to deduce\nthe structure of the target query and determine the vertices/edges which\nconstitute the query. Existing query construction methods rely on question\nunderstanding and conventional graph-based algorithms which lead to inefficient\nand degraded performances facing complex natural language questions over\nknowledge graphs with large scales. In this paper, we focus on this problem and\npropose a novel framework standing on recent knowledge graph embedding\ntechniques. Our framework first encodes the underlying knowledge graph into a\nlow-dimensional embedding space by leveraging generalized local knowledge\ngraphs. Given a natural language question, the learned embedding\nrepresentations of the knowledge graph are utilized to compute the query\nstructure and assemble vertices/edges into the target query. Extensive\nexperiments were conducted on the benchmark dataset, and the results\ndemonstrate that our framework outperforms state-of-the-art baseline models\nregarding effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:29:00 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Wang", "Ruijie", ""], ["Wang", "Meng", ""], ["Liu", "Jun", ""], ["Cochez", "Michael", ""], ["Decker", "Stefan", ""]]}, {"id": "1909.02939", "submitter": "Harikrishna Narasimhan", "authors": "Harikrishna Narasimhan, Andrew Cotter, Maya Gupta", "title": "Optimizing Generalized Rate Metrics through Game Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general framework for solving a large class of learning problems\nwith non-linear functions of classification rates. This includes problems where\none wishes to optimize a non-decomposable performance metric such as the\nF-measure or G-mean, and constrained training problems where the classifier\nneeds to satisfy non-linear rate constraints such as predictive parity\nfairness, distribution divergences or churn ratios. We extend previous\ntwo-player game approaches for constrained optimization to a game between three\nplayers to decouple the classifier rates from the non-linear objective, and\nseek to find an equilibrium of the game. Our approach generalizes many existing\nalgorithms, and makes possible new algorithms with more flexibility and tighter\nhandling of non-linear rate constraints. We provide convergence guarantees for\nconvex functions of rates, and show how our methodology can be extended to\nhandle sums of ratios of rates. Experiments on different fairness tasks confirm\nthe efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:47:33 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Narasimhan", "Harikrishna", ""], ["Cotter", "Andrew", ""], ["Gupta", "Maya", ""]]}, {"id": "1909.02940", "submitter": "Vaneet Aggarwal", "authors": "Mridul Agarwal and Vaneet Aggarwal", "title": "Reinforcement Learning for Joint Optimization of Multiple Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.IT cs.MA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms such as DQN owe their success to\nMarkov Decision Processes, and the fact that maximizing the sum of rewards\nallows using backward induction and reduce to the Bellman optimality equation.\nHowever, many real-world problems require optimization of an objective that is\nnon-linear in cumulative rewards for which dynamic programming cannot be\napplied directly. For example, in a resource allocation problem, one of the\nobjectives is to maximize long-term fairness among the users. We notice that\nwhen the function of the sum of rewards is considered, the problem loses its\nMarkov nature. This paper addresses and formalizes the problem of optimizing a\nnon-linear function of the long term average of rewards. We propose model-based\nand model-free algorithms to learn the policy, where the model-based policy is\nshown to achieve a regret of $\\Tilde{O}\\left(KDSA\\sqrt{\\frac{A}{T}}\\right)$ for\n$K$ users. Further, using the fairness in cellular base-station scheduling, and\nqueueing system scheduling as examples, the proposed algorithm is shown to\nsignificantly outperform the conventional RL approaches.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:48:07 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 20:42:51 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 05:10:01 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1909.02945", "submitter": "Vaneet Aggarwal", "authors": "Sathwik Chadaga and Mridul Agarwal and Vaneet Aggarwal", "title": "Encoders and Decoders for Quantum Expander Codes Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum key distribution (QKD) allows two distant parties to share encryption\nkeys with security based on laws of quantum mechanics. In order to share the\nkeys, the quantum bits have to be transmitted from the sender to the receiver\nover a noisy quantum channel. In order to transmit this information, efficient\nencoders and decoders need to be designed. However, large-scale design of\nquantum encoders and decoders have to depend on the channel characteristics and\nrequire look-up tables which require memory that is exponential in the number\nof qubits. In order to alleviate that, this paper aims to design the quantum\nencoders and decoders for expander codes by adapting techniques from machine\nlearning including reinforcement learning and neural networks to the quantum\ndomain. The proposed quantum decoder trains a neural network which is trained\nusing the maximum aposteriori error for the syndromes, eliminating the use of\nlarge lookup tables. The quantum encoder uses deep Q-learning based techniques\nto optimize the generator matrices in the quantum Calderbank-Shor-Steane (CSS)\ncodes. The evaluation results demonstrate improved performance of the proposed\nquantum encoder and decoder designs as compared to the quantum expander codes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:56:34 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Chadaga", "Sathwik", ""], ["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1909.02950", "submitter": "Douwe Kiela", "authors": "Douwe Kiela, Suvrat Bhooshan, Hamed Firooz, Ethan Perez, Davide\n  Testuggine", "title": "Supervised Multimodal Bitransformers for Classifying Images and Text", "comments": "Rejected from EMNLP, twice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised bidirectional transformer models such as BERT have led to\ndramatic improvements in a wide variety of textual classification tasks. The\nmodern digital world is increasingly multimodal, however, and textual\ninformation is often accompanied by other modalities such as images. We\nintroduce a supervised multimodal bitransformer model that fuses information\nfrom text and image encoders, and obtain state-of-the-art performance on\nvarious multimodal classification benchmark tasks, outperforming strong\nbaselines, including on hard test sets specifically designed to measure\nmultimodal performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:59:18 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 03:08:28 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kiela", "Douwe", ""], ["Bhooshan", "Suvrat", ""], ["Firooz", "Hamed", ""], ["Perez", "Ethan", ""], ["Testuggine", "Davide", ""]]}, {"id": "1909.02963", "submitter": "Abir De", "authors": "Abir De, Nastaran Okati, Paramita Koley, Niloy Ganguly, Manuel\n  Gomez-Rodriguez", "title": "Regression Under Human Assistance", "comments": "Extended version of AAAI 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decisions are increasingly taken by both humans and machine learning models.\nHowever, machine learning models are currently trained for full automation --\nthey are not aware that some of the decisions may still be taken by humans. In\nthis paper, we take a first step towards the development of machine learning\nmodels that are optimized to operate under different automation levels. More\nspecifically, we first introduce the problem of ridge regression under human\nassistance and show that it is NP-hard. Then, we derive an alternative\nrepresentation of the corresponding objective function as a difference of\nnondecreasing submodular functions. Building on this representation, we further\nshow that the objective is nondecreasing and satisfies $\\alpha$-submodularity,\na recently introduced notion of approximate submodularity. These properties\nallow a simple and efficient greedy algorithm to enjoy approximation guarantees\nat solving the problem. Experiments on synthetic and real-world data from two\nimportant applications -- medical diagnosis and content moderation-demonstrate\nthat our algorithm outsources to humans those samples in which the prediction\nerror of the ridge regression model would have been the highest if it had to\nmake a prediction, it outperforms several competitive baselines, and its\nperformance is robust with respect to several design choices and\nhyperparameters used in the experiments.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:08:52 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 11:56:14 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 12:19:33 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 10:42:37 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["De", "Abir", ""], ["Okati", "Nastaran", ""], ["Koley", "Paramita", ""], ["Ganguly", "Niloy", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1909.02964", "submitter": "Roxana R\\u{a}dulescu", "authors": "Roxana R\\u{a}dulescu, Patrick Mannion, Diederik M. Roijers, Ann Now\\'e", "title": "Multi-Objective Multi-Agent Decision Making: A Utility-based Analysis\n  and Survey", "comments": "Under review since 15 May 2019", "journal-ref": null, "doi": "10.1007/s10458-019-09433-x", "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of multi-agent system (MAS) implementations aim to optimise\nagents' policies with respect to a single objective, despite the fact that many\nreal-world problem domains are inherently multi-objective in nature.\nMulti-objective multi-agent systems (MOMAS) explicitly consider the possible\ntrade-offs between conflicting objective functions. We argue that, in MOMAS,\nsuch compromises should be analysed on the basis of the utility that these\ncompromises have for the users of a system. As is standard in multi-objective\noptimisation, we model the user utility using utility functions that map value\nor return vectors to scalar values. This approach naturally leads to two\ndifferent optimisation criteria: expected scalarised returns (ESR) and\nscalarised expected returns (SER). We develop a new taxonomy which classifies\nmulti-objective multi-agent decision making settings, on the basis of the\nreward structures, and which and how utility functions are applied. This allows\nus to offer a structured view of the field, to clearly delineate the current\nstate-of-the-art in multi-objective multi-agent decision making approaches and\nto identify promising directions for future research. Starting from the\nexecution phase, in which the selected policies are applied and the utility for\nthe users is attained, we analyse which solution concepts apply to the\ndifferent settings in our taxonomy. Furthermore, we define and discuss these\nsolution concepts under both ESR and SER optimisation criteria. We conclude\nwith a summary of our main findings and a discussion of many promising future\nresearch directions in multi-objective multi-agent systems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:09:31 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["R\u0103dulescu", "Roxana", ""], ["Mannion", "Patrick", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1909.02971", "submitter": "Ali Bahrami Rad", "authors": "Ali Bahrami Rad, Morteza Zabihi, Zheng Zhao, Moncef Gabbouj, Aggelos\n  K. Katsaggelos, and Simo S\\\"arkk\\\"a", "title": "Automated Polysomnography Analysis for Detection of Non-Apneic and\n  Non-Hypopneic Arousals using Feature Engineering and a Bidirectional LSTM\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: The aim of this study is to develop an automated classification\nalgorithm for polysomnography (PSG) recordings to detect non-apneic and\nnon-hypopneic arousals. Our particular focus is on detecting the respiratory\neffort-related arousals (RERAs) which are very subtle respiratory events that\ndo not meet the criteria for apnea or hypopnea, and are more challenging to\ndetect. Methods: The proposed algorithm is based on a bidirectional long\nshort-term memory (BiLSTM) classifier and 465 multi-domain features, extracted\nfrom multimodal clinical time series. The features consist of a set of\nphysiology-inspired features (n = 75), obtained by multiple steps of feature\nselection and expert analysis, and a set of physiology-agnostic features (n =\n390), derived from scattering transform. Results: The proposed algorithm is\nvalidated on the 2018 PhysioNet challenge dataset. The overall performance in\nterms of the area under the precision-recall curve (AUPRC) is 0.50 on the\nhidden test dataset. This result is tied for the second-best score during the\nfollow-up and official phases of the 2018 PhysioNet challenge. Conclusions: The\nresults demonstrate that it is possible to automatically detect subtle\nnon-apneic/non-hypopneic arousal events from PSG recordings. Significance:\nAutomatic detection of subtle respiratory events such as RERAs together with\nother non-apneic/non-hypopneic arousals will allow detailed annotations of\nlarge PSG databases. This contributes to a better retrospective analysis of\nsleep data, which may also improve the quality of treatment.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:29:54 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Rad", "Ali Bahrami", ""], ["Zabihi", "Morteza", ""], ["Zhao", "Zheng", ""], ["Gabbouj", "Moncef", ""], ["Katsaggelos", "Aggelos K.", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "1909.02977", "submitter": "Chi Thang Duong", "authors": "Chi Thang Duong, Hongzhi Yin, Thanh Dat Hoang, Truong Giang Le Ba,\n  Matthias Weidlich, Quoc Viet Hung Nguyen, Karl Aberer", "title": "Parallel Computation of Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph embedding aims at learning a vector-based representation of vertices\nthat incorporates the structure of the graph. This representation then enables\ninference of graph properties. Existing graph embedding techniques, however, do\nnot scale well to large graphs. We therefore propose a framework for parallel\ncomputation of a graph embedding using a cluster of compute nodes with resource\nconstraints. We show how to distribute any existing embedding technique by\nfirst splitting a graph for any given set of constrained compute nodes and then\nreconciling the embedding spaces derived for these subgraphs. We also propose a\nnew way to evaluate the quality of graph embeddings that is independent of a\nspecific inference task. Based thereon, we give a formal bound on the\ndifference between the embeddings derived by centralised and parallel\ncomputation. Experimental results illustrate that our approach for parallel\ncomputation scales well, while largely maintaining the embedding quality.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:41:44 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Duong", "Chi Thang", ""], ["Yin", "Hongzhi", ""], ["Hoang", "Thanh Dat", ""], ["Ba", "Truong Giang Le", ""], ["Weidlich", "Matthias", ""], ["Nguyen", "Quoc Viet Hung", ""], ["Aberer", "Karl", ""]]}, {"id": "1909.02982", "submitter": "Theo Jaunet", "authors": "Theo Jaunet, Romain Vuillemot and Christian Wolf", "title": "DRLViz: Understanding Decisions and Memory in Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DRLViz, a visual analytics interface to interpret the internal\nmemory of an agent (e.g. a robot) trained using deep reinforcement learning.\nThis memory is composed of large temporal vectors updated when the agent moves\nin an environment and is not trivial to understand due to the number of\ndimensions, dependencies to past vectors, spatial/temporal correlations, and\nco-correlation between dimensions. It is often referred to as a black box as\nonly inputs (images) and outputs (actions) are intelligible for humans. Using\nDRLViz, experts are assisted to interpret decisions using memory reduction\ninteractions, and to investigate the role of parts of the memory when errors\nhave been made (e.g. wrong direction). We report on DRLViz applied in the\ncontext of video games simulators (ViZDoom) for a navigation scenario with item\ngathering tasks. We also report on experts evaluation using DRLViz, and\napplicability of DRLViz to other scenarios and navigation problems beyond\nsimulation games, as well as its contribution to black box models\ninterpretability and explainability in the field of visual analytics.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:56:39 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 16:07:35 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Jaunet", "Theo", ""], ["Vuillemot", "Romain", ""], ["Wolf", "Christian", ""]]}, {"id": "1909.02998", "submitter": "Tino Werner", "authors": "Tino Werner", "title": "A review on ranking problems in statistical learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking problems, also known as preference learning problems, define a widely\nspread class of statistical learning problems with many applications, including\nfraud detection, document ranking, medicine, credit risk screening, image\nranking or media memorability. In this article, we systematically review\ndifferent types of instance ranking problems, i.e., ranking problems that\nrequire the prediction of an order of the response variables, and the\ncorresponding loss functions resp. goodness criteria. We discuss the\ndifficulties when trying to optimize those criteria. As for a detailed and\ncomprehensive overview of existing machine learning techniques to solve such\nranking problems, we systemize existing techniques and recapitulate the\ncorresponding optimization problems in a unified notation. We also discuss to\nwhich of the ranking problems the respective algorithms are tailored and\nidentify their strengths and limitations. Computational aspects and open\nresearch problems are also considered.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:24:23 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 13:30:41 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 14:11:07 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Werner", "Tino", ""]]}, {"id": "1909.03004", "submitter": "Jesse Dodge", "authors": "Jesse Dodge, Suchin Gururangan, Dallas Card, Roy Schwartz, Noah A.\n  Smith", "title": "Show Your Work: Improved Reporting of Experimental Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in natural language processing proceeds, in part, by demonstrating\nthat new models achieve superior performance (e.g., accuracy) on held-out test\ndata, compared to previous results. In this paper, we demonstrate that test-set\nperformance scores alone are insufficient for drawing accurate conclusions\nabout which model performs best. We argue for reporting additional details,\nespecially performance on validation data obtained during model development. We\npresent a novel technique for doing so: expected validation performance of the\nbest-found model as a function of computation budget (i.e., the number of\nhyperparameter search trials or the overall training time). Using our approach,\nwe find multiple recent model comparisons where authors would have reached a\ndifferent conclusion if they had used more (or less) computation. Our approach\nalso allows us to estimate the amount of computation required to obtain a given\naccuracy; applying it to several recently published results yields massive\nvariation across papers, from hours to weeks. We conclude with a set of best\npractices for reporting experimental results which allow for robust future\ncomparisons, and provide code to allow researchers to use our technique.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:40:42 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Dodge", "Jesse", ""], ["Gururangan", "Suchin", ""], ["Card", "Dallas", ""], ["Schwartz", "Roy", ""], ["Smith", "Noah A.", ""]]}, {"id": "1909.03009", "submitter": "Konstantinos Pitas", "authors": "Konstantinos Pitas", "title": "Dissecting Non-Vacuous Generalization Bounds based on the Mean-Field\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining how overparametrized neural networks simultaneously achieve low\nrisk and zero empirical risk on benchmark datasets is an open problem.\nPAC-Bayes bounds optimized using variational inference (VI) have been recently\nproposed as a promising direction in obtaining non-vacuous bounds. We show\nempirically that this approach gives negligible gains when modeling the\nposterior as a Gaussian with diagonal covariance--known as the mean-field\napproximation. We investigate common explanations, such as the failure of VI\ndue to problems in optimization or choosing a suboptimal prior. Our results\nsuggest that investigating richer posteriors is the most promising direction\nforward.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:43:49 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 16:57:07 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Pitas", "Konstantinos", ""]]}, {"id": "1909.03011", "submitter": "Jesse Dodge", "authors": "Jesse Dodge, Roy Schwartz, Hao Peng, Noah A. Smith", "title": "RNN Architecture Learning with Sparse Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models for NLP typically use large numbers of parameters to reach\nstate-of-the-art performance, which can lead to excessive memory usage and\nincreased runtime. We present a structure learning method for learning sparse,\nparameter-efficient NLP models. Our method applies group lasso to rational RNNs\n(Peng et al., 2018), a family of models that is closely connected to weighted\nfinite-state automata (WFSAs). We take advantage of rational RNNs' natural\ngrouping of the weights, so the group lasso penalty directly removes WFSA\nstates, substantially reducing the number of parameters in the model. Our\nexperiments on a number of sentiment analysis datasets, using both GloVe and\nBERT embeddings, show that our approach learns neural structures which have\nfewer parameters without sacrificing performance relative to parameter-rich\nbaselines. Our method also highlights the interpretable properties of rational\nRNNs. We show that sparsifying such models makes them easier to visualize, and\nwe present models that rely exclusively on as few as three WFSAs after pruning\nmore than 90% of the weights. We publicly release our code.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:51:21 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Dodge", "Jesse", ""], ["Schwartz", "Roy", ""], ["Peng", "Hao", ""], ["Smith", "Noah A.", ""]]}, {"id": "1909.03013", "submitter": "Xiaoqian Wang", "authors": "Xiaoqian Wang, Heng Huang", "title": "Approaching Machine Learning Fairness through Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is becoming a rising concern w.r.t. machine learning model\nperformance. Especially for sensitive fields such as criminal justice and loan\ndecision, eliminating the prediction discrimination towards a certain group of\npopulation (characterized by sensitive features like race and gender) is\nimportant for enhancing the trustworthiness of model. In this paper, we present\na new general framework to improve machine learning fairness. The goal of our\nmodel is to minimize the influence of sensitive feature from the perspectives\nof both the data input and the predictive model. In order to achieve this goal,\nwe reformulate the data input by removing the sensitive information and\nstrengthen model fairness by minimizing the marginal contribution of the\nsensitive feature. We propose to learn the non-sensitive input via sampling\namong features and design an adversarial network to minimize the dependence\nbetween the reformulated input and the sensitive information. Extensive\nexperiments on three benchmark datasets suggest that our model achieve better\nresults than related state-of-the-art methods with respect to both fairness\nmetrics and prediction performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:55:05 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Wang", "Xiaoqian", ""], ["Huang", "Heng", ""]]}, {"id": "1909.03030", "submitter": "Xizi Wei", "authors": "Xizi Wei, Melvyn Hunt, Adrian Skilling", "title": "Neural Network-Based Modeling of Phonetic Durations", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep neural network (DNN)-based model has been developed to predict\nnon-parametric distributions of durations of phonemes in specified phonetic\ncontexts and used to explore which factors influence durations most. Major\nfactors in US English are pre-pausal lengthening, lexical stress, and speaking\nrate. The model can be used to check that text-to-speech (TTS) training speech\nfollows the script and words are pronounced as expected. Duration prediction is\npoorer with training speech for automatic speech recognition (ASR) because the\ntraining corpus typically consists of single utterances from many speakers and\nis often noisy or casually spoken. Low probability durations in ASR training\nmaterial nevertheless mostly correspond to non-standard speech, with some\nhaving disfluencies. Children's speech is disproportionately present in these\nutterances, since children show much more variation in timing.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:37:48 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Wei", "Xizi", ""], ["Hunt", "Melvyn", ""], ["Skilling", "Adrian", ""]]}, {"id": "1909.03037", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Saheb Pasand, Fakhri Karray, Mark Crowley", "title": "Quantized Fisher Discriminant Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.IV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new subspace learning method, named Quantized Fisher\nDiscriminant Analysis (QFDA), which makes use of both machine learning and\ninformation theory. There is a lack of literature for combination of machine\nlearning and information theory and this paper tries to tackle this gap. QFDA\nfinds a subspace which discriminates the uniformly quantized images in the\nDiscrete Cosine Transform (DCT) domain at least as well as discrimination of\nnon-quantized images by Fisher Discriminant Analysis (FDA) while the images\nhave been compressed. This helps the user to throw away the original images and\nkeep the compressed images instead without noticeable loss of classification\naccuracy. We propose a cost function whose minimization can be interpreted as\nrate-distortion optimization in information theory. We also propose quantized\nFisherfaces for facial analysis in QFDA. Our experiments on AT&T face dataset\nand Fashion MNIST dataset show the effectiveness of this subspace learning\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:46:21 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Pasand", "Ali Saheb", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1909.03039", "submitter": "Jonas Kemp", "authors": "Jonas Kemp, Alvin Rajkomar, Andrew M. Dai", "title": "Improved Hierarchical Patient Classification with Language Model\n  Pretraining over Clinical Notes", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - extended\n  abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical notes in electronic health records contain highly heterogeneous\nwriting styles, including non-standard terminology or abbreviations. Using\nthese notes in predictive modeling has traditionally required preprocessing\n(e.g. taking frequent terms or topic modeling) that removes much of the\nrichness of the source data. We propose a pretrained hierarchical recurrent\nneural network model that parses minimally processed clinical notes in an\nintuitive fashion, and show that it improves performance for discharge\ndiagnosis classification tasks on the Medical Information Mart for Intensive\nCare III (MIMIC-III) dataset, compared to models that treat the notes as an\nunordered collection of terms or that conduct no pretraining. We also apply an\nattribution technique to examples to identify the words that the model uses to\nmake its prediction, and show the importance of the words' nearby context.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:49:56 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 20:04:00 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 02:17:14 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kemp", "Jonas", ""], ["Rajkomar", "Alvin", ""], ["Dai", "Andrew M.", ""]]}, {"id": "1909.03044", "submitter": "Qingyu Chen", "authors": "Qingyu Chen, Jingcheng Du, Sun Kim, W. John Wilbur and Zhiyong Lu", "title": "Deep learning with sentence embeddings pre-trained on biomedical corpora\n  improves the performance of finding similar sentences in electronic medical\n  records", "comments": "15 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing sentence semantics plays a vital role in a range of text mining\napplications. Despite continuous efforts on the development of related datasets\nand models in the general domain, both datasets and models are limited in\nbiomedical and clinical domains. The BioCreative/OHNLP organizers have made the\nfirst attempt to annotate 1,068 sentence pairs from clinical notes and have\ncalled for a community effort to tackle the Semantic Textual Similarity\n(BioCreative/OHNLP STS) challenge. We developed models using traditional\nmachine learning and deep learning approaches. For the post challenge, we focus\non two models: the Random Forest and the Encoder Network. We applied sentence\nembeddings pre-trained on PubMed abstracts and MIMIC-III clinical notes and\nupdated the Random Forest and the Encoder Network accordingly. The official\nresults demonstrated our best submission was the ensemble of eight models. It\nachieved a Person correlation coefficient of 0.8328, the highest performance\namong 13 submissions from 4 teams. For the post challenge, the performance of\nboth Random Forest and the Encoder Network was improved; in particular, the\ncorrelation of the Encoder Network was improved by ~13%. During the challenge\ntask, no end-to-end deep learning models had better performance than machine\nlearning models that take manually-crafted features. In contrast, with the\nsentence embeddings pre-trained on biomedical corpora, the Encoder Network now\nachieves a correlation of ~0.84, which is higher than the original best model.\nThe ensembled model taking the improved versions of the Random Forest and\nEncoder Network as inputs further increased performance to 0.8528. Deep\nlearning models with sentence embeddings pre-trained on biomedical corpora\nachieve the highest performance on the test set.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:56:01 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Chen", "Qingyu", ""], ["Du", "Jingcheng", ""], ["Kim", "Sun", ""], ["Wilbur", "W. John", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1909.03050", "submitter": "Kaisheng Liao", "authors": "Kaisheng Liao, Yaodong Zhao, Jie Gu, Yaping Zhang, Yi Zhong", "title": "Sequential Convolutional Recurrent Neural Networks for Fast Automatic\n  Modulation Classification", "comments": "update the content for some details and clarity", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3053427", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel and efficient end-to-end learning model for automatic modulation\nclassification is proposed for wireless spectrum monitoring applications, which\nautomatically learns from the time domain in-phase and quadrature data without\nrequiring the design of hand-crafted expert features. With the intuition of\nconvolutional layers with pooling serving as the role of front-end feature\ndistillation and dimensionality reduction, sequential convolutional recurrent\nneural networks are developed to take complementary advantage of parallel\ncomputing capability of convolutional neural networks and temporal sensitivity\nof recurrent neural networks. Experimental results demonstrate that the\nproposed architecture delivers overall superior performance in signal to noise\nratio range above -10~dB, and achieves significantly improved classification\naccuracy from 80\\% to 92.1\\% at high signal to noise ratio range, while\ndrastically reduces the average training and prediction time by approximately\n74% and 67%, respectively. Response patterns learned by the proposed\narchitecture are visualized to better understand the physics of the model.\nFurthermore, a comparative study is performed to investigate the impacts of\nvarious sequential convolutional recurrent neural network structure settings on\nclassification performance. A representative sequential convolutional recurrent\nneural network architecture with the two-layer convolutional neural network and\nsubsequent two-layer long short-term memory neural network is developed to\nsuggest the option for fast automatic modulation classification.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:44:51 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 01:18:52 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Liao", "Kaisheng", ""], ["Zhao", "Yaodong", ""], ["Gu", "Jie", ""], ["Zhang", "Yaping", ""], ["Zhong", "Yi", ""]]}, {"id": "1909.03059", "submitter": "Trung V. Phan", "authors": "Trung V. Phan, Mehrdad Hajizadeh, Nguyen Tuan Khai and Thomas\n  Bauschert", "title": "Destination-aware Adaptive Traffic Flow Rule Aggregation in\n  Software-Defined Networks", "comments": "This paper was presented at NetSys conference 2019. arXiv admin note:\n  text overlap with arXiv:1909.01544", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a destination-aware adaptive traffic flow rule\naggregation (DATA) mechanism for facilitating traffic flow monitoring in\nSDN-based networks. This method adapts the number of flow table entries in SDN\nswitches according to the level of detail of traffic flow information that\nother mechanisms (e.g. for traffic engineering, traffic monitoring, intrusion\ndetection) require. It also prevents performance degradation of the SDN\nswitches by keeping the number of flow table entries well below a critical\nlevel. This level is not preset as a hard threshold but learned during\noperation by using a machine-learning based algorithm. The DATA method is\nimplemented within a RESTful application (DATA App) which monitors and analyzes\nthe ongoing network traffic and provides instructions to the SDN controller to\nadapt the traffic flow matching strategies accordingly. A thorough performance\nevaluation of DATA is conducted in an SDN emulation environment. The results\nshow that---compared to the default behavior of common SDN controllers---the\nproposed DATA approach yields significant SDN switch performance improvements\nwhile still providing detailed traffic flow information on demand.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 13:10:53 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Phan", "Trung V.", ""], ["Hajizadeh", "Mehrdad", ""], ["Khai", "Nguyen Tuan", ""], ["Bauschert", "Thomas", ""]]}, {"id": "1909.03069", "submitter": "Pedram Rooshenas", "authors": "MohamadAli Torkamani, Shiv Shankar, Amirmohammad Rooshenas, Phillip\n  Wallis", "title": "Differential Equation Units: Learning Functional Forms of Activation\n  Functions from Data", "comments": "arXiv admin note: text overlap with arXiv:1905.07685", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep neural networks use simple, fixed activation functions, such as\nsigmoids or rectified linear units, regardless of domain or network structure.\nWe introduce differential equation units (DEUs), an improvement to modern\nneural networks, which enables each neuron to learn a particular nonlinear\nactivation function from a family of solutions to an ordinary differential\nequation. Specifically, each neuron may change its functional form during\ntraining based on the behavior of the other parts of the network. We show that\nusing neurons with DEU activation functions results in a more compact network\ncapable of achieving comparable, if not superior, performance when is compared\nto much larger networks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 17:06:15 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Torkamani", "MohamadAli", ""], ["Shankar", "Shiv", ""], ["Rooshenas", "Amirmohammad", ""], ["Wallis", "Phillip", ""]]}, {"id": "1909.03082", "submitter": "Dhrubojyoti Roy", "authors": "Dhrubojyoti Roy, Sangeeta Srivastava, Aditya Kusupati, Pranshu Jain,\n  Manik Varma, Anish Arora", "title": "One Size Does Not Fit All: Multi-Scale, Cascaded RNNs for Radar\n  Classification", "comments": "Conditionally accepted to ACM BuildSys 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge sensing with micro-power pulse-Doppler radars is an emergent domain in\nmonitoring and surveillance with several smart city applications. Existing\nsolutions for the clutter versus multi-source radar classification task are\nlimited in terms of either accuracy or efficiency, and in some cases, struggle\nwith a trade-off between false alarms and recall of sources. We find that this\nproblem can be resolved by learning the classifier across multiple time-scales.\nWe propose a multi-scale, cascaded recurrent neural network architecture,\nMSC-RNN, comprised of an efficient multi-instance learning (MIL) Recurrent\nNeural Network (RNN) for clutter discrimination at a lower tier, and a more\ncomplex RNN classifier for source classification at the upper tier. By\ncontrolling the invocation of the upper RNN with the help of the lower tier\nconditionally, MSC-RNN achieves an overall accuracy of 0.972. Our approach\nholistically improves the accuracy and per-class recalls over ML models\nsuitable for radar inferencing. Notably, we outperform cross-domain handcrafted\nfeature engineering with time-domain deep feature learning, while also being up\nto $\\sim$3$\\times$ more efficient than a competitive solution.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 18:12:03 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Roy", "Dhrubojyoti", ""], ["Srivastava", "Sangeeta", ""], ["Kusupati", "Aditya", ""], ["Jain", "Pranshu", ""], ["Varma", "Manik", ""], ["Arora", "Anish", ""]]}, {"id": "1909.03091", "submitter": "Behnaz Akbarian", "authors": "Behnaz Akbarian, Abbas Erfanian", "title": "A framework for seizure detection using effective connectivity, graph\n  theory and deep modular neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective\n  The electrical characteristics of the EEG signals can be used for seizure\ndetection. Statistical independence between different brain regions is measured\nby functional brain connectivity (FBC). Specific directional effects can't\nconsider by FBC and thus effective brain connectivity (EBC) is used to measure\ncausal intervention between one neuronal region and the rest of the neuronal\nregions. Our main purpose is to provide a reliable automatic seizure detection\napproach.\n  Methods\n  In this study, three new methods are provided. Deep modular neural network\n(DMNN) is developed based on a combination of various EBC classification\nresults in the different frequencies. Another method is named \"modular\neffective neural networks (MENN)\". This method combines the classification\nresults of the three different EBC in the specific frequency. \"Modular\nfrequency neural networks (MFNN)\" is another method that combines the\nclassification results of the specific EBC in the seven different frequencies.\n  Results\n  The mean accuracy of the MFNN are 97.14%, 98.53%, and 97.91% using directed\ntransfer function, directed coherence, and generalized partial directed\ncoherence, respectively. Using the MENN, the highest mean accuracy is 98.34%.\nFinally, DMNN has the highest mean accuracy which is equal to 99.43. To our\nbest knowledge, the proposed method is a new method that provides the high\naccuracy in comparison to other studies which used MIT-CHB database.\n  Conclusion and significance\n  The knowledge of structure-function relationships between different areas of\nthe brain is necessary for characterizing the underlying dynamics. Hence,\nfeatures based on EBC can provide a reliable automatic seizure detection\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:01:08 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Akbarian", "Behnaz", ""], ["Erfanian", "Abbas", ""]]}, {"id": "1909.03093", "submitter": "Chieh Wu T", "authors": "Chieh Wu, Jared Miller, Yale Chang, Mario Sznaier, Jennifer Dy", "title": "Solving Interpretable Kernel Dimension Reduction", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel dimensionality reduction (KDR) algorithms find a low dimensional\nrepresentation of the original data by optimizing kernel dependency measures\nthat are capable of capturing nonlinear relationships. The standard strategy is\nto first map the data into a high dimensional feature space using kernels prior\nto a projection onto a low dimensional space. While KDR methods can be easily\nsolved by keeping the most dominant eigenvectors of the kernel matrix, its\nfeatures are no longer easy to interpret. Alternatively, Interpretable KDR\n(IKDR) is different in that it projects onto a subspace \\textit{before} the\nkernel feature mapping, therefore, the projection matrix can indicate how the\noriginal features linearly combine to form the new features. Unfortunately, the\nIKDR objective requires a non-convex manifold optimization that is difficult to\nsolve and can no longer be solved by eigendecomposition. Recently, an efficient\niterative spectral (eigendecomposition) method (ISM) has been proposed for this\nobjective in the context of alternative clustering. However, ISM only provides\ntheoretical guarantees for the Gaussian kernel. This greatly constrains ISM's\nusage since any kernel method using ISM is now limited to a single kernel. This\nwork extends the theoretical guarantees of ISM to an entire family of kernels,\nthereby empowering ISM to solve any kernel method of the same objective. In\nidentifying this family, we prove that each kernel within the family has a\nsurrogate $\\Phi$ matrix and the optimal projection is formed by its most\ndominant eigenvectors. With this extension, we establish how a wide range of\nIKDR applications across different learning paradigms can be solved by ISM. To\nsupport reproducible results, the source code is made publicly available on\n\\url{https://github.com/chieh-neu/ISM_supervised_DR}.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:11:45 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 14:01:55 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 16:51:47 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wu", "Chieh", ""], ["Miller", "Jared", ""], ["Chang", "Yale", ""], ["Sznaier", "Mario", ""], ["Dy", "Jennifer", ""]]}, {"id": "1909.03108", "submitter": "Le Hou", "authors": "Le Hou, Youlong Cheng, Noam Shazeer, Niki Parmar, Yeqing Li,\n  Panagiotis Korfiatis, Travis M. Drucker, Daniel J. Blezek, Xiaodan Song", "title": "High Resolution Medical Image Analysis with Spatial Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical images such as 3D computerized tomography (CT) scans and pathology\nimages, have hundreds of millions or billions of voxels/pixels. It is\ninfeasible to train CNN models directly on such high resolution images, because\nneural activations of a single image do not fit in the memory of a single\nGPU/TPU, and naive data and model parallelism approaches do not work. Existing\nimage analysis approaches alleviate this problem by cropping or down-sampling\ninput images, which leads to complicated implementation and sub-optimal\nperformance due to information loss. In this paper, we implement spatial\npartitioning, which internally distributes the input and output of\nconvolutional layers across GPUs/TPUs. Our implementation is based on the\nMesh-TensorFlow framework and the computation distribution is transparent to\nend users. With this technique, we train a 3D Unet on up to 512 by 512 by 512\nresolution data. To the best of our knowledge, this is the first work for\nhandling such high resolution images end-to-end.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:58:11 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 01:05:10 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 18:53:36 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Hou", "Le", ""], ["Cheng", "Youlong", ""], ["Shazeer", "Noam", ""], ["Parmar", "Niki", ""], ["Li", "Yeqing", ""], ["Korfiatis", "Panagiotis", ""], ["Drucker", "Travis M.", ""], ["Blezek", "Daniel J.", ""], ["Song", "Xiaodan", ""]]}, {"id": "1909.03115", "submitter": "Milena \\v{C}uki\\'c Dr", "authors": "Milena \\v{C}uki\\'c Radenkovi\\'c and Victoria Lopez Lopez", "title": "Machine Learning Approaches for Detecting the Depression from\n  Resting-State Electroencephalogram (EEG): A Review Study", "comments": "30 pages, 1 table. arXiv admin note: substantial text overlap with\n  arXiv1903.11454", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aimed at reviewing present literature on employing\nnonlinear analysis in combination with machine learning methods, in depression\ndetection or prediction task. We are focusing on an affordable data-driven\napproach, applicable for everyday clinical practice, and in particular, those\nbased on electroencephalographic (EEG) recordings. Among those studies\nutilizing EEG, we are discussing a group of applications used for detecting the\ndepression based on the resting state EEG (detection studies) and\ninterventional studies (using stimulus in their protocols or aiming to predict\nthe outcome of therapy). We conclude with a discussion and review of guidelines\nto improve the reliability of developed models that could serve the improvement\nof diagnostic and more accurate treatment of depression.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 20:11:38 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Radenkovi\u0107", "Milena \u010cuki\u0107", ""], ["Lopez", "Victoria Lopez", ""]]}, {"id": "1909.03118", "submitter": "Jianjun Yuan", "authors": "Jianjun Yuan and Andrew Lamperski", "title": "Trading-Off Static and Dynamic Regret in Online Least-Squares and Beyond", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive least-squares algorithms often use forgetting factors as a\nheuristic to adapt to non-stationary data streams. The first contribution of\nthis paper rigorously characterizes the effect of forgetting factors for a\nclass of online Newton algorithms. For exp-concave and strongly convex\nobjectives, the algorithms achieve the dynamic regret of $\\max\\{O(\\log\nT),O(\\sqrt{TV})\\}$, where $V$ is a bound on the path length of the comparison\nsequence. In particular, we show how classic recursive least-squares with a\nforgetting factor achieves this dynamic regret bound. By varying $V$, we obtain\na trade-off between static and dynamic regret. In order to obtain more\ncomputationally efficient algorithms, our second contribution is a novel\ngradient descent step size rule for strongly convex functions. Our gradient\ndescent rule recovers the order optimal dynamic regret bounds described above.\nFor smooth problems, we can also obtain static regret of $O(T^{1-\\beta})$ and\ndynamic regret of $O(T^\\beta V^*)$, where $\\beta \\in (0,1)$ and $V^*$ is the\npath length of the sequence of minimizers. By varying $\\beta$, we obtain a\ntrade-off between static and dynamic regret.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 20:28:00 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 08:09:22 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Yuan", "Jianjun", ""], ["Lamperski", "Andrew", ""]]}, {"id": "1909.03147", "submitter": "Hung Phan D", "authors": "Hung Phan", "title": "Self Learning from Large Scale Code Corpus to Infer Structure of Method\n  Invocations", "comments": "This paper is appeared in the Late Break Result track of the\n  Automated Software Engineering 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically generating code from a textual description of method invocation\nconfronts challenges. There were two current research directions for this\nproblem. One direction focuses on considering a textual description of method\ninvocations as a separate Natural Language query and do not consider the\nsurrounding context of the code. Another direction takes advantage of a\npractical large scale code corpus for providing a Machine Translation model to\ngenerate code. However, this direction got very low accuracy. In this work, we\ntried to improve these drawbacks by proposing MethodInfoToCode, an approach\nthat embeds context information and optimizes the ability of learning of\noriginal Phrase-based Statistical Machine Translation (PBMT) in NLP to infer\nimplementation of method invocation given method name and other context\ninformation. We conduct an expression prediction models learned from 2.86\nmillion method invocations from the practical data of high qualities corpus on\nGithub that used 6 popular libraries: JDK, Android, GWT, Joda-Time, Hibernate,\nand Xstream. By the evaluation, we show that if the developers only write the\nmethod name of a method invocation in a body of a method, MethodInfoToCode can\npredict the generated expression correctly at 73% in F1 score.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 23:23:37 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Phan", "Hung", ""]]}, {"id": "1909.03166", "submitter": "Vivek Gupta", "authors": "Vivek Gupta, Pegah Nokhiz, Chitradeep Dutta Roy, Suresh\n  Venkatasubramanian", "title": "Equalizing Recourse across Groups", "comments": "13 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rise in machine learning-assisted decision-making has led to concerns\nabout the fairness of the decisions and techniques to mitigate problems of\ndiscrimination. If a negative decision is made about an individual (denying a\nloan, rejecting an application for housing, and so on) justice dictates that we\nbe able to ask how we might change circumstances to get a favorable decision\nthe next time. Moreover, the ability to change circumstances (a better\neducation, improved credentials) should not be limited to only those with\naccess to expensive resources. In other words, \\emph{recourse} for negative\ndecisions should be considered a desirable value that can be equalized across\n(demographically defined) groups. This paper describes how to build models that\nmake accurate predictions while still ensuring that the penalties for a\nnegative outcome do not disadvantage different groups disproportionately. We\nmeasure recourse as the distance of an individual from the decision boundary of\na classifier. We then introduce a regularized objective to minimize the\ndifference in recourse across groups. We explore linear settings and further\nextend recourse to non-linear settings as well as model-agnostic settings where\nthe exact distance from boundary cannot be calculated. Our results show that we\ncan successfully decrease the unfairness in recourse while maintaining\nclassifier performance.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 01:50:06 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gupta", "Vivek", ""], ["Nokhiz", "Pegah", ""], ["Roy", "Chitradeep Dutta", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "1909.03172", "submitter": "Tianyi Liu", "authors": "Mo Zhou, Tianyi Liu, Yan Li, Dachao Lin, Enlu Zhou and Tuo Zhao", "title": "Towards Understanding the Importance of Noise in Training Neural\n  Networks", "comments": "International Conference on Machine Learning (ICML), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous empirical evidence has corroborated that the noise plays a crucial\nrule in effective and efficient training of neural networks. The theory behind,\nhowever, is still largely unknown. This paper studies this fundamental problem\nthrough training a simple two-layer convolutional neural network model.\nAlthough training such a network requires solving a nonconvex optimization\nproblem with a spurious local optimum and a global optimum, we prove that\nperturbed gradient descent and perturbed mini-batch stochastic gradient\nalgorithms in conjunction with noise annealing is guaranteed to converge to a\nglobal optimum in polynomial time with arbitrary initialization. This implies\nthat the noise enables the algorithm to efficiently escape from the spurious\nlocal optimum. Numerical experiments are provided to support our theory.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 02:36:46 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhou", "Mo", ""], ["Liu", "Tianyi", ""], ["Li", "Yan", ""], ["Lin", "Dachao", ""], ["Zhou", "Enlu", ""], ["Zhao", "Tuo", ""]]}, {"id": "1909.03184", "submitter": "Kaixiong Zhou", "authors": "Kaixiong Zhou, Qingquan Song, Xiao Huang, Xia Hu", "title": "Auto-GNN: Neural Architecture Search of Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN) has been successfully applied to operate on the\ngraph-structured data. Given a specific scenario, rich human expertise and\ntremendous laborious trials are usually required to identify a suitable GNN\narchitecture. It is because the performance of a GNN architecture is\nsignificantly affected by the choice of graph convolution components, such as\naggregate function and hidden dimension. Neural architecture search (NAS) has\nshown its potential in discovering effective deep architectures for learning\ntasks in image and language modeling. However, existing NAS algorithms cannot\nbe directly applied to the GNN search problem. First, the search space of GNN\nis different from the ones in existing NAS work. Second, the representation\nlearning capacity of GNN architecture changes obviously with slight\narchitecture modifications. It affects the search efficiency of traditional\nsearch methods. Third, widely used techniques in NAS such as parameter sharing\nmight become unstable in GNN.\n  To bridge the gap, we propose the automated graph neural networks (AGNN)\nframework, which aims to find an optimal GNN architecture within a predefined\nsearch space. A reinforcement learning based controller is designed to greedily\nvalidate architectures via small steps. AGNN has a novel parameter sharing\nstrategy that enables homogeneous architectures to share parameters, based on a\ncarefully-designed homogeneity definition. Experiments on real-world benchmark\ndatasets demonstrate that the GNN architecture identified by AGNN achieves the\nbest performance, comparing with existing handcrafted models and tradistional\nsearch methods.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 04:10:41 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 01:14:33 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Zhou", "Kaixiong", ""], ["Song", "Qingquan", ""], ["Huang", "Xiao", ""], ["Hu", "Xia", ""]]}, {"id": "1909.03194", "submitter": "Wenbo Ren", "authors": "Wenbo Ren, Jia Liu, Ness B. Shroff", "title": "On Sample Complexity Upper and Lower Bounds for Exact Ranking from Noisy\n  Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of finding the exact ranking from noisy\ncomparisons. A comparison over a set of $m$ items produces a noisy outcome\nabout the most preferred item, and reveals some information about the ranking.\nBy repeatedly and adaptively choosing items to compare, we want to fully rank\nthe items with a certain confidence, and use as few comparisons as possible.\nDifferent from most previous works, in this paper, we have three main\nnovelties: (i) compared to prior works, our upper bounds (algorithms) and lower\nbounds on the sample complexity (aka number of comparisons) require the minimal\nassumptions on the instances, and are not restricted to specific models; (ii)\nwe give lower bounds and upper bounds on instances with unequal noise levels;\nand (iii) this paper aims at the exact ranking without knowledge on the\ninstances, while most of the previous works either focus on approximate\nrankings or study exact ranking but require prior knowledge. We first derive\nlower bounds for pairwise ranking (i.e., compare two items each time), and then\npropose (nearly) optimal pairwise ranking algorithms. We further make\nextensions to listwise ranking (i.e., comparing multiple items each time).\nNumerical results also show our improvements against the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 06:13:33 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 19:49:00 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 05:59:32 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ren", "Wenbo", ""], ["Liu", "Jia", ""], ["Shroff", "Ness B.", ""]]}, {"id": "1909.03198", "submitter": "Wenjie Shi", "authors": "Wenjie Shi, Shiji Song and Cheng Wu", "title": "Soft Policy Gradient Method for Maximum Entropy Deep Reinforcement\n  Learning", "comments": "to be published in Proceedings of the Twenty-Eighth International\n  Joint Conference on Artificial Intelligence (IJCAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum entropy deep reinforcement learning (RL) methods have been\ndemonstrated on a range of challenging continuous tasks. However, existing\nmethods either suffer from severe instability when training on large off-policy\ndata or cannot scale to tasks with very high state and action dimensionality\nsuch as 3D humanoid locomotion. Besides, the optimality of desired Boltzmann\npolicy set for non-optimal soft value function is not persuasive enough. In\nthis paper, we first derive soft policy gradient based on entropy regularized\nexpected reward objective for RL with continuous actions. Then, we present an\noff-policy actor-critic, model-free maximum entropy deep RL algorithm called\ndeep soft policy gradient (DSPG) by combining soft policy gradient with soft\nBellman equation. To ensure stable learning while eliminating the need of two\nseparate critics for soft value functions, we leverage double sampling approach\nto making the soft Bellman equation tractable. The experimental results\ndemonstrate that our method outperforms in performance over off-policy prior\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 06:53:01 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shi", "Wenjie", ""], ["Song", "Shiji", ""], ["Wu", "Cheng", ""]]}, {"id": "1909.03200", "submitter": "Sunghoon Hong", "authors": "Wonsup Shin, Hyolim Kang, Sunghoon Hong", "title": "Mature GAIL: Imitation Learning for Low-level and High-dimensional Input\n  using Global Encoder and Cost Transformation", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, GAIL framework and various variants have shown remarkable\npossibilities for solving practical MDP problems. However, detailed researches\nof low-level, and high-dimensional state input in this framework, such as image\nsequences, has not been conducted. Furthermore, the cost function learned in\nthe traditional GAIL frame-work only lies on a negative range, acting as a\nnon-penalized reward and making the agent difficult to learn the optimal\npolicy. In this paper, we propose a new algorithm based on the GAIL framework\nthat includes a global encoder and the reward penalization mechanism. The\nglobal encoder solves two issues that arise when applying GAIL framework to\nhigh-dimensional image state. Also, it is shown that the penalization mechanism\nprovides more adequate reward to the agent, resulting in stable performance\nimprovement. Our approach's potential can be backed up by the fact that it is\ngenerally applicable to variants of GAIL framework. We conducted in-depth\nexperiments by applying our methods to various variants of the GAIL framework.\nAnd, the results proved that our method significantly improves the performances\nwhen it comes to low-level and high-dimensional tasks.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 07:01:59 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shin", "Wonsup", ""], ["Kang", "Hyolim", ""], ["Hong", "Sunghoon", ""]]}, {"id": "1909.03204", "submitter": "Wenjie Shi", "authors": "Wenjie Shi, Shiji Song, Cheng Wu and C. L. Philip Chen", "title": "Multi Pseudo Q-learning Based Deterministic Policy Gradient for Tracking\n  Control of Autonomous Underwater Vehicles", "comments": "IEEE Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates trajectory tracking problem for a class of\nunderactuated autonomous underwater vehicles (AUVs) with unknown dynamics and\nconstrained inputs. Different from existing policy gradient methods which\nemploy single actor-critic but cannot realize satisfactory tracking control\naccuracy and stable learning, our proposed algorithm can achieve high-level\ntracking control accuracy of AUVs and stable learning by applying a hybrid\nactors-critics architecture, where multiple actors and critics are trained to\nlearn a deterministic policy and action-value function, respectively.\nSpecifically, for the critics, the expected absolute Bellman error based\nupdating rule is used to choose the worst critic to be updated in each time\nstep. Subsequently, to calculate the loss function with more accurate target\nvalue for the chosen critic, Pseudo Q-learning, which uses sub-greedy policy to\nreplace the greedy policy in Q-learning, is developed for continuous action\nspaces, and Multi Pseudo Q-learning (MPQ) is proposed to reduce the\noverestimation of action-value function and to stabilize the learning. As for\nthe actors, deterministic policy gradient is applied to update the weights, and\nthe final learned policy is defined as the average of all actors to avoid large\nbut bad updates. Moreover, the stability analysis of the learning is given\nqualitatively. The effectiveness and generality of the proposed MPQ-based\nDeterministic Policy Gradient (MPQ-DPG) algorithm are verified by the\napplication on AUV with two different reference trajectories. And the results\ndemonstrate high-level tracking control accuracy and stable learning of\nMPQ-DPG. Besides, the results also validate that increasing the number of the\nactors and critics will further improve the performance.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 07:18:41 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shi", "Wenjie", ""], ["Song", "Shiji", ""], ["Wu", "Cheng", ""], ["Chen", "C. L. Philip", ""]]}, {"id": "1909.03209", "submitter": "Ying Wei", "authors": "Ying Wei, Peilin Zhao, Huaxiu Yao, Junzhou Huang", "title": "Transferable Neural Processes for Hyperparameter Optimization", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning aims to automate the whole process of machine\nlearning, including model configuration. In this paper, we focus on automated\nhyperparameter optimization (HPO) based on sequential model-based optimization\n(SMBO). Though conventional SMBO algorithms work well when abundant HPO trials\nare available, they are far from satisfactory in practical applications where a\ntrial on a huge dataset may be so costly that an optimal hyperparameter\nconfiguration is expected to return in as few trials as possible. Observing\nthat human experts draw on their expertise in a machine learning model by\ntrying configurations that once performed well on other datasets, we are\ninspired to speed up HPO by transferring knowledge from historical HPO trials\non other datasets. We propose an end-to-end and efficient HPO algorithm named\nas Transfer Neural Processes (TNP), which achieves transfer learning by\nincorporating trials on other datasets, initializing the model with\nwell-generalized parameters, and learning an initial set of hyperparameters to\nevaluate. Experiments on extensive OpenML datasets and three computer vision\ndatasets show that the proposed model can achieve state-of-the-art performance\nin at least one order of magnitude less trials.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 08:10:08 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 04:41:24 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wei", "Ying", ""], ["Zhao", "Peilin", ""], ["Yao", "Huaxiu", ""], ["Huang", "Junzhou", ""]]}, {"id": "1909.03211", "submitter": "Deli Chen", "authors": "Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, Xu Sun", "title": "Measuring and Relieving the Over-smoothing Problem for Graph Neural\n  Networks from the Topological View", "comments": "Accepted by AAAI 2020. This complete version contains the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have achieved promising performance on a wide\nrange of graph-based tasks. Despite their success, one severe limitation of\nGNNs is the over-smoothing issue (indistinguishable representations of nodes in\ndifferent classes). In this work, we present a systematic and quantitative\nstudy on the over-smoothing issue of GNNs. First, we introduce two quantitative\nmetrics, MAD and MADGap, to measure the smoothness and over-smoothness of the\ngraph nodes representations, respectively. Then, we verify that smoothing is\nthe nature of GNNs and the critical factor leading to over-smoothness is the\nlow information-to-noise ratio of the message received by the nodes, which is\npartially determined by the graph topology. Finally, we propose two methods to\nalleviate the over-smoothing issue from the topological view: (1) MADReg which\nadds a MADGap-based regularizer to the training objective;(2) AdaGraph which\noptimizes the graph topology based on the model predictions. Extensive\nexperiments on 7 widely-used graph datasets with 10 typical GNN models show\nthat the two proposed methods are effective for relieving the over-smoothing\nissue, thus improving the performance of various GNN models.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 08:14:41 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 13:53:32 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chen", "Deli", ""], ["Lin", "Yankai", ""], ["Li", "Wei", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""], ["Sun", "Xu", ""]]}, {"id": "1909.03212", "submitter": "Praneet Dutta", "authors": "Praneet Dutta, Man Kit (Joe) Cheuk, Jonathan S Kim, Massimo Mascaro", "title": "AutoML for Contextual Bandits", "comments": "To be presented at the REVEAL Workshop at the ACM RecSys Conference\n  Copenhagen'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Contextual Bandits is one of the widely popular techniques used in\napplications such as personalization, recommendation systems, mobile health,\ncausal marketing etc . As a dynamic approach, it can be more efficient than\nstandard A/B testing in minimizing regret. We propose an end to end automated\nmeta-learning pipeline to approximate the optimal Q function for contextual\nbandits problems. We see that our model is able to perform much better than\nrandom exploration, being more regret efficient and able to converge with a\nlimited number of samples, while remaining very general and easy to use due to\nthe meta-learning approach. We used a linearly annealed e-greedy exploration\npolicy to define the exploration vs exploitation schedule. We tested the system\non a synthetic environment to characterize it fully and we evaluated it on some\nopen source datasets to benchmark against prior work. We see that our model\noutperforms or performs comparatively to other models while requiring no tuning\nnor feature engineering.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 08:18:03 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Dutta", "Praneet", "", "Joe"], ["Kit", "Man", "", "Joe"], ["Cheuk", "", ""], ["Kim", "Jonathan S", ""], ["Mascaro", "Massimo", ""]]}, {"id": "1909.03228", "submitter": "Yu He", "authors": "Yu He and Yangqiu Song and Jianxin Li and Cheng Ji and Jian Peng and\n  Hao Peng", "title": "HeteSpaceyWalk: A Heterogeneous Spacey Random Walk for Heterogeneous\n  Information Network Embedding", "comments": "CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous information network (HIN) embedding has gained increasing\ninterests recently. However, the current way of random-walk based HIN embedding\nmethods have paid few attention to the higher-order Markov chain nature of\nmeta-path guided random walks, especially to the stationarity issue. In this\npaper, we systematically formalize the meta-path guided random walk as a\nhigher-order Markov chain process, and present a heterogeneous personalized\nspacey random walk to efficiently and effectively attain the expected\nstationary distribution among nodes. Then we propose a generalized scalable\nframework to leverage the heterogeneous personalized spacey random walk to\nlearn embeddings for multiple types of nodes in an HIN guided by a meta-path, a\nmeta-graph, and a meta-schema respectively. We conduct extensive experiments in\nseveral heterogeneous networks and demonstrate that our methods substantially\noutperform the existing state-of-the-art network embedding algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 09:46:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["He", "Yu", ""], ["Song", "Yangqiu", ""], ["Li", "Jianxin", ""], ["Ji", "Cheng", ""], ["Peng", "Jian", ""], ["Peng", "Hao", ""]]}, {"id": "1909.03242", "submitter": "Isabelle Augenstein", "authors": "Isabelle Augenstein and Christina Lioma and Dongsheng Wang and Lucas\n  Chaves Lima and Casper Hansen and Christian Hansen and Jakob Grue Simonsen", "title": "MultiFC: A Real-World Multi-Domain Dataset for Evidence-Based Fact\n  Checking of Claims", "comments": "Proceedings of EMNLP 2019, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We contribute the largest publicly available dataset of naturally occurring\nfactual claims for the purpose of automatic claim verification. It is collected\nfrom 26 fact checking websites in English, paired with textual sources and rich\nmetadata, and labelled for veracity by human expert journalists. We present an\nin-depth analysis of the dataset, highlighting characteristics and challenges.\nFurther, we present results for automatic veracity prediction, both with\nestablished baselines and with a novel method for joint ranking of evidence\npages and predicting veracity that outperforms all baselines. Significant\nperformance increases are achieved by encoding evidence, and by modelling\nmetadata. Our best-performing model achieves a Macro F1 of 49.2%, showing that\nthis is a challenging testbed for claim veracity prediction.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 10:57:29 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 15:51:53 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Augenstein", "Isabelle", ""], ["Lioma", "Christina", ""], ["Wang", "Dongsheng", ""], ["Lima", "Lucas Chaves", ""], ["Hansen", "Casper", ""], ["Hansen", "Christian", ""], ["Simonsen", "Jakob Grue", ""]]}, {"id": "1909.03245", "submitter": "Wenjie Shi", "authors": "Wenjie Shi, Shiji Song, Hui Wu, Ya-Chu Hsu, Cheng Wu, Gao Huang", "title": "Regularized Anderson Acceleration for Off-Policy Deep Reinforcement\n  Learning", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) algorithms have been widely used\nfor a range of complex control tasks. However, slow convergence and sample\ninefficiency remain challenging problems in RL, especially when handling\ncontinuous and high-dimensional state spaces. To tackle this problem, we\npropose a general acceleration method for model-free, off-policy deep RL\nalgorithms by drawing the idea underlying regularized Anderson acceleration\n(RAA), which is an effective approach to accelerating the solving of fixed\npoint problems with perturbations. Specifically, we first explain how policy\niteration can be applied directly with Anderson acceleration. Then we extend\nRAA to the case of deep RL by introducing a regularization term to control the\nimpact of perturbation induced by function approximation errors. We further\npropose two strategies, i.e., progressive update and adaptive restart, to\nenhance the performance. The effectiveness of our method is evaluated on a\nvariety of benchmark tasks, including Atari 2600 and MuJoCo. Experimental\nresults show that our approach substantially improves both the learning speed\nand final performance of state-of-the-art deep RL algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 11:18:32 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 01:11:40 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Shi", "Wenjie", ""], ["Song", "Shiji", ""], ["Wu", "Hui", ""], ["Hsu", "Ya-Chu", ""], ["Wu", "Cheng", ""], ["Huang", "Gao", ""]]}, {"id": "1909.03253", "submitter": "Navid Alemi Koohbanani", "authors": "Mostafa Jahanifar, Navid Alemi Koohbanani, and Nasir Rajpoot", "title": "NuClick: From Clicks in the Nuclei to Nuclear Boundaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Best performing nuclear segmentation methods are based on deep learning\nalgorithms that require a large amount of annotated data. However, collecting\nannotations for nuclear segmentation is a very labor-intensive and\ntime-consuming task. Thereby, providing a tool that can facilitate and speed up\nthis procedure is very demanding. Here we propose a simple yet efficient\nframework based on convolutional neural networks, named NuClick, which can\nprecisely segment nuclei boundaries by accepting a single point position (or\nclick) inside each nucleus. Based on the clicked positions, inclusion and\nexclusion maps are generated which comprise 2D Gaussian distributions centered\non those positions. These maps serve as guiding signals for the network as they\nare concatenated to the input image. The inclusion map focuses on the desired\nnucleus while the exclusion map indicates neighboring nuclei and improve the\nresults of segmentation in scenes with nuclei clutter. The NuClick not only\nfacilitates collecting more annotation from unseen data but also leads to\nsuperior segmentation output for deep models. It is also worth mentioning that\nan instance segmentation model trained on NuClick generated labels was able to\nrank first in LYON19 challenge.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 11:52:19 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Jahanifar", "Mostafa", ""], ["Koohbanani", "Navid Alemi", ""], ["Rajpoot", "Nasir", ""]]}, {"id": "1909.03261", "submitter": "Riccardo Volpato", "authors": "Riccardo Volpato and Guangyan Song", "title": "Active learning to optimise time-expensive algorithm selection", "comments": "11 pages, 3 figures, 3 tables and 1 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hard optimisation problems such as Boolean Satisfiability typically have long\nsolving times and can usually be solved by many algorithms, although the\nperformance can vary widely in practice. Research has shown that no single\nalgorithm outperforms all the others; thus, it is crucial to select the best\nalgorithm for a given problem. Supervised machine learning models can\naccurately predict which solver is best for a given problem, but they require\nfirst to run every solver in the portfolio for all examples available to create\nlabelled data. As this approach cannot scale, we developed an active learning\nframework that addresses this problem by constructing an optimal training set,\nso that the learner can achieve higher or equal performances with less training\ndata. Our work proves that active learning is beneficial for algorithm\nselection techniques and provides practical guidance to incorporate into\nexisting systems.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 12:33:31 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Volpato", "Riccardo", ""], ["Song", "Guangyan", ""]]}, {"id": "1909.03267", "submitter": "Gerlind Plonka", "authors": "Renato Budinich, Gerlind Plonka", "title": "A Tree-based Dictionary Learning Framework", "comments": null, "journal-ref": "International Journal of Wavelets, Multiresolution and Information\n  Processing (2020) 2050041 (24 pages)", "doi": "10.1142/S0219691320500411", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new outline for adaptive dictionary learning methods for sparse\nencoding based on a hierarchical clustering of the training data. Through\nrecursive application of a clustering method, the data is organized into a\nbinary partition tree representing a multiscale structure. The dictionary atoms\nare defined adaptively based on the data clusters in the partition tree. This\napproach can be interpreted as a generalization of a discrete Haar wavelet\ntransform. Furthermore, any prior knowledge on the wanted structure of the\ndictionary elements can be simply incorporated. The computational complexity of\nour proposed algorithm depends on the employed clustering method and on the\nchosen similarity measure between data points. Thanks to the multiscale\nproperties of the partition tree, our dictionary is structured: when using\nOrthogonal Matching Pursuit to reconstruct patches from a natural image,\ndictionary atoms corresponding to nodes being closer to the root node in the\ntree have a tendency to be used with greater coefficients.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 13:48:23 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 15:55:31 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Budinich", "Renato", ""], ["Plonka", "Gerlind", ""]]}, {"id": "1909.03276", "submitter": "Weiyu Cheng", "authors": "Weiyu Cheng, Yanyan Shen, Linpeng Huang", "title": "Adaptive Factorization Network: Learning Adaptive-Order Feature\n  Interactions", "comments": "Accepted by AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various factorization-based methods have been proposed to leverage\nsecond-order, or higher-order cross features for boosting the performance of\npredictive models. They generally enumerate all the cross features under a\npredefined maximum order, and then identify useful feature interactions through\nmodel training, which suffer from two drawbacks. First, they have to make a\ntrade-off between the expressiveness of higher-order cross features and the\ncomputational cost, resulting in suboptimal predictions. Second, enumerating\nall the cross features, including irrelevant ones, may introduce noisy feature\ncombinations that degrade model performance. In this work, we propose the\nAdaptive Factorization Network (AFN), a new model that learns arbitrary-order\ncross features adaptively from data. The core of AFN is a logarithmic\ntransformation layer to convert the power of each feature in a feature\ncombination into the coefficient to be learned. The experimental results on\nfour real datasets demonstrate the superior predictive performance of AFN\nagainst the start-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 14:30:43 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 02:05:51 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Cheng", "Weiyu", ""], ["Shen", "Yanyan", ""], ["Huang", "Linpeng", ""]]}, {"id": "1909.03287", "submitter": "Davide Bacciu", "authors": "Davide Bacciu and Luigi Di Sotto", "title": "A Non-Negative Factorization approach to node pooling in Graph\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper discusses a pooling mechanism to induce subsampling in graph\nstructured data and introduces it as a component of a graph convolutional\nneural network. The pooling mechanism builds on the Non-Negative Matrix\nFactorization (NMF) of a matrix representing node adjacency and node similarity\nas adaptively obtained through the vertices embedding learned by the model.\nSuch mechanism is applied to obtain an incrementally coarser graph where nodes\nare adaptively pooled into communities based on the outcomes of the\nnon-negative factorization. The empirical analysis on graph classification\nbenchmarks shows how such coarsening process yields significant improvements in\nthe predictive performance of the model with respect to its non-pooled\ncounterpart.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 15:27:49 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Bacciu", "Davide", ""], ["Di Sotto", "Luigi", ""]]}, {"id": "1909.03290", "submitter": "Lav Varshney", "authors": "Lav R. Varshney, Nitish Shirish Keskar, Richard Socher", "title": "Pretrained AI Models: Performativity, Mobility, and Change", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paradigm of pretrained deep learning models has recently emerged in\nartificial intelligence practice, allowing deployment in numerous societal\nsettings with limited computational resources, but also embedding biases and\nenabling unintended negative uses. In this paper, we treat pretrained models as\nobjects of study and discuss the ethical impacts of their sociological\nposition. We discuss how pretrained models are developed and compared under the\ncommon task framework, but that this may make self-regulation inadequate.\nFurther how pretrained models may have a performative effect on society that\nexacerbates biases. We then discuss how pretrained models move through actor\nnetworks as a kind of computationally immutable mobile, but that users also act\nas agents of technological change by reinterpreting them via fine-tuning and\ntransfer. We further discuss how users may use pretrained models in malicious\nways, drawing a novel connection between the responsible innovation and\nuser-centered innovation literatures. We close by discussing how this\nsociological understanding of pretrained models can inform AI governance\nframeworks for fairness, accountability, and transparency.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 15:40:22 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Varshney", "Lav R.", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "1909.03306", "submitter": "Massimiliano Lupo Pasini Dr.", "authors": "Massimiliano Lupo Pasini, Junqi Yin, Ying Wai Li, Markus Eisenbach", "title": "A scalable constructive algorithm for the optimization of neural network\n  architectures", "comments": "12 pages, 15 figures, 3 table", "journal-ref": "Parallel Computing, 2021", "doi": "10.1016/j.parco.2021.102788", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new scalable method to optimize the architecture of an\nartificial neural network. The proposed algorithm, called Greedy Search for\nNeural Network Architecture, aims to determine a neural network with minimal\nnumber of layers that is at least as performant as neural networks of the same\nstructure identified by other hyperparameter search algorithms in terms of\naccuracy and computational cost. Numerical results performed on benchmark\ndatasets show that, for these datasets, our method outperforms state-of-the-art\nhyperparameter optimization algorithms in terms of attainable predictive\nperformance by the selected neural network architecture, and time-to-solution\nfor the hyperparameter optimization to complete.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 17:22:28 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 17:26:10 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 14:13:57 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Pasini", "Massimiliano Lupo", ""], ["Yin", "Junqi", ""], ["Li", "Ying Wai", ""], ["Eisenbach", "Markus", ""]]}, {"id": "1909.03316", "submitter": "Susan Meerdink", "authors": "Susan Meerdink, James Bocinsky, Alina Zare, Nicholas Kroeger, Connor\n  McCurley, Daniel Shats, Paul Gader", "title": "Multi-Target Multiple Instance Learning for Hyperspectral Target\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In remote sensing, it is often challenging to acquire or collect a large\ndataset that is accurately labeled. This difficulty is usually due to several\nissues, including but not limited to the study site's spatial area and\naccessibility, errors in the global positioning system (GPS), and mixed pixels\ncaused by an image's spatial resolution. We propose an approach, with two\nvariations, that estimates multiple target signatures from training samples\nwith imprecise labels: Multi-Target Multiple Instance Adaptive Cosine Estimator\n(Multi-Target MI-ACE) and Multi-Target Multiple Instance Spectral Match Filter\n(Multi-Target MI-SMF). The proposed methods address the problems above by\ndirectly considering the multiple-instance, imprecisely labeled dataset. They\nlearn a dictionary of target signatures that optimizes detection against a\nbackground using the Adaptive Cosine Estimator (ACE) and Spectral Match Filter\n(SMF). Experiments were conducted to test the proposed algorithms using a\nsimulated hyperspectral dataset, the MUUFL Gulfport hyperspectral dataset\ncollected over the University of Southern Mississippi-Gulfpark Campus, and the\nAVIRIS hyperspectral dataset collected over Santa Barbara County, California.\nBoth simulated and real hyperspectral target detection experiments show the\nproposed algorithms are effective at learning target signatures and performing\ntarget detection.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 18:30:54 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 16:01:44 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 20:26:23 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Meerdink", "Susan", ""], ["Bocinsky", "James", ""], ["Zare", "Alina", ""], ["Kroeger", "Nicholas", ""], ["McCurley", "Connor", ""], ["Shats", "Daniel", ""], ["Gader", "Paul", ""]]}, {"id": "1909.03317", "submitter": "Sam Davidson", "authors": "Sam Davidson, Dian Yu, Zhou Yu", "title": "Dependency Parsing for Spoken Dialog Systems", "comments": "To be presented at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency parsing of conversational input can play an important role in\nlanguage understanding for dialog systems by identifying the relationships\nbetween entities extracted from user utterances. Additionally, effective\ndependency parsing can elucidate differences in language structure and usage\nfor discourse analysis of human-human versus human-machine dialogs. However,\nmodels trained on datasets based on news articles and web data do not perform\nwell on spoken human-machine dialog, and currently available annotation schemes\ndo not adapt well to dialog data. Therefore, we propose the Spoken Conversation\nUniversal Dependencies (SCUD) annotation scheme that extends the Universal\nDependencies (UD) (Nivre et al., 2016) guidelines to spoken human-machine\ndialogs. We also provide ConvBank, a conversation dataset between humans and an\nopen-domain conversational dialog system with SCUD annotation. Finally, to\ndemonstrate the utility of the dataset, we train a dependency parser on the\nConvBank dataset. We demonstrate that by pre-training a dependency parser on a\nset of larger public datasets and fine-tuning on ConvBank data, we achieved the\nbest result, 85.05% unlabeled and 77.82% labeled attachment accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 18:32:28 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Davidson", "Sam", ""], ["Yu", "Dian", ""], ["Yu", "Zhou", ""]]}, {"id": "1909.03331", "submitter": "Georgios Papagiannis", "authors": "Georgios Papagiannis, Sotiris Moschoyiannis", "title": "Deep Reinforcement Learning for Control of Probabilistic Boolean\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Boolean Networks (PBNs) were introduced as a computational\nmodel for the study of complex dynamical systems, such as Gene Regulatory\nNetworks (GRNs). Controllability in this context is the process of making\nstrategic interventions to the state of a network in order to drive it towards\nsome other state that exhibits favourable biological properties. In this paper\nwe study the ability of a Double Deep Q-Network with Prioritized Experience\nReplay in learning control strategies within a finite number of time steps that\ndrive a PBN towards a target state, typically an attractor. The control method\nis model-free and does not require knowledge of the network's underlying\ndynamics, making it suitable for applications where inference of such dynamics\nis intractable. We present extensive experiment results on two synthetic PBNs\nand the PBN model constructed directly from gene-expression data of a study on\nmetastatic-melanoma.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 20:24:41 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 11:03:38 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 19:14:06 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 12:38:16 GMT"}, {"version": "v5", "created": "Mon, 7 Sep 2020 16:05:20 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Papagiannis", "Georgios", ""], ["Moschoyiannis", "Sotiris", ""]]}, {"id": "1909.03332", "submitter": "Zenon Gniazdowski", "authors": "Zenon Gniazdowski and Dawid Kaliszewski", "title": "On the clustering of correlated random variables", "comments": "70 pages, 32 figures", "journal-ref": "Zeszyty Naukowe WWSI, No 18, Vol. 12, 2018, pp. 45-114", "doi": "10.26348/znwwsi.18.45", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, the possibility of clustering correlated random variables was\nexamined, both because of their mutual similarity and because of their\nsimilarity to the principal components. The k-means algorithm and spectral\nalgorithms were used for clustering. For spectral methods, the similarity\nmatrix was both the matrix of relation established on the level of correlation\nand the matrix of coefficients of determination. For four different sets of\ndata, different ways of measuring the disimilarity of variables were analyzed,\nand the impact of the diversity of initial points on the efficiency of the\nk-means algorithm was analyzed.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 20:27:40 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gniazdowski", "Zenon", ""], ["Kaliszewski", "Dawid", ""]]}, {"id": "1909.03334", "submitter": "Uyeong Jang", "authors": "Uyeong Jang, Susmit Jha, Somesh Jha", "title": "On the Need for Topology-Aware Generative Models for Manifold-Based\n  Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning (ML) algorithms or models, especially deep neural networks\n(DNNs), have shown significant promise in several areas. However, researchers\nhave recently demonstrated that ML algorithms, especially DNNs, are vulnerable\nto adversarial examples (slightly perturbed samples that cause\nmisclassification). The existence of adversarial examples has hindered the\ndeployment of ML algorithms in safety-critical sectors, such as security.\nSeveral defenses for adversarial examples exist in the literature. One of the\nimportant classes of defenses are manifold-based defenses, where a sample is\n``pulled back\" into the data manifold before classifying. These defenses rely\non the assumption that data lie in a manifold of a lower dimension than the\ninput space. These defenses use a generative model to approximate the input\ndistribution. In this paper, we investigate the following question: do the\ngenerative models used in manifold-based defenses need to be topology-aware? We\nsuggest the answer is yes, and we provide theoretical and empirical evidence to\nsupport our claim.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 20:36:17 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 16:53:23 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 22:52:08 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 21:20:01 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Jang", "Uyeong", ""], ["Jha", "Susmit", ""], ["Jha", "Somesh", ""]]}, {"id": "1909.03347", "submitter": "Arash Ali Amini", "authors": "Arash A. Amini and Zahra S. Razaee", "title": "Concentration of kernel matrices with application to kernel spectral\n  clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the concentration of random kernel matrices around their mean. We\nderive nonasymptotic exponential concentration inequalities for Lipschitz\nkernels assuming that the data points are independent draws from a class of\nmultivariate distributions on $\\mathbb R^d$, including the strongly log-concave\ndistributions under affine transformations. A feature of our result is that the\ndata points need not have identical distributions or zero mean, which is key in\ncertain applications such as clustering. Our bound for the Lipschitz kernels is\ndimension-free and sharp up to constants. For comparison, we also derive the\ncompanion result for the Euclidean (inner product) kernel for a class of\nsub-Gaussian distributions. A notable difference between the two cases is that,\nin contrast to the Euclidean kernel, in the Lipschitz case, the concentration\ninequality does not depend on the mean of the underlying vectors. As an\napplication of these inequalities, we derive a bound on the misclassification\nrate of a kernel spectral clustering (KSC) algorithm, under a perturbed\nnonparametric mixture model. We show an example where this bound establishes\nthe high-dimensional consistency (as $d \\to \\infty$) of the KSC, when applied\nwith a Gaussian kernel, to a noisy model of nested nonlinear manifolds.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 22:56:55 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 08:25:48 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Amini", "Arash A.", ""], ["Razaee", "Zahra S.", ""]]}, {"id": "1909.03354", "submitter": "Soufiane Belharbi", "authors": "J\\'er\\^ome Rony, Soufiane Belharbi, Jose Dolz, Ismail Ben Ayed, Luke\n  McCaffrey, Eric Granger", "title": "Deep weakly-supervised learning methods for classification and\n  localization in histology images: a survey", "comments": "35 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using state-of-the-art deep learning models for cancer diagnosis presents\nseveral challenges related to the nature and availability of labeled histology\nimages. In particular, cancer grading and localization in these images normally\nrelies on both image- and pixel-level labels, the latter requiring a costly\nannotation process. In this survey, deep weakly-supervised learning (WSL)\nmodels are investigated to identify and locate diseases in histology images,\nwithout the need for pixel-level annotations. Given training data with global\nimage-level labels, these models allow to simultaneously classify histology\nimages and yield pixel-wise localization scores, thereby identifying the\ncorresponding regions of interest (ROI). Since relevant WSL models have mainly\nbeen investigated within the computer vision community, and validated on\nnatural scene images, we assess the extent to which they apply to histology\nimages which have challenging properties, e.g. very large size, similarity\nbetween foreground/background, highly unstructured regions, stain\nheterogeneity, and noisy/ambiguous labels. The most relevant models for deep\nWSL are compared experimentally in terms of accuracy (classification and\npixel-wise localization) on several public benchmark histology datasets for\nbreast and colon cancer -- BACH ICIAR 2018, BreaKHis, CAMELYON16, and GlaS.\nFurthermore, for large-scale evaluation of WSL models on histology images, we\npropose a protocol to construct WSL datasets from Whole Slide Imaging. Results\nindicate that several deep learning models can provide a high level of\nclassification accuracy, although accurate pixel-wise localization of cancer\nregions remains an issue for such images. Code is publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 00:01:37 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 14:12:21 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 04:16:09 GMT"}, {"version": "v4", "created": "Thu, 31 Dec 2020 05:41:51 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Rony", "J\u00e9r\u00f4me", ""], ["Belharbi", "Soufiane", ""], ["Dolz", "Jose", ""], ["Ayed", "Ismail Ben", ""], ["McCaffrey", "Luke", ""], ["Granger", "Eric", ""]]}, {"id": "1909.03359", "submitter": "Gurbinder Gill", "authors": "Gurbinder Gill (1), Roshan Dathathri (1), Saeed Maleki (2), Madan\n  Musuvathi (2), Todd Mytkowicz (2), Olli Saarikivi (2) ((1) The University of\n  Texas at Austin, (2) Microsoft Research)", "title": "Distributed Training of Embeddings using Graph Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications today, such as NLP, network analysis, and code analysis,\nrely on semantically embedding objects into low-dimensional fixed-length\nvectors. Such embeddings naturally provide a way to perform useful downstream\ntasks, such as identifying relations among objects or predicting objects for a\ngiven context, etc. Unfortunately, the training necessary for accurate\nembeddings is usually computationally intensive and requires processing large\namounts of data. Furthermore, distributing this training is challenging. Most\nembedding training uses stochastic gradient descent (SGD), an \"inherently\"\nsequential algorithm. Prior approaches to parallelizing SGD do not honor these\ndependencies and thus potentially suffer poor convergence.\n  This paper presents a distributed training framework for a class of\napplications that use Skip-gram-like models to generate embeddings. We call\nthis class Any2Vec and it includes Word2Vec, DeepWalk, and Node2Vec among\nothers. We first formulate Any2Vec training algorithm as a graph application\nand leverage the state-of-the-art distributed graph analytics framework,\nD-Galois. We adapt D-Galois to support dynamic graph generation and\nrepartitioning, and incorporate novel communication optimizations. Finally, we\nintroduce a novel way to combine gradients during distributed training to\nprevent accuracy loss. We show that our framework, called GraphAny2Vec, matches\non a cluster of 32 hosts the accuracy of the state-of-the-art shared-memory\nimplementations of Word2Vec and Vertex2Vec on 1 host, and gives a geo-mean\nspeedup of 12x and 5x respectively. Furthermore, GraphAny2Vec is on average 2x\nfaster than the state-of-the-art distributed Word2Vec implementation, DMTK, on\n32 hosts. We also show the superiority of our Gradient Combiner independent of\nGraphAny2Vec by incorporating it in DMTK, which raises its accuracy by > 30%.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 01:06:03 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 00:34:44 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gill", "Gurbinder", ""], ["Dathathri", "Roshan", ""], ["Maleki", "Saeed", ""], ["Musuvathi", "Madan", ""], ["Mytkowicz", "Todd", ""], ["Saarikivi", "Olli", ""]]}, {"id": "1909.03388", "submitter": "Yilun Xu", "authors": "Yilun Xu, Peng Cao, Yuqing Kong, Yizhou Wang", "title": "L_DMI: An Information-theoretic Noise-robust Loss Function", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately annotating large scale dataset is notoriously expensive both in\ntime and in money. Although acquiring low-quality-annotated dataset can be much\ncheaper, it often badly damages the performance of trained models when using\nsuch dataset without particular treatment. Various methods have been proposed\nfor learning with noisy labels. However, most methods only handle limited kinds\nof noise patterns, require auxiliary information or steps (e.g. , knowing or\nestimating the noise transition matrix), or lack theoretical justification. In\nthis paper, we propose a novel information-theoretic loss function,\n$\\mathcal{L}_{DMI}$, for training deep neural networks robust to label noise.\nThe core of $\\mathcal{L}_{DMI}$ is a generalized version of mutual information,\ntermed Determinant based Mutual Information (DMI), which is not only\ninformation-monotone but also relatively invariant. \\emph{To the best of our\nknowledge, $\\mathcal{L}_{DMI}$ is the first loss function that is provably\nrobust to instance-independent label noise, regardless of noise pattern, and it\ncan be applied to any existing classification neural networks straightforwardly\nwithout any auxiliary information}. In addition to theoretical justification,\nwe also empirically show that using $\\mathcal{L}_{DMI}$ outperforms all other\ncounterparts in the classification task on both image dataset and natural\nlanguage dataset include Fashion-MNIST, CIFAR-10, Dogs vs. Cats, MR with a\nvariety of synthesized noise patterns and noise amounts, as well as a\nreal-world dataset Clothing1M. Codes are available at\nhttps://github.com/Newbeeer/L_DMI .\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 05:09:45 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 18:16:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Xu", "Yilun", ""], ["Cao", "Peng", ""], ["Kong", "Yuqing", ""], ["Wang", "Yizhou", ""]]}, {"id": "1909.03403", "submitter": "Ziwei Liu", "authors": "Ziwei Liu, Zhongqi Miao, Xingang Pan, Xiaohang Zhan, Dahua Lin, Stella\n  X. Yu, Boqing Gong", "title": "Open Compound Domain Adaptation", "comments": "To appear in CVPR 2020 as an oral presentation. Code, datasets and\n  models are available at:\n  https://liuziwei7.github.io/projects/CompoundDomain.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical domain adaptation approach is to adapt models trained on the\nannotated data in a source domain (e.g., sunny weather) for achieving high\nperformance on the test data in a target domain (e.g., rainy weather). Whether\nthe target contains a single homogeneous domain or multiple heterogeneous\ndomains, existing works always assume that there exist clear distinctions\nbetween the domains, which is often not true in practice (e.g., changes in\nweather). We study an open compound domain adaptation (OCDA) problem, in which\nthe target is a compound of multiple homogeneous domains without domain labels,\nreflecting realistic data collection from mixed and novel situations. We\npropose a new approach based on two technical insights into OCDA: 1) a\ncurriculum domain adaptation strategy to bootstrap generalization across\ndomains in a data-driven self-organizing fashion and 2) a memory module to\nincrease the model's agility towards novel domains. Our experiments on digit\nclassification, facial expression recognition, semantic segmentation, and\nreinforcement learning demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 08:41:05 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 06:00:41 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Liu", "Ziwei", ""], ["Miao", "Zhongqi", ""], ["Pan", "Xingang", ""], ["Zhan", "Xiaohang", ""], ["Lin", "Dahua", ""], ["Yu", "Stella X.", ""], ["Gong", "Boqing", ""]]}, {"id": "1909.03410", "submitter": "Avik Pal", "authors": "Avik Pal and Aniket Das", "title": "TorchGAN: A Flexible Framework for GAN Training and Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TorchGAN is a PyTorch based framework for writing succinct and comprehensible\ncode for training and evaluation of Generative Adversarial Networks. The\nframework's modular design allows effortless customization of the model\narchitecture, loss functions, training paradigms, and evaluation metrics. The\nkey features of TorchGAN are its extensibility, built-in support for a large\nnumber of popular models, losses and evaluation metrics, and zero overhead\ncompared to vanilla PyTorch. By using the framework to implement several\npopular GAN models, we demonstrate its extensibility and ease of use. We also\nbenchmark the training time of our framework for said models against the\ncorresponding baseline PyTorch implementations and observe that TorchGAN's\nfeatures bear almost zero overhead.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 09:32:01 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Pal", "Avik", ""], ["Das", "Aniket", ""]]}, {"id": "1909.03416", "submitter": "Abdulkadir Celikkanat", "authors": "Abdulkadir \\c{C}elikkanat, Fragkiskos D. Malliaros", "title": "Kernel Node Embeddings", "comments": "Accepted to the 7th IEEE Global Conference on Signal and Information\n  Processing (GlobalSIP), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations of nodes in a low dimensional space is a crucial\ntask with many interesting applications in network analysis, including link\nprediction and node classification. Two popular approaches for this problem\ninclude matrix factorization and random walk-based models. In this paper, we\naim to bring together the best of both worlds, towards learning latent node\nrepresentations. In particular, we propose a weighted matrix factorization\nmodel which encodes random walk-based information about the nodes of the graph.\nThe main benefit of this formulation is that it allows to utilize kernel\nfunctions on the computation of the embeddings. We perform an empirical\nevaluation on real-world networks, showing that the proposed model outperforms\nbaseline node embedding algorithms in two downstream machine learning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 09:49:39 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 07:47:34 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["\u00c7elikkanat", "Abdulkadir", ""], ["Malliaros", "Fragkiskos D.", ""]]}, {"id": "1909.03418", "submitter": "Asaf Shabtai", "authors": "Gil Fidel, Ron Bitton, Asaf Shabtai", "title": "When Explainability Meets Adversarial Learning: Detecting Adversarial\n  Examples using SHAP Signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep neural networks (DNNs) are highly effective in solving\nmany complex real-world problems. However, these models are vulnerable to\nadversarial perturbation attacks, and despite the plethora of research in this\ndomain, to this day, adversaries still have the upper hand in the cat and mouse\ngame of adversarial example generation methods vs. detection and prevention\nmethods. In this research, we present a novel detection method that uses\nShapley Additive Explanations (SHAP) values computed for the internal layers of\na DNN classifier to discriminate between normal and adversarial inputs. We\nevaluate our method by building an extensive dataset of adversarial examples\nover the popular CIFAR-10 and MNIST datasets, and training a neural\nnetwork-based detector to distinguish between normal and adversarial inputs. We\nevaluate our detector against adversarial examples generated by diverse\nstate-of-the-art attacks and demonstrate its high detection accuracy and strong\ngeneralization ability to adversarial inputs generated with different attack\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 10:00:44 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Fidel", "Gil", ""], ["Bitton", "Ron", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1909.03428", "submitter": "Martin Atzmueller", "authors": "Spyroula Masiala and Willem Huijbers and Martin Atzmueller", "title": "Feature-Set-Engineering for Detecting Freezing of Gait in Parkinson's\n  Disease using Deep Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Freezing of gait (FoG) is a common gait disability in Parkinson's disease,\nthat usually appears in its advanced stage. Freeze episodes are associated with\nfalls, injuries, and psychological consequences, negatively affecting the\npatients' quality of life. For detecting FoG episodes automatically, a highly\naccurate detection method is necessary. This paper presents an approach for\ndetecting FoG episodes utilizing a deep recurrent neural network (RNN) on\n3D-accelerometer measurements. We investigate suitable features and feature\ncombinations extracted from the sensors' time series data. Specifically, for\ndetecting FoG episodes, we apply a deep RNN with Long Short-Term Memory cells.\nIn our experiments, we perform both user dependent and user independent\nexperiments, to detect freeze episodes. Our experimental results show that the\nfrequency domain features extracted from the trunk sensor are the most\ninformative feature group in the subject independent method, achieving an\naverage AUC score of 93%, Specificity of 90% and Sensitivity of 81%. Moreover,\nfrequency and statistical features of all the sensors are identified as the\nbest single input for the subject dependent method, achieving an average AUC\nscore of 97%, Specificity of 96% and Sensitivity of 87%. Overall, in a\ncomparison to state-of-the-art approaches from literature as baseline methods,\nour proposed approach outperforms these significantly.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 11:02:50 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Masiala", "Spyroula", ""], ["Huijbers", "Willem", ""], ["Atzmueller", "Martin", ""]]}, {"id": "1909.03433", "submitter": "Xialiang Dou", "authors": "Xialiang Dou, Mihai Anitescu", "title": "Distributionally Robust Optimization with Correlated Data from Vector\n  Autoregressive Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.CO stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributionally robust formulation of a stochastic optimization\nproblem for non-i.i.d vector autoregressive data. We use the Wasserstein\ndistance to define robustness in the space of distributions and we show, using\nduality theory, that the problem is equivalent to a finite convex-concave\nsaddle point problem. The performance of the method is demonstrated on both\nsynthetic and real data.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 11:30:04 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Dou", "Xialiang", ""], ["Anitescu", "Mihai", ""]]}, {"id": "1909.03434", "submitter": "Che-Ping Tsai", "authors": "Che-Ping Tsai and Hung-Yi Lee", "title": "Order-free Learning Alleviating Exposure Bias in Multi-label\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification (MLC) assigns multiple labels to each sample.\nPrior studies show that MLC can be transformed to a sequence prediction problem\nwith a recurrent neural network (RNN) decoder to model the label dependency.\nHowever, training a RNN decoder requires a predefined order of labels, which is\nnot directly available in the MLC specification. Besides, RNN thus trained\ntends to overfit the label combinations in the training set and have difficulty\ngenerating unseen label sequences. In this paper, we propose a new framework\nfor MLC which does not rely on a predefined label order and thus alleviates\nexposure bias. The experimental results on three multi-label classification\nbenchmark datasets show that our method outperforms competitive baselines by a\nlarge margin. We also find the proposed approach has a higher probability of\ngenerating label combinations not seen during training than the baseline\nmodels. The result shows that the proposed approach has better generalization\ncapability.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 11:53:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Tsai", "Che-Ping", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1909.03441", "submitter": "Chieh Wu T", "authors": "Chieh Wu, Stratis Ioannidis, Mario Sznaier, Xiangyu Li, David Kaeli,\n  Jennifer G. Dy", "title": "Iterative Spectral Method for Alternative Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a dataset and an existing clustering as input, alternative clustering\naims to find an alternative partition. One of the state-of-the-art approaches\nis Kernel Dimension Alternative Clustering (KDAC). We propose a novel Iterative\nSpectral Method (ISM) that greatly improves the scalability of KDAC. Our\nalgorithm is intuitive, relies on easily implementable spectral decompositions,\nand comes with theoretical guarantees. Its computation time improves upon\nexisting implementations of KDAC by as much as 5 orders of magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 12:15:20 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wu", "Chieh", ""], ["Ioannidis", "Stratis", ""], ["Sznaier", "Mario", ""], ["Li", "Xiangyu", ""], ["Kaeli", "David", ""], ["Dy", "Jennifer G.", ""]]}, {"id": "1909.03442", "submitter": "Ambedkar Dukkipati", "authors": "Sourabh Balgi and Ambedkar Dukkipati", "title": "CUDA: Contradistinguisher for Unsupervised Domain Adaptation", "comments": "International Conference on Data Mining, ICDM 2019", "journal-ref": null, "doi": "10.1109/ICDM.2019.00012", "report-no": "8970790", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple model referred as Contradistinguisher\n(CTDR) for unsupervised domain adaptation whose objective is to jointly learn\nto contradistinguish on unlabeled target domain in a fully unsupervised manner\nalong with prior knowledge acquired by supervised learning on an entirely\ndifferent domain. Most recent works in domain adaptation rely on an indirect\nway of first aligning the source and target domain distributions and then learn\na classifier on a labeled source domain to classify target domain. This\napproach of an indirect way of addressing the real task of unlabeled target\ndomain classification has three main drawbacks. (i) The sub-task of obtaining a\nperfect alignment of the domain in itself might be impossible due to large\ndomain shift (e.g., language domains). (ii) The use of multiple classifiers to\nalign the distributions unnecessarily increases the complexity of the neural\nnetworks leading to over-fitting in many cases. (iii) Due to distribution\nalignment, the domain-specific information is lost as the domains get morphed.\nIn this work, we propose a simple and direct approach that does not require\ndomain alignment. We jointly learn CTDR on both source and target distribution\nfor unsupervised domain adaptation task using contradistinguish loss for the\nunlabeled target domain in conjunction with a supervised loss for labeled\nsource domain. Our experiments show that avoiding domain alignment by directly\naddressing the task of unlabeled target domain classification using CTDR\nachieves state-of-the-art results on eight visual and four language benchmark\ndomain adaptation datasets.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 12:16:33 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Balgi", "Sourabh", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1909.03452", "submitter": "Tin Lai", "authors": "Tin Lai, Philippe Morere, Fabio Ramos, Gilad Francis", "title": "Bayesian Local Sampling-based Planning", "comments": "Accepted in IEEE Robotics and Automation Letters (RA-L)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling-based planning is the predominant paradigm for motion planning in\nrobotics. Most sampling-based planners use a global random sampling scheme to\nguarantee probabilistic completeness. However, most schemes are often\ninefficient as the samples drawn from the global proposal distribution, and do\nnot exploit relevant local structures. Local sampling-based motion planners, on\nthe other hand, take sequential decisions of random walks to samples valid\ntrajectories in configuration space. However, current approaches do not adapt\ntheir strategies according to the success and failures of past samples.\n  In this work, we introduce a local sampling-based motion planner with a\nBayesian learning scheme for modelling an adaptive sampling proposal\ndistribution. The proposal distribution is sequentially updated based on\nprevious samples, consequently shaping it according to local obstacles and\nconstraints in the configuration space. Thus, through learning from past\nobserved outcomes, we maximise the likelihood of sampling in regions that have\na higher probability to form trajectories within narrow passages. We provide\nthe formulation of a sample-efficient distribution, along with theoretical\nfoundation of sequentially updating this distribution. We demonstrate\nexperimentally that by using a Bayesian proposal distribution, a solution is\nfound faster, requiring fewer samples, and without any noticeable performance\noverhead.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 12:52:15 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 13:38:24 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Lai", "Tin", ""], ["Morere", "Philippe", ""], ["Ramos", "Fabio", ""], ["Francis", "Gilad", ""]]}, {"id": "1909.03462", "submitter": "Muhammad Usman Khalid", "authors": "Muhammad Usman Khalid, Janik M. Hager, Werner Kraus, Marco F. Huber,\n  Marc Toussaint", "title": "Deep Workpiece Region Segmentation for Bin Picking", "comments": "IEEE CASE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For most industrial bin picking solutions, the pose of a workpiece is\nlocalized by matching a CAD model to point cloud obtained from 3D sensor.\nDistinguishing flat workpieces from bottom of the bin in point cloud imposes\nchallenges in the localization of workpieces that lead to wrong or phantom\ndetections. In this paper, we propose a framework that solves this problem by\nautomatically segmenting workpiece regions from non-workpiece regions in a\npoint cloud data. It is done in real time by applying a fully convolutional\nneural network trained on both simulated and real data. The real data has been\nlabelled by our novel technique which automatically generates ground truth\nlabels for real point clouds. Along with real time workpiece segmentation, our\nframework also helps in improving the number of detected workpieces and\nestimating the correct object poses. Moreover, it decreases the computation\ntime by approximately 1s due to a reduction of the search space for the object\npose estimation.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 13:29:09 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Khalid", "Muhammad Usman", ""], ["Hager", "Janik M.", ""], ["Kraus", "Werner", ""], ["Huber", "Marco F.", ""], ["Toussaint", "Marc", ""]]}, {"id": "1909.03466", "submitter": "Muhammad Usman Khalid", "authors": "Muhammad Usman Khalid and Jie Yu", "title": "Multi-Modal Three-Stream Network for Action Recognition", "comments": "Presented in IEEE ICPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human action recognition in video is an active yet challenging research topic\ndue to high variation and complexity of data. In this paper, a novel video\nbased action recognition framework utilizing complementary cues is proposed to\nhandle this complex problem. Inspired by the successful two stream networks for\naction classification, additional pose features are studied and fused to\nenhance understanding of human action in a more abstract and semantic way.\nTowards practices, not only ground truth poses but also noisy estimated poses\nare incorporated in the framework with our proposed pre-processing module. The\nwhole framework and each cue are evaluated on varied benchmarking datasets as\nJHMDB, sub-JHMDB and Penn Action. Our results outperform state-of-the-art\nperformance on these datasets and show the strength of complementary cues.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 13:40:16 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Khalid", "Muhammad Usman", ""], ["Yu", "Jie", ""]]}, {"id": "1909.03467", "submitter": "Qi Zhang", "authors": "Qi Zhang, Tao Du, Changzheng Tian", "title": "Self-driving scale car trained by Deep reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The self-driving based on deep reinforcement learning, as the most important\napplication of artificial intelligence, has become a popular topic. Most of the\ncurrent self-driving methods focus on how to directly learn end-to-end\nself-driving control strategy from the raw sensory data. Essentially, this\ncontrol strategy can be considered as a mapping between images and driving\nbehavior, which usually faces a problem of low generalization ability. To\nimprove the generalization ability for the driving behavior, the reinforcement\nlearning method requires extrinsic reward from the real environment, which may\ndamage the car. In order to obtain a good generalization ability in safety, a\nvirtual simulation environment that can be constructed different driving scene\nis designed by Unity. A theoretical model is established and analyzed in the\nvirtual simulation environment, and it is trained by double Deep Q-network.\nThen, the trained model is migrated to a scale car in real world. This process\nis also called a sim2real method. The sim2real training method efficiently\nhandle the these two problems. The simulations and experiments are carried out\nto evaluate the performance and effectiveness of the proposed algorithm.\nFinally, it is demonstrated that the scale car in real world obtain the\ncapability for autonomous driving.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 13:41:42 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 15:53:53 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 12:48:39 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Zhang", "Qi", ""], ["Du", "Tao", ""], ["Tian", "Changzheng", ""]]}, {"id": "1909.03470", "submitter": "Moshe BenBassat Professor", "authors": "Moshe BenBassat", "title": "Disease Labeling via Machine Learning is NOT quite the same as Medical\n  Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key step in medical diagnosis is giving the patient a universally\nrecognized label (e.g. Appendicitis) which essentially assigns the patient to a\nclass(es) of patients with similar body failures. However, two patients having\nthe same disease label(s) with high probability may still have differences in\ntheir feature manifestation patterns implying differences in the required\ntreatments. Additionally, in many cases, the labels of the primary diagnoses\nleave some findings unexplained. Medical diagnosis is only partially about\nprobability calculations for label X or Y. Diagnosis is not complete until the\npatient overall situation is clinically understood to the level that enables\nthe best therapeutic decisions. Most machine learning models are data centric\nmodels, and evidence so far suggest they can reach expert level performance in\nthe disease labeling phase. Nonetheless, like any other mathematical technique,\nthey have their limitations and applicability scope. Primarily, data centric\nalgorithms are knowledge blind and lack anatomy and physiology knowledge that\nphysicians leverage to achieve complete diagnosis. This article advocates to\ncomplement them with intelligence to overcome their inherent limitations as\nknowledge blind algorithms. Machines can learn many things from data, but data\nis not the only source that machines can learn from. Historic patient data only\ntells us what the possible manifestations of a certain body failure are.\nAnatomy and physiology knowledge tell us how the body works and fails. Both are\nneeded for complete diagnosis. The proposed Double Deep Learning approach,\nalong with the initiative for Medical Wikipedia for Smart Machines, leads to AI\ndiagnostic support solutions for complete diagnosis beyond the limited data\nonly labeling solutions we see today. AI for medicine will forever be limited\nuntil their intelligence also integrates anatomy and physiology.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 13:54:00 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["BenBassat", "Moshe", ""]]}, {"id": "1909.03480", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Ethan Tien, Wesley Cheung, Zhaochen Luo,\n  William Ma, Lara J. Martin, Mark O. Riedl", "title": "Story Realization: Expanding Plot Events into Sentences", "comments": "In proceedings of AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based approaches to automated story plot generation attempt to\nlearn how to generate novel plots from a corpus of natural language plot\nsummaries. Prior work has shown that a semantic abstraction of sentences called\nevents improves neural plot generation and and allows one to decompose the\nproblem into: (1) the generation of a sequence of events (event-to-event) and\n(2) the transformation of these events into natural language sentences\n(event-to-sentence). However, typical neural language generation approaches to\nevent-to-sentence can ignore the event details and produce\ngrammatically-correct but semantically-unrelated sentences. We present an\nensemble-based model that generates natural language guided by events.We\nprovide results---including a human subjects study---for a full end-to-end\nautomated story generation system showing that our method generates more\ncoherent and plausible stories than baseline approaches.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 15:09:32 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 18:32:23 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Tien", "Ethan", ""], ["Cheung", "Wesley", ""], ["Luo", "Zhaochen", ""], ["Ma", "William", ""], ["Martin", "Lara J.", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1909.03483", "submitter": "Jianbo Jiao", "authors": "Jianbo Jiao, Ana I.L. Namburete, Aris T. Papageorghiou, J. Alison\n  Noble", "title": "Anatomy-Aware Self-supervised Fetal MRI Synthesis from Unpaired\n  Ultrasound Images", "comments": "MICCAI-MLMI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fetal brain magnetic resonance imaging (MRI) offers exquisite images of the\ndeveloping brain but is not suitable for anomaly screening. For this ultrasound\n(US) is employed. While expert sonographers are adept at reading US images, MR\nimages are much easier for non-experts to interpret. Hence in this paper we\nseek to produce images with MRI-like appearance directly from clinical US\nimages. Our own clinical motivation is to seek a way to communicate US findings\nto patients or clinical professionals unfamiliar with US, but in medical image\nanalysis such a capability is potentially useful, for instance, for US-MRI\nregistration or fusion. Our model is self-supervised and end-to-end trainable.\nSpecifically, based on an assumption that the US and MRI data share a similar\nanatomical latent space, we first utilise an extractor to determine shared\nlatent features, which are then used for data synthesis. Since paired data was\nunavailable for our study (and rare in practice), we propose to enforce the\ndistributions to be similar instead of employing pixel-wise constraints, by\nadversarial learning in both the image domain and latent space. Furthermore, we\npropose an adversarial structural constraint to regularise the anatomical\nstructures between the two modalities during the synthesis. A cross-modal\nattention scheme is proposed to leverage non-local spatial correlations. The\nfeasibility of the approach to produce realistic looking MR images is\ndemonstrated quantitatively and with a qualitative evaluation compared to real\nfetal MR images.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 15:28:35 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Jiao", "Jianbo", ""], ["Namburete", "Ana I. L.", ""], ["Papageorghiou", "Aris T.", ""], ["Noble", "J. Alison", ""]]}, {"id": "1909.03495", "submitter": "Naoya Takeishi", "authors": "Naoya Takeishi", "title": "Shapley Values of Reconstruction Errors of PCA for Explaining Anomaly\n  Detection", "comments": "Workshop on Learning and Mining with Industrial Data (LMID) 2019.\n  typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to compute the Shapley values of reconstruction errors of\nprincipal component analysis (PCA), which is particularly useful in explaining\nthe results of anomaly detection based on PCA. Because features are usually\ncorrelated when PCA-based anomaly detection is applied, care must be taken in\ncomputing a value function for the Shapley values. We utilize the probabilistic\nview of PCA, particularly its conditional distribution, to exactly compute a\nvalue function for the Shapely values. We also present numerical examples,\nwhich imply that the Shapley values are advantageous for explaining detected\nanomalies than raw reconstruction errors of each feature.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 16:09:31 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 08:50:05 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Takeishi", "Naoya", ""]]}, {"id": "1909.03496", "submitter": "Yaqin Zhou", "authors": "Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, Yang Liu", "title": "Devign: Effective Vulnerability Identification by Learning Comprehensive\n  Program Semantics via Graph Neural Networks", "comments": "accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability identification is crucial to protect the software systems from\nattacks for cyber security. It is especially important to localize the\nvulnerable functions among the source code to facilitate the fix. However, it\nis a challenging and tedious process, and also requires specialized security\nexpertise. Inspired by the work on manually-defined patterns of vulnerabilities\nfrom various code representation graphs and the recent advance on graph neural\nnetworks, we propose Devign, a general graph neural network based model for\ngraph-level classification through learning on a rich set of code semantic\nrepresentations. It includes a novel Conv module to efficiently extract useful\nfeatures in the learned rich node representations for graph-level\nclassification. The model is trained over manually labeled datasets built on 4\ndiversified large-scale open-source C projects that incorporate high complexity\nand variety of real source code instead of synthesis code used in previous\nworks. The results of the extensive evaluation on the datasets demonstrate that\nDevign outperforms the state of the arts significantly with an average of\n10.51% higher accuracy and 8.68\\% F1 score, increases averagely 4.66% accuracy\nand 6.37% F1 by the Conv module.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 16:14:31 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhou", "Yaqin", ""], ["Liu", "Shangqing", ""], ["Siow", "Jingkai", ""], ["Du", "Xiaoning", ""], ["Liu", "Yang", ""]]}, {"id": "1909.03500", "submitter": "Zhining Liu", "authors": "Zhining Liu, Wei Cao, Zhifeng Gao, Jiang Bian, Hechang Chen, Yi Chang,\n  Tie-Yan Liu", "title": "Self-paced Ensemble for Highly Imbalanced Massive Data Classification", "comments": "IEEE 36th International Conference on Data Engineering (ICDE 2020)", "journal-ref": "2020 IEEE 36th International Conference on Data Engineering\n  (ICDE). IEEE, 2020: 841-852", "doi": "10.1109/ICDE48307.2020.00078", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications reveal difficulties in learning classifiers from\nimbalanced data. The rising big data era has been witnessing more\nclassification tasks with large-scale but extremely imbalance and low-quality\ndatasets. Most of existing learning methods suffer from poor performance or low\ncomputation efficiency under such a scenario. To tackle this problem, we\nconduct deep investigations into the nature of class imbalance, which reveals\nthat not only the disproportion between classes, but also other difficulties\nembedded in the nature of data, especially, noises and class overlapping,\nprevent us from learning effective classifiers. Taking those factors into\nconsideration, we propose a novel framework for imbalance classification that\naims to generate a strong ensemble by self-paced harmonizing data hardness via\nunder-sampling. Extensive experiments have shown that this new framework, while\nbeing very computationally efficient, can lead to robust performance even under\nhighly overlapping classes and extremely skewed distribution. Note that, our\nmethods can be easily adapted to most of existing learning methods (e.g., C4.5,\nSVM, GBDT and Neural Network) to boost their performance on imbalanced data.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 16:32:47 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 10:39:57 GMT"}, {"version": "v3", "created": "Sat, 17 Oct 2020 13:49:17 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Liu", "Zhining", ""], ["Cao", "Wei", ""], ["Gao", "Zhifeng", ""], ["Bian", "Jiang", ""], ["Chen", "Hechang", ""], ["Chang", "Yi", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1909.03508", "submitter": "Martin Andrews", "authors": "Yew Ken Chia, Sam Witteveen, Martin Andrews", "title": "Transformer to CNN: Label-scarce distillation for efficient text\n  classification", "comments": "Accepted paper for CDNNRIA workshop at NeurIPS 2018. (3 pages +\n  references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant advances have been made in Natural Language Processing (NLP)\nmodelling since the beginning of 2018. The new approaches allow for accurate\nresults, even when there is little labelled data, because these NLP models can\nbenefit from training on both task-agnostic and task-specific unlabelled data.\nHowever, these advantages come with significant size and computational costs.\nThis workshop paper outlines how our proposed convolutional student\narchitecture, having been trained by a distillation process from a large-scale\nmodel, can achieve 300x inference speedup and 39x reduction in parameter count.\nIn some cases, the student model performance surpasses its teacher on the\nstudied tasks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 16:57:26 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Chia", "Yew Ken", ""], ["Witteveen", "Sam", ""], ["Andrews", "Martin", ""]]}, {"id": "1909.03522", "submitter": "Hsia Liang", "authors": "Xia Liang and Junmin Wu and Jing Cao", "title": "MIDI-Sandwich2: RNN-based Hierarchical Multi-modal Fusion Generation VAE\n  networks for multi-track symbolic music generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, almost all the multi-track music generation models use the\nConvolutional Neural Network (CNN) to build the generative model, while the\nRecurrent Neural Network (RNN) based models can not be applied in this task. In\nview of the above problem, this paper proposes a RNN-based Hierarchical\nMulti-modal Fusion Generation Variational Autoencoder (VAE) network,\nMIDI-Sandwich2, for multi-track symbolic music generation. Inspired by VQ-VAE2,\nMIDI-Sandwich2 expands the dimension of the original hierarchical model by\nusing multiple independent Binary Variational Autoencoder (BVAE) models without\nsharing weights to process the information of each track. Then, with\nmulti-modal fusion technology, the upper layer named Multi-modal Fusion\nGeneration VAE (MFG-VAE) combines the latent space vectors generated by the\nrespective tracks, and uses the decoder to perform the ascending dimension\nreconstruction to simulate the inverse operation of multi-modal fusion,\nmulti-modal generation, so as to realize the RNN-based multi-track symbolic\nmusic generation. For the multi-track format pianoroll, we also improve the\noutput binarization method of MuseGAN, which solves the problem that the\nrefinement step of the original scheme is difficult to differentiate and the\ngradient is hard to descent, making the generated song more expressive. The\nmodel is validated on the Lakh Pianoroll Dataset (LPD) multi-track dataset.\nCompared to the MuseGAN, MIDI-Sandwich2 can not only generate harmonious\nmulti-track music, the generation quality is also close to the state of the art\nlevel. At the same time, by using the VAE to restore songs, the semi-generated\nsongs reproduced by the MIDI-Sandwich2 are more beautiful than the pure\nautogeneration music generated by MuseGAN. Both the code and the audition audio\nsamples are open source on https://github.com/LiangHsia/MIDI-S2.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 17:55:16 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Liang", "Xia", ""], ["Wu", "Junmin", ""], ["Cao", "Jing", ""]]}, {"id": "1909.03526", "submitter": "Chiyu Zhang", "authors": "Chiyu Zhang and Muhammad Abdul-Mageed", "title": "Multi-Task Bidirectional Transformer Representations for Irony Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised deep learning requires large amounts of training data. In the\ncontext of the FIRE2019 Arabic irony detection shared task (IDAT@FIRE2019), we\nshow how we mitigate this need by fine-tuning the pre-trained bidirectional\nencoders from transformers (BERT) on gold data in a multi-task setting. We\nfurther improve our models by by further pre-training BERT on `in-domain' data,\nthus alleviating an issue of dialect mismatch in the Google-released BERT\nmodel. Our best model acquires 82.4 macro F1 score, and has the unique\nadvantage of being feature-engineering free (i.e., based exclusively on deep\nlearning).\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 18:31:42 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 04:37:02 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 06:57:28 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Zhang", "Chiyu", ""], ["Abdul-Mageed", "Muhammad", ""]]}, {"id": "1909.03539", "submitter": "Peng Liao", "authors": "Peng Liao, Kristjan Greenewald, Predrag Klasnja, Susan Murphy", "title": "Personalized HeartSteps: A Reinforcement Learning Algorithm for\n  Optimizing Physical Activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent evolution of mobile health technologies, health scientists\nare increasingly interested in developing just-in-time adaptive interventions\n(JITAIs), typically delivered via notification on mobile device and designed to\nhelp the user prevent negative health outcomes and promote the adoption and\nmaintenance of healthy behaviors. A JITAI involves a sequence of decision rules\n(i.e., treatment policy) that takes the user's current context as input and\nspecifies whether and what type of an intervention should be provided at the\nmoment. In this paper, we develop a Reinforcement Learning (RL) algorithm that\ncontinuously learns and improves the treatment policy embedded in the JITAI as\nthe data is being collected from the user. This work is motivated by our\ncollaboration on designing the RL algorithm in HeartSteps V2 based on data from\nHeartSteps V1. HeartSteps is a physical activity mobile health application. The\nRL algorithm developed in this paper is being used in HeartSteps V2 to decide,\nfive times per day, whether to deliver a context-tailored activity suggestion.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 20:12:30 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Liao", "Peng", ""], ["Greenewald", "Kristjan", ""], ["Klasnja", "Predrag", ""], ["Murphy", "Susan", ""]]}, {"id": "1909.03547", "submitter": "Shay Moran", "authors": "Mark Braverman and Gillat Kol and Shay Moran and Raghuvansh R. Saxena", "title": "Convex Set Disjointness, Distributed Learning of Halfspaces, and LP\n  Feasibility", "comments": "37 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Convex Set Disjointness (CSD) problem, where two players have\ninput sets taken from an arbitrary fixed domain~$U\\subseteq \\mathbb{R}^d$ of\nsize $\\lvert U\\rvert = n$. Their mutual goal is to decide using minimum\ncommunication whether the convex hulls of their sets intersect (equivalently,\nwhether their sets can be separated by a hyperplane).\n  Different forms of this problem naturally arise in distributed learning and\noptimization: it is equivalent to {\\em Distributed Linear Program (LP)\nFeasibility} -- a basic task in distributed optimization, and it is tightly\nlinked to {\\it Distributed Learning of Halfdpaces in $\\mathbb{R}^d$}. In\n{communication complexity theory}, CSD can be viewed as a geometric\ninterpolation between the classical problems of {Set Disjointness} (when~$d\\geq\nn-1$) and {Greater-Than} (when $d=1$).\n  We establish a nearly tight bound of $\\tilde \\Theta(d\\log n)$ on the\ncommunication complexity of learning halfspaces in $\\mathbb{R}^d$. For Convex\nSet Disjointness (and the equivalent task of distributed LP feasibility) we\nderive upper and lower bounds of $\\tilde O(d^2\\log n)$ and~$\\Omega(d\\log n)$.\nThese results improve upon several previous works in distributed learning and\noptimization.\n  Unlike typical works in communication complexity, the main technical\ncontribution of this work lies in the upper bounds. In particular, our\nprotocols are based on a {\\it Container Lemma for Halfspaces} and on two\nvariants of {\\it Carath\\'eodory's Theorem}, which may be of independent\ninterest. These geometric statements are used by our protocols to provide a\ncompressed summary of the players' input.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 21:19:34 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Braverman", "Mark", ""], ["Kol", "Gillat", ""], ["Moran", "Shay", ""], ["Saxena", "Raghuvansh R.", ""]]}, {"id": "1909.03550", "submitter": "Elad Hazan", "authors": "Elad Hazan", "title": "Lecture Notes: Optimization for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lecture notes on optimization for machine learning, derived from a course at\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\nSimons Foundation, Berkeley.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 21:49:42 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Hazan", "Elad", ""]]}, {"id": "1909.03564", "submitter": "Artit Wangperawong", "authors": "Xinyi Liu and Artit Wangperawong", "title": "Transfer Learning Robustness in Multi-Class Categorization by\n  Fine-Tuning Pre-Trained Contextualized Language Models", "comments": "Pre-trained models and code available at\n  https://github.com/artitw/text2class", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study compares the effectiveness and robustness of multi-class\ncategorization of Amazon product data using transfer learning on pre-trained\ncontextualized language models. Specifically, we fine-tuned BERT and XLNet, two\nbidirectional models that have achieved state-of-the-art performance on many\nnatural language tasks and benchmarks, including text classification. While\nexisting classification studies and benchmarks focus on binary targets, with\nthe exception of ordinal ranking tasks, here we examine the robustness of such\nmodels as the number of classes grows from 1 to 20. Our experiments demonstrate\nan approximately linear decrease in performance metrics (i.e., precision,\nrecall, $F_1$ score, and accuracy) with the number of class labels. BERT\nconsistently outperforms XLNet using identical hyperparameters on the entire\nrange of class label quantities for categorizing products based on their\ntextual descriptions. BERT is also more affordable than XLNet in terms of the\ncomputational cost (i.e., time and memory) required for training. In all cases\nstudied, the performance degradation rates were estimated to be 1% per\nadditional class label.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 23:35:00 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 17:54:14 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Liu", "Xinyi", ""], ["Wangperawong", "Artit", ""]]}, {"id": "1909.03569", "submitter": "Prince Zizhuang Wang", "authors": "Prince Zizhuang Wang and William Yang Wang", "title": "Neural Gaussian Copula for Variational Autoencoder", "comments": "11 pages", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational language models seek to estimate the posterior of latent\nvariables with an approximated variational posterior. The model often assumes\nthe variational posterior to be factorized even when the true posterior is not.\nThe learned variational posterior under this assumption does not capture the\ndependency relationships over latent variables. We argue that this would cause\na typical training problem called posterior collapse observed in all other\nvariational language models. We propose Gaussian Copula Variational Autoencoder\n(VAE) to avert this problem. Copula is widely used to model correlation and\ndependencies of high-dimensional random variables, and therefore it is helpful\nto maintain the dependency relationships that are lost in VAE. The empirical\nresults show that by modeling the correlation of latent variables explicitly\nusing a neural parametric copula, we can avert this training difficulty while\ngetting competitive results among all other VAE approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 00:10:58 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Prince Zizhuang", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.03577", "submitter": "Christopher Jung", "authors": "Christopher Jung, Katrina Ligett, Seth Neel, Aaron Roth, Saeed\n  Sharifi-Malvajerdi, Moshe Shenfeld", "title": "A New Analysis of Differential Privacy's Generalization Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new proof of the \"transfer theorem\" underlying adaptive data\nanalysis: that any mechanism for answering adaptively chosen statistical\nqueries that is differentially private and sample-accurate is also accurate\nout-of-sample. Our new proof is elementary and gives structural insights that\nwe expect will be useful elsewhere. We show: 1) that differential privacy\nensures that the expectation of any query on the posterior distribution on\ndatasets induced by the transcript of the interaction is close to its true\nvalue on the data distribution, and 2) sample accuracy on its own ensures that\nany query answer produced by the mechanism is close to its posterior\nexpectation with high probability. This second claim follows from a thought\nexperiment in which we imagine that the dataset is resampled from the posterior\ndistribution after the mechanism has committed to its answers. The transfer\ntheorem then follows by summing these two bounds, and in particular, avoids the\n\"monitor argument\" used to derive high probability bounds in prior work. An\nupshot of our new proof technique is that the concrete bounds we obtain are\nsubstantially better than the best previously known bounds, even though the\nimprovements are in the constants, rather than the asymptotics (which are known\nto be tight). As we show, our new bounds outperform the naive\n\"sample-splitting\" baseline at dramatically smaller dataset sizes compared to\nthe previous state of the art, bringing techniques from this literature closer\nto practicality.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 00:49:03 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Jung", "Christopher", ""], ["Ligett", "Katrina", ""], ["Neel", "Seth", ""], ["Roth", "Aaron", ""], ["Sharifi-Malvajerdi", "Saeed", ""], ["Shenfeld", "Moshe", ""]]}, {"id": "1909.03585", "submitter": "Jingyu Shao Mr.", "authors": "Jingyu Shao, Qing Wang and Fangbing Liu", "title": "Learning to Sample: an Active Learning Framework", "comments": "Accepted by ICDM'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning algorithms for active learning are emerging as a promising\nparadigm for learning the ``best'' active learning strategy. However, current\nlearning-based active learning approaches still require sufficient training\ndata so as to generalize meta-learning models for active learning. This is\ncontrary to the nature of active learning which typically starts with a small\nnumber of labeled samples. The unavailability of large amounts of labeled\nsamples for training meta-learning models would inevitably lead to poor\nperformance (e.g., instabilities and overfitting). In our paper, we tackle\nthese issues by proposing a novel learning-based active learning framework,\ncalled Learning To Sample (LTS). This framework has two key components: a\nsampling model and a boosting model, which can mutually learn from each other\nin iterations to improve the performance of each other. Within this framework,\nthe sampling model incorporates uncertainty sampling and diversity sampling\ninto a unified process for optimization, enabling us to actively select the\nmost representative and informative samples based on an optimized integration\nof uncertainty and diversity. To evaluate the effectiveness of the LTS\nframework, we have conducted extensive experiments on three different\nclassification tasks: image classification, salary level prediction, and entity\nresolution. The experimental results show that our LTS framework significantly\noutperforms all the baselines when the label budget is limited, especially for\ndatasets with highly imbalanced classes. In addition to this, our LTS framework\ncan effectively tackle the cold start problem occurring in many existing active\nlearning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 01:51:32 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shao", "Jingyu", ""], ["Wang", "Qing", ""], ["Liu", "Fangbing", ""]]}, {"id": "1909.03586", "submitter": "Ajay Tripathi", "authors": "Ajay Shanker Tripathi, Benjamin W. Domingue", "title": "Curve Fitting from Probabilistic Emissions and Applications to Dynamic\n  Item Response Theory", "comments": "Full version of our IEEE International Conference on Data Mining\n  (ICDM) 2019 paper. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item response theory (IRT) models are widely used in psychometrics and\neducational measurement, being deployed in many high stakes tests such as the\nGRE aptitude test. IRT has largely focused on estimation of a single latent\ntrait (e.g. ability) that remains static through the collection of item\nresponses. However, in contemporary settings where item responses are being\ncontinuously collected, such as Massive Open Online Courses (MOOCs), interest\nwill naturally be on the dynamics of ability, thus complicating usage of\ntraditional IRT models. We propose DynAEsti, an augmentation of the traditional\nIRT Expectation Maximization algorithm that allows ability to be a continuously\nvarying curve over time. In the process, we develop CurvFiFE, a novel\nnon-parametric continuous-time technique that handles the\ncurve-fitting/regression problem extended to address more general probabilistic\nemissions (as opposed to simply noisy data points). Furthermore, to accomplish\nthis, we develop a novel technique called grafting, which can successfully\napproximate distributions represented by graphical models when other popular\ntechniques like Loopy Belief Propogation (LBP) and Variational Inference (VI)\nfail. The performance of DynAEsti is evaluated through simulation, where we\nachieve results comparable to the optimal of what is observed in the static\nability scenario. Finally, DynAEsti is applied to a longitudinal performance\ndataset (80-years of competitive golf at the 18-hole Masters Tournament) to\ndemonstrate its ability to recover key properties of human performance and the\nheterogeneous characteristics of the different holes. Python code for CurvFiFE\nand DynAEsti is publicly available at github.com/chausies/DynAEstiAndCurvFiFE.\nThis is the full version of our ICDM 2019 paper.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 01:54:12 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Tripathi", "Ajay Shanker", ""], ["Domingue", "Benjamin W.", ""]]}, {"id": "1909.03600", "submitter": "Majid Abdolshah", "authors": "Majid Abdolshah, Alistair Shilton, Santu Rana, Sunil Gupta, Svetha\n  Venkatesh", "title": "Cost-aware Multi-objective Bayesian optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of expense in Bayesian optimisation generally refers to the\nuniformly expensive cost of function evaluations over the whole search space.\nHowever, in some scenarios, the cost of evaluation for black-box objective\nfunctions is non-uniform since different inputs from search space may incur\ndifferent costs for function evaluations. We introduce a cost-aware\nmulti-objective Bayesian optimisation with non-uniform evaluation cost over\nobjective functions by defining cost-aware constraints over the search space.\nThe cost-aware constraints are a sorted tuple of indexes that demonstrate the\nordering of dimensions of the search space based on the user's prior knowledge\nabout their cost of usage. We formulate a new multi-objective Bayesian\noptimisation acquisition function with detailed analysis of the convergence\nthat incorporates this cost-aware constraints while optimising the objective\nfunctions. We demonstrate our algorithm based on synthetic and real-world\nproblems in hyperparameter tuning of neural networks and random forests.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 02:49:17 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Abdolshah", "Majid", ""], ["Shilton", "Alistair", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1909.03601", "submitter": "Yuta Saito", "authors": "Yuta Saito, Suguru Yaginuma, Yuta Nishino, Hayato Sakata, Kazuhide\n  Nakata", "title": "Unbiased Recommender Learning from Missing-Not-At-Random Implicit\n  Feedback", "comments": "accepted at WSDM'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems widely use implicit feedback such as click data because\nof its general availability. Although the presence of clicks signals the users'\npreference to some extent, the lack of such clicks does not necessarily\nindicate a negative response from the users, as it is possible that the users\nwere not exposed to the items (positive-unlabeled problem). This leads to a\ndifficulty in predicting the users' preferences from implicit feedback.\nPrevious studies addressed the positive-unlabeled problem by uniformly\nupweighting the loss for the positive feedback data or estimating the\nconfidence of each data having relevance information via the EM-algorithm.\nHowever, these methods failed to address the missing-not-at-random problem in\nwhich popular or frequently recommended items are more likely to be clicked\nthan other items even if a user does not have a considerable interest in them.\nTo overcome these limitations, we first define an ideal loss function to be\noptimized to realize recommendations that maximize the relevance and propose an\nunbiased estimator for the ideal loss. Subsequently, we analyze the variance of\nthe proposed unbiased estimator and further propose a clipped estimator that\nincludes the unbiased estimator as a special case. We demonstrate that the\nclipped estimator is expected to improve the performance of the recommender\nsystem, by considering the bias-variance trade-off. We conduct semi-synthetic\nand real-world experiments and demonstrate that the proposed method largely\noutperforms the baselines. In particular, the proposed method works better for\nrare items that are less frequently observed in the training data. The findings\nindicate that the proposed method can better achieve the objective of\nrecommending items with the highest relevance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 02:54:20 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 20:39:18 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 07:28:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Saito", "Yuta", ""], ["Yaginuma", "Suguru", ""], ["Nishino", "Yuta", ""], ["Sakata", "Hayato", ""], ["Nakata", "Kazuhide", ""]]}, {"id": "1909.03602", "submitter": "Xiangyu Zhao", "authors": "Xiangyu Zhao, Changsheng Gu, Haoshenglun Zhang, Xiwang Yang, Xiaobing\n  Liu, Jiliang Tang, Hui Liu", "title": "DEAR: Deep Reinforcement Learning for Online Advertising Impression in\n  Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent prevalence of Reinforcement Learning (RL), there have been\ntremendous interests in utilizing RL for online advertising in recommendation\nplatforms (e.g., e-commerce and news feed sites). However, most RL-based\nadvertising algorithms focus on optimizing ads' revenue while ignoring the\npossible negative influence of ads on user experience of recommended items\n(products, articles and videos). Developing an optimal advertising algorithm in\nrecommendations faces immense challenges because interpolating ads improperly\nor too frequently may decrease user experience, while interpolating fewer ads\nwill reduce the advertising revenue. Thus, in this paper, we propose a novel\nadvertising strategy for the rec/ads trade-off. To be specific, we develop an\nRL-based framework that can continuously update its advertising strategies and\nmaximize reward in the long run. Given a recommendation list, we design a novel\nDeep Q-network architecture that can determine three internally related tasks\njointly, i.e., (i) whether to interpolate an ad or not in the recommendation\nlist, and if yes, (ii) the optimal ad and (iii) the optimal location to\ninterpolate. The experimental results based on real-world data demonstrate the\neffectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 02:56:03 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 02:54:37 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 01:39:14 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Zhao", "Xiangyu", ""], ["Gu", "Changsheng", ""], ["Zhang", "Haoshenglun", ""], ["Yang", "Xiwang", ""], ["Liu", "Xiaobing", ""], ["Tang", "Jiliang", ""], ["Liu", "Hui", ""]]}, {"id": "1909.03613", "submitter": "Aakanksha Rana", "authors": "S. M. Iman Zolanvari, Susana Ruano, Aakanksha Rana, Alan Cummins,\n  Rogerio Eduardo da Silva, Morteza Rahbar, Aljosa Smolic", "title": "DublinCity: Annotated LiDAR Point Cloud and its Applications", "comments": "Accepted to the 30th British Machine Vision Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene understanding of full-scale 3D models of an urban area remains a\nchallenging task. While advanced computer vision techniques offer\ncost-effective approaches to analyse 3D urban elements, a precise and densely\nlabelled dataset is quintessential. The paper presents the first-ever labelled\ndataset for a highly dense Aerial Laser Scanning (ALS) point cloud at\ncity-scale. This work introduces a novel benchmark dataset that includes a\nmanually annotated point cloud for over 260 million laser scanning points into\n100'000 (approx.) assets from Dublin LiDAR point cloud [12] in 2015. Objects\nare labelled into 13 classes using hierarchical levels of detail from large\n(i.e., building, vegetation and ground) to refined (i.e., window, door and\ntree) elements. To validate the performance of our dataset, two different\napplications are showcased. Firstly, the labelled point cloud is employed for\ntraining Convolutional Neural Networks (CNNs) to classify urban elements. The\ndataset is tested on the well-known state-of-the-art CNNs (i.e., PointNet,\nPointNet++ and So-Net). Secondly, the complete ALS dataset is applied as\ndetailed ground truth for city-scale image-based 3D reconstruction.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 13:47:31 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zolanvari", "S. M. Iman", ""], ["Ruano", "Susana", ""], ["Rana", "Aakanksha", ""], ["Cummins", "Alan", ""], ["da Silva", "Rogerio Eduardo", ""], ["Rahbar", "Morteza", ""], ["Smolic", "Aljosa", ""]]}, {"id": "1909.03615", "submitter": "Chun-Ting Liu", "authors": "Chun-Ting Liu", "title": "Neural Architecture Search in Embedding Space", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural architecture search (NAS) algorithm with reinforcement learning\ncan be a powerful and novel framework for the automatic discovering process of\nneural architectures. However, its application is restricted by noncontinuous\nand high-dimensional search spaces, which result in difficulty in optimization.\nTo resolve these problems, we proposed NAS in embedding space (NASES), which is\na novel framework. Unlike other NAS with reinforcement learning approaches that\nsearch over a discrete and high-dimensional architecture space, this approach\nenables reinforcement learning to search in an embedding space by using\narchitecture encoders and decoders. The current experiment demonstrated that\nthe performance of the final architecture network using the NASES procedure is\ncomparable with that of other popular NAS approaches for the image\nclassification task on CIFAR-10. The results of the experiment were efficient\nand indicated that NASES was highly efficient to discover final architecture\nonly in $<$3.5 GPU hours. The beneficial-performance and effectiveness of NASES\nwas impressive when the architecture-embedding searching and weight\ninitialization were applied.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 03:28:55 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 01:55:48 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 08:06:33 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Liu", "Chun-Ting", ""]]}, {"id": "1909.03620", "submitter": "S Indrapriyadarsini", "authors": "S. Indrapriyadarsini, Shahrzad Mahboubi, Hiroshi Ninomiya and Hideki\n  Asai", "title": "An Adaptive Stochastic Nesterov Accelerated Quasi Newton Method for\n  Training RNNs", "comments": "Accepted in NOLTA 2019, IEICE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem in training neural networks is the vanishing and/or\nexploding gradient problem which is more prominently seen in training of\nRecurrent Neural Networks (RNNs). Thus several algorithms have been proposed\nfor training RNNs. This paper proposes a novel adaptive stochastic Nesterov\naccelerated quasiNewton (aSNAQ) method for training RNNs. The proposed method\naSNAQ is an accelerated method that uses the Nesterov's gradient term along\nwith second order curvature information. The performance of the proposed method\nis evaluated in Tensorflow on benchmark sequence modeling problems. The results\nshow an improved performance while maintaining a low per-iteration cost and\nthus can be effectively used to train RNNs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 03:35:50 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Indrapriyadarsini", "S.", ""], ["Mahboubi", "Shahrzad", ""], ["Ninomiya", "Hiroshi", ""], ["Asai", "Hideki", ""]]}, {"id": "1909.03621", "submitter": "S Indrapriyadarsini", "authors": "S. Indrapriyadarsini, Shahrzad Mahboubi, Hiroshi Ninomiya and Hideki\n  Asai", "title": "A Stochastic Quasi-Newton Method with Nesterov's Accelerated Gradient", "comments": "Accepted at ECML-PKDD 2019", "journal-ref": null, "doi": "10.1007/978-3-030-46150-8_43", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating second order curvature information in gradient based methods\nhave shown to improve convergence drastically despite its computational\nintensity. In this paper, we propose a stochastic (online) quasi-Newton method\nwith Nesterov's accelerated gradient in both its full and limited memory forms\nfor solving large scale non-convex optimization problems in neural networks.\nThe performance of the proposed algorithm is evaluated in Tensorflow on\nbenchmark classification and regression problems. The results show improved\nperformance compared to the classical second order oBFGS and oLBFGS methods and\npopular first order stochastic methods such as SGD and Adam. The performance\nwith different momentum rates and batch sizes have also been illustrated.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 03:36:01 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Indrapriyadarsini", "S.", ""], ["Mahboubi", "Shahrzad", ""], ["Ninomiya", "Hiroshi", ""], ["Asai", "Hideki", ""]]}, {"id": "1909.03622", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Transfer Reward Learning for Policy Gradient-Based Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-specific scores are often used to optimize for and evaluate the\nperformance of conditional text generation systems. However, such scores are\nnon-differentiable and cannot be used in the standard supervised learning\nparadigm. Hence, policy gradient methods are used since the gradient can be\ncomputed without requiring a differentiable objective.\n  However, we argue that current n-gram overlap based measures that are used as\nrewards can be improved by using model-based rewards transferred from tasks\nthat directly compare the similarity of sentence pairs. These reward models\neither output a score of sentence-level syntactic and semantic similarity\nbetween entire predicted and target sentences as the expected return, or for\nintermediate phrases as segmented accumulative rewards.\n  We demonstrate that using a \\textit{Transferable Reward Learner} leads to\nimproved results on semantical evaluation measures in policy-gradient models\nfor image captioning tasks. Our InferSent actor-critic model improves over a\nBLEU trained actor-critic model on MSCOCO when evaluated on a Word Mover's\nDistance similarity measure by 6.97 points, also improving on a Sliding Window\nCosine Similarity measure by 10.48 points. Similar performance improvements are\nalso obtained on the smaller Flickr-30k dataset, demonstrating the general\napplicability of the proposed transfer learning method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 03:36:42 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1909.03631", "submitter": "Weiyu Li", "authors": "Weiyu Li, Tianyi Chen, Liping Li, Zhaoxian Wu, Qing Ling", "title": "Communication-Censored Distributed Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a communication-efficient algorithm to solve the\nstochastic optimization problem defined over a distributed network, aiming at\nreducing the burdensome communication in applications such as distributed\nmachine learning.Different from the existing works based on quantization and\nsparsification, we introduce a communication-censoring technique to reduce the\ntransmissions of variables, which leads to our communication-Censored\ndistributed Stochastic Gradient Descent (CSGD) algorithm. Specifically, in\nCSGD, the latest mini-batch stochastic gradient at a worker will be transmitted\nto the server if and only if it is sufficiently informative. When the latest\ngradient is not available, the stale one will be reused at the server. To\nimplement this communication-censoring strategy, the batch-size is increasing\nin order to alleviate the effect of stochastic gradient noise. Theoretically,\nCSGD enjoys the same order of convergence rate as that of SGD, but effectively\nreduces communication. Numerical experiments demonstrate the sizable\ncommunication saving of CSGD.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 04:27:57 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 07:34:20 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Li", "Weiyu", ""], ["Chen", "Tianyi", ""], ["Li", "Liping", ""], ["Wu", "Zhaoxian", ""], ["Ling", "Qing", ""]]}, {"id": "1909.03634", "submitter": "Yuka Hashimoto", "authors": "Yuka Hashimoto, Isao Ishikawa, Masahiro Ikeda, Yoichi Matsuo,\n  Yoshinobu Kawahara", "title": "Krylov Subspace Method for Nonlinear Dynamical Systems with Random Noise", "comments": null, "journal-ref": "Journal of Machine Learning Research, 21(172):1-29, 2020\n  (http://jmlr.org/papers/v21/19-993.html)", "doi": null, "report-no": null, "categories": "cs.LG math.DS math.FA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Operator-theoretic analysis of nonlinear dynamical systems has attracted much\nattention in a variety of engineering and scientific fields, endowed with\npractical estimation methods using data such as dynamic mode decomposition. In\nthis paper, we address a lifted representation of nonlinear dynamical systems\nwith random noise based on transfer operators, and develop a novel Krylov\nsubspace method for estimating the operators using finite data, with\nconsideration of the unboundedness of operators. For this purpose, we first\nconsider Perron-Frobenius operators with kernel-mean embeddings for such\nsystems. We then extend the Arnoldi method, which is the most classical type of\nKryov subspace method, so that it can be applied to the current case.\nMeanwhile, the Arnoldi method requires the assumption that the operator is\nbounded, which is not necessarily satisfied for transfer operators on nonlinear\nsystems. We accordingly develop the shift-invert Arnoldi method for\nPerron-Frobenius operators to avoid this problem. Also, we describe an approach\nof evaluating predictive accuracy by estimated operators on the basis of the\nmaximum mean discrepancy, which is applicable, for example, to anomaly\ndetection in complex systems. The empirical performance of our methods is\ninvestigated using synthetic and real-world healthcare data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 05:17:44 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 02:03:20 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 23:08:53 GMT"}, {"version": "v4", "created": "Thu, 24 Sep 2020 13:07:43 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Hashimoto", "Yuka", ""], ["Ishikawa", "Isao", ""], ["Ikeda", "Masahiro", ""], ["Matsuo", "Yoichi", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "1909.03637", "submitter": "Lori Dalton", "authors": "Ali Foroughi pour and Lori A. Dalton", "title": "Theory of Optimal Bayesian Feature Filtering", "comments": "51 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal Bayesian feature filtering (OBF) is a supervised screening method\ndesigned for biomarker discovery. In this article, we prove two major\ntheoretical properties of OBF. First, optimal Bayesian feature selection under\na general family of Bayesian models reduces to filtering if and only if the\nunderlying Bayesian model assumes all features are mutually independent.\nTherefore, OBF is optimal if and only if one assumes all features are mutually\nindependent, and OBF is the only filter method that is optimal under at least\none model in the general Bayesian framework. Second, OBF under independent\nGaussian models is consistent under very mild conditions, including cases where\nthe data is non-Gaussian with correlated features. This result provides\nconditions where OBF is guaranteed to identify the correct feature set given\nenough data, and it justifies the use of OBF in non-design settings where its\nassumptions are invalid.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 05:41:10 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["pour", "Ali Foroughi", ""], ["Dalton", "Lori A.", ""]]}, {"id": "1909.03638", "submitter": "Hyungseok Song", "authors": "Hyungseok Song, Hyeryung Jang, Hai H. Tran, Se-eun Yoon, Kyunghwan\n  Son, Donggyu Yun, Hyoju Chung, Yung Yi", "title": "Solving Continual Combinatorial Selection via Deep Reinforcement\n  Learning", "comments": "Accepted to IJCAI 2019,14 pages,8 figures", "journal-ref": "Proceedings of the Twenty-Eighth International Joint Conference\n  Artificial Intelligence, {IJCAI-19} (2019), 3467--3474", "doi": "10.24963/ijcai.2019/481", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Markov Decision Process (MDP) of selecting a subset of items\nat each step, termed the Select-MDP (S-MDP). The large state and action spaces\nof S-MDPs make them intractable to solve with typical reinforcement learning\n(RL) algorithms especially when the number of items is huge. In this paper, we\npresent a deep RL algorithm to solve this issue by adopting the following key\nideas. First, we convert the original S-MDP into an Iterative Select-MDP\n(IS-MDP), which is equivalent to the S-MDP in terms of optimal actions. IS-MDP\ndecomposes a joint action of selecting K items simultaneously into K iterative\nselections resulting in the decrease of actions at the expense of an\nexponential increase of states. Second, we overcome this state space explo-sion\nby exploiting a special symmetry in IS-MDPs with novel weight shared\nQ-networks, which prov-ably maintain sufficient expressive power. Various\nexperiments demonstrate that our approach works well even when the item space\nis large and that it scales to environments with item spaces different from\nthose used in training.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 05:45:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Song", "Hyungseok", ""], ["Jang", "Hyeryung", ""], ["Tran", "Hai H.", ""], ["Yoon", "Se-eun", ""], ["Son", "Kyunghwan", ""], ["Yun", "Donggyu", ""], ["Chung", "Hyoju", ""], ["Yi", "Yung", ""]]}, {"id": "1909.03676", "submitter": "Mansooreh Pakravan", "authors": "Mansooreh Pakravan and Mohammad Bagher Shamsollahi", "title": "Joint, Partially-joint, and Individual Independent Component Analysis in\n  Multi-Subject fMRI Data", "comments": null, "journal-ref": null, "doi": "10.1109/TBME.2019.2953274", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Objective: Joint analysis of multi-subject brain imaging datasets has wide\napplications in biomedical engineering. In these datasets, some sources belong\nto all subjects (joint), a subset of subjects (partially-joint), or a single\nsubject (individual). In this paper, this source model is referred to as\njoint/partially-joint/individual multiple datasets multidimensional (JpJI-MDM),\nand accordingly, a source extraction method is developed. Method: We present a\ndeflation-based algorithm utilizing higher order cumulants to analyze the\nJpJI-MDM source model. The algorithm maximizes a cost function which leads to\nan eigenvalue problem solved with thin-SVD (singular value decomposition)\nfactorization. Furthermore, we introduce the JpJI-feature which indicates the\nspatial shape of each source and the amount of its jointness with other\nsubjects. We use this feature to determine the type of sources. Results: We\nevaluate our algorithm by analyzing simulated data and two real functional\nmagnetic resonance imaging (fMRI) datasets. In our simulation study, we will\nshow that the proposed algorithm determines the type of sources with the\naccuracy of 95% and 100% for 2-class and 3-class clustering scenarios,\nrespectively. Furthermore, our algorithm extracts meaningful joint and\npartially-joint sources from the two real datasets, which are consistent with\nthe existing neuroscience studies. Conclusion: Our results in analyzing the\nreal datasets reveal that both datasets follow the JpJI-MDM source model. This\nsource model improves the accuracy of source extraction methods developed for\nmulti-subject datasets. Significance: The proposed joint blind source\nseparation algorithm is robust and avoids parameters which are difficult to\nfine-tune.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 07:34:08 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 18:33:59 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Pakravan", "Mansooreh", ""], ["Shamsollahi", "Mohammad Bagher", ""]]}, {"id": "1909.03680", "submitter": "Michal Vr\\'abel", "authors": "Michal Vr\\'abel, J\\'an Gen\\v{c}i, Pavol Bobik, Francesca Bisconti (for\n  the JEM-EUSO Collaboration)", "title": "Machine Learning Approach for Air Shower Recognition in EUSO-SPB Data", "comments": "8 pages, 8 figures, ICRC2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of The Extreme Universe Space Observatory on a Super Pressure\nBalloon (EUSO-SPB1) was to observe from above extensive air showers caused by\nultra-high energy cosmic rays. EUSO-SPB1 uses a fluorescence detector that\nobserves the atmosphere in a nadir observation mode from a near space altitude.\nDuring the 12-day flight, an onboard first level trigger detected more than\n\\num{175000} candidate events. This paper presents an approach to recognize air\nshowers in this dataset. The approach uses a feature extraction method to\ncreate a simpler representation of an event and then it uses established\nmachine learning techniques to classify data into at least two classes - shower\nand noise. The machine learning models are trained on a set of air shower\nsimulations put on top of the background observed during the flight and a set\nof events from the flight. We present the efficiency of the method on datasets\nof simulated events. The flight data events are also used in unsupervised\nlearning methods to identify groups of events with similar features. The\npresented methods allow us to shorten the candidate events list and, thanks to\nthe groups of similar events identified by the unsupervised methods, the\nclassification of the triggered events is made simpler.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 07:42:23 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Vr\u00e1bel", "Michal", "", "for\n  the JEM-EUSO Collaboration"], ["Gen\u010di", "J\u00e1n", "", "for\n  the JEM-EUSO Collaboration"], ["Bobik", "Pavol", "", "for\n  the JEM-EUSO Collaboration"], ["Bisconti", "Francesca", "", "for\n  the JEM-EUSO Collaboration"]]}, {"id": "1909.03681", "submitter": "Firuz Kamalov", "authors": "Firuz Kamalov and Ho Hon Leung", "title": "Outlier Detection in High Dimensional Data", "comments": null, "journal-ref": "Journal of Information & Knowledge Management (2020)", "doi": "10.1142/S0219649220400134", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data poses unique challenges in outlier detection process.\nMost of the existing algorithms fail to properly address the issues stemming\nfrom a large number of features. In particular, outlier detection algorithms\nperform poorly on data set of small size with a large number of features. In\nthis paper, we propose a novel outlier detection algorithm based on principal\ncomponent analysis and kernel density estimation. The proposed method is\ndesigned to address the challenges of dealing with high-dimensional data by\nprojecting the original data onto a smaller space and using the innate\nstructure of the data to calculate anomaly scores for each data point.\nNumerical experiments on synthetic and real-life data show that our method\nperforms well on high-dimensional data. In particular, the proposed method\noutperforms the benchmark methods as measured by the $F_1$-score. Our method\nalso produces better-than-average execution times compared to the benchmark\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 07:43:47 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kamalov", "Firuz", ""], ["Leung", "Ho Hon", ""]]}, {"id": "1909.03683", "submitter": "Christopher Clark", "authors": "Christopher Clark, Mark Yatskar, Luke Zettlemoyer", "title": "Don't Take the Easy Way Out: Ensemble Based Methods for Avoiding Known\n  Dataset Biases", "comments": "In EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art models often make use of superficial patterns in the data\nthat do not generalize well to out-of-domain or adversarial settings. For\nexample, textual entailment models often learn that particular key words imply\nentailment, irrespective of context, and visual question answering models learn\nto predict prototypical answers, without considering evidence in the image. In\nthis paper, we show that if we have prior knowledge of such biases, we can\ntrain a model to be more robust to domain shift. Our method has two stages: we\n(1) train a naive model that makes predictions exclusively based on dataset\nbiases, and (2) train a robust model as part of an ensemble with the naive one\nin order to encourage it to focus on other patterns in the data that are more\nlikely to generalize. Experiments on five datasets with out-of-domain test sets\nshow significantly improved robustness in all settings, including a 12 point\ngain on a changing priors visual question answering dataset and a 9 point gain\non an adversarial question answering test set.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 07:44:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Clark", "Christopher", ""], ["Yatskar", "Mark", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1909.03704", "submitter": "Yuan Meng", "authors": "Yuan Meng", "title": "Estimating Granger Causality with Unobserved Confounders via Deep\n  Latent-Variable Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger causality analysis, as one of the most popular time series causality\nmethods, has been widely used in the economics, neuroscience. However,\nunobserved confounders is a fundamental problem in the observational studies,\nwhich is still not solved for the non-linear Granger causality. The application\nworks often deal with this problem in virtue of the proxy variables, who can be\ntreated as a measure of the confounder with noise. But the proxy variables has\nbeen proved to be unreliable, because of the bias it may induce. In this paper,\nwe try to \"recover\" the unobserved confounders for the Granger causality. We\nuse a generative model with latent variable to build the relationship between\nthe unobserved confounders and the observed variables(tested variable and the\nproxy variables). The posterior distribution of the latent variable is adopted\nto represent the confounders distribution, which can be sampled to get the\nestimated confounders. We adopt the variational autoencoder to estimate the\nintractable posterior distribution. The recurrent neural network is applied to\nbuild the temporal relationship in the data. We evaluate our method in the\nsynthetic and semi-synthetic dataset. The result shows our estimated\nconfounders has a better performance than the proxy variables in the non-linear\nGranger causality with multiple proxies in the semi-synthetic dataset. But the\nperformances of the synthetic dataset and the different noise level of proxy\nseem terrible. Any advice can really help.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 08:49:22 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Meng", "Yuan", ""]]}, {"id": "1909.03705", "submitter": "Sophie Fosson", "authors": "Vito Cerone, Sophie M. Fosson, Diego Regruto", "title": "Sparse linear regression with compressed and low-precision data via\n  concave quadratic programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of the recovery of a k-sparse vector from compressed\nlinear measurements when data are corrupted by a quantization noise. When the\nnumber of measurements is not sufficiently large, different $k$-sparse\nsolutions may be present in the feasible set, and the classical l1 approach may\nbe unsuccessful. For this motivation, we propose a non-convex quadratic\nprogramming method, which exploits prior information on the magnitude of the\nnon-zero parameters. This results in a more efficient support recovery. We\nprovide sufficient conditions for successful recovery and numerical simulations\nto illustrate the practical feasibility of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 08:55:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Cerone", "Vito", ""], ["Fosson", "Sophie M.", ""], ["Regruto", "Diego", ""]]}, {"id": "1909.03712", "submitter": "Zhao Kang", "authors": "Xiaofan Bo and Zhao Kang and Zhitong Zhao and Yuanzhang Su and Wenyu\n  Chen", "title": "Latent Multi-view Semi-Supervised Classification", "comments": "ACML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To explore underlying complementary information from multiple views, in this\npaper, we propose a novel Latent Multi-view Semi-Supervised Classification\n(LMSSC) method. Unlike most existing multi-view semi-supervised classification\nmethods that learn the graph using original features, our method seeks an\nunderlying latent representation and performs graph learning and label\npropagation based on the learned latent representation. With the\ncomplementarity of multiple views, the latent representation could depict the\ndata more comprehensively than every single view individually, accordingly\nmaking the graph more accurate and robust as well. Finally, LMSSC integrates\nlatent representation learning, graph construction, and label propagation into\na unified framework, which makes each subtask optimized. Experimental results\non real-world benchmark datasets validate the effectiveness of our proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 09:18:39 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Bo", "Xiaofan", ""], ["Kang", "Zhao", ""], ["Zhao", "Zhitong", ""], ["Su", "Yuanzhang", ""], ["Chen", "Wenyu", ""]]}, {"id": "1909.03723", "submitter": "Marco Virgolin", "authors": "Marco Virgolin, Ziyuan Wang, Tanja Alderliesten, Peter A. N. Bosman", "title": "Machine learning for automatic construction of pseudo-realistic\n  pediatric abdominal phantoms", "comments": "Currently submitted to SPIE Medical Imaging journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.med-ph stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is proving extremely beneficial in many healthcare\napplications. In pediatric oncology, retrospective studies that investigate the\nrelationship between treatment and late adverse effects still rely on simple\nheuristics. To assess the effects of radiation therapy, treatment plans are\ntypically simulated on phantoms, i.e., virtual surrogates of patient anatomy.\nCurrently, phantoms are built according to reasonable, yet simple,\nhuman-designed criteria. This often results in a lack of individualization. We\npresent a novel approach that combines imaging and ML to build individualized\nphantoms automatically. Given the features of a patient treated historically\n(only 2D radiographs available), and a database of 3D Computed Tomography (CT)\nimaging with organ segmentations and relative patient features, our approach\nuses ML to predict how to assemble a patient-specific phantom automatically.\nExperiments on 60 abdominal CTs of pediatric patients show that our approach\nconstructs significantly more representative phantoms than using current\nphantom building criteria, in terms of location and shape of the abdomen and of\ntwo considered organs, the liver and the spleen. Among several ML algorithms\nconsidered, the Gene-pool Optimal Mixing Evolutionary Algorithm for Genetic\nProgramming (GP-GOMEA) is found to deliver the best performing models, which\nare, moreover, transparent and interpretable mathematical expressions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 09:38:22 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Virgolin", "Marco", ""], ["Wang", "Ziyuan", ""], ["Alderliesten", "Tanja", ""], ["Bosman", "Peter A. N.", ""]]}, {"id": "1909.03731", "submitter": "Bo Liu", "authors": "Bo Liu, Yi Liang", "title": "Optimal Function Approximation with Relu Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider in this paper the optimal approximations of convex univariate\nfunctions with feed-forward Relu neural networks. We are interested in the\nfollowing question: what is the minimal approximation error given the number of\napproximating linear pieces? We establish the necessary and sufficient\nconditions and uniqueness of optimal approximations, and give lower and upper\nbounds of the optimal approximation errors. Relu neural network architectures\nare then presented to generate these optimal approximations. Finally, we\npropose an algorithm to find the optimal approximations, as well as prove its\nconvergence and validate it with experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 09:53:28 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 06:00:44 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Liu", "Bo", ""], ["Liang", "Yi", ""]]}, {"id": "1909.03739", "submitter": "Guy Tennenholtz", "authors": "Guy Tennenholtz, Shie Mannor, Uri Shalit", "title": "Off-Policy Evaluation in Partially Observable Environments", "comments": "Accepted to AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the problem of batch off-policy evaluation for\nReinforcement Learning in partially observable environments. Off-policy\nevaluation under partial observability is inherently prone to bias, with risk\nof arbitrarily large errors. We define the problem of off-policy evaluation for\nPartially Observable Markov Decision Processes (POMDPs) and establish what we\nbelieve is the first off-policy evaluation result for POMDPs. In addition, we\nformulate a model in which observed and unobserved variables are decoupled into\ntwo dynamic processes, called a Decoupled POMDP. We show how off-policy\nevaluation can be performed under this new model, mitigating estimation errors\ninherent to general POMDPs. We demonstrate the pitfalls of off-policy\nevaluation in POMDPs using a well-known off-policy method, Importance Sampling,\nand compare it with our result on synthetic medical data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 10:13:09 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 08:51:04 GMT"}, {"version": "v3", "created": "Sun, 24 Nov 2019 07:10:15 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tennenholtz", "Guy", ""], ["Mannor", "Shie", ""], ["Shalit", "Uri", ""]]}, {"id": "1909.03742", "submitter": "Jary Pomponi", "authors": "Jary Pomponi, Simone Scardapane, Vincenzo Lomonaco, Aurelio Uncini", "title": "Efficient Continual Learning in Neural Networks with Embedding\n  Regularization", "comments": null, "journal-ref": "Neurocomputing, 397, pp. 139-148, 2020", "doi": "10.1016/j.neucom.2020.01.093", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning of deep neural networks is a key requirement for scaling\nthem up to more complex applicative scenarios and for achieving real lifelong\nlearning of these architectures. Previous approaches to the problem have\nconsidered either the progressive increase in the size of the networks, or have\ntried to regularize the network behavior to equalize it with respect to\npreviously observed tasks. In the latter case, it is essential to understand\nwhat type of information best represents this past behavior. Common techniques\ninclude regularizing the past outputs, gradients, or individual weights. In\nthis work, we propose a new, relatively simple and efficient method to perform\ncontinual learning by regularizing instead the network internal embeddings. To\nmake the approach scalable, we also propose a dynamic sampling strategy to\nreduce the memory footprint of the required external storage. We show that our\nmethod performs favorably with respect to state-of-the-art approaches in the\nliterature, while requiring significantly less space in memory and\ncomputational time. In addition, inspired inspired by to recent works, we\nevaluate the impact of selecting a more flexible model for the activation\nfunctions inside the network, evaluating the impact of catastrophic forgetting\non the activation functions themselves.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 10:16:47 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 14:24:29 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Pomponi", "Jary", ""], ["Scardapane", "Simone", ""], ["Lomonaco", "Vincenzo", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1909.03749", "submitter": "Fabio Ferreira", "authors": "Fabio Ferreira, Lin Shao, Tamim Asfour, Jeannette Bohg", "title": "Learning Visual Dynamics Models of Rigid Objects using Relational\n  Inductive Biases", "comments": "short paper (4 pages, two figures), accepted to NeurIPS 2019 Graph\n  Representation Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endowing robots with human-like physical reasoning abilities remains\nchallenging. We argue that existing methods often disregard spatio-temporal\nrelations and by using Graph Neural Networks (GNNs) that incorporate a\nrelational inductive bias, we can shift the learning process towards exploiting\nrelations. In this work, we learn action-conditional forward dynamics models of\na simulated manipulation task from visual observations involving cluttered and\nirregularly shaped objects. We investigate two GNN approaches and empirically\nassess their capability to generalize to scenarios with novel and an increasing\nnumber of objects. The first, Graph Networks (GN) based approach, considers\nexplicitly defined edge attributes and not only does it consistently\nunderperform an auto-encoder baseline that we modified to predict future\nstates, our results indicate how different edge attributes can significantly\ninfluence the predictions. Consequently, we develop the Auto-Predictor that\ndoes not rely on explicitly defined edge attributes. It outperforms the\nbaseline and the GN-based models. Overall, our results show the sensitivity of\nGNN-based approaches to the task representation, the efficacy of relational\ninductive biases and advocate choosing lightweight approaches that implicitly\nreason about relations over ones that leave these decisions to human designers.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 10:43:56 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 21:00:07 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 17:32:04 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Ferreira", "Fabio", ""], ["Shao", "Lin", ""], ["Asfour", "Tamim", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1909.03752", "submitter": "Dan Barnes", "authors": "Dan Barnes, Rob Weston and Ingmar Posner", "title": "Masking by Moving: Learning Distraction-Free Radar Odometry from Pose\n  Information", "comments": "Conference on Robot Learning (CoRL), 2019. Video summary:\n  https://youtu.be/eG4Q-j3_6dk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an end-to-end radar odometry system which delivers\nrobust, real-time pose estimates based on a learned embedding space free of\nsensing artefacts and distractor objects. The system deploys a fully\ndifferentiable, correlation-based radar matching approach. This provides the\nsame level of interpretability as established scan-matching methods and allows\nfor a principled derivation of uncertainty estimates. The system is trained in\na (self-)supervised way using only previously obtained pose information as a\ntraining signal. Using 280km of urban driving data, we demonstrate that our\napproach outperforms the previous state-of-the-art in radar odometry by\nreducing errors by up 68% whilst running an order of magnitude faster.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 10:46:15 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 11:19:34 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 12:41:10 GMT"}, {"version": "v4", "created": "Fri, 17 Jan 2020 16:14:26 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Barnes", "Dan", ""], ["Weston", "Rob", ""], ["Posner", "Ingmar", ""]]}, {"id": "1909.03765", "submitter": "Shuyu Lin", "authors": "Shuyu Lin, Stephen Roberts, Niki Trigoni, Ronald Clark", "title": "Balancing Reconstruction Quality and Regularisation in ELBO for VAEs", "comments": "8 pages for main contents and 15 pages for supplemental materials\n  that include data pre-processing, model architectures and more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A trade-off exists between reconstruction quality and the prior\nregularisation in the Evidence Lower Bound (ELBO) loss that Variational\nAutoencoder (VAE) models use for learning. There are few satisfactory\napproaches to deal with a balance between the prior and reconstruction\nobjective, with most methods dealing with this problem through heuristics. In\nthis paper, we show that the noise variance (often set as a fixed value) in the\nGaussian likelihood p(x|z) for real-valued data can naturally act to provide\nsuch a balance. By learning this noise variance so as to maximise the ELBO\nloss, we automatically obtain an optimal trade-off between the reconstruction\nerror and the prior constraint on the posteriors. This variance can be\ninterpreted intuitively as the necessary noise level for the current model to\nbe the best explanation of the observed dataset. Further, by allowing the\nvariance inference to be more flexible it can conveniently be used as an\nuncertainty estimator for reconstructed or generated samples. We demonstrate\nthat optimising the noise variance is a crucial component of VAE learning, and\nshowcase the performance on MNIST, Fashion MNIST and CelebA datasets. We find\nour approach can significantly improve the quality of generated samples whilst\nmaintaining a smooth latent-space manifold to represent the data. The method\nalso offers an indication of uncertainty in the final generative model.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:18:52 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Lin", "Shuyu", ""], ["Roberts", "Stephen", ""], ["Trigoni", "Niki", ""], ["Clark", "Ronald", ""]]}, {"id": "1909.03767", "submitter": "Julius Ruseckas", "authors": "Julius Ruseckas", "title": "Differential equations as models of deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we systematically analyze general properties of differential\nequations used as machine learning models. We demonstrate that the gradient of\nthe loss function with respect to to the hidden state can be considered as a\ngeneralized momentum conjugate to the hidden state, allowing application of the\ntools of classical mechanics. In addition, we show that not only residual\nnetworks, but also feedforward neural networks with small nonlinearities and\nthe weights matrices deviating only slightly from identity matrices can be\nrelated to the differential equations. We propose a differential equation\ndescribing such networks and investigate its properties.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:19:29 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 09:48:10 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Ruseckas", "Julius", ""]]}, {"id": "1909.03772", "submitter": "Nicolai Anton Lynnerup", "authors": "Nicolai A. Lynnerup, Laura Nolling, Rasmus Hasle, John Hallam", "title": "A Survey on Reproducibility by Evaluating Deep Reinforcement Learning\n  Algorithms on Real-World Robots", "comments": "Appears in Proceedings of the Third Conference on Robot Learning\n  (CoRL 2019). Companion source code at\n  https://github.com/dti-research/SenseActExperiments/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As reinforcement learning (RL) achieves more success in solving complex\ntasks, more care is needed to ensure that RL research is reproducible and that\nalgorithms herein can be compared easily and fairly with minimal bias. RL\nresults are, however, notoriously hard to reproduce due to the algorithms'\nintrinsic variance, the environments' stochasticity, and numerous (potentially\nunreported) hyper-parameters. In this work we investigate the many issues\nleading to irreproducible research and how to manage those. We further show how\nto utilise a rigorous and standardised evaluation approach for easing the\nprocess of documentation, evaluation and fair comparison of different\nalgorithms, where we emphasise the importance of choosing the right measurement\nmetrics and conducting proper statistics on the results, for unbiased reporting\nof the results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:33:09 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 07:42:00 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Lynnerup", "Nicolai A.", ""], ["Nolling", "Laura", ""], ["Hasle", "Rasmus", ""], ["Hallam", "John", ""]]}, {"id": "1909.03773", "submitter": "Xinqiang Cai", "authors": "Xin-Qiang Cai, Yao-Xiang Ding, Yuan Jiang, Zhi-Hua Zhou", "title": "Imitation Learning from Pixel-Level Demonstrations by HashReward", "comments": "Accepted by AAMAS-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key issues for imitation learning lies in making policy learned\nfrom limited samples to generalize well in the whole state-action space. This\nproblem is much more severe in high-dimensional state environments, such as\ngame playing with raw pixel inputs. Under this situation, even state-of-the-art\nadversary-based imitation learning algorithms fail. Through empirical studies,\nwe find that the main cause lies in the failure of training a powerful\ndiscriminator to generate meaningful rewards in high-dimensional environments.\nAlthough it seems that dimensionality reduction can help, a straightforward\napplication of off-the-shelf methods cannot achieve good performance. In this\nwork, we show in theory that the balance between dimensionality reduction and\ndiscriminative training is essential for effective learning. To achieve this\ntarget, we propose HashReward, which utilizes the idea of supervised hashing to\nrealize such an ideal balance. Experimental results show that HashReward could\noutperform state-of-the-art methods for a large gap under the challenging\nhigh-dimensional environments.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:37:09 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 10:08:18 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 08:19:00 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Cai", "Xin-Qiang", ""], ["Ding", "Yao-Xiang", ""], ["Jiang", "Yuan", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1909.03790", "submitter": "Daniele Zambon", "authors": "Daniele Zambon, Cesare Alippi, Lorenzo Livi", "title": "Graph Random Neural Features for Distance-Preserving Graph\n  Representations", "comments": "to be published in Proceedings of the 37th International Conference\n  on Machine Learning, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Graph Random Neural Features (GRNF), a novel embedding method from\ngraph-structured data to real vectors based on a family of graph neural\nnetworks. The embedding naturally deals with graph isomorphism and preserves\nthe metric structure of the graph domain, in probability. In addition to being\nan explicit embedding method, it also allows us to efficiently and effectively\napproximate graph metric distances (as well as complete kernel functions); a\ncriterion to select the embedding dimension trading off the approximation\naccuracy with the computational cost is also provided. GRNF can be used within\ntraditional processing methods or as a training-free input layer of a graph\nneural network. The theoretical guarantees that accompany GRNF ensure that the\nconsidered graph distance is metric, hence allowing to distinguish any pair of\nnon-isomorphic graphs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:13:46 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 08:22:46 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 08:37:17 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Zambon", "Daniele", ""], ["Alippi", "Cesare", ""], ["Livi", "Lorenzo", ""]]}, {"id": "1909.03792", "submitter": "Arezoo Hatefi Ghahfarrokhi", "authors": "Arezoo Hatefi Ghahfarrokhi, Mehrnoush Shamsfard", "title": "Tehran Stock Exchange Prediction Using Sentiment Analysis of Online\n  Textual Opinions", "comments": "Intelligent Systems in Accounting, Finance and Management (2019)", "journal-ref": null, "doi": "10.1002/isaf.1465", "report-no": null, "categories": "q-fin.ST cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the impact of the social media data in\npredicting the Tehran Stock Exchange (TSE) variables for the first time. We\nconsider the closing price and daily return of three different stocks for this\ninvestigation. We collected our social media data from Sahamyab.com/stocktwits\nfor about three months. To extract information from online comments, we propose\na hybrid sentiment analysis approach that combines lexicon-based and\nlearning-based methods. Since lexicons that are available for the Persian\nlanguage are not practical for sentiment analysis in the stock market domain,\nwe built a particular sentiment lexicon for this domain. After designing and\ncalculating daily sentiment indices using the sentiment of the comments, we\nexamine their impact on the baseline models that only use historical market\ndata and propose new predictor models using multi regression analysis. In\naddition to the sentiments, we also examine the comments volume and the users'\nreliabilities. We conclude that the predictability of various stocks in TSE is\ndifferent depending on their attributes. Moreover, we indicate that for\npredicting the closing price only comments volume and for predicting the daily\nreturn both the volume and the sentiment of the comments could be useful. We\ndemonstrate that Users' Trust coefficients have different behaviors toward the\nthree stocks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 13:36:21 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 08:10:56 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Ghahfarrokhi", "Arezoo Hatefi", ""], ["Shamsfard", "Mehrnoush", ""]]}, {"id": "1909.03794", "submitter": "Zhiwei Lin", "authors": "Lianbo Ma, Peng Sun, Zhiwei Lin, Hui Wang", "title": "Composing Knowledge Graph Embeddings via Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge graph embedding from an existing knowledge graph is very\nimportant to knowledge graph completion. For a fact $(h,r,t)$ with the head\nentity $h$ having a relation $r$ with the tail entity $t$, the current\napproaches aim to learn low dimensional representations\n$(\\mathbf{h},\\mathbf{r},\\mathbf{t})$, each of which corresponds to the elements\nin $(h, r, t)$, respectively. As $(\\mathbf{h},\\mathbf{r},\\mathbf{t})$ is\nlearned from the existing facts within a knowledge graph, these representations\ncan not be used to detect unknown facts (if the entities or relations never\noccur in the knowledge graph).\n  This paper proposes a new approach called TransW, aiming to go beyond the\ncurrent work by composing knowledge graph embeddings using word embeddings.\nGiven the fact that an entity or a relation contains one or more words (quite\noften), it is sensible to learn a mapping function from word embedding spaces\nto knowledge embedding spaces, which shows how entities are constructed using\nhuman words. More importantly, composing knowledge embeddings using word\nembeddings makes it possible to deal with the emerging new facts (either new\nentities or relations). Experimental results using three public datasets show\nthe consistency and outperformance of the proposed TransW.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:22:28 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Ma", "Lianbo", ""], ["Sun", "Peng", ""], ["Lin", "Zhiwei", ""], ["Wang", "Hui", ""]]}, {"id": "1909.03798", "submitter": "Feng Chen", "authors": "Xin Su, Shangqi Guo and Feng Chen", "title": "Subjectivity Learning Theory towards Artificial General Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction of artificial general intelligence (AGI) was a long-term\ngoal of AI research aiming to deal with the complex data in the real world and\nmake reasonable judgments in various cases like a human. However, the current\nAI creations, referred to as \"Narrow AI\", are limited to a specific problem.\nThe constraints come from two basic assumptions of data, which are independent\nand identical distributed samples and single-valued mapping between inputs and\noutputs. We completely break these constraints and develop the subjectivity\nlearning theory for general intelligence. We assign the mathematical meaning\nfor the philosophical concept of subjectivity and build the data representation\nof general intelligence. Under the subjectivity representation, then the global\nrisk is constructed as the new learning goal. We prove that subjectivity\nlearning holds a lower risk bound than traditional machine learning. Moreover,\nwe propose the principle of empirical global risk minimization (EGRM) as the\nsubjectivity learning process in practice, establish the condition of\nconsistency, and present triple variables for controlling the total risk bound.\nThe subjectivity learning is a novel learning theory for unconstrained real\ndata and provides a path to develop AGI.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:29:32 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 03:20:11 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Su", "Xin", ""], ["Guo", "Shangqi", ""], ["Chen", "Feng", ""]]}, {"id": "1909.03814", "submitter": "Dmytro Pukhkaiev", "authors": "Dmytro Pukhkaiev, Uwe A{\\ss}mann", "title": "Parameter Tuning for Self-optimizing Software at Scale", "comments": "To appear in Workshop on Model Selection and Parameter Tuning in\n  Recommender Systems (MoST-Rec'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiency of self-optimizing systems is heavily dependent on their\noptimization strategies, e.g., choosing exact or approximate solver. A choice\nof such a strategy, in turn, is influenced by numerous factors, such as\nre-optimization time, size of the problem, optimality constraints, etc. Exact\nsolvers are domain-independent and can guarantee optimality but suffer from\nscaling, while approximate solvers offer a \"good-enough\" solution in exchange\nfor a lack of generality and parameter-dependence. In this paper we discuss the\ntrade-offs between exact and approximate optimizers for solving a quality-based\nsoftware selection and hardware mapping problem from the scalability\nperspective. We show that even a simple heuristic can compete with thoroughly\ndeveloped exact solvers under condition of an effective parameter tuning.\nMoreover, we discuss robustness of the obtained algorithm's configuration. Last\nbut not least, we present a software product line for parameter tuning, which\ncomprise the main features of this process and can serve as a platform for\nfurther research in the area of parameter tuning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:50:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Pukhkaiev", "Dmytro", ""], ["A\u00dfmann", "Uwe", ""]]}, {"id": "1909.03817", "submitter": "Xinyue Zheng", "authors": "Xinyue Zheng, Peng Wang, Qigang Wang, Zhongchao shi, Feiyu Xu", "title": "Efficient Automatic Meta Optimization Search for Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous works on meta-learning either relied on elaborately hand-designed\nnetwork structures or adopted specialized learning rules to a particular\ndomain. We propose a universal framework to optimize the meta-learning process\nautomatically by adopting neural architecture search technique (NAS). NAS\nautomatically generates and evaluates meta-learner's architecture for few-shot\nlearning problems, while the meta-learner uses meta-learning algorithm to\noptimize its parameters based on the distribution of learning tasks. Parameter\nsharing and experience replay are adopted to accelerate the architectures\nsearching process, so it takes only 1-2 GPU days to find good architectures.\nExtensive experiments on Mini-ImageNet and Omniglot show that our algorithm\nexcels in few-shot learning tasks. The best architecture found on Mini-ImageNet\nachieves competitive results when transferred to Omniglot, which shows the high\ntransferability of architectures among different computer vision problems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 02:48:52 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zheng", "Xinyue", ""], ["Wang", "Peng", ""], ["Wang", "Qigang", ""], ["shi", "Zhongchao", ""], ["Xu", "Feiyu", ""]]}, {"id": "1909.03818", "submitter": "Ioan Gabriel Bucur", "authors": "Ioan Gabriel Bucur, Tom Claassen, Tom Heskes", "title": "Large-Scale Local Causal Inference of Gene Regulatory Relationships", "comments": "32 pages, 9 figures, 2 tables. This manuscript version has been\n  accepted for publication in the International Journal of Approximate\n  Reasoning. It incorporates reviewer comments and has a new title. This\n  manuscript constitutes an extended version of a previous paper shared on\n  arXiv (arXiv:1809.06827) that has been published in the proceedings of the\n  PGM 2018 conference", "journal-ref": null, "doi": "10.1016/j.ijar.2019.08.012", "report-no": null, "categories": "stat.ML cs.LG q-bio.GN q-bio.MN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene regulatory networks play a crucial role in controlling an organism's\nbiological processes, which is why there is significant interest in developing\ncomputational methods that are able to extract their structure from\nhigh-throughput genetic data. Many of these computational methods are designed\nto infer individual regulatory relationships among genes from data on gene\nexpression. We propose a novel efficient Bayesian method for discovering local\ncausal relationships among triplets of (normally distributed) variables. In our\napproach, we score covariance structures for each triplet in one go and\nincorporate available background knowledge in the form of priors to derive\nposterior probabilities over local causal structures. Our method is flexible in\nthe sense that it allows for different types of causal structures and\nassumptions. We apply our approach to the task of learning causal regulatory\nrelationships among genes. We show that the proposed algorithm produces stable\nand conservative posterior probability estimates over local causal structures\nthat can be used to derive an honest ranking of the most meaningful regulatory\nrelationships. We demonstrate the stability and efficacy of our method both on\nsimulated data and on real-world data from an experiment on yeast.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 17:54:33 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 13:36:39 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Bucur", "Ioan Gabriel", ""], ["Claassen", "Tom", ""], ["Heskes", "Tom", ""]]}, {"id": "1909.03820", "submitter": "Steffen Van Bergerem", "authors": "Steffen van Bergerem", "title": "Learning Concepts Definable in First-Order Logic with Counting", "comments": null, "journal-ref": "34th Annual ACM/IEEE Symposium on Logic in Computer Science, LICS\n  2019, Vancouver, BC, Canada, June 24-27, 2019", "doi": "10.1109/LICS.2019.8785811", "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study classification problems over relational background structures for\nhypotheses that are defined using logics with counting. The aim of this paper\nis to find learning algorithms running in time sublinear in the size of the\nbackground structure. We show that hypotheses defined by FOCN(P)-formulas over\nstructures of polylogarithmic degree can be learned in sublinear time.\nFurthermore, we prove that for structures of unbounded degree there is no\nsublinear learning algorithm for first-order formulas.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 12:57:29 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["van Bergerem", "Steffen", ""]]}, {"id": "1909.03824", "submitter": "Yongqiang Tian", "authors": "Yongqiang Tian, Shiqing Ma, Ming Wen, Yepang Liu, Shing-Chi Cheung,\n  Xiangyu Zhang", "title": "Testing Deep Learning Models for Image Analysis Using Object-Relevant\n  Metamorphic Relations", "comments": "Please note that a later version of this paper is accepted by\n  Empirical Software Engineering in 2021. The title of the accepted paper is:\n  \"To What Extent Do DNN-based Image Classification Models Make Unreliable\n  Inferences?\". Please contact the first author if you are interested in the\n  accepted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are widely used for image analysis. While they offer\nhigh performance in terms of accuracy, people are concerned about if these\nmodels inappropriately make inferences using irrelevant features that are not\nencoded from the target object in a given image. To address the concern, we\npropose a metamorphic testing approach that assesses if a given inference is\nmade based on irrelevant features. Specifically, we propose two novel\nmetamorphic relations to detect such inappropriate inferences. We applied our\napproach to 10 image classification models and 10 object detection models, with\nthree large datasets, i.e., ImageNet, COCO, and Pascal VOC. Over 5.3% of the\ntop-5 correct predictions made by the image classification models are subject\nto inappropriate inferences using irrelevant features. The corresponding rate\nfor the object detection models is over 8.5%. Based on the findings, we further\ndesigned a new image generation strategy that can effectively attack existing\nmodels. Comparing with a baseline approach, our strategy can double the success\nrate of attacks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 13:31:15 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 07:10:53 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Tian", "Yongqiang", ""], ["Ma", "Shiqing", ""], ["Wen", "Ming", ""], ["Liu", "Yepang", ""], ["Cheung", "Shing-Chi", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "1909.03830", "submitter": "Di Wang", "authors": "Di Wang, Feiqing Huang, Jingyu Zhao, Guodong Li, Guangjian Tian", "title": "Compact Autoregressive Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive networks can achieve promising performance in many sequence\nmodeling tasks with short-range dependence. However, when handling\nhigh-dimensional inputs and outputs, the huge amount of parameters in the\nnetwork lead to expensive computational cost and low learning efficiency. The\nproblem can be alleviated slightly by introducing one more narrow hidden layer\nto the network, but the sample size required to achieve a certain training\nerror is still large. To address this challenge, we rearrange the weight\nmatrices of a linear autoregressive network into a tensor form, and then make\nuse of Tucker decomposition to represent low-rank structures. This leads to a\nnovel compact autoregressive network, called Tucker AutoRegressive (TAR) net.\nInterestingly, the TAR net can be applied to sequences with long-range\ndependence since the dimension along the sequential order is reduced.\nTheoretical studies show that the TAR net improves the learning efficiency, and\nrequires much fewer samples for model training. Experiments on synthetic and\nreal-world datasets demonstrate the promising performance of the proposed\ncompact network.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:20:08 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Di", ""], ["Huang", "Feiqing", ""], ["Zhao", "Jingyu", ""], ["Li", "Guodong", ""], ["Tian", "Guangjian", ""]]}, {"id": "1909.03831", "submitter": "Jinming Lu", "authors": "Jinming Lu, Siyuan Lu, Zhisheng Wang, Chao Fang, Jun Lin, Zhongfeng\n  Wang, and Li Du", "title": "Training Deep Neural Networks Using Posit Number System", "comments": "accepted by SOCC2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing size of Deep Neural Network (DNN) models, the high memory\nspace requirements and computational complexity have become an obstacle for\nefficient DNN implementations. To ease this problem, using reduced-precision\nrepresentations for DNN training and inference has attracted many interests\nfrom researchers. This paper first proposes a methodology for training DNNs\nwith the posit arithmetic, a type- 3 universal number (Unum) format that is\nsimilar to the floating point(FP) but has reduced precision. A warm-up training\nstrategy and layer-wise scaling factors are adopted to stabilize training and\nfit the dynamic range of DNN parameters. With the proposed training\nmethodology, we demonstrate the first successful training of DNN models on\nImageNet image classification task in 16 bits posit with no accuracy loss.\nThen, an efficient hardware architecture for the posit multiply-and-accumulate\noperation is also proposed, which can achieve significant improvement in energy\nefficiency than traditional floating-point implementations. The proposed design\nis helpful for future low-power DNN training accelerators.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 13:50:30 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Lu", "Jinming", ""], ["Lu", "Siyuan", ""], ["Wang", "Zhisheng", ""], ["Fang", "Chao", ""], ["Lin", "Jun", ""], ["Wang", "Zhongfeng", ""], ["Du", "Li", ""]]}, {"id": "1909.03834", "submitter": "Dongsheng Ruan", "authors": "Dongsheng Ruan and Jun Wen and Nenggan Zheng and Min Zheng", "title": "Linear Context Transform Block", "comments": "AAAI-2020 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Squeeze-and-Excitation (SE) block presents a channel attention mechanism for\nmodeling global context via explicitly capturing dependencies across channels.\nHowever, we are still far from understanding how the SE block works. In this\nwork, we first revisit the SE block, and then present a detailed empirical\nstudy of the relationship between global context and attention distribution,\nbased on which we propose a simple yet effective module, called Linear Context\nTransform (LCT) block. We divide all channels into different groups and\nnormalize the globally aggregated context features within each channel group,\nreducing the disturbance from irrelevant channels. Through linear transform of\nthe normalized context features, we model global context for each channel\nindependently. The LCT block is extremely lightweight and easy to be plugged\ninto different backbone models while with negligible parameters and\ncomputational burden increase. Extensive experiments show that the LCT block\noutperforms the SE block in image classification task on the ImageNet and\nobject detection/segmentation on the COCO dataset with different backbone\nmodels. Moreover, LCT yields consistent performance gains over existing\nstate-of-the-art detection architectures, e.g., 1.5$\\sim$1.7% AP$^{bbox}$ and\n1.0$\\sim$1.2% AP$^{mask}$ improvements on the COCO benchmark, irrespective of\ndifferent baseline models of varied capacities. We hope our simple yet\neffective approach will shed some light on future research of attention-based\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 12:31:28 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 10:57:33 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Ruan", "Dongsheng", ""], ["Wen", "Jun", ""], ["Zheng", "Nenggan", ""], ["Zheng", "Min", ""]]}, {"id": "1909.03835", "submitter": "Haochuan Lu", "authors": "Haochuan Lu and Huanlin Xu and Nana Liu and Yangfan Zhou and Xin Wang", "title": "Data Sanity Check for Deep Learning Systems via Learnt Assertions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliability is a critical consideration to DL-based systems. But the\nstatistical nature of DL makes it quite vulnerable to invalid inputs, i.e.,\nthose cases that are not considered in the training phase of a DL model. This\npaper proposes to perform data sanity check to identify invalid inputs, so as\nto enhance the reliability of DL-based systems. We design and implement a tool\nto detect behavior deviation of a DL model when processing an input case. This\ntool extracts the data flow footprints and conducts an assertion-based\nvalidation mechanism. The assertions are built automatically, which are\nspecifically-tailored for DL model data flow analysis. Our experiments\nconducted with real-world scenarios demonstrate that such an assertion-based\ndata sanity check mechanism is effective in identifying invalid input cases.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 10:15:21 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 11:47:40 GMT"}, {"version": "v3", "created": "Sat, 28 Sep 2019 09:55:00 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Lu", "Haochuan", ""], ["Xu", "Huanlin", ""], ["Liu", "Nana", ""], ["Zhou", "Yangfan", ""], ["Wang", "Xin", ""]]}, {"id": "1909.03837", "submitter": "Ji Wang", "authors": "Ji Wang, Qi Jing, Jianbo Gao", "title": "SEdroid: A Robust Android Malware Detector using Selective Ensemble\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the dramatic increase of Android malware and low efficiency of manual\ncheck process, deep learning methods started to be an auxiliary means for\nAndroid malware detection these years. However, these models are highly\ndependent on the quality of datasets, and perform unsatisfactory results when\nthe quality of training data is not good enough. In the real world, the quality\nof datasets without manually check cannot be guaranteed, even Google Play may\ncontain malicious applications, which will cause the trained model failure. To\naddress the challenge, we propose a robust Android malware detection approach\nbased on selective ensemble learning, trying to provide an effective solution\nnot that limited to the quality of datasets. The proposed model utilizes\ngenetic algorithm to help find the best combination of the component learners\nand improve robustness of the model. Our results show that the proposed\napproach achieves a more robust performance than other approaches in the same\narea.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 08:59:35 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Ji", ""], ["Jing", "Qi", ""], ["Gao", "Jianbo", ""]]}, {"id": "1909.03848", "submitter": "Zvezdin Besarabov", "authors": "Zvezdin Besarabov and Todor Kolev", "title": "Distributed creation of Machine learning agents for Blockchain analysis", "comments": "arXiv admin note: text overlap with arXiv:1810.06696", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating efficient deep neural networks involves repetitive manual\noptimization of the topology and the hyperparameters. This human intervention\nsignificantly inhibits the process. Recent publications propose various Neural\nArchitecture Search (NAS) algorithms that automate this work. We have applied a\ncustomized NAS algorithm with network morphism and Bayesian optimization to the\nproblem of cryptocurrency predictions, where it achieved results on par with\nour best manually designed models. This is consistent with the findings of\nother teams, while several known experiments suggest that given enough\ncomputing power, NAS algorithms can surpass state-of-the-art neural network\nmodels designed by humans. In this paper, we propose a blockchain network\nprotocol that incentivises independent computing nodes to run NAS algorithms\nand compete in finding better neural network models for a particular task. If\nimplemented, such network can be an autonomous and self-improving source of\nmachine learning models, significantly boosting and democratizing the access to\nAI capabilities for many industries.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 16:52:03 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Besarabov", "Zvezdin", ""], ["Kolev", "Todor", ""]]}, {"id": "1909.03862", "submitter": "Yinhe Zheng Dr.", "authors": "Yinhe Zheng, Guanyi Chen, Minlie Huang", "title": "Out-of-domain Detection for Natural Language Understanding in Dialog\n  Systems", "comments": "Accepted by TALSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Understanding (NLU) is a vital component of dialogue\nsystems, and its ability to detect Out-of-Domain (OOD) inputs is critical in\npractical applications, since the acceptance of the OOD input that is\nunsupported by the current system may lead to catastrophic failure. However,\nmost existing OOD detection methods rely heavily on manually labeled OOD\nsamples and cannot take full advantage of unlabeled data. This limits the\nfeasibility of these models in practical applications.\n  In this paper, we propose a novel model to generate high-quality pseudo OOD\nsamples that are akin to IN-Domain (IND) input utterances, and thereby improves\nthe performance of OOD detection. To this end, an autoencoder is trained to map\nan input utterance into a latent code. and the codes of IND and OOD samples are\ntrained to be indistinguishable by utilizing a generative adversarial network.\nTo provide more supervision signals, an auxiliary classifier is introduced to\nregularize the generated OOD samples to have indistinguishable intent labels.\nExperiments show that these pseudo OOD samples generated by our model can be\nused to effectively improve OOD detection in NLU. Besides, we also demonstrate\nthat the effectiveness of these pseudo OOD data can be further improved by\nefficiently utilizing unlabeled data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 13:49:10 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 02:50:03 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 01:58:50 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Zheng", "Yinhe", ""], ["Chen", "Guanyi", ""], ["Huang", "Minlie", ""]]}, {"id": "1909.03868", "submitter": "Florian K\\\"opf", "authors": "Florian K\\\"opf, Alexander Nitsch, Michael Flad and S\\\"oren Hohmann", "title": "Partner Approximating Learners (PAL): Simulation-Accelerated Learning\n  with Explicit Partner Modeling in Multi-Agent Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed cooperative-competitive control scenarios such as human-machine\ninteraction with individual goals of the interacting partners are very\nchallenging for reinforcement learning agents. In order to contribute towards\nintuitive human-machine collaboration, we focus on problems in the continuous\nstate and control domain where no explicit communication is considered and the\nagents do not know the others' goals or control laws but only sense their\ncontrol inputs retrospectively. Our proposed framework combines a learned\npartner model based on online data with a reinforcement learning agent that is\ntrained in a simulated environment including the partner model. Thus, we\novercome drawbacks of independent learners and, in addition, benefit from a\nreduced amount of real world data required for reinforcement learning which is\nvital in the human-machine context. We finally analyze an example that\ndemonstrates the merits of our proposed framework which learns fast due to the\nsimulated environment and adapts to the continuously changing partner due to\nthe partner approximation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 13:58:15 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 09:41:21 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 17:17:32 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["K\u00f6pf", "Florian", ""], ["Nitsch", "Alexander", ""], ["Flad", "Michael", ""], ["Hohmann", "S\u00f6ren", ""]]}, {"id": "1909.03879", "submitter": "Mingqing Xiao", "authors": "Mingqing Xiao, Adam Kortylewski, Ruihai Wu, Siyuan Qiao, Wei Shen,\n  Alan Yuille", "title": "TDAPNet: Prototype Network with Recurrent Top-Down Attention for Robust\n  Object Classification under Partial Occlusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite deep convolutional neural networks' great success in object\nclassification, it suffers from severe generalization performance drop under\nocclusion due to the inconsistency between training and testing data. Because\nof the large variance of occluders, our goal is a model trained on\nocclusion-free data while generalizable to occlusion conditions. In this work,\nwe integrate prototypes, partial matching and top-down attention regulation\ninto deep neural networks to realize robust object classification under\nocclusion. We first introduce prototype learning as its regularization\nencourages compact data clusters, which enables better generalization ability\nunder inconsistent conditions. Then, attention map at intermediate layer based\non feature dictionary and activation scale is estimated for partial matching,\nwhich sifts irrelevant information out when comparing features with prototypes.\nFurther, inspired by neuroscience research that reveals the important role of\nfeedback connection for object recognition under occlusion, a top-down feedback\nattention regulation is introduced into convolution layers, purposefully\nreducing the contamination by occlusion during feature extraction stage. Our\nexperiment results on partially occluded MNIST and vehicles from the PASCAL3D+\ndataset demonstrate that the proposed network significantly improves the\nrobustness of current deep neural networks under occlusion. Our code will be\nreleased.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:17:59 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 06:57:01 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Xiao", "Mingqing", ""], ["Kortylewski", "Adam", ""], ["Wu", "Ruihai", ""], ["Qiao", "Siyuan", ""], ["Shen", "Wei", ""], ["Yuille", "Alan", ""]]}, {"id": "1909.03881", "submitter": "Sahil Garg", "authors": "Sahil Garg, Aram Galstyan, Greg Ver Steeg, Guillermo Cecchi", "title": "Nearly-Unsupervised Hashcode Representations for Relation Extraction", "comments": "Proceedings of EMNLP-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, kernelized locality sensitive hashcodes have been successfully\nemployed as representations of natural language text, especially showing high\nrelevance to biomedical relation extraction tasks. In this paper, we propose to\noptimize the hashcode representations in a nearly unsupervised manner, in which\nwe only use data points, but not their class labels, for learning. The\noptimized hashcode representations are then fed to a supervised classifier\nfollowing the prior work. This nearly unsupervised approach allows fine-grained\noptimization of each hash function, which is particularly suitable for building\nhashcode representations generalizing from a training set to a test set. We\nempirically evaluate the proposed approach for biomedical relation extraction\ntasks, obtaining significant accuracy improvements w.r.t. state-of-the-art\nsupervised and semi-supervised approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:20:05 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Garg", "Sahil", ""], ["Galstyan", "Aram", ""], ["Steeg", "Greg Ver", ""], ["Cecchi", "Guillermo", ""]]}, {"id": "1909.03889", "submitter": "Guangcan Liu", "authors": "Guangcan Liu, Wayne Zhang", "title": "Recovery of Future Data via Convolution Nuclear Norm Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of time series forecasting (TSF) from the\nperspective of compressed sensing. First of all, we convert TSF into a more\ninclusive problem called tensor completion with arbitrary sampling (TCAS),\nwhich is to restore a tensor from a subset of its entries sampled in an\narbitrary manner. While it is known that, in the framework of Tucker\nlow-rankness, it is theoretically impossible to identify the target tensor\nbased on some arbitrarily selected entries, in this work we shall show that\nTCAS is indeed tackleable in the light of a new concept called convolutional\nlow-rankness, which is a generalization of the well-known Fourier sparsity.\nThen we introduce a convex program termed Convolution Nuclear Norm Minimization\n(CNNM), and we prove that CNNM succeeds in solving TCAS as long as a sampling\ncondition--which depends on the convolution rank of the target tensor--is\nobeyed. Experiments on univariate time series, images and videos show\nencouraging results.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:52:22 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 08:00:23 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 08:04:08 GMT"}, {"version": "v4", "created": "Fri, 28 May 2021 08:12:17 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Liu", "Guangcan", ""], ["Zhang", "Wayne", ""]]}, {"id": "1909.03890", "submitter": "Sebastian P\\\"olsterl", "authors": "Sebastian P\\\"olsterl, Ignacio Sarasua, Benjam\\'in Guti\\'errez-Becker,\n  Christian Wachinger", "title": "A Wide and Deep Neural Network for Survival Analysis from Anatomical\n  Shape and Tabular Clinical Data", "comments": "Data and Machine Learning Advances with Multiple Views Workshop,\n  ECML-PKDD 2019", "journal-ref": null, "doi": "10.1007/978-3-030-43823-4_37", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a wide and deep neural network for prediction of progression\nfrom patients with mild cognitive impairment to Alzheimer's disease.\nInformation from anatomical shape and tabular clinical data (demographics,\nbiomarkers) are fused in a single neural network. The network is invariant to\nshape transformations and avoids the need to identify point correspondences\nbetween shapes. To account for right censored time-to-event data, i.e., when it\nis only known that a patient did not develop Alzheimer's disease up to a\nparticular time point, we employ a loss commonly used in survival analysis. Our\nnetwork is trained end-to-end to combine information from a patient's\nhippocampus shape and clinical biomarkers. Our experiments on data from the\nAlzheimer's Disease Neuroimaging Initiative demonstrate that our proposed model\nis able to learn a shape descriptor that augments clinical biomarkers and\noutperforms a deep neural network on shape alone and a linear model on common\nclinical biomarkers.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:37:47 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["P\u00f6lsterl", "Sebastian", ""], ["Sarasua", "Ignacio", ""], ["Guti\u00e9rrez-Becker", "Benjam\u00edn", ""], ["Wachinger", "Christian", ""]]}, {"id": "1909.03891", "submitter": "Hamed Yazdanpanah", "authors": "Hamed Yazdanpanah", "title": "On Data-Selective Learning", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive filters are applied in several electronic and communication devices\nlike smartphones, advanced headphones, DSP chips, smart antenna, and\nteleconference systems. Also, they have application in many areas such as\nsystem identification, channel equalization, noise reduction, echo\ncancellation, interference cancellation, signal prediction, and stock market.\nTherefore, reducing the energy consumption of the adaptive filtering algorithms\nhas great importance, particularly in green technologies and in devices using\nbattery.\n  In this thesis, data-selective adaptive filters, in particular the\nset-membership (SM) adaptive filters, are the tools to reach the goal. There\nare well known SM adaptive filters in literature. This work introduces new\nalgorithms based on the classical ones in order to improve their performances\nand reduce the number of required arithmetic operations at the same time.\nTherefore, firstly, we analyze the robustness of the classical SM adaptive\nfiltering algorithms. Secondly, we extend the SM technique to trinion and\nquaternion systems. Thirdly, by combining SM filtering and partial-updating, we\nintroduce a new improved set-membership affine projection algorithm with\nconstrained step size to improve its stability behavior. Fourthly, we propose\nsome new least-mean-square (LMS) based and recursive least-squares based\nadaptive filtering algorithms with low computational complexity for sparse\nsystems. Finally, we derive some feature LMS algorithms to exploit the hidden\nsparsity in the parameters.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 00:04:46 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Yazdanpanah", "Hamed", ""]]}, {"id": "1909.03892", "submitter": "Donghoon Lee", "authors": "Donghoon Lee and Georgios B. Giannakis", "title": "A Variational Bayes Approach to Adaptive Radio Tomography", "comments": "submitted to IEEE Transactions on Signal Processing. arXiv admin\n  note: substantial text overlap with arXiv:1804.02084", "journal-ref": null, "doi": "10.1109/TSP.2020.3003130", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radio tomographic imaging (RTI) is an emerging technology for localization of\nphysical objects in a geographical area covered by wireless networks. With\nattenuation measurements collected at spatially distributed sensors, RTI\ncapitalizes on spatial loss fields (SLFs) measuring the absorption of radio\nfrequency waves at spatial locations along the propagation path. These SLFs can\nbe utilized for interference management in wireless communication networks,\nenvironmental monitoring, and survivor localization after natural disasters\nsuch as earthquakes. Key to the success of RTI is to accurately model shadowing\nas the weighted line integral of the SLF. To learn the SLF exhibiting\nstatistical heterogeneity induced by spatially diverse environments, the\npresent work develops a Bayesian framework entailing a piecewise homogeneous\nSLF with an underlying hidden Markov random field model. Utilizing variational\nBayes techniques, the novel approach yields efficient field estimators at\naffordable complexity. A data-adaptive sensor selection strategy is also\nintroduced to collect informative measurements for effective reconstruction of\nthe SLF. Numerical tests using synthetic and real datasets demonstrate the\ncapabilities of the proposed approach to radio tomography and channel-gain\nestimation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 21:32:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lee", "Donghoon", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1909.03894", "submitter": "Lev Utkin", "authors": "Lev V. Utkin, Mikhail V. Kots, Viacheslav S. Chukanov", "title": "Estimation of Personalized Heterogeneous Treatment Effects Using\n  Concatenation and Augmentation of Feature Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new meta-algorithm for estimating the conditional average treatment effects\nis proposed in the paper. The main idea underlying the algorithm is to consider\na new dataset consisting of feature vectors produced by means of concatenation\nof examples from control and treatment groups, which are close to each other.\nOutcomes of new data are defined as the difference between outcomes of the\ncorresponding examples comprising new feature vectors. The second idea is based\non the assumption that the number of controls is rather large and the control\noutcome function is precisely determined. This assumption allows us to augment\ntreatments by generating feature vectors which are closed to available\ntreatments. The outcome regression function constructed on the augmented set of\nconcatenated feature vectors can be viewed as an estimator of the conditional\naverage treatment effects. A simple modification of the Co-learner based on the\nrandom subspace method or the feature bagging is also proposed. Various\nnumerical simulation experiments illustrate the proposed algorithm and show its\noutperformance in comparison with the well-known T-learner and X-learner for\nseveral types of the control and treatment outcome functions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:43:30 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Utkin", "Lev V.", ""], ["Kots", "Mikhail V.", ""], ["Chukanov", "Viacheslav S.", ""]]}, {"id": "1909.03895", "submitter": "Sebastian Gomez-Gonzalez", "authors": "Sebastian Gomez-Gonzalez, Sergey Prokudin, Bernhard Scholkopf and Jan\n  Peters", "title": "Real Time Trajectory Prediction Using Deep Conditional Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data driven methods for time series forecasting that quantify uncertainty\nopen new important possibilities for robot tasks with hard real time\nconstraints, allowing the robot system to make decisions that trade off between\nreaction time and accuracy in the predictions. Despite the recent advances in\ndeep learning, it is still challenging to make long term accurate predictions\nwith the low latency required by real time robotic systems. In this paper, we\npropose a deep conditional generative model for trajectory prediction that is\nlearned from a data set of collected trajectories. Our method uses encoder and\ndecoder deep networks that maps complete or partial trajectories to a Gaussian\ndistributed latent space and back, allowing for fast inference of the future\nvalues of a trajectory given previous observations. The encoder and decoder\nnetworks are trained using stochastic gradient variational Bayes. In the\nexperiments, we show that our model provides more accurate long term\npredictions with a lower latency that popular models for trajectory forecasting\nlike recurrent neural networks or physical models based on differential\nequations. Finally, we test our proposed approach in a robot table tennis\nscenario to evaluate the performance of the proposed method in a robotic task\nwith hard real time constraints.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:46:16 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 11:37:50 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Gomez-Gonzalez", "Sebastian", ""], ["Prokudin", "Sergey", ""], ["Scholkopf", "Bernhard", ""], ["Peters", "Jan", ""]]}, {"id": "1909.03906", "submitter": "Kristopher De Asis", "authors": "Kristopher De Asis, Alan Chan, Silviu Pitis, Richard S. Sutton, Daniel\n  Graves", "title": "Fixed-Horizon Temporal Difference Methods for Stable Reinforcement\n  Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore fixed-horizon temporal difference (TD) methods, reinforcement\nlearning algorithms for a new kind of value function that predicts the sum of\nrewards over a $\\textit{fixed}$ number of future time steps. To learn the value\nfunction for horizon $h$, these algorithms bootstrap from the value function\nfor horizon $h-1$, or some shorter horizon. Because no value function\nbootstraps from itself, fixed-horizon methods are immune to the stability\nproblems that plague other off-policy TD methods using function approximation\n(also known as \"the deadly triad\"). Although fixed-horizon methods require the\nstorage of additional value functions, this gives the agent additional\npredictive power, while the added complexity can be substantially reduced via\nparallel updates, shared weights, and $n$-step bootstrapping. We show how to\nuse fixed-horizon value functions to solve reinforcement learning problems\ncompetitively with methods such as Q-learning that learn conventional value\nfunctions. We also prove convergence of fixed-horizon temporal difference\nmethods with linear and general function approximation. Taken together, our\nresults establish fixed-horizon TD methods as a viable new way of avoiding the\nstability problems of the deadly triad.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 14:57:42 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 04:54:49 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["De Asis", "Kristopher", ""], ["Chan", "Alan", ""], ["Pitis", "Silviu", ""], ["Sutton", "Richard S.", ""], ["Graves", "Daniel", ""]]}, {"id": "1909.03935", "submitter": "Dingfan Chen", "authors": "Dingfan Chen, Ning Yu, Yang Zhang, Mario Fritz", "title": "GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative\n  Models", "comments": "CCS 2020, 20 pages", "journal-ref": "Proceedings of the 2020 ACM SIGSAC Conference on Computer and\n  Communications Security (CCS)", "doi": "10.1145/3372297.3417238", "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved overwhelming success, spanning from discriminative\nmodels to generative models. In particular, deep generative models have\nfacilitated a new level of performance in a myriad of areas, ranging from media\nmanipulation to sanitized dataset generation. Despite the great success, the\npotential risks of privacy breach caused by generative models have not been\nanalyzed systematically. In this paper, we focus on membership inference attack\nagainst deep generative models that reveals information about the training data\nused for victim models. Specifically, we present the first taxonomy of\nmembership inference attacks, encompassing not only existing attacks but also\nour novel ones. In addition, we propose the first generic attack model that can\nbe instantiated in a large range of settings and is applicable to various kinds\nof deep generative models. Moreover, we provide a theoretically grounded attack\ncalibration technique, which consistently boosts the attack performance in all\ncases, across different attack settings, data modalities, and training\nconfigurations. We complement the systematic analysis of attack performance by\na comprehensive experimental study, that investigates the effectiveness of\nvarious attacks w.r.t. model type and training configurations, over three\ndiverse application scenarios (i.e., images, medical data, and location data).\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 15:34:07 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 19:31:24 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 18:11:05 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chen", "Dingfan", ""], ["Yu", "Ning", ""], ["Zhang", "Yang", ""], ["Fritz", "Mario", ""]]}, {"id": "1909.03939", "submitter": "Qingpeng Cai", "authors": "Qingpeng Cai, Ling Pan, Pingzhong Tang", "title": "Deterministic Value-Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms such as the deep deterministic policy\ngradient algorithm (DDPG) has been widely used in continuous control tasks.\nHowever, the model-free DDPG algorithm suffers from high sample complexity. In\nthis paper we consider the deterministic value gradients to improve the sample\nefficiency of deep reinforcement learning algorithms. Previous works consider\ndeterministic value gradients with the finite horizon, but it is too myopic\ncompared with infinite horizon. We firstly give a theoretical guarantee of the\nexistence of the value gradients in this infinite setting. Based on this\ntheoretical guarantee, we propose a class of the deterministic value gradient\nalgorithm (DVG) with infinite horizon, and different rollout steps of the\nanalytical gradients by the learned model trade off between the variance of the\nvalue gradients and the model bias. Furthermore, to better combine the\nmodel-based deterministic value gradient estimators with the model-free\ndeterministic policy gradient estimator, we propose the deterministic\nvalue-policy gradient (DVPG) algorithm. We finally conduct extensive\nexperiments comparing DVPG with state-of-the-art methods on several standard\ncontinuous control benchmarks. Results demonstrate that DVPG substantially\noutperforms other baselines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 15:37:04 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 11:58:48 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Cai", "Qingpeng", ""], ["Pan", "Ling", ""], ["Tang", "Pingzhong", ""]]}, {"id": "1909.03947", "submitter": "Gabriel Laberge", "authors": "G. Laberge and S. Shirzad and P. Diehl and H. Kaiser and S. Prudhomme\n  and A. Lemoine", "title": "Scheduling optimization of parallel linear algebra algorithms using\n  Supervised Learning", "comments": "Accepted at HPCML19", "journal-ref": null, "doi": "10.1109/MLHPC49564.2019.00009", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear algebra algorithms are used widely in a variety of domains, e.g\nmachine learning, numerical physics and video games graphics. For all these\napplications, loop-level parallelism is required to achieve high performance.\nHowever, finding the optimal way to schedule the workload between threads is a\nnon-trivial problem because it depends on the structure of the algorithm being\nparallelized and the hardware the executable is run on. In the realm of\nAsynchronous Many Task runtime systems, a key aspect of the scheduling problem\nis predicting the proper chunk-size, where the chunk-size is defined as the\nnumber of iterations of a for-loop assigned to a thread as one task. In this\npaper, we study the applications of supervised learning models to predict the\nchunk-size which yields maximum performance on multiple parallel linear algebra\noperations using the HPX backend of Blaze's linear algebra library. More\nprecisely, we generate our training and tests sets by measuring performance of\nthe application with different chunk-sizes for multiple linear algebra\noperations; vector-addition, matrix-vector-multiplication, matrix-matrix\naddition and matrix-matrix-multiplication. We compare the use of logistic\nregression, neural networks and decision trees with a newly developed decision\ntree based model in order to predict the optimal value for chunk-size. Our\nresults show that classical decision trees and our custom decision tree model\nare able to forecast a chunk-size which results in good performance for the\nlinear algebra operations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 15:54:35 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 19:10:27 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Laberge", "G.", ""], ["Shirzad", "S.", ""], ["Diehl", "P.", ""], ["Kaiser", "H.", ""], ["Prudhomme", "S.", ""], ["Lemoine", "A.", ""]]}, {"id": "1909.03951", "submitter": "Vikrant Singhal", "authors": "Gautam Kamath, Or Sheffet, Vikrant Singhal, Jonathan Ullman", "title": "Differentially Private Algorithms for Learning Mixtures of Separated\n  Gaussians", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the parameters of Gaussian mixture models is a fundamental and\nwidely studied problem with numerous applications. In this work, we give new\nalgorithms for learning the parameters of a high-dimensional, well separated,\nGaussian mixture model subject to the strong constraint of differential\nprivacy. In particular, we give a differentially private analogue of the\nalgorithm of Achlioptas and McSherry. Our algorithm has two key properties not\nachieved by prior work: (1) The algorithm's sample complexity matches that of\nthe corresponding non-private algorithm up to lower order terms in a wide range\nof parameters. (2) The algorithm does not require strong a priori bounds on the\nparameters of the mixture components.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 15:58:52 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 21:48:40 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Kamath", "Gautam", ""], ["Sheffet", "Or", ""], ["Singhal", "Vikrant", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1909.03953", "submitter": "Bernhard Gahr", "authors": "Bernhard Gahr, Shu Liu, Kevin Koch, Filipe Barata, Andr\\'e Dahlinger,\n  Benjamin Ryder, Elgar Fleisch, Felix Wortmann", "title": "Driver Identification via the Steering Wheel", "comments": "10 pages, 16 figures, 6 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driver identification has emerged as a vital research field, where both\npractitioners and researchers investigate the potential of driver\nidentification to enable a personalized driving experience. Within recent\nyears, a selection of studies have reported that individuals could be perfectly\nidentified based on their driving behavior under controlled conditions.\nHowever, research investigating the potential of driver identification under\nnaturalistic conditions claim accuracies only marginally higher than random\nguess. The paper at hand provides a comprehensive summary of the recent work,\nhighlighting the main discrepancies in the design of the machine learning\napproaches, primarily the window length parameter that was considered. Key\nfindings further indicate that the longitudinal vehicle control information is\nparticularly useful for driver identification, leaving the research gap on the\nextent to which the lateral vehicle control can be used for reliable\nidentification. Building upon existing work, we provide a novel approach for\nthe design of the window length parameter that provides evidence that reliable\ndriver identification can be achieved with data limited to the steering wheel\nonly. The results and insights in this paper are based on data collected from\nthe largest naturalistic driving study conducted in this field. Overall, a\nneural network based on GRUs was found to provide better identification\nperformance than traditional methods, increasing the prediction accuracy from\nunder 15\\% to over 65\\% for 15 drivers. When leveraging the full field study\ndataset, comprising 72 drivers, the accuracy of identification prediction of\nthe approach improved a random guess approach by a factor of 25.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:00:50 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gahr", "Bernhard", ""], ["Liu", "Shu", ""], ["Koch", "Kevin", ""], ["Barata", "Filipe", ""], ["Dahlinger", "Andr\u00e9", ""], ["Ryder", "Benjamin", ""], ["Fleisch", "Elgar", ""], ["Wortmann", "Felix", ""]]}, {"id": "1909.03965", "submitter": "Hanna Silen", "authors": "Rob Clark, Hanna Silen, Tom Kenter, Ralph Leith", "title": "Evaluating Long-form Text-to-Speech: Comparing the Ratings of Sentences\n  and Paragraphs", "comments": "Accepted for The 10th ISCA Speech Synthesis Workshop (SSW10), 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-to-speech systems are typically evaluated on single sentences. When\nlong-form content, such as data consisting of full paragraphs or dialogues is\nconsidered, evaluating sentences in isolation is not always appropriate as the\ncontext in which the sentences are synthesized is missing. In this paper, we\ninvestigate three different ways of evaluating the naturalness of long-form\ntext-to-speech synthesis. We compare the results obtained from evaluating\nsentences in isolation, evaluating whole paragraphs of speech, and presenting a\nselection of speech or text as context and evaluating the subsequent speech. We\nfind that, even though these three evaluations are based upon the same\nmaterial, the outcomes differ per setting, and moreover that these outcomes do\nnot necessarily correlate with each other. We show that our findings are\nconsistent between a single speaker setting of read paragraphs and a\ntwo-speaker dialogue scenario. We conclude that to evaluate the quality of\nlong-form speech, the traditional way of evaluating sentences in isolation does\nnot suffice, and that multiple evaluations are required.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:13:20 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Clark", "Rob", ""], ["Silen", "Hanna", ""], ["Kenter", "Tom", ""], ["Leith", "Ralph", ""]]}, {"id": "1909.03974", "submitter": "Kiran Reddy M", "authors": "M Kiran Reddy, K Sreenivasa Rao", "title": "DNN-based cross-lingual voice conversion using Bottleneck Features", "comments": null, "journal-ref": null, "doi": "10.1007/s11063-019-10149-y", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual voice conversion (CLVC) is a quite challenging task since the\nsource and target speakers speak different languages. This paper proposes a\nCLVC framework based on bottleneck features and deep neural network (DNN). In\nthe proposed method, the bottleneck features extracted from a deep auto-encoder\n(DAE) are used to represent speaker-independent features of speech signals from\ndifferent languages. A DNN model is trained to learn the mapping between\nbottleneck features and the corresponding spectral features of the target\nspeaker. The proposed method can capture speaker-specific characteristics of a\ntarget speaker, and hence requires no speech data from source speaker during\ntraining. The performance of the proposed method is evaluated using data from\nthree Indian languages: Telugu, Tamil and Malayalam. The experimental results\nshow that the proposed method outperforms the baseline Gaussian mixture model\n(GMM)-based CLVC approach.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:35:55 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 04:46:07 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Reddy", "M Kiran", ""], ["Rao", "K Sreenivasa", ""]]}, {"id": "1909.03977", "submitter": "Ulrich A\\\"ivodji", "authors": "Ulrich A\\\"ivodji, Julien Ferry, S\\'ebastien Gambs, Marie-Jos\\'e\n  Huguet, Mohamed Siala", "title": "Learning Fair Rule Lists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the use of black-box models becomes ubiquitous in high stake\ndecision-making systems, demands for fair and interpretable models are\nincreasing. While it has been shown that interpretable models can be as\naccurate as black-box models in several critical domains, existing fair\nclassification techniques that are interpretable by design often display poor\naccuracy/fairness tradeoffs in comparison with their non-interpretable\ncounterparts. In this paper, we propose FairCORELS, a fair classification\ntechnique interpretable by design, whose objective is to learn fair rule lists.\nOur solution is a multi-objective variant of CORELS, a branch-and-bound\nalgorithm to learn rule lists, that supports several statistical notions of\nfairness. Examples of such measures include statistical parity, equal\nopportunity and equalized odds. The empirical evaluation of FairCORELS on\nreal-world datasets demonstrates that it outperforms state-of-the-art fair\nclassification techniques that are interpretable by design while being\ncompetitive with non-interpretable ones.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:37:14 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 01:57:23 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["A\u00efvodji", "Ulrich", ""], ["Ferry", "Julien", ""], ["Gambs", "S\u00e9bastien", ""], ["Huguet", "Marie-Jos\u00e9", ""], ["Siala", "Mohamed", ""]]}, {"id": "1909.03978", "submitter": "Saavan Patel", "authors": "Saavan Patel and Sayeef Salahuddin", "title": "Combining Learned Representations for Combinatorial Optimization", "comments": "Submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to combine Restricted Boltzmann Machines (RBMs)\nthat can be used to solve combinatorial optimization problems. This allows\nsynthesis of larger models from smaller RBMs that have been pretrained, thus\neffectively bypassing the problem of learning in large RBMs, and creating a\nsystem able to model a large, complex multi-modal space. We validate this\napproach by using learned representations to create ``invertible boolean\nlogic'', where we can use Markov chain Monte Carlo (MCMC) approaches to find\nthe solution to large scale boolean satisfiability problems and show viability\ntowards other combinatorial optimization problems. Using this method, we are\nable to solve 64 bit addition based problems, as well as factorize 16 bit\nnumbers. We find that these combined representations can provide a more\naccurate result for the same sample size as compared to a fully trained model.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:38:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Patel", "Saavan", ""], ["Salahuddin", "Sayeef", ""]]}, {"id": "1909.03980", "submitter": "Damian Campo", "authors": "Damian Campo, Vahid Bastani, Lucio Marcenaro, Carlo Regazzoni", "title": "Incremental learning of environment interactive structures from\n  trajectories of individuals", "comments": null, "journal-ref": "2016 19th International Conference on Information Fusion (FUSION)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel method for estimating the influence that unknown\nstatic objects might have over mobile agents. Since the motion of agents can be\naffected by the presence of fixed objects, it is possible use the information\nabout trajectories deviations to infer the presence of obstacles and estimate\nthe forces involved in a scene. Artificial neural networks are used to estimate\na non-parametric function related to the velocity field influencing moving\nagents. The proposed method is able to incrementally learn the velocity fields\ndue to external static objects within the monitored environment. It determines\nwhether an object has a repulsive or an attractive influence and provides an\nestimation of its position and size. As stationarity is assumed, i.e.,\ntime-invariance of force fields, learned observation models can be used as\nprior knowledge for estimating hierarchically the properties of new objects in\na scene.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:39:08 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Campo", "Damian", ""], ["Bastani", "Vahid", ""], ["Marcenaro", "Lucio", ""], ["Regazzoni", "Carlo", ""]]}, {"id": "1909.03984", "submitter": "Alberto Maria Metelli", "authors": "Alberto Maria Metelli, Guglielmo Manneschi, Marcello Restelli", "title": "Policy Space Identification in Configurable Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying the policy space of a learning agent,\nhaving access to a set of demonstrations generated by its optimal policy. We\nintroduce an approach based on statistical testing to identify the set of\npolicy parameters the agent can control, within a larger parametric policy\nspace. After presenting two identification rules (combinatorial and\nsimplified), applicable under different assumptions on the policy space, we\nprovide a probabilistic analysis of the simplified one in the case of linear\npolicies belonging to the exponential family. To improve the performance of our\nidentification rules, we frame the problem in the recently introduced framework\nof the Configurable Markov Decision Processes, exploiting the opportunity of\nconfiguring the environment to induce the agent revealing which parameters it\ncan control. Finally, we provide an empirical evaluation, on both discrete and\ncontinuous domains, to prove the effectiveness of our identification rules.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 16:47:27 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Metelli", "Alberto Maria", ""], ["Manneschi", "Guglielmo", ""], ["Restelli", "Marcello", ""]]}, {"id": "1909.03991", "submitter": "Changlin Wan", "authors": "Changlin Wan, Wennan Chang, Tong Zhao, Mengya Li, Sha Cao, Chi Zhang", "title": "Fast And Efficient Boolean Matrix Factorization By Geometric\n  Segmentation", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean matrix has been used to represent digital information in many fields,\nincluding bank transaction, crime records, natural language processing,\nprotein-protein interaction, etc. Boolean matrix factorization (BMF) aims to\nfind an approximation of a binary matrix as the Boolean product of two low rank\nBoolean matrices, which could generate vast amount of information for the\npatterns of relationships between the features and samples. Inspired by binary\nmatrix permutation theories and geometric segmentation, we developed a fast and\nefficient BMF approach called MEBF (Median Expansion for Boolean\nFactorization). Overall, MEBF adopted a heuristic approach to locate binary\npatterns presented as submatrices that are dense in 1's. At each iteration,\nMEBF permutates the rows and columns such that the permutated matrix is\napproximately Upper Triangular-Like (UTL) with so-called Simultaneous\nConsecutive-ones Property (SC1P). The largest submatrix dense in 1 would lies\non the upper triangular area of the permutated matrix, and its location was\ndetermined based on a geometric segmentation of a triangular. We compared MEBF\nwith other state of the art approaches on data scenarios with different\nsparsity and noise levels. MEBF demonstrated superior performances in lower\nreconstruction error, and higher computational efficiency, as well as more\naccurate sparse patterns than popular methods such as ASSO, PANDA and MP. We\ndemonstrated the application of MEBF on both binary and non-binary data sets,\nand revealed its further potential in knowledge retrieving and data denoising.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:02:57 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 19:17:30 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Wan", "Changlin", ""], ["Chang", "Wennan", ""], ["Zhao", "Tong", ""], ["Li", "Mengya", ""], ["Cao", "Sha", ""], ["Zhang", "Chi", ""]]}, {"id": "1909.03999", "submitter": "Amit Livne", "authors": "Amit Livne, Moshe Unger, Bracha Shapira and Lior Rokach", "title": "Deep Context-Aware Recommender System Utilizing Sequential Latent\n  Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-aware recommender systems (CARSs) apply sensing and analysis of user\ncontext in order to provide personalized services. Adding context to a\nrecommendation model is challenging, since the addition of context may\nincreases both the dimensionality and sparsity of the model. Recent research\nhas shown that modeling contextual information as a latent vector may address\nthe sparsity and dimensionality challenges. We suggest a new latent modeling of\nsequential context by generating sequences of contextual information and\nreducing their contextual space to a compressed latent space.We train a long\nshort-term memory (LSTM) encoder-decoder network on sequences of contextual\ninformation and extract sequential latent context from the hidden layer of the\nnetwork in order to represent a compressed representation of sequential data.\nWe propose new context-aware recommendation models that extend the neural\ncollaborative filtering approach and learn nonlinear interactions between\nlatent features of users, items, and contexts which take into account the\nsequential latent context representation as part of the recommendation process.\nWe deployed our approach using two context-aware datasets with different\ncontext dimensions. Empirical analysis of our results validates that our\nproposed sequential latent context-aware model (SLCM), surpasses state of the\nart CARS models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:20:15 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 06:57:30 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Livne", "Amit", ""], ["Unger", "Moshe", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""]]}, {"id": "1909.04010", "submitter": "Damian Campo", "authors": "Damian Campo, Alejandro Betancourt, Lucio Marcenaro, Carlo Regazzoni", "title": "Static force field representation of environments based on agents\n  nonlinear motions", "comments": null, "journal-ref": "EURASIP Journal on Advances in Signal Processing, December 2017,\n  2017:13", "doi": "10.1186/s13634-017-0444-5", "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology that aims at the incremental representation\nof areas inside environments in terms of attractive forces. It is proposed a\nparametric representation of velocity fields ruling the dynamics of moving\nagents. It is assumed that attractive spots in the environment are responsible\nfor modifying the motion of agents. A switching model is used to describe near\nand far velocity fields, which in turn are used to learn attractive\ncharacteristics of environments. The effect of such areas is considered radial\nover all the scene. Based on the estimation of attractive areas, a map that\ndescribes their effects in terms of their localizations, ranges of action, and\nintensities is derived in an online way. Information of static attractive areas\nis added dynamically into a set of filters that describes possible interactions\nbetween moving agents and an environment. The proposed approach is first\nevaluated on synthetic data; posteriorly, the method is applied on real\ntrajectories coming from moving pedestrians in an indoor environment.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:46:16 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Campo", "Damian", ""], ["Betancourt", "Alejandro", ""], ["Marcenaro", "Lucio", ""], ["Regazzoni", "Carlo", ""]]}, {"id": "1909.04013", "submitter": "Maciej Koch-Janusz", "authors": "Vlad Pushkarov, Jonathan Efroni, Mykola Maksymenko and Maciej\n  Koch-Janusz", "title": "Training Deep Neural Networks by optimizing over nonlocal paths in\n  hyperparameter space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization is both a practical issue and an interesting\ntheoretical problem in training of deep architectures. Despite many recent\nadvances the most commonly used methods almost universally involve training\nmultiple and decoupled copies of the model, in effect sampling the\nhyperparameter space. We show that at a negligible additional computational\ncost, results can be improved by sampling nonlocal paths instead of points in\nhyperparameter space. To this end we interpret hyperparameters as controlling\nthe level of correlated noise in training, which can be mapped to an effective\ntemperature. The usually independent instances of the model are coupled and\nallowed to exchange their hyperparameters throughout the training using the\nwell established parallel tempering technique of statistical physics. Each\nsimulation corresponds then to a unique path, or history, in the joint\nhyperparameter/model-parameter space. We provide empirical tests of our method,\nin particular for dropout and learning rate optimization. We observed faster\ntraining and improved resistance to overfitting and showed a systematic\ndecrease in the absolute validation error, improving over benchmark results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:49:15 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Pushkarov", "Vlad", ""], ["Efroni", "Jonathan", ""], ["Maksymenko", "Mykola", ""], ["Koch-Janusz", "Maciej", ""]]}, {"id": "1909.04016", "submitter": "Justin Sybrandt", "authors": "Justin Sybrandt, Ruslan Shaydulin, Ilya Safro", "title": "Hypergraph Partitioning With Embeddings", "comments": null, "journal-ref": null, "doi": "10.1109/TKDE.2020.3017120", "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems in scientific computing, such as distributing large sparse matrix\noperations, have analogous formulations as hypergraph partitioning problems. A\nhypergraph is a generalization of a traditional graph wherein \"hyperedges\" may\nconnect any number of nodes. As a result, hypergraph partitioning is an NP-Hard\nproblem to both solve or approximate. State-of-the-art algorithms that solve\nthis problem follow the multilevel paradigm, which begins by iteratively\n\"coarsening\" the input hypergraph to smaller problem instances that share key\nstructural features. Once identifying an approximate problem that is small\nenough to be solved directly, that solution can be interpolated and refined to\nthe original problem. While this strategy represents an excellent trade off\nbetween quality and running time, it is sensitive to coarsening strategy. In\nthis work we propose using graph embeddings of the initial hypergraph in order\nto ensure that coarsened problem instances retrain key structural features. Our\napproach prioritizes coarsening within self-similar regions within the input\ngraph, and leads to significantly improved solution quality across a range of\nconsidered hypergraphs. Reproducibility: All source code, plots and\nexperimental data are available at https://sybrandt.com/2019/partition.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:55:23 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 13:18:07 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 15:05:52 GMT"}, {"version": "v4", "created": "Mon, 16 Mar 2020 16:36:23 GMT"}, {"version": "v5", "created": "Tue, 25 Aug 2020 21:02:16 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Sybrandt", "Justin", ""], ["Shaydulin", "Ruslan", ""], ["Safro", "Ilya", ""]]}, {"id": "1909.04019", "submitter": "Yang Li", "authors": "Yang Li and Jos\\'e M. F. Moura", "title": "Forecaster: A Graph Transformer for Forecasting Spatial and\n  Time-Dependent Data", "comments": null, "journal-ref": "in European Conference on Artificial Intelligence (ECAI), pp. 1293\n  - 1300, 2020", "doi": "10.3233/FAIA200231", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial and time-dependent data is of interest in many applications. This\ntask is difficult due to its complex spatial dependency, long-range temporal\ndependency, data non-stationarity, and data heterogeneity. To address these\nchallenges, we propose Forecaster, a graph Transformer architecture.\nSpecifically, we start by learning the structure of the graph that\nparsimoniously represents the spatial dependency between the data at different\nlocations. Based on the topology of the graph, we sparsify the Transformer to\naccount for the strength of spatial dependency, long-range temporal dependency,\ndata non-stationarity, and data heterogeneity. We evaluate Forecaster in the\nproblem of forecasting taxi ride-hailing demand and show that our proposed\narchitecture significantly outperforms the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:58:43 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 20:41:59 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 12:19:38 GMT"}, {"version": "v4", "created": "Tue, 14 Jan 2020 19:53:12 GMT"}, {"version": "v5", "created": "Fri, 21 Feb 2020 00:00:14 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Li", "Yang", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "1909.04021", "submitter": "Yosuke Shinya", "authors": "Yosuke Shinya, Edgar Simo-Serra, Taiji Suzuki", "title": "Understanding the Effects of Pre-Training for Object Detectors via\n  Eigenspectrum", "comments": "ICCV 2019 Workshop on Neural Architects (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ImageNet pre-training has been regarded as essential for training accurate\nobject detectors for a long time. Recently, it has been shown that object\ndetectors trained from randomly initialized weights can be on par with those\nfine-tuned from ImageNet pre-trained models. However, the effects of\npre-training and the differences caused by pre-training are still not fully\nunderstood. In this paper, we analyze the eigenspectrum dynamics of the\ncovariance matrix of each feature map in object detectors. Based on our\nanalysis on ResNet-50, Faster R-CNN with FPN, and Mask R-CNN, we show that\nobject detectors trained from ImageNet pre-trained models and those trained\nfrom scratch behave differently from each other even if both object detectors\nhave similar accuracy. Furthermore, we propose a method for automatically\ndetermining the widths (the numbers of channels) of object detectors based on\nthe eigenspectrum. We train Faster R-CNN with FPN from randomly initialized\nweights, and show that our method can reduce ~27% of the parameters of\nResNet-50 without increasing Multiply-Accumulate operations and losing\naccuracy. Our results indicate that we should develop more appropriate methods\nfor transferring knowledge from image classification to object detection (or\nother tasks).\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:59:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Shinya", "Yosuke", ""], ["Simo-Serra", "Edgar", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1909.04028", "submitter": "Matr Grenander", "authors": "Matt Grenander, Yue Dong, Jackie Chi Kit Cheung, Annie Louis", "title": "Countering the Effects of Lead Bias in News Summarization via\n  Multi-Stage Training and Auxiliary Losses", "comments": "5 pages, accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence position is a strong feature for news summarization, since the lead\noften (but not always) summarizes the key points of the article. In this paper,\nwe show that recent neural systems excessively exploit this trend, which\nalthough powerful for many inputs, is also detrimental when summarizing\ndocuments where important content should be extracted from later parts of the\narticle. We propose two techniques to make systems sensitive to the importance\nof content in different parts of the article. The first technique employs\n'unbiased' data; i.e., randomly shuffled sentences of the source document, to\npretrain the model. The second technique uses an auxiliary ROUGE-based loss\nthat encourages the model to distribute importance scores throughout a document\nby mimicking sentence-level ROUGE scores on the training data. We show that\nthese techniques significantly improve the performance of a competitive\nreinforcement learning based extractive system, with the auxiliary loss being\nmore powerful than pretraining.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 05:50:18 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Grenander", "Matt", ""], ["Dong", "Yue", ""], ["Cheung", "Jackie Chi Kit", ""], ["Louis", "Annie", ""]]}, {"id": "1909.04060", "submitter": "Alireza Vafaei Sadr", "authors": "Alireza Vafaei Sadr, Bruce A. Bassett and Martin Kunz", "title": "A Flexible Framework for Anomaly Detection via Dimensionality Reduction", "comments": "6 pages", "journal-ref": "Proceeding, 6th International Conference on Soft Computing &\n  Machine Intelligence (ISCMI), Johannesburg, South Africa, 2019, pp. 106-110", "doi": "10.1109/ISCMI47871.2019.9004400", "report-no": null, "categories": "cs.LG astro-ph.IM cs.AI stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is challenging, especially for large datasets in high\ndimensions. Here we explore a general anomaly detection framework based on\ndimensionality reduction and unsupervised clustering. We release DRAMA, a\ngeneral python package that implements the general framework with a wide range\nof built-in options. We test DRAMA on a wide variety of simulated and real\ndatasets, in up to 3000 dimensions, and find it robust and highly competitive\nwith commonly-used anomaly detection algorithms, especially in high dimensions.\nThe flexibility of the DRAMA framework allows for significant optimization once\nsome examples of anomalies are available, making it ideal for online anomaly\ndetection, active learning and highly unbalanced datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:00:12 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Sadr", "Alireza Vafaei", ""], ["Bassett", "Bruce A.", ""], ["Kunz", "Martin", ""]]}, {"id": "1909.04063", "submitter": "Thomas Barrett Dr", "authors": "Thomas D. Barrett, William R. Clements, Jakob N. Foerster, A. I.\n  Lvovsky", "title": "Exploratory Combinatorial Optimization with Reinforcement Learning", "comments": "In Proceedings of the 34th National Conference on Artificial\n  Intelligence, AAAI 2020", "journal-ref": "Proceedings of Thirty-fourth AAAI conference on artificial\n  intelligence, 3243-3250 (2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems can be reduced to combinatorial optimization on a\ngraph, where the subset or ordering of vertices that maximize some objective\nfunction must be found. With such tasks often NP-hard and analytically\nintractable, reinforcement learning (RL) has shown promise as a framework with\nwhich efficient heuristic methods to tackle these problems can be learned.\nPrevious works construct the solution subset incrementally, adding one element\nat a time, however, the irreversible nature of this approach prevents the agent\nfrom revising its earlier decisions, which may be necessary given the\ncomplexity of the optimization task. We instead propose that the agent should\nseek to continuously improve the solution by learning to explore at test time.\nOur approach of exploratory combinatorial optimization (ECO-DQN) is, in\nprinciple, applicable to any combinatorial problem that can be defined on a\ngraph. Experimentally, we show our method to produce state-of-the-art RL\nperformance on the Maximum Cut problem. Moreover, because ECO-DQN can start\nfrom any arbitrary configuration, it can be combined with other search methods\nto further improve performance, which we demonstrate using a simple random\nsearch.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:00:24 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 13:38:56 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Barrett", "Thomas D.", ""], ["Clements", "William R.", ""], ["Foerster", "Jakob N.", ""], ["Lvovsky", "A. I.", ""]]}, {"id": "1909.04068", "submitter": "Pratyush Maini", "authors": "Pratyush Maini, Eric Wong and J. Zico Kolter", "title": "Adversarial Robustness Against the Union of Multiple Perturbation Models", "comments": "ICML 2020 Final Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the susceptibility of deep learning systems to adversarial attacks,\nthere has been a great deal of work in developing (both empirically and\ncertifiably) robust classifiers. While most work has defended against a single\ntype of attack, recent work has looked at defending against multiple\nperturbation models using simple aggregations of multiple attacks. However,\nthese methods can be difficult to tune, and can easily result in imbalanced\ndegrees of robustness to individual perturbation models, resulting in a\nsub-optimal worst-case loss over the union. In this work, we develop a natural\ngeneralization of the standard PGD-based procedure to incorporate multiple\nperturbation models into a single attack, by taking the worst-case over all\nsteepest descent directions. This approach has the advantage of directly\nconverging upon a trade-off between different perturbation models which\nminimizes the worst-case performance over the union. With this approach, we are\nable to train standard architectures which are simultaneously robust against\n$\\ell_\\infty$, $\\ell_2$, and $\\ell_1$ attacks, outperforming past approaches on\nthe MNIST and CIFAR10 datasets and achieving adversarial accuracy of 47.0%\nagainst the union of ($\\ell_\\infty$, $\\ell_2$, $\\ell_1$) perturbations with\nradius = (0.03, 0.5, 12) on the latter, improving upon previous approaches\nwhich achieve 40.6% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:02:09 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 21:44:04 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Maini", "Pratyush", ""], ["Wong", "Eric", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1909.04078", "submitter": "Riccardo La Grassa", "authors": "Riccardo La Grassa, Ignazio Gallo, Alessandro Calefati, Dimitri\n  Ognibene", "title": "A Classification Methodology based on Subspace Graphs Learning", "comments": "8 pages, Dicta Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a design methodology for one-class classifiers\nusing an ensemble-of-classifiers approach. The objective is to select the best\nstructures created during the training phase using an ensemble of spanning\ntrees. It takes the best classifier, partitioning the area near a pattern into\n$\\gamma^{\\gamma-2}$ sub-spaces and combining all possible spanning trees that\ncan be created starting from $\\gamma$ nodes. The proposed method leverages on a\nsupervised classification methodology and the concept of minimum distance. We\nevaluate our approach on well-known benchmark datasets and results obtained\ndemonstrate that it achieves comparable and, in many cases, state-of-the-art\nresults. Moreover, it obtains good performance even with unbalanced datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:10:06 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["La Grassa", "Riccardo", ""], ["Gallo", "Ignazio", ""], ["Calefati", "Alessandro", ""], ["Ognibene", "Dimitri", ""]]}, {"id": "1909.04079", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Bindya Venkatesh, Prasanna Sattigeri,\n  Peer-Timo Bremer", "title": "Building Calibrated Deep Models via Uncertainty Matching with Auxiliary\n  Interval Predictors", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid adoption of deep learning in critical applications, the question\nof when and how much to trust these models often arises, which drives the need\nto quantify the inherent uncertainties. While identifying all sources that\naccount for the stochasticity of models is challenging, it is common to augment\npredictions with confidence intervals to convey the expected variations in a\nmodel's behavior. We require prediction intervals to be well-calibrated,\nreflect the true uncertainties, and to be sharp. However, existing techniques\nfor obtaining prediction intervals are known to produce unsatisfactory results\nin at least one of these criteria. To address this challenge, we develop a\nnovel approach for building calibrated estimators. More specifically, we use\nseparate models for prediction and interval estimation, and pose a bi-level\noptimization problem that allows the former to leverage estimates from the\nlatter through an \\textit{uncertainty matching} strategy. Using experiments in\nregression, time-series forecasting, and object localization, we show that our\napproach achieves significant improvements over existing uncertainty\nquantification methods, both in terms of model fidelity and calibration error.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:10:50 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 17:40:26 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Venkatesh", "Bindya", ""], ["Sattigeri", "Prasanna", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1909.04104", "submitter": "Zengming Shen", "authors": "Zengming Shen, Yifan Chen, S.Kevin Zhou, Bogdan Georgescu, Xuqi Liu,\n  Thomas S. Huang", "title": "Towards Learning a Self-inverse Network for Bidirectional Image-to-image\n  Translation", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The one-to-one mapping is necessary for many bidirectional image-to-image\ntranslation applications, such as MRI image synthesis as MRI images are unique\nto the patient. State-of-the-art approaches for image synthesis from domain X\nto domain Y learn a convolutional neural network that meticulously maps between\nthe domains. A different network is typically implemented to map along the\nopposite direction, from Y to X. In this paper, we explore the possibility of\nonly wielding one network for bi-directional image synthesis. In other words,\nsuch an autonomous learning network implements a self-inverse function. A\nself-inverse network shares several distinct advantages: only one network\ninstead of two, better generalization and more restricted parameter space. Most\nimportantly, a self-inverse function guarantees a one-to-one mapping, a\nproperty that cannot be guaranteed by earlier approaches that are not\nself-inverse. The experiments on three datasets show that, compared with the\nbaseline approaches that use two separate models for the image synthesis along\ntwo directions, our self-inverse network achieves better synthesis results in\nterms of standard metrics. Finally, our sensitivity analysis confirms the\nfeasibility of learning a self-inverse function for the bidirectional image\ntranslation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:56:30 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 20:46:02 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Shen", "Zengming", ""], ["Chen", "Yifan", ""], ["Zhou", "S. Kevin", ""], ["Georgescu", "Bogdan", ""], ["Liu", "Xuqi", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1909.04108", "submitter": "Kaiyang Cheng", "authors": "Kaiyang Cheng, Claudia Iriondo, Francesco Caliv\\'a, Justin Krogue,\n  Sharmila Majumdar, Valentina Pedoia", "title": "Adversarial Policy Gradient for Deep Learning Image Augmentation", "comments": "9 pages, 2 figures, MICCAI 2019, First two authors contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of semantic segmentation for masking and cropping input images has\nproven to be a significant aid in medical imaging classification tasks by\ndecreasing the noise and variance of the training dataset. However,\nimplementing this approach with classical methods is challenging: the cost of\nobtaining a dense segmentation is high, and the precise input area that is most\ncrucial to the classification task is difficult to determine a-priori. We\npropose a novel joint-training deep reinforcement learning framework for image\naugmentation. A segmentation network, weakly supervised with policy gradient\noptimization, acts as an agent, and outputs masks as actions given samples as\nstates, with the goal of maximizing reward signals from the classification\nnetwork. In this way, the segmentation network learns to mask unimportant\nimaging features. Our method, Adversarial Policy Gradient Augmentation (APGA),\nshows promising results on Stanford's MURA dataset and on a hip fracture\nclassification task with an increase in global accuracy of up to 7.33% and\nimproved performance over baseline methods in 9/10 tasks evaluated. We discuss\nthe broad applicability of our joint training strategy to a variety of medical\nimaging tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:04:21 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Cheng", "Kaiyang", ""], ["Iriondo", "Claudia", ""], ["Caliv\u00e1", "Francesco", ""], ["Krogue", "Justin", ""], ["Majumdar", "Sharmila", ""], ["Pedoia", "Valentina", ""]]}, {"id": "1909.04110", "submitter": "Zengming Shen", "authors": "Zengming Shen, S.Kevin Zhou, Yifan Chen, Bogdan Georgescu, Xuqi Liu,\n  Thomas S. Huang", "title": "One-to-one Mapping for Unpaired Image-to-image Translation", "comments": "Accepted by WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently image-to-image translation has attracted significant interests in\nthe literature, starting from the successful use of the generative adversarial\nnetwork (GAN), to the introduction of cyclic constraint, to extensions to\nmultiple domains. However, in existing approaches, there is no guarantee that\nthe mapping between two image domains is unique or one-to-one. Here we propose\na self-inverse network learning approach for unpaired image-to-image\ntranslation. Building on top of CycleGAN, we learn a self-inverse function by\nsimply augmenting the training samples by swapping inputs and outputs during\ntraining and with separated cycle consistency loss for each mapping direction.\nThe outcome of such learning is a proven one-to-one mapping function. Our\nextensive experiments on a variety of datasets, including cross-modal medical\nimage synthesis, object transfiguration, and semantic labeling, consistently\ndemonstrate clear improvement over the CycleGAN method both qualitatively and\nquantitatively. Especially our proposed method reaches the state-of-the-art\nresult on the cityscapes benchmark dataset for the label to photo unpaired\ndirectional image translation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:10:05 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 15:41:37 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 14:26:52 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 20:52:09 GMT"}, {"version": "v5", "created": "Sat, 12 Oct 2019 07:35:28 GMT"}, {"version": "v6", "created": "Wed, 15 Jan 2020 03:13:18 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Shen", "Zengming", ""], ["Zhou", "S. Kevin", ""], ["Chen", "Yifan", ""], ["Georgescu", "Bogdan", ""], ["Liu", "Xuqi", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1909.04115", "submitter": "Pierluca D'Oro", "authors": "Pierluca D'Oro, Alberto Maria Metelli, Andrea Tirinzoni, Matteo\n  Papini, Marcello Restelli", "title": "Gradient-Aware Model-based Policy Search", "comments": null, "journal-ref": null, "doi": "10.1609/aaai.v34i04.5791", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional model-based reinforcement learning approaches learn a model of\nthe environment dynamics without explicitly considering how it will be used by\nthe agent. In the presence of misspecified model classes, this can lead to poor\nestimates, as some relevant available information is ignored. In this paper, we\nintroduce a novel model-based policy search approach that exploits the\nknowledge of the current agent policy to learn an approximate transition model,\nfocusing on the portions of the environment that are most relevant for policy\nimprovement. We leverage a weighting scheme, derived from the minimization of\nthe error on the model-based policy gradient estimator, in order to define a\nsuitable objective function that is optimized for learning the approximate\ntransition model. Then, we integrate this procedure into a batch policy\nimprovement algorithm, named Gradient-Aware Model-based Policy Search (GAMPS),\nwhich iteratively learns a transition model and uses it, together with the\ncollected trajectories, to compute the new policy parameters. Finally, we\nempirically validate GAMPS on benchmark domains analyzing and discussing its\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:26:27 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 22:17:37 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["D'Oro", "Pierluca", ""], ["Metelli", "Alberto Maria", ""], ["Tirinzoni", "Andrea", ""], ["Papini", "Matteo", ""], ["Restelli", "Marcello", ""]]}, {"id": "1909.04120", "submitter": "Michael Glass", "authors": "Michael Glass, Alfio Gliozzo, Rishav Chakravarti, Anthony Ferritto,\n  Lin Pan, G P Shrivatsa Bhargav, Dinesh Garg, Avirup Sil", "title": "Span Selection Pre-training for Question Answering", "comments": "Accepted at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT (Bidirectional Encoder Representations from Transformers) and related\npre-trained Transformers have provided large gains across many language\nunderstanding tasks, achieving a new state-of-the-art (SOTA). BERT is\npre-trained on two auxiliary tasks: Masked Language Model and Next Sentence\nPrediction. In this paper we introduce a new pre-training task inspired by\nreading comprehension to better align the pre-training from memorization to\nunderstanding. Span Selection Pre-Training (SSPT) poses cloze-like training\ninstances, but rather than draw the answer from the model's parameters, it is\nselected from a relevant passage. We find significant and consistent\nimprovements over both BERT-BASE and BERT-LARGE on multiple reading\ncomprehension (MRC) datasets. Specifically, our proposed model has strong\nempirical evidence as it obtains SOTA results on Natural Questions, a new\nbenchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer\nprediction. We also show significant impact in HotpotQA, improving answer\nprediction F1 by 4 points and supporting fact prediction F1 by 1 point and\noutperforming the previous best system. Moreover, we show that our pre-training\napproach is particularly effective when training data is limited, improving the\nlearning curve by a large amount.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:32:31 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 18:18:04 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Glass", "Michael", ""], ["Gliozzo", "Alfio", ""], ["Chakravarti", "Rishav", ""], ["Ferritto", "Anthony", ""], ["Pan", "Lin", ""], ["Bhargav", "G P Shrivatsa", ""], ["Garg", "Dinesh", ""], ["Sil", "Avirup", ""]]}, {"id": "1909.04121", "submitter": "Andrey Kurenkov", "authors": "Andrey Kurenkov, Ajay Mandlekar, Roberto Martin-Martin, Silvio\n  Savarese, Animesh Garg", "title": "AC-Teach: A Bayesian Actor-Critic Method for Policy Learning with an\n  Ensemble of Suboptimal Teachers", "comments": "Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration mechanism used by a Deep Reinforcement Learning (RL) agent\nplays a key role in determining its sample efficiency. Thus, improving over\nrandom exploration is crucial to solve long-horizon tasks with sparse rewards.\nWe propose to leverage an ensemble of partial solutions as teachers that guide\nthe agent's exploration with action suggestions throughout training. While the\nsetup of learning with teachers has been previously studied, our proposed\napproach - Actor-Critic with Teacher Ensembles (AC-Teach) - is the first to\nwork with an ensemble of suboptimal teachers that may solve only part of the\nproblem or contradict other each other, forming a unified algorithmic solution\nthat is compatible with a broad range of teacher ensembles. AC-Teach leverages\na probabilistic representation of the expected outcome of the teachers' and\nstudent's actions to direct exploration, reduce dithering, and adapt to the\ndynamically changing quality of the learner. We evaluate a variant of AC-Teach\nthat guides the learning of a Bayesian DDPG agent on three tasks - path\nfollowing, robotic pick and place, and robotic cube sweeping using a hook - and\nshow that it improves largely on sampling efficiency over a set of baselines,\nboth for our target scenario of unconstrained suboptimal teachers and for\neasier setups with optimal or single teachers. Additional results and videos at\nhttps://sites.google.com/view/acteach/home.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:38:25 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 09:14:07 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 00:15:26 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Kurenkov", "Andrey", ""], ["Mandlekar", "Ajay", ""], ["Martin-Martin", "Roberto", ""], ["Savarese", "Silvio", ""], ["Garg", "Animesh", ""]]}, {"id": "1909.04126", "submitter": "Ang Li", "authors": "Ang Li, Jiayi Guo, Huanrui Yang, Flora D. Salim, Yiran Chen", "title": "DeepObfuscator: Obfuscating Intermediate Representations with\n  Privacy-Preserving Adversarial Learning on Smartphones", "comments": "This paper is to be published in IoTDI'21", "journal-ref": null, "doi": "10.1145/3450268.3453519", "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been widely applied in many computer vision applications,\nwith remarkable success. However, running deep learning models on mobile\ndevices is generally challenging due to the limitation of computing resources.\nA popular alternative is to use cloud services to run deep learning models to\nprocess raw data. This, however, imposes privacy risks. Some prior arts\nproposed sending the features extracted from raw data to the cloud.\nUnfortunately, these extracted features can still be exploited by attackers to\nrecover raw images and to infer embedded private attributes. In this paper, we\npropose an adversarial training framework, DeepObfuscator, which prevents the\nusage of the features for reconstruction of the raw images and inference of\nprivate attributes. This is done while retaining useful information for the\nintended cloud service. DeepObfuscator includes a learnable obfuscator that is\ndesigned to hide privacy-related sensitive information from the features by\nperforming our proposed adversarial training algorithm. The proposed algorithm\nis designed by simulating the game between an attacker who makes efforts to\nreconstruct raw image and infer private attributes from the extracted features\nand a defender who aims to protect user privacy. By deploying the trained\nobfuscator on the smartphone, features can be locally extracted and then sent\nto the cloud. Our experiments on CelebA and LFW datasets show that the quality\nof the reconstructed images from the obfuscated features of the raw image is\ndramatically decreased from 0.9458 to 0.3175 in terms of multi-scale structural\nsimilarity. The person in the reconstructed image, hence, becomes hardly to be\nre-identified. The classification accuracy of the inferred private attributes\nthat can be achieved by the attacker is significantly reduced to a\nrandom-guessing level.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:57:01 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 02:46:26 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Li", "Ang", ""], ["Guo", "Jiayi", ""], ["Yang", "Huanrui", ""], ["Salim", "Flora D.", ""], ["Chen", "Yiran", ""]]}, {"id": "1909.04131", "submitter": "Hristos Tyralis", "authors": "Hristos Tyralis, Georgia Papacharalampous, Andreas Langousis", "title": "Super ensemble learning for daily streamflow forecasting: Large-scale\n  demonstration and comparison with multiple machine learning algorithms", "comments": null, "journal-ref": "Neural Computing and Applications 33 (2021) 3053-3068", "doi": "10.1007/s00521-020-05172-3", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Daily streamflow forecasting through data-driven approaches is traditionally\nperformed using a single machine learning algorithm. Existing applications are\nmostly restricted to examination of few case studies, not allowing accurate\nassessment of the predictive performance of the algorithms involved. Here we\npropose super learning (a type of ensemble learning) by combining 10 machine\nlearning algorithms. We apply the proposed algorithm in one-step ahead\nforecasting mode. For the application, we exploit a big dataset consisting of\n10-year long time series of daily streamflow, precipitation and temperature\nfrom 511 basins. The super learner improves over the performance of the linear\nregression algorithm by 20.06%, outperforming the \"hard to beat in practice\"\nequal weight combiner. The latter improves over the performance of the linear\nregression algorithm by 19.21%. The best performing individual machine learning\nalgorithm is neural networks, which improves over the performance of the linear\nregression algorithm by 16.73%, followed by extremely randomized trees\n(16.40%), XGBoost (15.92%), loess (15.36%), random forests (12.75%), polyMARS\n(12.36%), MARS (4.74%), lasso (0.11%) and support vector regression (-0.45%).\nBased on the obtained large-scale results, we propose super learning for daily\nstreamflow forecasting.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 20:01:53 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 18:50:47 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Tyralis", "Hristos", ""], ["Papacharalampous", "Georgia", ""], ["Langousis", "Andreas", ""]]}, {"id": "1909.04134", "submitter": "Rahul Ramesh", "authors": "Arjun Manoharan, Rahul Ramesh, and Balaraman Ravindran", "title": "Option Encoder: A Framework for Discovering a Policy Basis in\n  Reinforcement Learning", "comments": "ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Option discovery and skill acquisition frameworks are integral to the\nfunctioning of a Hierarchically organized Reinforcement learning agent.\nHowever, such techniques often yield a large number of options or skills, which\ncan potentially be represented succinctly by filtering out any redundant\ninformation. Such a reduction can reduce the required computation while also\nimproving the performance on a target task. In order to compress an array of\noption policies, we attempt to find a policy basis that accurately captures the\nset of all options. In this work, we propose Option Encoder, an auto-encoder\nbased framework with intelligently constrained weights, that helps discover a\ncollection of basis policies. The policy basis can be used as a proxy for the\noriginal set of skills in a suitable hierarchically organized framework. We\ndemonstrate the efficacy of our method on a collection of grid-worlds and on\nthe high-dimensional Fetch-Reach robotic manipulation task by evaluating the\nobtained policy basis on a set of downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 20:10:12 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 05:50:15 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 08:12:02 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Manoharan", "Arjun", ""], ["Ramesh", "Rahul", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1909.04141", "submitter": "Lin Xu", "authors": "Lin Xu, Cheng Xu, Yi Tong, Yu Chun Su", "title": "Detection and Classification of Breast Cancer Metastates Based on U-Net", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents U-net based breast cancer metastases detection and\nclassification in lymph nodes, as well as patient-level classification based on\nmetastases detection. The whole pipeline can be divided into five steps:\npreprocessing and data argumentation, patch-based segmentation, post\nprocessing, slide-level classification, and patient-level classification. In\norder to reduce overfitting and speedup convergence, we applied batch\nnormalization and dropout into U-Net. The final Kappa score reaches 0.902 on\ntraining data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 20:34:32 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Xu", "Lin", ""], ["Xu", "Cheng", ""], ["Tong", "Yi", ""], ["Su", "Yu Chun", ""]]}, {"id": "1909.04142", "submitter": "Lin Xu", "authors": "Justin Quan, Lin Xu, Rene Xu, Tyrael Tong, and Jean Su", "title": "DaTscan SPECT Image Classification for Parkinson's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinson's Disease (PD) is a neurodegenerative disease that currently does\nnot have a cure. In order to facilitate disease management and reduce the speed\nof symptom progression, early diagnosis is essential. The current clinical,\ndiagnostic approach is to have radiologists perform human visual analysis of\nthe degeneration of dopaminergic neurons in the substantia nigra region of the\nbrain. Clinically, dopamine levels are monitored through observing dopamine\ntransporter (DaT) activity. One method of DaT activity analysis is performed\nwith the injection of an Iodine-123 fluoropropyl (123I-FP-CIT) tracer combined\nwith single photon emission computerized tomography (SPECT) imaging. The tracer\nillustrates the region of interest in the resulting DaTscan SPECT images. Human\nvisual analysis is slow and vulnerable to subjectivity between radiologists, so\nthe goal was to develop an introductory implementation of a deep convolutional\nneural network that can objectively and accurately classify DaTscan SPECT\nimages as Parkinson's Disease or normal. This study illustrates the approach of\nusing a deep convolutional neural network and evaluates its performance on\nDaTscan SPECT image classification. The data used in this study was obtained\nthrough a database provided by the Parkinson's Progression Markers Initiative\n(PPMI). The deep neural network in this study utilizes the InceptionV3\narchitecture, 1st runner up in the 2015 ImageNet Large Scale Visual Recognition\nCompetition (ILSVRC), as a base model. A custom, binary classifier block was\nadded on top of this base. In order to account for the small dataset size, a\nten fold cross validation was implemented to evaluate the model's performance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 20:35:23 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Quan", "Justin", ""], ["Xu", "Lin", ""], ["Xu", "Rene", ""], ["Tong", "Tyrael", ""], ["Su", "Jean", ""]]}, {"id": "1909.04157", "submitter": "Liang Lu", "authors": "Liang Lu, Eric Sun and Yifan Gong", "title": "Self-Teaching Networks", "comments": "5 pages, Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose self-teaching networks to improve the generalization capacity of\ndeep neural networks. The idea is to generate soft supervision labels using the\noutput layer for training the lower layers of the network. During the network\ntraining, we seek an auxiliary loss that drives the lower layer to mimic the\nbehavior of the output layer. The connection between the two network layers\nthrough the auxiliary loss can help the gradient flow, which works similar to\nthe residual networks. Furthermore, the auxiliary loss also works as a\nregularizer, which improves the generalization capacity of the network. We\nevaluated the self-teaching network with deep recurrent neural networks on\nspeech recognition tasks, where we trained the acoustic model using 30 thousand\nhours of data. We tested the acoustic model using data collected from 4\nscenarios. We show that the self-teaching network can achieve consistent\nimprovements and outperform existing methods such as label smoothing and\nconfidence penalization.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 21:11:35 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Lu", "Liang", ""], ["Sun", "Eric", ""], ["Gong", "Yifan", ""]]}, {"id": "1909.04163", "submitter": "JIan Deng", "authors": "Jian Deng and Krzysztof Czarnecki", "title": "MLOD: A multi-view 3D object detection based on robust feature fusion\n  method", "comments": "6 pages, 6 figures, 2019 22st International Conference on Intelligent\n  Transportation Systems (ITSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Multi-view Labelling Object Detector (MLOD). The detector\ntakes an RGB image and a LIDAR point cloud as input and follows the two-stage\nobject detection framework. A Region Proposal Network (RPN) generates 3D\nproposals in a Bird's Eye View (BEV) projection of the point cloud. The second\nstage projects the 3D proposal bounding boxes to the image and BEV feature maps\nand sends the corresponding map crops to a detection header for classification\nand bounding-box regression. Unlike other multi-view based methods, the cropped\nimage features are not directly fed to the detection header, but masked by the\ndepth information to filter out parts outside 3D bounding boxes. The fusion of\nimage and BEV features is challenging, as they are derived from different\nperspectives. We introduce a novel detection header, which provides detection\nresults not just from fusion layer, but also from each sensor channel. Hence\nthe object detector can be trained on data labelled in different views to avoid\nthe degeneration of feature extractors. MLOD achieves state-of-the-art\nperformance on the KITTI 3D object detection benchmark. Most importantly, the\nevaluation shows that the new header architecture is effective in preventing\nimage feature extractor degeneration.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 21:18:41 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Deng", "Jian", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1909.04169", "submitter": "Md. Rezaul Karim", "authors": "Md. Rezaul Karim, Michael Cochez, Oya Beyan, Stefan Decker, Christoph\n  Lange", "title": "OncoNetExplainer: Explainable Predictions of Cancer Types Based on Gene\n  Expression Data", "comments": "In proc. of 19th IEEE International Conference on Bioinformatics and\n  Bioengineering(IEEE BIBE 2019)", "journal-ref": "IEEE International Conference on Bioinformatics and\n  Bioengineering(IEEE BIBE 2019)", "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.GN", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The discovery of important biomarkers is a significant step towards\nunderstanding the molecular mechanisms of carcinogenesis; enabling accurate\ndiagnosis for, and prognosis of, a certain cancer type. Before recommending any\ndiagnosis, genomics data such as gene expressions(GE) and clinical outcomes\nneed to be analyzed. However, complex nature, high dimensionality, and\nheterogeneity in genomics data make the overall analysis challenging.\nConvolutional neural networks(CNN) have shown tremendous success in solving\nsuch problems. However, neural network models are perceived mostly as `black\nbox' methods because of their not well-understood internal functioning.\nHowever, interpretability is important to provide insights on why a given\ncancer case has a certain type. Besides, finding the most important biomarkers\ncan help in recommending more accurate treatments and drug repositioning. In\nthis paper, we propose a new approach called OncoNetExplainer to make\nexplainable predictions of cancer types based on GE data. We used genomics data\nabout 9,074 cancer patients covering 33 different cancer types from the\nPan-Cancer Atlas on which we trained CNN and VGG16 networks using\nguided-gradient class activation maps++(GradCAM++). Further, we generate\nclass-specific heat maps to identify significant biomarkers and computed\nfeature importance in terms of mean absolute impact to rank top genes across\nall the cancer types. Quantitative and qualitative analyses show that both\nmodels exhibit high confidence at predicting the cancer types correctly giving\nan average precision of 96.25%. To provide comparisons with the baselines, we\nidentified top genes, and cancer-specific driver genes using gradient boosted\ntrees and SHapley Additive exPlanations(SHAP). Finally, our findings were\nvalidated with the annotations provided by the TumorPortal.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 21:43:59 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Karim", "Md. Rezaul", ""], ["Cochez", "Michael", ""], ["Beyan", "Oya", ""], ["Decker", "Stefan", ""], ["Lange", "Christoph", ""]]}, {"id": "1909.04170", "submitter": "Giacomo Spigler", "authors": "Giacomo Spigler", "title": "Meta-learnt priors slow down catastrophic forgetting in neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current training regimes for deep learning usually involve exposure to a\nsingle task / dataset at a time. Here we start from the observation that in\nthis context the trained model is not given any knowledge of anything outside\nits (single-task) training distribution, and has thus no way to learn\nparameters (i.e., feature detectors or policies) that could be helpful to solve\nother tasks, and to limit future interference with the acquired knowledge, and\nthus catastrophic forgetting. Here we show that catastrophic forgetting can be\nmitigated in a meta-learning context, by exposing a neural network to multiple\ntasks in a sequential manner during training. Finally, we present SeqFOMAML, a\nmeta-learning algorithm that implements these principles, and we evaluate it on\nsequential learning problems composed by Omniglot and MiniImageNet\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 21:46:19 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 16:39:32 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Spigler", "Giacomo", ""]]}, {"id": "1909.04176", "submitter": "Jiawei Wu", "authors": "Jiawei Wu, Wenhan Xiong, William Yang Wang", "title": "Learning to Learn and Predict: A Meta-Learning Approach for Multi-Label\n  Classification", "comments": "11pages, 5 figures, accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in natural language processing can be viewed as multi-label\nclassification problems. However, most of the existing models are trained with\nthe standard cross-entropy loss function and use a fixed prediction policy\n(e.g., a threshold of 0.5) for all the labels, which completely ignores the\ncomplexity and dependencies among different labels. In this paper, we propose a\nmeta-learning method to capture these complex label dependencies. More\nspecifically, our method utilizes a meta-learner to jointly learn the training\npolicies and prediction policies for different labels. The training policies\nare then used to train the classifier with the cross-entropy loss function, and\nthe prediction policies are further implemented for prediction. Experimental\nresults on fine-grained entity typing and text classification demonstrate that\nour proposed method can obtain more accurate multi-label classification\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 22:00:39 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wu", "Jiawei", ""], ["Xiong", "Wenhan", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.04188", "submitter": "Zheyuan Zhu", "authors": "Zheyuan Zhu, Yangyang Sun, Johnathon White, Zenghu Chang and Shuo Pang", "title": "Signal retrieval with measurement system knowledge using variational\n  generative model", "comments": "8 pages, 5 figures. Initial submission to IEEE Transactions on\n  Computational Imaging", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2978435", "report-no": null, "categories": "eess.IV cs.LG eess.SP physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal retrieval from a series of indirect measurements is a common task in\nmany imaging, metrology and characterization platforms in science and\nengineering. Because most of the indirect measurement processes are\nwell-described by physical models, signal retrieval can be solved with an\niterative optimization that enforces measurement consistency and prior\nknowledge on the signal. These iterative processes are time-consuming and only\naccommodate a linear measurement process and convex signal constraints.\nRecently, neural networks have been widely adopted to supersede iterative\nsignal retrieval methods by approximating the inverse mapping of the\nmeasurement model. However, networks with deterministic processes have failed\nto distinguish signal ambiguities in an ill-posed measurement system, and\nretrieved signals often lack consistency with the measurement. In this work we\nintroduce a variational generative model to capture the distribution of all\npossible signals, given a particular measurement. By exploiting the known\nmeasurement model in the variational generative framework, our signal retrieval\nprocess resolves the ambiguity in the forward process, and learns to retrieve\nsignals that satisfy the measurement with high fidelity in a variety of linear\nand nonlinear ill-posed systems, including ultrafast pulse retrieval, coded\naperture compressive video sensing and image retrieval from Fresnel hologram.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 22:41:33 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Zhu", "Zheyuan", ""], ["Sun", "Yangyang", ""], ["White", "Johnathon", ""], ["Chang", "Zenghu", ""], ["Pang", "Shuo", ""]]}, {"id": "1909.04190", "submitter": "Nhan Nguyen-Thanh", "authors": "Nhan Nguyen-Thanh, Dana Marinca, Kinda Khawam, David Rohde, Flavian\n  Vasile, Elena Simona Lohan, Steven Martin, Dominique Quadri", "title": "Recommendation System-based Upper Confidence Bound for Online\n  Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the method UCB-RS, which resorts to recommendation system (RS)\nfor enhancing the upper-confidence bound algorithm UCB, is presented. The\nproposed method is used for dealing with non-stationary and large-state spaces\nmulti-armed bandit problems. The proposed method has been targeted to the\nproblem of the product recommendation in the online advertising. Through\nextensive testing with RecoGym, an OpenAI Gym-based reinforcement learning\nenvironment for the product recommendation in online advertising, the proposed\nmethod outperforms the widespread reinforcement learning schemes such as\n$\\epsilon$-Greedy, Upper Confidence (UCB1) and Exponential Weights for\nExploration and Exploitation (EXP3).\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 22:43:33 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Nguyen-Thanh", "Nhan", ""], ["Marinca", "Dana", ""], ["Khawam", "Kinda", ""], ["Rohde", "David", ""], ["Vasile", "Flavian", ""], ["Lohan", "Elena Simona", ""], ["Martin", "Steven", ""], ["Quadri", "Dominique", ""]]}, {"id": "1909.04196", "submitter": "Yohei Sawada", "authors": "Yohei Sawada", "title": "Machine learning accelerates parameter optimization and uncertainty\n  assessment of a land surface model", "comments": "53 pages, 19 figures", "journal-ref": null, "doi": "10.1029/2020JD032688", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of land surface models (LSMs) significantly affects the\nunderstanding of atmospheric and related processes. Many of the LSMs' soil and\nvegetation parameters were unknown so that it is crucially important to\nefficiently optimize them. Here I present a globally applicable and\ncomputationally efficient method for parameter optimization and uncertainty\nassessment of the LSM by combining Markov Chain Monte Carlo (MCMC) with machine\nlearning. First, I performed the long-term (decadal scales) ensemble simulation\nof the LSM, in which each ensemble member has different parameters' values, and\ncalculated the gap between simulation and observation, or the cost function,\nfor each ensemble member. Second, I developed the statistical machine learning\nbased surrogate model, which is computationally cheap but accurately mimics the\nrelationship between parameters and the cost function, by applying the Gaussian\nprocess regression to learn the model simulation. Third, we applied MCMC by\nrepeatedly driving the surrogate model to get the posterior probabilistic\ndistribution of parameters. Using satellite passive microwave brightness\ntemperature observations, both synthetic and real-data experiments in the Sahel\nregion of west Africa were performed to optimize unknown soil and vegetation\nparameters of the LSM. The primary findings are (1) the proposed method is\n50,000 times as fast as the direct application of MCMC to the full LSM; (2) the\nskill of the LSM to simulate both soil moisture and vegetation dynamics can be\nimproved; (3) I successfully quantify the characteristics of equifinality by\nobtaining the full non-parametric probabilistic distribution of parameters.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 23:47:03 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 00:53:45 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sawada", "Yohei", ""]]}, {"id": "1909.04200", "submitter": "Isaac Ahern", "authors": "Isaac Ahern, Adam Noack, Luis Guzman-Nateras, Dejing Dou, Boyang Li,\n  and Jun Huan", "title": "NormLime: A New Feature Importance Metric for Explaining Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of explaining deep learning models, and model predictions\ngenerally, has attracted intensive interest recently. Many successful\napproaches forgo global approximations in order to provide more faithful local\ninterpretations of the model's behavior. LIME develops multiple interpretable\nmodels, each approximating a large neural network on a small region of the data\nmanifold and SP-LIME aggregates the local models to form a global\ninterpretation. Extending this line of research, we propose a simple yet\neffective method, NormLIME for aggregating local models into global and\nclass-specific interpretations. A human user study strongly favored\nclass-specific interpretations created by NormLIME to other feature importance\nmetrics. Numerical experiments confirm that NormLIME is effective at\nrecognizing important features.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 00:01:51 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 04:43:35 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Ahern", "Isaac", ""], ["Noack", "Adam", ""], ["Guzman-Nateras", "Luis", ""], ["Dou", "Dejing", ""], ["Li", "Boyang", ""], ["Huan", "Jun", ""]]}, {"id": "1909.04202", "submitter": "Baihong Jin", "authors": "Baihong Jin, Yingshui Tan, Yuxin Chen, Alberto Sangiovanni-Vincentelli", "title": "Augmenting Monte Carlo Dropout Classification Models with Unsupervised\n  Learning Tasks for Detecting and Diagnosing Out-of-Distribution Faults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Monte Carlo dropout method has proved to be a scalable and easy-to-use\napproach for estimating the uncertainty of deep neural network predictions.\nThis approach was recently applied to Fault Detection and Di-agnosis (FDD)\napplications to improve the classification performance on incipient faults. In\nthis paper, we propose a novel approach of augmenting the classification model\nwith an additional unsupervised learning task. We justify our choice of\nalgorithm design via an information-theoretical analysis. Our experimental\nresults on three datasets from diverse application domains show that the\nproposed method leads to improved fault detection and diagnosis performance,\nespecially on out-of-distribution examples including both incipient and unknown\nfaults.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 00:07:28 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Jin", "Baihong", ""], ["Tan", "Yingshui", ""], ["Chen", "Yuxin", ""], ["Sangiovanni-Vincentelli", "Alberto", ""]]}, {"id": "1909.04203", "submitter": "C.B. Scott", "authors": "C.B. Scott, Eric Mjolsness", "title": "Novel diffusion-derived distance measures for graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM math.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define a new family of similarity and distance measures on graphs, and\nexplore their theoretical properties in comparison to conventional distance\nmetrics. These measures are defined by the solution(s) to an optimization\nproblem which attempts find a map minimizing the discrepancy between two graph\nLaplacian exponential matrices, under norm-preserving and sparsity constraints.\nVariants of the distance metric are introduced to consider such optimized maps\nunder sparsity constraints as well as fixed time-scaling between the two\nLaplacians. The objective function of this optimization is multimodal and has\ndiscontinuous slope, and is hence difficult for univariate optimizers to solve.\nWe demonstrate a novel procedure for efficiently calculating these optima for\ntwo of our distance measure variants. We present numerical experiments\ndemonstrating that (a) upper bounds of our distance metrics can be used to\ndistinguish between lineages of related graphs; (b) our procedure is faster at\nfinding the required optima, by as much as a factor of 10^3; and (c) the upper\nbounds satisfy the triangle inequality exactly under some assumptions and\napproximately under others. We also derive an upper bound for the distance\nbetween two graph products, in terms of the distance between the two pairs of\nfactors. Additionally, we present several possible applications, including the\nconstruction of infinite \"graph limits\" by means of Cauchy sequences of graphs\nrelated to one another by our distance measure.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 00:17:18 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Scott", "C. B.", ""], ["Mjolsness", "Eric", ""]]}, {"id": "1909.04217", "submitter": "Xinyi Ding", "authors": "Xinyi Ding, Zohreh Raziei, Eric C. Larson, Eli V. Olinick, Paul\n  Krueger, Michael Hahsler", "title": "Swapped Face Detection using Deep Learning and Subjective Assessment", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous success of deep learning for imaging applications has resulted\nin numerous beneficial advances. Unfortunately, this success has also been a\ncatalyst for malicious uses such as photo-realistic face swapping of parties\nwithout consent. Transferring one person's face from a source image to a target\nimage of another person, while keeping the image photo-realistic overall has\nbecome increasingly easy and automatic, even for individuals without much\nknowledge of image processing. In this study, we use deep transfer learning for\nface swapping detection, showing true positive rates >96% with very few false\nalarms. Distinguished from existing methods that only provide detection\naccuracy, we also provide uncertainty for each prediction, which is critical\nfor trust in the deployment of such detection systems. Moreover, we provide a\ncomparison to human subjects. To capture human recognition performance, we\nbuild a website to collect pairwise comparisons of images from human subjects.\nBased on these comparisons, images are ranked from most real to most fake. We\ncompare this ranking to the outputs from our automatic model, showing good, but\nimperfect, correspondence with linear correlations >0.75. Overall, the results\nshow the effectiveness of our method. As part of this study, we create a novel,\npublicly available dataset that is, to the best of our knowledge, the largest\npublic swapped face dataset created using still images. Our goal of this study\nis to inspire more research in the field of image forensics through the\ncreation of a public dataset and initial analysis.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 01:06:43 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Ding", "Xinyi", ""], ["Raziei", "Zohreh", ""], ["Larson", "Eric C.", ""], ["Olinick", "Eli V.", ""], ["Krueger", "Paul", ""], ["Hahsler", "Michael", ""]]}, {"id": "1909.04226", "submitter": "Rupak Chatterjee", "authors": "Abhijat Sarma, Rupak Chatterjee, Kaitlin Gili, and Ting Yu", "title": "Quantum Unsupervised and Supervised Learning on Superconducting\n  Processors", "comments": "6 pages, 4 figures, 2 tables", "journal-ref": "Quantum Information and Computation 20 (7&8), 541-552 (2020)", "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms perform well on identifying patterns in many\ndatasets due to their versatility. However, as one increases the size of the\ndata, the time for training and using these statistical models grows quickly.\nHere, we propose and implement on the IBMQ a quantum analogue to K-means\nclustering, and compare it to a previously developed quantum support vector\nmachine. We find the algorithm's accuracy comparable to classical K-means for\nclustering and classification problems, and find that it becomes less\ncomputationally expensive to implement for large datasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 01:31:32 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Sarma", "Abhijat", ""], ["Chatterjee", "Rupak", ""], ["Gili", "Kaitlin", ""], ["Yu", "Ting", ""]]}, {"id": "1909.04236", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Mohammad Ghavamzadeh, Shie Mannor", "title": "Online Planning with Lookahead Policies", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real Time Dynamic Programming (RTDP) is an online algorithm based on Dynamic\nProgramming (DP) that acts by 1-step greedy planning. Unlike DP, RTDP does not\nrequire access to the entire state space, i.e., it explicitly handles the\nexploration. This fact makes RTDP particularly appealing when the state space\nis large and it is not possible to update all states simultaneously. In this we\ndevise a multi-step greedy RTDP algorithm, which we call $h$-RTDP, that\nreplaces the 1-step greedy policy with a $h$-step lookahead policy. We analyze\n$h$-RTDP in its exact form and establish that increasing the lookahead horizon,\n$h$, results in an improved sample complexity, with the cost of additional\ncomputations. This is the first work that proves improved sample complexity as\na result of {\\em increasing} the lookahead horizon in online planning. We then\nanalyze the performance of $h$-RTDP in three approximate settings: approximate\nmodel, approximate value updates, and approximate state representation. For\nthese cases, we prove that the asymptotic performance of $h$-RTDP remains the\nsame as that of a corresponding approximate DP algorithm, the best one can hope\nfor without further assumptions on the approximation errors.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 02:00:52 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 16:38:35 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Efroni", "Yonathan", ""], ["Ghavamzadeh", "Mohammad", ""], ["Mannor", "Shie", ""]]}, {"id": "1909.04239", "submitter": "Yitong Meng", "authors": "Yitong Meng, Xinyan Dai, Xiao Yan, James Cheng, Weiwen Liu, Benben\n  Liao, Jun Guo, Guangyong Chen", "title": "PMD: An Optimal Transportation-based User Distance for Recommender\n  Systems", "comments": "This paper is accepted by European Conference on Information\n  Retrieval (ECIR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering, a widely-used recommendation technique, predicts a\nuser's preference by aggregating the ratings from similar users. As a result,\nthese measures cannot fully utilize the rating information and are not suitable\nfor real world sparse data. To solve these issues, we propose a novel user\ndistance measure named Preference Mover's Distance (PMD) which makes full use\nof all ratings made by each user. Our proposed PMD can properly measure the\ndistance between a pair of users even if they have no co-rated items. We show\nthat this measure can be cast as an instance of the Earth Mover's Distance, a\nwell-studied transportation problem for which several highly efficient solvers\nhave been developed. Experimental results show that PMD can help achieve\nsuperior recommendation accuracy than state-of-the-art methods, especially when\ntraining data is very sparse.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 02:06:57 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 07:05:41 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Meng", "Yitong", ""], ["Dai", "Xinyan", ""], ["Yan", "Xiao", ""], ["Cheng", "James", ""], ["Liu", "Weiwen", ""], ["Liao", "Benben", ""], ["Guo", "Jun", ""], ["Chen", "Guangyong", ""]]}, {"id": "1909.04240", "submitter": "Stephan Hoyer", "authors": "Stephan Hoyer, Jascha Sohl-Dickstein, Sam Greydanus", "title": "Neural reparameterization improves structural optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural optimization is a popular method for designing objects such as\nbridge trusses, airplane wings, and optical devices. Unfortunately, the quality\nof solutions depends heavily on how the problem is parameterized. In this\npaper, we propose using the implicit bias over functions induced by neural\nnetworks to improve the parameterization of structural optimization. Rather\nthan directly optimizing densities on a grid, we instead optimize the\nparameters of a neural network which outputs those densities. This\nreparameterization leads to different and often better solutions. On a\nselection of 116 structural optimization tasks, our approach produces the best\ndesign 50% more often than the best baseline method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 02:07:09 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 00:22:41 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Hoyer", "Stephan", ""], ["Sohl-Dickstein", "Jascha", ""], ["Greydanus", "Sam", ""]]}, {"id": "1909.04242", "submitter": "Guanhua Zhang", "authors": "Guanhua Zhang, Bing Bai, Junqi Zhang, Kun Bai, Conghui Zhu, Tiejun\n  Zhao", "title": "Mitigating Annotation Artifacts in Natural Language Inference Datasets\n  to Improve Cross-dataset Generalization Ability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language inference (NLI) aims at predicting the relationship between\na given pair of premise and hypothesis. However, several works have found that\nthere widely exists a bias pattern called annotation artifacts in NLI datasets,\nmaking it possible to identify the label only by looking at the hypothesis.\nThis irregularity makes the evaluation results over-estimated and affects\nmodels' generalization ability. In this paper, we consider a more trust-worthy\nsetting, i.e., cross-dataset evaluation. We explore the impacts of annotation\nartifacts in cross-dataset testing. Furthermore, we propose a training\nframework to mitigate the impacts of the bias pattern. Experimental results\ndemonstrate that our methods can alleviate the negative effect of the artifacts\nand improve the generalization ability of models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 02:35:34 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 14:40:31 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhang", "Guanhua", ""], ["Bai", "Bing", ""], ["Zhang", "Junqi", ""], ["Bai", "Kun", ""], ["Zhu", "Conghui", ""], ["Zhao", "Tiejun", ""]]}, {"id": "1909.04246", "submitter": "Yuanfu Lu", "authors": "Yuanfu Lu, Xiao Wang, Chuan Shi, Philip S. Yu, Yanfang Ye", "title": "Temporal Network Embedding with Micro- and Macro-dynamics", "comments": "CIKM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding aims to embed nodes into a low-dimensional space, while\ncapturing the network structures and properties. Although quite a few promising\nnetwork embedding methods have been proposed, most of them focus on static\nnetworks. In fact, temporal networks, which usually evolve over time in terms\nof microscopic and macroscopic dynamics, are ubiquitous. The micro-dynamics\ndescribe the formation process of network structures in a detailed manner,\nwhile the macro-dynamics refer to the evolution pattern of the network scale.\nBoth micro- and macro-dynamics are the key factors to network evolution;\nhowever, how to elegantly capture both of them for temporal network embedding,\nespecially macro-dynamics, has not yet been well studied. In this paper, we\npropose a novel temporal network embedding method with micro- and\nmacro-dynamics, named $\\rm{M^2DNE}$. Specifically, for micro-dynamics, we\nregard the establishments of edges as the occurrences of chronological events\nand propose a temporal attention point process to capture the formation process\nof network structures in a fine-grained manner. For macro-dynamics, we define a\ngeneral dynamics equation parameterized with network embeddings to capture the\ninherent evolution pattern and impose constraints in a higher structural level\non network embeddings. Mutual evolutions of micro- and macro-dynamics in a\ntemporal network alternately affect the process of learning node embeddings.\nExtensive experiments on three real-world temporal networks demonstrate that\n$\\rm{M^2DNE}$ significantly outperforms the state-of-the-arts not only in\ntraditional tasks, e.g., network reconstruction, but also in temporal\ntendency-related tasks, e.g., scale prediction.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 02:43:43 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Lu", "Yuanfu", ""], ["Wang", "Xiao", ""], ["Shi", "Chuan", ""], ["Yu", "Philip S.", ""], ["Ye", "Yanfang", ""]]}, {"id": "1909.04252", "submitter": "Wonsup Shin", "authors": "Wonsup Shin, Tae-Young Kim, and Sung-Bae Cho", "title": "Lifelog Patterns Analyzation using Graph Embedding based on Deep Neural\n  Network", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, as the spread of smart devices increases, the amount of data\ncollected through sensors is increasing. A lifelog is a kind of big data to\nanalyze behavior patterns in the daily life of individuals collected from\nvarious smart de-vices. However, sensor data is a low-level signal that makes\nit difficult for hu-mans to recognize the situation directly and cannot express\nrelations clearly. It is also difficult to identify the daily behavior pattern\nbecause it records heterogene-ous data by various sensors. In this paper, we\npropose a method to define a graph structure with node and edge and to extract\nthe daily behavior pattern from the generated lifelog graph. We use the graph\nconvolution method to embeds the lifelog graph and maps it to low dimension.\nThe graph convolution layer im-proves the expressive power of the daily\nbehavior pattern by implanting the life-log graph in the non-Euclidean space\nand learns the patterns of graphs. Experi-mental results show that the proposed\nmethod automatically extracts meaningful user patterns from UbiqLog dataset. In\naddition, we confirm the usefulness by comparing our method with existing\nmethods to evaluate performance.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 03:05:56 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Shin", "Wonsup", ""], ["Kim", "Tae-Young", ""], ["Cho", "Sung-Bae", ""]]}, {"id": "1909.04261", "submitter": "Wei Xie", "authors": "Wei Xie and Bo Wang and Cheng Li and Dongming Xie and Jared Auclair", "title": "Interpretable Biomanufacturing Process Risk and Sensitivity Analyses for\n  Quality-by-Design and Stability Control", "comments": "41 pages, 8 figures", "journal-ref": "Naval Research Logistics, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While biomanufacturing plays a significant role in supporting the economy and\nensuring public health, it faces critical challenges, including complexity,\nhigh variability, lengthy lead time, and very limited process data, especially\nfor personalized new cell and gene biotherapeutics. Driven by these challenges,\nwe propose an interpretable semantic bioprocess probabilistic knowledge graph\nand develop a game theory based risk and sensitivity analyses for production\nprocess to facilitate quality-by-design and stability control. Specifically, by\nexploring the causal relationships and interactions of critical process\nparameters and quality attributes (CPPs/CQAs), we create a Bayesian network\nbased probabilistic knowledge graph characterizing the complex causal\ninterdependencies of all factors. Then, we introduce a Shapley value based\nsensitivity analysis, which can correctly quantify the variation contribution\nfrom each input factor on the outputs (i.e., productivity, product quality).\nSince the bioprocess model coefficients are learned from limited process\nobservations, we derive the Bayesian posterior distribution to quantify model\nuncertainty and further develop the Shapley value based sensitivity analysis to\nevaluate the impact of estimation uncertainty from each set of model\ncoefficients. Therefore, the proposed bioprocess risk and sensitivity analyses\ncan identify the bottlenecks, guide the reliable process specifications and the\nmost \"informative\" data collection, and improve production stability.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 03:26:01 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 22:10:27 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 14:58:08 GMT"}, {"version": "v4", "created": "Wed, 2 Jun 2021 16:01:25 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Xie", "Wei", ""], ["Wang", "Bo", ""], ["Li", "Cheng", ""], ["Xie", "Dongming", ""], ["Auclair", "Jared", ""]]}, {"id": "1909.04266", "submitter": "Yitong Meng", "authors": "Yitong Meng, Guangyong Chen, Benben Liao, Jun Guo, Weiwen Liu", "title": "Wasserstein Collaborative Filtering for Item Cold-start Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The item cold-start problem seriously limits the recommendation performance\nof Collaborative Filtering (CF) methods when new items have either none or very\nlittle interactions. To solve this issue, many modern Internet applications\npropose to predict a new item's interaction from the possessing contents.\nHowever, it is difficult to design and learn a map between the item's\ninteraction history and the corresponding contents. In this paper, we apply the\nWasserstein distance to address the item cold-start problem. Given item content\ninformation, we can calculate the similarity between the interacted items and\ncold-start ones, so that a user's preference on cold-start items can be\ninferred by minimizing the Wasserstein distance between the distributions over\nthese two types of items. We further adopt the idea of CF and propose\nWasserstein CF (WCF) to improve the recommendation performance on cold-start\nitems. Experimental results demonstrate the superiority of WCF over\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 03:32:05 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Meng", "Yitong", ""], ["Chen", "Guangyong", ""], ["Liao", "Benben", ""], ["Guo", "Jun", ""], ["Liu", "Weiwen", ""]]}, {"id": "1909.04276", "submitter": "Pankaj Malhotra", "authors": "Priyanka Gupta, Diksha Garg, Pankaj Malhotra, Lovekesh Vig, Gautam\n  Shroff", "title": "NISER: Normalized Item and Session Representations to Handle Popularity\n  Bias", "comments": "Presented at 1st International Workshop on Graph Representation\n  Learning and its Applications, CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of session-based recommendation (SR) models is to utilize the\ninformation from past actions (e.g. item/product clicks) in a session to\nrecommend items that a user is likely to click next. Recently it has been shown\nthat the sequence of item interactions in a session can be modeled as\ngraph-structured data to better account for complex item transitions. Graph\nneural networks (GNNs) can learn useful representations for such\nsession-graphs, and have been shown to improve over sequential models such as\nrecurrent neural networks [14]. However, we note that these GNN-based\nrecommendation models suffer from popularity bias: the models are biased\ntowards recommending popular items, and fail to recommend relevant long-tail\nitems (less popular or less frequent items). Therefore, these models perform\npoorly for the less popular new items arriving daily in a practical online\nsetting. We demonstrate that this issue is, in part, related to the magnitude\nor norm of the learned item and session-graph representations (embedding\nvectors). We propose a training procedure that mitigates this issue by using\nnormalized representations. The models using normalized item and session-graph\nrepresentations perform significantly better: i. for the less popular long-tail\nitems in the offline setting, and ii. for the less popular newly introduced\nitems in the online setting. Furthermore, our approach significantly improves\nupon existing state-of-the-art on three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 04:24:35 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 05:29:42 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 13:28:59 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 13:04:37 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Gupta", "Priyanka", ""], ["Garg", "Diksha", ""], ["Malhotra", "Pankaj", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "1909.04286", "submitter": "Soma Minami", "authors": "Soma Minami, Tsubasa Hirakawa, Takayoshi Yamashita, Hironobu Fujiyoshi", "title": "Knowledge Transfer Graph for Deep Collaborative Learning", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge transfer among multiple networks using their outputs or\nintermediate activations have evolved through extensive manual design from a\nsimple teacher-student approach (knowledge distillation) to a bidirectional\ncohort one (deep mutual learning). The key factors of such knowledge transfer\ninvolve the network size, the number of networks, the transfer direction, and\nthe design of the loss function. However, because these factors are enormous\nwhen combined and become intricately entangled, the methods of conventional\nknowledge transfer have explored only limited combinations. In this paper, we\npropose a new graph-based approach for more flexible and diverse combinations\nof knowledge transfer. To achieve the knowledge transfer, we propose a novel\ngraph representation called knowledge transfer graph that provides a unified\nview of the knowledge transfer and has the potential to represent diverse\nknowledge transfer patterns. We also propose four gate functions that are\nintroduced into loss functions. The four gates, which control the gradient, can\ndeliver diverse combinations of knowledge transfer. Searching the graph\nstructure enables us to discover more effective knowledge transfer methods than\na manually designed one. Experimental results on the CIFAR-10, -100, and\nTiny-ImageNet datasets show that the proposed method achieved significant\nperformance improvements and was able to find remarkable graph structures.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 04:56:29 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 03:46:16 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Minami", "Soma", ""], ["Hirakawa", "Tsubasa", ""], ["Yamashita", "Takayoshi", ""], ["Fujiyoshi", "Hironobu", ""]]}, {"id": "1909.04288", "submitter": "Zhenxin Xiao", "authors": "Zhenxin Xiao, Puyudi Yang, Yuchen Jiang, Kai-Wei Chang, Cho-Jui Hsieh", "title": "BOSH: An Efficient Meta Algorithm for Decision-based Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial example generation becomes a viable method for evaluating the\nrobustness of a machine learning model. In this paper, we consider hard-label\nblack-box attacks (a.k.a. decision-based attacks), which is a challenging\nsetting that generates adversarial examples based on only a series of black-box\nhard-label queries. This type of attacks can be used to attack discrete and\ncomplex models, such as Gradient Boosting Decision Tree (GBDT) and\ndetection-based defense models. Existing decision-based attacks based on\niterative local updates often get stuck in a local minimum and fail to generate\nthe optimal adversarial example with the smallest distortion. To remedy this\nissue, we propose an efficient meta algorithm called BOSH-attack, which\ntremendously improves existing algorithms through Bayesian Optimization (BO)\nand Successive Halving (SH). In particular, instead of traversing a single\nsolution path when searching an adversarial example, we maintain a pool of\nsolution paths to explore important regions. We show empirically that the\nproposed algorithm converges to a better solution than existing approaches,\nwhile the query count is smaller than applying multiple random initializations\nby a factor of 10.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 05:00:06 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 21:31:26 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 14:14:57 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Xiao", "Zhenxin", ""], ["Yang", "Puyudi", ""], ["Jiang", "Yuchen", ""], ["Chang", "Kai-Wei", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1909.04293", "submitter": "Kasun Bandara", "authors": "Kasun Bandara, Christoph Bergmeir and Hansika Hewamalage", "title": "LSTM-MSNet: Leveraging Forecasts on Sets of Related Time Series with\n  Multiple Seasonal Patterns", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.2985720", "report-no": null, "categories": "stat.AP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating forecasts for time series with multiple seasonal cycles is an\nimportant use-case for many industries nowadays. Accounting for the\nmulti-seasonal patterns becomes necessary to generate more accurate and\nmeaningful forecasts in these contexts. In this paper, we propose Long\nShort-Term Memory Multi-Seasonal Net (LSTM-MSNet), a decomposition based,\nunified prediction framework to forecast time series with multiple seasonal\npatterns. The current state of the art in this space are typically univariate\nmethods, in which the model parameters of each time series are estimated\nindependently. Consequently, these models are unable to include key patterns\nand structures that may be shared by a collection of time series. In contrast,\nLSTM-MSNet is a globally trained Long Short-Term Memory network (LSTM), where a\nsingle prediction model is built across all the available time series to\nexploit the cross series knowledge in a group of related time series.\nFurthermore, our methodology combines a series of state-of-the-art\nmultiseasonal decomposition techniques to supplement the LSTM learning\nprocedure. In our experiments, we are able to show that on datasets from\ndisparate data sources, like e.g. the popular M4 forecasting competition, a\ndecomposition step is beneficial, whereas in the common real-world situation of\nhomogeneous series from a single application, exogenous seasonal variables or\nno seasonal preprocessing at all are better choices. All options are readily\nincluded in the framework and allow us to achieve competitive results for both\ncases, outperforming many state-of-the-art multi-seasonal forecasting methods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 05:15:24 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 12:52:37 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bandara", "Kasun", ""], ["Bergmeir", "Christoph", ""], ["Hewamalage", "Hansika", ""]]}, {"id": "1909.04299", "submitter": "Gang Wang", "authors": "Gang Wang, Bingcong Li, Georgios B. Giannakis", "title": "A Multistep Lyapunov Approach for Finite-Time Analysis of Biased\n  Stochastic Approximation", "comments": "28 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the widespread use of temporal-difference (TD-) and Q-learning\nalgorithms in reinforcement learning, this paper studies a class of biased\nstochastic approximation (SA) procedures under a mild \"ergodic-like\" assumption\non the underlying stochastic noise sequence. Building upon a carefully designed\nmultistep Lyapunov function that looks ahead to several future updates to\naccommodate the stochastic perturbations (for control of the gradient bias), we\nprove a general result on the convergence of the iterates, and use it to derive\nnon-asymptotic bounds on the mean-square error in the case of constant\nstepsizes. This novel looking-ahead viewpoint renders finite-time analysis of\nbiased SA algorithms under a large family of stochastic perturbations possible.\nFor direct comparison with existing contributions, we also demonstrate these\nbounds by applying them to TD- and Q-learning with linear function\napproximation, under the practical Markov chain observation model. The\nresultant finite-time error bound for both the TD- as well as the Q-learning\nalgorithms is the first of its kind, in the sense that it holds i) for the\nunmodified versions (i.e., without making any modifications to the parameter\nupdates) using even nonlinear function approximators; as well as for Markov\nchains ii) under general mixing conditions and iii) starting from any initial\ndistribution, at least one of which has to be violated for existing results to\nbe applicable.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 05:27:58 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 03:25:23 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 13:54:24 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Wang", "Gang", ""], ["Li", "Bingcong", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1909.04302", "submitter": "Shao-Yen Tseng", "authors": "Shao-Yen Tseng, Panayiotis Georgiou, Shrikanth Narayanan", "title": "Multimodal Embeddings from Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings such as ELMo have recently been shown to model word semantics\nwith greater efficacy through contextualized learning on large-scale language\ncorpora, resulting in significant improvement in state of the art across many\nnatural language tasks. In this work we integrate acoustic information into\ncontextualized lexical embeddings through the addition of multimodal inputs to\na pretrained bidirectional language model. The language model is trained on\nspoken language that includes text and audio modalities. The resulting\nrepresentations from this model are multimodal and contain paralinguistic\ninformation which can modify word meanings and provide affective information.\nWe show that these multimodal embeddings can be used to improve over previous\nstate of the art multimodal models in emotion recognition on the CMU-MOSEI\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 05:46:39 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Tseng", "Shao-Yen", ""], ["Georgiou", "Panayiotis", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1909.04305", "submitter": "Junghyo Jo", "authors": "Junghyo Jo and Danh-Tai Hoang and Vipul Periwal", "title": "Inverse Ising inference from high-temperature re-weighting of\n  observations", "comments": "5 pages, 4 figures", "journal-ref": "Phys. Rev. E 101, 032107 (2020)", "doi": "10.1103/PhysRevE.101.032107", "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum Likelihood Estimation (MLE) is the bread and butter of system\ninference for stochastic systems. In some generality, MLE will converge to the\ncorrect model in the infinite data limit. In the context of physical approaches\nto system inference, such as Boltzmann machines, MLE requires the arduous\ncomputation of partition functions summing over all configurations, both\nobserved and unobserved. We present here a conceptually and computationally\ntransparent data-driven approach to system inference that is based on the\nsimple question: How should the Boltzmann weights of observed configurations be\nmodified to make the probability distribution of observed configurations close\nto a flat distribution? This algorithm gives accurate inference by using only\nobserved configurations for systems with a large number of degrees of freedom\nwhere other approaches are intractable.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 06:02:07 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Jo", "Junghyo", ""], ["Hoang", "Danh-Tai", ""], ["Periwal", "Vipul", ""]]}, {"id": "1909.04306", "submitter": "Yi Wu", "authors": "Yi Wu, Yuxin Wu, Aviv Tamar, Stuart Russell, Georgia Gkioxari,\n  Yuandong Tian", "title": "Bayesian Relational Memory for Semantic Visual Navigation", "comments": "Accepted at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new memory architecture, Bayesian Relational Memory (BRM), to\nimprove the generalization ability for semantic visual navigation agents in\nunseen environments, where an agent is given a semantic target to navigate\ntowards. BRM takes the form of a probabilistic relation graph over semantic\nentities (e.g., room types), which allows (1) capturing the layout prior from\ntraining environments, i.e., prior knowledge, (2) estimating posterior layout\nat test time, i.e., memory update, and (3) efficient planning for navigation,\naltogether. We develop a BRM agent consisting of a BRM module for producing\nsub-goals and a goal-conditioned locomotion module for control. When testing in\nunseen environments, the BRM agent outperforms baselines that do not explicitly\nutilize the probabilistic relational memory structure\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 06:02:15 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wu", "Yi", ""], ["Wu", "Yuxin", ""], ["Tamar", "Aviv", ""], ["Russell", "Stuart", ""], ["Gkioxari", "Georgia", ""], ["Tian", "Yuandong", ""]]}, {"id": "1909.04311", "submitter": "Byunggill Joe", "authors": "Byunggill Joe, Sung Ju Hwang, Insik Shin", "title": "Learning to Disentangle Robust and Vulnerable Features for Adversarial\n  Detection", "comments": "main: 10 pages appendix: 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural networks have shown promising performances on various\ntasks, even achieving human-level performance on some, they are shown to be\nsusceptible to incorrect predictions even with imperceptibly small\nperturbations to an input. There exists a large number of previous works which\nproposed to defend against such adversarial attacks either by robust inference\nor detection of adversarial inputs. Yet, most of them cannot effectively defend\nagainst whitebox attacks where an adversary has a knowledge of the model and\ndefense. More importantly, they do not provide a convincing reason why the\ngenerated adversarial inputs successfully fool the target models. To address\nthese shortcomings of the existing approaches, we hypothesize that the\nadversarial inputs are tied to latent features that are susceptible to\nadversarial perturbation, which we call vulnerable features. Then based on this\nintuition, we propose a minimax game formulation to disentangle the latent\nfeatures of each instance into robust and vulnerable ones, using variational\nautoencoders with two latent spaces. We thoroughly validate our model for both\nblackbox and whitebox attacks on MNIST, Fashion MNIST5, and Cat & Dog datasets,\nwhose results show that the adversarial inputs cannot bypass our detector\nwithout changing its semantics, in which case the attack has failed.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 06:17:06 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Joe", "Byunggill", ""], ["Hwang", "Sung Ju", ""], ["Shin", "Insik", ""]]}, {"id": "1909.04319", "submitter": "Hiroyuki Kido", "authors": "Hiroyuki Kido and Beishui Liao", "title": "A Bayesian Approach to Direct and Inverse Abstract Argumentation\n  Problems", "comments": "This paper was submitted to the journal of Artificial Intelligence\n  (AIJ) and rejected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a fundamental mechanism of how to detect a conflict\nbetween arguments given sentiments regarding acceptability of the arguments. We\nintroduce a concept of the inverse problem of the abstract argumentation to\ntackle the problem. Given noisy sets of acceptable arguments, it aims to find\nattack relations explaining the sets well in terms of acceptability semantics.\nIt is the inverse of the direct problem corresponding to the traditional\nproblem of the abstract argumentation that focuses on finding sets of\nacceptable arguments in terms of the semantics given an attack relation between\nthe arguments. We give a probabilistic model handling both of the problems in a\nway that is faithful to the acceptability semantics. From a theoretical point\nof view, we show that a solution to both the direct and inverse problems is a\nspecial case of the probabilistic inference on the model. We discuss that the\nmodel provides a natural extension of the semantics to cope with uncertain\nattack relations distributed probabilistically. From en empirical point of\nview, we argue that it reasonably predicts individuals sentiments regarding\nacceptability of arguments. This paper contributes to lay the foundation for\nmaking acceptability semantics data-driven and to provide a way to tackle the\nknowledge acquisition bottleneck.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 06:37:12 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 17:51:56 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Kido", "Hiroyuki", ""], ["Liao", "Beishui", ""]]}, {"id": "1909.04324", "submitter": "Xianglei Xing", "authors": "Xianglei Xing, Tianfu Wu, Song-Chun Zhu, Ying Nian Wu", "title": "Inducing Hierarchical Compositional Model by Sparsifying Generator\n  Network", "comments": "This is the CVPR version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes to learn hierarchical compositional AND-OR model for\ninterpretable image synthesis by sparsifying the generator network. The\nproposed method adopts the scene-objects-parts-subparts-primitives hierarchy in\nimage representation. A scene has different types (i.e., OR) each of which\nconsists of a number of objects (i.e., AND). This can be recursively formulated\nacross the scene-objects-parts-subparts hierarchy and is terminated at the\nprimitive level (e.g., wavelets-like basis). To realize this AND-OR hierarchy\nin image synthesis, we learn a generator network that consists of the following\ntwo components: (i) Each layer of the hierarchy is represented by an\nover-complete set of convolutional basis functions. Off-the-shelf convolutional\nneural architectures are exploited to implement the hierarchy. (ii)\nSparsity-inducing constraints are introduced in end-to-end training, which\ninduces a sparsely activated and sparsely connected AND-OR model from the\ninitially densely connected generator network. A straightforward\nsparsity-inducing constraint is utilized, that is to only allow the top-$k$\nbasis functions to be activated at each layer (where $k$ is a hyper-parameter).\nThe learned basis functions are also capable of image reconstruction to explain\nthe input images. In experiments, the proposed method is tested on four\nbenchmark datasets. The results show that meaningful and interpretable\nhierarchical representations are learned with better qualities of image\nsynthesis and reconstruction obtained than baselines.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 07:06:33 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 05:02:00 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Xing", "Xianglei", ""], ["Wu", "Tianfu", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1909.04344", "submitter": "Vinay Verma Kumar", "authors": "Vinay Kumar Verma, Dhanajit Brahma and Piyush Rai", "title": "A Meta-Learning Framework for Generalized Zero-Shot Learning", "comments": "Under Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to classify unseen class samples at test time is popularly referred\nto as zero-shot learning (ZSL). If test samples can be from training (seen) as\nwell as unseen classes, it is a more challenging problem due to the existence\nof strong bias towards seen classes. This problem is generally known as\n\\emph{generalized} zero-shot learning (GZSL). Thanks to the recent advances in\ngenerative models such as VAEs and GANs, sample synthesis based approaches have\ngained considerable attention for solving this problem. These approaches are\nable to handle the problem of class bias by synthesizing unseen class samples.\nHowever, these ZSL/GZSL models suffer due to the following key limitations:\n$(i)$ Their training stage learns a class-conditioned generator using only\n\\emph{seen} class data and the training stage does not \\emph{explicitly} learn\nto generate the unseen class samples; $(ii)$ They do not learn a generic\noptimal parameter which can easily generalize for both seen and unseen class\ngeneration; and $(iii)$ If we only have access to a very few samples per seen\nclass, these models tend to perform poorly. In this paper, we propose a\nmeta-learning based generative model that naturally handles these limitations.\nThe proposed model is based on integrating model-agnostic meta learning with a\nWasserstein GAN (WGAN) to handle $(i)$ and $(iii)$, and uses a novel task\ndistribution to handle $(ii)$. Our proposed model yields significant\nimprovements on standard ZSL as well as more challenging GZSL setting. In ZSL\nsetting, our model yields 4.5\\%, 6.0\\%, 9.8\\%, and 27.9\\% relative improvements\nover the current state-of-the-art on CUB, AWA1, AWA2, and aPY datasets,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 08:11:46 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Verma", "Vinay Kumar", ""], ["Brahma", "Dhanajit", ""], ["Rai", "Piyush", ""]]}, {"id": "1909.04349", "submitter": "Christian Zimmermann", "authors": "Christian Zimmermann, Duygu Ceylan, Jimei Yang, Bryan Russell, Max\n  Argus and Thomas Brox", "title": "FreiHAND: A Dataset for Markerless Capture of Hand Pose and Shape from\n  Single RGB Images", "comments": "Accepted to ICCV 2019, Project page:\n  https://lmb.informatik.uni-freiburg.de/projects/freihand/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating 3D hand pose from single RGB images is a highly ambiguous problem\nthat relies on an unbiased training dataset. In this paper, we analyze\ncross-dataset generalization when training on existing datasets. We find that\napproaches perform well on the datasets they are trained on, but do not\ngeneralize to other datasets or in-the-wild scenarios. As a consequence, we\nintroduce the first large-scale, multi-view hand dataset that is accompanied by\nboth 3D hand pose and shape annotations. For annotating this real-world\ndataset, we propose an iterative, semi-automated `human-in-the-loop' approach,\nwhich includes hand fitting optimization to infer both the 3D pose and shape\nfor each sample. We show that methods trained on our dataset consistently\nperform well when tested on other datasets. Moreover, the dataset allows us to\ntrain a network that predicts the full articulated hand shape from a single RGB\nimage. The evaluation set can serve as a benchmark for articulated hand shape\nestimation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 08:29:58 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 08:37:23 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 09:04:40 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Zimmermann", "Christian", ""], ["Ceylan", "Duygu", ""], ["Yang", "Jimei", ""], ["Russell", "Bryan", ""], ["Argus", "Max", ""], ["Brox", "Thomas", ""]]}, {"id": "1909.04373", "submitter": "Zhendong Zhang", "authors": "Zhendong Zhang and Cheolkon Jung", "title": "GBDT-MO: Gradient Boosted Decision Trees for Multiple Outputs", "comments": "10 pages, 5 figtures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradient boosted decision trees (GBDTs) are widely used in machine learning,\nand the output of current GBDT implementations is a single variable. When there\nare multiple outputs, GBDT constructs multiple trees corresponding to the\noutput variables. The correlations between variables are ignored by such a\nstrategy causing redundancy of the learned tree structures. In this paper, we\npropose a general method to learn GBDT for multiple outputs, called GBDT-MO.\nEach leaf of GBDT-MO constructs predictions of all variables or a subset of\nautomatically selected variables. This is achieved by considering the summation\nof objective gains over all output variables. Moreover, we extend histogram\napproximation into multiple output case to speed up the training process.\nVarious experiments on synthetic and real-world datasets verify that GBDT-MO\nachieves outstanding performance in terms of both accuracy and training speed.\nOur codes are available on-line.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 09:48:04 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 08:29:43 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhang", "Zhendong", ""], ["Jung", "Cheolkon", ""]]}, {"id": "1909.04385", "submitter": "Aditya Ganeshan Master", "authors": "Aditya Ganeshan, B.S. Vivek, R. Venkatesh Babu", "title": "FDA: Feature Disruptive Attack", "comments": "Accepted in ICCV;19. Code Available at\n  https://github.com/BardOfCodes/fda", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though Deep Neural Networks (DNN) show excellent performance across various\ncomputer vision tasks, several works show their vulnerability to adversarial\nsamples, i.e., image samples with imperceptible noise engineered to manipulate\nthe network's prediction. Adversarial sample generation methods range from\nsimple to complex optimization techniques. Majority of these methods generate\nadversaries through optimization objectives that are tied to the pre-softmax or\nsoftmax output of the network. In this work we, (i) show the drawbacks of such\nattacks, (ii) propose two new evaluation metrics: Old Label New Rank (OLNR) and\nNew Label Old Rank (NLOR) in order to quantify the extent of damage made by an\nattack, and (iii) propose a new adversarial attack FDA: Feature Disruptive\nAttack, to address the drawbacks of existing attacks. FDA works by generating\nimage perturbation that disrupt features at each layer of the network and\ncauses deep-features to be highly corrupt. This allows FDA adversaries to\nseverely reduce the performance of deep networks. We experimentally validate\nthat FDA generates stronger adversaries than other state-of-the-art methods for\nimage classification, even in the presence of various defense measures. More\nimportantly, we show that FDA disrupts feature-representation based tasks even\nwithout access to the task-specific network or methodology. Code available at:\nhttps://github.com/BardOfCodes/fda\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:09:38 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Ganeshan", "Aditya", ""], ["Vivek", "B. S.", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "1909.04390", "submitter": "Alex Frid", "authors": "Alex Frid, Larry M. Manevitz, Norberto Eiji Nawa", "title": "Classifying the Valence of Autobiographical Memories from fMRI Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that fMRI analysis using machine learning tools are sufficient to\ndistinguish valence (i.e., positive or negative) of freely retrieved\nautobiographical memories in a cross-participant setting. Our methodology uses\nfeature selection (ReliefF) in combination with boosting methods, both applied\ndirectly to data represented in voxel space. In previous work using the same\ndata set, Nawa and Ando showed that whole-brain based classification could\nachieve above-chance classification accuracy only when both training and\ntesting data came from the same individual. In a cross-participant setting,\nclassification results were not statistically significant. Additionally, on\naverage the classification accuracy obtained when using ReliefF is\nsubstantially higher than previous results - 81% for the within-participant\nclassification, and 62% for the cross-participant classification. Furthermore,\nsince features are defined in voxel space, it is possible to show brain maps\nindicating the regions of that are most relevant in determining the results of\nthe classification. Interestingly, the voxels that were selected using the\nproposed computational pipeline seem to be consistent with current\nneurophysiological theories regarding the brain regions actively involved in\nautobiographical memory processes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:24:44 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 06:24:34 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Frid", "Alex", ""], ["Manevitz", "Larry M.", ""], ["Nawa", "Norberto Eiji", ""]]}, {"id": "1909.04402", "submitter": "Mitja Nikolaus", "authors": "Mitja Nikolaus, Mostafa Abdou, Matthew Lamm, Rahul Aralikatte and\n  Desmond Elliott", "title": "Compositional Generalization in Image Captioning", "comments": "To appear at CoNLL 2019, EMNLP", "journal-ref": "Proceedings of the 23rd Conference on Computational Natural\n  Language Learning (CoNLL), pp. 87--98, ACL, 2019", "doi": "10.18653/v1/K19-1009", "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning models are usually evaluated on their ability to describe a\nheld-out set of images, not on their ability to generalize to unseen concepts.\nWe study the problem of compositional generalization, which measures how well a\nmodel composes unseen combinations of concepts when describing images.\nState-of-the-art image captioning models show poor generalization performance\non this task. We propose a multi-task model to address the poor performance,\nthat combines caption generation and image--sentence ranking, and uses a\ndecoding mechanism that re-ranks the captions according their similarity to the\nimage. This model is substantially better at generalizing to unseen\ncombinations of concepts compared to state-of-the-art captioning models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:55:56 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 15:53:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Nikolaus", "Mitja", ""], ["Abdou", "Mostafa", ""], ["Lamm", "Matthew", ""], ["Aralikatte", "Rahul", ""], ["Elliott", "Desmond", ""]]}, {"id": "1909.04406", "submitter": "Gokularam Muthukrishnan", "authors": "Vishnu Menon, Gokularam M, Sheetal Kalyani", "title": "Subspace clustering without knowing the number of clusters: A parameter\n  free approach", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3018665", "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering, the task of clustering high dimensional data when the\ndata points come from a union of subspaces is one of the fundamental tasks in\nunsupervised machine learning. Most of the existing algorithms for this task\nrequire prior knowledge of the number of clusters along with few additional\nparameters which need to be set or tuned apriori according to the type of data\nto be clustered. In this work, a parameter free method for subspace clustering\nis proposed, where the data points are clustered on the basis of the difference\nin statistical distribution of the angles subtended by the data points within a\nsubspace and those by points belonging to different subspaces. Given an initial\nfine clustering, the proposed algorithm merges the clusters until a final\nclustering is obtained. This, unlike many existing methods, does not require\nthe number of clusters apriori. Also, the proposed algorithm does not involve\nthe use of an unknown parameter or tuning for one. %through cross validation. A\nparameter free method for producing a fine initial clustering is also\ndiscussed, making the whole process of subspace clustering parameter free. The\ncomparison of proposed algorithm's performance with that of the existing\nstate-of-the-art techniques in synthetic and real data sets, shows the\nsignificance of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 11:03:55 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 19:37:00 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 15:54:27 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Menon", "Vishnu", ""], ["M", "Gokularam", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1909.04421", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Dimitrios Athanasakis, Hamed Haddadi and Benjamin\n  Livshits", "title": "Privacy-Preserving Bandits", "comments": "13 pages, 7 figures", "journal-ref": "In Proceedings of the 3rd Conference on Machine Learning and\n  Systems (MLSys 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms~(CBAs) often rely on personal data to provide\nrecommendations. Centralized CBA agents utilize potentially sensitive data from\nrecent interactions to provide personalization to end-users. Keeping the\nsensitive data locally, by running a local agent on the user's device, protects\nthe user's privacy, however, the agent requires longer to produce useful\nrecommendations, as it does not leverage feedback from other users. This paper\nproposes a technique we call Privacy-Preserving Bandits (P2B); a system that\nupdates local agents by collecting feedback from other local agents in a\ndifferentially-private manner. Comparisons of our proposed approach with a\nnon-private, as well as a fully-private (local) system, show competitive\nperformance on both synthetic benchmarks and real-world data. Specifically, we\nobserved only a decrease of 2.6% and 3.6% in multi-label classification\naccuracy, and a CTR increase of 0.0025 in online advertising for a privacy\nbudget $\\epsilon \\approx 0.693$. These results suggest P2B is an effective\napproach to challenges arising in on-device privacy-preserving personalization.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 11:39:58 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 22:36:09 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 16:12:00 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 12:39:06 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Athanasakis", "Dimitrios", ""], ["Haddadi", "Hamed", ""], ["Livshits", "Benjamin", ""]]}, {"id": "1909.04425", "submitter": "Linilson Padovese", "authors": "O. M. Serra, F. P. R. Martins, L. R. Padovese", "title": "Automatic detection of estuarine dolphin whistles in spectrogram images", "comments": "10 pages; 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm for detecting tonal vocalizations from estuarine dolphin\n(Sotalia guianensis) specimens without interference of a human operator is\ndeveloped. The raw audio data collected from a passive monitoring sensor in the\nCanan\\'eia underwater soundscape is converted to spectrogram images, containing\nthe desired acoustic event (whistle) as a linear pattern in the images.\nDetection is a four-step method: first, ridge maps are obtained from the\nspectrogram images; second, a probabilistic Hough transform algorithm is\napplied to detect roughly linear ridges, which are adjusted to the true\ncorresponding shape of the whistles via an active contour algorithm; third,\nfeature vectors are built from the geometry of each detected curve; and fourth,\nthe detections are fed to a random forest classifier to parse out false\npositives. We develop a system capable of reliably classifying roughly 97% of\nthe characteristic patterns detected as Sotalia guianensis whistles or random\nempty detections.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:00:26 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Serra", "O. M.", ""], ["Martins", "F. P. R.", ""], ["Padovese", "L. R.", ""]]}, {"id": "1909.04436", "submitter": "Martin Shepperd", "authors": "Martin Shepperd, Yuchen Guo, Ning Li, Mahir Arzoky, Andrea Capiluppi,\n  Steve Counsell, Giuseppe Destefanis, Stephen Swift, Allan Tucker, and Leila\n  Yousefi", "title": "The Prevalence of Errors in Machine Learning Experiments", "comments": "20th International Conference on Intelligent Data Engineering and\n  Automated Learning (IDEAL), 14--16 November 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Context: Conducting experiments is central to research machine learning\nresearch to benchmark, evaluate and compare learning algorithms. Consequently\nit is important we conduct reliable, trustworthy experiments. Objective: We\ninvestigate the incidence of errors in a sample of machine learning experiments\nin the domain of software defect prediction. Our focus is simple arithmetical\nand statistical errors. Method: We analyse 49 papers describing 2456 individual\nexperimental results from a previously undertaken systematic review comparing\nsupervised and unsupervised defect prediction classifiers. We extract the\nconfusion matrices and test for relevant constraints, e.g., the marginal\nprobabilities must sum to one. We also check for multiple statistical\nsignificance testing errors. Results: We find that a total of 22 out of 49\npapers contain demonstrable errors. Of these 7 were statistical and 16 related\nto confusion matrix inconsistency (one paper contained both classes of error).\nConclusions: Whilst some errors may be of a relatively trivial nature, e.g.,\ntranscription errors their presence does not engender confidence. We strongly\nurge researchers to follow open science principles so errors can be more easily\nbe detected and corrected, thus as a community reduce this worryingly high\nerror rate with our computational experiments.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:32:00 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Shepperd", "Martin", ""], ["Guo", "Yuchen", ""], ["Li", "Ning", ""], ["Arzoky", "Mahir", ""], ["Capiluppi", "Andrea", ""], ["Counsell", "Steve", ""], ["Destefanis", "Giuseppe", ""], ["Swift", "Stephen", ""], ["Tucker", "Allan", ""], ["Yousefi", "Leila", ""]]}, {"id": "1909.04443", "submitter": "Hui-Po Wang", "authors": "Hui-Po Wang, Wen-Hsiao Peng, and Wei-Jan Ko", "title": "Learning Priors for Adversarial Autoencoders", "comments": "Accepted by APSIPA ASC, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep latent factor models choose simple priors for simplicity,\ntractability or not knowing what prior to use. Recent studies show that the\nchoice of the prior may have a profound effect on the expressiveness of the\nmodel,especially when its generative network has limited capacity. In this\npaper, we propose to learn a proper prior from data for adversarial\nautoencoders(AAEs). We introduce the notion of code generators to transform\nmanually selected simple priors into ones that can better characterize the data\ndistribution. Experimental results show that the proposed model can generate\nbetter image quality and learn better disentangled representations than AAEs in\nboth supervised and unsupervised settings. Lastly, we present its ability to do\ncross-domain translation in a text-to-image synthesis task.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:42:32 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wang", "Hui-Po", ""], ["Peng", "Wen-Hsiao", ""], ["Ko", "Wei-Jan", ""]]}, {"id": "1909.04454", "submitter": "Saber Salehkaleybar", "authors": "M. Reza Heydari, Saber Salehkaleybar, Kun Zhang", "title": "Adversarial Orthogonal Regression: Two non-Linear Regressions for Causal\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two nonlinear regression methods, named Adversarial Orthogonal\nRegression (AdOR) for additive noise models and Adversarial Orthogonal\nStructural Equation Model (AdOSE) for the general case of structural equation\nmodels. Both methods try to make the residual of regression independent from\nregressors while putting no assumption on noise distribution. In both methods,\ntwo adversarial networks are trained simultaneously where a regression network\noutputs predictions and a loss network that estimates mutual information (in\nAdOR) and KL-divergence (in AdOSE). These methods can be formulated as a\nminimax two-player game; at equilibrium, AdOR finds a deterministic map between\ninputs and output and estimates mutual information between residual and inputs,\nwhile AdOSE estimates a conditional probability distribution of output given\ninputs. The proposed methods can be used as subroutines to address several\nlearning problems in causality, such as causal direction determination (or more\ngenerally, causal structure learning) and causal model estimation. Synthetic\nand real-world experiments demonstrate that the proposed methods have a\nremarkable performance with respect to previous solutions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:59:59 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Heydari", "M. Reza", ""], ["Salehkaleybar", "Saber", ""], ["Zhang", "Kun", ""]]}, {"id": "1909.04469", "submitter": "Anoop Katti", "authors": "Christian Reisswig, Anoop R Katti, Marco Spinaci, Johannes H\\\"ohne", "title": "Chargrid-OCR: End-to-end Trainable Optical Character Recognition for\n  Printed Documents using Instance Segmentation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end trainable approach for Optical Character Recognition\n(OCR) on printed documents. Specifically, we propose a model that predicts a) a\ntwo-dimensional character grid (\\emph{chargrid}) representation of a document\nimage as a semantic segmentation task and b) character boxes for delineating\ncharacter instances as an object detection task. For training the model, we\nbuild two large-scale datasets without resorting to any manual annotation -\nsynthetic documents with clean labels and real documents with noisy labels. We\ndemonstrate experimentally that our method, trained on the combination of these\ndatasets, (i) outperforms previous state-of-the-art approaches in accuracy (ii)\nis easily parallelizable on GPU and is, therefore, significantly faster and\n(iii) is easy to train and adapt to a new domain.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 13:30:55 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 09:07:54 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 16:21:15 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2020 12:44:54 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Reisswig", "Christian", ""], ["Katti", "Anoop R", ""], ["Spinaci", "Marco", ""], ["H\u00f6hne", "Johannes", ""]]}, {"id": "1909.04474", "submitter": "Sabine Wieluch", "authors": "Sabine Wieluch, Dr. Friedhelm Schwenker", "title": "Dropout Induced Noise for Co-Creative GAN Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates how Dropout can be used in Generative Adversarial\nNetworks to generate multiple different outputs to one input. This method is\nthought as an alternative to latent space exploration, especially if\nconstraints in the input should be preserved, like in A-to-B translation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 13:38:56 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wieluch", "Sabine", ""], ["Schwenker", "Dr. Friedhelm", ""]]}, {"id": "1909.04491", "submitter": "Zi-Jing Liu", "authors": "Zijing Liu, Mauricio Barahona", "title": "Graph-based data clustering via multiscale community detection", "comments": "16 pages, 5 figures", "journal-ref": "Appl Netw Sci (2020) 5: 3", "doi": "10.1007/s41109-019-0248-7", "report-no": null, "categories": "cs.IR cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a graph-theoretical approach to data clustering, which combines\nthe creation of a graph from the data with Markov Stability, a multiscale\ncommunity detection framework. We show how the multiscale capabilities of the\nmethod allow the estimation of the number of clusters, as well as alleviating\nthe sensitivity to the parameters in graph construction. We use both synthetic\nand benchmark real datasets to compare and evaluate several graph construction\nmethods and clustering algorithms, and show that multiscale graph-based\nclustering achieves improved performance compared to popular clustering methods\nwithout the need to set externally the number of clusters.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 10:44:26 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 10:21:45 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Liu", "Zijing", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1909.04495", "submitter": "Yulun Hsieh", "authors": "Yu-Lun Hsieh and Minhao Cheng and Da-Cheng Juan and Wei Wei and\n  Wen-Lian Hsu and Cho-Jui Hsieh", "title": "Natural Adversarial Sentence Generation with Gradient-based Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work proposes a novel algorithm to generate natural language adversarial\ninput for text classification models, in order to investigate the robustness of\nthese models. It involves applying gradient-based perturbation on the sentence\nembeddings that are used as the features for the classifier, and learning a\ndecoder for generation. We employ this method to a sentiment analysis model and\nverify its effectiveness in inducing incorrect predictions by the model. We\nalso conduct quantitative and qualitative analysis on these examples and\ndemonstrate that our approach can generate more natural adversaries. In\naddition, it can be used to successfully perform black-box attacks, which\ninvolves attacking other existing models whose parameters are not known. On a\npublic sentiment analysis API, the proposed method introduces a 20% relative\ndecrease in average accuracy and 74% relative increase in absolute error.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 07:22:01 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Hsieh", "Yu-Lun", ""], ["Cheng", "Minhao", ""], ["Juan", "Da-Cheng", ""], ["Wei", "Wei", ""], ["Hsu", "Wen-Lian", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1909.04497", "submitter": "Qiong Wu", "authors": "Qiong Wu, Zheng Zhang, Andrea Pizzoferrato, Mihai Cucuringu, Zhenming\n  Liu", "title": "A Deep Learning Framework for Pricing Financial Instruments", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an integrated deep learning architecture for the stock movement\nprediction. Our architecture simultaneously leverages all available alpha\nsources. The sources include technical signals, financial news signals, and\ncross-sectional signals. Our architecture possesses three main properties.\nFirst, our architecture eludes overfitting issues. Although we consume a large\nnumber of technical signals but has better generalization properties than\nlinear models. Second, our model effectively captures the interactions between\nsignals from different categories. Third, our architecture has low computation\ncost. We design a graph-based component that extracts cross-sectional\ninteractions which circumvents usage of SVD that's needed in standard models.\nExperimental results on the real-world stock market show that our approach\noutperforms the existing baselines. Meanwhile, the results from different\ntrading simulators demonstrate that we can effectively monetize the signals.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 21:53:47 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Wu", "Qiong", ""], ["Zhang", "Zheng", ""], ["Pizzoferrato", "Andrea", ""], ["Cucuringu", "Mihai", ""], ["Liu", "Zhenming", ""]]}, {"id": "1909.04499", "submitter": "Jason Lee", "authors": "Jason Lee, Kyunghyun Cho, Douwe Kiela", "title": "Countering Language Drift via Visual Grounding", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergent multi-agent communication protocols are very different from natural\nlanguage and not easily interpretable by humans. We find that agents that were\ninitially pretrained to produce natural language can also experience\ndetrimental language drift: when a non-linguistic reward is used in a\ngoal-based task, e.g. some scalar success metric, the communication protocol\nmay easily and radically diverge from natural language. We recast translation\nas a multi-agent communication game and examine auxiliary training constraints\nfor their effectiveness in mitigating language drift. We show that a\ncombination of syntactic (language model likelihood) and semantic (visual\ngrounding) constraints gives the best communication performance, allowing\npre-trained agents to retain English syntax while learning to accurately convey\nthe intended meaning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 14:05:28 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Lee", "Jason", ""], ["Cho", "Kyunghyun", ""], ["Kiela", "Douwe", ""]]}, {"id": "1909.04501", "submitter": "Benedikt Pf\\\"ulb", "authors": "Benedikt Pf\\\"ulb, Christoph Hardegen, Alexander Gepperth and Sebastian\n  Rieger", "title": "A Study of Deep Learning for Network Traffic Data Forecasting", "comments": "16 pages, 12 figures, 28th International Conference on Artificial\n  Neural Networks (ICANN 2019)", "journal-ref": null, "doi": "10.1007/978-3-030-30490-4_40", "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study of deep learning applied to the domain of network traffic\ndata forecasting. This is a very important ingredient for network traffic\nengineering, e.g., intelligent routing, which can optimize network performance,\nespecially in large networks. In a nutshell, we wish to predict, in advance,\nthe bit rate for a transmission, based on low-dimensional connection metadata\n(\"flows\") that is available whenever a communication is initiated. Our study\nhas several genuinely new points: First, it is performed on a large dataset\n(~50 million flows), which requires a new training scheme that operates on\nsuccessive blocks of data since the whole dataset is too large for in-memory\nprocessing. Additionally, we are the first to propose and perform a more\nfine-grained prediction that distinguishes between low, medium and high bit\nrates instead of just \"mice\" and \"elephant\" flows. Lastly, we apply\nstate-of-the-art visualization and clustering techniques to flow data and show\nthat visualizations are insightful despite the heterogeneous and non-metric\nnature of the data. We developed a processing pipeline to handle the highly\nnon-trivial acquisition process and allow for proper data preprocessing to be\nable to apply DNNs to network traffic data. We conduct DNN hyper-parameter\noptimization as well as feature selection experiments, which clearly show that\nfine-grained network traffic forecasting is feasible, and that domain-dependent\ndata enrichment and augmentation strategies can improve results. An outlook\nabout the fundamental challenges presented by network traffic analysis (high\ndata throughput, unbalanced and dynamic classes, changing statistics, outlier\ndetection) concludes the article.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 14:09:31 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 08:15:22 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Pf\u00fclb", "Benedikt", ""], ["Hardegen", "Christoph", ""], ["Gepperth", "Alexander", ""], ["Rieger", "Sebastian", ""]]}, {"id": "1909.04503", "submitter": "Arquimedes Canedo", "authors": "Arquimedes Canedo and Palash Goyal and Di Huang and Amit Pandey and\n  Gustavo Quiros", "title": "ArduCode: Predictive Framework for Automation Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automation engineering is the task of integrating, via software, various\nsensors, actuators, and controls for automating a real-world process. Today,\nautomation engineering is supported by a suite of software tools including\nintegrated development environments (IDE), hardware configurators, compilers,\nand runtimes. These tools focus on the automation code itself, but leave the\nautomation engineer unassisted in their decision making. This can lead to\nincreased time for software development because of imperfections in decision\nmaking leading to multiple iterations between software and hardware. To address\nthis, this paper defines multiple challenges often faced in automation\nengineering and propose solutions using machine learning to assist engineers\ntackle such challenges. We show that machine learning can be leveraged to\nassist the automation engineer in classifying automation, finding similar code\nsnippets, and reasoning about the hardware selection of sensors and actuators.\nWe validate our architecture on two real datasets consisting of 2,927 Arduino\nprojects, and 683 Programmable Logic Controller (PLC) projects. Our results\nshow that paragraph embedding techniques can be utilized to classify automation\nusing code snippets with precision close to human annotation, giving an\nF1-score of 72%. Further, we show that such embedding techniques can help us\nfind similar code snippets with high accuracy. Finally, we use autoencoder\nmodels for hardware recommendation and achieve a p@3 of 0.79 and p@5 of 0.95.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 20:19:05 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 07:53:53 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 17:12:44 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 01:09:08 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Canedo", "Arquimedes", ""], ["Goyal", "Palash", ""], ["Huang", "Di", ""], ["Pandey", "Amit", ""], ["Quiros", "Gustavo", ""]]}, {"id": "1909.04509", "submitter": "Stephen Tridgell", "authors": "Stephen Tridgell, Martin Kumm, Martin Hardieck, David Boland, Duncan\n  Moss, Peter Zipf, Philip H.W. Leong", "title": "Unrolling Ternary Neural Networks", "comments": "Accepted in TRETS", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of neural networks for large scale or real-time\napplications necessitates hardware acceleration. Most approaches assume that\nthe network architecture and parameters are unknown at design time, permitting\nusage in a large number of applications. This paper demonstrates, for the case\nwhere the neural network architecture and ternary weight values are known a\npriori, that extremely high throughput implementations of neural network\ninference can be made by customising the datapath and routing to remove\nunnecessary computations and data movement. This approach is ideally suited to\nFPGA implementations as a specialized implementation of a trained network\nimproves efficiency while still retaining generality with the reconfigurability\nof an FPGA. A VGG style network with ternary weights and fixed point\nactivations is implemented for the CIFAR10 dataset on Amazon's AWS F1 instance.\nThis paper demonstrates how to remove 90% of the operations in convolutional\nlayers by exploiting sparsity and compile-time optimizations. The\nimplementation in hardware achieves 90.9 +/- 0.1% accuracy and 122 k frames per\nsecond, with a latency of only 29 us, which is the fastest CNN inference\nimplementation reported so far on an FPGA.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 05:03:06 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Tridgell", "Stephen", ""], ["Kumm", "Martin", ""], ["Hardieck", "Martin", ""], ["Boland", "David", ""], ["Moss", "Duncan", ""], ["Zipf", "Peter", ""], ["Leong", "Philip H. W.", ""]]}, {"id": "1909.04525", "submitter": "Andre Pacheco", "authors": "Andre G. C. Pacheco and Abder-Rahman Ali and Thomas Trappenberg", "title": "Skin cancer detection based on deep learning and entropy to detect\n  outlier samples", "comments": "3rd and 4th places in tasks 1 and 2 respectively, at ISIC challenge\n  2019 @ MICCAI workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe our methods that achieved the 3rd and 4th places in tasks 1 and\n2, respectively, at ISIC challenge 2019. The goal of this challenge is to\nprovide the diagnostic for skin cancer using images and meta-data. There are\nnine classes in the dataset, nonetheless, one of them is an outlier and is not\npresent on it. To tackle the challenge, we apply an ensemble of classifiers,\nwhich has 13 convolutional neural networks (CNN), we develop two approaches to\nhandle the outlier class and we propose a straightforward method to use the\nmeta-data along with the images. Throughout this report, we detail each\nmethodology and parameters to make it easy to replicate our work. The results\nobtained are in accordance with the previous challenges and the approaches to\ndetect the outlier class and to address the meta-data seem to be work properly.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 14:36:16 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 22:45:19 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Pacheco", "Andre G. C.", ""], ["Ali", "Abder-Rahman", ""], ["Trappenberg", "Thomas", ""]]}, {"id": "1909.04532", "submitter": "Haibo Yang", "authors": "Haibo Yang, Xin Zhang, Minghong Fang, and Jia Liu", "title": "Byzantine-Resilient Stochastic Gradient Descent for Distributed\n  Learning: A Lipschitz-Inspired Coordinate-wise Median Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the resilience of distributed algorithms based on\nstochastic gradient descent (SGD) in distributed learning with potentially\nByzantine attackers, who could send arbitrary information to the parameter\nserver to disrupt the training process. Toward this end, we propose a new\nLipschitz-inspired coordinate-wise median approach (LICM-SGD) to mitigate\nByzantine attacks. We show that our LICM-SGD algorithm can resist up to half of\nthe workers being Byzantine attackers, while still converging almost surely to\na stationary region in non-convex settings. Also, our LICM-SGD method does not\nrequire any information about the number of attackers and the Lipschitz\nconstant, which makes it attractive for practical implementations. Moreover,\nour LICM-SGD method enjoys the optimal $O(md)$ computational time-complexity in\nthe sense that the time-complexity is the same as that of the standard SGD\nunder no attacks. We conduct extensive experiments to show that our LICM-SGD\nalgorithm consistently outperforms existing methods in training multi-class\nlogistic regression and convolutional neural networks with MNIST and CIFAR-10\ndatasets. In our experiments, LICM-SGD also achieves a much faster running time\nthanks to its low computational time-complexity.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 14:45:21 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Yang", "Haibo", ""], ["Zhang", "Xin", ""], ["Fang", "Minghong", ""], ["Liu", "Jia", ""]]}, {"id": "1909.04538", "submitter": "H{\\aa}kon Hukkel{\\aa}s", "authors": "H{\\aa}kon Hukkel{\\aa}s, Rudolf Mester and Frank Lindseth", "title": "DeepPrivacy: A Generative Adversarial Network for Face Anonymization", "comments": "Accepted to ISVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a novel architecture which is able to automatically anonymize\nfaces in images while retaining the original data distribution. We ensure total\nanonymization of all faces in an image by generating images exclusively on\nprivacy-safe information. Our model is based on a conditional generative\nadversarial network, generating images considering the original pose and image\nbackground. The conditional information enables us to generate highly realistic\nfaces with a seamless transition between the generated face and the existing\nbackground. Furthermore, we introduce a diverse dataset of human faces,\nincluding unconventional poses, occluded faces, and a vast variability in\nbackgrounds. Finally, we present experimental results reflecting the capability\nof our model to anonymize images while preserving the data distribution, making\nthe data suitable for further training of deep learning models. As far as we\nknow, no other solution has been proposed that guarantees the anonymization of\nfaces while generating realistic images.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 14:52:24 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Hukkel\u00e5s", "H\u00e5kon", ""], ["Mester", "Rudolf", ""], ["Lindseth", "Frank", ""]]}, {"id": "1909.04548", "submitter": "Minsoo Rhu", "authors": "Yujeong Choi, Minsoo Rhu", "title": "PREMA: A Predictive Multi-task Scheduling Algorithm For Preemptible\n  Neural Processing Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To amortize cost, cloud vendors providing DNN acceleration as a service to\nend-users employ consolidation and virtualization to share the underlying\nresources among multiple DNN service requests. This paper makes a case for a\n\"preemptible\" neural processing unit (NPU) and a \"predictive\" multi-task\nscheduler to meet the latency demands of high-priority inference while\nmaintaining high throughput. We evaluate both the mechanisms that enable NPUs\nto be preemptible and the policies that utilize them to meet scheduling\nobjectives. We show that preemptive NPU multi-tasking can achieve an average\n7.8x, 1.4x, and 4.8x improvement in latency, throughput, and SLA satisfaction,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 13:34:31 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Choi", "Yujeong", ""], ["Rhu", "Minsoo", ""]]}, {"id": "1909.04567", "submitter": "Eyy\\\"ub Sari", "authors": "Ramchalam Kinattinkara Ramakrishnan and Eyy\\\"ub Sari, Vahid Partovi\n  Nia", "title": "Differentiable Mask for Pruning Convolutional and Recurrent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning is one of the most effective model reduction techniques. Deep\nnetworks require massive computation and such models need to be compressed to\nbring them on edge devices. Most existing pruning techniques are focused on\nvision-based models like convolutional networks, while text-based models are\nstill evolving. The emergence of multi-modal multi-task learning calls for a\ngeneral method that works on vision and text architectures simultaneously. We\nintroduce a \\emph{differentiable mask}, that induces sparsity on various\ngranularity to fill this gap. We apply our method successfully to prune\nweights, filters, subnetwork of a convolutional architecture, as well as nodes\nof a recurrent network.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:25:43 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 14:03:18 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Ramakrishnan", "Ramchalam Kinattinkara", ""], ["Sari", "Eyy\u00fcb", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "1909.04568", "submitter": "Henry Chai", "authors": "Shali Jiang, Henry Chai, Javier Gonzalez, Roman Garnett", "title": "BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design", "comments": "13 pages, 4 figures, 6 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite-horizon sequential experimental design (SED) arises naturally in many\ncontexts, including hyperparameter tuning in machine learning among more\ntraditional settings. Computing the optimal policy for such problems requires\nsolving Bellman equations, which are generally intractable. Most existing work\nresorts to severely myopic approximations by limiting the decision horizon to\nonly a single time-step, which can underweight exploration in favor of\nexploitation. We present BINOCULARS: Batch-Informed NOnmyopic Choices, Using\nLong-horizons for Adaptive, Rapid SED, a general framework for deriving\nefficient, nonmyopic approximations to the optimal experimental policy. Our key\nidea is simple and surprisingly effective: we first compute a one-step optimal\nbatch of experiments, then select a single point from this batch to evaluate.\nWe realize BINOCULARS for Bayesian optimization and Bayesian quadrature -- two\nnotable SED problems with radically different objectives -- and demonstrate\nthat BINOCULARS significantly outperforms myopic alternatives in real-world\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:26:55 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 03:21:42 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 06:23:53 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Jiang", "Shali", ""], ["Chai", "Henry", ""], ["Gonzalez", "Javier", ""], ["Garnett", "Roman", ""]]}, {"id": "1909.04570", "submitter": "Dominik Linzner", "authors": "Dominik Linzner, Michael Schmidt and Heinz Koeppl", "title": "Scalable Structure Learning of Continuous-Time Bayesian Networks from\n  Incomplete Data", "comments": "Accepted at NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous-time Bayesian Networks (CTBNs) represent a compact yet powerful\nframework for understanding multivariate time-series data. Given complete data,\nparameters and structure can be estimated efficiently in closed-form. However,\nif data is incomplete, the latent states of the CTBN have to be estimated by\nlaboriously simulating the intractable dynamics of the assumed CTBN. This is a\nproblem, especially for structure learning tasks, where this has to be done for\neach element of a super-exponentially growing set of possible structures. In\norder to circumvent this notorious bottleneck, we develop a novel\ngradient-based approach to structure learning. Instead of sampling and scoring\nall possible structures individually, we assume the generator of the CTBN to be\ncomposed as a mixture of generators stemming from different structures. In this\nframework, structure learning can be performed via a gradient-based\noptimization of mixture weights. We combine this approach with a new\nvariational method that allows for a closed-form calculation of this mixture\nmarginal likelihood. We show the scalability of our method by learning\nstructures of previously inaccessible sizes from synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:29:46 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 08:28:06 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 09:16:13 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Linzner", "Dominik", ""], ["Schmidt", "Michael", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1909.04588", "submitter": "Qinghui Liu", "authors": "Qinghui Liu, Michael Kampffmeyer, Robert Jenssen, Arnt-B{\\o}rre\n  Salberg", "title": "Road Mapping In LiDAR Images Using A Joint-Task Dense Dilated\n  Convolutions Merging Network", "comments": "IGARSS 2019. arXiv admin note: text overlap with arXiv:1908.11799", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It is important, but challenging, for the forest industry to accurately map\nroads which are used for timber transport by trucks. In this work, we propose a\nDense Dilated Convolutions Merging Network (DDCM-Net) to detect these roads in\nlidar images. The DDCM-Net can effectively recognize multi-scale and complex\nshaped roads with similar texture and colors, and also is shown to have\nsuperior performance over existing methods. To further improve its ability to\naccurately infer categories of roads, we propose the use of a joint-task\nlearning strategy that utilizes two auxiliary output branches, i.e, multi-class\nclassification and binary segmentation, joined with the main output of\nfull-class segmentation. This pushes the network towards learning more robust\nrepresentations that are expected to boost the ultimate performance of the main\ntask. In addition, we introduce an iterative-random-weighting method to\nautomatically weigh the joint losses for auxiliary tasks. This can avoid the\ndifficult and expensive process of tuning the weights of each task's loss by\nhand. The experiments demonstrate that our proposed joint-task DDCM-Net can\nachieve better performance with fewer parameters and higher computational\nefficiency than previous state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 16:35:55 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Liu", "Qinghui", ""], ["Kampffmeyer", "Michael", ""], ["Jenssen", "Robert", ""], ["Salberg", "Arnt-B\u00f8rre", ""]]}, {"id": "1909.04596", "submitter": "Mehul S. Raval", "authors": "Rupal Agravat, Mehul S Raval", "title": "Prediction of Overall Survival of Brain Tumor Patients", "comments": "5 pages, IEEE TENCON 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated brain tumor segmentation plays an important role in the diagnosis\nand prognosis of the patient. In addition, features from the tumorous brain\nhelp in predicting patients overall survival. The main focus of this paper is\nto segment tumor from BRATS 2018 benchmark dataset and use age, shape and\nvolumetric features to predict overall survival of patients. The random forest\nclassifier achieves overall survival accuracy of 59% on the test dataset and\n67% on the dataset with resection status as gross total resection. The proposed\napproach uses fewer features but achieves better accuracy than state of the art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 16:09:12 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Agravat", "Rupal", ""], ["Raval", "Mehul S", ""]]}, {"id": "1909.04605", "submitter": "Jose Rodrigues Jr", "authors": "Jose F Rodrigues-Jr, Gabriel Spadon, Bruno Brandoli, Sihem Amer-Yahia", "title": "Patient trajectory prediction in the Mimic-III dataset, challenges and\n  pitfalls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated medical prognosis has gained interest as artificial intelligence\nevolves and the potential for computer-aided medicine becomes evident.\nNevertheless, it is challenging to design an effective system that, given a\npatient's medical history, is able to predict probable future conditions.\nPrevious works, mostly carried out over private datasets, have tackled the\nproblem by using artificial neural network architectures that cannot deal with\nlow-cardinality datasets, or by means of non-generalizable inference\napproaches. We introduce a Deep Learning architecture whose design results from\nan intensive experimental process. The final architecture is based on two\nparallel Minimal Gated Recurrent Unit networks working in bi-directional\nmanner, which was extensively tested with the open-access Mimic-III dataset.\nOur results demonstrate significant improvements in automated medical\nprognosis, as measured with Recall@k. We summarize our experience as a set of\nrelevant insights for the design of Deep Learning architectures. Our work\nimproves the performance of computer-aided medicine and can serve as a guide in\ndesigning artificial neural networks used in prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 16:30:24 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 12:05:15 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 08:45:00 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 13:07:08 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Rodrigues-Jr", "Jose F", ""], ["Spadon", "Gabriel", ""], ["Brandoli", "Bruno", ""], ["Amer-Yahia", "Sihem", ""]]}, {"id": "1909.04607", "submitter": "Vivek Veeriah", "authors": "Vivek Veeriah, Matteo Hessel, Zhongwen Xu, Richard Lewis, Janarthanan\n  Rajendran, Junhyuk Oh, Hado van Hasselt, David Silver, Satinder Singh", "title": "Discovery of Useful Questions as Auxiliary Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arguably, intelligent agents ought to be able to discover their own questions\nso that in learning answers for them they learn unanticipated useful knowledge\nand skills; this departs from the focus in much of machine learning on agents\nlearning answers to externally defined questions. We present a novel method for\na reinforcement learning (RL) agent to discover questions formulated as general\nvalue functions or GVFs, a fairly rich form of knowledge representation.\nSpecifically, our method uses non-myopic meta-gradients to learn GVF-questions\nsuch that learning answers to them, as an auxiliary task, induces useful\nrepresentations for the main task faced by the RL agent. We demonstrate that\nauxiliary tasks based on the discovered GVFs are sufficient, on their own, to\nbuild representations that support main task learning, and that they do so\nbetter than popular hand-designed auxiliary tasks from the literature.\nFurthermore, we show, in the context of Atari 2600 videogames, how such\nauxiliary tasks, meta-learned alongside the main task, can improve the data\nefficiency of an actor-critic agent.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 16:30:54 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Veeriah", "Vivek", ""], ["Hessel", "Matteo", ""], ["Xu", "Zhongwen", ""], ["Lewis", "Richard", ""], ["Rajendran", "Janarthanan", ""], ["Oh", "Junhyuk", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""], ["Singh", "Satinder", ""]]}, {"id": "1909.04625", "submitter": "Ethan Wilcox", "authors": "Aixiu An, Peng Qian, Ethan Wilcox, and Roger Levy", "title": "Representation of Constituents in Neural Language Models: Coordination\n  Phrase as a Case Study", "comments": "To appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural language models have achieved state-of-the-art performances on many\nNLP tasks, and recently have been shown to learn a number of\nhierarchically-sensitive syntactic dependencies between individual words.\nHowever, equally important for language processing is the ability to combine\nwords into phrasal constituents, and use constituent-level features to drive\ndownstream expectations. Here we investigate neural models' ability to\nrepresent constituent-level features, using coordinated noun phrases as a case\nstudy. We assess whether different neural language models trained on English\nand French represent phrase-level number and gender features, and use those\nfeatures to drive downstream expectations. Our results suggest that models use\na linear combination of NP constituent number to drive CoordNP/verb number\nagreement. This behavior is highly regular and even sensitive to local\nsyntactic context, however it differs crucially from observed human behavior.\nModels have less success with gender agreement. Models trained on large corpora\nperform best, and there is no obvious advantage for models trained using\nexplicit syntactic supervision.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 17:02:15 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["An", "Aixiu", ""], ["Qian", "Peng", ""], ["Wilcox", "Ethan", ""], ["Levy", "Roger", ""]]}, {"id": "1909.04630", "submitter": "Aravind Rajeswaran", "authors": "Aravind Rajeswaran, Chelsea Finn, Sham Kakade, Sergey Levine", "title": "Meta-Learning with Implicit Gradients", "comments": "NeurIPS 2019. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core capability of intelligent systems is the ability to quickly learn new\ntasks by drawing on prior experience. Gradient (or optimization) based\nmeta-learning has recently emerged as an effective approach for few-shot\nlearning. In this formulation, meta-parameters are learned in the outer loop,\nwhile task-specific models are learned in the inner-loop, by using only a small\namount of data from the current task. A key challenge in scaling these\napproaches is the need to differentiate through the inner loop learning\nprocess, which can impose considerable computational and memory burdens. By\ndrawing upon implicit differentiation, we develop the implicit MAML algorithm,\nwhich depends only on the solution to the inner level optimization and not the\npath taken by the inner loop optimizer. This effectively decouples the\nmeta-gradient computation from the choice of inner loop optimizer. As a result,\nour approach is agnostic to the choice of inner loop optimizer and can\ngracefully handle many gradient steps without vanishing gradients or memory\nconstraints. Theoretically, we prove that implicit MAML can compute accurate\nmeta-gradients with a memory footprint that is, up to small constant factors,\nno more than that which is required to compute a single inner loop gradient and\nat no overall increase in the total computational cost. Experimentally, we show\nthat these benefits of implicit MAML translate into empirical gains on few-shot\nimage recognition benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 17:14:14 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Rajeswaran", "Aravind", ""], ["Finn", "Chelsea", ""], ["Kakade", "Sham", ""], ["Levine", "Sergey", ""]]}, {"id": "1909.04648", "submitter": "Kirk Swanson", "authors": "Kirk Swanson, Shubhendu Trivedi, Joshua Lequieu, Kyle Swanson, Risi\n  Kondor", "title": "Deep Learning for Automated Classification and Characterization of\n  Amorphous Materials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cond-mat.dis-nn cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is difficult to quantify structure-property relationships and to identify\nstructural features of complex materials. The characterization of amorphous\nmaterials is especially challenging because their lack of long-range order\nmakes it difficult to define structural metrics. In this work, we apply deep\nlearning algorithms to accurately classify amorphous materials and characterize\ntheir structural features. Specifically, we show that convolutional neural\nnetworks and message passing neural networks can classify two-dimensional\nliquids and liquid-cooled glasses from molecular dynamics simulations with\ngreater than 0.98 AUC, with no a priori assumptions about local particle\nrelationships, even when the liquids and glasses are prepared at the same\ninherent structure energy. Furthermore, we demonstrate that message passing\nneural networks surpass convolutional neural networks in this context in both\naccuracy and interpretability. We extract a clear interpretation of how message\npassing neural networks evaluate liquid and glass structures by using a\nself-attention mechanism. Using this interpretation, we derive three novel\nstructural metrics that accurately characterize glass formation. The methods\npresented here provide us with a procedure to identify important structural\nfeatures in materials that could be missed by standard techniques and give us a\nunique insight into how these neural networks process data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 17:49:04 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Swanson", "Kirk", ""], ["Trivedi", "Shubhendu", ""], ["Lequieu", "Joshua", ""], ["Swanson", "Kyle", ""], ["Kondor", "Risi", ""]]}, {"id": "1909.04653", "submitter": "Tianyi Liu", "authors": "Tianyi Liu, Minshuo Chen, Mo Zhou, Simon S. Du, Enlu Zhou and Tuo Zhao", "title": "Towards Understanding the Importance of Shortcut Connections in Residual\n  Networks", "comments": "Thirty-third Conference on Neural Information Processing Systems,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual Network (ResNet) is undoubtedly a milestone in deep learning. ResNet\nis equipped with shortcut connections between layers, and exhibits efficient\ntraining using simple first order algorithms. Despite of the great empirical\nsuccess, the reason behind is far from being well understood. In this paper, we\nstudy a two-layer non-overlapping convolutional ResNet. Training such a network\nrequires solving a non-convex optimization problem with a spurious local\noptimum. We show, however, that gradient descent combined with proper\nnormalization, avoids being trapped by the spurious local optimum, and\nconverges to a global optimum in polynomial time, when the weight of the first\nlayer is initialized at 0, and that of the second layer is initialized\narbitrarily in a ball. Numerical experiments are provided to support our\ntheory.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 17:55:03 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 01:49:50 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 15:55:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liu", "Tianyi", ""], ["Chen", "Minshuo", ""], ["Zhou", "Mo", ""], ["Du", "Simon S.", ""], ["Zhou", "Enlu", ""], ["Zhao", "Tuo", ""]]}, {"id": "1909.04697", "submitter": "Zheyu Yan", "authors": "Zheyu Yan, Yiyu Shi, Wang Liao, Masanori Hashimoto, Xichuan Zhou,\n  Cheng Zhuo", "title": "When Single Event Upset Meets Deep Neural Networks: Observations,\n  Explorations, and Remedies", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network has proved its potential in various perception tasks and\nhence become an appealing option for interpretation and data processing in\nsecurity sensitive systems. However, security-sensitive systems demand not only\nhigh perception performance, but also design robustness under various\ncircumstances. Unlike prior works that study network robustness from software\nlevel, we investigate from hardware perspective about the impact of Single\nEvent Upset (SEU) induced parameter perturbation (SIPP) on neural networks. We\nsystematically define the fault models of SEU and then provide the definition\nof sensitivity to SIPP as the robustness measure for the network. We are then\nable to analytically explore the weakness of a network and summarize the key\nfindings for the impact of SIPP on different types of bits in a floating point\nparameter, layer-wise robustness within the same network and impact of network\ndepth. Based on those findings, we propose two remedy solutions to protect DNNs\nfrom SIPPs, which can mitigate accuracy degradation from 28% to 0.27% for\nResNet with merely 0.24-bit SRAM area overhead per parameter.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 18:24:43 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Yan", "Zheyu", ""], ["Shi", "Yiyu", ""], ["Liao", "Wang", ""], ["Hashimoto", "Masanori", ""], ["Zhou", "Xichuan", ""], ["Zhuo", "Cheng", ""]]}, {"id": "1909.04702", "submitter": "James Foulds", "authors": "Kamrun Naher Keya, Yannis Papanikolaou, James R. Foulds", "title": "Neural Embedding Allocation: Distributed Representations of Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding models such as the skip-gram learn vector representations of\nwords' semantic relationships, and document embedding models learn similar\nrepresentations for documents. On the other hand, topic models provide latent\nrepresentations of the documents' topical themes. To get the benefits of these\nrepresentations simultaneously, we propose a unifying algorithm, called neural\nembedding allocation (NEA), which deconstructs topic models into interpretable\nvector-space embeddings of words, topics, documents, authors, and so on, by\nlearning neural embeddings to mimic the topic models. We showcase NEA's\neffectiveness and generality on LDA, author-topic models and the recently\nproposed mixed membership skip gram topic model and achieve better performance\nwith the embeddings compared to several state-of-the-art models. Furthermore,\nwe demonstrate that using NEA to smooth out the topics improves coherence\nscores over the original topic models when the number of topics is large.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 18:39:26 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Keya", "Kamrun Naher", ""], ["Papanikolaou", "Yannis", ""], ["Foulds", "James R.", ""]]}, {"id": "1909.04711", "submitter": "David Gagne", "authors": "David John Gagne II, Hannah M. Christensen, Aneesh C. Subramanian, and\n  Adam H. Monahan", "title": "Machine Learning for Stochastic Parameterization: Generative Adversarial\n  Networks in the Lorenz '96 Model", "comments": "Submitted to Journal of Advances in Modeling Earth Systems (JAMES)", "journal-ref": null, "doi": "10.1029/2019MS001896", "report-no": null, "categories": "physics.ao-ph cs.LG nlin.CD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic parameterizations account for uncertainty in the representation of\nunresolved sub-grid processes by sampling from the distribution of possible\nsub-grid forcings. Some existing stochastic parameterizations utilize\ndata-driven approaches to characterize uncertainty, but these approaches\nrequire significant structural assumptions that can limit their scalability.\nMachine learning models, including neural networks, are able to represent a\nwide range of distributions and build optimized mappings between a large number\nof inputs and sub-grid forcings. Recent research on machine learning\nparameterizations has focused only on deterministic parameterizations. In this\nstudy, we develop a stochastic parameterization using the generative\nadversarial network (GAN) machine learning framework. The GAN stochastic\nparameterization is trained and evaluated on output from the Lorenz '96 model,\nwhich is a common baseline model for evaluating both parameterization and data\nassimilation techniques. We evaluate different ways of characterizing the input\nnoise for the model and perform model runs with the GAN parameterization at\nweather and climate timescales. Some of the GAN configurations perform better\nthan a baseline bespoke parameterization at both timescales, and the networks\nclosely reproduce the spatio-temporal correlations and regimes of the Lorenz\n'96 system. We also find that in general those models which produce skillful\nforecasts are also associated with the best climate simulations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 19:19:14 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Gagne", "David John", "II"], ["Christensen", "Hannah M.", ""], ["Subramanian", "Aneesh C.", ""], ["Monahan", "Adam H.", ""]]}, {"id": "1909.04715", "submitter": "Ahmed Khaled", "authors": "Ahmed Khaled and Konstantin Mishchenko and Peter Richt\\'arik", "title": "First Analysis of Local GD on Heterogeneous Data", "comments": "NeurIPS 2019 Workshop on Federated Learning for Data Privacy and\n  Confidentiality. 11 pages, 4 lemmas, 1 theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first convergence analysis of local gradient descent for\nminimizing the average of smooth and convex but otherwise arbitrary functions.\nProblems of this form and local gradient descent as a solution method are of\nimportance in federated learning, where each function is based on private data\nstored by a user on a mobile device, and the data of different users can be\narbitrarily heterogeneous. We show that in a low accuracy regime, the method\nhas the same communication complexity as gradient descent.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 19:46:13 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 13:25:03 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Khaled", "Ahmed", ""], ["Mishchenko", "Konstantin", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1909.04716", "submitter": "Ahmed Khaled", "authors": "Ahmed Khaled and Peter Richt\\'arik", "title": "Gradient Descent with Compressed Iterates", "comments": "NeurIPS 2019 Workshop on Federated Learning for Data Privacy and\n  Confidentiality. 10 pages, 1 algorithm, 1 theorem, 5 lemmas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a new type of stochastic first order method: gradient\ndescent with compressed iterates (GDCI). GDCI in each iteration first\ncompresses the current iterate using a lossy randomized compression technique,\nand subsequently takes a gradient step. This method is a distillation of a key\ningredient in the current practice of federated learning, where a model needs\nto be compressed by a mobile device before it is sent back to a server for\naggregation. Our analysis provides a step towards closing the gap between the\ntheory and practice of federated learning, and opens the possibility for many\nextensions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 19:52:09 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 13:35:45 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Khaled", "Ahmed", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1909.04719", "submitter": "Haifeng Qian", "authors": "Haifeng Qian", "title": "Neural Belief Reasoner", "comments": null, "journal-ref": "International Joint Conference on Artificial Intelligence (IJCAI),\n  2020", "doi": "10.24963/ijcai.2020/590", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new generative model called neural belief reasoner\n(NBR). It differs from previous models in that it specifies a belief function\nrather than a probability distribution. Its implementation consists of neural\nnetworks, fuzzy-set operations and belief-function operations, and\nquery-answering, sample-generation and training algorithms are presented. This\npaper studies NBR in two tasks. The first is a synthetic unsupervised-learning\ntask, which demonstrates NBR's ability to perform multi-hop reasoning,\nreasoning with uncertainty and reasoning about conflicting information. The\nsecond is supervised learning: a robust MNIST classifier for 4 and 9, which is\nthe most challenging pair of digits. This classifier needs no adversarial\ntraining, and it substantially exceeds the state of the art in adversarial\nrobustness as measured by the L2 metric, while at the same time maintains 99.1%\naccuracy on natural images.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 19:56:11 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 03:40:04 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 18:12:49 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Qian", "Haifeng", ""]]}, {"id": "1909.04723", "submitter": "Navdeep Kaur", "authors": "Navdeep Kaur and Gautam Kunapuli and Saket Joshi and Kristian Kersting\n  and Sriraam Natarajan", "title": "Neural Networks for Relational Data", "comments": "15 pages, 2 figures. To appear in the proceedings of 29th\n  International Conference on Inductive Logic Programming (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While deep networks have been enormously successful over the last decade,\nthey rely on flat-feature vector representations, which makes them unsuitable\nfor richly structured domains such as those arising in applications like social\nnetwork analysis. Such domains rely on relational representations to capture\ncomplex relationships between entities and their attributes. Thus, we consider\nthe problem of learning neural networks for relational data. We distinguish\nourselves from current approaches that rely on expert hand-coded rules by\nlearning relational random-walk-based features to capture local structural\ninteractions and the resulting network architecture. We further exploit\nparameter tying of the network weights of the resulting relational neural\nnetwork, where instances of the same type share parameters. Our experimental\nresults across several standard relational data sets demonstrate the\neffectiveness of the proposed approach over multiple neural net baselines as\nwell as state-of-the-art statistical relational models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:11:05 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 17:15:26 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 17:26:00 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Kaur", "Navdeep", ""], ["Kunapuli", "Gautam", ""], ["Joshi", "Saket", ""], ["Kersting", "Kristian", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1909.04724", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker, Alan Colman, Jun Han, A.S.M. Kayes and Paul Watters", "title": "CalBehav: A Machine Learning based Personalized Calendar Behavioral\n  Model using Time-Series Smartphone Data", "comments": "16 pages, double column", "journal-ref": "The Computer Journal, Section C: Computational Intelligence,\n  Machine Learning and Data Analytics, Publisher: Oxford University Press, UK,\n  2019", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electronic calendar is a valuable resource nowadays for managing our\ndaily life appointments or schedules, also known as events, ranging from\nprofessional to highly personal. Researchers have studied various types of\ncalendar events to predict smartphone user behavior for incoming mobile\ncommunications. However, these studies typically do not take into account\nbehavioral variations between individuals. In the real world, smartphone users\ncan differ widely from each other in how they respond to incoming\ncommunications during their scheduled events. Moreover, an individual user may\nrespond the incoming communications differently in different contexts subject\nto what type of event is scheduled in her personal calendar. Thus, a static\ncalendar-based behavioral model for individual smartphone users does not\nnecessarily reflect their behavior to the incoming communications. In this\npaper, we present a machine learning based context-aware model that is\npersonalized and dynamically identifies individual's dominant behavior for\ntheir scheduled events using logged time-series smartphone data, and shortly\nname as ``CalBehav''. The experimental results based on real datasets from\ncalendar and phone logs, show that this data-driven personalized model is more\neffective for intelligently managing the incoming mobile communications\ncompared to existing calendar-based approaches.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 08:26:11 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Colman", "Alan", ""], ["Han", "Jun", ""], ["Kayes", "A. S. M.", ""], ["Watters", "Paul", ""]]}, {"id": "1909.04746", "submitter": "Ahmed Khaled", "authors": "Ahmed Khaled and Konstantin Mishchenko and Peter Richt\\'arik", "title": "Tighter Theory for Local SGD on Identical and Heterogeneous Data", "comments": "To appear in AISTATS 2020. 31 pages, 1 algorithm, 5 theorems, 6\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new analysis of local SGD, removing unnecessary assumptions and\nelaborating on the difference between two data regimes: identical and\nheterogeneous. In both cases, we improve the existing theory and provide values\nof the optimal stepsize and optimal number of local iterations. Our bounds are\nbased on a new notion of variance that is specific to local SGD methods with\ndifferent data. The tightness of our results is guaranteed by recovering known\nstatements when we plug $H=1$, where $H$ is the number of local steps. The\nempirical evidence further validates the severe impact of data heterogeneity on\nthe performance of local SGD.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 20:47:10 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 08:17:47 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 21:27:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Khaled", "Ahmed", ""], ["Mishchenko", "Konstantin", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1909.04747", "submitter": "Madeleine Bartlett Miss", "authors": "Madeleine Bartlett, Daniel Hernandez Garcia, Serge Thill and Tony\n  Belpaeme", "title": "Recognizing Human Internal States: A Conceptor-Based Approach", "comments": "4 pages, 1 figure, HRI conference workshop", "journal-ref": null, "doi": null, "report-no": "SREC/2019/04", "categories": "cs.HC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The past few decades has seen increased interest in the application of social\nrobots to interventions for Autism Spectrum Disorder as behavioural coaches\n[4]. We consider that robots embedded in therapies could also provide\nquantitative diagnostic information by observing patient behaviours. The social\nnature of ASD symptoms means that, to achieve this, robots need to be able to\nrecognize the internal states their human interaction partners are\nexperiencing, e.g. states of confusion, engagement etc. Approaching this\nproblem can be broken down into two questions: (1) what information, accessible\nto robots, can be used to recognize internal states, and (2) how can a system\nclassify internal states such that it allows for sufficiently detailed\ndiagnostic information? In this paper we discuss these two questions in depth\nand propose a novel, conceptor-based classifier. We report the initial results\nof this system in a proof-of-concept study and outline plans for future work.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 13:10:52 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Bartlett", "Madeleine", ""], ["Garcia", "Daniel Hernandez", ""], ["Thill", "Serge", ""], ["Belpaeme", "Tony", ""]]}, {"id": "1909.04751", "submitter": "Yue Zheng", "authors": "Yue Zheng", "title": "Reinforcement Learning and Video Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has exceeded human-level performance in game playing\nAI with deep learning methods according to the experiments from DeepMind on Go\nand Atari games. Deep learning solves high dimension input problems which stop\nthe development of reinforcement for many years. This study uses both two\ntechniques to create several agents with different algorithms that successfully\nlearn to play T-rex Runner. Deep Q network algorithm and three types of\nimprovements are implemented to train the agent. The results from some of them\nare far from satisfactory but others are better than human experts. Batch\nnormalization is a method to solve internal covariate shift problems in deep\nneural network. The positive influence of this on reinforcement learning has\nalso been proved in this study.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 20:51:42 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Zheng", "Yue", ""]]}, {"id": "1909.04757", "submitter": "Wenrui Zhang", "authors": "Changqing Xu, Wenrui Zhang, Yu Liu, Peng Li", "title": "Boosting Throughput and Efficiency of Hardware Spiking Neural\n  Accelerators using Time Compression Supporting Multiple Spike Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": "Frontiers in Neuroscience, 14, p.104", "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are the third generation of neural networks\nand can explore both rate and temporal coding for energy-efficient event-driven\ncomputation. However, the decision accuracy of existing SNN designs is\ncontingent upon processing a large number of spikes over a long period.\nNevertheless, the switching power of SNN hardware accelerators is proportional\nto the number of spikes processed while the length of spike trains limits\nthroughput and static power efficiency. This paper presents the first study on\ndeveloping temporal compression to significantly boost throughput and reduce\nenergy dissipation of digital hardware SNN accelerators while being applicable\nto multiple spike codes. The proposed compression architectures consist of\nlow-cost input spike compression units, novel input-and-output-weighted spiking\nneurons, and reconfigurable time constant scaling to support large and flexible\ntime compression ratios. Our compression architectures can be transparently\napplied to any given pre-designed SNNs employing either rate or temporal codes\nwhile incurring minimal modification of the neural models, learning algorithms,\nand hardware design. Using spiking speech and image recognition datasets, we\ndemonstrate the feasibility of supporting large time compression ratios of up\nto 16x, delivering up to 15.93x, 13.88x, and 86.21x improvements in throughput,\nenergy dissipation, the tradeoffs between hardware area, runtime, energy, and\nclassification accuracy, respectively based on different spike codes on a\nXilinx Zynq-7000 FPGA. These results are achieved while incurring little extra\nhardware overhead.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 21:16:04 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Xu", "Changqing", ""], ["Zhang", "Wenrui", ""], ["Liu", "Yu", ""], ["Li", "Peng", ""]]}, {"id": "1909.04760", "submitter": "Venktesh Pandey", "authors": "Venktesh Pandey, Evana Wang, and Stephen D. Boyles", "title": "Deep Reinforcement Learning Algorithm for Dynamic Pricing of Express\n  Lanes with Multiple Access Locations", "comments": null, "journal-ref": null, "doi": "10.1016/j.trc.2020.102715", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article develops a deep reinforcement learning (Deep-RL) framework for\ndynamic pricing on managed lanes with multiple access locations and\nheterogeneity in travelers' value of time, origin, and destination. This\nframework relaxes assumptions in the literature by considering multiple origins\nand destinations, multiple access locations to the managed lane, en route\ndiversion of travelers, partial observability of the sensor readings, and\nstochastic demand and observations. The problem is formulated as a partially\nobservable Markov decision process (POMDP) and policy gradient methods are used\nto determine tolls as a function of real-time observations. Tolls are modeled\nas continuous and stochastic variables, and are determined using a feedforward\nneural network. The method is compared against a feedback control method used\nfor dynamic pricing. We show that Deep-RL is effective in learning toll\npolicies for maximizing revenue, minimizing total system travel time, and other\njoint weighted objectives, when tested on real-world transportation networks.\nThe Deep-RL toll policies outperform the feedback control heuristic for the\nrevenue maximization objective by generating revenues up to 9.5% higher than\nthe heuristic and for the objective minimizing total system travel time (TSTT)\nby generating TSTT up to 10.4% lower than the heuristic. We also propose reward\nshaping methods for the POMDP to overcome the undesired behavior of toll\npolicies, like the jam-and-harvest behavior of revenue-maximizing policies.\nAdditionally, we test transferability of the algorithm trained on one set of\ninputs for new input distributions and offer recommendations on real-time\nimplementations of Deep-RL algorithms. The source code for our experiments is\navailable online at https://github.com/venktesh22/ExpressLanes_Deep-RL\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 21:20:59 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Pandey", "Venktesh", ""], ["Wang", "Evana", ""], ["Boyles", "Stephen D.", ""]]}, {"id": "1909.04761", "submitter": "Julian Eisenschlos", "authors": "Julian Martin Eisenschlos, Sebastian Ruder, Piotr Czapla, Marcin\n  Kardas, Sylvain Gugger, Jeremy Howard", "title": "MultiFiT: Efficient Multi-lingual Language Model Fine-tuning", "comments": "Proceedings of EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models are promising particularly for low-resource\nlanguages as they only require unlabelled data. However, training existing\nmodels requires huge amounts of compute, while pretrained cross-lingual models\noften underperform on low-resource languages. We propose Multi-lingual language\nmodel Fine-Tuning (MultiFiT) to enable practitioners to train and fine-tune\nlanguage models efficiently in their own language. In addition, we propose a\nzero-shot method using an existing pretrained cross-lingual model. We evaluate\nour methods on two widely used cross-lingual classification datasets where they\noutperform models pretrained on orders of magnitude more data and compute. We\nrelease all models and code.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 21:30:54 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 19:05:15 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Eisenschlos", "Julian Martin", ""], ["Ruder", "Sebastian", ""], ["Czapla", "Piotr", ""], ["Kardas", "Marcin", ""], ["Gugger", "Sylvain", ""], ["Howard", "Jeremy", ""]]}, {"id": "1909.04766", "submitter": "Yongjune Kim", "authors": "Yongjune Kim, Yuval Cassuto, Lav R. Varshney", "title": "Boosting Classifiers with Noisy Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a principled framework to address resource allocation for\nrealizing boosting algorithms on substrates with communication or computation\nnoise. Boosting classifiers (e.g., AdaBoost) make a final decision via a\nweighted vote from the outputs of many base classifiers (weak classifiers).\nSuppose that the base classifiers' outputs are noisy or communicated over noisy\nchannels; these noisy outputs will degrade the final classification accuracy.\nWe show that this degradation can be effectively reduced by allocating more\nsystem resources for more important base classifiers. We formulate resource\noptimization problems in terms of importance metrics for boosting. Moreover, we\nshow that the optimized noisy boosting classifiers can be more robust than\nbagging for the noise during inference (test stage). We provide numerical\nevidence to demonstrate the benefits of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 21:38:56 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 01:10:44 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Kim", "Yongjune", ""], ["Cassuto", "Yuval", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1909.04778", "submitter": "Robert Podschwadt", "authors": "Robert Podschwadt, Hassan Takabi", "title": "Effectiveness of Adversarial Examples and Defenses for Malware\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks have been successfully used for many different\nclassification tasks including malware detection and distinguishing between\nmalicious and non-malicious programs. Although artificial neural networks\nperform very well on these tasks, they are also vulnerable to adversarial\nexamples. An adversarial example is a sample that has minor modifications made\nto it so that the neural network misclassifies it. Many techniques have been\nproposed, both for crafting adversarial examples and for hardening neural\nnetworks against them. Most previous work has been done in the image domain.\nSome of the attacks have been adopted to work in the malware domain which\ntypically deals with binary feature vectors. In order to better understand the\nspace of adversarial examples in malware classification, we study different\napproaches of crafting adversarial examples and defense techniques in the\nmalware domain and compare their effectiveness on multiple datasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 22:20:32 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Podschwadt", "Robert", ""], ["Takabi", "Hassan", ""]]}, {"id": "1909.04779", "submitter": "Eitan Rothberg", "authors": "Eitan Rothberg, Tingting Chen, Luo Jie, Hao Ji", "title": "Localized Adversarial Training for Increased Accuracy and Robustness in\n  Image Classification", "comments": "4 pages (excluding references). Presented at AdvML: 1st Workshop on\n  Adversarial Learning Methods for Machine Learning and Data Mining at KDD '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's state-of-the-art image classifiers fail to correctly classify\ncarefully manipulated adversarial images. In this work, we develop a new,\nlocalized adversarial attack that generates adversarial examples by\nimperceptibly altering the backgrounds of normal images. We first use this\nattack to highlight the unnecessary sensitivity of neural networks to changes\nin the background of an image, then use it as part of a new training technique:\nlocalized adversarial training. By including locally adversarial images in the\ntraining set, we are able to create a classifier that suffers less loss than a\nnon-adversarially trained counterpart model on both natural and adversarial\ninputs. The evaluation of our localized adversarial training algorithm on MNIST\nand CIFAR-10 datasets shows decreased accuracy loss on natural images, and\nincreased robustness against adversarial inputs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 22:26:48 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Rothberg", "Eitan", ""], ["Chen", "Tingting", ""], ["Jie", "Luo", ""], ["Ji", "Hao", ""]]}, {"id": "1909.04787", "submitter": "Bohan Wu", "authors": "Bohan Wu, Iretiayo Akinola, Jacob Varley, Peter Allen", "title": "MAT: Multi-Fingered Adaptive Tactile Grasping via Deep Reinforcement\n  Learning", "comments": "Accepted at 3rd Conference on Robot Learning (CoRL 2019). Oral\n  Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vision-based grasping systems typically adopt an open-loop execution of a\nplanned grasp. This policy can fail due to many reasons, including ubiquitous\ncalibration error. Recovery from a failed grasp is further complicated by\nvisual occlusion, as the hand is usually occluding the vision sensor as it\nattempts another open-loop regrasp. This work presents MAT, a tactile\nclosed-loop method capable of realizing grasps provided by a coarse initial\npositioning of the hand above an object. Our algorithm is a deep reinforcement\nlearning (RL) policy optimized through the clipped surrogate objective within a\nmaximum entropy RL framework to balance exploitation and exploration. The\nmethod utilizes tactile and proprioceptive information to act through both fine\nfinger motions and larger regrasp movements to execute stable grasps. A novel\ncurriculum of action motion magnitude makes learning more tractable and helps\nturn common failure cases into successes. Careful selection of features that\nexhibit small sim-to-real gaps enables this tactile grasping policy, trained\npurely in simulation, to transfer well to real world environments without the\nneed for additional learning. Experimentally, this methodology improves over a\nvision-only grasp success rate substantially on a multi-fingered robot hand.\nWhen this methodology is used to realize grasps from coarse initial positions\nprovided by a vision-only planner, the system is made dramatically more robust\nto calibration errors in the camera-robot transform.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 23:02:04 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 00:04:26 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Wu", "Bohan", ""], ["Akinola", "Iretiayo", ""], ["Varley", "Jacob", ""], ["Allen", "Peter", ""]]}, {"id": "1909.04790", "submitter": "Shabnam Daghaghi", "authors": "Shabnam Daghaghi, Tharun Medini, Anshumali Shrivastava", "title": "SDM-Net: A Simple and Effective Model for Generalized Zero-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-Shot Learning (ZSL) is a classification task where we do not have even a\nsingle training labeled example from a set of unseen classes. Instead, we only\nhave prior information (or description) about seen and unseen classes, often in\nthe form of physically realizable or descriptive attributes. Lack of any single\ntraining example from a set of classes prohibits use of standard classification\ntechniques and losses, including the popular crossentropy loss. Currently,\nstate-of-the-art approaches encode the prior class information into dense\nvectors and optimize some distance between the learned projections of the input\nvector and the corresponding class vector (collectively known as embedding\nmodels). In this paper, we propose a novel architecture of casting zero-shot\nlearning as a standard neural-network with crossentropy loss. During training\nour approach performs soft-labeling by combining the observed training data for\nthe seen classes with the similarity information from the attributes for which\nwe have no training data or unseen classes. To the best of our knowledge, such\nsimilarity based soft-labeling is not explored in the field of deep learning.\nWe evaluate the proposed model on the four benchmark datasets for zero-shot\nlearning, AwA, aPY, SUN and CUB datasets, and show that our model achieves\nsignificant improvement over the state-of-the-art methods in Generalized-ZSL\nand ZSL settings on all of these datasets consistently.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 23:27:24 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 10:27:37 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Daghaghi", "Shabnam", ""], ["Medini", "Tharun", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1909.04791", "submitter": "Alireza Ghods", "authors": "Alireza Ghods and Diane J Cook", "title": "A Survey of Techniques All Classifiers Can Learn from Deep Networks:\n  Models, Optimizations, and Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have introduced novel and useful tools to the machine\nlearning community. Other types of classifiers can potentially make use of\nthese tools as well to improve their performance and generality. This paper\nreviews the current state of the art for deep learning classifier technologies\nthat are being used outside of deep neural networks. Non-network classifiers\ncan employ many components found in deep neural network architectures. In this\npaper, we review the feature learning, optimization, and regularization methods\nthat form a core of deep network technologies. We then survey non-neural\nnetwork learning algorithms that make innovative use of these methods to\nimprove classification. Because many opportunities and challenges still exist,\nwe discuss directions that can be pursued to expand the area of deep learning\nfor a variety of classification algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 23:33:19 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 17:50:42 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ghods", "Alireza", ""], ["Cook", "Diane J", ""]]}, {"id": "1909.04797", "submitter": "Raunak Dey", "authors": "Raunak Dey, Yi Hong", "title": "Hybrid Cascaded Neural Network for Liver Lesion Segmentation", "comments": null, "journal-ref": null, "doi": "10.1109/ISBI45749.2020.9098656", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic liver lesion segmentation is a challenging task while having a\nsignificant impact on assisting medical professionals in the designing of\neffective treatment and planning proper care. In this paper we propose a\ncascaded system that combines both 2D and 3D convolutional neural networks to\neffectively segment hepatic lesions. Our 2D network operates on a slice by\nslice basis to segment the liver and larger tumors, while we use a 3D network\nto detect small lesions that are often missed in a 2D segmentation design. We\nemploy this algorithm on the LiTS challenge obtaining a Dice score per case of\n68.1%, which performs the best among all non pre-trained models and the second\nbest among published methods. We also perform two-fold cross-validation to\nreveal the over- and under-segmentation issues in the LiTS annotations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 00:11:14 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 16:38:34 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 05:25:43 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Dey", "Raunak", ""], ["Hong", "Yi", ""]]}, {"id": "1909.04800", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Anupriy, Vinay P. Namboodiri", "title": "Probabilistic framework for solving Visual Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a probabilistic framework for solving the task of\n`Visual Dialog'. Solving this task requires reasoning and understanding of\nvisual modality, language modality, and common sense knowledge to answer.\nVarious architectures have been proposed to solve this task by variants of\nmulti-modal deep learning techniques that combine visual and language\nrepresentations. However, we believe that it is crucial to understand and\nanalyze the sources of uncertainty for solving this task. Our approach allows\nfor estimating uncertainty and also aids a diverse generation of answers. The\nproposed approach is obtained through a probabilistic representation module\nthat provides us with representations for image, question and conversation\nhistory, a module that ensures that diverse latent representations for\ncandidate answers are obtained given the probabilistic representations and an\nuncertainty representation module that chooses the appropriate answer that\nminimizes uncertainty. We thoroughly evaluate the model with a detailed\nablation analysis, comparison with state of the art and visualization of the\nuncertainty that aids in the understanding of the method. Using the proposed\nprobabilistic framework, we thus obtain an improved visual dialog system that\nis also more explainable.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 00:25:12 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 07:30:39 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Patro", "Badri N.", ""], ["Anupriy", "", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1909.04803", "submitter": "Ehsan Amid", "authors": "Ehsan Amid and Manfred K. Warmuth", "title": "An Implicit Form of Krasulina's k-PCA Update without the Orthonormality\n  Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We shed new insights on the two commonly used updates for the online $k$-PCA\nproblem, namely, Krasulina's and Oja's updates. We show that Krasulina's update\ncorresponds to a projected gradient descent step on the Stiefel manifold of the\northonormal $k$-frames, while Oja's update amounts to a gradient descent step\nusing the unprojected gradient. Following these observations, we derive a more\n\\emph{implicit} form of Krasulina's $k$-PCA update, i.e. a version that uses\nthe information of the future gradient as much as possible. Most interestingly,\nour implicit Krasulina update avoids the costly QR-decomposition step by\nbypassing the orthonormality constraint. We show that the new update in fact\ncorresponds to an online EM step applied to a probabilistic $k$-PCA model. The\nprobabilistic view of the updates allows us to combine multiple models in a\ndistributed setting. We show experimentally that the implicit Krasulina update\nyields superior convergence while being significantly faster. We also give\nstrong evidence that the new update can benefit from parallelism and is more\nstable w.r.t. tuning of the learning rate.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 00:36:22 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Amid", "Ehsan", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1909.04807", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata, Machiko Toyoda, Shotaro Tora, Naonori Ueda", "title": "Anomaly Detection with Inexact Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a supervised anomaly detection method for data with inexact\nanomaly labels, where each label, which is assigned to a set of instances,\nindicates that at least one instance in the set is anomalous. Although many\nanomaly detection methods have been proposed, they cannot handle inexact\nanomaly labels. To measure the performance with inexact anomaly labels, we\ndefine the inexact AUC, which is our extension of the area under the ROC curve\n(AUC) for inexact labels. The proposed method trains an anomaly score function\nso that the smooth approximation of the inexact AUC increases while anomaly\nscores for non-anomalous instances become low. We model the anomaly score\nfunction by a neural network-based unsupervised anomaly detection method, e.g.,\nautoencoders. The proposed method performs well even when only a small number\nof inexact labels are available by incorporating an unsupervised anomaly\ndetection mechanism with inexact AUC maximization. Using various datasets, we\nexperimentally demonstrate that our proposed method improves the anomaly\ndetection performance with inexact anomaly labels, and outperforms existing\nunsupervised and supervised anomaly detection and multiple instance learning\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 01:30:38 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Toyoda", "Machiko", ""], ["Tora", "Shotaro", ""], ["Ueda", "Naonori", ""]]}, {"id": "1909.04822", "submitter": "Elaheh ShafieiBavani", "authors": "Elaheh ShafieiBavani, Antonio Jimeno Yepes, Xu Zhong, David Martinez\n  Iraola", "title": "Global Locality in Biomedical Relation and Event Extraction", "comments": "10 pages. arXiv admin note: text overlap with arXiv:1802.10569,\n  arXiv:1710.08312 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the exponential growth of biomedical literature, event and relation\nextraction are important tasks in biomedical text mining. Most work only focus\non relation extraction, and detect a single entity pair mention on a short span\nof text, which is not ideal due to long sentences that appear in biomedical\ncontexts. We propose an approach to both relation and event extraction, for\nsimultaneously predicting relationships between all mention pairs in a text. We\nalso perform an empirical study to discuss different network setups for this\npurpose. The best performing model includes a set of multi-head attentions and\nconvolutions, an adaptation of the transformer architecture, which offers\nself-attention the ability to strengthen dependencies among related elements,\nand models the interaction between features extracted by multiple attention\nheads. Experiment results demonstrate that our approach outperforms the state\nof the art on a set of benchmark biomedical corpora including BioNLP 2009,\n2011, 2013 and BioCreative 2017 shared tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 02:20:57 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 07:03:07 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["ShafieiBavani", "Elaheh", ""], ["Yepes", "Antonio Jimeno", ""], ["Zhong", "Xu", ""], ["Iraola", "David Martinez", ""]]}, {"id": "1909.04823", "submitter": "Haidong Rong", "authors": "Haidong Rong, Yangzihao Wang, Feihu Zhou, Junjie Zhai, Haiyang Wu, Rui\n  Lan, Fan Li, Han Zhang, Yuekui Yang, Zhenyu Guo, Di Wang", "title": "Distributed Equivalent Substitution Training for Large-Scale Recommender\n  Systems", "comments": "Accepted by SIGIR '2020. Proceedings of the 43rd International ACM\n  SIGIR Conference on Research and Development in Information Retrieval. 2020", "journal-ref": null, "doi": "10.1145/3397271.3401113", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Distributed Equivalent Substitution (DES) training, a novel\ndistributed training framework for large-scale recommender systems with dynamic\nsparse features. DES introduces fully synchronous training to large-scale\nrecommendation system for the first time by reducing communication, thus making\nthe training of commercial recommender systems converge faster and reach better\nCTR. DES requires much less communication by substituting the weights-rich\noperators with the computationally equivalent sub-operators and aggregating\npartial results instead of transmitting the huge sparse weights directly\nthrough the network. Due to the use of synchronous training on large-scale Deep\nLearning Recommendation Models (DLRMs), DES achieves higher AUC(Area Under\nROC). We successfully apply DES training on multiple popular DLRMs of\nindustrial scenarios. Experiments show that our implementation outperforms the\nstate-of-the-art PS-based training framework, achieving up to 68.7%\ncommunication savings and higher throughput compared to other PS-based\nrecommender systems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 13:16:26 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 13:38:06 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 12:17:32 GMT"}, {"version": "v4", "created": "Thu, 28 May 2020 10:19:28 GMT"}, {"version": "v5", "created": "Sat, 30 May 2020 07:28:00 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Rong", "Haidong", ""], ["Wang", "Yangzihao", ""], ["Zhou", "Feihu", ""], ["Zhai", "Junjie", ""], ["Wu", "Haiyang", ""], ["Lan", "Rui", ""], ["Li", "Fan", ""], ["Zhang", "Han", ""], ["Yang", "Yuekui", ""], ["Guo", "Zhenyu", ""], ["Wang", "Di", ""]]}, {"id": "1909.04824", "submitter": "Lia Ahrens", "authors": "Julian Ahrens and Lia Ahrens and Hans D. Schotten", "title": "A Machine Learning Method for Prediction of Multipath Channels", "comments": "7 pages, 2 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a machine learning method for predicting the evolution of a\nmobile communication channel based on a specific type of convolutional neural\nnetwork is developed and evaluated in a simulated multipath transmission\nscenario. The simulation and channel estimation are designed to replicate\nreal-world scenarios and common measurements supported by reference signals in\nmodern cellular networks. The capability of the predictor meets the\nrequirements that a deployment of the developed method in a radio resource\nscheduler of a base station poses. Possible applications of the method are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 13:00:35 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 21:34:13 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ahrens", "Julian", ""], ["Ahrens", "Lia", ""], ["Schotten", "Hans D.", ""]]}, {"id": "1909.04825", "submitter": "Guillaume Godin", "authors": "Ruud van Deursen, Peter Ertl, Igor V. Tetko and Guillaume Godin", "title": "GEN: Highly Efficient SMILES Explorer Using Autodidactic Generative\n  Examination Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recurrent neural networks have been widely used to generate millions of de\nnovo molecules in a known chemical space. These deep generative models are\ntypically setup with LSTM or GRU units and trained with canonical SMILEs. In\nthis study, we introduce a new robust architecture, Generative Examination\nNetworks GEN, based on bidirectional RNNs with concatenated sub-models to learn\nand generate molecular SMILES with a trained target space. GENs autonomously\nlearn the target space in a few epochs while being subjected to an independent\nonline examination mechanism to measure the quality of the generated set. Here\nwe have used online statistical quality control (SQC) on the percentage of\nvalid molecules SMILES as an examination measure to select the earliest\navailable stable model weights. Very high levels of valid SMILES (95-98%) can\nbe generated using multiple parallel encoding layers in combination with SMILES\naugmentation using unrestricted SMILES randomization. Our architecture combines\nan excellent novelty rate (85-90%) while generating SMILES with a strong\nconservation of the property space (95-99%). Our flexible examination mechanism\nis open to other quality criteria.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 13:44:04 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["van Deursen", "Ruud", ""], ["Ertl", "Peter", ""], ["Tetko", "Igor V.", ""], ["Godin", "Guillaume", ""]]}, {"id": "1909.04826", "submitter": "Pratik Ratadiya", "authors": "Pratik Ratadiya, Rahul Moorthy", "title": "Spam filtering on forums: A synthetic oversampling based approach for\n  imbalanced data classification", "comments": "Presented at SciPy India Conference 2018, IIT Bombay", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Forums play an important role in providing a platform for community\ninteraction. The introduction of irrelevant content or spam by individuals for\ncommercial and social gains tends to degrade the professional experience\npresented to the forum users. Automated moderation of the relevancy of posted\ncontent is desired. Machine learning is used for text classification and finds\napplications in spam email detection, fraudulent transaction detection etc. The\nbalance of classes in training data is essential in the case of classification\nalgorithms to make the learning efficient and accurate. However, in the case of\nforums, the spam content is sparse compared to the relevant content giving rise\nto a bias towards the latter while training. A model trained on such biased\ndata will fail to classify a spam sample. An approach based on Synthetic\nMinority Over-sampling Technique(SMOTE) is presented in this paper to tackle\nimbalanced training data. It involves synthetically creating new minority class\nsamples from the existing ones until balance in data is achieved. The enhanced\ndata is then passed through various classifiers for which the performance is\nrecorded. The results were analyzed on the data of forums of Spoken Tutorial,\nIIT Bombay over standard performance metrics and revealed that models trained\nafter Synthetic Minority oversampling outperform the ones trained on imbalanced\ndata by substantial margins. An empirical comparison of the results obtained by\nboth SMOTE and without SMOTE for various supervised classification algorithms\nhave been presented in this paper. Synthetic oversampling proves to be a\ncritical technique for achieving uniform class distribution which in turn\nyields commendable results in text classification. The presented approach can\nbe further extended to content categorization on educational websites thus\nhelping to improve the overall digital learning experience.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 11:22:37 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Ratadiya", "Pratik", ""], ["Moorthy", "Rahul", ""]]}, {"id": "1909.04837", "submitter": "Xiaojun Jia", "authors": "Xiaojun Jia, Xingxing Wei, Xiaochun Cao", "title": "Identifying and Resisting Adversarial Videos Using Temporal Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Video classification is a challenging task in computer vision. Although Deep\nNeural Networks (DNNs) have achieved excellent performance in video\nclassification, recent research shows adding imperceptible perturbations to\nclean videos can make the well-trained models output wrong labels with high\nconfidence. In this paper, we propose an effective defense framework to\ncharacterize and defend adversarial videos. The proposed method contains two\nphases: (1) adversarial video detection using temporal consistency between\nadjacent frames, and (2) adversarial perturbation reduction via denoisers in\nthe spatial and temporal domains respectively. Specifically, because of the\nlinear nature of DNNs, the imperceptible perturbations will enlarge with the\nincreasing of DNNs depth, which leads to the inconsistency of DNNs output\nbetween adjacent frames. However, the benign video frames often have the same\noutputs with their neighbor frames owing to the slight changes. Based on this\nobservation, we can distinguish between adversarial videos and benign videos.\nAfter that, we utilize different defense strategies against different attacks.\nWe propose the temporal defense, which reconstructs the polluted frames with\ntheir temporally neighbor clean frames, to deal with the adversarial videos\nwith sparse polluted frames. For the videos with dense polluted frames, we use\nan efficient adversarial denoiser to process each frame in the spatial domain,\nand thus purify the perturbations (we call it as spatial defense). A series of\nexperiments conducted on the UCF-101 dataset demonstrate that the proposed\nmethod significantly improves the robustness of video classifiers against\nadversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 03:11:52 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Jia", "Xiaojun", ""], ["Wei", "Xingxing", ""], ["Cao", "Xiaochun", ""]]}, {"id": "1909.04839", "submitter": "Hang Yu", "authors": "Hang Yu, Aishan Liu, Xianglong Liu, Gengchao Li, Ping Luo, Ran Cheng,\n  Jichen Yang, Chongzhi Zhang", "title": "PDA: Progressive Data Augmentation for General Robustness of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial images are designed to mislead deep neural networks (DNNs),\nattracting great attention in recent years. Although several defense strategies\nachieved encouraging robustness against adversarial samples, most of them fail\nto improve the robustness on common corruptions such as noise, blur, and\nweather/digital effects (e.g. frost, pixelate). To address this problem, we\npropose a simple yet effective method, named Progressive Data Augmentation\n(PDA), which enables general robustness of DNNs by progressively injecting\ndiverse adversarial noises during training. In other words, DNNs trained with\nPDA are able to obtain more robustness against both adversarial attacks as well\nas common corruptions than the recent state-of-the-art methods. We also find\nthat PDA is more efficient than prior arts and able to prevent accuracy drop on\nclean samples without being attacked. Furthermore, we theoretically show that\nPDA can control the perturbation bound and guarantee better generalization\nability than existing work. Extensive experiments on many benchmarks such as\nCIFAR-10, SVHN, and ImageNet demonstrate that PDA significantly outperforms its\ncounterparts in various experimental setups.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 03:27:54 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 05:01:22 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 11:58:05 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Yu", "Hang", ""], ["Liu", "Aishan", ""], ["Liu", "Xianglong", ""], ["Li", "Gengchao", ""], ["Luo", "Ping", ""], ["Cheng", "Ran", ""], ["Yang", "Jichen", ""], ["Zhang", "Chongzhi", ""]]}, {"id": "1909.04844", "submitter": "Jonas Mueller", "authors": "Jonas Mueller, Alex Smola", "title": "Recognizing Variables from their Data via Deep Embeddings of\n  Distributions", "comments": "IEEE International Conference on Data Mining (ICDM), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key obstacle in automated analytics and meta-learning is the inability to\nrecognize when different datasets contain measurements of the same variable.\nBecause provided attribute labels are often uninformative in practice, this\ntask may be more robustly addressed by leveraging the data values themselves\nrather than just relying on their arbitrarily selected variable names. Here, we\npresent a computationally efficient method to identify high-confidence variable\nmatches between a given set of data values and a large repository of previously\nencountered datasets. Our approach enjoys numerous advantages over\ndistributional similarity based techniques because we leverage learned vector\nembeddings of datasets which adaptively account for natural forms of data\nvariation encountered in practice. Based on the neural architecture of deep\nsets, our embeddings can be computed for both numeric and string data. In\ndataset search and schema matching tasks, our methods outperform standard\nstatistical techniques and we find that the learned embeddings generalize well\nto new data sources.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 04:10:48 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Mueller", "Jonas", ""], ["Smola", "Alex", ""]]}, {"id": "1909.04847", "submitter": "Eugene Ie", "authors": "Eugene Ie, Chih-wei Hsu, Martin Mladenov, Vihan Jain, Sanmit Narvekar,\n  Jing Wang, Rui Wu, Craig Boutilier", "title": "RecSim: A Configurable Simulation Platform for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose RecSim, a configurable platform for authoring simulation\nenvironments for recommender systems (RSs) that naturally supports sequential\ninteraction with users. RecSim allows the creation of new environments that\nreflect particular aspects of user behavior and item structure at a level of\nabstraction well-suited to pushing the limits of current reinforcement learning\n(RL) and RS techniques in sequential interactive recommendation problems.\nEnvironments can be easily configured that vary assumptions about: user\npreferences and item familiarity; user latent state and its dynamics; and\nchoice models and other user response behavior. We outline how RecSim offers\nvalue to RL and RS researchers and practitioners, and how it can serve as a\nvehicle for academic-industrial collaboration.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 04:43:45 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 13:30:53 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Ie", "Eugene", ""], ["Hsu", "Chih-wei", ""], ["Mladenov", "Martin", ""], ["Jain", "Vihan", ""], ["Narvekar", "Sanmit", ""], ["Wang", "Jing", ""], ["Wu", "Rui", ""], ["Boutilier", "Craig", ""]]}, {"id": "1909.04860", "submitter": "Chanho Ahn", "authors": "Chanho Ahn, Eunwoo Kim, Songhwai Oh", "title": "Deep Elastic Networks with Model Selection for Multi-Task Learning", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of instance-wise dynamic network model\nselection for multi-task learning. To this end, we propose an efficient\napproach to exploit a compact but accurate model in a backbone architecture for\neach instance of all tasks. The proposed method consists of an estimator and a\nselector. The estimator is based on a backbone architecture and structured\nhierarchically. It can produce multiple different network models of different\nconfigurations in a hierarchical structure. The selector chooses a model\ndynamically from a pool of candidate models given an input instance. The\nselector is a relatively small-size network consisting of a few layers, which\nestimates a probability distribution over the candidate models when an input\ninstance of a task is given. Both estimator and selector are jointly trained in\na unified learning framework in conjunction with a sampling-based learning\nstrategy, without additional computation steps. We demonstrate the proposed\napproach for several image classification tasks compared to existing approaches\nperforming model selection or learning multiple tasks. Experimental results\nshow that our approach gives not only outstanding performance compared to other\ncompetitors but also the versatility to perform instance-wise model selection\nfor multiple tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 05:46:58 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Ahn", "Chanho", ""], ["Kim", "Eunwoo", ""], ["Oh", "Songhwai", ""]]}, {"id": "1909.04866", "submitter": "Dylan Campbell", "authors": "Stephen Gould, Richard Hartley and Dylan Campbell", "title": "Deep Declarative Networks: A New Hope", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a new class of end-to-end learnable models wherein data processing\nnodes (or network layers) are defined in terms of desired behavior rather than\nan explicit forward function. Specifically, the forward function is implicitly\ndefined as the solution to a mathematical optimization problem. Consistent with\nnomenclature in the programming languages community, we name these models deep\ndeclarative networks. Importantly, we show that the class of deep declarative\nnetworks subsumes current deep learning models. Moreover, invoking the implicit\nfunction theorem, we show how gradients can be back-propagated through many\ndeclaratively defined data processing nodes thereby enabling end-to-end\nlearning. We show how these declarative processing nodes can be implemented in\nthe popular PyTorch deep learning software library allowing declarative and\nimperative nodes to co-exist within the same network. We also provide numerous\ninsights and illustrative examples of declarative nodes and demonstrate their\napplication for image and point cloud classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 06:19:25 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 03:56:39 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Gould", "Stephen", ""], ["Hartley", "Richard", ""], ["Campbell", "Dylan", ""]]}, {"id": "1909.04883", "submitter": "Jian Li", "authors": "Jian Li, Yong Liu, and Weiping Wang", "title": "Semi-supervised Vector-valued Learning: From Theory to Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector-valued learning, where the output space admits a vector-valued\nstructure, is an important problem that covers a broad family of important\ndomains, e.g. multi-label learning and multi-class classification. Using local\nRademacher complexity and unlabeled data, we derive novel data-dependent excess\nrisk bounds for learning vector-valued functions in both the kernel space and\nlinear space. The derived bounds are much sharper than existing ones, where\nconvergence rates are improved from $\\mathcal{O}(1/\\sqrt{n})$ to\n$\\mathcal{O}(1/\\sqrt{n+u}),$ and $\\mathcal{O}(1/n)$ in special cases. Motivated\nby our theoretical analysis, we propose a unified framework for learning\nvector-valued functions, incorporating both local Rademacher complexity and\nLaplacian regularization. Empirical results on a wide number of benchmark\ndatasets show that the proposed algorithm significantly outperforms baseline\nmethods, which coincides with our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 07:30:53 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 08:42:05 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 03:28:10 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Li", "Jian", ""], ["Liu", "Yong", ""], ["Wang", "Weiping", ""]]}, {"id": "1909.04885", "submitter": "Michael Kaufmann", "authors": "Michael Kaufmann, Kornilios Kourtis, Celestine Mendler-D\\\"unner,\n  Adrian Sch\\\"upbach, Thomas Parnell", "title": "Addressing Algorithmic Bottlenecks in Elastic Machine Learning with\n  Chicle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning training is one of the most common and important\nworkloads running on data centers today, but it is rarely executed alone.\nInstead, to reduce costs, computing resources are consolidated and shared by\ndifferent applications. In this scenario, elasticity and proper load balancing\nare vital to maximize efficiency, fairness, and utilization. Currently, most\ndistributed training frameworks do not support the aforementioned properties. A\nfew exceptions that do support elasticity, imitate generic distributed\nframeworks and use micro-tasks. In this paper we illustrate that micro-tasks\nare problematic for machine learning applications, because they require a high\ndegree of parallelism which hinders the convergence of distributed training at\na pure algorithmic level (i.e., ignoring overheads and scalability\nlimitations). To address this, we propose Chicle, a new elastic distributed\ntraining framework which exploits the nature of machine learning algorithms to\nimplement elasticity and load balancing without micro-tasks. We use Chicle to\ntrain deep neural network as well as generalized linear models, and show that\nChicle achieves performance competitive with state of the art rigid frameworks,\nwhile efficiently enabling elastic execution and dynamic load balancing.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 07:37:05 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kaufmann", "Michael", ""], ["Kourtis", "Kornilios", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Sch\u00fcpbach", "Adrian", ""], ["Parnell", "Thomas", ""]]}, {"id": "1909.04886", "submitter": "Arvind Easwaran", "authors": "Xiaozhe Gu and Arvind Easwaran", "title": "Towards Safe Machine Learning for CPS: Infer Uncertainty from Training\n  Data", "comments": "Publication rights licensed to ACM", "journal-ref": "In Proceedings of the 10th ACM/IEEE International Conference on\n  Cyber-Physical Systems (ICCPS), 2019. ACM, New York, NY, USA, pages 249-258", "doi": "10.1145/3302509.3311038", "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) techniques are increasingly applied to decision-making\nand control problems in Cyber-Physical Systems among which many are\nsafety-critical, e.g., chemical plants, robotics, autonomous vehicles. Despite\nthe significant benefits brought by ML techniques, they also raise additional\nsafety issues because 1) most expressive and powerful ML models are not\ntransparent and behave as a black box and 2) the training data which plays a\ncrucial role in ML safety is usually incomplete. An important technique to\nachieve safety for ML models is \"Safe Fail\", i.e., a model selects a reject\noption and applies the backup solution, a traditional controller or a human\noperator for example, when it has low confidence in a prediction.\n  Data-driven models produced by ML algorithms learn from training data, and\nhence they are only as good as the examples they have learnt. As pointed in\n[17], ML models work well in the \"training space\" (i.e., feature space with\nsufficient training data), but they could not extrapolate beyond the training\nspace. As observed in many previous studies, a feature space that lacks\ntraining data generally has a much higher error rate than the one that contains\nsufficient training samples [31]. Therefore, it is essential to identify the\ntraining space and avoid extrapolating beyond the training space. In this\npaper, we propose an efficient Feature Space Partitioning Tree (FSPT) to\naddress this problem. Using experiments, we also show that, a strong\nrelationship exists between model performance and FSPT score.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 07:38:53 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Gu", "Xiaozhe", ""], ["Easwaran", "Arvind", ""]]}, {"id": "1909.04894", "submitter": "Jian Li", "authors": "Jian Li, Yong Liu and Weiping Wang", "title": "Automated Spectral Kernel Learning", "comments": "Publised in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalization performance of kernel methods is largely determined by the\nkernel, but common kernels are stationary thus input-independent and\noutput-independent, that limits their applications on complicated tasks. In\nthis paper, we propose a powerful and efficient spectral kernel learning\nframework and learned kernels are dependent on both inputs and outputs, by\nusing non-stationary spectral kernels and flexibly learning the spectral\nmeasure from the data. Further, we derive a data-dependent generalization error\nbound based on Rademacher complexity, which estimates the generalization\nability of the learning framework and suggests two regularization terms to\nimprove performance. Extensive experimental results validate the effectiveness\nof the proposed algorithm and confirm our theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 07:54:17 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 11:34:48 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Li", "Jian", ""], ["Liu", "Yong", ""], ["Wang", "Weiping", ""]]}, {"id": "1909.04904", "submitter": "Yurii Rebryk", "authors": "Igor E. Kuralenok, Yurii Rebryk, Ruslan Solovev, Anton Ermilov", "title": "Factorized MultiClass Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new approach to multiclass classification\nproblem. We decompose the problem into a series of regression tasks, that are\nsolved with CART trees. The proposed method works significantly faster than\nstate-of-the-art solutions while giving the same level of model quality. The\nalgorithm is also robust to imbalanced datasets, allowing to reach high-quality\nresults in significantly less time without class re-balancing.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 08:18:16 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kuralenok", "Igor E.", ""], ["Rebryk", "Yurii", ""], ["Solovev", "Ruslan", ""], ["Ermilov", "Anton", ""]]}, {"id": "1909.04919", "submitter": "Tomasz Ku\\'smierczyk", "authors": "Tomasz Ku\\'smierczyk, Joseph Sakaya, Arto Klami", "title": "Correcting Predictions for Approximate Bayesian Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian models quantify uncertainty and facilitate optimal decision-making\nin downstream applications. For most models, however, practitioners are forced\nto use approximate inference techniques that lead to sub-optimal decisions due\nto incorrect posterior predictive distributions. We present a novel approach\nthat corrects for inaccuracies in posterior inference by altering the\ndecision-making process. We train a separate model to make optimal decisions\nunder the approximate posterior, combining interpretable Bayesian modeling with\noptimization of direct predictive accuracy in a principled fashion. The\nsolution is generally applicable as a plug-in module for predictive\ndecision-making for arbitrary probabilistic programs, irrespective of the\nposterior inference strategy. We demonstrate the approach empirically in\nseveral problems, confirming its potential.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 08:42:25 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Ku\u015bmierczyk", "Tomasz", ""], ["Sakaya", "Joseph", ""], ["Klami", "Arto", ""]]}, {"id": "1909.04928", "submitter": "Vinay Jethava", "authors": "Vinay Jethava", "title": "On weighted uncertainty sampling in active learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note explores probabilistic sampling weighted by uncertainty in active\nlearning. This method has been previously used and authors have tangentially\nremarked on its efficacy. The scheme has several benefits: (1) it is\ncomputationally cheap, (2) it can be implemented in a single-pass streaming\nfashion which is a benefit when deployed in real-world systems where different\nsubsystems perform the suggestion scoring and extraction of user feedback, and\n(3) it is easily parameterizable. In this paper, we show on publicly available\ndatasets that using probabilistic weighting is often beneficial and strikes a\ngood compromise between exploration and representation especially when the\nstarting set of labelled points is biased.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 08:59:14 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Jethava", "Vinay", ""]]}, {"id": "1909.04930", "submitter": "Mustafa Teke", "authors": "Mustafa Teke and Yasemin Yard{\\i}mc{\\i}", "title": "Multi-Year Vector Dynamic Time Warping Based Crop Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent automated crop mapping via supervised learning-based methods have\ndemonstrated unprecedented improvement over classical techniques. However, most\ncrop mapping studies are limited to same-year crop mapping in which the present\nyear's labeled data is used to predict the same year's crop map. Classification\naccuracies of these methods degrade considerably in cross-year mapping.\nCross-year crop mapping is more useful as it allows the prediction of the\nfollowing years' crop maps using previously labeled data. We propose Vector\nDynamic Time Warping (VDTW), a novel multi-year classification approach based\non warping of angular distances between phenological vectors. The results prove\nthat the proposed VDTW method is robust to temporal and spectral variations\ncompensating for different farming practices, climate and atmospheric effects,\nand measurement errors between years. We also describe a method for determining\nthe most discriminative time window that allows high classification accuracies\nwith limited data. We carried out tests of our approach with Landsat 8\ntime-series imagery from years 2013 to 2016 for classification of corn and\ncotton in the Harran Plain, and corn, cotton, and soybean in the Bismil Plain\nof Southeastern Turkey. In addition, we tested VDTW corn and soybean in Kansas,\nthe US for 2017 and 2018 with the Harmonized Landsat Sentinel data. The VDTW\nmethod achieved 99.85% and 99.74% overall accuracies for the same and cross\nyears, respectively with fewer training samples compared to other\nstate-of-the-art approaches, i.e. spectral angle mapper (SAM), dynamic time\nwarping (DTW), time-weighted DTW (TWDTW), random forest (RF), support vector\nmachine (SVM) and deep long short-term memory (LSTM) methods. The proposed\nmethod could be expanded for other crop types and/or geographical areas.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 09:05:05 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 08:28:22 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Teke", "Mustafa", ""], ["Yard\u0131mc\u0131", "Yasemin", ""]]}, {"id": "1909.04931", "submitter": "Jiaxiang Tang", "authors": "Jiaxiang Tang, Wei Hu, Xiang Gao, Zongming Guo", "title": "Joint Learning of Graph Representation and Node Features in Graph\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Neural Networks (GCNNs) extend classical CNNs to graph\ndata domain, such as brain networks, social networks and 3D point clouds. It is\ncritical to identify an appropriate graph for the subsequent graph convolution.\nExisting methods manually construct or learn one fixed graph for all the layers\nof a GCNN. In order to adapt to the underlying structure of node features in\ndifferent layers, we propose dynamic learning of graphs and node features\njointly in GCNNs. In particular, we cast the graph optimization problem as\ndistance metric learning to capture pairwise similarities of features in each\nlayer. We deploy the Mahalanobis distance metric and further decompose the\nmetric matrix into a low-dimensional matrix, which converts graph learning to\nthe optimization of a low-dimensional matrix for efficient implementation.\nExtensive experiments on point clouds and citation network datasets demonstrate\nthe superiority of the proposed method in terms of both accuracies and\nrobustness.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 09:09:40 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Tang", "Jiaxiang", ""], ["Hu", "Wei", ""], ["Gao", "Xiang", ""], ["Guo", "Zongming", ""]]}, {"id": "1909.04939", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Benjamin Lucas, Germain Forestier, Charlotte\n  Pelletier, Daniel F. Schmidt, Jonathan Weber, Geoffrey I. Webb, Lhassane\n  Idoumghar, Pierre-Alain Muller, Fran\\c{c}ois Petitjean", "title": "InceptionTime: Finding AlexNet for Time Series Classification", "comments": null, "journal-ref": null, "doi": "10.1007/s10618-020-00710-y", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper brings deep learning at the forefront of research into Time Series\nClassification (TSC). TSC is the area of machine learning tasked with the\ncategorization (or labelling) of time series. The last few decades of work in\nthis area have led to significant progress in the accuracy of classifiers, with\nthe state of the art now represented by the HIVE-COTE algorithm. While\nextremely accurate, HIVE-COTE cannot be applied to many real-world datasets\nbecause of its high training time complexity in O(N2 * T4) for a dataset with N\ntime series of length T. For example, it takes HIVE-COTE more than 8 days to\nlearn from a small dataset with N = 1500 time series of short length T = 46.\nMeanwhile deep learning has received enormous attention because of its high\naccuracy and scalability. Recent approaches to deep learning for TSC have been\nscalable, but less accurate than HIVE-COTE. We introduce InceptionTime - an\nensemble of deep Convolutional Neural Network (CNN) models, inspired by the\nInception-v4 architecture. Our experiments show that InceptionTime is on par\nwith HIVE-COTE in terms of accuracy while being much more scalable: not only\ncan it learn from 1,500 time series in one hour but it can also learn from 8M\ntime series in 13 hours, a quantity of data that is fully out of reach of\nHIVE-COTE.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 09:32:40 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 14:28:15 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2020 18:11:29 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Lucas", "Benjamin", ""], ["Forestier", "Germain", ""], ["Pelletier", "Charlotte", ""], ["Schmidt", "Daniel F.", ""], ["Weber", "Jonathan", ""], ["Webb", "Geoffrey I.", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""], ["Petitjean", "Fran\u00e7ois", ""]]}, {"id": "1909.04948", "submitter": "Timo Denk", "authors": "Timo I. Denk, Christian Reisswig", "title": "BERTgrid: Contextualized Embedding for 2D Document Representation and\n  Understanding", "comments": "4 pages, accepted at the \"Document Intelligence\" workshop of 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For understanding generic documents, information like font sizes, column\nlayout, and generally the positioning of words may carry semantic information\nthat is crucial for solving a downstream document intelligence task. Our novel\nBERTgrid, which is based on Chargrid by Katti et al. (2018), represents a\ndocument as a grid of contextualized word piece embedding vectors, thereby\nmaking its spatial structure and semantics accessible to the processing neural\nnetwork. The contextualized embedding vectors are retrieved from a BERT\nlanguage model. We use BERTgrid in combination with a fully convolutional\nnetwork on a semantic instance segmentation task for extracting fields from\ninvoices. We demonstrate its performance on tabulated line item and document\nheader field extraction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 09:51:02 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 09:55:39 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Denk", "Timo I.", ""], ["Reisswig", "Christian", ""]]}, {"id": "1909.04985", "submitter": "Edouard Delasalles", "authors": "Edouard Delasalles, Sylvain Lamprier, Ludovic Denoyer", "title": "Learning Dynamic Author Representations with Temporal Language Models", "comments": "International Conference on Data Mining, ICDM 2019", "journal-ref": null, "doi": "10.1109/ICDM.2019.00022", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models are at the heart of numerous works, notably in the text\nmining and information retrieval communities. These statistical models aim at\nextracting word distributions, from simple unigram models to recurrent\napproaches with latent variables that capture subtle dependencies in texts.\nHowever, those models are learned from word sequences only, and authors'\nidentities, as well as publication dates, are seldom considered. We propose a\nneural model, based on recurrent language modeling, which aims at capturing\nlanguage diffusion tendencies in author communities through time. By\nconditioning language models with author and temporal vector states, we are\nable to leverage the latent dependencies between the text contexts. This allows\nus to beat several temporal and non-temporal language baselines on two\nreal-world corpora, and to learn meaningful author representations that vary\nthrough time.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 11:51:43 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Delasalles", "Edouard", ""], ["Lamprier", "Sylvain", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "1909.04999", "submitter": "Yongseok Choi", "authors": "Yongseok Choi, Junyoung Park, Subin Yi, Dong-Yeon Cho", "title": "Domain-Agnostic Few-Shot Classification by Learning Disparate Modulators", "comments": "Presented at NeurIPS 2019 Workshop on Meta-Learning (MetaLearn 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although few-shot learning research has advanced rapidly with the help of\nmeta-learning, its practical usefulness is still limited because most of them\nassumed that all meta-training and meta-testing examples came from a single\ndomain. We propose a simple but effective way for few-shot classification in\nwhich a task distribution spans multiple domains including ones never seen\nduring meta-training. The key idea is to build a pool of models to cover this\nwide task distribution and learn to select the best one for a particular task\nthrough cross-domain meta-learning. All models in the pool share a base network\nwhile each model has a separate modulator to refine the base network in its own\nway. This framework allows the pool to have representational diversity without\nlosing beneficial domain-invariant features. We verify the effectiveness of the\nproposed algorithm through experiments on various datasets across diverse\ndomains.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 12:18:15 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 12:09:35 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Choi", "Yongseok", ""], ["Park", "Junyoung", ""], ["Yi", "Subin", ""], ["Cho", "Dong-Yeon", ""]]}, {"id": "1909.05004", "submitter": "Arpan Kusari", "authors": "Arpan Kusari and Jonathan P. How", "title": "Predicting optimal value functions by interpolating reward functions in\n  scalarized multi-objective reinforcement learning", "comments": "Accepted at ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach for defining a reward function for Multi-objective\nReinforcement Learning (MORL) problems is the weighted sum of the multiple\nobjectives. The weights are then treated as design parameters dependent on the\nexpertise (and preference) of the person performing the learning, with the\ntypical result that a new solution is required for any change in these\nsettings. This paper investigates the relationship between the reward function\nand the optimal value function for MORL; specifically addressing the question\nof how to approximate the optimal value function well beyond the set of weights\nfor which the optimization problem was actually solved, thereby avoiding the\nneed to recompute for any particular choice. We prove that the value function\ntransforms smoothly given a transformation of weights of the reward function\n(and thus a smooth interpolation in the policy space). A Gaussian process is\nused to obtain a smooth interpolation over the reward function weights of the\noptimal value function for three well-known examples: GridWorld, Objectworld\nand Pendulum. The results show that the interpolation can provide very robust\nvalues for sample states and action space in discrete and continuous domain\nproblems. Significant advantages arise from utilizing this interpolation\ntechnique in the domain of autonomous vehicles: easy, instant adaptation of\nuser preferences while driving and true randomization of obstacle vehicle\nbehavior preferences during training.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 12:26:42 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 20:58:20 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 01:59:01 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 17:17:51 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Kusari", "Arpan", ""], ["How", "Jonathan P.", ""]]}, {"id": "1909.05006", "submitter": "Sanzo Miyazawa", "authors": "Sanzo Miyazawa", "title": "Boltzmann machine learning and regularization methods for inferring\n  evolutionary fields and couplings from a multiple sequence alignment", "comments": "In this version, the value of selective temperature for protein\n  PF00153, $T_s$ in Table 5 and $k_B T_s$ in the last line of the section 2.8,\n  has been corrected. The version 2 (arXiv:1909.05006v2) was published in the\n  IEEE/ACM Transactions on Computational Biology and Bioinformatics. The\n  program and multiple sequence alignments are available from\n  https://gitlab.com/sanzo.miyazawa/BM/", "journal-ref": "IEEE/ACM Transactions on Computational Biology and Bioinformatics,\n  2020, Early Access Article", "doi": "10.1109/TCBB.2020.2993232", "report-no": null, "categories": "q-bio.PE cond-mat.stat-mech cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse Potts problem to infer a Boltzmann distribution for homologous\nprotein sequences from their single-site and pairwise amino acid frequencies\nrecently attracts a great deal of attention in the studies of protein structure\nand evolution. We study regularization and learning methods and how to tune\nregularization parameters to correctly infer interactions in Boltzmann machine\nlearning. Using $L_2$ regularization for fields, group $L_1$ for couplings is\nshown to be very effective for sparse couplings in comparison with $L_2$ and\n$L_1$. Two regularization parameters are tuned to yield equal values for both\nthe sample and ensemble averages of evolutionary energy. Both averages smoothly\nchange and converge, but their learning profiles are very different between\nlearning methods. The Adam method is modified to make stepsize proportional to\nthe gradient for sparse couplings and to use a soft-thresholding function for\ngroup $L_1$. It is shown by first inferring interactions from protein sequences\nand then from Monte Carlo samples that the fields and couplings can be well\nrecovered, but that recovering the pairwise correlations in the resolution of a\ntotal energy is harder for the natural proteins than for the protein-like\nsequences. Selective temperature for folding/structural constrains in protein\nevolution is also estimated.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 08:41:19 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 04:47:06 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 05:41:55 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Miyazawa", "Sanzo", ""]]}, {"id": "1909.05007", "submitter": "Daron Anderson", "authors": "Daron Anderson, Douglas Leith", "title": "Optimality of the Subgradient Algorithm in the Stochastic Setting", "comments": "6 figures, Corrected off-by-one errors coming from proof in Appendix\n  A. Replaced with newer Version April 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG cs.SY eess.SY math.OC math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Subgradient algorithm is universal for online learning on\nthe simplex in the sense that it simultaneously achieves $O(\\sqrt N)$ regret\nfor adversarial costs and $O(1)$ pseudo-regret for i.i.d costs. To the best of\nour knowledge this is the first demonstration of a universal algorithm on the\nsimplex that is not a variant of Hedge. Since Subgradient is a popular and\nwidely used algorithm our results have immediate broad application.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:44:30 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 14:33:20 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 12:22:22 GMT"}, {"version": "v4", "created": "Wed, 30 Oct 2019 12:02:47 GMT"}, {"version": "v5", "created": "Thu, 31 Oct 2019 12:50:45 GMT"}, {"version": "v6", "created": "Fri, 3 Apr 2020 17:04:11 GMT"}, {"version": "v7", "created": "Fri, 27 Nov 2020 14:31:37 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Anderson", "Daron", ""], ["Leith", "Douglas", ""]]}, {"id": "1909.05017", "submitter": "Artit Wangperawong", "authors": "Kettip Kriangchaivech and Artit Wangperawong", "title": "Question Generation by Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning model was developed to automatically generate questions\nfrom Wikipedia passages using transformers, an attention-based model eschewing\nthe paradigm of existing recurrent neural networks (RNNs). The model was\ntrained on the inverted Stanford Question Answering Dataset (SQuAD), which is a\nreading comprehension dataset consisting of 100,000+ questions posed by\ncrowdworkers on a set of Wikipedia articles. After training, the question\ngeneration model is able to generate simple questions relevant to unseen\npassages and answers containing an average of 8 words per question. The word\nerror rate (WER) was used as a metric to compare the similarity between SQuAD\nquestions and the model-generated questions. Although the high average WER\nsuggests that the questions generated differ from the original SQuAD questions,\nthe questions generated are mostly grammatically correct and plausible in their\nown right.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:48:53 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 20:02:20 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kriangchaivech", "Kettip", ""], ["Wangperawong", "Artit", ""]]}, {"id": "1909.05020", "submitter": "Jemin George", "authors": "Jemin George, Prudhvi Gurram", "title": "Distributed Deep Learning with Event-Triggered Communication", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.06693", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Distributed Event-Triggered Stochastic GRAdient Descent\n(DETSGRAD) algorithm for solving non-convex optimization problems typically\nencountered in distributed deep learning. We propose a novel communication\ntriggering mechanism that would allow the networked agents to update their\nmodel parameters aperiodically and provide sufficient conditions on the\nalgorithm step-sizes that guarantee the asymptotic mean-square convergence. The\nalgorithm is applied to a distributed supervised-learning problem, in which a\nset of networked agents collaboratively train their individual neural networks\nto recognize handwritten digits in images, while aperiodically sharing the\nmodel parameters with their one-hop neighbors. Results indicate that all agents\nreport similar performance that is also comparable to the performance of a\ncentrally trained neural network, while the event-triggered communication\nprovides significant reduction in inter-agent communication. Results also show\nthat the proposed algorithm allows the individual agents to recognize the\ndigits even though the training data corresponding to all the digits are not\nlocally available to each agent.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 20:11:40 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["George", "Jemin", ""], ["Gurram", "Prudhvi", ""]]}, {"id": "1909.05023", "submitter": "Johannes Bausch", "authors": "Johannes Bausch, Sathyawageeswar Subramanian, Stephen Piddock", "title": "A Quantum Search Decoder for Natural Language Processing", "comments": "39 pages, 16 figures, 2 algorithms", "journal-ref": "Quantum Mach. Intell. 3, 16 (2021)", "doi": "10.1007/s42484-021-00041-1", "report-no": null, "categories": "quant-ph cs.CL cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic language models, e.g. those based on an LSTM, often face the\nproblem of finding a high probability prediction from a sequence of random\nvariables over a set of tokens. This is commonly addressed using a form of\ngreedy decoding such as beam search, where a limited number of\nhighest-likelihood paths (the beam width) of the decoder are kept, and at the\nend the maximum-likelihood path is chosen. In this work, we construct a quantum\nalgorithm to find the globally optimal parse (i.e. for infinite beam width)\nwith high constant success probability. When the input to the decoder is\ndistributed as a power-law with exponent $k>0$, our algorithm has runtime $R^{n\nf(R,k)}$, where $R$ is the alphabet size, $n$ the input length; here $f<1/2$,\nand $f\\rightarrow 0$ exponentially fast with increasing $k$, hence making our\nalgorithm always more than quadratically faster than its classical counterpart.\nWe further modify our procedure to recover a finite beam width variant, which\nenables an even stronger empirical speedup while still retaining higher\naccuracy than possible classically. Finally, we apply this quantum beam search\ndecoder to Mozilla's implementation of Baidu's DeepSpeech neural net, which we\nshow to exhibit such a power law word rank frequency.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 17:59:23 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 16:51:11 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Bausch", "Johannes", ""], ["Subramanian", "Sathyawageeswar", ""], ["Piddock", "Stephen", ""]]}, {"id": "1909.05024", "submitter": "Lu Liu", "authors": "Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang", "title": "Learning to Propagate for Graph Meta-Learning", "comments": "Accepted to NeurIPS 2019, code at\n  https://github.com/liulu112601/Gated-Propagation-Net, slides at\n  https://liulu112601.github.io/resources/GPN-NeurIPS-Slides-revised.pdf,\n  Poster at\n  https://liulu112601.github.io/resources/Graph-Meta-Learning-Poster-revised.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning extracts common knowledge from learning different tasks and\nuses it for unseen tasks. It can significantly improve tasks that suffer from\ninsufficient training data, e.g., few shot learning. In most meta-learning\nmethods, tasks are implicitly related by sharing parameters or optimizer. In\nthis paper, we show that a meta-learner that explicitly relates tasks on a\ngraph describing the relations of their output dimensions (e.g., classes) can\nsignificantly improve few shot learning. The graph's structure is usually free\nor cheap to obtain but has rarely been explored in previous works. We develop a\nnovel meta-learner of this type for prototype-based classification, in which a\nprototype is generated for each class, such that the nearest neighbor search\namong the prototypes produces an accurate classification. The meta-learner,\ncalled \"Gated Propagation Network (GPN)\", learns to propagate messages between\nprototypes of different classes on the graph, so that learning the prototype of\neach class benefits from the data of other related classes. In GPN, an\nattention mechanism aggregates messages from neighboring classes of each class,\nwith a gate choosing between the aggregated message and the message from the\nclass itself. We train GPN on a sequence of tasks from many-shot to few shot\ngenerated by subgraph sampling. During training, it is able to reuse and update\npreviously achieved prototypes from the memory in a life-long learning cycle.\nIn experiments, under different training-test discrepancy and test task\ngeneration settings, GPN outperforms recent meta-learning methods on two\nbenchmark datasets. The code of GPN and dataset generation is available at\nhttps://github.com/liulu112601/Gated-Propagation-Net.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 13:00:24 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 08:46:48 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Liu", "Lu", ""], ["Zhou", "Tianyi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1909.05030", "submitter": "Chamin Hewa Koneputugodage", "authors": "Chamin Hewa Koneputugodage, Rhys Healy, Sean Lamont, Ian Mallett, Matt\n  Brown, Matt Walters, Ushini Attanayake, Libo Zhang, Roger T. Dean, Alexander\n  Hunter, Charles Gretton, Christian Walder", "title": "Computer Assisted Composition in Continuous Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of combining sequence models of symbolic music with\nuser defined constraints. For typical models this is non-trivial as only the\nconditional distribution of each symbol given the earlier symbols is available,\nwhile the constraints correspond to arbitrary times. Previously this has been\naddressed by assuming a discrete time model of fixed rhythm. We generalise to\ncontinuous time and arbitrary rhythm by introducing a simple, novel, and\nefficient particle filter scheme, applicable to general continuous time point\nprocesses. Extensive experimental evaluations demonstrate that in comparison\nwith a more traditional beam search baseline, the particle filter exhibits\nsuperior statistical properties and yields more agreeable results in an\nextensive human listening test experiment.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 05:57:58 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Koneputugodage", "Chamin Hewa", ""], ["Healy", "Rhys", ""], ["Lamont", "Sean", ""], ["Mallett", "Ian", ""], ["Brown", "Matt", ""], ["Walters", "Matt", ""], ["Attanayake", "Ushini", ""], ["Zhang", "Libo", ""], ["Dean", "Roger T.", ""], ["Hunter", "Alexander", ""], ["Gretton", "Charles", ""], ["Walder", "Christian", ""]]}, {"id": "1909.05032", "submitter": "Tatiana Gabruseva", "authors": "Tatiana Gabruseva, Sergey Zlobin, Peter Wang", "title": "Photometric light curves classification with machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Large Synoptic Survey Telescope will complete its survey in 2022 and\nproduce terabytes of imaging data each night. To work with this massive onset\nof data, automated algorithms to classify astronomical light curves are\ncrucial. Here, we present a method for automated classification of photometric\nlight curves for a range of astronomical objects. Our approach is based on the\ngradient boosting of decision trees, feature extraction and selection, and\naugmentation. The solution was developed in the context of The Photometric LSST\nAstronomical Time Series Classification Challenge (PLAsTiCC) and achieved one\nof the top results in the challenge.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 01:28:19 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Gabruseva", "Tatiana", ""], ["Zlobin", "Sergey", ""], ["Wang", "Peter", ""]]}, {"id": "1909.05040", "submitter": "Francesco Croce", "authors": "Francesco Croce, Matthias Hein", "title": "Sparse and Imperceivable Adversarial Attacks", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been proven to be vulnerable to a variety of adversarial\nattacks. From a safety perspective, highly sparse adversarial attacks are\nparticularly dangerous. On the other hand the pixelwise perturbations of sparse\nattacks are typically large and thus can be potentially detected. We propose a\nnew black-box technique to craft adversarial examples aiming at minimizing\n$l_0$-distance to the original image. Extensive experiments show that our\nattack is better or competitive to the state of the art. Moreover, we can\nintegrate additional bounds on the componentwise perturbation. Allowing pixels\nto change only in region of high variation and avoiding changes along\naxis-aligned edges makes our adversarial examples almost non-perceivable.\nMoreover, we adapt the Projected Gradient Descent attack to the $l_0$-norm\nintegrating componentwise constraints. This allows us to do adversarial\ntraining to enhance the robustness of classifiers against sparse and\nimperceivable adversarial manipulations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 13:28:44 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Croce", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "1909.05044", "submitter": "Jonas Schouterden", "authors": "Jonas Schouterden, Jesse Davis, Hendrik Blockeel", "title": "LazyBum: Decision tree learning using lazy propositionalization", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": "10.1007/978-3-030-49210-6_9", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propositionalization is the process of summarizing relational data into a\ntabular (attribute-value) format. The resulting table can next be used by any\npropositional learner. This approach makes it possible to apply a wide variety\nof learning methods to relational data. However, the transformation from\nrelational to propositional format is generally not lossless: different\nrelational structures may be mapped onto the same feature vector. At the same\ntime, features may be introduced that are not needed for the learning task at\nhand. In general, it is hard to define a feature space that contains all and\nonly those features that are needed for the learning task. This paper presents\nLazyBum, a system that can be considered a lazy version of the recently\nproposed OneBM method for propositionalization. LazyBum interleaves OneBM's\nfeature construction method with a decision tree learner. This learner both\nuses and guides the propositionalization process. It indicates when and where\nto look for new features. This approach is similar to what has elsewhere been\ncalled dynamic propositionalization. In an experimental comparison with the\noriginal OneBM and with two other recently proposed propositionalization\nmethods (nFOIL and MODL, which respectively perform dynamic and static\npropositionalization), LazyBum achieves a comparable accuracy with a lower\nexecution time on most of the datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 13:33:27 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Schouterden", "Jonas", ""], ["Davis", "Jesse", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1909.05062", "submitter": "Naman Agarwal", "authors": "Naman Agarwal, Elad Hazan, Karan Singh", "title": "Logarithmic Regret for Online Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study optimal regret bounds for control in linear dynamical systems under\nadversarially changing strongly convex cost functions, given the knowledge of\ntransition dynamics. This includes several well studied and fundamental\nframeworks such as the Kalman filter and the linear quadratic regulator. State\nof the art methods achieve regret which scales as $O(\\sqrt{T})$, where $T$ is\nthe time horizon.\n  We show that the optimal regret in this setting can be significantly smaller,\nscaling as $O(\\text{poly}(\\log T))$. This regret bound is achieved by two\ndifferent efficient iterative methods, online gradient descent and online\nnatural gradient.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 13:59:40 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Agarwal", "Naman", ""], ["Hazan", "Elad", ""], ["Singh", "Karan", ""]]}, {"id": "1909.05063", "submitter": "Jan St\\\"uhmer", "authors": "Jan St\\\"uhmer, Richard E. Turner, Sebastian Nowozin", "title": "Independent Subspace Analysis for Unsupervised Learning of Disentangled\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been an increased interest in unsupervised learning of\ndisentangled representations using the Variational Autoencoder (VAE) framework.\nMost of the existing work has focused largely on modifying the variational cost\nfunction to achieve this goal. We first show that these modifications, e.g.\nbeta-VAE, simplify the tendency of variational inference to underfit causing\npathological over-pruning and over-orthogonalization of learned components.\nSecond we propose a complementary approach: to modify the probabilistic model\nwith a structured latent prior. This prior allows to discover latent variable\nrepresentations that are structured into a hierarchy of independent vector\nspaces. The proposed prior has three major advantages: First, in contrast to\nthe standard VAE normal prior the proposed prior is not rotationally invariant.\nThis resolves the problem of unidentifiability of the standard VAE normal\nprior. Second, we demonstrate that the proposed prior encourages a disentangled\nlatent representation which facilitates learning of disentangled\nrepresentations. Third, extensive quantitative experiments demonstrate that the\nprior significantly mitigates the trade-off between reconstruction loss and\ndisentanglement over the state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 08:58:49 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["St\u00fchmer", "Jan", ""], ["Turner", "Richard E.", ""], ["Nowozin", "Sebastian", ""]]}, {"id": "1909.05073", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Fu-Ming Guo, Wei Niu, Xue Lin, Jian Tang, Kaisheng Ma,\n  Bin Ren, Yanzhi Wang", "title": "PCONV: The Missing but Desirable Sparsity in DNN Weight Pruning for\n  Real-time Execution on Mobile Devices", "comments": "To appear in Proceedings of the 34th AAAI Conference on Artificial\n  Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression techniques on Deep Neural Network (DNN) have been widely\nacknowledged as an effective way to achieve acceleration on a variety of\nplatforms, and DNN weight pruning is a straightforward and effective method.\nThere are currently two mainstreams of pruning methods representing two\nextremes of pruning regularity: non-structured, fine-grained pruning can\nachieve high sparsity and accuracy, but is not hardware friendly; structured,\ncoarse-grained pruning exploits hardware-efficient structures in pruning, but\nsuffers from accuracy drop when the pruning rate is high. In this paper, we\nintroduce PCONV, comprising a new sparsity dimension, -- fine-grained pruning\npatterns inside the coarse-grained structures. PCONV comprises two types of\nsparsities, Sparse Convolution Patterns (SCP) which is generated from\nintra-convolution kernel pruning and connectivity sparsity generated from\ninter-convolution kernel pruning. Essentially, SCP enhances accuracy due to its\nspecial vision properties, and connectivity sparsity increases pruning rate\nwhile maintaining balanced workload on filter computation. To deploy PCONV, we\ndevelop a novel compiler-assisted DNN inference framework and execute PCONV\nmodels in real-time without accuracy compromise, which cannot be achieved in\nprior work. Our experimental results show that, PCONV outperforms three\nstate-of-art end-to-end DNN frameworks, TensorFlow-Lite, TVM, and Alibaba\nMobile Neural Network with speedup up to 39.2x, 11.4x, and 6.3x, respectively,\nwith no accuracy loss. Mobile devices can achieve real-time inference on\nlarge-scale DNNs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 03:58:29 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 01:33:36 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 00:18:07 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 19:39:06 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Ma", "Xiaolong", ""], ["Guo", "Fu-Ming", ""], ["Niu", "Wei", ""], ["Lin", "Xue", ""], ["Tang", "Jian", ""], ["Ma", "Kaisheng", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1909.05075", "submitter": "James Edwards", "authors": "James Edwards", "title": "Practical Calculation of Gittins Indices for Multi-armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gittins indices provide an optimal solution to the classical multi-armed\nbandit problem. An obstacle to their use has been the common perception that\ntheir computation is very difficult. This paper demonstrates an accessible\ngeneral methodology for the calculating Gittins indices for the multi-armed\nbandit with a detailed study on the cases of Bernoulli and Gaussian rewards.\nWith accompanying easy-to-use open source software, this work removes\ncomputation as a barrier to using Gittins indices in these commonly found\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 14:24:43 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Edwards", "James", ""]]}, {"id": "1909.05076", "submitter": "Ryan Bernstein", "authors": "Ryan Bernstein", "title": "Static Analysis for Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming is a powerful abstraction for statistical machine\nlearning. Applying static analysis methods to probabilistic programs could\nserve to optimize the learning process, automatically verify properties of\nmodels, and improve the programming interface for users. This field of static\nanalysis for probabilistic programming (SAPP) is young and unorganized,\nconsisting of a constellation of techniques with various goals and limitations.\nThe primary aim of this work is to synthesize the major contributions of the\nSAPP field within an organizing structure and context. We provide technical\nbackground for static analysis and probabilistic programming, suggest a\nfunctional taxonomy for probabilistic programming languages, and analyze the\napplicability of major ideas in the SAPP field. We conclude that, while current\nstatic analysis techniques for probabilistic programs have practical\nlimitations, there are a number of future directions with high potential to\nimprove the state of statistical machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:34:10 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Bernstein", "Ryan", ""]]}, {"id": "1909.05090", "submitter": "Kun Zhang", "authors": "Kun Zhang, Peng He, Ping Yao, Ge Chen, Rui Wu, Min Du, Huimin Li, Li\n  Fu, Tianyao Zheng", "title": "Learning Enhanced Resolution-wise features for Human Pose Estimation", "comments": "Published on ICIP 2020", "journal-ref": null, "doi": "10.1109/ICIP40778.2020.9191174", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, multi-resolution networks (such as Hourglass, CPN, HRNet, etc.)\nhave achieved significant performance on pose estimation by combining feature\nmaps of various resolutions. In this paper, we propose a Resolution-wise\nAttention Module (RAM) and Gradual Pyramid Refinement (GPR), to learn enhanced\nresolution-wise feature maps for precise pose estimation. Specifically, RAM\nlearns a group of weights to represent the different importance of feature maps\nacross resolutions, and the GPR gradually merges every two feature maps from\nlow to high resolutions to regress final human keypoint heatmaps. With the\nenhanced resolution-wise features learnt by CNN, we obtain more accurate human\nkeypoint locations. The efficacies of our proposed methods are demonstrated on\nMS-COCO dataset, achieving state-of-the-art performance with average precision\nof 77.7 on COCO val2017 set and 77.0 on test-dev2017 set without using extra\nhuman keypoint training dataset.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 14:46:28 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 06:43:59 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 09:53:05 GMT"}, {"version": "v4", "created": "Sun, 13 Dec 2020 15:22:41 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhang", "Kun", ""], ["He", "Peng", ""], ["Yao", "Ping", ""], ["Chen", "Ge", ""], ["Wu", "Rui", ""], ["Du", "Min", ""], ["Li", "Huimin", ""], ["Fu", "Li", ""], ["Zheng", "Tianyao", ""]]}, {"id": "1909.05095", "submitter": "Carlos Eduardo Rosar Kos Lassance", "authors": "Carlos Lassance, Vincent Gripon, Jian Tang, Antonio Ortega", "title": "Structural Robustness for Deep Learning Architectures", "comments": null, "journal-ref": null, "doi": "10.1109/DSW.2019.8755564", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Networks have been shown to provide state-of-the-art performance in many\nmachine learning challenges. Unfortunately, they are susceptible to various\ntypes of noise, including adversarial attacks and corrupted inputs. In this\nwork we introduce a formal definition of robustness which can be viewed as a\nlocalized Lipschitz constant of the network function, quantified in the domain\nof the data to be classified. We compare this notion of robustness to existing\nones, and study its connections with methods in the literature. We evaluate\nthis metric by performing experiments on various competitive vision datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 14:52:18 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Lassance", "Carlos", ""], ["Gripon", "Vincent", ""], ["Tang", "Jian", ""], ["Ortega", "Antonio", ""]]}, {"id": "1909.05097", "submitter": "Chieh Wu T", "authors": "Chieh Wu, Jared Miller, Yale Chang, Mario Sznaier, Jennifer Dy", "title": "Spectral Non-Convex Optimization for Dimension Reduction with\n  Hilbert-Schmidt Independence Criterion", "comments": "arXiv admin note: substantial text overlap with arXiv:1909.03093", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hilbert Schmidt Independence Criterion (HSIC) is a kernel dependence\nmeasure that has applications in various aspects of machine learning.\nConveniently, the objectives of different dimensionality reduction applications\nusing HSIC often reduce to the same optimization problem. However, the\nnonconvexity of the objective function arising from non-linear kernels poses a\nserious challenge to optimization efficiency and limits the potential of\nHSIC-based formulations. As a result, only linear kernels have been\ncomputationally tractable in practice. This paper proposes a spectral-based\noptimization algorithm that extends beyond the linear kernel. The algorithm\nidentifies a family of suitable kernels and provides the first and second-order\nlocal guarantees when a fixed point is reached. Furthermore, we propose a\nprincipled initialization strategy, thereby removing the need to repeat the\nalgorithm at random initialization points. Compared to state-of-the-art\noptimization algorithms, our empirical results on real data show a run-time\nimprovement by as much as a factor of $10^5$ while consistently achieving lower\ncost and classification/clustering errors. The implementation source code is\npublicly available on https://github.com/endsley.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 20:41:04 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Wu", "Chieh", ""], ["Miller", "Jared", ""], ["Chang", "Yale", ""], ["Sznaier", "Mario", ""], ["Dy", "Jennifer", ""]]}, {"id": "1909.05099", "submitter": "Cl\\'ement Christophe", "authors": "Cl\\'ement Christophe, Julien Velcin, Jairo Cugliari, Philippe\n  Suignard, Manel Boumghar", "title": "How to detect novelty in textual data streams? A comparative study of\n  existing methods", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since datasets with annotation for novelty at the document and/or word level\nare not easily available, we present a simulation framework that allows us to\ncreate different textual datasets in which we control the way novelty occurs.\nWe also present a benchmark of existing methods for novelty detection in\ntextual data streams. We define a few tasks to solve and compare several\nstate-of-the-art methods. The simulation framework allows us to evaluate their\nperformances according to a set of limited scenarios and test their sensitivity\nto some parameters. Finally, we experiment with the same methods on different\nkinds of novelty in the New York Times Annotated Dataset.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 14:55:02 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Christophe", "Cl\u00e9ment", ""], ["Velcin", "Julien", ""], ["Cugliari", "Jairo", ""], ["Suignard", "Philippe", ""], ["Boumghar", "Manel", ""]]}, {"id": "1909.05100", "submitter": "Chen Cai", "authors": "Chen Cai", "title": "Group Representation Theory for Knowledge Graph Embedding", "comments": "Paper withdrawn due to company policy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding has recently become a popular way to model\nrelations and infer missing links. In this paper, we present a group\ntheoretical perspective of knowledge graph embedding, connecting previous\nmethods with different group actions. Furthermore, by utilizing Schur's lemma\nfrom group representation theory, we show that the state of the art embedding\nmethod RotatE can model relations from any finite Abelian group.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 14:55:19 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 16:24:46 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Cai", "Chen", ""]]}, {"id": "1909.05106", "submitter": "Bastian Alt", "authors": "Bastian Alt, Adrian \\v{S}o\\v{s}i\\'c, Heinz Koeppl", "title": "Correlation Priors for Reinforcement Learning", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many decision-making problems naturally exhibit pronounced structures\ninherited from the characteristics of the underlying environment. In a Markov\ndecision process model, for example, two distinct states can have inherently\nrelated semantics or encode resembling physical state configurations. This\noften implies locally correlated transition dynamics among the states. In order\nto complete a certain task in such environments, the operating agent usually\nneeds to execute a series of temporally and spatially correlated actions.\nThough there exists a variety of approaches to capture these correlations in\ncontinuous state-action domains, a principled solution for discrete\nenvironments is missing. In this work, we present a Bayesian learning framework\nbased on P\\'olya-Gamma augmentation that enables an analogous reasoning in such\ncases. We demonstrate the framework on a number of common decision-making\nrelated problems, such as imitation learning, subgoal extraction, system\nidentification and Bayesian reinforcement learning. By explicitly modeling the\nunderlying correlation structures of these problems, the proposed approach\nyields superior predictive performance compared to correlation-agnostic models,\neven when trained on data sets that are an order of magnitude smaller in size.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 15:01:31 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 11:01:39 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Alt", "Bastian", ""], ["\u0160o\u0161i\u0107", "Adrian", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1909.05114", "submitter": "Jannis Born", "authors": "Jannis Born, Matteo Manica, Ali Oskooei, Joris Cadow, Karsten\n  Borgwardt, Mar\\'ia Rodr\\'iguez Mart\\'inez", "title": "PaccMann$^{RL}$: Designing anticancer drugs from transcriptomic data via\n  reinforcement learning", "comments": "18 pages total (12 pages main text, 4 pages references, 11 pages\n  appendix) 8 figures", "journal-ref": "International Conference on Research in Computational Molecular\n  Biology 2020", "doi": "10.1007/978-3-030-45257-5_18", "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of deep generative models in computational chemistry, in\nsilico anticancer drug design has undergone an unprecedented transformation.\nWhile state-of-the-art deep learning approaches have shown potential in\ngenerating compounds with desired chemical properties, they disregard the\ngenetic profile and properties of the target disease. Here, we introduce the\nfirst generative model capable of tailoring anticancer compounds for a specific\nbiomolecular profile. Using a RL framework, the transcriptomic profiles of\ncancer cells are used as a context for the generation of candidate molecules.\nOur molecule generator combines two separately pretrained variational\nautoencoders (VAEs) - the first VAE encodes transcriptomic profiles into a\nsmooth, latent space which in turn is used to condition a second VAE to\ngenerate novel molecular structures on the given transcriptomic profile. The\ngenerative process is optimized through PaccMann, a previously developed drug\nsensitivity prediction model to obtain effective anticancer compounds for the\ngiven context (i.e., transcriptomic profile). We demonstrate how the molecule\ngeneration can be biased towards compounds with high predicted inhibitory\neffect against individual cell lines or specific cancer sites. We verify our\napproach by investigating candidate drugs generated against specific cancer\ntypes and find the highest structural similarity to existing compounds with\nknown efficacy against these cancer types. We envision our approach to\ntransform in silico anticancer drug design by leveraging the biomolecular\ncharacteristics of the disease in order to increase success rates in lead\ncompound discovery.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 18:27:27 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 10:08:35 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 21:08:45 GMT"}, {"version": "v4", "created": "Thu, 16 Apr 2020 18:25:28 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Born", "Jannis", ""], ["Manica", "Matteo", ""], ["Oskooei", "Ali", ""], ["Cadow", "Joris", ""], ["Borgwardt", "Karsten", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""]]}, {"id": "1909.05122", "submitter": "Varun Kanade", "authors": "Tomas Va\\v{s}kevi\\v{c}ius, Varun Kanade and Patrick Rebeschini", "title": "Implicit Regularization for Optimal Sparse Recovery", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate implicit regularization schemes for gradient descent methods\napplied to unpenalized least squares regression to solve the problem of\nreconstructing a sparse signal from an underdetermined system of linear\nmeasurements under the restricted isometry assumption. For a given\nparametrization yielding a non-convex optimization problem, we show that\nprescribed choices of initialization, step size and stopping time yield a\nstatistically and computationally optimal algorithm that achieves the minimax\nrate with the same cost required to read the data up to poly-logarithmic\nfactors. Beyond minimax optimality, we show that our algorithm adapts to\ninstance difficulty and yields a dimension-independent rate when the\nsignal-to-noise ratio is high enough. Key to the computational efficiency of\nour method is an increasing step size scheme that adapts to refined estimates\nof the true solution. We validate our findings with numerical experiments and\ncompare our algorithm against explicit $\\ell_{1}$ penalization. Going from hard\ninstances to easy ones, our algorithm is seen to undergo a phase transition,\neventually matching least squares with an oracle knowledge of the true support.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 15:15:08 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Va\u0161kevi\u010dius", "Tomas", ""], ["Kanade", "Varun", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "1909.05125", "submitter": "Luis Mu\\~noz-Gonz\\'alez", "authors": "Luis Mu\\~noz-Gonz\\'alez, Kenneth T. Co, Emil C. Lupu", "title": "Byzantine-Robust Federated Machine Learning through Adaptive Model\n  Averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables training collaborative machine learning models at\nscale with many participants whilst preserving the privacy of their datasets.\nStandard federated learning techniques are vulnerable to Byzantine failures,\nbiased local datasets, and poisoning attacks. In this paper we introduce\nAdaptive Federated Averaging, a novel algorithm for robust federated learning\nthat is designed to detect failures, attacks, and bad updates provided by\nparticipants in a collaborative model. We propose a Hidden Markov Model to\nmodel and learn the quality of model updates provided by each participant\nduring training. In contrast to existing robust federated learning schemes, we\npropose a robust aggregation rule that detects and discards bad or malicious\nlocal model updates at each training iteration. This includes a mechanism that\nblocks unwanted participants, which also increases the computational and\ncommunication efficiency. Our experimental evaluation on 4 real datasets show\nthat our algorithm is significantly more robust to faulty, noisy and malicious\nparticipants, whilst being computationally more efficient than other\nstate-of-the-art robust federated learning methods such as Multi-KRUM and\ncoordinate-wise median.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 15:19:36 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Co", "Kenneth T.", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1909.05136", "submitter": "Haijun Yu", "authors": "Bo Li, Shanshan Tang and Haijun Yu", "title": "PowerNet: Efficient Representations of Polynomials and Smooth Functions\n  by Deep Neural Networks with Rectified Power Units", "comments": "22 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1903.05858", "journal-ref": "J. Math. Study Vol. 53, No. 2, pp. 159-191, 2020", "doi": "10.4208/jms.v53n2.20.03", "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network with rectified linear units (ReLU) is getting more and\nmore popular recently. However, the derivatives of the function represented by\na ReLU network are not continuous, which limit the usage of ReLU network to\nsituations only when smoothness is not required. In this paper, we construct\ndeep neural networks with rectified power units (RePU), which can give better\napproximations for smooth functions. Optimal algorithms are proposed to\nexplicitly build neural networks with sparsely connected RePUs, which we call\nPowerNets, to represent polynomials with no approximation error. For general\nsmooth functions, we first project the function to their polynomial\napproximations, then use the proposed algorithms to construct corresponding\nPowerNets. Thus, the error of best polynomial approximation provides an upper\nbound of the best RePU network approximation error. For smooth functions in\nhigher dimensional Sobolev spaces, we use fast spectral transforms for\ntensor-product grid and sparse grid discretization to get polynomial\napproximations. Our constructive algorithms show clearly a close connection\nbetween spectral methods and deep neural networks: a PowerNet with $n$ layers\ncan exactly represent polynomials up to degree $s^n$, where $s$ is the power of\nRePUs. The proposed PowerNets have potential applications in the situations\nwhere high-accuracy is desired or smoothness is required.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 05:21:49 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Li", "Bo", ""], ["Tang", "Shanshan", ""], ["Yu", "Haijun", ""]]}, {"id": "1909.05142", "submitter": "Majnu John", "authors": "Sujit Vettam, Majnu John", "title": "Regularized deep learning with nonconvex penalties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization methods are often employed in deep learning neural networks\n(DNNs) to prevent overfitting. For penalty based DNN regularization methods,\nconvex penalties are typically considered because of their optimization\nguarantees. Recent theoretical work have shown that nonconvex penalties that\nsatisfy certain regularity conditions are also guaranteed to perform well with\nstandard optimization algorithms. In this paper, we examine new and currently\nexisting nonconvex penalties for DNN regularization. We provide theoretical\njustifications for the new penalties and also assess the performance of all\npenalties with DNN analyses of seven datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 15:32:44 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 15:48:42 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 18:24:15 GMT"}, {"version": "v4", "created": "Thu, 19 Nov 2020 19:56:37 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Vettam", "Sujit", ""], ["John", "Majnu", ""]]}, {"id": "1909.05151", "submitter": "Samuel Showalter", "authors": "Samuel Showalter and Jeffrey Gropp", "title": "Validating Weak-form Market Efficiency in United States Stock Markets\n  with Trend Deterministic Price Data and Machine Learning", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Efficient Market Hypothesis has been a staple of economics research for\ndecades. In particular, weak-form market efficiency -- the notion that past\nprices cannot predict future performance -- is strongly supported by\neconometric evidence. In contrast, machine learning algorithms implemented to\npredict stock price have been touted, to varying degrees, as successful.\nMoreover, some data scientists boast the ability to garner above-market returns\nusing price data alone. This study endeavors to connect existing econometric\nresearch on weak-form efficient markets with data science innovations in\nalgorithmic trading. First, a traditional exploration of stationarity in stock\nindex prices over the past decade is conducted with Augmented Dickey-Fuller and\nVariance Ratio tests. Then, an algorithmic trading platform is implemented with\nthe use of five machine learning algorithms. Econometric findings identify\npotential stationarity, hinting technical evaluation may be possible, though\nalgorithmic trading results find little predictive power in any machine\nlearning model, even when using trend-specific metrics. Accounting for\ntransaction costs and risk, no system achieved above-market returns\nconsistently. Our findings reinforce the validity of weak-form market\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 15:39:49 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Showalter", "Samuel", ""], ["Gropp", "Jeffrey", ""]]}, {"id": "1909.05152", "submitter": "Alireza Rahimpour", "authors": "Alireza Rahimpour, Sujitha Martin, Ashish Tawari, Hairong Qi", "title": "Context Aware Road-user Importance Estimation (iCARE)", "comments": "Published in: IEEE Intelligent Vehicles (IV), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road-users are a critical part of decision-making for both self-driving cars\nand driver assistance systems. Some road-users, however, are more important for\ndecision-making than others because of their respective intentions, ego\nvehicle's intention and their effects on each other. In this paper, we propose\na novel architecture for road-user importance estimation which takes advantage\nof the local and global context of the scene. For local context, the model\nexploits the appearance of the road users (which captures orientation,\nintention, etc.) and their location relative to ego-vehicle. The global context\nin our model is defined based on the feature map of the convolutional layer of\nthe module which predicts the future path of the ego-vehicle and contains rich\nglobal information of the scene (e.g., infrastructure, road lanes, etc.), as\nwell as the ego vehicle's intention information. Moreover, this paper\nintroduces a new data set of real-world driving, concentrated around\ninter-sections and includes annotations of important road users. Systematic\nevaluations of our proposed method against several baselines show promising\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 05:54:44 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Rahimpour", "Alireza", ""], ["Martin", "Sujitha", ""], ["Tawari", "Ashish", ""], ["Qi", "Hairong", ""]]}, {"id": "1909.05167", "submitter": "Kacper Sokol", "authors": "Kacper Sokol, Raul Santos-Rodriguez, Peter Flach", "title": "FAT Forensics: A Python Toolbox for Algorithmic Fairness, Accountability\n  and Transparency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms can take important decisions, sometimes legally\nbinding, about our everyday life. In most cases, however, these systems and\ndecisions are neither regulated nor certified. Given the potential harm that\nthese algorithms can cause, qualities such as fairness, accountability and\ntransparency of predictive systems are of paramount importance. Recent\nliterature suggested voluntary self-reporting on these aspects of predictive\nsystems -- e.g., data sheets for data sets -- but their scope is often limited\nto a single component of a machine learning pipeline, and producing them\nrequires manual labour. To resolve this impasse and ensure high-quality, fair,\ntransparent and reliable machine learning systems, we developed an open source\ntoolbox that can inspect selected fairness, accountability and transparency\naspects of these systems to automatically and objectively report them back to\ntheir engineers and users. We describe design, scope and usage examples of this\nPython toolbox in this paper. The toolbox provides functionality for inspecting\nfairness, accountability and transparency of all aspects of the machine\nlearning process: data (and their features), models and predictions. It is\navailable to the public under the BSD 3-Clause open source licence.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:11:44 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Sokol", "Kacper", ""], ["Santos-Rodriguez", "Raul", ""], ["Flach", "Peter", ""]]}, {"id": "1909.05176", "submitter": "Ling Feng", "authors": "Ling Feng, Lin Zhang and Choy Heng Lai", "title": "Optimal Machine Intelligence at the Edge of Chaos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE nlin.AO nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been suggested that the biological brain operates at some\ncritical point between two different phases, possibly order and chaos. Despite\nmany indirect empirical evidence from the brain and analytical indication on\nsimple neural networks, the foundation of this hypothesis on generic non-linear\nsystems remains unclear. Here we develop a general theory that reveals the\nexact edge of chaos is the boundary between the chaotic phase and the\n(pseudo)periodic phase arising from Neimark-Sacker bifurcation. This edge is\nanalytically determined by the asymptotic Jacobian norm values of the\nnon-linear operator and influenced by the dimensionality of the system. The\noptimality at the edge of chaos is associated with the highest information\ntransfer between input and output at this point similar to that of the logistic\nmap. As empirical validations, our experiments on the various deep learning\nmodels in computer vision demonstrate the optimality of the models near the\nedge of chaos, and we observe that the state-of-art training algorithms push\nthe models towards such edge as they become more accurate. We further\nestablishes the theoretical understanding of deep learning model generalization\nthrough asymptotic stability.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:23:13 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 10:16:34 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Feng", "Ling", ""], ["Zhang", "Lin", ""], ["Lai", "Choy Heng", ""]]}, {"id": "1909.05189", "submitter": "Aaron Halfaker", "authors": "Aaron Halfaker and R. Stuart Geiger", "title": "ORES: Lowering Barriers with Participatory Machine Learning in Wikipedia", "comments": "29 pages + 3 pages appendix. Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Algorithmic systems---from rule-based bots to machine learning\nclassifiers---have a long history of supporting the essential work of content\nmoderation and other curation work in peer production projects. From\ncounter-vandalism to task routing, basic machine prediction has allowed open\nknowledge projects like Wikipedia to scale to the largest encyclopedia in the\nworld, while maintaining quality and consistency. However, conversations about\nhow quality control should work and what role algorithms should play have\ngenerally been led by the expert engineers who have the skills and resources to\ndevelop and modify these complex algorithmic systems. In this paper, we\ndescribe ORES: an algorithmic scoring service that supports real-time scoring\nof wiki edits using multiple independent classifiers trained on different\ndatasets. ORES decouples several activities that have typically all been\nperformed by engineers: choosing or curating training data, building models to\nserve predictions, auditing predictions, and developing interfaces or automated\nagents that act on those predictions. This meta-algorithmic system was designed\nto open up socio-technical conversations about algorithms in Wikipedia to a\nbroader set of participants. In this paper, we discuss the theoretical\nmechanisms of social change ORES enables and detail case studies in\nparticipatory machine learning around ORES from the 5 years since its\ndeployment.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:40:03 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 14:19:58 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 14:35:49 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Halfaker", "Aaron", ""], ["Geiger", "R. Stuart", ""]]}, {"id": "1909.05190", "submitter": "Kuo Liao", "authors": "Xiao Ding, Kuo Liao, Ting Liu, Zhongyang Li, Junwen Duan", "title": "Event Representation Learning Enhanced with External Commonsense\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work has proposed effective methods to learn event representations that\ncan capture syntactic and semantic information over text corpus, demonstrating\ntheir effectiveness for downstream tasks such as script event prediction. On\nthe other hand, events extracted from raw texts lacks of commonsense knowledge,\nsuch as the intents and emotions of the event participants, which are useful\nfor distinguishing event pairs when there are only subtle differences in their\nsurface realizations. To address this issue, this paper proposes to leverage\nexternal commonsense knowledge about the intent and sentiment of the event.\nExperiments on three event-related tasks, i.e., event similarity, script event\nprediction and stock market prediction, show that our model obtains much better\nevent embeddings for the tasks, achieving 78% improvements on hard similarity\ntask, yielding more precise inferences on subsequent events under given\ncontexts, and better accuracies in predicting the volatilities of the stock\nmarket.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 03:00:39 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 08:51:02 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ding", "Xiao", ""], ["Liao", "Kuo", ""], ["Liu", "Ting", ""], ["Li", "Zhongyang", ""], ["Duan", "Junwen", ""]]}, {"id": "1909.05192", "submitter": "Bernhard Lutz", "authors": "Bernhard Lutz, Nicolas Pr\\\"ollochs, Dirk Neumann", "title": "The Longer the Better? The Interplay Between Review Length and Line of\n  Argumentation in Online Consumer Reviews", "comments": "arXiv admin note: text overlap with arXiv:1810.10942", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Review helpfulness serves as focal point in understanding customers' purchase\ndecision-making process on online retailer platforms. An overwhelming majority\nof previous works find longer reviews to be more helpful than short reviews. In\nthis paper, we propose that longer reviews should not be assumed to be\nuniformly more helpful; instead, we argue that the effect depends on the line\nof argumentation in the review text. To test this idea, we use a large dataset\nof customer reviews from Amazon in combination with a state-of-the-art approach\nfrom natural language processing that allows us to study argumentation lines at\nsentence level. Our empirical analysis suggests that the frequency of\nargumentation changes moderates the effect of review length on helpfulness.\nAltogether, we disprove the prevailing narrative that longer reviews are\nuniformly perceived as more helpful. Our findings allow retailer platforms to\nimprove their customer feedback systems and to feature more useful product\nreviews.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:19:51 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 18:51:18 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 09:25:44 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Lutz", "Bernhard", ""], ["Pr\u00f6llochs", "Nicolas", ""], ["Neumann", "Dirk", ""]]}, {"id": "1909.05193", "submitter": "Adnan Siraj Rakin", "authors": "Adnan Siraj Rakin, Zhezhi He and Deliang Fan", "title": "TBT: Targeted Neural Network Attack with Bit Trojan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security of modern Deep Neural Networks (DNNs) is under severe scrutiny as\nthe deployment of these models become widespread in many intelligence-based\napplications. Most recently, DNNs are attacked through Trojan which can\neffectively infect the model during the training phase and get activated only\nthrough specific input patterns (i.e, trigger) during inference. In this work,\nfor the first time, we propose a novel Targeted Bit Trojan(TBT) method, which\ncan insert a targeted neural Trojan into a DNN through the bit-flip attack. Our\nalgorithm efficiently generates a trigger specifically designed to locate\ncertain vulnerable bits of DNN weights stored in main memory (i.e., DRAM). The\nobjective is that once the attacker flips these vulnerable bits, the network\nstill operates with normal inference accuracy with benign input. However, when\nthe attacker activates the trigger by embedding it with any input, the network\nis forced to classify all inputs to a certain target class. We demonstrate that\nflipping only several vulnerable bits identified by our method, using available\nbit-flip techniques (i.e, row-hammer), can transform a fully functional DNN\nmodel into a Trojan-infected model. We perform extensive experiments of\nCIFAR-10, SVHN and ImageNet datasets on both VGG-16 and Resnet-18\narchitectures. Our proposed TBT could classify 92 % of test images to a target\nclass with as little as 84 bit-flips out of 88 million weight bits on Resnet-18\nfor CIFAR10 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 07:51:26 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 03:32:09 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 00:16:32 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Rakin", "Adnan Siraj", ""], ["He", "Zhezhi", ""], ["Fan", "Deliang", ""]]}, {"id": "1909.05197", "submitter": "Jan Carius", "authors": "Jan Carius, Farbod Farshidian, Marco Hutter", "title": "MPC-Net: A First Principles Guided Policy Search", "comments": null, "journal-ref": null, "doi": "10.1109/LRA.2020.2974653", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an Imitation Learning approach for the control of dynamical\nsystems with a known model. Our policy search method is guided by solutions\nfrom MPC. Typical policy search methods of this kind minimize a distance metric\nbetween the guiding demonstrations and the learned policy. Our loss function,\nhowever, corresponds to the minimization of the control Hamiltonian, which\nderives from the principle of optimality. Therefore, our algorithm directly\nattempts to solve the optimality conditions with a parameterized class of\ncontrol laws. Additionally, the proposed loss function explicitly encodes the\nconstraints of the optimal control problem and we provide numerical evidence\nthat its minimization achieves improved constraint satisfaction. We train a\nmixture-of-expert neural network architecture for controlling a quadrupedal\nrobot and show that this policy structure is well suited for such multimodal\nsystems. The learned policy can successfully stabilize different gaits on the\nreal walking robot from less than 10 min of demonstration data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:48:10 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 17:23:26 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Carius", "Jan", ""], ["Farshidian", "Farbod", ""], ["Hutter", "Marco", ""]]}, {"id": "1909.05207", "submitter": "Elad Hazan", "authors": "Elad Hazan", "title": "Introduction to Online Convex Optimization", "comments": "arXiv admin note: text overlap with arXiv:1909.03550", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript portrays optimization as a process. In many practical\napplications the environment is so complex that it is infeasible to lay out a\ncomprehensive theoretical model and use classical algorithmic theory and\nmathematical optimization. It is necessary as well as beneficial to take a\nrobust approach, by applying an optimization method that learns as one goes\nalong, learning from experience as more aspects of the problem are observed.\nThis view of optimization as a process has become prominent in varied fields\nand has led to some spectacular success in modeling and systems that are now\npart of our daily lives.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 19:06:23 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Hazan", "Elad", ""]]}, {"id": "1909.05215", "submitter": "Ellen Zhong", "authors": "Ellen D. Zhong, Tristan Bepler, Joseph H. Davis, Bonnie Berger", "title": "Reconstructing continuous distributions of 3D protein structure from\n  cryo-EM images", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR), 2020", "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryo-electron microscopy (cryo-EM) is a powerful technique for determining\nthe structure of proteins and other macromolecular complexes at near-atomic\nresolution. In single particle cryo-EM, the central problem is to reconstruct\nthe three-dimensional structure of a macromolecule from $10^{4-7}$ noisy and\nrandomly oriented two-dimensional projections. However, the imaged protein\ncomplexes may exhibit structural variability, which complicates reconstruction\nand is typically addressed using discrete clustering approaches that fail to\ncapture the full range of protein dynamics. Here, we introduce a novel method\nfor cryo-EM reconstruction that extends naturally to modeling continuous\ngenerative factors of structural heterogeneity. This method encodes structures\nin Fourier space using coordinate-based deep neural networks, and trains these\nnetworks from unlabeled 2D cryo-EM images by combining exact inference over\nimage orientation with variational inference for structural heterogeneity. We\ndemonstrate that the proposed method, termed cryoDRGN, can perform ab initio\nreconstruction of 3D protein complexes from simulated and real 2D cryo-EM image\ndata. To our knowledge, cryoDRGN is the first neural network-based approach for\ncryo-EM reconstruction and the first end-to-end method for directly\nreconstructing continuous ensembles of protein structures from cryo-EM images.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 17:13:06 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 23:45:23 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 04:31:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhong", "Ellen D.", ""], ["Bepler", "Tristan", ""], ["Davis", "Joseph H.", ""], ["Berger", "Bonnie", ""]]}, {"id": "1909.05229", "submitter": "Rui Zhang", "authors": "Alexander Shapiro, Yao Xie, Rui Zhang", "title": "Goodness-of-fit tests on manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general theory for the goodness-of-fit test to non-linear\nmodels. In particular, we assume that the observations are noisy samples of a\nsubmanifold defined by a \\yao{sufficiently smooth non-linear map}. The\nobservation noise is additive Gaussian. Our main result shows that the\n\"residual\" of the model fit, by solving a non-linear least-square problem,\nfollows a (possibly noncentral) $\\chi^2$ distribution. The parameters of the\n$\\chi^2$ distribution are related to the model order and dimension of the\nproblem. We further present a method to select the model orders sequentially.\nWe demonstrate the broad application of the general theory in machine learning\nand signal processing, including determining the rank of low-rank (possibly\ncomplex-valued) matrices and tensors from noisy, partial, or indirect\nobservations, determining the number of sources in signal demixing, and\npotential applications in determining the number of hidden nodes in neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 17:38:25 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 21:32:24 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shapiro", "Alexander", ""], ["Xie", "Yao", ""], ["Zhang", "Rui", ""]]}, {"id": "1909.05233", "submitter": "Ankur Mali", "authors": "Ankur Mali, Alexander Ororbia, C. Lee Giles", "title": "The Neural State Pushdown Automata", "comments": "10 pages, 7 Table, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to learn complex grammars, recurrent neural networks (RNNs) require\nsufficient computational resources to ensure correct grammar recognition. A\nwidely-used approach to expand model capacity would be to couple an RNN to an\nexternal memory stack. Here, we introduce a \"neural state\" pushdown automaton\n(NSPDA), which consists of a digital stack, instead of an analog one, that is\ncoupled to a neural network state machine. We empirically show its\neffectiveness in recognizing various context-free grammars (CFGs). First, we\ndevelop the underlying mechanics of the proposed higher order recurrent network\nand its manipulation of a stack as well as how to stably program its underlying\npushdown automaton (PDA) to achieve desired finite-state network dynamics.\nNext, we introduce a noise regularization scheme for higher-order (tensor)\nnetworks, to our knowledge the first of its kind, and design an algorithm for\nimproved incremental learning. Finally, we design a method for inserting\ngrammar rules into a NSPDA and empirically show that this prior knowledge\nimproves its training convergence time by an order of magnitude and, in some\ncases, leads to better generalization. The NSPDA is also compared to a\nclassical analog stack neural network pushdown automaton (NNPDA) as well as a\nwide array of first and second-order RNNs with and without external memory,\ntrained using different learning algorithms. Our results show that, for Dyck(2)\nlanguages, prior rule-based knowledge is critical for optimization convergence\nand for ensuring generalization to longer sequences at test time. We observe\nthat many RNNs with and without memory, but no prior knowledge, fail to\nconverge and generalize poorly on CFGs.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 00:32:11 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 20:12:33 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Mali", "Ankur", ""], ["Ororbia", "Alexander", ""], ["Giles", "C. Lee", ""]]}, {"id": "1909.05236", "submitter": "Thiago D. Sim\\~ao", "authors": "Thiago D. Sim\\~ao, Romain Laroche, R\\'emi Tachet des Combes", "title": "Safe Policy Improvement with an Estimated Baseline Policy", "comments": "Published at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous work has shown the unreliability of existing algorithms in the batch\nReinforcement Learning setting, and proposed the theoretically-grounded Safe\nPolicy Improvement with Baseline Bootstrapping (SPIBB) fix: reproduce the\nbaseline policy in the uncertain state-action pairs, in order to control the\nvariance on the trained policy performance. However, in many real-world\napplications such as dialogue systems, pharmaceutical tests or crop management,\ndata is collected under human supervision and the baseline remains unknown. In\nthis paper, we apply SPIBB algorithms with a baseline estimate built from the\ndata. We formally show safe policy improvement guarantees over the true\nbaseline even without direct access to it. Our empirical experiments on finite\nand continuous states tasks support the theoretical findings. It shows little\nloss of performance in comparison with SPIBB when the baseline policy is given,\nand more importantly, drastically and significantly outperforms competing\nalgorithms both in safe policy improvement, and in average performance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 17:48:00 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 20:25:07 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Sim\u00e3o", "Thiago D.", ""], ["Laroche", "Romain", ""], ["Combes", "R\u00e9mi Tachet des", ""]]}, {"id": "1909.05244", "submitter": "Liyang Sun", "authors": "Rahul Singh and Liyang Sun", "title": "De-biased Machine Learning in Instrumental Variable Models for Treatment\n  Effects", "comments": "41 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a de-biased machine learning (DML) approach to estimating\ncomplier parameters with high-dimensional data. Complier parameters include\nlocal average treatment effect, average complier characteristics, and complier\ncounterfactual outcome distributions. In our approach, the de-biasing is itself\nperformed by machine learning, a variant called automatic de-biased machine\nlearning (Auto-DML). By regularizing the balancing weights, it does not require\nad hoc trimming or censoring. We prove our estimator is consistent,\nasymptotically normal, and semi-parametrically efficient. We use the new\napproach to estimate the effect of 401(k) participation on the distribution of\nnet financial assets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 16:08:54 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 14:41:14 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 05:06:29 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Singh", "Rahul", ""], ["Sun", "Liyang", ""]]}, {"id": "1909.05246", "submitter": "Mansour Saffar Mehrjardi", "authors": "Mansour Saffar Mehrjardi, Amine Trabelsi, Osmar R. Zaiane", "title": "Self-Attentional Models Application in Task-Oriented Dialogue Generation\n  Systems", "comments": "Appeared in proceedings of Recent Advances in Natural Language\n  Processing (RANLP) Conference, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-attentional models are a new paradigm for sequence modelling tasks which\ndiffer from common sequence modelling methods, such as recurrence-based and\nconvolution-based sequence learning, in the way that their architecture is only\nbased on the attention mechanism. Self-attentional models have been used in the\ncreation of the state-of-the-art models in many NLP tasks such as neural\nmachine translation, but their usage has not been explored for the task of\ntraining end-to-end task-oriented dialogue generation systems yet. In this\nstudy, we apply these models on the three different datasets for training\ntask-oriented chatbots. Our finding shows that self-attentional models can be\nexploited to create end-to-end task-oriented chatbots which not only achieve\nhigher evaluation scores compared to recurrence-based models, but also do so\nmore efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 03:40:26 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Mehrjardi", "Mansour Saffar", ""], ["Trabelsi", "Amine", ""], ["Zaiane", "Osmar R.", ""]]}, {"id": "1909.05288", "submitter": "Shuyang Dai", "authors": "Shuyang Dai, Yu Cheng, Yizhe Zhang, Zhe Gan, Jingjing Liu, Lawrence\n  Carin", "title": "Contrastively Smoothed Class Alignment for Unsupervised Domain\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent unsupervised approaches to domain adaptation primarily focus on\nminimizing the gap between the source and the target domains through refining\nthe feature generator, in order to learn a better alignment between the two\ndomains. This minimization can be achieved via a domain classifier to detect\ntarget-domain features that are divergent from source-domain features. However,\nby optimizing via such domain classification discrepancy, ambiguous target\nsamples that are not smoothly distributed on the low-dimensional data manifold\nare often missed. To solve this issue, we propose a novel Contrastively\nSmoothed Class Alignment (CoSCA) model, that explicitly incorporates both\nintra- and inter-class domain discrepancy to better align ambiguous target\nsamples with the source domain. CoSCA estimates the underlying label hypothesis\nof target samples, and simultaneously adapts their feature representations by\noptimizing a proposed contrastive loss. In addition, Maximum Mean Discrepancy\n(MMD) is utilized to directly match features between source and target samples\nfor better global alignment. Experiments on several benchmark datasets\ndemonstrate that CoSCA can outperform state-of-the-art approaches for\nunsupervised domain adaptation by producing more discriminative features.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:32:00 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 18:30:08 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 19:29:52 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 21:09:02 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Dai", "Shuyang", ""], ["Cheng", "Yu", ""], ["Zhang", "Yizhe", ""], ["Gan", "Zhe", ""], ["Liu", "Jingjing", ""], ["Carin", "Lawrence", ""]]}, {"id": "1909.05289", "submitter": "Baptiste Barreau", "authors": "Baptiste Barreau, Laurent Carlier, Damien Challet", "title": "Deep Prediction of Investor Interest: a Supervised Clustering Approach", "comments": null, "journal-ref": "Algorithmic Finance, vol. 8, no. 3-4, pp. 77-89, 2020", "doi": "10.3233/AF-200296", "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep learning architecture suitable for the prediction of\ninvestor interest for a given asset in a given time frame. This architecture\nperforms both investor clustering and modelling at the same time. We first\nverify its superior performance on a synthetic scenario inspired by real data\nand then apply it to two real-world databases, a publicly available dataset\nabout the position of investors in Spanish stock market and proprietary data\nfrom BNP Paribas Corporate and Institutional Banking.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:32:06 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 06:56:22 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 13:28:01 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Barreau", "Baptiste", ""], ["Carlier", "Laurent", ""], ["Challet", "Damien", ""]]}, {"id": "1909.05299", "submitter": "Yuta Saito", "authors": "Yuta Saito, Shota Yasui", "title": "Counterfactual Cross-Validation: Stable Model Selection Procedure for\n  Causal Inference Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the model selection problem in conditional average treatment effect\n(CATE) prediction. Unlike previous works on this topic, we focus on preserving\nthe rank order of the performance of candidate CATE predictors to enable\naccurate and stable model selection. To this end, we analyze the model\nperformance ranking problem and formulate guidelines to obtain a better\nevaluation metric. We then propose a novel metric that can identify the ranking\nof the performance of CATE predictors with high confidence. Empirical\nevaluations demonstrate that our metric outperforms existing metrics in both\nmodel selection and hyperparameter tuning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:43:32 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 07:11:53 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 01:58:25 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 21:27:48 GMT"}, {"version": "v5", "created": "Thu, 16 Jul 2020 23:41:00 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Saito", "Yuta", ""], ["Yasui", "Shota", ""]]}, {"id": "1909.05304", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Yiannis Kantaros, Alessandro Abate, Daniel\n  Kroening, George J. Pappas, Insup Lee", "title": "Reinforcement Learning for Temporal Logic Control Synthesis with\n  Probabilistic Satisfaction Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has emerged as an efficient method of choice for\nsolving complex sequential decision making problems in automatic control,\ncomputer science, economics, and biology. In this paper we present a model-free\nRL algorithm to synthesize control policies that maximize the probability of\nsatisfying high-level control objectives given as Linear Temporal Logic (LTL)\nformulas. Uncertainty is considered in the workspace properties, the structure\nof the workspace, and the agent actions, giving rise to a\nProbabilistically-Labeled Markov Decision Process (PL-MDP) with unknown graph\nstructure and stochastic behaviour, which is even more general case than a\nfully unknown MDP. We first translate the LTL specification into a Limit\nDeterministic Buchi Automaton (LDBA), which is then used in an on-the-fly\nproduct with the PL-MDP. Thereafter, we define a synchronous reward function\nbased on the acceptance condition of the LDBA. Finally, we show that the RL\nalgorithm delivers a policy that maximizes the satisfaction probability\nasymptotically. We provide experimental results that showcase the efficiency of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:48:02 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Kantaros", "Yiannis", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""], ["Pappas", "George J.", ""], ["Lee", "Insup", ""]]}, {"id": "1909.05310", "submitter": "Tomasz Danel", "authors": "Tomasz Danel, Przemys{\\l}aw Spurek, Jacek Tabor, Marek \\'Smieja,\n  {\\L}ukasz Struski, Agnieszka S{\\l}owik, {\\L}ukasz Maziarka", "title": "Spatial Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have recently become the primary choice\nfor learning from graph-structured data, superseding hash fingerprints in\nrepresenting chemical compounds. However, GCNs lack the ability to take into\naccount the ordering of node neighbors, even when there is a geometric\ninterpretation of the graph vertices that provides an order based on their\nspatial positions. To remedy this issue, we propose Spatial Graph Convolutional\nNetwork (SGCN) which uses spatial features to efficiently learn from graphs\nthat can be naturally located in space. Our contribution is threefold: we\npropose a GCN-inspired architecture which (i) leverages node positions, (ii) is\na proper generalization of both GCNs and Convolutional Neural Networks (CNNs),\n(iii) benefits from augmentation which further improves the performance and\nassures invariance with respect to the desired properties. Empirically, SGCN\noutperforms state-of-the-art graph-based methods on image classification and\nchemical tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 18:59:41 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 14:29:14 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Danel", "Tomasz", ""], ["Spurek", "Przemys\u0142aw", ""], ["Tabor", "Jacek", ""], ["\u015amieja", "Marek", ""], ["Struski", "\u0141ukasz", ""], ["S\u0142owik", "Agnieszka", ""], ["Maziarka", "\u0141ukasz", ""]]}, {"id": "1909.05314", "submitter": "Xueyuan She", "authors": "Xueyuan She, Yun Long, Daehyun Kim, Saibal Mukhopadhyay", "title": "ScieNet: Deep Learning with Spike-assisted Contextual Information\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) provide high image classification accuracy, but\nexperience significant performance degradation when perturbation from various\nsources are present in the input. The lack of resilience to input perturbations\nmakes DNN less reliable for systems interacting with physical world such as\nautonomous vehicles, robotics, to name a few, where imperfect input is the\nnormal condition. We present a hybrid deep network architecture with\nspike-assisted contextual information extraction (ScieNet). ScieNet integrates\nunsupervised learning using spiking neural network (SNN) for unsupervised\ncontextual informationextraction with a back-end DNN trained for\nclassification. The integrated network demonstrates high resilience to input\nperturbations without relying on prior training on perturbed inputs. We\ndemonstrate ScieNet with different back-end DNNs for image classification using\nCIFAR dataset considering stochastic (noise) and structured (rain) input\nperturbations. Experimental results demonstrate significant improvement in\naccuracy on noisy and rainy images without prior training, while maintaining\nstate-of-the-art accuracy on clean images.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 19:10:07 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["She", "Xueyuan", ""], ["Long", "Yun", ""], ["Kim", "Daehyun", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "1909.05330", "submitter": "Arindrima Datta", "authors": "Anjuli Kannan, Arindrima Datta, Tara N. Sainath, Eugene Weinstein,\n  Bhuvana Ramabhadran, Yonghui Wu, Ankur Bapna, Zhifeng Chen, Seungji Lee", "title": "Large-Scale Multilingual Speech Recognition with a Streaming End-to-End\n  Model", "comments": "Accepted in Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual end-to-end (E2E) models have shown great promise in expansion of\nautomatic speech recognition (ASR) coverage of the world's languages. They have\nshown improvement over monolingual systems, and have simplified training and\nserving by eliminating language-specific acoustic, pronunciation, and language\nmodels. This work presents an E2E multilingual system which is equipped to\noperate in low-latency interactive applications, as well as handle a key\nchallenge of real world data: the imbalance in training data across languages.\nUsing nine Indic languages, we compare a variety of techniques, and find that a\ncombination of conditioning on a language vector and training language-specific\nadapter layers produces the best model. The resulting E2E multilingual model\nachieves a lower word error rate (WER) than both monolingual E2E models (eight\nof nine languages) and monolingual conventional systems (all nine languages).\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 19:46:21 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Kannan", "Anjuli", ""], ["Datta", "Arindrima", ""], ["Sainath", "Tara N.", ""], ["Weinstein", "Eugene", ""], ["Ramabhadran", "Bhuvana", ""], ["Wu", "Yonghui", ""], ["Bapna", "Ankur", ""], ["Chen", "Zhifeng", ""], ["Lee", "Seungji", ""]]}, {"id": "1909.05331", "submitter": "Roja Eini", "authors": "Roja Eini, Sherif Abdelwahed", "title": "Learning-based Model Predictive Control for Smart Building Thermal\n  Management", "comments": "5 pages, 9 figures, conference paper, accepted in the 16th\n  International Conference on Smart Cities: Improving Quality of Life Using ICT\n  & IoT (HONET-ICT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.NE cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a learning-based model predictive control (MPC) approach\nfor the thermal control of a four-zone smart building. The objectives are to\nminimize energy consumption and maintain the residents' comfort. The proposed\ncontrol scheme incorporates learning with the model-based control. The\noccupancy profile in the building zones are estimated in a long-term horizon\nthrough the artificial neural network (ANN), and this data is fed into the\nmodel-based predictor to get the indoor temperature predictions. The Energy\nPlus software is utilized as the actual dataset provider (weather data, indoor\ntemperature, energy consumption). The optimization problem, including the\nactual and predicted data, is solved in each step of the simulation and the\ninput setpoint temperature for the heating/cooling system, is generated.\nComparing the results of the proposed approach with the conventional MPC\nresults proved the significantly better performance of the proposed method in\nenergy savings (40.56% less cooling power consumption and 16.73% less heating\npower consumption), and residents' comfort.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 19:47:02 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Eini", "Roja", ""], ["Abdelwahed", "Sherif", ""]]}, {"id": "1909.05350", "submitter": "Sebastian U. Stich", "authors": "Sebastian U. Stich, Sai Praneeth Karimireddy", "title": "The Error-Feedback Framework: Better Rates for SGD with Delayed\n  Gradients and Compressed Communication", "comments": "Submitted 9/19, Published 9/20", "journal-ref": "Journal of Machine Learning Research (JMLR), 21(237):1-36, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze (stochastic) gradient descent (SGD) with delayed updates on smooth\nquasi-convex and non-convex functions and derive concise, non-asymptotic,\nconvergence rates. We show that the rate of convergence in all cases consists\nof two terms: (i) a stochastic term which is not affected by the delay, and\n(ii) a higher order deterministic term which is only linearly slowed down by\nthe delay. Thus, in the presence of noise, the effects of the delay become\nnegligible after a few iterations and the algorithm converges at the same\noptimal rate as standard SGD. This result extends a line of research that\nshowed similar results in the asymptotic regime or for strongly-convex\nquadratic functions only. We further show similar results for SGD with more\nintricate form of delayed gradients -- compressed gradients under error\ncompensation and for local~SGD where multiple workers perform local steps\nbefore communicating with each other. In all of these settings, we improve upon\nthe best known rates. These results show that SGD is robust to compressed\nand/or delayed stochastic gradient updates. This is in particular important for\ndistributed parallel implementations, where asynchronous and communication\nefficient methods are the key to achieve linear speedups for optimization with\nmultiple devices.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 20:54:49 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 15:44:47 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Stich", "Sebastian U.", ""], ["Karimireddy", "Sai Praneeth", ""]]}, {"id": "1909.05352", "submitter": "Junfeng Wen", "authors": "Junfeng Wen, Russell Greiner, Dale Schuurmans", "title": "Domain Aggregation Networks for Multi-Source Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications, we want to exploit multiple source datasets\nof similar tasks to learn a model for a different but related target dataset --\ne.g., recognizing characters of a new font using a set of different fonts.\nWhile most recent research has considered ad-hoc combination rules to address\nthis problem, we extend previous work on domain discrepancy minimization to\ndevelop a finite-sample generalization bound, and accordingly propose a\ntheoretically justified optimization procedure. The algorithm we develop,\nDomain AggRegation Network (DARN), is able to effectively adjust the weight of\neach source domain during training to ensure relevant domains are given more\nimportance for adaptation. We evaluate the proposed method on real-world\nsentiment analysis and digit recognition datasets and show that DARN can\nsignificantly outperform the state-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 21:02:40 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 07:15:37 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wen", "Junfeng", ""], ["Greiner", "Russell", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1909.05356", "submitter": "Alankar Jain", "authors": "Alankar Jain, Bhargavi Paranjape, Zachary C. Lipton", "title": "Entity Projection via Machine Translation for Cross-Lingual NER", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although over 100 languages are supported by strong off-the-shelf machine\ntranslation systems, only a subset of them possess large annotated corpora for\nnamed entity recognition. Motivated by this fact, we leverage machine\ntranslation to improve annotation-projection approaches to cross-lingual named\nentity recognition. We propose a system that improves over prior\nentity-projection methods by: (a) leveraging machine translation systems twice:\nfirst for translating sentences and subsequently for translating entities; (b)\nmatching entities based on orthographic and phonetic similarity; and (c)\nidentifying matches based on distributional statistics derived from the\ndataset. Our approach improves upon current state-of-the-art methods for\ncross-lingual named entity recognition on 5 diverse languages by an average of\n4.1 points. Further, our method achieves state-of-the-art F_1 scores for\nArmenian, outperforming even a monolingual model trained on Armenian source\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 17:40:21 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 06:44:24 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Jain", "Alankar", ""], ["Paranjape", "Bhargavi", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1909.05357", "submitter": "Ming Tan", "authors": "Ming Tan, Yang Yu, Haoyu Wang, Dakuo Wang, Saloni Potdar, Shiyu Chang,\n  Mo Yu", "title": "Out-of-Domain Detection for Low-Resource Text Classification Tasks", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-domain (OOD) detection for low-resource text classification is a\nrealistic but understudied task. The goal is to detect the OOD cases with\nlimited in-domain (ID) training data, since we observe that training data is\noften insufficient in machine learning applications. In this work, we propose\nan OOD-resistant Prototypical Network to tackle this zero-shot OOD detection\nand few-shot ID classification task. Evaluation on real-world datasets show\nthat the proposed solution outperforms state-of-the-art methods in zero-shot\nOOD detection task, while maintaining a competitive performance on ID\nclassification task.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 20:23:26 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Tan", "Ming", ""], ["Yu", "Yang", ""], ["Wang", "Haoyu", ""], ["Wang", "Dakuo", ""], ["Potdar", "Saloni", ""], ["Chang", "Shiyu", ""], ["Yu", "Mo", ""]]}, {"id": "1909.05358", "submitter": "Chinnadhurai Sankar", "authors": "Bill Byrne, Karthik Krishnamoorthi, Chinnadhurai Sankar, Arvind\n  Neelakantan, Daniel Duckworth, Semih Yavuz, Ben Goodrich, Amit Dubey, Andy\n  Cedilnik, Kyu-Young Kim", "title": "Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset", "comments": "To appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant barrier to progress in data-driven approaches to building\ndialog systems is the lack of high quality, goal-oriented conversational data.\nTo help satisfy this elementary requirement, we introduce the initial release\nof the Taskmaster-1 dataset which includes 13,215 task-based dialogs comprising\nsix domains. Two procedures were used to create this collection, each with\nunique advantages. The first involves a two-person, spoken \"Wizard of Oz\" (WOz)\napproach in which trained agents and crowdsourced workers interact to complete\nthe task while the second is \"self-dialog\" in which crowdsourced workers write\nthe entire dialog themselves. We do not restrict the workers to detailed\nscripts or to a small knowledge base and hence we observe that our dataset\ncontains more realistic and diverse conversations in comparison to existing\ndatasets. We offer several baseline models including state of the art neural\nseq2seq architectures with benchmark performance as well as qualitative human\nevaluations. Dialogs are labeled with API calls and arguments, a simple and\ncost effective approach which avoids the requirement of complex annotation\nschema. The layer of abstraction between the dialog model and the service\nprovider API allows for a given model to interact with multiple services that\nprovide similar functionally. Finally, the dataset will evoke interest in\nwritten vs. spoken language, discourse patterns, error handling and other\nlinguistic phenomena related to dialog system research, development and design.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2019 22:18:39 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Byrne", "Bill", ""], ["Krishnamoorthi", "Karthik", ""], ["Sankar", "Chinnadhurai", ""], ["Neelakantan", "Arvind", ""], ["Duckworth", "Daniel", ""], ["Yavuz", "Semih", ""], ["Goodrich", "Ben", ""], ["Dubey", "Amit", ""], ["Cedilnik", "Andy", ""], ["Kim", "Kyu-Young", ""]]}, {"id": "1909.05362", "submitter": "Mayank Sharma", "authors": "Prabhakar Gupta, Mayank Sharma, Kartik Pitale, Keshav Kumar", "title": "Problems with automating translation of movie/TV show subtitles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present 27 problems encountered in automating the translation of movie/TV\nshow subtitles. We categorize each problem in one of the three categories viz.\nproblems directly related to textual translation, problems related to subtitle\ncreation guidelines, and problems due to adaptability of machine translation\n(MT) engines. We also present the findings of a translation quality evaluation\nexperiment where we share the frequency of 16 key problems. We show that the\nsystems working at the frontiers of Natural Language Processing do not perform\nwell for subtitles and require some post-processing solutions for redressal of\nthese problems\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 06:45:51 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Gupta", "Prabhakar", ""], ["Sharma", "Mayank", ""], ["Pitale", "Kartik", ""], ["Kumar", "Keshav", ""]]}, {"id": "1909.05365", "submitter": "Mingyang Zhou", "authors": "Mingyang Zhou, Josh Arnold, Zhou Yu", "title": "Building Task-Oriented Visual Dialog Systems Through Alternative\n  Optimization Between Dialog Policy and Language Generation", "comments": "updated with acknowledgement and minor typo fixes on tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is an effective approach to learn an optimal\ndialog policy for task-oriented visual dialog systems. A common practice is to\napply RL on a neural sequence-to-sequence (seq2seq) framework with the action\nspace being the output vocabulary in the decoder. However, it is difficult to\ndesign a reward function that can achieve a balance between learning an\neffective policy and generating a natural dialog response. This paper proposes\na novel framework that alternatively trains a RL policy for image guessing and\na supervised seq2seq model to improve dialog generation quality. We evaluate\nour framework on the GuessWhich task and the framework achieves the\nstate-of-the-art performance in both task completion and dialog quality.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 01:28:34 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 19:45:17 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Zhou", "Mingyang", ""], ["Arnold", "Josh", ""], ["Yu", "Zhou", ""]]}, {"id": "1909.05367", "submitter": "Giuseppe Marra", "authors": "Marco Maggini, Giuseppe Marra, Stefano Melacci, Andrea Zugarini", "title": "Learning in Text Streams: Discovery and Disambiguation of Entity and\n  Relation Instances", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2019.2955597", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a scenario where an artificial agent is reading a stream of text\ncomposed of a set of narrations, and it is informed about the identity of some\nof the individuals that are mentioned in the text portion that is currently\nbeing read. The agent is expected to learn to follow the narrations, thus\ndisambiguating mentions and discovering new individuals. We focus on the case\nin which individuals are entities and relations, and we propose an end-to-end\ntrainable memory network that learns to discover and disambiguate them in an\nonline manner, performing one-shot learning, and dealing with a small number of\nsparse supervisions. Our system builds a not-given-in-advance knowledge base,\nand it improves its skills while reading unsupervised text. The model deals\nwith abrupt changes in the narration, taking into account their effects when\nresolving co-references. We showcase the strong disambiguation and discovery\nskills of our model on a corpus of Wikipedia documents and on a newly\nintroduced dataset, that we make publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:01:07 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 09:55:41 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 18:07:20 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Maggini", "Marco", ""], ["Marra", "Giuseppe", ""], ["Melacci", "Stefano", ""], ["Zugarini", "Andrea", ""]]}, {"id": "1909.05370", "submitter": "Yun Zhao", "authors": "Yun Zhao", "title": "An Auxiliary Classifier Generative Adversarial Framework for Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction models suffer from limited qualified training data. Using\nhuman annotators to label sentences is too expensive and does not scale well\nespecially when dealing with large datasets. In this paper, we use Auxiliary\nClassifier Generative Adversarial Networks (AC-GANs) to generate high-quality\nrelational sentences and to improve the performance of relation classifier in\nend-to-end models. In AC-GAN, the discriminator gives not only a probability\ndistribution over the real source, but also a probability distribution over the\nrelation labels. This helps to generate meaningful relational sentences.\nExperimental results show that our proposed data augmentation method\nsignificantly improves the performance of relation extraction compared to\nstate-of-the-art methods\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:24:51 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Zhao", "Yun", ""]]}, {"id": "1909.05371", "submitter": "Paul Atzberger", "authors": "Nathaniel Trask, Ravi G.Patel, Ben J. Gross, Paul J. Atzberger", "title": "GMLS-Nets: A framework for learning from unstructured data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data fields sampled on irregularly spaced points arise in many applications\nin the sciences and engineering. For regular grids, Convolutional Neural\nNetworks (CNNs) have been successfully used to gaining benefits from weight\nsharing and invariances. We generalize CNNs by introducing methods for data on\nunstructured point clouds based on Generalized Moving Least Squares (GMLS).\nGMLS is a non-parametric technique for estimating linear bounded functionals\nfrom scattered data, and has recently been used in the literature for solving\npartial differential equations. By parameterizing the GMLS estimator, we obtain\nlearning methods for operators with unstructured stencils. In GMLS-Nets the\nnecessary calculations are local, readily parallelizable, and the estimator is\nsupported by a rigorous approximation theory. We show how the framework may be\nused for unstructured physical data sets to perform functional regression to\nidentify associated differential operators and to regress quantities of\ninterest. The results suggest the architectures to be an attractive foundation\nfor data-driven model development in scientific machine learning applications.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 01:07:33 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 18:39:29 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Trask", "Nathaniel", ""], ["Patel", "Ravi G.", ""], ["Gross", "Ben J.", ""], ["Atzberger", "Paul J.", ""]]}, {"id": "1909.05372", "submitter": "Christopher R\\'e", "authors": "Christopher R\\'e, Feng Niu, Pallavi Gudipati, Charles Srisuwananukorn", "title": "Overton: A Data System for Monitoring and Improving Machine-Learned\n  Products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a system called Overton, whose main design goal is to support\nengineers in building, monitoring, and improving production machine learning\nsystems. Key challenges engineers face are monitoring fine-grained quality,\ndiagnosing errors in sophisticated applications, and handling contradictory or\nincomplete supervision data. Overton automates the life cycle of model\nconstruction, deployment, and monitoring by providing a set of novel\nhigh-level, declarative abstractions. Overton's vision is to shift developers\nto these higher-level tasks instead of lower-level machine learning tasks. In\nfact, using Overton, engineers can build deep-learning-based applications\nwithout writing any code in frameworks like TensorFlow. For over a year,\nOverton has been used in production to support multiple applications in both\nnear-real-time applications and back-of-house processing. In that time,\nOverton-based applications have answered billions of queries in multiple\nlanguages and processed trillions of records reducing errors 1.7-2.9 times\nversus production systems.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 03:51:13 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["R\u00e9", "Christopher", ""], ["Niu", "Feng", ""], ["Gudipati", "Pallavi", ""], ["Srisuwananukorn", "Charles", ""]]}, {"id": "1909.05379", "submitter": "Oron Ashual", "authors": "Oron Ashual, Lior Wolf", "title": "Specifying Object Attributes and Relations in Interactive Scene\n  Generation", "comments": "Best Paper Honorable Mention in ICCV 2019", "journal-ref": "The IEEE International Conference on Computer Vision (ICCV), 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for the generation of images from an input scene graph.\nThe method separates between a layout embedding and an appearance embedding.\nThe dual embedding leads to generated images that better match the scene graph,\nhave higher visual quality, and support more complex scene graphs. In addition,\nthe embedding scheme supports multiple and diverse output images per scene\ngraph, which can be further controlled by the user. We demonstrate two modes of\nper-object control: (i) importing elements from other images, and (ii)\nnavigation in the object space, by selecting an appearance archetype. Our code\nis publicly available at https://www.github.com/ashual/scene_generation\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 21:16:38 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 15:33:05 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Ashual", "Oron", ""], ["Wolf", "Lior", ""]]}, {"id": "1909.05388", "submitter": "Dong Wang", "authors": "Yang Zhang, Daniel Zhang, Nathan Vance, Dong Wang", "title": "An Online Reinforcement Learning Approach to Quality-Cost-Aware Task\n  Allocation for Multi-Attribute Social Sensing", "comments": "The paper has been accepted to Elsevier Pervasive and Mobile\n  Computing (PMC) in September 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social sensing has emerged as a new sensing paradigm where humans (or devices\non their behalf) collectively report measurements about the physical world.\nThis paper focuses on a quality-cost-aware task allocation problem in\nmulti-attribute social sensing applications. The goal is to identify a task\nallocation strategy (i.e., decide when and where to collect sensing data) to\nachieve an optimized tradeoff between the data quality and the sensing cost.\nWhile recent progress has been made to tackle similar problems, three important\nchallenges have not been well addressed: (i) \"online task allocation\": the task\nallocation schemes need to respond quickly to the potentially large dynamics of\nthe measured variables in social sensing; (ii) \"multi-attribute constrained\noptimization\": minimizing the overall sensing error given the dependencies and\nconstraints of multiple attributes of the measured variables is a non-trivial\nproblem to solve; (iii) \"nonuniform task allocation cost\": the task allocation\ncost in social sensing often has a nonuniform distribution which adds\nadditional complexity to the optimized task allocation problem. This paper\ndevelops a Quality-Cost-Aware Online Task Allocation (QCO-TA) scheme to address\nthe above challenges using a principled online reinforcement learning\nframework. We evaluate the QCO-TA scheme through a real-world social sensing\napplication and the results show that our scheme significantly outperforms the\nstate-of-the-art baselines in terms of both sensing accuracy and cost.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 21:56:33 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Zhang", "Yang", ""], ["Zhang", "Daniel", ""], ["Vance", "Nathan", ""], ["Wang", "Dong", ""]]}, {"id": "1909.05393", "submitter": "Richard Jiang", "authors": "Tiancheng Xia, Richard Jiang, YongQing Fu and Nanlin Jin", "title": "Automated Blood Cell Detection and Counting via Deep Learning for\n  Microfluidic Point-of-Care Medical Devices", "comments": null, "journal-ref": "Proceeding of 2019 3rd International Conference on Artificial\n  Intelligence Applications and Technologies (AIAAT 2019)", "doi": "10.1088/1757-899X/646/1/012048", "report-no": null, "categories": "cs.CV cs.AI cs.ET cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated in-vitro cell detection and counting have been a key theme for\nartificial and intelligent biological analysis such as biopsy, drug analysis\nand decease diagnosis. Along with the rapid development of microfluidics and\nlab-on-chip technologies, in-vitro live cell analysis has been one of the\ncritical tasks for both research and industry communities. However, it is a\ngreat challenge to obtain and then predict the precise information of live\ncells from numerous microscopic videos and images. In this paper, we\ninvestigated in-vitro detection of white blood cells using deep neural\nnetworks, and discussed how state-of-the-art machine learning techniques could\nfulfil the needs of medical diagnosis. The approach we used in this study was\nbased on Faster Region-based Convolutional Neural Networks (Faster RCNNs), and\na transfer learning process was applied to apply this technique to the\nmicroscopic detection of blood cells. Our experimental results demonstrated\nthat fast and efficient analysis of blood cells via automated microscopic\nimaging can achieve much better accuracy and faster speed than the\nconventionally applied methods, implying a promising future of this technology\nto be applied to the microfluidic point-of-care medical devices.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 22:14:03 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Xia", "Tiancheng", ""], ["Jiang", "Richard", ""], ["Fu", "YongQing", ""], ["Jin", "Nanlin", ""]]}, {"id": "1909.05402", "submitter": "Jingliang Duan", "authors": "Jingliang Duan, Shengbo Eben Li, Zhengyu Liu, Monimoy Bujarbaruah, Bo\n  Cheng", "title": "Generalized Policy Iteration for Optimal Control in Continuous Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the Deep Generalized Policy Iteration (DGPI) algorithm to\nfind the infinite horizon optimal control policy for general nonlinear\ncontinuous-time systems with known dynamics. Unlike existing adaptive dynamic\nprogramming algorithms for continuous time systems, DGPI does not require the\nadmissibility of initialized policy, and input-affine nature of controlled\nsystems for convergence. Our algorithm employs the actor-critic architecture to\napproximate both policy and value functions with the purpose of iteratively\nsolving the Hamilton-Jacobi-Bellman equation. Both the policy and value\nfunctions are approximated by deep neural networks. Given any arbitrary initial\npolicy, the proposed DGPI algorithm can eventually converge to an admissible,\nand subsequently an optimal policy for an arbitrary nonlinear system. We also\nrelax the update termination conditions of both the policy evaluation and\nimprovement processes, which leads to a faster convergence speed than\nconventional Policy Iteration (PI) methods, for the same architecture of\nfunction approximators. We further prove the convergence and optimality of the\nalgorithm with thorough Lyapunov analysis, and demonstrate its generality and\nefficacy using two detailed numerical examples.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 23:43:41 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Duan", "Jingliang", ""], ["Li", "Shengbo Eben", ""], ["Liu", "Zhengyu", ""], ["Bujarbaruah", "Monimoy", ""], ["Cheng", "Bo", ""]]}, {"id": "1909.05414", "submitter": "Mei Wang", "authors": "Mei Wang, Weizhi Li, Yan Yan", "title": "Time-weighted Attentional Session-Aware Recommender System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Session-based Recurrent Neural Networks (RNNs) are gaining increasing\npopularity for recommendation task, due to the high autocorrelation of user's\nbehavior on the latest session and the effectiveness of RNN to capture the\nsequence order information. However, most existing session-based RNN\nrecommender systems still solely focus on the short-term interactions within a\nsingle session and completely discard all the other long-term data across\ndifferent sessions. While traditional Collaborative Filtering (CF) methods have\nmany advanced research works on exploring long-term dependency, which show\ngreat value to be explored and exploited in deep learning models. Therefore, in\nthis paper, we propose ASARS, a novel framework that effectively imports the\ntemporal dynamics methodology in CF into session-based RNN system in DL, such\nthat the temporal info can act as scalable weights by a parallel attentional\nnetwork. Specifically, we first conduct an extensive data analysis to show the\ndistribution and importance of such temporal interactions data both within\nsessions and across sessions. And then, our ASARS framework promotes two novel\nmodels: (1) an inter-session temporal dynamic model that captures the long-term\nuser interaction for RNN recommender system. We integrate the time changes in\nsession RNN and add user preferences as model drifting; and (2) a novel\ntriangle parallel attention network that enhances the original RNN model by\nincorporating time information. Such triangle parallel network is also\nspecially designed for realizing data argumentation in sequence-to-scalar RNN\narchitecture, and thus it can be trained very efficiently. Our extensive\nexperiments on four real datasets from different domains demonstrate the\neffectiveness and large improvement of ASARS for personalized recommendation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 00:31:23 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Wang", "Mei", ""], ["Li", "Weizhi", ""], ["Yan", "Yan", ""]]}, {"id": "1909.05417", "submitter": "Myungsu Chae", "authors": "Hyoung-Kyu Song, Ebrahim AlAlkeem, Jaewoong Yun, Tae-Ho Kim, Tae-Ho\n  Kim, Hyerin Yoo, Dasom Heo, Chan Yeob Yeun, and Myungsu Chae", "title": "Deep User Identification Model with Multiple Biometrics", "comments": "Accepted, CIKM 2019 Workshop on DTMBio", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification using biometrics is an important yet challenging task.\nAbundant research has been conducted on identifying personal identity or gender\nusing given signals. Various types of biometrics such as electrocardiogram\n(ECG), electroencephalogram (EEG), face, fingerprint, and voice have been used\nfor these tasks. Most research has only focused on single modality or a single\ntask, while the combination of input modality or tasks is yet to be\ninvestigated. In this paper, we propose deep identification and gender\nclassification using multimodal biometrics. Our model uses ECG, fingerprint,\nand facial data. It then performs two tasks: gender identification and\nclassification. By engaging multi-modality, a single model can handle various\ninput domains without training each modality independently, and the correlation\nbetween domains can increase its generalization performance on the tasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 09:13:11 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Song", "Hyoung-Kyu", ""], ["AlAlkeem", "Ebrahim", ""], ["Yun", "Jaewoong", ""], ["Kim", "Tae-Ho", ""], ["Kim", "Tae-Ho", ""], ["Yoo", "Hyerin", ""], ["Heo", "Dasom", ""], ["Yeun", "Chan Yeob", ""], ["Chae", "Myungsu", ""]]}, {"id": "1909.05442", "submitter": "Amrit Singh Bedi", "authors": "Amrit Singh Bedi, Alec Koppel, Ketan Rajawat, and Brian M. Sadler", "title": "Nonstationary Nonparametric Online Learning: Balancing Dynamic Regret\n  and Model Parsimony", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open challenge in supervised learning is \\emph{conceptual drift}: a data\npoint begins as classified according to one label, but over time the notion of\nthat label changes. Beyond linear autoregressive models, transfer and meta\nlearning address drift, but require data that is representative of disparate\ndomains at the outset of training. To relax this requirement, we propose a\nmemory-efficient \\emph{online} universal function approximator based on\ncompressed kernel methods. Our approach hinges upon viewing non-stationary\nlearning as online convex optimization with dynamic comparators, for which\nperformance is quantified by dynamic regret.\n  Prior works control dynamic regret growth only for linear models. In\ncontrast, we hypothesize actions belong to reproducing kernel Hilbert spaces\n(RKHS). We propose a functional variant of online gradient descent (OGD)\noperating in tandem with greedy subspace projections. Projections are necessary\nto surmount the fact that RKHS functions have complexity proportional to time.\n  For this scheme, we establish sublinear dynamic regret growth in terms of\nboth loss variation and functional path length, and that the memory of the\nfunction sequence remains moderate. Experiments demonstrate the usefulness of\nthe proposed technique for online nonlinear regression and classification\nproblems with non-stationary data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 03:27:44 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Bedi", "Amrit Singh", ""], ["Koppel", "Alec", ""], ["Rajawat", "Ketan", ""], ["Sadler", "Brian M.", ""]]}, {"id": "1909.05443", "submitter": "Chang Song", "authors": "Chang Song, Zuoguan Wang, Hai Li", "title": "Feedback Learning for Improving the Robustness of Neural Networks", "comments": "Accepted by ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research studies revealed that neural networks are vulnerable to\nadversarial attacks. State-of-the-art defensive techniques add various\nadversarial examples in training to improve models' adversarial robustness.\nHowever, these methods are not universal and can't defend unknown or\nnon-adversarial evasion attacks. In this paper, we analyze the model robustness\nin the decision space. A feedback learning method is then proposed, to\nunderstand how well a model learns and to facilitate the retraining process of\nremedying the defects. The evaluations according to a set of distance-based\ncriteria show that our method can significantly improve models' accuracy and\nrobustness against different types of evasion attacks. Moreover, we observe the\nexistence of inter-class inequality and propose to compensate it by changing\nthe proportions of examples generated in different classes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 03:50:28 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Song", "Chang", ""], ["Wang", "Zuoguan", ""], ["Li", "Hai", ""]]}, {"id": "1909.05447", "submitter": "Mohammad Pirhooshyaran", "authors": "Mohammad Pirhooshyaran, Katya Scheinberg, Lawrence V. Snyder", "title": "Feature Engineering and Forecasting via Derivative-free Optimization and\n  Ensemble of Sequence-to-sequence Networks with Applications in Renewable\n  Energy", "comments": null, "journal-ref": null, "doi": "10.1016/j.energy.2020.117136", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study introduces a framework for the forecasting, reconstruction and\nfeature engineering of multivariate processes along with its renewable energy\napplications. We integrate derivative-free optimization with an ensemble of\nsequence-to-sequence networks and design a new resampling technique called\nadditive resampling, which, along with Bootstrap aggregating (bagging)\nresampling, are applied to initialize the ensemble structure. Moreover, we\nexplore the proposed framework performance on three renewable energy\nsources---wind, solar and ocean wave---and conduct several short- to long-term\nforecasts showing the superiority of the proposed method compared to numerous\nmachine learning techniques. The findings indicate that the introduced method\nperforms more accurately when the forecasting horizon becomes longer. In\naddition, we modify the framework for automated feature selection. The model\nrepresents a clear interpretation of the selected features. Furthermore, we\ninvestigate the effects of different environmental and marine factors on the\nwind speed and ocean output power, respectively, and report the selected\nfeatures. Finally, we explore the online forecasting setting and illustrate\nthat the model outperforms alternatives through different measurement errors.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 04:14:25 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 00:49:53 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 02:52:15 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Pirhooshyaran", "Mohammad", ""], ["Scheinberg", "Katya", ""], ["Snyder", "Lawrence V.", ""]]}, {"id": "1909.05460", "submitter": "Vishnu Suresh Lokhande", "authors": "Vishnu Suresh Lokhande, Shaofei Wang, Maneesh Singh, Julian Yarkony", "title": "Accelerating Column Generation via Flexible Dual Optimal Inequalities\n  with Application to Entity Resolution", "comments": "Accepted at AAAI20. Version update. Update the link to project page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new optimization approach to Entity Resolution.\nTraditional approaches tackle entity resolution with hierarchical clustering,\nwhich does not benefit from a formal optimization formulation. In contrast, we\nmodel entity resolution as correlation-clustering, which we treat as a weighted\nset-packing problem and write as an integer linear program (ILP). In this case\nsources in the input data correspond to elements and entities in output data\ncorrespond to sets/clusters. We tackle optimization of weighted set packing by\nrelaxing integrality in our ILP formulation. The set of potential sets/clusters\ncan not be explicitly enumerated, thus motivating optimization via column\ngeneration. In addition to the novel formulation, we also introduce new dual\noptimal inequalities (DOI), that we call flexible dual optimal inequalities,\nwhich tightly lower-bound dual variables during optimization and accelerate\ncolumn generation. We apply our formulation to entity resolution (also called\nde-duplication of records), and achieve state-of-the-art accuracy on two\npopular benchmark datasets. The project page is available at the following url,\nhttps://github.com/lokhande-vishnu/EntityResolution\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 05:33:06 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 23:19:34 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 07:39:48 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Lokhande", "Vishnu Suresh", ""], ["Wang", "Shaofei", ""], ["Singh", "Maneesh", ""], ["Yarkony", "Julian", ""]]}, {"id": "1909.05477", "submitter": "Dexter Scobee", "authors": "Dexter R.R. Scobee and S. Shankar Sastry", "title": "Maximum Likelihood Constraint Inference for Inverse Reinforcement\n  Learning", "comments": "Published as a conference paper at the International Conference on\n  Learning Representations (ICLR), 2020 (at\n  https://openreview.net/forum?id=BJliakStvH )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most approaches to the problem of Inverse Reinforcement Learning (IRL)\nfocus on estimating a reward function that best explains an expert agent's\npolicy or demonstrated behavior on a control task, it is often the case that\nsuch behavior is more succinctly represented by a simple reward combined with a\nset of hard constraints. In this setting, the agent is attempting to maximize\ncumulative rewards subject to these given constraints on their behavior. We\nreformulate the problem of IRL on Markov Decision Processes (MDPs) such that,\ngiven a nominal model of the environment and a nominal reward function, we seek\nto estimate state, action, and feature constraints in the environment that\nmotivate an agent's behavior. Our approach is based on the Maximum Entropy IRL\nframework, which allows us to reason about the likelihood of an expert agent's\ndemonstrations given our knowledge of an MDP. Using our method, we can infer\nwhich constraints can be added to the MDP to most increase the likelihood of\nobserving these demonstrations. We present an algorithm which iteratively\ninfers the Maximum Likelihood Constraint to best explain observed behavior, and\nwe evaluate its efficacy using both simulated behavior and recorded data of\nhumans navigating around an obstacle.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 06:38:46 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 00:13:16 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Scobee", "Dexter R. R.", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1909.05478", "submitter": "Muhammad Nabeel Asim", "authors": "Muhammad Nabeel Asim, Muhammad Usman Ghani Khan, Muhammad Imran Malik,\n  Andreas Dengel, Sheraz Ahmed", "title": "A Robust Hybrid Approach for Textual Document Classification", "comments": "ICDAR Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text document classification is an important task for diverse natural\nlanguage processing based applications. Traditional machine learning approaches\nmainly focused on reducing dimensionality of textual data to perform\nclassification. This although improved the overall classification accuracy, the\nclassifiers still faced sparsity problem due to lack of better data\nrepresentation techniques. Deep learning based text document classification, on\nthe other hand, benefitted greatly from the invention of word embeddings that\nhave solved the sparsity problem and researchers focus mainly remained on the\ndevelopment of deep architectures. Deeper architectures, however, learn some\nredundant features that limit the performance of deep learning based solutions.\nIn this paper, we propose a two stage text document classification methodology\nwhich combines traditional feature engineering with automatic feature\nengineering (using deep learning). The proposed methodology comprises a filter\nbased feature selection (FSE) algorithm followed by a deep convolutional neural\nnetwork. This methodology is evaluated on the two most commonly used public\ndatasets, i.e., 20 Newsgroups data and BBC news data. Evaluation results reveal\nthat the proposed methodology outperforms the state-of-the-art of both the\n(traditional) machine learning and deep learning based text document\nclassification methodologies with a significant margin of 7.7% on 20 Newsgroups\nand 6.6% on BBC news datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 06:39:07 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Asim", "Muhammad Nabeel", ""], ["Khan", "Muhammad Usman Ghani", ""], ["Malik", "Muhammad Imran", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "1909.05479", "submitter": "Vishnu Suresh Lokhande", "authors": "Vishnu Suresh Lokhande, Songwong Tasneeyapant, Abhay Venkatesh, Sathya\n  N. Ravi and Vikas Singh", "title": "Generating Accurate Pseudo-labels in Semi-Supervised Learning and\n  Avoiding Overconfident Predictions via Hermite Polynomial Activations", "comments": "Accepted at 2020 IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rectified Linear Units (ReLUs) are among the most widely used activation\nfunction in a broad variety of tasks in vision. Recent theoretical results\nsuggest that despite their excellent practical performance, in various cases, a\nsubstitution with basis expansions (e.g., polynomials) can yield significant\nbenefits from both the optimization and generalization perspective.\nUnfortunately, the existing results remain limited to networks with a couple of\nlayers, and the practical viability of these results is not yet known.\nMotivated by some of these results, we explore the use of Hermite polynomial\nexpansions as a substitute for ReLUs in deep networks. While our experiments\nwith supervised learning do not provide a clear verdict, we find that this\nstrategy offers considerable benefits in semi-supervised learning (SSL) /\ntransductive learning settings. We carefully develop this idea and show how the\nuse of Hermite polynomials based activations can yield improvements in\npseudo-label accuracies and sizable financial savings (due to concurrent\nruntime benefits). Further, we show via theoretical analysis, that the networks\n(with Hermite activations) offer robustness to noise and other attractive\nmathematical properties.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 06:42:08 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 06:01:54 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Lokhande", "Vishnu Suresh", ""], ["Tasneeyapant", "Songwong", ""], ["Venkatesh", "Abhay", ""], ["Ravi", "Sathya N.", ""], ["Singh", "Vikas", ""]]}, {"id": "1909.05494", "submitter": "Faicel Chamroukhi", "authors": "Fa\u007f\\\"icel Chamroukhi, Florian Lecocq, and Hien D. Nguyen", "title": "Regularized Estimation and Feature Selection in Mixtures of\n  Gaussian-Gated Experts Models", "comments": "Research School on Statistics and Data Science - RSSDS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixtures-of-Experts models and their maximum likelihood estimation (MLE) via\nthe EM algorithm have been thoroughly studied in the statistics and machine\nlearning literature. They are subject of a growing investigation in the context\nof modeling with high-dimensional predictors with regularized MLE. We examine\nMoE with Gaussian gating network, for clustering and regression, and propose an\n$\\ell_1$-regularized MLE to encourage sparse models and deal with the\nhigh-dimensional setting. We develop an EM-Lasso algorithm to perform parameter\nestimation and utilize a BIC-like criterion to select the model parameters,\nincluding the sparsity tuning hyperparameters. Experiments conducted on\nsimulated data show the good performance of the proposed regularized MLE\ncompared to the standard MLE with the EM algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 07:56:27 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Chamroukhi", "Fa\u007f\u00efcel", ""], ["Lecocq", "Florian", ""], ["Nguyen", "Hien D.", ""]]}, {"id": "1909.05499", "submitter": "Xiaocheng Li", "authors": "Xiaocheng Li, Yinyu Ye", "title": "Online Linear Programming: Dual Convergence, New Algorithms, and Regret\n  Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an online linear programming (OLP) problem under a random input\nmodel in which the columns of the constraint matrix along with the\ncorresponding coefficients in the objective function are generated i.i.d. from\nan unknown distribution and revealed sequentially over time. Virtually all\npre-existing online algorithms were based on learning the dual optimal\nsolutions/prices of the linear programs (LP), and their analyses were focused\non the aggregate objective value and solving the packing LP where all\ncoefficients in the constraint matrix and objective are nonnegative. However,\ntwo major open questions were: (i) Does the set of LP optimal dual prices\nlearned in the pre-existing algorithms converge to those of the \"offline\" LP,\nand (ii) Could the results be extended to general LP problems where the\ncoefficients can be either positive or negative. We resolve these two questions\nby establishing convergence results for the dual prices under moderate\nregularity conditions for general LP problems. Specifically, we identify an\nequivalent form of the dual problem which relates the dual LP with a sample\naverage approximation to a stochastic program. Furthermore, we propose a new\ntype of OLP algorithm, Action-History-Dependent Learning Algorithm, which\nimproves the previous algorithm performances by taking into account the past\ninput data as well as decisions/actions already made. We derive an $O(\\log n\n\\log \\log n)$ regret bound (under a locally strong convexity and smoothness\ncondition) for the proposed algorithm, against the $O(\\sqrt{n})$ bound for\ntypical dual-price learning algorithms, where $n$ is the number of decision\nvariables. Numerical experiments demonstrate the effectiveness of the proposed\nalgorithm and the action-history-dependent design.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 08:18:44 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 23:33:44 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 03:09:07 GMT"}, {"version": "v4", "created": "Sun, 6 Dec 2020 22:31:15 GMT"}, {"version": "v5", "created": "Mon, 19 Apr 2021 10:19:45 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Li", "Xiaocheng", ""], ["Ye", "Yinyu", ""]]}, {"id": "1909.05503", "submitter": "Ruoqi Shen", "authors": "Ruoqi Shen, Yin Tat Lee", "title": "The Randomized Midpoint Method for Log-Concave Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling from log-concave distributions is a well researched problem that has\nmany applications in statistics and machine learning. We study the\ndistributions of the form $p^{*}\\propto\\exp(-f(x))$, where\n$f:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$ has an $L$-Lipschitz gradient and is\n$m$-strongly convex. In our paper, we propose a Markov chain Monte Carlo (MCMC)\nalgorithm based on the underdamped Langevin diffusion (ULD). It can achieve\n$\\epsilon\\cdot D$ error (in 2-Wasserstein distance) in\n$\\tilde{O}\\left(\\kappa^{7/6}/\\epsilon^{1/3}+\\kappa/\\epsilon^{2/3}\\right)$\nsteps, where $D\\overset{\\mathrm{def}}{=}\\sqrt{\\frac{d}{m}}$ is the effective\ndiameter of the problem and $\\kappa\\overset{\\mathrm{def}}{=}\\frac{L}{m}$ is the\ncondition number. Our algorithm performs significantly faster than the\npreviously best known algorithm for solving this problem, which requires\n$\\tilde{O}\\left(\\kappa^{1.5}/\\epsilon\\right)$ steps. Moreover, our algorithm\ncan be easily parallelized to require only $O(\\kappa\\log\\frac{1}{\\epsilon})$\nparallel steps.\n  To solve the sampling problem, we propose a new framework to discretize\nstochastic differential equations. We apply this framework to discretize and\nsimulate ULD, which converges to the target distribution $p^{*}$. The framework\ncan be used to solve not only the log-concave sampling problem, but any problem\nthat involves simulating (stochastic) differential equations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 08:32:39 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Shen", "Ruoqi", ""], ["Lee", "Yin Tat", ""]]}, {"id": "1909.05504", "submitter": "Christoph Stanik", "authors": "Christoph Stanik, Marlo Haering and Walid Maalej", "title": "Classifying Multilingual User Feedback using Traditional Machine\n  Learning and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of social media like Twitter and of software distribution\nplatforms like app stores, users got various ways to express their opinion\nabout software products. Popular software vendors get user feedback\nthousandfold per day. Research has shown that such feedback contains valuable\ninformation for software development teams such as problem reports or feature\nand support inquires. Since the manual analysis of user feedback is cumbersome\nand hard to manage many researchers and tool vendors suggested to use automated\nanalyses based on traditional supervised machine learning approaches. In this\nwork, we compare the results of traditional machine learning and deep learning\nin classifying user feedback in English and Italian into problem reports,\ninquiries, and irrelevant. Our results show that using traditional machine\nlearning, we can still achieve comparable results to deep learning, although we\ncollected thousands of labels.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 08:35:54 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Stanik", "Christoph", ""], ["Haering", "Marlo", ""], ["Maalej", "Walid", ""]]}, {"id": "1909.05508", "submitter": "Giuseppe Paolo Mr", "authors": "Giuseppe Paolo and Alban Laflaqui\\`ere and Alexandre Coninx and\n  Stephane Doncieux", "title": "Unsupervised Learning and Exploration of Reachable Outcome Space", "comments": "Published at IEEE International Conference on Robotics and Automation\n  (ICRA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing Reinforcement Learning in sparse rewards settings, with very\nlittle prior knowledge, is a challenging problem since there is no signal to\nproperly guide the learning process. In such situations, a good search strategy\nis fundamental. At the same time, not having to adapt the algorithm to every\nsingle problem is very desirable. Here we introduce TAXONS, a Task Agnostic\neXploration of Outcome spaces through Novelty and Surprise algorithm. Based on\na population-based divergent-search approach, it learns a set of diverse\npolicies directly from high-dimensional observations, without any task-specific\ninformation. TAXONS builds a repertoire of policies while training an\nautoencoder on the high-dimensional observation of the final state of the\nsystem to build a low-dimensional outcome space. The learned outcome space,\ncombined with the reconstruction error, is used to drive the search for new\npolicies. Results show that TAXONS can find a diverse set of controllers,\ncovering a good part of the ground-truth outcome space, while having no\ninformation about such space.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 08:47:44 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 12:34:35 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 18:03:22 GMT"}, {"version": "v4", "created": "Mon, 4 May 2020 09:20:08 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Paolo", "Giuseppe", ""], ["Laflaqui\u00e8re", "Alban", ""], ["Coninx", "Alexandre", ""], ["Doncieux", "Stephane", ""]]}, {"id": "1909.05527", "submitter": "J\\\"org Martin", "authors": "J\\\"org Martin, Clemens Elster", "title": "Inspecting adversarial examples using the Fisher information", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are slight perturbations that are designed to fool\nartificial neural networks when fed as an input. In this work the usability of\nthe Fisher information for the detection of such adversarial attacks is\nstudied. We discuss various quantities whose computation scales well with the\nnetwork size, study their behavior on adversarial examples and show how they\ncan highlight the importance of single input neurons, thereby providing a\nvisual tool for further analyzing (un-)reasonable behavior of a neural network.\nThe potential of our methods is demonstrated by applications to the MNIST,\nCIFAR10 and Fruits-360 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 09:26:30 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Martin", "J\u00f6rg", ""], ["Elster", "Clemens", ""]]}, {"id": "1909.05557", "submitter": "Yutian Chen", "authors": "Yutian Chen, Abram L. Friesen, Feryal Behbahani, Arnaud Doucet, David\n  Budden, Matthew W. Hoffman, Nando de Freitas", "title": "Modular Meta-Learning with Shrinkage", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems, including multi-speaker text-to-speech synthesis,\ncan greatly benefit from the ability to meta-learn large models with only a few\ntask-specific components. Updating only these task-specific modules then allows\nthe model to be adapted to low-data tasks for as many steps as necessary\nwithout risking overfitting. Unfortunately, existing meta-learning methods\neither do not scale to long adaptation or else rely on handcrafted\ntask-specific architectures. Here, we propose a meta-learning approach that\nobviates the need for this often sub-optimal hand-selection. In particular, we\ndevelop general techniques based on Bayesian shrinkage to automatically\ndiscover and learn both task-specific and general reusable modules.\nEmpirically, we demonstrate that our method discovers a small set of meaningful\ntask-specific modules and outperforms existing meta-learning approaches in\ndomains like few-shot text-to-speech that have little task data and long\nadaptation horizons. We also show that existing meta-learning methods including\nMAML, iMAML, and Reptile emerge as special cases of our method.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 10:40:13 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 11:08:35 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 20:37:23 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 16:45:20 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Chen", "Yutian", ""], ["Friesen", "Abram L.", ""], ["Behbahani", "Feryal", ""], ["Doucet", "Arnaud", ""], ["Budden", "David", ""], ["Hoffman", "Matthew W.", ""], ["de Freitas", "Nando", ""]]}, {"id": "1909.05580", "submitter": "Yannik Potdevin", "authors": "Yannik Potdevin, Dirk Nowotka and Vijay Ganesh", "title": "An Empirical Investigation of Randomized Defenses against Adversarial\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Neural Networks (DNNs) have had a dramatic impact on a\nvariety of problems that were long considered very difficult, e. g., image\nclassification and automatic language translation to name just a few. The\naccuracy of modern DNNs in classification tasks is remarkable indeed. At the\nsame time, attackers have devised powerful methods to construct\nspecially-crafted malicious inputs (often referred to as adversarial examples)\nthat can trick DNNs into mis-classifying them. What is worse is that despite\nthe many defense mechanisms proposed to protect DNNs against adversarial\nattacks, attackers are often able to circumvent these defenses, rendering them\nuseless. This state of affairs is extremely worrying, especially since machine\nlearning systems get adopted at scale.\n  In this paper, we propose a scientific evaluation methodology aimed at\nassessing the quality, efficacy, robustness and efficiency of randomized\ndefenses to protect DNNs against adversarial examples. Using this methodology,\nwe evaluate a variety of defense mechanisms. In addition, we also propose a\ndefense mechanism we call Randomly Perturbed Ensemble Neural Networks (RPENNs).\nWe provide a thorough and comprehensive evaluation of the considered defense\nmechanisms against a white-box attacker model, six different adversarial attack\nmethods and using the ILSVRC2012 validation data set.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 11:44:33 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Potdevin", "Yannik", ""], ["Nowotka", "Dirk", ""], ["Ganesh", "Vijay", ""]]}, {"id": "1909.05622", "submitter": "Matin Hosseini", "authors": "Matin Hosseini, Anthony S. Maida, Majid Hosseini, Gottumukkala Raju", "title": "Inception-inspired LSTM for Next-frame Video Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of video frame prediction has received much interest due to its\nrelevance to many computer vision applications such as autonomous vehicles or\nrobotics. Supervised methods for video frame prediction rely on labeled data,\nwhich may not always be available. In this paper, we provide a novel\nunsupervised deep-learning method called Inception-based LSTM for video frame\nprediction. The general idea of inception networks is to implement wider\nnetworks instead of deeper networks. This network design was shown to improve\nthe performance of image classification. The proposed method is evaluated on\nboth Inception-v1 and Inception-v2 structures. The proposed Inception LSTM\nmethods are compared with convolutional LSTM when applied using PredNet\npredictive coding framework for both the KITTI and KTH data sets. We observed\nthat the Inception based LSTM outperforms the convolutional LSTM. Also,\nInception LSTM has better prediction performance compared to Inception v2 LSTM.\nHowever, Inception v2 LSTM has a lower computational cost compared to Inception\nLSTM.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 03:49:07 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:06:36 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Hosseini", "Matin", ""], ["Maida", "Anthony S.", ""], ["Hosseini", "Majid", ""], ["Raju", "Gottumukkala", ""]]}, {"id": "1909.05623", "submitter": "Jiancheng Lyu", "authors": "Jiancheng Lyu and Spencer Sheen", "title": "A Channel-Pruned and Weight-Binarized Convolutional Neural Network for\n  Keyword Spotting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study channel number reduction in combination with weight binarization\n(1-bit weight precision) to trim a convolutional neural network for a keyword\nspotting (classification) task. We adopt a group-wise splitting method based on\nthe group Lasso penalty to achieve over 50% channel sparsity while maintaining\nthe network performance within 0.25% accuracy loss. We show an effective\nthree-stage procedure to balance accuracy and sparsity in network training.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 13:22:25 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Lyu", "Jiancheng", ""], ["Sheen", "Spencer", ""]]}, {"id": "1909.05624", "submitter": "Vaidheeswaran Archana", "authors": "Murugesan Vadivel, SelvaKumar Murugan, Suriyadeepan Ramamoorthy,\n  Vaidheeswaran Archana, Malaikannan Sankarasubbu", "title": "Detecting Parking Spaces in a Parcel using Satellite Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote Sensing Images from satellites have been used in various domains for\ndetecting and understanding structures on the ground surface. In this work,\nsatellite images were used for localizing parking spaces and vehicles in\nparking lots for a given parcel using an RCNN based Neural Network\nArchitectures. Parcel shapefiles and raster images from USGS image archive were\nused for developing images for both training and testing. Feature Pyramid based\nMask RCNN yields average class accuracy of 97.56% for both parking spaces and\nvehicles\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 07:00:13 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 13:37:07 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Vadivel", "Murugesan", ""], ["Murugan", "SelvaKumar", ""], ["Ramamoorthy", "Suriyadeepan", ""], ["Archana", "Vaidheeswaran", ""], ["Sankarasubbu", "Malaikannan", ""]]}, {"id": "1909.05630", "submitter": "Walid Abdullah Al", "authors": "Walid Abdullah Al, Il Dong Yun", "title": "Reinforcing Medical Image Classifier to Improve Generalization on Small\n  Datasets", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advents of deep learning, improved image classification with complex\ndiscriminative models has been made possible. However, such deep models with\nincreased complexity require a huge set of labeled samples to generalize the\ntraining. Such classification models can easily overfit when applied for\nmedical images because of limited training data, which is a common problem in\nthe field of medical image analysis. This paper proposes and investigates a\nreinforced classifier for improving the generalization under a few available\ntraining data. Partially following the idea of reinforcement learning, the\nproposed classifier uses a generalization-feedback from a subset of the\ntraining data to update its parameter instead of only using the conventional\ncross-entropy loss about the training data. We evaluate the improvement of the\nproposed classifier by applying it on three different classification problems\nagainst the standard deep classifiers equipped with existing\noverfitting-prevention techniques. Besides an overall improvement in\nclassification performance, the proposed classifier showed remarkable\ncharacteristics of generalized learning, which can have great potential in\nmedical classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 09:12:36 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 04:28:33 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Al", "Walid Abdullah", ""], ["Yun", "Il Dong", ""]]}, {"id": "1909.05631", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, Simon Alford, Vijay Gadepally, Michael Jones, Lauren\n  Milechin, Ryan Robinett, Sid Samsi", "title": "Sparse Deep Neural Network Graph Challenge", "comments": "7 pages, 5 figures, 3 tables, 60 references, accepted to IEEE HPEC\n  2019. arXiv admin note: substantial text overlap with arXiv:1807.03165,\n  arXiv:1708.02937, arXiv:1708.06866", "journal-ref": null, "doi": "10.1109/HPEC.2019.8916336", "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MIT/IEEE/Amazon GraphChallenge.org encourages community approaches to\ndeveloping new solutions for analyzing graphs and sparse data. Sparse AI\nanalytics present unique scalability difficulties. The proposed Sparse Deep\nNeural Network (DNN) Challenge draws upon prior challenges from machine\nlearning, high performance computing, and visual analytics to create a\nchallenge that is reflective of emerging sparse AI systems. The Sparse DNN\nChallenge is based on a mathematically well-defined DNN inference computation\nand can be implemented in any programming environment. Sparse DNN inference is\namenable to both vertex-centric implementations and array-based implementations\n(e.g., using the GraphBLAS.org standard). The computations are simple enough\nthat performance predictions can be made based on simple computing hardware\nmodels. The input data sets are derived from the MNIST handwritten letters. The\nsurrounding I/O and verification provide the context for each sparse DNN\ninference that allows rigorous definition of both the input and the output.\nFurthermore, since the proposed sparse DNN challenge is scalable in both\nproblem size and hardware, it can be used to measure and quantitatively compare\na wide range of present day and future systems. Reference implementations have\nbeen implemented and their serial and parallel performance have been measured.\nSpecifications, data, and software are publicly available at GraphChallenge.org\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 02:29:52 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kepner", "Jeremy", ""], ["Alford", "Simon", ""], ["Gadepally", "Vijay", ""], ["Jones", "Michael", ""], ["Milechin", "Lauren", ""], ["Robinett", "Ryan", ""], ["Samsi", "Sid", ""]]}, {"id": "1909.05632", "submitter": "Arno Khachatourian", "authors": "Arno Khachatourian", "title": "Reusing Convolutional Activations from Frame to Frame to Speed up\n  Training and Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When processing similar frames in succession, we can take advantage of the\nlocality of the convolution operation to reevaluate only portions of the image\nthat changed from the previous frame. By saving the output of a layer of\nconvolutions and calculating the change from frame to frame, we can reuse\nprevious activations and save computational resources that would otherwise be\nwasted recalculating convolutions whose outputs we have already observed. This\ntechnique can be applied to many domains, such as processing videos from\nstationary video cameras, studying the effects of occluding or distorting\nsections of images, applying convolution to multiple frames of audio or time\nseries data, or playing Atari games. Furthermore, this technique can be applied\nto speed up both training and inference.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 00:21:03 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 05:59:09 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Khachatourian", "Arno", ""]]}, {"id": "1909.05637", "submitter": "Tao-Yang Fu", "authors": "Tao-yang Fu, Wang-Chien Lee", "title": "DeepIST: Deep Image-based Spatio-Temporal Network for Travel Time\n  Estimation", "comments": "10 pages, accepted by The 28th ACM International Conference on\n  Information and Knowledge Management (CIKM) 2019", "journal-ref": "The 28th ACM International Conference on Information and Knowledge\n  Management (CIKM) 2019", "doi": "10.1145/3357384.3357870", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the travel time for a given path is a fundamental problem in many\nurban transportation systems. However, prior works fail to well capture moving\nbehaviors embedded in paths and thus do not estimate the travel time\naccurately. To fill in this gap, in this work, we propose a novel neural\nnetwork framework, namely {\\em Deep Image-based Spatio-Temporal network\n(DeepIST)}, for travel time estimation of a given path. The novelty of DeepIST\nlies in the following aspects: 1) we propose to plot a path as a sequence of\n\"generalized images\" which include sub-paths along with additional information,\nsuch as traffic conditions, road network and traffic signals, in order to\nharness the power of convolutional neural network model (CNN) on image\nprocessing; 2) we design a novel two-dimensional CNN, namely {\\em PathCNN}, to\nextract spatial patterns for lines in images by regularization and adopting\nmultiple pooling methods; and 3) we apply a one-dimensional CNN to capture\ntemporal patterns among the spatial patterns along the paths for the\nestimation. Empirical results show that DeepIST soundly outperforms the\nstate-of-the-art travel time estimation models by 24.37\\% to 25.64\\% of mean\nabsolute error (MAE) in multiple large-scale real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 04:38:42 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Fu", "Tao-yang", ""], ["Lee", "Wang-Chien", ""]]}, {"id": "1909.05638", "submitter": "Lahiru D. Chamain Hewa Gamage", "authors": "Lahiru D. Chamain, Zhi Ding", "title": "Faster and Accurate Classification for JPEG2000 Compressed Images in\n  Networked Applications", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  JPEG2000 (j2k) is a highly popular format for image and video\ncompression.With the rapidly growing applications of cloud based image\nclassification, most existing j2k-compatible schemes would stream compressed\ncolor images from the source before reconstruction at the processing center as\ninputs to deep CNNs. We propose to remove the computationally costly\nreconstruction step by training a deep CNN image classifier using the CDF 9/7\nDiscrete Wavelet Transformed (DWT) coefficients directly extracted from\nj2k-compressed images. We demonstrate additional computation savings by\nutilizing shallower CNN to achieve classification of good accuracy in the DWT\ndomain. Furthermore, we show that traditional augmentation transforms such as\nflipping/shifting are ineffective in the DWT domain and present different\naugmentation transformations to achieve more accurate classification without\nany additional cost. This way, faster and more accurate classification is\npossible for j2k encoded images without image reconstruction. Through\nexperiments on CIFAR-10 and Tiny ImageNet data sets, we show that the\nperformance of the proposed solution is consistent for image transmission over\nlimited channel bandwidth.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 19:03:35 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Chamain", "Lahiru D.", ""], ["Ding", "Zhi", ""]]}, {"id": "1909.05644", "submitter": "Richard Tomsett", "authors": "David Mott, Richard Tomsett", "title": "Illuminated Decision Trees with Lucid", "comments": "Presented at BMVC 2019: Workshop on Interpretable and Explainable\n  Machine Vision, Cardiff, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lucid methods described by Olah et al. (2018) provide a way to inspect\nthe inner workings of neural networks trained on image classification tasks\nusing feature visualization. Such methods have generally been applied to\nnetworks trained on visually rich, large-scale image datasets like ImageNet,\nwhich enables them to produce enticing feature visualizations. To investigate\nthese methods further, we applied them to classifiers trained to perform the\nmuch simpler (in terms of dataset size and visual richness), yet challenging\ntask of distinguishing between different kinds of white blood cell from\nmicroscope images. Such a task makes generating useful feature visualizations\ndifficult, as the discriminative features are inherently hard to identify and\ninterpret. We address this by presenting the \"Illuminated Decision Tree\"\napproach, in which we use a neural network trained on the task as a feature\nextractor, then learn a decision tree based on these features, and provide\nLucid visualizations for each node in the tree. We demonstrate our approach\nwith several examples, showing how this approach could be useful both in model\ndevelopment and debugging, and when explaining model outputs to non-experts.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 12:32:44 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Mott", "David", ""], ["Tomsett", "Richard", ""]]}, {"id": "1909.05654", "submitter": "Di Fu", "authors": "Di Fu, Cornelius Weber, Guochun Yang, Matthias Kerzel, Weizhi Nan,\n  Pablo Barros, Haiyan Wu, Xun Liu, Stefan Wermter", "title": "What can computational models learn from human selective attention? A\n  review from an audiovisual crossmodal perspective", "comments": "29pages, 5 figures, 1 table, journal article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Selective attention plays an essential role in information acquisition and\nutilization from the environment. In the past 50 years, research on selective\nattention has been a central topic in cognitive science. Compared with unimodal\nstudies, crossmodal studies are more complex but necessary to solve real-world\nchallenges in both human experiments and computational modeling. Although an\nincreasing number of findings on crossmodal selective attention have shed light\non humans' behavioral patterns and neural underpinnings, a much better\nunderstanding is still necessary to yield the same benefit for computational\nintelligent agents. This article reviews studies of selective attention in\nunimodal visual and auditory and crossmodal audiovisual setups from the\nmultidisciplinary perspectives of psychology and cognitive neuroscience, and\nevaluates different ways to simulate analogous mechanisms in computational\nmodels and robotics. We discuss the gaps between these fields in this\ninterdisciplinary review and provide insights about how to use psychological\nfindings and theories in artificial intelligence from different perspectives.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 18:12:05 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Fu", "Di", ""], ["Weber", "Cornelius", ""], ["Yang", "Guochun", ""], ["Kerzel", "Matthias", ""], ["Nan", "Weizhi", ""], ["Barros", "Pablo", ""], ["Wu", "Haiyan", ""], ["Liu", "Xun", ""], ["Wermter", "Stefan", ""]]}, {"id": "1909.05658", "submitter": "Zhe Zhao", "authors": "Zhe Zhao and Hui Chen and Jinbin Zhang and Xin Zhao and Tao Liu and\n  Wei Lu and Xi Chen and Haotang Deng and Qi Ju and Xiaoyong Du", "title": "UER: An Open-Source Toolkit for Pre-training Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing works, including ELMO and BERT, have revealed the importance of\npre-training for NLP tasks. While there does not exist a single pre-training\nmodel that works best in all cases, it is of necessity to develop a framework\nthat is able to deploy various pre-training models efficiently. For this\npurpose, we propose an assemble-on-demand pre-training toolkit, namely\nUniversal Encoder Representations (UER). UER is loosely coupled, and\nencapsulated with rich modules. By assembling modules on demand, users can\neither reproduce a state-of-the-art pre-training model or develop a\npre-training model that remains unexplored. With UER, we have built a model\nzoo, which contains pre-trained models based on different corpora, encoders,\nand targets (objectives). With proper pre-trained models, we could achieve new\nstate-of-the-art results on a range of downstream datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 13:46:58 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Zhao", "Zhe", ""], ["Chen", "Hui", ""], ["Zhang", "Jinbin", ""], ["Zhao", "Xin", ""], ["Liu", "Tao", ""], ["Lu", "Wei", ""], ["Chen", "Xi", ""], ["Deng", "Haotang", ""], ["Ju", "Qi", ""], ["Du", "Xiaoyong", ""]]}, {"id": "1909.05659", "submitter": "Nutan Chen Ph.D.", "authors": "Nutan Chen, G\\\"oran Westling, Benoni B. Edin, Patrick van der Smagt", "title": "Estimating Fingertip Forces, Torques, and Local Curvatures from\n  Fingernail Images", "comments": "Robotica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of dexterous manipulation has provided important insights in humans\nsensorimotor control as well as inspiration for manipulation strategies in\nrobotic hands. Previous work focused on experimental environment with\nrestrictions. Here we describe a method using the deformation and color\ndistribution of the fingernail and its surrounding skin, to estimate the\nfingertip forces, torques and contact surface curvatures for various objects,\nincluding the shape and material of the contact surfaces and the weight of the\nobjects. The proposed method circumvents limitations associated with sensorized\nobjects, gloves or fixed contact surface type. In addition, compared with\nprevious single finger estimation in an experimental environment, we extend the\napproach to multiple finger force estimation, which can be used for\napplications such as human grasping analysis. Four algorithms are used, c.q.,\nGaussian process (GP), Convolutional Neural Networks (CNN), Neural Networks\nwith Fast Dropout (NN-FD) and Recurrent Neural Networks with Fast Dropout\n(RNN-FD), to model a mapping from images to the corresponding labels. The\nresults further show that the proposed method has high accuracy to predict\nforce, torque and contact surface.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 19:22:32 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Chen", "Nutan", ""], ["Westling", "G\u00f6ran", ""], ["Edin", "Benoni B.", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1909.05660", "submitter": "Juan Miguel Valverde", "authors": "Juan Miguel Valverde, Vandad Imani, John D. Lewis, Jussi Tohka", "title": "Predicting intelligence based on cortical WM/GM contrast, cortical\n  thickness and volumetry", "comments": "Submission to the ABCD Neurocognitive Prediction Challenge at MICCAI\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a four-layer fully-connected neural network (FNN) for predicting\nfluid intelligence scores from T1-weighted MR images for the ABCD-challenge. In\naddition to the volumes of brain structures, the FNN uses cortical WM/GM\ncontrast and cortical thickness at 78 cortical regions. These last two\nmeasurements were derived from the T1-weighted MR images using cortical\nsurfaces produced by the CIVET pipeline. The age and gender of the subjects and\nthe scanner manufacturer are also used as features for the learning algorithm.\nThis yielded 283 features provided to the FNN with two hidden layers of 20 and\n15 nodes. The method was applied to the data from the ABCD study. Trained with\na training set of 3736 subjects, the proposed method achieved a MSE of 71.596\nand a correlation of 0.151 in the validation set of 415 subjects. For the final\nsubmission, the model was trained with 3568 subjects and it achieved a MSE of\n94.0270 in the test set comprised of 4383 subjects.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:53:19 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Valverde", "Juan Miguel", ""], ["Imani", "Vandad", ""], ["Lewis", "John D.", ""], ["Tohka", "Jussi", ""]]}, {"id": "1909.05667", "submitter": "Liam Hiley BSc", "authors": "Liam Hiley, Alun Preece, Yulia Hicks", "title": "Explainable Deep Learning for Video Recognition Tasks: A Framework &\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of Deep Learning for real-world applications is ever-growing.\nWith the introduction of high performance hardware, applications are no longer\nlimited to image recognition. With the introduction of more complex problems\ncomes more and more complex solutions, and the increasing need for explainable\nAI. Deep Neural Networks for Video tasks are amongst the most complex models,\nwith at least twice the parameters of their Image counterparts. However,\nexplanations for these models are often ill-adapted to the video domain. The\ncurrent work in explainability for video models is still overshadowed by Image\ntechniques, while Video Deep Learning itself is quickly gaining on methods for\nstill images. This paper seeks to highlight the need for explainability methods\ndesigned with video deep learning models, and by association spatio-temporal\ninput in mind, by first illustrating the cutting edge for video deep learning,\nand then noting the scarcity of research into explanations for these methods.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 19:34:48 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Hiley", "Liam", ""], ["Preece", "Alun", ""], ["Hicks", "Yulia", ""]]}, {"id": "1909.05677", "submitter": "Anthony Bourached", "authors": "Anthony Bourached, George Cann", "title": "Raiders of the Lost Art", "comments": "Submitted to NeurIPS workshop on Machine Learning for Creativity and\n  Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural style transfer, first proposed by Gatys et al. (2015), can be used to\ncreate novel artistic work through rendering a content image in the form of a\nstyle image. We present a novel method of reconstructing lost artwork, by\napplying neural style transfer to x-radiographs of artwork with secondary\ninterior artwork beneath a primary exterior, so as to reconstruct lost artwork.\nFinally we reflect on AI art exhibitions and discuss the social, cultural,\nethical, and philosophical impact of these technical innovations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 12:14:04 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Bourached", "Anthony", ""], ["Cann", "George", ""]]}, {"id": "1909.05699", "submitter": "Thomas Beckers", "authors": "Thomas Beckers, Somil Bansal, Claire J. Tomlin, Sandra Hirche", "title": "Closed-loop Model Selection for Kernel-based Models using Bayesian\n  Optimization", "comments": null, "journal-ref": "IEEE Conference on Decision and Control 2019", "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel-based nonparametric models have become very attractive for model-based\ncontrol approaches for nonlinear systems. However, the selection of the kernel\nand its hyperparameters strongly influences the quality of the learned model.\nClassically, these hyperparameters are optimized to minimize the prediction\nerror of the model but this process totally neglects its later usage in the\ncontrol loop. In this work, we present a framework to optimize the kernel and\nhyperparameters of a kernel-based model directly with respect to the\nclosed-loop performance of the model. Our framework uses Bayesian optimization\nto iteratively refine the kernel-based model using the observed performance on\nthe actual system until a desired performance is achieved. We demonstrate the\nproposed approach in a simulation and on a 3-DoF robotic arm.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:14:24 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Beckers", "Thomas", ""], ["Bansal", "Somil", ""], ["Tomlin", "Claire J.", ""], ["Hirche", "Sandra", ""]]}, {"id": "1909.05704", "submitter": "Carlos Caetano", "authors": "Carlos Caetano, Fran\\c{c}ois Br\\'emond, William Robson Schwartz", "title": "Skeleton Image Representation for 3D Action Recognition based on Tree\n  Structure and Reference Joints", "comments": "Conference on Graphics, Patterns and Images (SIBGRAPI2019). arXiv\n  admin note: substantial text overlap with arXiv:1907.13025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, the computer vision research community has studied on how\nto model temporal dynamics in videos to employ 3D human action recognition. To\nthat end, two main baseline approaches have been researched: (i) Recurrent\nNeural Networks (RNNs) with Long-Short Term Memory (LSTM); and (ii) skeleton\nimage representations used as input to a Convolutional Neural Network (CNN).\nAlthough RNN approaches present excellent results, such methods lack the\nability to efficiently learn the spatial relations between the skeleton joints.\nOn the other hand, the representations used to feed CNN approaches present the\nadvantage of having the natural ability of learning structural information from\n2D arrays (i.e., they learn spatial relations from the skeleton joints). To\nfurther improve such representations, we introduce the Tree Structure Reference\nJoints Image (TSRJI), a novel skeleton image representation to be used as input\nto CNNs. The proposed representation has the advantage of combining the use of\nreference joints and a tree structure skeleton. While the former incorporates\ndifferent spatial relationships between the joints, the latter preserves\nimportant spatial relations by traversing a skeleton tree with a depth-first\norder algorithm. Experimental results demonstrate the effectiveness of the\nproposed representation for 3D action recognition on two datasets achieving\nstate-of-the-art results on the recent NTU RGB+D~120 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:35:06 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Caetano", "Carlos", ""], ["Br\u00e9mond", "Fran\u00e7ois", ""], ["Schwartz", "William Robson", ""]]}, {"id": "1909.05707", "submitter": "Seungjoon Lee", "authors": "Seungjoon Lee, Mahdi Kooshkbaghi, Konstantinos Spiliotis, Constantinos\n  I. Siettos, Ioannis G. Kevrekidis", "title": "Coarse-scale PDEs from fine-scale observations via machine learning", "comments": null, "journal-ref": null, "doi": "10.1063/1.5126869", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex spatiotemporal dynamics of physicochemical processes are often\nmodeled at a microscopic level (through e.g. atomistic, agent-based or lattice\nmodels) based on first principles. Some of these processes can also be\nsuccessfully modeled at the macroscopic level using e.g. partial differential\nequations (PDEs) describing the evolution of the right few macroscopic\nobservables (e.g. concentration and momentum fields). Deriving good macroscopic\ndescriptions (the so-called \"closure problem\") is often a time-consuming\nprocess requiring deep understanding/intuition about the system of interest.\nRecent developments in data science provide alternative ways to effectively\nextract/learn accurate macroscopic descriptions approximating the underlying\nmicroscopic observations. In this paper, we introduce a data-driven framework\nfor the identification of unavailable coarse-scale PDEs from microscopic\nobservations via machine learning algorithms. Specifically, using Gaussian\nProcesses, Artificial Neural Networks, and/or Diffusion Maps, the proposed\nframework uncovers the relation between the relevant macroscopic space fields\nand their time evolution (the right-hand-side of the explicitly unavailable\nmacroscopic PDE). Interestingly, several choices equally representative of the\ndata can be discovered. The framework will be illustrated through the\ndata-driven discovery of macroscopic, concentration-level PDEs resulting from a\nfine-scale, Lattice Boltzmann level model of a reaction/transport process. Once\nthe coarse evolution law is identified, it can be simulated to produce\nlong-term macroscopic predictions. Different features (pros as well as cons) of\nalternative machine learning algorithms for performing this task (Gaussian\nProcesses and Artificial Neural Networks), are presented and discussed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:21:07 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 18:47:55 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Lee", "Seungjoon", ""], ["Kooshkbaghi", "Mahdi", ""], ["Spiliotis", "Konstantinos", ""], ["Siettos", "Constantinos I.", ""], ["Kevrekidis", "Ioannis G.", ""]]}, {"id": "1909.05729", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Lin Meng", "title": "GResNet: Graph Residual Network for Reviving Deep GNNs from Suspended\n  Animation", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing graph neural networks (GNNs) based on the spectral graph\nconvolutional operator have been criticized for its performance degradation,\nwhich is especially common for the models with deep architectures. In this\npaper, we further identify the suspended animation problem with the existing\nGNNs. Such a problem happens when the model depth reaches the suspended\nanimation limit, and the model will not respond to the training data any more\nand become not learnable. Analysis about the causes of the suspended animation\nproblem with existing GNNs will be provided in this paper, whereas several\nother peripheral factors that will impact the problem will be reported as well.\nTo resolve the problem, we introduce the GResNet (Graph Residual Network)\nframework in this paper, which creates extensively connected highways to\ninvolve nodes' raw features or intermediate representations throughout the\ngraph for all the model layers. Different from the other learning settings, the\nextensive connections in the graph data will render the existing simple\nresidual learning methods fail to work. We prove the effectiveness of the\nintroduced new graph residual terms from the norm preservation perspective,\nwhich will help avoid dramatic changes to the node's representations between\nsequential layers. Detailed studies about the GResNet framework for many\nexisting GNNs, including GCN, GAT and LoopyNet, will be reported in the paper\nwith extensive empirical experiments on real-world benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:46:12 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 17:13:36 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Zhang", "Jiawei", ""], ["Meng", "Lin", ""]]}, {"id": "1909.05736", "submitter": "Boyang Deng", "authors": "Boyang Deng, Kyle Genova, Soroosh Yazdani, Sofien Bouaziz, Geoffrey\n  Hinton, Andrea Tagliasacchi", "title": "CvxNet: Learnable Convex Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any solid object can be decomposed into a collection of convex polytopes (in\nshort, convexes). When a small number of convexes are used, such a\ndecomposition can be thought of as a piece-wise approximation of the geometry.\nThis decomposition is fundamental in computer graphics, where it provides one\nof the most common ways to approximate geometry, for example, in real-time\nphysics simulation. A convex object also has the property of being\nsimultaneously an explicit and implicit representation: one can interpret it\nexplicitly as a mesh derived by computing the vertices of a convex hull, or\nimplicitly as the collection of half-space constraints or support functions.\nTheir implicit representation makes them particularly well suited for neural\nnetwork training, as they abstract away from the topology of the geometry they\nneed to represent. However, at testing time, convexes can also generate\nexplicit representations -- polygonal meshes -- which can then be used in any\ndownstream application. We introduce a network architecture to represent a low\ndimensional family of convexes. This family is automatically derived via an\nauto-encoding process. We investigate the applications of this architecture\nincluding automatic convex decomposition, image to 3D reconstruction, and\npart-based shape retrieval.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:59:52 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 15:59:46 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 19:18:09 GMT"}, {"version": "v4", "created": "Sun, 12 Apr 2020 23:43:12 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Deng", "Boyang", ""], ["Genova", "Kyle", ""], ["Yazdani", "Soroosh", ""], ["Bouaziz", "Sofien", ""], ["Hinton", "Geoffrey", ""], ["Tagliasacchi", "Andrea", ""]]}, {"id": "1909.05738", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall, Franz Kir\\'aly, Markus L\\\"oning, Matthew Middlehurst\n  and George Oastler", "title": "A tale of two toolkits, report the first: benchmarking time series\n  classification algorithms for correctness and efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  sktime is an open source, Python based, sklearn compatible toolkit for time\nseries analysis developed by researchers at the University of East Anglia\n(UEA), University College London and the Alan Turing Institute. A key initial\ngoal for sktime was to provide time series classification functionality\nequivalent to that available in a related java package, tsml, also developed at\nUEA. We describe the implementation of six such classifiers in sktime and\ncompare them to their tsml equivalents. We demonstrate correctness through\nequivalence of accuracy on a range of standard test problems and compare the\nbuild time of the different implementations. We find that there is significant\ndifference in accuracy on only one of the six algorithms we look at (Proximity\nForest). This difference is causing us some pain in debugging. We found a much\nwider range of difference in efficiency. Again, this was not unexpected, but it\ndoes highlight ways both toolkits could be improved.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 15:01:30 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 19:38:02 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2019 10:46:27 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Bagnall", "Anthony", ""], ["Kir\u00e1ly", "Franz", ""], ["L\u00f6ning", "Markus", ""], ["Middlehurst", "Matthew", ""], ["Oastler", "George", ""]]}, {"id": "1909.05746", "submitter": "Tingle Li", "authors": "Tingle Li, Jiawei Chen, Haowen Hou, Ming Li", "title": "Sams-Net: A Sliced Attention-based Neural Network for Music Source\n  Separation", "comments": "Submitted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.IR cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Network (CNN) or Long short-term memory (LSTM) based\nmodels with the input of spectrogram or waveforms are commonly used for deep\nlearning based audio source separation. In this paper, we propose a Sliced\nAttention-based neural network (Sams-Net) in the spectrogram domain for the\nmusic source separation task. It enables spectral feature interactions with\nmulti-head attention mechanism, achieves easier parallel computing and has a\nlarger receptive field compared with LSTMs and CNNs respectively. Experimental\nresults on the MUSDB18 dataset show that the proposed method, with fewer\nparameters, outperforms most of the state-of-the-art DNN-based methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 15:21:36 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 06:46:27 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 13:46:41 GMT"}, {"version": "v4", "created": "Tue, 19 May 2020 03:37:22 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Li", "Tingle", ""], ["Chen", "Jiawei", ""], ["Hou", "Haowen", ""], ["Li", "Ming", ""]]}, {"id": "1909.05748", "submitter": "Ren Hu", "authors": "Ren Hu, Qifeng Li, Feng Qiu", "title": "Ensemble Learning Based Convex Approximation of Three-Phase Power Flow", "comments": "8 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though the convex optimization has been widely used in power systems, it\nstill cannot guarantee to yield a tight (accurate) solution to some problems.\nTo mitigate this issue, this paper proposes an ensemble learning based convex\napproximation for AC power flow equations that differs from the existing convex\nrelaxations. The proposed approach is based on quadratic power flow equations\nin rectangular coordinates and it can be used in both balanced and unbalanced\nthree-phase power networks. To develop this data-driven convex approximation of\npower flows, the polynomial regression (PR) is first deployed as a basic\nlearner to fit convex relationships between the independent and dependent\nvariables. Then, ensemble learning algorithms such as gradient boosting (GB)\nand bagging are introduced to combine learners to boost model performance.\nBased on the learned convex approximation of power flows, optimal power flow\n(OPF) is formulated as a convex quadratic programming problem. The simulation\nresults on IEEE standard cases show that, in the context of solving OPF, the\nproposed data-driven convex approximation outperforms the conventional SDP\nrelaxation in both accuracy and computational efficiency, especially in the\ncases that the conventional SDP relaxation fails.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 15:24:45 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 14:59:37 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Hu", "Ren", ""], ["Li", "Qifeng", ""], ["Qiu", "Feng", ""]]}, {"id": "1909.05755", "submitter": "Kristian Miok", "authors": "Kristian Miok, Dong Nguyen-Doan, Daniela Zaharie and Marko\n  Robnik-\\v{S}ikonja", "title": "Generating Data using Monte Carlo Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many analytical problems the challenge is to handle huge amounts of\navailable data. However, there are data science application areas where\ncollecting information is difficult and costly, e.g., in the study of\ngeological phenomena, rare diseases, faults in complex systems, insurance\nfrauds, etc. In many such cases, generators of synthetic data with the same\nstatistical and predictive properties as the actual data allow efficient\nsimulations and development of tools and applications. In this work, we propose\nthe incorporation of Monte Carlo Dropout method within Autoencoder (MCD-AE) and\nVariational Autoencoder (MCD-VAE) as efficient generators of synthetic data\nsets. As the Variational Autoencoder (VAE) is one of the most popular generator\ntechniques, we explore its similarities and differences to the proposed\nmethods. We compare the generated data sets with the original data based on\nstatistical properties, structural similarity, and predictive similarity. The\nresults obtained show a strong similarity between the results of VAE, MCD-VAE\nand MCD-AE; however, the proposed methods are faster and can generate values\nsimilar to specific selected initial instances.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 15:33:20 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 13:07:17 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Miok", "Kristian", ""], ["Nguyen-Doan", "Dong", ""], ["Zaharie", "Daniela", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "1909.05772", "submitter": "Paolo Casari", "authors": "Constantine Ayimba, Paolo Casari, Vincenzo Mancuso", "title": "SQLR: Short-Term Memory Q-Learning for Elastic Provisioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more and more application providers transition to the cloud and deliver\ntheir services on a Software as a Service (SaaS) basis, cloud providers need to\nmake their provisioning systems agile enough to meet Service Level Agreements.\nAt the same time they should guard against over-provisioning which limits their\ncapacity to accommodate more tenants. To this end we propose SQLR, a dynamic\nprovisioning system employing a customized model-free reinforcement learning\nalgorithm that is capable of reusing contextual knowledge learned from one\nworkload to optimize resource provisioning for other workload patterns. SQLR\nachieves results comparable to those where resources are unconstrained, with\nminimal overhead. Our experiments show that we can reduce the amount of\nprovisioned resources by almost 25% with less than 1% overall service\nunavailability (due to blocking) while delivering similar response times as\nthose of an over-provisioned system.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:08:14 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 10:15:53 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Ayimba", "Constantine", ""], ["Casari", "Paolo", ""], ["Mancuso", "Vincenzo", ""]]}, {"id": "1909.05780", "submitter": "Yasumasa Onoe", "authors": "Yasumasa Onoe, Greg Durrett", "title": "Fine-Grained Entity Typing for Domain Independent Entity Linking", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural entity linking models are very powerful, but run the risk of\noverfitting to the domain they are trained in. For this problem, a domain is\ncharacterized not just by genre of text but even by factors as specific as the\nparticular distribution of entities, as neural models tend to overfit by\nmemorizing properties of frequent entities in a dataset. We tackle the problem\nof building robust entity linking models that generalize effectively and do not\nrely on labeled entity linking data with a specific entity distribution. Rather\nthan predicting entities directly, our approach models fine-grained entity\nproperties, which can help disambiguate between even closely related entities.\nWe derive a large inventory of types (tens of thousands) from Wikipedia\ncategories, and use hyperlinked mentions in Wikipedia to distantly label data\nand train an entity typing model. At test time, we classify a mention with this\ntyping model and use soft type predictions to link the mention to the most\nsimilar candidate entity. We evaluate our entity linking system on the\nCoNLL-YAGO dataset (Hoffart et al., 2011) and show that our approach\noutperforms prior domain-independent entity linking systems. We also test our\napproach in a harder setting derived from the WikilinksNED dataset (Eshel et\nal., 2017) where all the mention-entity pairs are unseen during test time.\nResults indicate that our approach generalizes better than a state-of-the-art\nneural model on the dataset.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:29:24 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 17:50:10 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Onoe", "Yasumasa", ""], ["Durrett", "Greg", ""]]}, {"id": "1909.05800", "submitter": "Silvia Chiappa", "authors": "Silvia Chiappa", "title": "Explicit-Duration Markov Switching Models", "comments": null, "journal-ref": "Foundations and Trends in Machine Learning, Volume 7, Issue 6,\n  pages 803-886, 2014", "doi": "10.1561/2200000054", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov switching models (MSMs) are probabilistic models that employ multiple\nsets of parameters to describe different dynamic regimes that a time series may\nexhibit at different periods of time. The switching mechanism between regimes\nis controlled by unobserved random variables that form a first-order Markov\nchain. Explicit-duration MSMs contain additional variables that explicitly\nmodel the distribution of time spent in each regime. This allows to define\nduration distributions of any form, but also to impose complex dependence\nbetween the observations and to reset the dynamics to initial conditions.\nModels that focus on the first two properties are most commonly known as hidden\nsemi-Markov models or segment models, whilst models that focus on the third\nproperty are most commonly known as changepoint models or reset models. In this\nmonograph, we provide a description of explicit-duration modelling by\ncategorizing the different approaches into three groups, which differ in\nencoding in the explicit-duration variables different information about regime\nchange/reset boundaries. The approaches are described using the formalism of\ngraphical models, which allows to graphically represent and assess statistical\ndependence and therefore to easily describe the structure of complex models and\nderive inference routines. The presentation is intended to be pedagogical,\nfocusing on providing a characterization of the three groups in terms of model\nstructure constraints and inference properties. The monograph is supplemented\nwith a software package that contains most of the models and examples\ndescribed. The material presented should be useful to both researchers wishing\nto learn about these models and researchers wishing to develop them further.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:54:16 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Chiappa", "Silvia", ""]]}, {"id": "1909.05803", "submitter": "Yichen Jiang", "authors": "Yichen Jiang, Mohit Bansal", "title": "Self-Assembling Modular Networks for Interpretable Multi-Hop Reasoning", "comments": "11 pages (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop QA requires a model to connect multiple pieces of evidence\nscattered in a long context to answer the question. The recently proposed\nHotpotQA (Yang et al., 2018) dataset is comprised of questions embodying four\ndifferent multi-hop reasoning paradigms (two bridge entity setups, checking\nmultiple properties, and comparing two entities), making it challenging for a\nsingle neural network to handle all four. In this work, we present an\ninterpretable, controller-based Self-Assembling Neural Modular Network (Hu et\nal., 2017, 2018) for multi-hop reasoning, where we design four novel modules\n(Find, Relocate, Compare, NoOp) to perform unique types of language reasoning.\nBased on a question, our layout controller RNN dynamically infers a series of\nreasoning modules to construct the entire network. Empirically, we show that\nour dynamic, multi-hop modular network achieves significant improvements over\nthe static, single-hop baseline (on both regular and adversarial evaluation).\nWe further demonstrate the interpretability of our model via three analyses.\nFirst, the controller can softly decompose the multi-hop question into multiple\nsingle-hop sub-questions to promote compositional reasoning behavior of the\nmain network. Second, the controller can predict layouts that conform to the\nlayouts designed by human experts. Finally, the intermediate module can infer\nthe entity that connects two distantly-located supporting facts by addressing\nthe sub-question from the controller.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:00:45 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 21:11:19 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Jiang", "Yichen", ""], ["Bansal", "Mohit", ""]]}, {"id": "1909.05822", "submitter": "Pascale Gourdeau", "authors": "Pascale Gourdeau, Varun Kanade, Marta Kwiatkowska, James Worrell", "title": "On the Hardness of Robust Classification", "comments": "To appear in the proceedings of Neural Information Processing Systems\n  Conference (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is becoming increasingly important to understand the vulnerability of\nmachine learning models to adversarial attacks. In this paper we study the\nfeasibility of robust learning from the perspective of computational learning\ntheory, considering both sample and computational complexity. In particular,\nour definition of robust learnability requires polynomial sample complexity. We\nstart with two negative results. We show that no non-trivial concept class can\nbe robustly learned in the distribution-free setting against an adversary who\ncan perturb just a single input bit. We show moreover that the class of\nmonotone conjunctions cannot be robustly learned under the uniform distribution\nagainst an adversary who can perturb $\\omega(\\log n)$ input bits. However if\nthe adversary is restricted to perturbing $O(\\log n)$ bits, then the class of\nmonotone conjunctions can be robustly learned with respect to a general class\nof distributions (that includes the uniform distribution). Finally, we provide\na simple proof of the computational hardness of robust learning on the boolean\nhypercube. Unlike previous results of this nature, our result does not rely on\nanother computational model (e.g. the statistical query model) nor on any\nhardness assumption other than the existence of a hard learning problem in the\nPAC framework.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:29:08 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Gourdeau", "Pascale", ""], ["Kanade", "Varun", ""], ["Kwiatkowska", "Marta", ""], ["Worrell", "James", ""]]}, {"id": "1909.05829", "submitter": "Suraj Nair", "authors": "Suraj Nair, Chelsea Finn", "title": "Hierarchical Foresight: Self-Supervised Learning of Long-Horizon Tasks\n  via Visual Subgoal Generation", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video prediction models combined with planning algorithms have shown promise\nin enabling robots to learn to perform many vision-based tasks through only\nself-supervision, reaching novel goals in cluttered scenes with unseen objects.\nHowever, due to the compounding uncertainty in long horizon video prediction\nand poor scalability of sampling-based planning optimizers, one significant\nlimitation of these approaches is the ability to plan over long horizons to\nreach distant goals. To that end, we propose a framework for subgoal generation\nand planning, hierarchical visual foresight (HVF), which generates subgoal\nimages conditioned on a goal image, and uses them for planning. The subgoal\nimages are directly optimized to decompose the task into easy to plan segments,\nand as a result, we observe that the method naturally identifies semantically\nmeaningful states as subgoals. Across three out of four simulated vision-based\nmanipulation tasks, we find that our method achieves nearly a 200% performance\nimprovement over planning without subgoals and model-free RL approaches.\nFurther, our experiments illustrate that our approach extends to real,\ncluttered visual scenes. Project page:\nhttps://sites.google.com/stanford.edu/hvf\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:36:45 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Nair", "Suraj", ""], ["Finn", "Chelsea", ""]]}, {"id": "1909.05830", "submitter": "Jeffrey Li", "authors": "Jeffrey Li, Mikhail Khodak, Sebastian Caldas, Ameet Talwalkar", "title": "Differentially Private Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter-transfer is a well-known and versatile approach for meta-learning,\nwith applications including few-shot learning, federated learning, and\nreinforcement learning. However, parameter-transfer algorithms often require\nsharing models that have been trained on the samples from specific tasks, thus\nleaving the task-owners susceptible to breaches of privacy. We conduct the\nfirst formal study of privacy in this setting and formalize the notion of\ntask-global differential privacy as a practical relaxation of more commonly\nstudied threat models. We then propose a new differentially private algorithm\nfor gradient-based parameter transfer that not only satisfies this privacy\nrequirement but also retains provable transfer learning guarantees in convex\nsettings. Empirically, we apply our analysis to the problems of federated\nlearning with personalization and few-shot classification, showing that\nallowing the relaxation to task-global privacy from the more commonly studied\nnotion of local privacy leads to dramatically increased performance in\nrecurrent neural language modeling and image classification.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:37:08 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 17:08:10 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Li", "Jeffrey", ""], ["Khodak", "Mikhail", ""], ["Caldas", "Sebastian", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1909.05840", "submitter": "Amir Gholami", "authors": "Sheng Shen and Zhen Dong and Jiayu Ye and Linjian Ma and Zhewei Yao\n  and Amir Gholami and Michael W. Mahoney and Kurt Keutzer", "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer based architectures have become de-facto models used for a range\nof Natural Language Processing tasks. In particular, the BERT based models\nachieved significant accuracy gain for GLUE tasks, CoNLL-03 and SQuAD. However,\nBERT based models have a prohibitive memory footprint and latency. As a result,\ndeploying BERT based models in resource constrained environments has become a\nchallenging task. In this work, we perform an extensive analysis of fine-tuned\nBERT models using second order Hessian information, and we use our results to\npropose a novel method for quantizing BERT models to ultra low precision. In\nparticular, we propose a new group-wise quantization scheme, and we use a\nHessian based mix-precision method to compress the model further. We\nextensively test our proposed method on BERT downstream tasks of SST-2, MNLI,\nCoNLL-03, and SQuAD. We can achieve comparable performance to baseline with at\nmost $2.3\\%$ performance degradation, even with ultra-low precision\nquantization down to 2 bits, corresponding up to $13\\times$ compression of the\nmodel parameters, and up to $4\\times$ compression of the embedding table as\nwell as activations. Among all tasks, we observed the highest performance loss\nfor BERT fine-tuned on SQuAD. By probing into the Hessian based analysis as\nwell as visualization, we show that this is related to the fact that current\ntraining/fine-tuning strategy of BERT does not converge for SQuAD.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:45:59 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 00:13:30 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Shen", "Sheng", ""], ["Dong", "Zhen", ""], ["Ye", "Jiayu", ""], ["Ma", "Linjian", ""], ["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Mahoney", "Michael W.", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1909.05844", "submitter": "Boyue Li", "authors": "Boyue Li, Shicong Cen, Yuxin Chen, Yuejie Chi", "title": "Communication-Efficient Distributed Optimization in Networks with\n  Gradient Tracking and Variance Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing interest in large-scale machine learning and optimization\nover decentralized networks, e.g. in the context of multi-agent learning and\nfederated learning. Due to the imminent need to alleviate the communication\nburden, the investigation of communication-efficient distributed optimization\nalgorithms - particularly for empirical risk minimization - has flourished in\nrecent years. A large fraction of these algorithms have been developed for the\nmaster/slave setting, relying on a central parameter server that can\ncommunicate with all agents. This paper focuses on distributed optimization\nover networks, or decentralized optimization, where each agent is only allowed\nto aggregate information from its neighbors. By properly adjusting the global\ngradient estimate via local averaging in conjunction with proper correction, we\ndevelop a communication-efficient approximate Newton-type method Network-DANE,\nwhich generalizes DANE to the decentralized scenarios. Our key ideas can be\napplied in a systematic manner to obtain decentralized versions of other\nmaster/slave distributed algorithms. A notable development is\nNetwork-SVRG/SARAH, which employs variance reduction to further accelerate\nlocal computation. We establish linear convergence of Network-DANE and\nNetwork-SVRG for strongly convex losses, and Network-SARAH for quadratic\nlosses, which shed light on the impacts of data homogeneity, network\nconnectivity, and local averaging upon the rate of convergence. We further\nextend Network-DANE to composite optimization by allowing a nonsmooth penalty\nterm. Numerical evidence is provided to demonstrate the appealing performance\nof our algorithms over competitive baselines, in terms of both communication\nand computation efficiency. Our work suggests that performing a certain amount\nof local communications and computations per iteration can substantially\nimprove the overall efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:50:03 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 01:00:16 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 19:31:46 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Li", "Boyue", ""], ["Cen", "Shicong", ""], ["Chen", "Yuxin", ""], ["Chi", "Yuejie", ""]]}, {"id": "1909.05850", "submitter": "Nathan Kallus", "authors": "Nathan Kallus and Masatoshi Uehara", "title": "Efficiently Breaking the Curse of Horizon in Off-Policy Evaluation with\n  Double Reinforcement Learning", "comments": "In V3, we significantly changed the derivation of the efficiency\n  bound to follow standard (iid) semiparametric theory. We also derive the\n  efficient influence function. In V4, we add an experiment in a\n  continuous-state environment employing function approximation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation (OPE) in reinforcement learning is notoriously\ndifficult in long- and infinite-horizon settings due to diminishing overlap\nbetween behavior and target policies. In this paper, we study the role of\nMarkovian and time-invariant structure in efficient OPE. We first derive the\nefficiency bounds for OPE when one assumes each of these structures. This\nprecisely characterizes the curse of horizon: in time-variant processes, OPE is\nonly feasible in the near-on-policy setting, where behavior and target policies\nare sufficiently similar. But, in time-invariant Markov decision processes, our\nbounds show that truly-off-policy evaluation is feasible, even with only just\none dependent trajectory, and provide the limits of how well we could hope to\ndo. We develop a new estimator based on Double Reinforcement Learning (DRL)\nthat leverages this structure for OPE using the efficient influence function we\nderive. Our DRL estimator simultaneously uses estimated stationary density\nratios and $q$-functions and remains efficient when both are estimated at slow,\nnonparametric rates and remains consistent when either is estimated\nconsistently. We investigate these properties and the performance benefits of\nleveraging the problem structure for more efficient OPE.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:52:55 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 10:10:10 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 17:57:41 GMT"}, {"version": "v4", "created": "Wed, 24 Mar 2021 04:35:06 GMT"}, {"version": "v5", "created": "Mon, 3 May 2021 15:27:23 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Kallus", "Nathan", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "1909.05862", "submitter": "Miles Cranmer", "authors": "Miles D. Cranmer, Rui Xu, Peter Battaglia, Shirley Ho", "title": "Learning Symbolic Physics with Graph Networks", "comments": "6 pages; references added + improvements to writing and clarity;\n  accepted for an oral presentation at Machine Learning and the Physical\n  Sciences Workshop @ NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach for imposing physically motivated inductive biases\non graph networks to learn interpretable representations and improved zero-shot\ngeneralization. Our experiments show that our graph network models, which\nimplement this inductive bias, can learn message representations equivalent to\nthe true force vector when trained on n-body gravitational and spring-like\nsimulations. We use symbolic regression to fit explicit algebraic equations to\nour trained model's message function and recover the symbolic form of Newton's\nlaw of gravitation without prior knowledge. We also show that our model\ngeneralizes better at inference time to systems with more bodies than had been\nexperienced during training. Our approach is extensible, in principle, to any\nunknown interaction law learned by a graph network, and offers a valuable\ntechnique for interpreting and inferring explicit causal theories about the\nworld from implicit knowledge captured by deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:00:00 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 15:33:25 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Cranmer", "Miles D.", ""], ["Xu", "Rui", ""], ["Battaglia", "Peter", ""], ["Ho", "Shirley", ""]]}, {"id": "1909.05885", "submitter": "Ishita Dasgupta", "authors": "Ishita Dasgupta, Demi Guo, Samuel J. Gershman and Noah D. Goodman", "title": "Analyzing machine-learned representations: A natural language case study", "comments": "This article supersedes a previous article arXiv:1802.04302", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As modern deep networks become more complex, and get closer to human-like\ncapabilities in certain domains, the question arises of how the representations\nand decision rules they learn compare to the ones in humans. In this work, we\nstudy representations of sentences in one such artificial system for natural\nlanguage processing. We first present a diagnostic test dataset to examine the\ndegree of abstract composable structure represented. Analyzing performance on\nthese diagnostic tests indicates a lack of systematicity in the representations\nand decision rules, and reveals a set of heuristic strategies. We then\ninvestigate the effect of the training distribution on learning these heuristic\nstrategies, and study changes in these representations with various\naugmentations to the training set. Our results reveal parallels to the\nanalogous representations in people. We find that these systems can learn\nabstract rules and generalize them to new contexts under certain circumstances\n-- similar to human zero-shot reasoning. However, we also note some\nshortcomings in this generalization behavior -- similar to human judgment\nerrors like belief bias. Studying these parallels suggests new ways to\nunderstand psychological phenomena in humans as well as informs best strategies\nfor building artificial intelligence with human-like language understanding.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:03:17 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Dasgupta", "Ishita", ""], ["Guo", "Demi", ""], ["Gershman", "Samuel J.", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1909.05886", "submitter": "Lingda Wang", "authors": "Lingda Wang, Huozhi Zhou, Bingcong Li, Lav R. Varshney, Zhizhen Zhao", "title": "Nearly Optimal Algorithms for Piecewise-Stationary Cascading Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cascading bandit (CB) is a popular model for web search and online\nadvertising, where an agent aims to learn the $K$ most attractive items out of\na ground set of size $L$ during the interaction with a user. However, the\nstationary CB model may be too simple to apply to real-world problems, where\nuser preferences may change over time. Considering piecewise-stationary\nenvironments, two efficient algorithms, \\texttt{GLRT-CascadeUCB} and\n\\texttt{GLRT-CascadeKL-UCB}, are developed and shown to ensure regret upper\nbounds on the order of $\\mathcal{O}(\\sqrt{NLT\\log{T}})$, where $N$ is the\nnumber of piecewise-stationary segments, and $T$ is the number of time slots.\nAt the crux of the proposed algorithms is an almost parameter-free change-point\ndetector, the generalized likelihood ratio test (GLRT). Comparing with existing\nworks, the GLRT-based algorithms: i) are free of change-point-dependent\ninformation for choosing parameters; ii) have fewer tuning parameters; iii)\nimprove at least the $L$ dependence in regret upper bounds. In addition, we\nshow that the proposed algorithms are optimal (up to a logarithm factor) in\nterms of regret by deriving a minimax lower bound on the order of\n$\\Omega(\\sqrt{NLT})$ for piecewise-stationary CB. The efficiency of the\nproposed algorithms relative to state-of-the-art approaches is validated\nthrough numerical experiments on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:04:12 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 14:19:02 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 15:06:18 GMT"}, {"version": "v4", "created": "Mon, 7 Oct 2019 15:00:06 GMT"}, {"version": "v5", "created": "Mon, 17 Feb 2020 17:16:08 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wang", "Lingda", ""], ["Zhou", "Huozhi", ""], ["Li", "Bingcong", ""], ["Varshney", "Lav R.", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "1909.05894", "submitter": "Georgi Nalbantov", "authors": "Georgi Nalbantov and Svetoslav Ivanov", "title": "A Note on Posterior Probability Estimation for Classifiers", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central themes in the classification task is the estimation of\nclass posterior probability at a new point $\\bf{x}$. The vast majority of\nclassifiers output a score for $\\bf{x}$, which is monotonically related to the\nposterior probability via an unknown relationship. There are many attempts in\nthe literature to estimate this latter relationship. Here, we provide a way to\nestimate the posterior probability without resorting to using classification\nscores. Instead, we vary the prior probabilities of classes in order to derive\nthe ratio of pdf's at point $\\bf{x}$, which is directly used to determine class\nposterior probabilities. We consider here the binary classification problem.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 18:19:00 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Nalbantov", "Georgi", ""], ["Ivanov", "Svetoslav", ""]]}, {"id": "1909.05917", "submitter": "Alessandro Bruno", "authors": "Alessandro Bruno, Anna Anzalone, Carlo Vigorito (for the JEM-EUSO\n  collaboration)", "title": "A method for Cloud Mapping in the Field of View of the Infra-Red Camera\n  during the EUSO-SPB1 flight", "comments": "7 pages, 8 figures, 36th International Cosmic Ray Conference\n  -ICRC2019", "journal-ref": "36th International Cosmic Ray Conference (ICRC2019), volume=36,\n  year=2019 }", "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.EP cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  EUSO-SPB1 was released on April 24th, 2017, from the NASA balloon launch site\nin Wanaka (New Zealand) and landed on the South Pacific Ocean on May 7th. The\ndata collected by the instruments onboard the balloon were analyzed to search\nUV pulse signatures of UHECR (Ultra High Energy Cosmic Rays) air showers.\nIndirect measurements of UHECRs can be affected by cloud presence during\nnighttime, therefore it is crucial to know the meteorological conditions during\nthe observation period of the detector. During the flight, the onboard\nEUSO-SPB1 UCIRC camera (University of Chicago Infra-Red Camera), acquired\nimages in the field of view of the UV telescope. The available nighttime and\ndaytime images include information on meteorological conditions of the\natmosphere observed in two infra-red bands. The presence of clouds has been\ninvestigated employing a method developed to provide a dense cloudiness map for\neach available infra-red image. The final masks are intended to give pixel\ncloudiness information at the IR-camera pixel resolution that is nearly 4-times\nhigher than the one of the UV-camera. In this work, cloudiness maps are\nobtained by using an expert system based on the analysis of different low-level\nimage features. Furthermore, an image enhancement step was needed to be applied\nas a preprocessing step to deal with uncalibrated data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 19:26:19 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Bruno", "Alessandro", "", "for the JEM-EUSO\n  collaboration"], ["Anzalone", "Anna", "", "for the JEM-EUSO\n  collaboration"], ["Vigorito", "Carlo", "", "for the JEM-EUSO\n  collaboration"]]}, {"id": "1909.05921", "submitter": "Pratik Vaishnavi", "authors": "Pratik Vaishnavi, Kevin Eykholt, Atul Prakash, Amir Rahmati", "title": "Towards Model-Agnostic Adversarial Defenses using Adversarially Trained\n  Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial machine learning is a well-studied field of research where an\nadversary causes predictable errors in a machine learning algorithm through\nprecise manipulation of the input. Numerous techniques have been proposed to\nharden machine learning algorithms and mitigate the effect of adversarial\nattacks. Of these techniques, adversarial training, which augments the training\ndata with adversarial samples, has proven to be an effective defense with\nrespect to a certain class of attacks. However, adversarial training is\ncomputationally expensive and its improvements are limited to a single model.\nIn this work, we take a first step toward creating a model-agnostic adversarial\ndefense. We propose Adversarially-Trained Autoencoder Augmentation (AAA), the\nfirst model-agnostic adversarial defense that is robust against certain\nadaptive adversaries. We show that AAA allows us to achieve a partially\nmodel-agnostic defense by training a single autoencoder to protect multiple\npre-trained classifiers; achieving adversarial performance on par or better\nthan adversarial training without modifying the classifiers. Furthermore, we\ndemonstrate that AAA can be used to create a fully model-agnostic defense for\nMNIST and Fashion MNIST datasets by improving the adversarial performance of a\nnever before seen pre-trained classifier by at least 45% with no additional\ntraining. Finally, using a natural image corruption dataset, we show that our\napproach improves robustness to naturally corrupted images,which has been\nidentified as strongly indicative of true adversarial robustness.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 19:51:14 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 22:50:06 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 23:38:30 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Vaishnavi", "Pratik", ""], ["Eykholt", "Kevin", ""], ["Prakash", "Atul", ""], ["Rahmati", "Amir", ""]]}, {"id": "1909.05926", "submitter": "Rodney LaLonde III", "authors": "Rodney LaLonde, Drew Torigian, Ulas Bagci", "title": "Encoding Visual Attributes in Capsules for Explainable Medical Diagnoses", "comments": "Accepted for publication at MICCAI 2020 (23rd International\n  Conference on Medical Image Computing and Computer Assisted Intervention).\n  Code is publicly available at https://github.com/lalonderodney/X-Caps", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network based systems have largely failed to be adopted\nin many high-risk application areas, including healthcare, military, security,\ntransportation, finance, and legal, due to their highly uninterpretable\n\"black-box\" nature. Towards solving this deficiency, we teach a novel\nmulti-task capsule network to improve the explainability of predictions by\nembodying the same high-level language used by human-experts. Our explainable\ncapsule network, X-Caps, encodes high-level visual object attributes within the\nvectors of its capsules, then forms predictions based solely on these\nhuman-interpretable features. To encode attributes, X-Caps utilizes a new\nrouting sigmoid function to independently route information from child capsules\nto parents. Further, to provide radiologists with an estimate of model\nconfidence, we train our network on a distribution of expert labels, modeling\ninter-observer agreement and punishing over/under confidence during training,\nsupervised by human-experts' agreement. X-Caps simultaneously learns attribute\nand malignancy scores from a multi-center dataset of over 1000 CT scans of lung\ncancer screening patients. We demonstrate a simple 2D capsule network can\noutperform a state-of-the-art deep dense dual-path 3D CNN at capturing\nvisually-interpretable high-level attributes and malignancy prediction, while\nproviding malignancy prediction scores approaching that of non-explainable 3D\nCNNs. To the best of our knowledge, this is the first study to investigate\ncapsule networks for making predictions based on radiologist-level\ninterpretable attributes and its applications to medical image diagnosis. Code\nis publicly available at https://github.com/lalonderodney/X-Caps .\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 20:04:16 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 07:58:34 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 17:58:42 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 03:02:06 GMT"}, {"version": "v5", "created": "Sat, 20 Jun 2020 23:52:39 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["LaLonde", "Rodney", ""], ["Torigian", "Drew", ""], ["Bagci", "Ulas", ""]]}, {"id": "1909.05946", "submitter": "Sylvain Calinon Dr", "authors": "Sylvain Calinon", "title": "Gaussians on Riemannian Manifolds: Applications for Robot Learning and\n  Adaptive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents an overview of robot learning and adaptive control\napplications that can benefit from a joint use of Riemannian geometry and\nprobabilistic representations. The roles of Riemannian manifolds, geodesics and\nparallel transport in robotics are first discussed. Several forms of manifolds\nalready employed in robotics are then presented, by also listing manifolds that\nhave been underexploited but that have potentials in future robot learning\napplications. A varied range of techniques employing Gaussian distributions on\nRiemannian manifolds is then introduced, including clustering, regression,\ninformation fusion, planning and control problems. Two examples of applications\nare presented, involving the control of a prosthetic hand from surface\nelectromyography (sEMG) data, and the teleoperation of a bimanual underwater\nrobot. Further perspectives are finally discussed, with suggestions of\npromising research directions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 20:59:27 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 01:02:01 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 15:52:23 GMT"}, {"version": "v4", "created": "Mon, 30 Mar 2020 08:30:49 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Calinon", "Sylvain", ""]]}, {"id": "1909.05948", "submitter": "Filippo Maria Bianchi", "authors": "Luigi T. Luppino, Filippo M. Bianchi, Gabriele Moser, Stian N.\n  Anfinsen", "title": "Unsupervised Image Regression for Heterogeneous Change Detection", "comments": "arXiv admin note: text overlap with arXiv:1807.11766", "journal-ref": null, "doi": "10.1109/TGRS.2019.2930348", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change detection in heterogeneous multitemporal satellite images is an\nemerging and challenging topic in remote sensing. In particular, one of the\nmain challenges is to tackle the problem in an unsupervised manner. In this\npaper we propose an unsupervised framework for bitemporal heterogeneous change\ndetection based on the comparison of affinity matrices and image regression.\nFirst, our method quantifies the similarity of affinity matrices computed from\nco-located image patches in the two images. This is done to automatically\nidentify pixels that are likely to be unchanged. With the identified pixels as\npseudo-training data, we learn a transformation to map the first image to the\ndomain of the other image, and vice versa. Four regression methods are selected\nto carry out the transformation: Gaussian process regression, support vector\nregression, random forest regression, and a recently proposed kernel regression\nmethod called homogeneous pixel transformation. To evaluate the potentials and\nlimitations of our framework, and also the benefits and disadvantages of each\nregression method, we perform experiments on two real data sets. The results\nindicate that the comparison of the affinity matrices can already be considered\na change detection method by itself. However, image regression is shown to\nimprove the results obtained by the previous step alone and produces accurate\nchange detection maps despite of the heterogeneity of the multitemporal input\ndata. Notably, the random forest regression approach excels by achieving\nsimilar accuracy as the other methods, but with a significantly lower\ncomputational cost and with fast and robust tuning of hyperparameters.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 12:26:11 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Luppino", "Luigi T.", ""], ["Bianchi", "Filippo M.", ""], ["Moser", "Gabriele", ""], ["Anfinsen", "Stian N.", ""]]}, {"id": "1909.05949", "submitter": "Jaime Carrasco Barra", "authors": "Jaime Carrasco, Cristobal Pais, Zuo-Jun Max Shen and Andres Weintraub", "title": "Adjusting Rate of Spread Factors through Derivative-Free Optimization: A\n  New Methodology to Improve the Performance of Forest Fire Simulators", "comments": "8 figures, 35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical applications, it is common that wildfire simulators do not\ncorrectly predict the evolution of the fire scar. Usually, this is caused due\nto multiple factors including inaccuracy in the input data such as land cover\nclassification, moisture, improperly represented local winds, cumulative errors\nin the fire growth simulation model, high level of discontinuity/heterogeneity\nwithin the landscape, among many others. Therefore in practice, it is necessary\nto adjust the propagation of the fire to obtain better results, either to\nsupport suppression activities or to improve the performance of the simulator\nconsidering new default parameters for future events, best representing the\ncurrent fire spread growth phenomenon. In this article, we address this problem\nthrough a new methodology using Derivative-Free Optimization (DFO) algorithms\nfor adjusting the Rate of Spread (ROS) factors in a fire simulation growth\nmodel called Cell2Fire. To achieve this, we solve an error minimization\noptimization problem that captures the difference between the simulated and\nobserved fire, which involves the evaluation of the simulator output in each\niteration as part of a DFO framework, allowing us to find the best possible\nfactors for each fuel present on the landscape. Numerical results for different\nobjective functions are shown and discussed, including a performance comparison\nof alternative DFO algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 05:05:01 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Carrasco", "Jaime", ""], ["Pais", "Cristobal", ""], ["Shen", "Zuo-Jun Max", ""], ["Weintraub", "Andres", ""]]}, {"id": "1909.05950", "submitter": "Felix Leibfried", "authors": "Felix Leibfried and Jordi Grau-Moya", "title": "Mutual-Information Regularization in Markov Decision Processes and\n  Actor-Critic Learning", "comments": "Proceedings of the 3rd Conference on Robot Learning (CoRL), Osaka,\n  Japan, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cumulative entropy regularization introduces a regulatory signal to the\nreinforcement learning (RL) problem that encourages policies with high-entropy\nactions, which is equivalent to enforcing small deviations from a uniform\nreference marginal policy. This has been shown to improve exploration and\nrobustness, and it tackles the value overestimation problem. It also leads to a\nsignificant performance increase in tabular and high-dimensional settings, as\ndemonstrated via algorithms such as soft Q-learning (SQL) and soft actor-critic\n(SAC). Cumulative entropy regularization has been extended to optimize over the\nreference marginal policy instead of keeping it fixed, yielding a\nregularization that minimizes the mutual information between states and\nactions. While this has been initially proposed for Markov Decision Processes\n(MDPs) in tabular settings, it was recently shown that a similar principle\nleads to significant improvements over vanilla SQL in RL for high-dimensional\ndomains with discrete actions and function approximators.\n  Here, we follow the motivation of mutual-information regularization from an\ninference perspective and theoretically analyze the corresponding Bellman\noperator. Inspired by this Bellman operator, we devise a novel\nmutual-information regularized actor-critic learning (MIRACLE) algorithm for\ncontinuous action spaces that optimizes over the reference marginal policy. We\nempirically validate MIRACLE in the Mujoco robotics simulator, where we\ndemonstrate that it can compete with contemporary RL methods. Most notably, it\ncan improve over the model-free state-of-the-art SAC algorithm which implicitly\nassumes a fixed reference policy.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 16:43:25 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Leibfried", "Felix", ""], ["Grau-Moya", "Jordi", ""]]}, {"id": "1909.05965", "submitter": "Tian Xia", "authors": "Tian Xia, Shaodan Zhai, Shaojun Wang", "title": "Analysis of Regression Tree Fitting Algorithms in Learning to Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In learning to rank area, industry-level applications have been dominated by\ngradient boosting framework, which fits a tree using least square error\nprinciple. While in classification area, another tree fitting principle,\nweighted least square error, has been widely used, such as LogitBoost and its\nvariants. However, there is a lack of analysis on the relationship between the\ntwo principles in the scenario of learning to rank. We propose a new principle\nnamed least objective loss based error that enables us to analyze the issue\nabove as well as several important learning to rank models. We also implement\ntwo typical and strong systems and conduct our experiments in two real-world\ndatasets. Experimental results show that our proposed method brings moderate\nimprovements over least square error principle.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:07:48 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Xia", "Tian", ""], ["Zhai", "Shaodan", ""], ["Wang", "Shaojun", ""]]}, {"id": "1909.05974", "submitter": "EPTCS", "authors": "Yi Xiao, Emilio Tuosto", "title": "On Learning Nominal Automata with Binders", "comments": "In Proceedings ICE 2019, arXiv:1909.05242", "journal-ref": "EPTCS 304, 2019, pp. 137-155", "doi": "10.4204/EPTCS.304.9", "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a learning algorithm in the context of nominal automata, an\nextension of classical automata to alphabets featuring names. This class of\nautomata captures nominal regular languages; analogously to the classical\nlanguage theory, nominal automata have been shown to characterise nominal\nregular expressions with binders. These formalisms are amenable to abstract\nmodelling resource-aware computations. We propose a learning algorithm on\nnominal regular languages with binders. Our algorithm generalises Angluin's L*\nalgorithm with respect to nominal regular languages with binders. We show the\ncorrectness and study the theoretical complexity of our algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:25:56 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Xiao", "Yi", ""], ["Tuosto", "Emilio", ""]]}, {"id": "1909.05976", "submitter": "Alain Barrat", "authors": "Koya Sato, Mizuki Oka, Alain Barrat, Ciro Cattuto", "title": "DyANE: Dynamics-aware node embedding for temporal networks", "comments": "updated version with additional results", "journal-ref": "EPJ Data Science volume 10: 22 (2021)", "doi": "10.1140/epjds/s13688-021-00277-8", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-dimensional vector representations of network nodes have proven\nsuccessful to feed graph data to machine learning algorithms and to improve\nperformance across diverse tasks. Most of the embedding techniques, however,\nhave been developed with the goal of achieving dense, low-dimensional encoding\nof network structure and patterns. Here, we present a node embedding technique\naimed at providing low-dimensional feature vectors that are informative of\ndynamical processes occurring over temporal networks -- rather than of the\nnetwork structure itself -- with the goal of enabling prediction tasks related\nto the evolution and outcome of these processes. We achieve this by using a\nmodified supra-adjacency representation of temporal networks and building on\nstandard embedding techniques for static graphs based on random-walks. We show\nthat the resulting embedding vectors are useful for prediction tasks related to\nparadigmatic dynamical processes, namely epidemic spreading over empirical\ntemporal networks. In particular, we illustrate the performance of our approach\nfor the prediction of nodes' epidemic states in a single instance of a\nspreading process. We show how framing this task as a supervised multi-label\nclassification task on the embedding vectors allows us to estimate the temporal\nevolution of the entire system from a partial sampling of nodes at random\ntimes, with potential impact for nowcasting infectious disease dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:40:37 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 20:24:21 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Sato", "Koya", ""], ["Oka", "Mizuki", ""], ["Barrat", "Alain", ""], ["Cattuto", "Ciro", ""]]}, {"id": "1909.05989", "submitter": "Boris Hanin", "authors": "Boris Hanin, Mihai Nica", "title": "Finite Depth and Width Corrections to the Neural Tangent Kernel", "comments": "27 pages, 2 figures, comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove the precise scaling, at finite depth and width, for the mean and\nvariance of the neural tangent kernel (NTK) in a randomly initialized ReLU\nnetwork. The standard deviation is exponential in the ratio of network depth to\nwidth. Thus, even in the limit of infinite overparameterization, the NTK is not\ndeterministic if depth and width simultaneously tend to infinity. Moreover, we\nprove that for such deep and wide networks, the NTK has a non-trivial evolution\nduring training by showing that the mean of its first SGD update is also\nexponential in the ratio of network depth to width. This is sharp contrast to\nthe regime where depth is fixed and network width is very large. Our results\nsuggest that, unlike relatively shallow and wide networks, deep and wide ReLU\nnetworks are capable of learning data-dependent features even in the so-called\nlazy training regime.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 00:21:53 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Hanin", "Boris", ""], ["Nica", "Mihai", ""]]}, {"id": "1909.06008", "submitter": "Zhao Kang", "authors": "Zhao Kang and Zipeng Guo and Shudong Huang and Siying Wang and Wenyu\n  Chen and Yuanzhang Su and Zenglin Xu", "title": "Multiple Partitions Aligned Clustering", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view clustering is an important yet challenging task due to the\ndifficulty of integrating the information from multiple representations. Most\nexisting multi-view clustering methods explore the heterogeneous information in\nthe space where the data points lie. Such common practice may cause significant\ninformation loss because of unavoidable noise or inconsistency among views.\nSince different views admit the same cluster structure, the natural space\nshould be all partitions. Orthogonal to existing techniques, in this paper, we\npropose to leverage the multi-view information by fusing partitions.\nSpecifically, we align each partition to form a consensus cluster indicator\nmatrix through a distinct rotation matrix. Moreover, a weight is assigned for\neach view to account for the clustering capacity differences of views. Finally,\nthe basic partitions, weights, and consensus clustering are jointly learned in\na unified framework. We demonstrate the effectiveness of our approach on\nseveral real datasets, where significant improvement is found over other\nstate-of-the-art multi-view clustering methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 02:45:13 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Kang", "Zhao", ""], ["Guo", "Zipeng", ""], ["Huang", "Shudong", ""], ["Wang", "Siying", ""], ["Chen", "Wenyu", ""], ["Su", "Yuanzhang", ""], ["Xu", "Zenglin", ""]]}, {"id": "1909.06019", "submitter": "Michael Katehakis", "authors": "Wesley Cowan, Michael N. Katehakis, Daniel Pirutinsky", "title": "Reinforcement Learning: a Comparison of UCB Versus Alternative Adaptive\n  Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the basic version of Reinforcement Learning (RL)\nthat involves computing optimal data driven (adaptive) policies for Markovian\ndecision process with unknown transition probabilities. We provide a brief\nsurvey of the state of the art of the area and we compare the performance of\nthe classic UCB policy of \\cc{bkmdp97} with a new policy developed herein which\nwe call MDP-Deterministic Minimum Empirical Divergence (MDP-DMED), and a method\nbased on Posterior sampling (MDP-PS).\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 03:43:19 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Cowan", "Wesley", ""], ["Katehakis", "Michael N.", ""], ["Pirutinsky", "Daniel", ""]]}, {"id": "1909.06020", "submitter": "Shilian Zheng", "authors": "Shilian Zheng, Shichuan Chen, Peihan Qi, Huaji Zhou, and Xiaoniu Yang", "title": "Spectrum Sensing Based on Deep Learning Classification for Cognitive\n  Radios", "comments": "Submitted to China Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectrum sensing is a key technology for cognitive radios. We present\nspectrum sensing as a classification problem and propose a sensing method based\non deep learning classification. We normalize the received signal power to\novercome the effects of noise power uncertainty. We train the model with as\nmany types of signals as possible as well as noise data to enable the trained\nnetwork model to adapt to untrained new signals. We also use transfer learning\nstrategies to improve the performance for real-world signals. Extensive\nexperiments are conducted to evaluate the performance of this method. The\nsimulation results show that the proposed method performs better than two\ntraditional spectrum sensing methods, i.e., maximum-minimum eigenvalue\nratio-based method and frequency domain entropy-based method. In addition, the\nexperimental results of the new untrained signal types show that our method can\nadapt to the detection of these new signals. Furthermore, the real-world signal\ndetection experiment results show that the detection performance can be further\nimproved by transfer learning. Finally, experiments under colored noise show\nthat our proposed method has superior detection performance under colored\nnoise, while the traditional methods have a significant performance\ndegradation, which further validate the superiority of our method.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 03:47:19 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Zheng", "Shilian", ""], ["Chen", "Shichuan", ""], ["Qi", "Peihan", ""], ["Zhou", "Huaji", ""], ["Yang", "Xiaoniu", ""]]}, {"id": "1909.06030", "submitter": "Xiaoyang Huang", "authors": "Xiaoyang Huang and Jiancheng Yang and Linguo Li and Haoran Deng and\n  Bingbing Ni and Yi Xu", "title": "Evaluating and Boosting Uncertainty Quantification in Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergence of artificial intelligence techniques in biomedical applications\nurges the researchers to pay more attention on the uncertainty quantification\n(UQ) in machine-assisted medical decision making. For classification tasks,\nprior studies on UQ are difficult to compare with each other, due to the lack\nof a unified quantitative evaluation metric. Considering that well-performing\nUQ models ought to know when the classification models act incorrectly, we\ndesign a new evaluation metric, area under Confidence-Classification\nCharacteristic curves (AUCCC), to quantitatively evaluate the performance of\nthe UQ models. AUCCC is threshold-free, robust to perturbation, and insensitive\nto the classification performance. We evaluate several UQ methods (e.g., max\nsoftmax output) with AUCCC to validate its effectiveness. Furthermore, a simple\nscheme, named Uncertainty Distillation (UDist), is developed to boost the UQ\nperformance, where a confidence model is distilling the confidence estimated by\ndeep ensembles. The proposed method is easy to implement; it consistently\noutperforms strong baselines on natural and medical image datasets in our\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 04:37:39 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 09:34:49 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Huang", "Xiaoyang", ""], ["Yang", "Jiancheng", ""], ["Li", "Linguo", ""], ["Deng", "Haoran", ""], ["Ni", "Bingbing", ""], ["Xu", "Yi", ""]]}, {"id": "1909.06034", "submitter": "Tamir Blum", "authors": "Tamir Blum, William Jones and Kazuya Yoshida", "title": "Deep Learned Path Planning via Randomized Reward-Linked-Goals and\n  Potential Space Applications", "comments": "8 pages, 3 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space exploration missions have seen use of increasingly sophisticated\nrobotic systems with ever more autonomy. Deep learning promises to take this\neven a step further, and has applications for high-level tasks, like path\nplanning, as well as low-level tasks, like motion control, which are critical\ncomponents for mission efficiency and success. Using deep reinforcement\nend-to-end learning with randomized reward function parameters during training,\nwe teach a simulated 8 degree-of-freedom quadruped ant-like robot to travel\nanywhere within a perimeter, conducting path plan and motion control on a\nsingle neural network, without any system model or prior knowledge of the\nterrain or environment. Our approach also allows for user specified waypoints,\nwhich could translate well to either fully autonomous or\nsemi-autonomous/teleoperated space applications that encounter delay times. We\ntrained the agent using randomly generated waypoints linked to the reward\nfunction and passed waypoint coordinates as inputs to the neural network. Such\napplications show promise on a variety of space exploration robots, including\nhigh speed rovers for fast locomotion and legged cave robots for rough terrain.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 04:58:52 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Blum", "Tamir", ""], ["Jones", "William", ""], ["Yoshida", "Kazuya", ""]]}, {"id": "1909.06035", "submitter": "Jiacheng Sun", "authors": "Hanwen Liang, Shifeng Zhang, Jiacheng Sun, Xingqiu He, Weiran Huang,\n  Kechen Zhuang, Zhenguo Li", "title": "DARTS+: Improved Differentiable Architecture Search with Early Stopping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a growing interest in automating the process of\nneural architecture design, and the Differentiable Architecture Search (DARTS)\nmethod makes the process available within a few GPU days. However, the\nperformance of DARTS is often observed to collapse when the number of search\nepochs becomes large. Meanwhile, lots of \"{\\em skip-connect}s\" are found in the\nselected architectures. In this paper, we claim that the cause of the collapse\nis that there exists overfitting in the optimization of DARTS. Therefore, we\npropose a simple and effective algorithm, named \"DARTS+\", to avoid the collapse\nand improve the original DARTS, by \"early stopping\" the search procedure when\nmeeting a certain criterion. We also conduct comprehensive experiments on\nbenchmark datasets and different search spaces and show the effectiveness of\nour DARTS+ algorithm, and DARTS+ achieves $2.32\\%$ test error on CIFAR10,\n$14.87\\%$ on CIFAR100, and $23.7\\%$ on ImageNet. We further remark that the\nidea of \"early stopping\" is implicitly included in some existing DARTS variants\nby manually setting a small number of search epochs, while we give an {\\em\nexplicit} criterion for \"early stopping\".\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:07:57 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 06:21:28 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Liang", "Hanwen", ""], ["Zhang", "Shifeng", ""], ["Sun", "Jiacheng", ""], ["He", "Xingqiu", ""], ["Huang", "Weiran", ""], ["Zhuang", "Kechen", ""], ["Li", "Zhenguo", ""]]}, {"id": "1909.06039", "submitter": "Neil G. Marchant", "authors": "Neil G. Marchant, Andee Kaplan, Daniel N. Elazar, Benjamin I. P.\n  Rubinstein, Rebecca C. Steorts", "title": "d-blink: Distributed End-to-End Bayesian Entity Resolution", "comments": "32 pages, 6 figures, 5 tables. Includes 22 pages of supplementary\n  material. This revision incorporates a case study on the 2010 U.S. Decennial\n  Census", "journal-ref": null, "doi": "10.1080/10618600.2020.1825451", "report-no": null, "categories": "stat.CO cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity resolution (ER; also known as record linkage or de-duplication) is the\nprocess of merging noisy databases, often in the absence of unique identifiers.\nA major advancement in ER methodology has been the application of Bayesian\ngenerative models, which provide a natural framework for inferring latent\nentities with rigorous quantification of uncertainty. Despite these advantages,\nexisting models are severely limited in practice, as standard inference\nalgorithms scale quadratically in the number of records. While scaling can be\nmanaged by fitting the model on separate blocks of the data, such a na\\\"ive\napproach may induce significant error in the posterior. In this paper, we\npropose a principled model for scalable Bayesian ER, called \"distributed\nBayesian linkage\" or d-blink, which jointly performs blocking and ER without\ncompromising posterior correctness. Our approach relies on several key ideas,\nincluding: (i) an auxiliary variable representation that induces a partition of\nthe entities and records into blocks; (ii) a method for constructing\nwell-balanced blocks based on k-d trees; (iii) a distributed\npartially-collapsed Gibbs sampler with improved mixing; and (iv) fast\nalgorithms for performing Gibbs updates. Empirical studies on six data\nsets---including a case study on the 2010 Decennial Census---demonstrate the\nscalability and effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:28:37 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 00:58:17 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 13:42:27 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Marchant", "Neil G.", ""], ["Kaplan", "Andee", ""], ["Elazar", "Daniel N.", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Steorts", "Rebecca C.", ""]]}, {"id": "1909.06040", "submitter": "Yanghua Peng", "authors": "Yanghua Peng, Yixin Bao, Yangrui Chen, Chuan Wu, Chen Meng, Wei Lin", "title": "DL2: A Deep Learning-driven Scheduler for Deep Learning Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more companies have deployed machine learning (ML) clusters, where\ndeep learning (DL) models are trained for providing various AI-driven services.\nEfficient resource scheduling is essential for maximal utilization of expensive\nDL clusters. Existing cluster schedulers either are agnostic to ML workload\ncharacteristics, or use scheduling heuristics based on operators' understanding\nof particular ML framework and workload, which are less efficient or not\ngeneral enough. In this paper, we show that DL techniques can be adopted to\ndesign a generic and efficient scheduler. DL2 is a DL-driven scheduler for DL\nclusters, targeting global training job expedition by dynamically resizing\nresources allocated to jobs. DL2 advocates a joint supervised learning and\nreinforcement learning approach: a neural network is warmed up via offline\nsupervised learning based on job traces produced by the existing cluster\nscheduler; then the neural network is plugged into the live DL cluster,\nfine-tuned by reinforcement learning carried out throughout the training\nprogress of the DL jobs, and used for deciding job resource allocation in an\nonline fashion. By applying past decisions made by the existing cluster\nscheduler in the preparatory supervised learning phase, our approach enables a\nsmooth transition from existing scheduler, and renders a high-quality scheduler\nin minimizing average training completion time. We implement DL2 on Kubernetes\nand enable dynamic resource scaling in DL jobs on MXNet. Extensive evaluation\nshows that DL2 outperforms fairness scheduler (i.e., DRF) by 44.1% and expert\nheuristic scheduler (i.e., Optimus) by 17.5% in terms of average job completion\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:30:11 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Peng", "Yanghua", ""], ["Bao", "Yixin", ""], ["Chen", "Yangrui", ""], ["Wu", "Chuan", ""], ["Meng", "Chen", ""], ["Lin", "Wei", ""]]}, {"id": "1909.06041", "submitter": "Neema Kachappilly Davis", "authors": "Neema Davis, Gaurav Raina, Krishna Jagannathan", "title": "LSTM-Based Anomaly Detection: Detection Rules from Extreme Value Theory", "comments": "Proceedings of the EPIA Conference on Artificial Intelligence 2019.\n  The final publication is available at Springer via\n  https://doi.org/10.1007/978-3-030-30241-2_48", "journal-ref": null, "doi": "10.1007/978-3-030-30241-2_48", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore various statistical techniques for anomaly\ndetection in conjunction with the popular Long Short-Term Memory (LSTM) deep\nlearning model for transportation networks. We obtain the prediction errors\nfrom an LSTM model, and then apply three statistical models based on (i) the\nGaussian distribution, (ii) Extreme Value Theory (EVT), and (iii) the Tukey's\nmethod. Using statistical tests and numerical studies, we find strong evidence\nagainst the widely employed Gaussian distribution based detection rule on the\nprediction errors. Next, motivated by fundamental results from Extreme Value\nTheory, we propose a detection technique that does not assume any parent\ndistribution on the prediction errors. Through numerical experiments conducted\non several real-world traffic data sets, we show that the EVT-based detection\nrule is superior to other detection rules, and is supported by statistical\nevidence.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:31:07 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Davis", "Neema", ""], ["Raina", "Gaurav", ""], ["Jagannathan", "Krishna", ""]]}, {"id": "1909.06044", "submitter": "Haochen Liu", "authors": "Haochen Liu, Tyler Derr, Zitao Liu and Jiliang Tang", "title": "Say What I Want: Towards the Dark Side of Neural Dialogue Models", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dialogue models have been widely adopted in various chatbot\napplications because of their good performance in simulating and generalizing\nhuman conversations. However, there exists a dark side of these models -- due\nto the vulnerability of neural networks, a neural dialogue model can be\nmanipulated by users to say what they want, which brings in concerns about the\nsecurity of practical chatbot services. In this work, we investigate whether we\ncan craft inputs that lead a well-trained black-box neural dialogue model to\ngenerate targeted outputs. We formulate this as a reinforcement learning (RL)\nproblem and train a Reverse Dialogue Generator which efficiently finds such\ninputs for targeted outputs. Experiments conducted on a representative neural\ndialogue model show that our proposed model is able to discover such desired\ninputs in a considerable portion of cases. Overall, our work reveals this\nweakness of neural dialogue models and may prompt further researches of\ndeveloping corresponding solutions to avoid it.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:50:50 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 16:12:10 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 00:43:28 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Liu", "Haochen", ""], ["Derr", "Tyler", ""], ["Liu", "Zitao", ""], ["Tang", "Jiliang", ""]]}, {"id": "1909.06058", "submitter": "Mengdi Zhu", "authors": "Mengdi Zhu, Zheye Deng, Wenhan Xiong, Mo Yu, Ming Zhang, William Yang\n  Wang", "title": "Neural Correction Model for Open-Domain Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) plays an important role in a wide range of\nnatural language processing tasks, such as relation extraction, question\nanswering, etc. However, previous studies on NER are limited to particular\ngenres, using small manually-annotated or large but low-quality datasets.\nMeanwhile, previous datasets for open-domain NER, built using distant\nsupervision, suffer from low precision, recall and ratio of annotated tokens\n(RAT). In this work, to address the low precision and recall problems, we first\nutilize DBpedia as the source of distant supervision to annotate abstracts from\nWikipedia and design a neural correction model trained with a human-annotated\nNER dataset, DocRED, to correct the false entity labels. In this way, we build\na large and high-quality dataset called AnchorNER and then train various models\nwith it. To address the low RAT problem of previous datasets, we introduce a\nmulti-task learning method to exploit the context information. We evaluate our\nmethods on five NER datasets and our experimental results show that models\ntrained with AnchorNER and our multi-task learning method obtain\nstate-of-the-art performances in the open-domain setting.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 06:44:30 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 10:14:01 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhu", "Mengdi", ""], ["Deng", "Zheye", ""], ["Xiong", "Wenhan", ""], ["Yu", "Mo", ""], ["Zhang", "Ming", ""], ["Wang", "William Yang", ""]]}, {"id": "1909.06064", "submitter": "Yu Inatsu", "authors": "Yu Inatsu, Masayuki Karasuyama, Keiichi Inoue, Ichiro Takeuchi", "title": "Active learning for level set estimation under cost-dependent input\n  uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of a quality control process in manufacturing it is often necessary\nto test whether all parts of a product satisfy a required property, with as few\ninspections as possible. When multiple inspection apparatuses with different\ncosts and precision exist, it is desirable that testing can be carried out\ncost-effectively by properly controlling the trade-off between the costs and\nthe precision. In this paper, we formulate this as a level set estimation (LSE)\nproblem under cost-dependent input uncertainty - LSE being a type of active\nlearning for estimating the level set, i.e., the subset of the input space in\nwhich an unknown function value is greater or smaller than a pre-determined\nthreshold. Then, we propose a new algorithm for LSE under cost-dependent input\nuncertainty with theoretical convergence guarantee. We demonstrate the\neffectiveness of the proposed algorithm by applying it to synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 07:11:12 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Inatsu", "Yu", ""], ["Karasuyama", "Masayuki", ""], ["Inoue", "Keiichi", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1909.06091", "submitter": "Alham Fikri Aji", "authors": "Alham Fikri Aji, Kenneth Heafield", "title": "Neural Machine Translation with 4-Bit Precision and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) is resource intensive. We design a\nquantization procedure to compress NMT models better for devices with limited\nhardware capability. Because most neural network parameters are near zero, we\nemploy logarithmic quantization in lieu of fixed-point quantization. However,\nwe find bias terms are less amenable to log quantization but note they comprise\na tiny fraction of the model, so we leave them uncompressed. We also propose to\nuse an error-feedback mechanism during retraining, to preserve the compressed\nmodel as a stale gradient. We empirically show that NMT models based on\nTransformer or RNN architecture can be compressed up to 4-bit precision without\nany noticeable quality degradation. Models can be compressed up to binary\nprecision, albeit with lower quality. The RNN architecture seems to be more\nrobust to quantization, compared to the Transformer.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 08:55:08 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 17:26:10 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Aji", "Alham Fikri", ""], ["Heafield", "Kenneth", ""]]}, {"id": "1909.06108", "submitter": "Nikita Kozodoi", "authors": "Nikita Kozodoi, Panagiotis Katsas, Stefan Lessmann, Luis\n  Moreira-Matias, Konstantinos Papakonstantinou", "title": "Shallow Self-Learning for Reject Inference in Credit Scoring", "comments": "Preprint of the paper accepted to ECML PKDD 2019", "journal-ref": "ECML PKDD 2019. Lecture Notes in Computer Science, vol 11908.\n  Springer, Cham", "doi": "10.1007/978-3-030-46133-1_31", "report-no": null, "categories": "stat.ML cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit scoring models support loan approval decisions in the financial\nservices industry. Lenders train these models on data from previously granted\ncredit applications, where the borrowers' repayment behavior has been observed.\nThis approach creates sample bias. The scoring model (i.e., classifier) is\ntrained on accepted cases only. Applying the resulting model to screen credit\napplications from the population of all borrowers degrades model performance.\nReject inference comprises techniques to overcome sampling bias through\nassigning labels to rejected cases. The paper makes two contributions. First,\nwe propose a self-learning framework for reject inference. The framework is\ngeared toward real-world credit scoring requirements through considering\ndistinct training regimes for iterative labeling and model training. Second, we\nintroduce a new measure to assess the effectiveness of reject inference\nstrategies. Our measure leverages domain knowledge to avoid artificial labeling\nof rejected cases during strategy evaluation. We demonstrate this approach to\noffer a robust and operational assessment of reject inference strategies.\nExperiments on a real-world credit scoring data set confirm the superiority of\nthe adjusted self-learning framework over regular self-learning and previous\nreject inference strategies. We also find strong evidence in favor of the\nproposed evaluation measure assessing reject inference strategies more\nreliably, raising the performance of the eventual credit scoring model.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 09:37:24 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Kozodoi", "Nikita", ""], ["Katsas", "Panagiotis", ""], ["Lessmann", "Stefan", ""], ["Moreira-Matias", "Luis", ""], ["Papakonstantinou", "Konstantinos", ""]]}, {"id": "1909.06122", "submitter": "Run Wang", "authors": "Run Wang, Felix Juefei-Xu, Lei Ma, Xiaofei Xie, Yihao Huang, Jian\n  Wang, Yang Liu", "title": "FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized\n  Fake Faces", "comments": "Accepted to IJCAI 2020; SOLE copyright holder is IJCAI (international\n  Joint Conferences on Artificial Intelligence), all rights reserved.\n  https://www.ijcai.org/Proceedings/2020/333", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, generative adversarial networks (GANs) and its variants have\nachieved unprecedented success in image synthesis. They are widely adopted in\nsynthesizing facial images which brings potential security concerns to humans\nas the fakes spread and fuel the misinformation. However, robust detectors of\nthese AI-synthesized fake faces are still in their infancy and are not ready to\nfully tackle this emerging challenge. In this work, we propose a novel\napproach, named FakeSpotter, based on monitoring neuron behaviors to spot\nAI-synthesized fake faces. The studies on neuron coverage and interactions have\nsuccessfully shown that they can be served as testing criteria for deep\nlearning systems, especially under the settings of being exposed to adversarial\nattacks. Here, we conjecture that monitoring neuron behavior can also serve as\nan asset in detecting fake faces since layer-by-layer neuron activation\npatterns may capture more subtle features that are important for the fake\ndetector. Experimental results on detecting four types of fake faces\nsynthesized with the state-of-the-art GANs and evading four perturbation\nattacks show the effectiveness and robustness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 10:08:44 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 06:02:29 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 06:44:53 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Wang", "Run", ""], ["Juefei-Xu", "Felix", ""], ["Ma", "Lei", ""], ["Xie", "Xiaofei", ""], ["Huang", "Yihao", ""], ["Wang", "Jian", ""], ["Liu", "Yang", ""]]}, {"id": "1909.06134", "submitter": "Yuming Huang", "authors": "Yuming Huang, Ashkan Panahi, Hamid Krim, Yiyi Yu, Spencer L. Smith", "title": "Deep Adversarial Belief Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel adversarial framework for training deep belief networks\n(DBNs), which includes replacing the generator network in the methodology of\ngenerative adversarial networks (GANs) with a DBN and developing a highly\nparallelizable numerical algorithm for training the resulting architecture in a\nstochastic manner. Unlike the existing techniques, this framework can be\napplied to the most general form of DBNs with no requirement for back\npropagation. As such, it lays a new foundation for developing DBNs on a par\nwith GANs with various regularization units, such as pooling and normalization.\nForegoing back-propagation, our framework also exhibits superior scalability as\ncompared to other DBN and GAN learning techniques. We present a number of\nnumerical experiments in computer vision as well as neurosciences to illustrate\nthe main advantages of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 10:53:48 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 14:01:48 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Huang", "Yuming", ""], ["Panahi", "Ashkan", ""], ["Krim", "Hamid", ""], ["Yu", "Yiyi", ""], ["Smith", "Spencer L.", ""]]}, {"id": "1909.06137", "submitter": "Chaomin Shen", "authors": "Chaomin Shen, Yaxin Peng, Guixu Zhang, Jinsong Fan", "title": "Defending Against Adversarial Attacks by Suppressing the Largest\n  Eigenvalue of Fisher Information Matrix", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scheme for defending against adversarial attacks by suppressing\nthe largest eigenvalue of the Fisher information matrix (FIM). Our starting\npoint is one explanation on the rationale of adversarial examples. Based on the\nidea of the difference between a benign sample and its adversarial example is\nmeasured by the Euclidean norm, while the difference between their\nclassification probability densities at the last (softmax) layer of the network\ncould be measured by the Kullback-Leibler (KL) divergence, the explanation\nshows that the output difference is a quadratic form of the input difference.\nIf the eigenvalue of this quadratic form (a.k.a. FIM) is large, the output\ndifference becomes large even when the input difference is small, which\nexplains the adversarial phenomenon. This makes the adversarial defense\npossible by controlling the eigenvalues of the FIM. Our solution is adding one\nterm representing the trace of the FIM to the loss function of the original\nnetwork, as the largest eigenvalue is bounded by the trace. Our defensive\nscheme is verified by experiments using a variety of common attacking methods\non typical deep neural networks, e.g. LeNet, VGG and ResNet, with datasets\nMNIST, CIFAR-10, and German Traffic Sign Recognition Benchmark (GTSRB). Our new\nnetwork, after adopting the novel loss function and retraining, has an\neffective and robust defensive capability, as it decreases the fooling ratio of\nthe generated adversarial examples, and remains the classification accuracy of\nthe original network.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 11:00:48 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Shen", "Chaomin", ""], ["Peng", "Yaxin", ""], ["Zhang", "Guixu", ""], ["Fan", "Jinsong", ""]]}, {"id": "1909.06143", "submitter": "Yadong Li", "authors": "Yadong Li and Xin Cui", "title": "Shapley Interpretation and Activation in Neural Networks", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Shapley value approach to help address neural networks'\ninterpretability and \"vanishing gradient\" problems. Our method is based on an\naccurate analytical approximation to the Shapley value of a neuron with ReLU\nactivation. This analytical approximation admits a linear propagation of\nrelevance across neural network layers, resulting in a simple, fast and\nsensible interpretation of neural networks' decision making process.\n  We then derived a globally continuous and non-vanishing Shapley gradient,\nwhich can replace the conventional gradient in training neural network layers\nwith ReLU activation, and leading to better training performance. We further\nderived a Shapley Activation (SA) function, which is a close approximation to\nReLU but features the Shapley gradient. The SA is easy to implement in existing\nmachine learning frameworks. Numerical tests show that SA consistently\noutperforms ReLU in training convergence, accuracy and stability.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 11:13:27 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 00:26:36 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Li", "Yadong", ""], ["Cui", "Xin", ""]]}, {"id": "1909.06146", "submitter": "Qiao Jin", "authors": "Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W. Cohen, Xinghua Lu", "title": "PubMedQA: A Dataset for Biomedical Research Question Answering", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PubMedQA, a novel biomedical question answering (QA) dataset\ncollected from PubMed abstracts. The task of PubMedQA is to answer research\nquestions with yes/no/maybe (e.g.: Do preoperative statins reduce atrial\nfibrillation after coronary artery bypass grafting?) using the corresponding\nabstracts. PubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k\nartificially generated QA instances. Each PubMedQA instance is composed of (1)\na question which is either an existing research article title or derived from\none, (2) a context which is the corresponding abstract without its conclusion,\n(3) a long answer, which is the conclusion of the abstract and, presumably,\nanswers the research question, and (4) a yes/no/maybe answer which summarizes\nthe conclusion. PubMedQA is the first QA dataset where reasoning over\nbiomedical research texts, especially their quantitative contents, is required\nto answer the questions. Our best performing model, multi-phase fine-tuning of\nBioBERT with long answer bag-of-word statistics as additional supervision,\nachieves 68.1% accuracy, compared to single human performance of 78.0% accuracy\nand majority-baseline of 55.2% accuracy, leaving much room for improvement.\nPubMedQA is publicly available at https://pubmedqa.github.io.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 11:18:20 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Jin", "Qiao", ""], ["Dhingra", "Bhuwan", ""], ["Liu", "Zhengping", ""], ["Cohen", "William W.", ""], ["Lu", "Xinghua", ""]]}, {"id": "1909.06153", "submitter": "Michael Lutter", "authors": "Michael Lutter, Boris Belousov, Kim Listmann, Debora Clever, Jan\n  Peters", "title": "HJB Optimal Feedback Control with Deep Differential Value Functions and\n  Action Constraints", "comments": "Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning optimal feedback control laws capable of executing optimal\ntrajectories is essential for many robotic applications. Such policies can be\nlearned using reinforcement learning or planned using optimal control. While\nreinforcement learning is sample inefficient, optimal control only plans an\noptimal trajectory from a specific starting configuration. In this paper we\npropose deep optimal feedback control to learn an optimal feedback policy\nrather than a single trajectory. By exploiting the inherent structure of the\nrobot dynamics and strictly convex action cost, we can derive principled cost\nfunctions such that the optimal policy naturally obeys the action limits, is\nglobally optimal and stable on the training domain given the optimal value\nfunction. The corresponding optimal value function is learned end-to-end by\nembedding a deep differential network in the Hamilton-Jacobi-Bellmann\ndifferential equation and minimizing the error of this equality while\nsimultaneously decreasing the discounting from short- to far-sighted to enable\nthe learning. Our proposed approach enables us to learn an optimal feedback\ncontrol law in continuous time, that in contrast to existing approaches\ngenerates an optimal trajectory from any point in state-space without the need\nof replanning. The resulting approach is evaluated on non-linear systems and\nachieves optimal feedback control, where standard optimal control methods\nrequire frequent replanning.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 11:34:40 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 07:21:39 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Lutter", "Michael", ""], ["Belousov", "Boris", ""], ["Listmann", "Kim", ""], ["Clever", "Debora", ""], ["Peters", "Jan", ""]]}, {"id": "1909.06161", "submitter": "Jonas Kubilius", "authors": "Jonas Kubilius, Martin Schrimpf, Kohitij Kar, Ha Hong, Najib J. Majaj,\n  Rishi Rajalingham, Elias B. Issa, Pouya Bashivan, Jonathan Prescott-Roy,\n  Kailyn Schmidt, Aran Nayebi, Daniel Bear, Daniel L. K. Yamins, and James J.\n  DiCarlo", "title": "Brain-Like Object Recognition with High-Performing Shallow Recurrent\n  ANNs", "comments": "NeurIPS 2019 (Oral). Code available at\n  https://github.com/dicarlolab/neurips2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional artificial neural networks (ANNs) are the leading class of\ncandidate models of the mechanisms of visual processing in the primate ventral\nstream. While initially inspired by brain anatomy, over the past years, these\nANNs have evolved from a simple eight-layer architecture in AlexNet to\nextremely deep and branching architectures, demonstrating increasingly better\nobject categorization performance, yet bringing into question how brain-like\nthey still are. In particular, typical deep models from the machine learning\ncommunity are often hard to map onto the brain's anatomy due to their vast\nnumber of layers and missing biologically-important connections, such as\nrecurrence. Here we demonstrate that better anatomical alignment to the brain\nand high performance on machine learning as well as neuroscience measures do\nnot have to be in contradiction. We developed CORnet-S, a shallow ANN with four\nanatomically mapped areas and recurrent connectivity, guided by Brain-Score, a\nnew large-scale composite of neural and behavioral benchmarks for quantifying\nthe functional fidelity of models of the primate ventral visual stream. Despite\nbeing significantly shallower than most models, CORnet-S is the top model on\nBrain-Score and outperforms similarly compact models on ImageNet. Moreover, our\nextensive analyses of CORnet-S circuitry variants reveal that recurrence is the\nmain predictive factor of both Brain-Score and ImageNet top-1 performance.\nFinally, we report that the temporal evolution of the CORnet-S \"IT\" neural\npopulation resembles the actual monkey IT population dynamics. Taken together,\nthese results establish CORnet-S, a compact, recurrent ANN, as the current best\nmodel of the primate ventral visual stream.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 12:09:34 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 07:30:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kubilius", "Jonas", ""], ["Schrimpf", "Martin", ""], ["Kar", "Kohitij", ""], ["Hong", "Ha", ""], ["Majaj", "Najib J.", ""], ["Rajalingham", "Rishi", ""], ["Issa", "Elias B.", ""], ["Bashivan", "Pouya", ""], ["Prescott-Roy", "Jonathan", ""], ["Schmidt", "Kailyn", ""], ["Nayebi", "Aran", ""], ["Bear", "Daniel", ""], ["Yamins", "Daniel L. K.", ""], ["DiCarlo", "James J.", ""]]}, {"id": "1909.06162", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta, Khushbu Saxena, Usama Yaseen, Thomas Runkler, Hinrich\n  Sch\\\"utze", "title": "Neural Architectures for Fine-Grained Propaganda Detection in News", "comments": "EMNLP2019: Fine-grained propaganda detection shared task at NLP4IF\n  workshop (EMNLP2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our system (MIC-CIS) details and results of\nparticipation in the fine-grained propaganda detection shared task 2019. To\naddress the tasks of sentence (SLC) and fragment level (FLC) propaganda\ndetection, we explore different neural architectures (e.g., CNN, LSTM-CRF and\nBERT) and extract linguistic (e.g., part-of-speech, named entity, readability,\nsentiment, emotion, etc.), layout and topical features. Specifically, we have\ndesigned multi-granularity and multi-tasking neural architectures to jointly\nperform both the sentence and fragment level propaganda detection.\nAdditionally, we investigate different ensemble schemes such as\nmajority-voting, relax-voting, etc. to boost overall system performance.\nCompared to the other participating systems, our submissions are ranked 3rd and\n4th in FLC and SLC tasks, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 12:11:47 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Gupta", "Pankaj", ""], ["Saxena", "Khushbu", ""], ["Yaseen", "Usama", ""], ["Runkler", "Thomas", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1909.06175", "submitter": "Markus Roland Ernst", "authors": "Markus Roland Ernst, Jochen Triesch and Thomas Burwick", "title": "Recurrent Connectivity Aids Recognition of Partly Occluded Objects", "comments": "9 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1907.08831", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedforward convolutional neural networks are the prevalent model of core\nobject recognition. For challenging conditions, such as occlusion,\nneuroscientists believe that the recurrent connectivity in the visual cortex\naids object recognition. In this work we investigate if and how artificial\nneural networks can also benefit from recurrent connectivity. For this we\nsystematically compare architectures comprised of bottom-up (B), lateral (L)\nand top-down (T) connections. To evaluate performance, we introduce two novel\nstereoscopic occluded object datasets, which bridge the gap from classifying\ndigits to recognizing 3D objects. The task consists of recognizing one target\nobject occluded by multiple occluder objects. We find that recurrent models\nperform significantly better than their feedforward counterparts, which were\nmatched in parametric complexity. We show that for challenging stimuli, the\nrecurrent feedback is able to correctly revise the initial feedforward guess of\nthe network. Overall, our results suggest that both artificial and biological\nneural networks can exploit recurrence for improved object recognition.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:42:34 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Ernst", "Markus Roland", ""], ["Triesch", "Jochen", ""], ["Burwick", "Thomas", ""]]}, {"id": "1909.06178", "submitter": "Liwei Lin", "authors": "Liwei Lin, Xiangdong Wang, Hong Liu and Yueliang Qian", "title": "Guided Learning Convolution System for DCASE 2019 Task 4", "comments": "Accept by DCASE2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe in detail the system we submitted to DCASE2019\ntask 4: sound event detection (SED) in domestic environments. We employ a\nconvolutional neural network (CNN) with an embedding-level attention pooling\nmodule to solve it. By considering the interference caused by the co-occurrence\nof multiple events in the unbalanced dataset, we utilize the disentangled\nfeature to raise the performance of the model. To take advantage of the\nunlabeled data, we adopt Guided Learning for semi-supervised learning. A group\nof median filters with adaptive window sizes is utilized in the post-processing\nof output probabilities of the model. We also analyze the effect of the\nsynthetic data on the performance of the model and finally achieve an\nevent-based F-measure of 45.43% on the validation set and an event-based\nF-measure of 42.7% on the test set. The system we submitted to the challenge\nachieves the best performance compared to those of other participates.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 03:42:45 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Lin", "Liwei", ""], ["Wang", "Xiangdong", ""], ["Liu", "Hong", ""], ["Qian", "Yueliang", ""]]}, {"id": "1909.06179", "submitter": "Sunil Pai", "authors": "Sunil Pai, Ian A. D. Williamson, Tyler W. Hughes, Momchil Minkov, Olav\n  Solgaard, Shanhui Fan, David A. B. Miller", "title": "Parallel fault-tolerant programming of an arbitrary feedforward photonic\n  network", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconfigurable photonic mesh networks of tunable beamsplitter nodes can\nlinearly transform $N$-dimensional vectors representing input modal amplitudes\nof light for applications such as energy-efficient machine learning hardware,\nquantum information processing, and mode demultiplexing. Such photonic meshes\nare typically programmed and/or calibrated by tuning or characterizing each\nbeam splitter one-by-one, which can be time-consuming and can limit scaling to\nlarger meshes. Here we introduce a graph-topological approach that defines the\ngeneral class of feedforward networks commonly used in such applications and\nidentifies columns of non-interacting nodes that can be adjusted\nsimultaneously. By virtue of this approach, we can calculate the necessary\ninput vectors to program entire columns of nodes in parallel by simultaneously\nnullifying the power in one output of each node via optoelectronic feedback\nonto adjustable phase shifters or couplers. This parallel nullification\napproach is fault-tolerant to fabrication errors, requiring no prior knowledge\nor calibration of the node parameters, and can reduce the programming time by a\nfactor of order $N$ to being proportional to the optical depth (or number of\nnode columns in the device). As a demonstration, we simulate our programming\nprotocol on a feedforward optical neural network model trained to classify\nhandwritten digit images from the MNIST dataset with up to 98% validation\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 22:59:16 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Pai", "Sunil", ""], ["Williamson", "Ian A. D.", ""], ["Hughes", "Tyler W.", ""], ["Minkov", "Momchil", ""], ["Solgaard", "Olav", ""], ["Fan", "Shanhui", ""], ["Miller", "David A. B.", ""]]}, {"id": "1909.06194", "submitter": "Fereshteh Jafariakinabad", "authors": "Fereshteh Jafariakinabad, Kien A. Hua", "title": "Style-aware Neural Model with Application in Authorship Attribution", "comments": "arXiv admin note: text overlap with arXiv:1902.09723", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing style is a combination of consistent decisions associated with a\nspecific author at different levels of language production, including lexical,\nsyntactic, and structural. In this paper, we introduce a style-aware neural\nmodel to encode document information from three stylistic levels and evaluate\nit in the domain of authorship attribution. First, we propose a simple way to\njointly encode syntactic and lexical representations of sentences.\nSubsequently, we employ an attention-based hierarchical neural network to\nencode the syntactic and semantic structure of sentences in documents while\nrewarding the sentences which contribute more to capturing the writing style.\nOur experimental results, based on four benchmark datasets, reveal the benefits\nof encoding document information from all three stylistic levels when compared\nto the baseline methods in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:25:05 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Jafariakinabad", "Fereshteh", ""], ["Hua", "Kien A.", ""]]}, {"id": "1909.06200", "submitter": "Mengdi Zhu", "authors": "Mengdi Zhu, Zhiwei Yu, Xiaojun Wan", "title": "A Neural Approach to Irony Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ironies can not only express stronger emotions but also show a sense of\nhumor. With the development of social media, ironies are widely used in public.\nAlthough many prior research studies have been conducted in irony detection,\nfew studies focus on irony generation. The main challenges for irony generation\nare the lack of large-scale irony dataset and difficulties in modeling the\nironic pattern. In this work, we first systematically define irony generation\nbased on style transfer task. To address the lack of data, we make use of\ntwitter and build a large-scale dataset. We also design a combination of\nrewards for reinforcement learning to control the generation of ironic\nsentences. Experimental results demonstrate the effectiveness of our model in\nterms of irony accuracy, sentiment preservation, and content preservation.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 13:05:27 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 03:56:02 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Zhu", "Mengdi", ""], ["Yu", "Zhiwei", ""], ["Wan", "Xiaojun", ""]]}, {"id": "1909.06228", "submitter": "S VenkataKeerthy", "authors": "S. VenkataKeerthy, Rohit Aggarwal, Shalini Jain, Maunendra Sankar\n  Desarkar, Ramakrishna Upadrasta and Y. N. Srikant", "title": "IR2Vec: LLVM IR based Scalable Program Embeddings", "comments": "Accepted in ACM TACO", "journal-ref": null, "doi": "10.1145/3418463", "report-no": null, "categories": "cs.PL cs.LG cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose IR2Vec, a Concise and Scalable encoding infrastructure to\nrepresent programs as a distributed embedding in continuous space. This\ndistributed embedding is obtained by combining representation learning methods\nwith flow information to capture the syntax as well as the semantics of the\ninput programs. As our infrastructure is based on the Intermediate\nRepresentation (IR) of the source code, obtained embeddings are both language\nand machine independent. The entities of the IR are modeled as relationships,\nand their representations are learned to form a seed embedding vocabulary.\nUsing this infrastructure, we propose two incremental encodings:Symbolic and\nFlow-Aware. Symbolic encodings are obtained from the seed embedding vocabulary,\nand Flow-Aware encodings are obtained by augmenting the Symbolic encodings with\nthe flow information.\n  We show the effectiveness of our methodology on two optimization tasks\n(Heterogeneous device mapping and Thread coarsening). Our way of representing\nthe programs enables us to use non-sequential models resulting in orders of\nmagnitude of faster training time. Both the encodings generated by IR2Vec\noutperform the existing methods in both the tasks, even while using simple\nmachine learning models. In particular, our results improve or match the\nstate-of-the-art speedup in 11/14 benchmark-suites in the device mapping task\nacross two platforms and 53/68 benchmarks in the Thread coarsening task across\nfour different platforms. When compared to the other methods, our embeddings\nare more scalable, is non-data-hungry, and has betterOut-Of-Vocabulary (OOV)\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 13:41:40 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 06:22:25 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 09:24:01 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["VenkataKeerthy", "S.", ""], ["Aggarwal", "Rohit", ""], ["Jain", "Shalini", ""], ["Desarkar", "Maunendra Sankar", ""], ["Upadrasta", "Ramakrishna", ""], ["Srikant", "Y. N.", ""]]}, {"id": "1909.06236", "submitter": "Sohrab Ferdowsi", "authors": "Sohrab Ferdowsi, Maurits Diephuis, Shideh Rezaeifar, Slava\n  Voloshynovskiy", "title": "$\\rho$-VAE: Autoregressive parametrization of the VAE encoder", "comments": "Submitted to NeurIPS workshop on Bayesian deep learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make a minimal, but very effective alteration to the VAE model. This is\nabout a drop-in replacement for the (sample-dependent) approximate posterior to\nchange it from the standard white Gaussian with diagonal covariance to the\nfirst-order autoregressive Gaussian. We argue that this is a more reasonable\nchoice to adopt for natural signals like images, as it does not force the\nexisting correlation in the data to disappear in the posterior. Moreover, it\nallows more freedom for the approximate posterior to match the true posterior.\nThis allows for the repararametrization trick, as well as the KL-divergence\nterm to still have closed-form expressions, obviating the need for its\nsample-based estimation. Although providing more freedom to adapt to correlated\ndistributions, our parametrization has even less number of parameters than the\ndiagonal covariance, as it requires only two scalars, $\\rho$ and $s$, to\ncharacterize correlation and scaling, respectively. As validated by the\nexperiments, our proposition noticeably and consistently improves the quality\nof image generation in a plug-and-play manner, needing no further parameter\ntuning, and across all setups. The code to reproduce our experiments is\navailable at \\url{https://github.com/sssohrab/rho_VAE/}.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:01:33 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Ferdowsi", "Sohrab", ""], ["Diephuis", "Maurits", ""], ["Rezaeifar", "Shideh", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1909.06238", "submitter": "Masakiyo Kitazawa", "authors": "Takuya Matsumoto, Masakiyo Kitazawa, Yasuhiro Kohno", "title": "Classifying Topological Charge in SU(3) Yang-Mills Theory with Machine\n  Learning", "comments": "28 pages, 12 figures, version to appear in PTEP", "journal-ref": null, "doi": null, "report-no": "J-PARC-TH-0170", "categories": "hep-lat cs.CV cs.LG hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply a machine learning technique for identifying the topological charge\nof quantum gauge configurations in four-dimensional SU(3) Yang-Mills theory.\nThe topological charge density measured on the original and smoothed gauge\nconfigurations with and without dimensional reduction is used as inputs for the\nneural networks (NN) with and without convolutional layers. The gradient flow\nis used for the smoothing of the gauge field. We find that the topological\ncharge determined at a large flow time can be predicted with high accuracy from\nthe data at small flow times by the trained NN; for example, the accuracy\nexceeds $99\\%$ with the data at $t/a^2\\le0.3$. High robustness against the\nchange of simulation parameters is also confirmed with a fixed physical volume.\nWe find that the best performance is obtained when the spatial coordinates of\nthe topological charge density are fully integrated out in preprocessing, which\nimplies that our convolutional NN does not find characteristic structures in\nmulti-dimensional space relevant for the determination of the topological\ncharge.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:02:10 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 12:20:38 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Matsumoto", "Takuya", ""], ["Kitazawa", "Masakiyo", ""], ["Kohno", "Yasuhiro", ""]]}, {"id": "1909.06264", "submitter": "Marcos Bedo", "authors": "Gustavo Blanco, Agma J. M. Traina, Caetano Traina Jr., and Paulo M.\n  Azevedo-Marques, Ana E. S. Jorge, Daniel de Oliveira, and Marcos V. N. Bedo", "title": "A superpixel-driven deep learning approach for the analysis of\n  dermatological wounds", "comments": null, "journal-ref": null, "doi": "10.1016/j.cmpb.2019.105079", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. The image-based identification of distinct tissues within\ndermatological wounds enhances patients' care since it requires no intrusive\nevaluations. This manuscript presents an approach, we named QTDU, that combines\ndeep learning models with superpixel-driven segmentation methods for assessing\nthe quality of tissues from dermatological ulcers.\n  Method. QTDU consists of a three-stage pipeline for the obtaining of ulcer\nsegmentation, tissues' labeling, and wounded area quantification. We set up our\napproach by using a real and annotated set of dermatological ulcers for\ntraining several deep learning models to the identification of ulcered\nsuperpixels.\n  Results. Empirical evaluations on 179,572 superpixels divided into four\nclasses showed QTDU accurately spot wounded tissues (AUC = 0.986, sensitivity =\n0.97, and specificity = 0.974) and outperformed machine-learning approaches in\nup to 8.2% regarding F1-Score through fine-tuning of a ResNet-based model.\nLast, but not least, experimental evaluations also showed QTDU correctly\nquantified wounded tissue areas within a 0.089 Mean Absolute Error ratio.\n  Conclusions. Results indicate QTDU effectiveness for both tissue segmentation\nand wounded area quantification tasks. When compared to existing\nmachine-learning approaches, the combination of superpixels and deep learning\nmodels outperformed the competitors within strong significant levels.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:41:19 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 21:49:54 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Blanco", "Gustavo", ""], ["Traina", "Agma J. M.", ""], ["Traina", "Caetano", "Jr."], ["Azevedo-Marques", "Paulo M.", ""], ["Jorge", "Ana E. S.", ""], ["de Oliveira", "Daniel", ""], ["Bedo", "Marcos V. N.", ""]]}, {"id": "1909.06271", "submitter": "Ziming Zhang", "authors": "Zudi Lin and Hanspeter Pfister and Ziming Zhang", "title": "White-Box Adversarial Defense via Self-Supervised Data Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of how to defend classifiers against\nadversarial attacks that fool the classifiers using subtly modified input data.\nIn contrast to previous works, here we focus on the white-box adversarial\ndefense where the attackers are granted full access to not only the classifiers\nbut also defenders to produce as strong attacks as possible. In such a context\nwe propose viewing a defender as a functional, a higher-order function that\ntakes functions as its argument to represent a function space, rather than\nfixed functions conventionally. From this perspective, a defender should be\nrealized and optimized individually for each adversarial input. To this end, we\npropose RIDE, an efficient and provably convergent self-supervised learning\nalgorithm for individual data estimation to protect the predictions from\nadversarial attacks. We demonstrate the significant improvement of adversarial\ndefense performance on image recognition, eg, 98%, 76%, 43% test accuracy on\nMNIST, CIFAR-10, and ImageNet datasets respectively under the state-of-the-art\nBPDA attacker.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:51:50 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Lin", "Zudi", ""], ["Pfister", "Hanspeter", ""], ["Zhang", "Ziming", ""]]}, {"id": "1909.06273", "submitter": "Martin Andrews", "authors": "Martin Andrews, Yew Ken Chia, Sam Witteveen", "title": "Scene Graph Parsing by Attention Graph", "comments": "Accepted paper for the ViGIL workshop at NeurIPS 2018. (4 pages +\n  references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene graph representations, which form a graph of visual object nodes\ntogether with their attributes and relations, have proved useful across a\nvariety of vision and language applications. Recent work in the area has used\nNatural Language Processing dependency tree methods to automatically build\nscene graphs.\n  In this work, we present an 'Attention Graph' mechanism that can be trained\nend-to-end, and produces a scene graph structure that can be lifted directly\nfrom the top layer of a standard Transformer model.\n  The scene graphs generated by our model achieve an F-score similarity of\n52.21% to ground-truth graphs on the evaluation set using the SPICE metric,\nsurpassing the best previous approaches by 2.5%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:54:37 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Andrews", "Martin", ""], ["Chia", "Yew Ken", ""], ["Witteveen", "Sam", ""]]}, {"id": "1909.06293", "submitter": "Lucas Cassano", "authors": "Lucas Cassano and Ali H. Sayed", "title": "ISL: A novel approach for deep exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we explore an alternative approach to address deep\nexploration and we introduce the ISL algorithm, which is efficient at\nperforming deep exploration. Similarly to maximum entropy RL, we derive the\nalgorithm by augmenting the traditional RL objective with a novel\nregularization term. A distinctive feature of our approach is that, as opposed\nto other works that tackle the problem of deep exploration, in our derivation\nboth the learning equations and the exploration-exploitation strategy are\nderived in tandem as the solution to a well-posed optimization problem whose\nminimization leads to the optimal value function. Empirically we show that our\nmethod exhibits state of the art performance on a range of challenging\ndeep-exploration benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:28:09 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 21:15:14 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 10:12:19 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 15:10:00 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Cassano", "Lucas", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1909.06296", "submitter": "Hunter Gabbard", "authors": "Hunter Gabbard, Chris Messenger, Ik Siong Heng, Francesco Tonolini,\n  Roderick Murray-Smith", "title": "Bayesian parameter estimation using conditional variational autoencoders\n  for gravitational-wave astronomy", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG gr-qc", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gravitational wave (GW) detection is now commonplace and as the sensitivity\nof the global network of GW detectors improves, we will observe\n$\\mathcal{O}(100)$s of transient GW events per year. The current methods used\nto estimate their source parameters employ optimally sensitive but\ncomputationally costly Bayesian inference approaches where typical analyses\nhave taken between 6 hours and 5 days. For binary neutron star and neutron star\nblack hole systems prompt counterpart electromagnetic (EM) signatures are\nexpected on timescales of 1 second -- 1 minute and the current fastest method\nfor alerting EM follow-up observers, can provide estimates in $\\mathcal{O}(1)$\nminute, on a limited range of key source parameters. Here we show that a\nconditional variational autoencoder pre-trained on binary black hole signals\ncan return Bayesian posterior probability estimates. The training procedure\nneed only be performed once for a given prior parameter space and the resulting\ntrained machine can then generate samples describing the posterior distribution\n$\\sim 6$ orders of magnitude faster than existing techniques.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:41:33 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 14:54:01 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 09:50:46 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Gabbard", "Hunter", ""], ["Messenger", "Chris", ""], ["Heng", "Ik Siong", ""], ["Tonolini", "Francesco", ""], ["Murray-Smith", "Roderick", ""]]}, {"id": "1909.06297", "submitter": "Han Liu", "authors": "Han Liu, Zhizhong Han, Yu-Shen Liu, Ming Gu", "title": "Fast Low-rank Metric Learning for Large-scale and High-dimensional Data", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank metric learning aims to learn better discrimination of data subject\nto low-rank constraints. It keeps the intrinsic low-rank structure of datasets\nand reduces the time cost and memory usage in metric learning. However, it is\nstill a challenge for current methods to handle datasets with both high\ndimensions and large numbers of samples. To address this issue, we present a\nnovel fast low-rank metric learning (FLRML) method.FLRML casts the low-rank\nmetric learning problem into an unconstrained optimization on the Stiefel\nmanifold, which can be efficiently solved by searching along the descent curves\nof the manifold.FLRML significantly reduces the complexity and memory usage in\noptimization, which makes the method scalable to both high dimensions and large\nnumbers of samples.Furthermore, we introduce a mini-batch version of FLRML to\nmake the method scalable to larger datasets which are hard to be loaded and\ndecomposed in limited memory. The outperforming experimental results show that\nour method is with high accuracy and much faster than the state-of-the-art\nmethods under several benchmarks with large numbers of high-dimensional data.\nCode has been made available at https://github.com/highan911/FLRML\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:42:21 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Liu", "Han", ""], ["Han", "Zhizhong", ""], ["Liu", "Yu-Shen", ""], ["Gu", "Ming", ""]]}, {"id": "1909.06301", "submitter": "Alessandro Fanfarillo", "authors": "Alessandro Fanfarillo, Davide Del Vento", "title": "AITuning: Machine Learning-based Tuning Tool for Run-Time Communication\n  Libraries", "comments": "11 pages, 1 figure, ParCo 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address the problem of tuning communication libraries by\nusing a deep reinforcement learning approach. Reinforcement learning is a\nmachine learning technique incredibly effective in solving game-like\nsituations. In fact, tuning a set of parameters in a communication library in\norder to get better performance in a parallel application can be expressed as a\ngame: Find the right combination/path that provides the best reward. Even\nthough AITuning has been designed to be utilized with different run-time\nlibraries, we focused this work on applying it to the OpenCoarrays run-time\ncommunication library, built on top of MPI-3. This work not only shows the\npotential of using a reinforcement learning algorithm for tuning communication\nlibraries, but also demonstrates how the MPI Tool Information Interface,\nintroduced by the MPI-3 standard, can be used effectively by run-time libraries\nto improve the performance without human intervention.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:48:16 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Fanfarillo", "Alessandro", ""], ["Del Vento", "Davide", ""]]}, {"id": "1909.06312", "submitter": "Stanislav Morozov", "authors": "Sergei Popov, Stanislav Morozov, Artem Babenko", "title": "Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, deep neural networks (DNNs) have become the main instrument for\nmachine learning tasks within a wide range of domains, including vision, NLP,\nand speech. Meanwhile, in an important case of heterogenous tabular data, the\nadvantage of DNNs over shallow counterparts remains questionable. In\nparticular, there is no sufficient evidence that deep learning machinery allows\nconstructing methods that outperform gradient boosting decision trees (GBDT),\nwhich are often the top choice for tabular problems. In this paper, we\nintroduce Neural Oblivious Decision Ensembles (NODE), a new deep learning\narchitecture, designed to work with any tabular data. In a nutshell, the\nproposed NODE architecture generalizes ensembles of oblivious decision trees,\nbut benefits from both end-to-end gradient-based optimization and the power of\nmulti-layer hierarchical representation learning. With an extensive\nexperimental comparison to the leading GBDT packages on a large number of\ntabular datasets, we demonstrate the advantage of the proposed NODE\narchitecture, which outperforms the competitors on most of the tasks. We\nopen-source the PyTorch implementation of NODE and believe that it will become\na universal framework for machine learning on tabular data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 16:11:28 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 13:30:23 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Popov", "Sergei", ""], ["Morozov", "Stanislav", ""], ["Babenko", "Artem", ""]]}, {"id": "1909.06319", "submitter": "Yang Li", "authors": "Yang Li, Shoaib Akbar, Junier B. Oliva", "title": "Flow Models for Arbitrary Conditional Likelihoods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the dependencies among features of a dataset is at the core of\nmost unsupervised learning tasks. However, a majority of generative modeling\napproaches are focused solely on the joint distribution $p(x)$ and utilize\nmodels where it is intractable to obtain the conditional distribution of some\narbitrary subset of features $x_u$ given the rest of the observed covariates\n$x_o$: $p(x_u \\mid x_o)$. Traditional conditional approaches provide a model\nfor a fixed set of covariates conditioned on another fixed set of observed\ncovariates. Instead, in this work we develop a model that is capable of\nyielding all conditional distributions $p(x_u \\mid x_o)$ (for arbitrary $x_u$)\nvia tractable conditional likelihoods. We propose a novel extension of (change\nof variables based) flow generative models, arbitrary conditioning flow models\n(AC-Flow), that can be conditioned on arbitrary subsets of observed covariates,\nwhich was previously infeasible. We apply AC-Flow to the imputation of\nfeatures, and also develop a unified platform for both multiple and single\nimputation by introducing an auxiliary objective that provides a principled\nsingle \"best guess\" for flow models. Extensive empirical evaluations show that\nour models achieve state-of-the-art performance in both single and multiple\nimputation across image inpainting and feature imputation in synthetic and\nreal-world datasets. Code is available at https://github.com/lupalab/ACFlow.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 16:35:17 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 13:30:33 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Li", "Yang", ""], ["Akbar", "Shoaib", ""], ["Oliva", "Junier B.", ""]]}, {"id": "1909.06322", "submitter": "Quanquan Gu", "authors": "Lingxiao Wang and Quanquan Gu", "title": "A Knowledge Transfer Framework for Differentially Private Sparse\n  Learning", "comments": "24 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating high dimensional models with underlying\nsparse structures while preserving the privacy of each training example. We\ndevelop a differentially private high-dimensional sparse learning framework\nusing the idea of knowledge transfer. More specifically, we propose to distill\nthe knowledge from a \"teacher\" estimator trained on a private dataset, by\ncreating a new dataset from auxiliary features, and then train a differentially\nprivate \"student\" estimator using this new dataset. In addition, we establish\nthe linear convergence rate as well as the utility guarantee for our proposed\nmethod. For sparse linear regression and sparse logistic regression, our method\nachieves improved utility guarantees compared with the best known results\n(Kifer et al., 2012; Wang and Gu, 2019). We further demonstrate the superiority\nof our framework through both synthetic and real-world data experiments.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 16:46:02 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Wang", "Lingxiao", ""], ["Gu", "Quanquan", ""]]}, {"id": "1909.06326", "submitter": "Justin Krogue", "authors": "Justin D Krogue, Kaiyang V Cheng, Kevin M Hwang, Paul Toogood, Eric G\n  Meinberg, Erik J Geiger, Musa Zaid, Kevin C McGill, Rina Patel, Jae Ho Sohn,\n  Alexandra Wright, Bryan F Darger, Kevin A Padrez, Eugene Ozhinsky, Sharmila\n  Majumdar, Valentina Pedoia", "title": "Automatic Hip Fracture Identification and Functional Subclassification\n  with Deep Learning", "comments": "Presented at Orthopaedic Research Society, Austin, TX, Feb 2, 2019,\n  currently in submission for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG eess.IV physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Hip fractures are a common cause of morbidity and mortality.\nAutomatic identification and classification of hip fractures using deep\nlearning may improve outcomes by reducing diagnostic errors and decreasing time\nto operation. Methods: Hip and pelvic radiographs from 1118 studies were\nreviewed and 3034 hips were labeled via bounding boxes and classified as\nnormal, displaced femoral neck fracture, nondisplaced femoral neck fracture,\nintertrochanteric fracture, previous ORIF, or previous arthroplasty. A deep\nlearning-based object detection model was trained to automate the placement of\nthe bounding boxes. A Densely Connected Convolutional Neural Network (DenseNet)\nwas trained on a subset of the bounding box images, and its performance\nevaluated on a held out test set and by comparison on a 100-image subset to two\ngroups of human observers: fellowship-trained radiologists and orthopaedists,\nand senior residents in emergency medicine, radiology, and orthopaedics.\nResults: The binary accuracy for fracture of our model was 93.8% (95% CI,\n91.3-95.8%), with sensitivity of 92.7% (95% CI, 88.7-95.6%), and specificity\n95.0% (95% CI, 91.5-97.3%). Multiclass classification accuracy was 90.4% (95%\nCI, 87.4-92.9%). When compared to human observers, our model achieved at least\nexpert-level classification under all conditions. Additionally, when the model\nwas used as an aid, human performance improved, with aided resident performance\napproximating unaided fellowship-trained expert performance. Conclusions: Our\ndeep learning model identified and classified hip fractures with at least\nexpert-level accuracy, and when used as an aid improved human performance, with\naided resident performance approximating that of unaided fellowship-trained\nattendings.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 15:03:43 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Krogue", "Justin D", ""], ["Cheng", "Kaiyang V", ""], ["Hwang", "Kevin M", ""], ["Toogood", "Paul", ""], ["Meinberg", "Eric G", ""], ["Geiger", "Erik J", ""], ["Zaid", "Musa", ""], ["McGill", "Kevin C", ""], ["Patel", "Rina", ""], ["Sohn", "Jae Ho", ""], ["Wright", "Alexandra", ""], ["Darger", "Bryan F", ""], ["Padrez", "Kevin A", ""], ["Ozhinsky", "Eugene", ""], ["Majumdar", "Sharmila", ""], ["Pedoia", "Valentina", ""]]}, {"id": "1909.06335", "submitter": "Tzu-Ming Harry Hsu", "authors": "Tzu-Ming Harry Hsu, Hang Qi, Matthew Brown", "title": "Measuring the Effects of Non-Identical Data Distribution for Federated\n  Visual Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning enables visual models to be trained in a\nprivacy-preserving way using real-world data from mobile devices. Given their\ndistributed nature, the statistics of the data across these devices is likely\nto differ significantly. In this work, we look at the effect such non-identical\ndata distributions has on visual classification via Federated Learning. We\npropose a way to synthesize datasets with a continuous range of identicalness\nand provide performance measures for the Federated Averaging algorithm. We show\nthat performance degrades as distributions differ more, and propose a\nmitigation strategy via server momentum. Experiments on CIFAR-10 demonstrate\nimproved classification performance over a range of non-identicalness, with\nclassification accuracy improved from 30.1% to 76.9% in the most skewed\nsettings.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 17:26:20 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Hsu", "Tzu-Ming Harry", ""], ["Qi", "Hang", ""], ["Brown", "Matthew", ""]]}, {"id": "1909.06342", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Alice Xiang, Shubham Sharma, Adrian Weller, Ankur Taly,\n  Yunhan Jia, Joydeep Ghosh, Ruchir Puri, Jos\\'e M. F. Moura, Peter Eckersley", "title": "Explainable Machine Learning in Deployment", "comments": "ACM Conference on Fairness, Accountability, and Transparency 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable machine learning offers the potential to provide stakeholders\nwith insights into model behavior by using various methods such as feature\nimportance scores, counterfactual explanations, or influential training data.\nYet there is little understanding of how organizations use these methods in\npractice. This study explores how organizations view and use explainability for\nstakeholder consumption. We find that, currently, the majority of deployments\nare not for end users affected by the model but rather for machine learning\nengineers, who use explainability to debug the model itself. There is thus a\ngap between explainability in practice and the goal of transparency, since\nexplanations primarily serve internal stakeholders rather than external ones.\nOur study synthesizes the limitations of current explainability techniques that\nhamper their use for end users. To facilitate end user interaction, we develop\na framework for establishing clear goals for explainability. We end by\ndiscussing concerns raised regarding explainability.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 17:35:53 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 18:30:09 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 17:31:01 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2020 13:53:00 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Bhatt", "Umang", ""], ["Xiang", "Alice", ""], ["Sharma", "Shubham", ""], ["Weller", "Adrian", ""], ["Taly", "Ankur", ""], ["Jia", "Yunhan", ""], ["Ghosh", "Joydeep", ""], ["Puri", "Ruchir", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Eckersley", "Peter", ""]]}, {"id": "1909.06349", "submitter": "Vincent Chen", "authors": "Vincent S. Chen and Sen Wu and Zhenzhen Weng and Alexander Ratner and\n  Christopher R\\'e", "title": "Slice-based Learning: A Programming Model for Residual Learning in\n  Critical Data Slices", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world machine learning applications, data subsets correspond to\nespecially critical outcomes: vulnerable cyclist detections are safety-critical\nin an autonomous driving task, and \"question\" sentences might be important to a\ndialogue agent's language understanding for product purposes. While machine\nlearning models can achieve high quality performance on coarse-grained metrics\nlike F1-score and overall accuracy, they may underperform on critical\nsubsets---we define these as slices, the key abstraction in our approach. To\naddress slice-level performance, practitioners often train separate \"expert\"\nmodels on slice subsets or use multi-task hard parameter sharing. We propose\nSlice-based Learning, a new programming model in which the slicing function\n(SF), a programming interface, specifies critical data subsets for which the\nmodel should commit additional capacity. Any model can leverage SFs to learn\nslice expert representations, which are combined with an attention mechanism to\nmake slice-aware predictions. We show that our approach maintains a\nparameter-efficient representation while improving over baselines by up to 19.0\nF1 on slices and 4.6 F1 overall on datasets spanning language understanding\n(e.g. SuperGLUE), computer vision, and production-scale industrial systems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 17:49:20 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 06:56:36 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Vincent S.", ""], ["Wu", "Sen", ""], ["Weng", "Zhenzhen", ""], ["Ratner", "Alexander", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1909.06356", "submitter": "Shiyue Zhang", "authors": "Shiyue Zhang, Mohit Bansal", "title": "Addressing Semantic Drift in Question Generation for Semi-Supervised\n  Question Answering", "comments": "15 pages (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based Question Generation (QG) aims at generating natural and relevant\nquestions that can be answered by a given answer in some context. Existing QG\nmodels suffer from a \"semantic drift\" problem, i.e., the semantics of the\nmodel-generated question drifts away from the given context and answer. In this\npaper, we first propose two semantics-enhanced rewards obtained from downstream\nquestion paraphrasing and question answering tasks to regularize the QG model\nto generate semantically valid questions. Second, since the traditional\nevaluation metrics (e.g., BLEU) often fall short in evaluating the quality of\ngenerated questions, we propose a QA-based evaluation method which measures the\nQG model's ability to mimic human annotators in generating QA training data.\nExperiments show that our method achieves the new state-of-the-art performance\nw.r.t. traditional metrics, and also performs best on our QA-based evaluation\nmetrics. Further, we investigate how to use our QG model to augment QA datasets\nand enable semi-supervised QA. We propose two ways to generate synthetic QA\npairs: generate new questions from existing articles or collect QA pairs from\nnew articles. We also propose two empirically effective strategies, a data\nfilter and mixing mini-batch training, to properly use the QG-generated data\nfor QA. Experiments show that our method improves over both BiDAF and BERT QA\nbaselines, even without introducing new articles.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 17:59:03 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Zhang", "Shiyue", ""], ["Bansal", "Mohit", ""]]}, {"id": "1909.06362", "submitter": "Nasim Sonboli", "authors": "Kun Lin, Nasim Sonboli, Bamshad Mobasher, Robin Burke", "title": "Crank up the volume: preference bias amplification in collaborative\n  recommendation", "comments": "Presented at the RMSE workshop held in conjunction with the 13th ACM\n  Conference on Recommender Systems (RecSys), 2019, in Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender systems are personalized: we expect the results given to a\nparticular user to reflect that user's preferences. Some researchers have\nstudied the notion of calibration, how well recommendations match users' stated\npreferences, and bias disparity the extent to which mis-calibration affects\ndifferent user groups. In this paper, we examine bias disparity over a range of\ndifferent algorithms and for different item categories and demonstrate\nsignificant differences between model-based and memory-based algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 03:23:02 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Lin", "Kun", ""], ["Sonboli", "Nasim", ""], ["Mobasher", "Bamshad", ""], ["Burke", "Robin", ""]]}, {"id": "1909.06365", "submitter": "Andreas Weinand", "authors": "Andreas Weinand, Raja Sattiraju, Michael Karrenbauer, Hans D. Schotten", "title": "Supervised Learning for Physical Layer based Message Authentication in\n  URLLC scenarios", "comments": "arXiv admin note: text overlap with arXiv:1711.05088", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PHYSEC based message authentication can, as an alternative to conventional\nsecurity schemes, be applied within \\gls{urllc} scenarios in order to meet the\nrequirement of secure user data transmissions in the sense of authenticity and\nintegrity. In this work, we investigate the performance of supervised learning\nclassifiers for discriminating legitimate transmitters from illegimate ones in\nsuch scenarios. We further present our methodology of data collection using\n\\gls{sdr} platforms and the data processing pipeline including e.g. necessary\npreprocessing steps. Finally, the performance of the considered supervised\nlearning schemes under different side conditions is presented.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 08:45:46 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Weinand", "Andreas", ""], ["Sattiraju", "Raja", ""], ["Karrenbauer", "Michael", ""], ["Schotten", "Hans D.", ""]]}, {"id": "1909.06397", "submitter": "Stefan Sommer", "authors": "Stefan Sommer, Alex Bronstein", "title": "Horizontal Flows and Manifold Stochastics in Geometric Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two constructions in geometric deep learning for 1) transporting\norientation-dependent convolutional filters over a manifold in a continuous way\nand thereby defining a convolution operator that naturally incorporates the\nrotational effect of holonomy; and 2) allowing efficient evaluation of manifold\nconvolution layers by sampling manifold valued random variables that center\naround a weighted diffusion mean. Both methods are inspired by stochastics on\nmanifolds and geometric statistics, and provide examples of how stochastic\nmethods -- here horizontal frame bundle flows and non-linear bridge sampling\nschemes, can be used in geometric deep learning. We outline the theoretical\nfoundation of the two methods, discuss their relation to Euclidean deep\nnetworks and existing methodology in geometric deep learning, and establish\nimportant properties of the proposed constructions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 18:27:02 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 13:28:51 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 19:00:10 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Sommer", "Stefan", ""], ["Bronstein", "Alex", ""]]}, {"id": "1909.06414", "submitter": "Yilun Zhou", "authors": "Yilun Zhou, Julie A. Shah, Steven Schockaert", "title": "Learning Household Task Knowledge from WikiHow Descriptions", "comments": "IJCAI 2019 Workshop on Semantic Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense procedural knowledge is important for AI agents and robots that\noperate in a human environment. While previous attempts at constructing\nprocedural knowledge are mostly rule- and template-based, recent advances in\ndeep learning provide the possibility of acquiring such knowledge directly from\nnatural language sources. As a first step in this direction, we propose a model\nto learn embeddings for tasks, as well as the individual steps that need to be\ntaken to solve them, based on WikiHow articles. We learn these embeddings such\nthat they are predictive of both step relevance and step ordering. We also\nexperiment with the use of integer programming for inferring consistent global\nstep orderings from noisy pairwise predictions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 19:16:53 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Zhou", "Yilun", ""], ["Shah", "Julie A.", ""], ["Schockaert", "Steven", ""]]}, {"id": "1909.06429", "submitter": "Rinat Khaziev", "authors": "Rinat Khaziev, Bryce Casavant, Pearce Washabaugh, Amy A. Winecoff, and\n  Matthew Graham", "title": "Recommendation or Discrimination?: Quantifying Distribution Parity in\n  Information Retrieval Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information retrieval (IR) systems often leverage query data to suggest\nrelevant items to users. This introduces the possibility of unfairness if the\nquery (i.e., input) and the resulting recommendations unintentionally correlate\nwith latent factors that are protected variables (e.g., race, gender, and age).\nFor instance, a visual search system for fashion recommendations may pick up on\nfeatures of the human models rather than fashion garments when generating\nrecommendations. In this work, we introduce a statistical test for\n\"distribution parity\" in the top-K IR results, which assesses whether a given\nset of recommendations is fair with respect to a specific protected variable.\nWe evaluate our test using both simulated and empirical results. First, using\nartificially biased recommendations, we demonstrate the trade-off between\nstatistically detectable bias and the size of the search catalog. Second, we\napply our test to a visual search system for fashion garments, specifically\ntesting for recommendation bias based on the skin tone of fashion models. Our\ndistribution parity test can help ensure that IR systems' results are fair and\nproduce a good experience for all users.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 20:17:19 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Khaziev", "Rinat", ""], ["Casavant", "Bryce", ""], ["Washabaugh", "Pearce", ""], ["Winecoff", "Amy A.", ""], ["Graham", "Matthew", ""]]}, {"id": "1909.06434", "submitter": "Sebastien Jean", "authors": "S\\'ebastien Jean, Orhan Firat, Melvin Johnson", "title": "Adaptive Scheduling for Multi-Task Learning", "comments": "Continual Learning Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To train neural machine translation models simultaneously on multiple tasks\n(languages), it is common to sample each task uniformly or in proportion to\ndataset sizes. As these methods offer little control over performance\ntrade-offs, we explore different task scheduling approaches. We first consider\nexisting non-adaptive techniques, then move on to adaptive schedules that\nover-sample tasks with poorer results compared to their respective baseline. As\nexplicit schedules can be inefficient, especially if one task is highly\nover-sampled, we also consider implicit schedules, learning to scale learning\nrates or gradients of individual tasks instead. These techniques allow training\nmultilingual models that perform better for low-resource language pairs (tasks\nwith small amount of data), while minimizing negative effects on high-resource\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 20:23:40 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Jean", "S\u00e9bastien", ""], ["Firat", "Orhan", ""], ["Johnson", "Melvin", ""]]}, {"id": "1909.06442", "submitter": "Devin Taylor", "authors": "Devin Taylor, Simeon Spasov and Pietro Li\\`o", "title": "Co-Attentive Cross-Modal Deep Learning for Medical Evidence Synthesis\n  and Decision Making", "comments": "7 pages, 2 figures, Machine Learning for Health (ML4H) at NeurIPS\n  2019 - Extended Abstract, clarified graph and math notation, typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern medicine requires generalised approaches to the synthesis and\nintegration of multimodal data, often at different biological scales, that can\nbe applied to a variety of evidence structures, such as complex disease\nanalyses and epidemiological models. However, current methods are either slow\nand expensive, or ineffective due to the inability to model the complex\nrelationships between data modes which differ in scale and format. We address\nthese issues by proposing a cross-modal deep learning architecture and\nco-attention mechanism to accurately model the relationships between the\ndifferent data modes, while further reducing patient diagnosis time.\nDifferentiating Parkinson's Disease (PD) patients from healthy patients forms\nthe basis of the evaluation. The model outperforms the previous\nstate-of-the-art unimodal analysis by 2.35%, while also being 53% more\nparameter efficient than the industry standard cross-modal model. Furthermore,\nthe evaluation of the attention coefficients allows for qualitative insights to\nbe obtained. Through the coupling with bioinformatics, a novel link between the\ninterferon-gamma-mediated pathway, DNA methylation and PD was identified. We\nbelieve that our approach is general and could optimise the process of medical\nevidence synthesis and decision making in an actionable way.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 20:49:55 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 06:58:53 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Taylor", "Devin", ""], ["Spasov", "Simeon", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1909.06446", "submitter": "Odemir Bruno PhD", "authors": "Leonardo F. S. Scabini, Lucas C. Ribas, Odemir M. Bruno", "title": "Spatio-spectral networks for color-texture analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Texture is one of the most-studied visual attribute for image\ncharacterization since the 1960s. However, most hand-crafted descriptors are\nmonochromatic, focusing on the gray scale images and discarding the color\ninformation. In this context, this work focus on a new method for color texture\nanalysis considering all color channels in a more intrinsic approach. Our\nproposal consists of modeling color images as directed complex networks that we\nnamed Spatio-Spectral Network (SSN). Its topology includes within-channel edges\nthat cover spatial patterns throughout individual image color channels, while\nbetween-channel edges tackle spectral properties of channel pairs in an\nopponent fashion. Image descriptors are obtained through a concise topological\ncharacterization of the modeled network in a multiscale approach with radially\nsymmetric neighborhoods. Experiments with four datasets cover several aspects\nof color-texture analysis, and results demonstrate that SSN overcomes all the\ncompared literature methods, including known deep convolutional networks, and\nalso has the most stable performance between datasets, achieving $98.5(\\pm1.1)$\nof average accuracy against $97.1(\\pm1.3)$ of MCND and $96.8(\\pm3.2)$ of\nAlexNet. Additionally, an experiment verifies the performance of the methods\nunder different color spaces, where results show that SSN also has higher\nperformance and robustness.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 20:54:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Scabini", "Leonardo F. S.", ""], ["Ribas", "Lucas C.", ""], ["Bruno", "Odemir M.", ""]]}, {"id": "1909.06463", "submitter": "Parameswaran Raman", "authors": "Parameswaran Raman, Jiasen Yang", "title": "Optimization on the Surface of the (Hyper)-Sphere", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thomson problem is a classical problem in physics to study how $n$ number of\ncharged particles distribute themselves on the surface of a sphere of $k$\ndimensions. When $k=2$, i.e. a 2-sphere (a circle), the particles appear at\nequally spaced points. Such a configuration can be computed analytically.\nHowever, for higher dimensions such as $k \\ge 3$, i.e. the case of 3-sphere\n(standard sphere), there is not much that is understood analytically. Finding\nglobal minimum of the problem under these settings is particularly tough since\nthe optimization problem becomes increasingly computationally intensive with\nlarger values of $k$ and $n$. In this work, we explore a wide variety of\nnumerical optimization methods to solve the Thomson problem. In our empirical\nstudy, we find stochastic gradient based methods (SGD) to be a compelling\nchoice for this problem as it scales well with the number of points.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 21:50:57 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Raman", "Parameswaran", ""], ["Yang", "Jiasen", ""]]}, {"id": "1909.06473", "submitter": "Ali Siahkoohi", "authors": "Felix J. Herrmann, Ali Siahkoohi, Gabrio Rizzuti", "title": "Learned imaging with constraints and uncertainty quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline new approaches to incorporate ideas from deep learning into\nwave-based least-squares imaging. The aim, and main contribution of this work,\nis the combination of handcrafted constraints with deep convolutional neural\nnetworks, as a way to harness their remarkable ease of generating natural\nimages. The mathematical basis underlying our method is the\nexpectation-maximization framework, where data are divided in batches and\ncoupled to additional \"latent\" unknowns. These unknowns are pairs of elements\nfrom the original unknown space (but now coupled to a specific data batch) and\nnetwork inputs. In this setting, the neural network controls the similarity\nbetween these additional parameters, acting as a \"center\" variable. The\nresulting problem amounts to a maximum-likelihood estimation of the network\nparameters when the augmented data model is marginalized over the latent\nvariables.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 22:14:36 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 08:01:20 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Herrmann", "Felix J.", ""], ["Siahkoohi", "Ali", ""], ["Rizzuti", "Gabrio", ""]]}, {"id": "1909.06491", "submitter": "Gita Sukthankar", "authors": "Saif Alabachi, Gita Sukthankar, and Rahul Sukthankar", "title": "Selfie Drone Stick: A Natural Interface for Quadcopter Photography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A physical selfie stick extends the user's reach, enabling the acquisition of\npersonal photos that include more of the background scene. Similarly, a\nquadcopter can capture photos from vantage points unattainable by the user; but\nteleoperating a quadcopter to good viewpoints is a difficult task. This paper\npresents a natural interface for quadcopter photography, the SelfieDroneStick\nthat allows the user to guide the quadcopter to the optimal vantage point based\non the phone's sensors. Users specify the composition of their desired\nlong-range selfies using their smartphone, and the quadcopter autonomously\nflies to a sequence of vantage points from where the desired shots can be\ntaken. The robot controller is trained from a combination of real-world images\nand simulated flight data. This paper describes two key innovations required to\ndeploy deep reinforcement learning models on a real robot: 1) an abstract state\nrepresentation for transferring learning from simulation to the hardware\nplatform, and 2) reward shaping and staging paradigms for training the\ncontroller. Both of these improvements were found to be essential in learning a\nrobot controller from simulation that transfers successfully to the real robot.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 00:13:05 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 23:38:30 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Alabachi", "Saif", ""], ["Sukthankar", "Gita", ""], ["Sukthankar", "Rahul", ""]]}, {"id": "1909.06493", "submitter": "William Koch", "authors": "William Koch", "title": "Flight Controller Synthesis Via Deep Reinforcement Learning", "comments": "206 pages, PhD Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditional control methods are inadequate in many deployment settings\ninvolving control of Cyber-Physical Systems (CPS). In such settings, CPS\ncontrollers must operate and respond to unpredictable interactions, conditions,\nor failure modes. Dealing with such unpredictability requires the use of\nexecutive and cognitive control functions that allow for planning and\nreasoning. Motivated by the sport of drone racing, this dissertation addresses\nthese concerns for state-of-the-art flight control by investigating the use of\ndeep neural networks to bring essential elements of higher-level cognition for\nconstructing low level flight controllers.\n  This thesis reports on the development and release of an open source, full\nsolution stack for building neuro-flight controllers. This stack consists of\nthe methodology for constructing a multicopter digital twin for synthesize the\nflight controller unique to a specific aircraft, a tuning framework for\nimplementing training environments (GymFC), and a firmware for the world's\nfirst neural network supported flight controller (Neuroflight). GymFC's novel\napproach fuses together the digital twinning paradigm for flight control\ntraining to provide seamless transfer to hardware. Additionally, this thesis\nexamines alternative reward system functions as well as changes to the software\nenvironment to bridge the gap between the simulation and real world deployment\nenvironments.\n  Work summarized in this thesis demonstrates that reinforcement learning is\nable to be leveraged for training neural network controllers capable, not only\nof maintaining stable flight, but also precision aerobatic maneuvers in real\nworld settings. As such, this work provides a foundation for developing the\nnext generation of flight control systems.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 00:35:21 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Koch", "William", ""]]}, {"id": "1909.06507", "submitter": "Ajay Shrestha", "authors": "Santosh Paudel, Ajay Kumar Shrestha, Pradip Singh Maharjan, Rameshwar\n  Rijal", "title": "Performance Analysis of Spatial and Transform Filters for Efficient\n  Image Noise Reduction", "comments": "7 pages, 7 figures, 3 tables, conference \"for associated conference\n  file, see\n  http://https://www.researchgate.net/publication/291974499_Performance_Analysis_of_Spatial_and_Transform_Filters_for_Efficient_Image_Noise_Reduction\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the acquisition of an image from its source, noise always becomes an\nintegral part of it. Various algorithms have been used in past to denoise the\nimages. Image denoising still has scope for improvement. Visual information\ntransmitted in the form of digital images has become a considerable method of\ncommunication in the modern age, but the image obtained after the transmission\nis often corrupted due to noise. In this paper, we review the existing\ndenoising algorithms such as filtering approach and wavelets based approach and\nthen perform their comparative study with bilateral filters. We use different\nnoise models to describe additive and multiplicative noise in an image. Based\non the samples of degraded pixel neighbourhoods as inputs, the output of an\nefficient filtering approach has shown a better image denoising performance.\nThis yields promising qualitative and quantitative results of the degraded\nnoisy images in terms of Peak Signal to Noise Ratio, Mean Square Error and\nUniversal Quality Identifier.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 02:05:45 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Paudel", "Santosh", ""], ["Shrestha", "Ajay Kumar", ""], ["Maharjan", "Pradip Singh", ""], ["Rijal", "Rameshwar", ""]]}, {"id": "1909.06511", "submitter": "Alden Bradford", "authors": "Mireille Boutin and Alden Bradford", "title": "A highly likely clusterable data model with no clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model for a dataset in ${\\mathbb R}^D$ that does not contain any\nclusters but yet is such that a projection of the points on a random\none-dimensional subspace is likely to yield a clustering of the points. This\nmodel is compatible with some recent empirical observations.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 02:38:31 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Boutin", "Mireille", ""], ["Bradford", "Alden", ""]]}, {"id": "1909.06522", "submitter": "Chunxi Liu", "authors": "Chunxi Liu, Qiaochu Zhang, Xiaohui Zhang, Kritika Singh, Yatharth\n  Saraf, Geoffrey Zweig", "title": "Multilingual Graphemic Hybrid ASR with Massive Data Augmentation", "comments": "Accepted for publication at the 1st Joint Workshop of SLTU (Spoken\n  Language Technologies for Under-resourced languages) and CCURL (Collaboration\n  and Computing for Under-Resourced Languages) (SLTU-CCURL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards developing high-performing ASR for low-resource languages, approaches\nto address the lack of resources are to make use of data from multiple\nlanguages, and to augment the training data by creating acoustic variations. In\nthis work we present a single grapheme-based ASR model learned on 7\ngeographically proximal languages, using standard hybrid BLSTM-HMM acoustic\nmodels with lattice-free MMI objective. We build the single ASR grapheme set\nvia taking the union over each language-specific grapheme set, and we find such\nmultilingual graphemic hybrid ASR model can perform language-independent\nrecognition on all 7 languages, and substantially outperform each monolingual\nASR model. Secondly, we evaluate the efficacy of multiple data augmentation\nalternatives within language, as well as their complementarity with\nmultilingual modeling. Overall, we show that the proposed multilingual\ngraphemic hybrid ASR with various data augmentation can not only recognize any\nwithin training set languages, but also provide large ASR performance\nimprovements.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 03:46:49 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 20:39:07 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 22:09:51 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Liu", "Chunxi", ""], ["Zhang", "Qiaochu", ""], ["Zhang", "Xiaohui", ""], ["Singh", "Kritika", ""], ["Saraf", "Yatharth", ""], ["Zweig", "Geoffrey", ""]]}, {"id": "1909.06526", "submitter": "K. R. Jayaram", "authors": "K. R. Jayaram, Vinod Muthusamy, Parijat Dube, Vatche Ishakian, Chen\n  Wang, Benjamin Herta, Scott Boag, Diana Arroyo, Asser Tantawi, Archit Verma,\n  Falk Pollok, Rania Khalaf", "title": "FfDL : A Flexible Multi-tenant Deep Learning Platform", "comments": "MIDDLEWARE 2019", "journal-ref": null, "doi": "10.1145/3361525.3361538", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) is becoming increasingly popular in several application\ndomains and has made several new application features involving computer\nvision, speech recognition and synthesis, self-driving automobiles, drug\ndesign, etc. feasible and accurate. As a result, large scale on-premise and\ncloud-hosted deep learning platforms have become essential infrastructure in\nmany organizations. These systems accept, schedule, manage and execute DL\ntraining jobs at scale.\n  This paper describes the design, implementation and our experiences with\nFfDL, a DL platform used at IBM. We describe how our design balances\ndependability with scalability, elasticity, flexibility and efficiency. We\nexamine FfDL qualitatively through a retrospective look at the lessons learned\nfrom building, operating, and supporting FfDL; and quantitatively through a\ndetailed empirical evaluation of FfDL, including the overheads introduced by\nthe platform for various deep learning models, the load and performance\nobserved in a real case study using FfDL within our organization, the frequency\nof various faults observed including unanticipated faults, and experiments\ndemonstrating the benefits of various scheduling policies. FfDL has been\nopen-sourced.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 04:02:45 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Jayaram", "K. R.", ""], ["Muthusamy", "Vinod", ""], ["Dube", "Parijat", ""], ["Ishakian", "Vatche", ""], ["Wang", "Chen", ""], ["Herta", "Benjamin", ""], ["Boag", "Scott", ""], ["Arroyo", "Diana", ""], ["Tantawi", "Asser", ""], ["Verma", "Archit", ""], ["Pollok", "Falk", ""], ["Khalaf", "Rania", ""]]}, {"id": "1909.06527", "submitter": "Christoforos Mavrogiannis", "authors": "Gilwoo Lee, Christoforos Mavrogiannis, Siddhartha S. Srinivasa", "title": "Towards Effective Human-AI Teams: The Case of Collaborative Packing", "comments": "Added two graphs and made some minor edits to the text", "journal-ref": null, "doi": null, "report-no": "AI-HRI/2019/20", "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of designing an artificial agent (AI), capable of\nassisting a human user to complete a task. Our goal is to guide human users\ntowards optimal task performance while keeping their cognitive load as low as\npossible. Our insight is that doing so requires an understanding of human\ndecision making for the task domain at hand. In this work, we consider the\ndomain of collaborative packing, in which an AI agent provides placement\nrecommendations to a human user. As a first step, we explore the mechanisms\nunderlying human packing strategies. We conducted a user study in which 100\nhuman participants completed a series of packing tasks in a virtual\nenvironment. We analyzed their packing strategies and discovered spatial and\ntemporal patterns, such as that humans tend to place larger items at corners\nfirst. We expect that imbuing an artificial agent with an understanding of this\nspatiotemporal structure will enable improved assistance, which will be\nreflected in the task performance and the human perception of the AI. Ongoing\nwork involves the development of a framework that incorporates the extracted\ninsights to predict and manipulate human decision making towards an efficient\ntrajectory of low cognitive load and high efficiency. A follow-up study will\nevaluate our framework against a set of baselines featuring alternative\nstrategies of assistance. Our eventual goal is the deployment and evaluation of\nour framework on an autonomous robotic manipulator, actively assisting users on\na packing task.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 04:13:35 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 18:53:11 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 04:18:15 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Lee", "Gilwoo", ""], ["Mavrogiannis", "Christoforos", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "1909.06532", "submitter": "Hieu-Thi Luong", "authors": "Hieu-Thi Luong, Junichi Yamagishi", "title": "Bootstrapping non-parallel voice conversion from speaker-adaptive\n  text-to-speech", "comments": "Accepted for IEEE ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice conversion (VC) and text-to-speech (TTS) are two tasks that share a\nsimilar objective, generating speech with a target voice. However, they are\nusually developed independently under vastly different frameworks. In this\npaper, we propose a methodology to bootstrap a VC system from a pretrained\nspeaker-adaptive TTS model and unify the techniques as well as the\ninterpretations of these two tasks. Moreover by offloading the heavy data\ndemand to the training stage of the TTS model, our VC system can be built using\na small amount of target speaker speech data. It also opens up the possibility\nof using speech in a foreign unseen language to build the system. Our\nsubjective evaluations show that the proposed framework is able to not only\nachieve competitive performance in the standard intra-language scenario but\nalso adapt and convert using speech utterances in an unseen language.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 04:43:32 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Luong", "Hieu-Thi", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1909.06541", "submitter": "Haitao Liu", "authors": "Haitao Liu, Yew-Soon Ong, Ziwei Yu, Jianfei Cai, Xiaobo Shen", "title": "Scalable Gaussian Process Classification with Additive Noise for Various\n  Likelihoods", "comments": "11 pages, 5 figures, preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process classification (GPC) provides a flexible and powerful\nstatistical framework describing joint distributions over function space.\nConventional GPCs however suffer from (i) poor scalability for big data due to\nthe full kernel matrix, and (ii) intractable inference due to the non-Gaussian\nlikelihoods. Hence, various scalable GPCs have been proposed through (i) the\nsparse approximation built upon a small inducing set to reduce the time\ncomplexity; and (ii) the approximate inference to derive analytical evidence\nlower bound (ELBO). However, these scalable GPCs equipped with analytical ELBO\nare limited to specific likelihoods or additional assumptions. In this work, we\npresent a unifying framework which accommodates scalable GPCs using various\nlikelihoods. Analogous to GP regression (GPR), we introduce additive noises to\naugment the probability space for (i) the GPCs with step, (multinomial) probit\nand logit likelihoods via the internal variables; and particularly, (ii) the\nGPC using softmax likelihood via the noise variables themselves. This leads to\nunified scalable GPCs with analytical ELBO by using variational inference.\nEmpirically, our GPCs showcase better results than state-of-the-art scalable\nGPCs for extensive binary/multi-class classification tasks with up to two\nmillion data points.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 06:24:38 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Liu", "Haitao", ""], ["Ong", "Yew-Soon", ""], ["Yu", "Ziwei", ""], ["Cai", "Jianfei", ""], ["Shen", "Xiaobo", ""]]}, {"id": "1909.06543", "submitter": "Yiwei Sun", "authors": "Yiwei Sun, Suhang Wang, Xianfeng Tang, Tsung-Yu Hsieh, Vasant Honavar", "title": "Node Injection Attacks on Graphs via Reinforcement Learning", "comments": "Preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world graph applications, such as advertisements and product\nrecommendations make profits based on accurately classify the label of the\nnodes. However, in such scenarios, there are high incentives for the\nadversaries to attack such graph to reduce the node classification performance.\nPrevious work on graph adversarial attacks focus on modifying existing graph\nstructures, which is infeasible in most real-world applications. In contrast,\nit is more practical to inject adversarial nodes into existing graphs, which\ncan also potentially reduce the performance of the classifier. In this paper,\nwe study the novel node injection poisoning attacks problem which aims to\npoison the graph. We describe a reinforcement learning based method, namely\nNIPA, to sequentially modify the adversarial information of the injected nodes.\nWe report the results of experiments using several benchmark data sets that\nshow the superior performance of the proposed method NIPA, relative to the\nexisting state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 06:35:22 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Sun", "Yiwei", ""], ["Wang", "Suhang", ""], ["Tang", "Xianfeng", ""], ["Hsieh", "Tsung-Yu", ""], ["Honavar", "Vasant", ""]]}, {"id": "1909.06563", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta, Yatin Chaudhary, Hinrich Sch\\\"utze", "title": "Multi-view and Multi-source Transfers in Neural Topic Modeling with\n  Pretrained Topic and Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though word embeddings and topics are complementary representations, several\npast works have only used pre-trained word embeddings in (neural) topic\nmodeling to address data sparsity problem in short text or small collection of\ndocuments. However, no prior work has employed (pre-trained latent) topics in\ntransfer learning paradigm. In this paper, we propose an approach to (1)\nperform knowledge transfer using latent topics obtained from a large source\ncorpus, and (2) jointly transfer knowledge via the two representations (or\nviews) in neural topic modeling to improve topic quality, better deal with\npolysemy and data sparsity issues in a target corpus. In doing so, we first\naccumulate topics and word representations from one or many source corpora to\nbuild a pool of topics and word vectors. Then, we identify one or multiple\nrelevant source domain(s) and take advantage of corresponding topics and word\nfeatures via the respective pools to guide meaningful learning in the sparse\ntarget domain. We quantify the quality of topic and document representations\nvia generalization (perplexity), interpretability (topic coherence) and\ninformation retrieval (IR) using short-text, long-text, small and large\ndocument collections from news and medical domains. We have demonstrated the\nstate-of-the-art results on topic modeling with the proposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 09:16:05 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 13:05:34 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Gupta", "Pankaj", ""], ["Chaudhary", "Yatin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1909.06576", "submitter": "Tristan Deleu", "authors": "Tristan Deleu, Tobias W\\\"urfl, Mandana Samiei, Joseph Paul Cohen,\n  Yoshua Bengio", "title": "Torchmeta: A Meta-Learning library for PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The constant introduction of standardized benchmarks in the literature has\nhelped accelerating the recent advances in meta-learning research. They offer a\nway to get a fair comparison between different algorithms, and the wide range\nof datasets available allows full control over the complexity of this\nevaluation. However, for a large majority of code available online, the data\npipeline is often specific to one dataset, and testing on another dataset\nrequires significant rework. We introduce Torchmeta, a library built on top of\nPyTorch that enables seamless and consistent evaluation of meta-learning\nalgorithms on multiple datasets, by providing data-loaders for most of the\nstandard benchmarks in few-shot classification and regression, with a new\nmeta-dataset abstraction. It also features some extensions for PyTorch to\nsimplify the development of models compatible with meta-learning algorithms.\nThe code is available here: https://github.com/tristandeleu/pytorch-meta\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 10:58:53 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Deleu", "Tristan", ""], ["W\u00fcrfl", "Tobias", ""], ["Samiei", "Mandana", ""], ["Cohen", "Joseph Paul", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1909.06588", "submitter": "Jingyue Lu", "authors": "Rudy Bunel, Jingyue Lu, Ilker Turkaslan, Philip H.S. Torr, Pushmeet\n  Kohli, M. Pawan Kumar", "title": "Branch and Bound for Piecewise Linear Neural Network Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of Deep Learning and its potential use in many safety-critical\napplications has motivated research on formal verification of Neural Network\n(NN) models. In this context, verification involves proving or disproving that\nan NN model satisfies certain input-output properties. Despite the reputation\nof learned NN models as black boxes, and the theoretical hardness of proving\nuseful properties about them, researchers have been successful in verifying\nsome classes of models by exploiting their piecewise linear structure and\ntaking insights from formal methods such as Satisifiability Modulo Theory.\nHowever, these methods are still far from scaling to realistic neural networks.\nTo facilitate progress on this crucial area, we exploit the Mixed Integer\nLinear Programming (MIP) formulation of verification to propose a family of\nalgorithms based on Branch-and-Bound (BaB). We show that our family contains\nprevious verification methods as special cases. With the help of the BaB\nframework, we make three key contributions. Firstly, we identify new methods\nthat combine the strengths of multiple existing approaches, accomplishing\nsignificant performance improvements over previous state of the art. Secondly,\nwe introduce an effective branching strategy on ReLU non-linearities. This\nbranching strategy allows us to efficiently and successfully deal with high\ninput dimensional problems with convolutional network architecture, on which\nprevious methods fail frequently. Finally, we propose comprehensive test data\nsets and benchmarks which includes a collection of previously released\ntestcases. We use the data sets to conduct a thorough experimental comparison\nof existing and new algorithms and to provide an inclusive analysis of the\nfactors impacting the hardness of verification problems.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 12:44:35 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:50:30 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 23:49:41 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 10:33:37 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Bunel", "Rudy", ""], ["Lu", "Jingyue", ""], ["Turkaslan", "Ilker", ""], ["Torr", "Philip H. S.", ""], ["Kohli", "Pushmeet", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1909.06591", "submitter": "Yi Sun", "authors": "Yi Sun, Xushen Han, Kai Sun, Boren Li, Yongjiang Chen, and Mingyang Li", "title": "Sem-LSD: A Learning-based Semantic Line Segment Detector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduces a new type of line-shaped image representation,\nnamed semantic line segment (Sem-LS) and focus on solving its detection\nproblem. Sem-LS contains high-level semantics and is a compact scene\nrepresentation where only visually salient line segments with stable semantics\nare preserved. Combined with high-level semantics, Sem-LS is more robust under\ncluttered environment compared with existing line-shaped representations. The\ncompactness of Sem-LS facilitates its use in large-scale applications, such as\ncity-scale SLAM (simultaneously localization and mapping) and LCD (loop closure\ndetection). Sem-LS detection is a challenging task due to its significantly\ndifferent appearance from existing learning-based image representations such as\nwireframes and objects. For further investigation, we first label Sem-LS on two\nwell-known datasets, KITTI and KAIST URBAN, as new benchmarks. Then, we propose\na learning-based Sem-LS detector (Sem-LSD) and devise new module as well as\nmetrics to address unique challenges in Sem-LS detection. Experimental results\nhave shown both the efficacy and efficiency of Sem-LSD. Finally, the\neffectiveness of the proposed Sem-LS is supported by two experiments on\ndetector repeatability and a city-scale LCD problem. Labeled datasets and code\nwill be released shortly.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 13:02:00 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 11:23:13 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Sun", "Yi", ""], ["Han", "Xushen", ""], ["Sun", "Kai", ""], ["Li", "Boren", ""], ["Chen", "Yongjiang", ""], ["Li", "Mingyang", ""]]}, {"id": "1909.06609", "submitter": "Fabrizio Frasca", "authors": "Fabrizio Frasca, Diego Galeano, Guadalupe Gonzalez, Ivan Laponogov,\n  Kirill Veselkov, Alberto Paccanaro and Michael M. Bronstein", "title": "Learning Interpretable Disease Self-Representations for Drug\n  Repositioning", "comments": "10 pages, 2 figures, v2 corresponds to the camera ready version\n  accepted at the Graph Representation Learning Workshop, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug repositioning is an attractive cost-efficient strategy for the\ndevelopment of treatments for human diseases. Here, we propose an interpretable\nmodel that learns disease self-representations for drug repositioning. Our\nself-representation model represents each disease as a linear combination of a\nfew other diseases. We enforce proximity in the learnt representations in a way\nto preserve the geometric structure of the human phenome network - a\ndomain-specific knowledge that naturally adds relational inductive bias to the\ndisease self-representations. We prove that our method is globally optimal and\nshow results outperforming state-of-the-art drug repositioning approaches. We\nfurther show that the disease self-representations are biologically\ninterpretable.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 15:11:37 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 21:28:29 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Frasca", "Fabrizio", ""], ["Galeano", "Diego", ""], ["Gonzalez", "Guadalupe", ""], ["Laponogov", "Ivan", ""], ["Veselkov", "Kirill", ""], ["Paccanaro", "Alberto", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "1909.06614", "submitter": "Qiujia Li", "authors": "Qiujia Li, Chao Zhang, Philip C. Woodland", "title": "Integrating Source-channel and Attention-based Sequence-to-sequence\n  Models for Speech Recognition", "comments": "To appear in Proc. ASRU2019, December 14-18, 2019, Sentosa, Singapore", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel automatic speech recognition (ASR) framework\ncalled Integrated Source-Channel and Attention (ISCA) that combines the\nadvantages of traditional systems based on the noisy source-channel model (SC)\nand end-to-end style systems using attention-based sequence-to-sequence models.\nThe traditional SC system framework includes hidden Markov models and\nconnectionist temporal classification (CTC) based acoustic models, language\nmodels (LMs), and a decoding procedure based on a lexicon, whereas the\nend-to-end style attention-based system jointly models the whole process with a\nsingle model. By rescoring the hypotheses produced by traditional systems using\nend-to-end style systems based on an extended noisy source-channel model, ISCA\nallows structured knowledge to be easily incorporated via the SC-based model\nwhile exploiting the complementarity of the attention-based model. Experiments\non the AMI meeting corpus show that ISCA is able to give a relative word error\nrate reduction up to 21% over an individual system, and by 13% over an\nalternative method which also involves combining CTC and attention-based\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 15:40:27 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 11:09:08 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Li", "Qiujia", ""], ["Zhang", "Chao", ""], ["Woodland", "Philip C.", ""]]}, {"id": "1909.06618", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano and Ond\\v{r}ej Bojar", "title": "Efficiency Metrics for Data-Driven Models: A Text Summarization Case\n  Study", "comments": "11 pages, 4 tables, 2 figures, 6 equations. Published in proceedings\n  of INLG 2019, the 12th International Conference on Natural Language\n  Generation, Tokyo, Japan", "journal-ref": null, "doi": "10.18653/v1/W19-8630", "report-no": null, "categories": "cs.CL cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using data-driven models for solving text summarization or similar tasks has\nbecome very common in the last years. Yet most of the studies report basic\naccuracy scores only, and nothing is known about the ability of the proposed\nmodels to improve when trained on more data. In this paper, we define and\npropose three data efficiency metrics: data score efficiency, data time\ndeficiency and overall data efficiency. We also propose a simple scheme that\nuses those metrics and apply it for a more comprehensive evaluation of popular\nmethods on text summarization and title generation tasks. For the latter task,\nwe process and release a huge collection of 35 million abstract-title pairs\nfrom scientific articles. Our results reveal that among the tested models, the\nTransformer is the most efficient on both tasks.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 16:03:49 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["\u00c7ano", "Erion", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1909.06627", "submitter": "Xiaotian Han", "authors": "Chuan Shi, Xiaotian Han, Li Song, Xiao Wang, Senzhang Wang, Junping\n  Du, Philip S. Yu", "title": "Deep Collaborative Filtering with Multi-Aspect Information in\n  Heterogeneous Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, recommender systems play a pivotal role in alleviating the problem\nof information overload. Latent factor models have been widely used for\nrecommendation. Most existing latent factor models mainly utilize the\ninteraction information between users and items, although some recently\nextended models utilize some auxiliary information to learn a unified latent\nfactor for users and items. The unified latent factor only represents the\ncharacteristics of users and the properties of items from the aspect of\npurchase history. However, the characteristics of users and the properties of\nitems may stem from different aspects, e.g., the brand-aspect and\ncategory-aspect of items. Moreover, the latent factor models usually use the\nshallow projection, which cannot capture the characteristics of users and items\nwell. In this paper, we propose a Neural network based Aspect-level\nCollaborative Filtering model (NeuACF) to exploit different aspect latent\nfactors. Through modelling the rich object properties and relations in\nrecommender system as a heterogeneous information network, NeuACF first\nextracts different aspect-level similarity matrices of users and items\nrespectively through different meta-paths, and then feeds an elaborately\ndesigned deep neural network with these matrices to learn aspect-level latent\nfactors. Finally, the aspect-level latent factors are fused for the top-N\nrecommendation. Moreover, to fuse information from different aspects more\neffectively, we further propose NeuACF++ to fuse aspect-level latent factors\nwith self-attention mechanism. Extensive experiments on three real world\ndatasets show that NeuACF and NeuACF++ significantly outperform both existing\nlatent factor models and recent neural network models.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 16:33:16 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Shi", "Chuan", ""], ["Han", "Xiaotian", ""], ["Song", "Li", ""], ["Wang", "Xiao", ""], ["Wang", "Senzhang", ""], ["Du", "Junping", ""], ["Yu", "Philip S.", ""]]}, {"id": "1909.06628", "submitter": "Sawyer Birnbaum", "authors": "Sawyer Birnbaum, Volodymyr Kuleshov, Zayd Enam, Pang Wei Koh, Stefano\n  Ermon", "title": "Temporal FiLM: Capturing Long-Range Sequence Dependencies with\n  Feature-Wise Modulations", "comments": "Presented at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations that accurately capture long-range dependencies in\nsequential inputs -- including text, audio, and genomic data -- is a key\nproblem in deep learning. Feed-forward convolutional models capture only\nfeature interactions within finite receptive fields while recurrent\narchitectures can be slow and difficult to train due to vanishing gradients.\nHere, we propose Temporal Feature-Wise Linear Modulation (TFiLM) -- a novel\narchitectural component inspired by adaptive batch normalization and its\nextensions -- that uses a recurrent neural network to alter the activations of\na convolutional model. This approach expands the receptive field of\nconvolutional sequence models with minimal computational overhead. Empirically,\nwe find that TFiLM significantly improves the learning speed and accuracy of\nfeed-forward neural networks on a range of generative and discriminative\nlearning tasks, including text classification and audio super-resolution\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 16:44:35 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 00:03:01 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 02:26:20 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Birnbaum", "Sawyer", ""], ["Kuleshov", "Volodymyr", ""], ["Enam", "Zayd", ""], ["Koh", "Pang Wei", ""], ["Ermon", "Stefano", ""]]}, {"id": "1909.06635", "submitter": "Shweta Mahajan", "authors": "Shweta Mahajan, Teresa Botschen, Iryna Gurevych, Stefan Roth", "title": "Joint Wasserstein Autoencoders for Aligning Multimodal Embeddings", "comments": "Accepted at ICCV 2019 Workshop on Cross-Modal Learning in Real World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges in learning joint embeddings of multiple\nmodalities, e.g. of images and text, is to ensure coherent cross-modal\nsemantics that generalize across datasets. We propose to address this through\njoint Gaussian regularization of the latent representations. Building on\nWasserstein autoencoders (WAEs) to encode the input in each domain, we enforce\nthe latent embeddings to be similar to a Gaussian prior that is shared across\nthe two domains, ensuring compatible continuity of the encoded semantic\nrepresentations of images and texts. Semantic alignment is achieved through\nsupervision from matching image-text pairs. To show the benefits of our\nsemi-supervised representation, we apply it to cross-modal retrieval and phrase\nlocalization. We not only achieve state-of-the-art accuracy, but significantly\nbetter generalization across datasets, owing to the semantic continuity of the\nlatent space.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 17:25:03 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Mahajan", "Shweta", ""], ["Botschen", "Teresa", ""], ["Gurevych", "Iryna", ""], ["Roth", "Stefan", ""]]}, {"id": "1909.06639", "submitter": "Yaushian Wang", "authors": "Yau-Shian Wang and Hung-Yi Lee and Yun-Nung Chen", "title": "Tree Transformer: Integrating Tree Structures into Self-Attention", "comments": "accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training Transformer from large-scale raw texts and fine-tuning on the\ndesired task have achieved state-of-the-art results on diverse NLP tasks.\nHowever, it is unclear what the learned attention captures. The attention\ncomputed by attention heads seems not to match human intuitions about\nhierarchical structures. This paper proposes Tree Transformer, which adds an\nextra constraint to attention heads of the bidirectional Transformer encoder in\norder to encourage the attention heads to follow tree structures. The tree\nstructures can be automatically induced from raw texts by our proposed\n\"Constituent Attention\" module, which is simply implemented by self-attention\nbetween two adjacent words. With the same training procedure identical to BERT,\nthe experiments demonstrate the effectiveness of Tree Transformer in terms of\ninducing tree structures, better language modeling, and further learning more\nexplainable attention scores.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 17:49:37 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 20:38:07 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wang", "Yau-Shian", ""], ["Lee", "Hung-Yi", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1909.06674", "submitter": "Edward Raff", "authors": "Edward Raff", "title": "A Step Toward Quantifying Independently Reproducible Machine Learning\n  Research", "comments": "to appear in Proc. Neural Information Processing Systems (NeurIPS),\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What makes a paper independently reproducible? Debates on reproducibility\ncenter around intuition or assumptions but lack empirical results. Our field\nfocuses on releasing code, which is important, but is not sufficient for\ndetermining reproducibility. We take the first step toward a quantifiable\nanswer by manually attempting to implement 255 papers published from 1984 until\n2017, recording features of each paper, and performing statistical analysis of\nthe results. For each paper, we did not look at the authors code, if released,\nin order to prevent bias toward discrepancies between code and paper.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 20:53:16 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Raff", "Edward", ""]]}, {"id": "1909.06677", "submitter": "Charles Marx", "authors": "Charles T. Marx, Flavio du Pin Calmon, Berk Ustun", "title": "Predictive Multiplicity in Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction problems often admit competing models that perform almost equally\nwell. This effect challenges key assumptions in machine learning when competing\nmodels assign conflicting predictions. In this paper, we define predictive\nmultiplicity as the ability of a prediction problem to admit competing models\nwith conflicting predictions. We introduce formal measures to evaluate the\nseverity of predictive multiplicity and develop integer programming tools to\ncompute them exactly for linear classification problems. We apply our tools to\nmeasure predictive multiplicity in recidivism prediction problems. Our results\nshow that real-world datasets may admit competing models that assign wildly\nconflicting predictions, and motivate the need to measure and report predictive\nmultiplicity in model development.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 21:12:04 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 08:39:47 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 05:10:08 GMT"}, {"version": "v4", "created": "Wed, 16 Sep 2020 04:58:29 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Marx", "Charles T.", ""], ["Calmon", "Flavio du Pin", ""], ["Ustun", "Berk", ""]]}, {"id": "1909.06678", "submitter": "Khe Sim", "authors": "Khe Chai Sim, Petr Zadrazil, Fran\\c{c}oise Beaufays", "title": "An Investigation Into On-device Personalization of End-to-end Automatic\n  Speech Recognition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker-independent speech recognition systems trained with data from many\nusers are generally robust against speaker variability and work well for a\nlarge population of speakers. However, these systems do not always generalize\nwell for users with very different speech characteristics. This issue can be\naddressed by building personalized systems that are designed to work well for\neach specific user. In this paper, we investigate the idea of securely training\npersonalized end-to-end speech recognition models on mobile devices so that\nuser data and models never leave the device and are never stored on a server.\nWe study how the mobile training environment impacts performance by simulating\non-device data consumption. We conduct experiments using data collected from\nspeech impaired users for personalization. Our results show that\npersonalization achieved 63.7\\% relative word error rate reduction when trained\nin a server environment and 58.1% in a mobile environment. Moving to on-device\npersonalization resulted in 18.7% performance degradation, in exchange for\nimproved scalability and data privacy. To train the model on device, we split\nthe gradient computation into two and achieved 45% memory reduction at the\nexpense of 42% increase in training time.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 21:12:38 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Sim", "Khe Chai", ""], ["Zadrazil", "Petr", ""], ["Beaufays", "Fran\u00e7oise", ""]]}, {"id": "1909.06684", "submitter": "Ali Hatamizadeh", "authors": "Andriy Myronenko and Ali Hatamizadeh", "title": "3D Kidneys and Kidney Tumor Semantic Segmentation using Boundary-Aware\n  Networks", "comments": "Manuscript of MICCAI Kidney Tumor Segmentation Challenge 2019", "journal-ref": "MICCAI Kidney Tumor Segmentation Challenge 2019", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated segmentation of kidneys and kidney tumors is an important step in\nquantifying the tumor's morphometrical details to monitor the progression of\nthe disease and accurately compare decisions regarding the kidney tumor\ntreatment. Manual delineation techniques are often tedious, error-prone and\nrequire expert knowledge for creating unambiguous representation of kidneys and\nkidney tumors segmentation. In this work, we propose an end-to-end boundary\naware fully Convolutional Neural Networks (CNNs) for reliable kidney and kidney\ntumor semantic segmentation from arterial phase abdominal 3D CT scans. We\npropose a segmentation network consisting of an encoder-decoder architecture\nthat specifically accounts for organ and tumor edge information by devising a\ndedicated boundary branch supervised by edge-aware loss terms. We have\nevaluated our model on 2019 MICCAI KiTS Kidney Tumor Segmentation Challenge\ndataset and our method has achieved dice scores of 0.9742 and 0.8103 for kidney\nand tumor repetitively and an overall composite dice score of 0.8923.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 21:49:09 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Myronenko", "Andriy", ""], ["Hatamizadeh", "Ali", ""]]}, {"id": "1909.06686", "submitter": "Shenyang Huang", "authors": "Shenyang Huang, Vincent Fran\\c{c}ois-Lavet, Guillaume Rabusseau", "title": "Neural Architecture Search for Class-incremental Learning", "comments": "8 pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In class-incremental learning, a model learns continuously from a sequential\ndata stream in which new classes occur. Existing methods often rely on static\narchitectures that are manually crafted. These methods can be prone to capacity\nsaturation because a neural network's ability to generalize to new concepts is\nlimited by its fixed capacity. To understand how to expand a continual learner,\nwe focus on the neural architecture design problem in the context of\nclass-incremental learning: at each time step, the learner must optimize its\nperformance on all classes observed so far by selecting the most competitive\nneural architecture. To tackle this problem, we propose Continual Neural\nArchitecture Search (CNAS): an autoML approach that takes advantage of the\nsequential nature of class-incremental learning to efficiently and adaptively\nidentify strong architectures in a continual learning setting. We employ a task\nnetwork to perform the classification task and a reinforcement learning agent\nas the meta-controller for architecture search. In addition, we apply network\ntransformations to transfer weights from previous learning step and to reduce\nthe size of the architecture search space, thus saving a large amount of\ncomputational resources. We evaluate CNAS on the CIFAR-100 dataset under varied\nincremental learning scenarios with limited computational power (1 GPU).\nExperimental results demonstrate that CNAS outperforms architectures that are\noptimized for the entire dataset. In addition, CNAS is at least an order of\nmagnitude more efficient than naively using existing autoML methods.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 22:16:02 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Huang", "Shenyang", ""], ["Fran\u00e7ois-Lavet", "Vincent", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "1909.06695", "submitter": "Qian Yang", "authors": "Qian Yang, Zhouyuan Huo, Wenlin Wang, Heng Huang, Lawrence Carin", "title": "Ouroboros: On Accelerating Training of Transformer-Based Language Models", "comments": "To appear in the proceedings of Neural Information Processing Systems\n  Conference (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models are essential for natural language processing (NLP) tasks,\nsuch as machine translation and text summarization. Remarkable performance has\nbeen demonstrated recently across many NLP domains via a Transformer-based\nlanguage model with over a billion parameters, verifying the benefits of model\nsize. Model parallelism is required if a model is too large to fit in a single\ncomputing device. Current methods for model parallelism either suffer from\nbackward locking in backpropagation or are not applicable to language models.\nWe propose the first model-parallel algorithm that speeds the training of\nTransformer-based language models. We also prove that our proposed algorithm is\nguaranteed to converge to critical points for non-convex problems. Extensive\nexperiments on Transformer and Transformer-XL language models demonstrate that\nthe proposed algorithm obtains a much faster speedup beyond data parallelism,\nwith comparable or better accuracy. Code to reproduce experiments is to be\nfound at \\url{https://github.com/LaraQianYang/Ouroboros}.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 23:21:56 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Yang", "Qian", ""], ["Huo", "Zhouyuan", ""], ["Wang", "Wenlin", ""], ["Huang", "Heng", ""], ["Carin", "Lawrence", ""]]}, {"id": "1909.06708", "submitter": "Zhuohan Li", "authors": "Zhuohan Li, Zi Lin, Di He, Fei Tian, Tao Qin, Liwei Wang, Tie-Yan Liu", "title": "Hint-Based Training for Non-Autoregressive Machine Translation", "comments": "EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the unparallelizable nature of the autoregressive factorization,\nAutoRegressive Translation (ART) models have to generate tokens sequentially\nduring decoding and thus suffer from high inference latency. Non-AutoRegressive\nTranslation (NART) models were proposed to reduce the inference time, but could\nonly achieve inferior translation accuracy. In this paper, we proposed a novel\napproach to leveraging the hints from hidden states and word alignments to help\nthe training of NART models. The results achieve significant improvement over\nprevious NART models for the WMT14 En-De and De-En datasets and are even\ncomparable to a strong LSTM-based ART baseline but one order of magnitude\nfaster in inference.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 01:39:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Li", "Zhuohan", ""], ["Lin", "Zi", ""], ["He", "Di", ""], ["Tian", "Fei", ""], ["Qin", "Tao", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1909.06710", "submitter": "Dhruv Mauria Saxena", "authors": "Dhruv Mauria Saxena, Sangjae Bae, Alireza Nakhaei, Kikuo Fujimura,\n  Maxim Likhachev", "title": "Driving in Dense Traffic with Model-Free Reinforcement Learning", "comments": "Proceedings of the IEEE International Conference on Robotics and\n  Automation (ICRA), 2020. Updated Github repository links", "journal-ref": null, "doi": "10.1109/ICRA40945.2020.9197132", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional planning and control methods could fail to find a feasible\ntrajectory for an autonomous vehicle to execute amongst dense traffic on roads.\nThis is because the obstacle-free volume in spacetime is very small in these\nscenarios for the vehicle to drive through. However, that does not mean the\ntask is infeasible since human drivers are known to be able to drive amongst\ndense traffic by leveraging the cooperativeness of other drivers to open a gap.\nThe traditional methods fail to take into account the fact that the actions\ntaken by an agent affect the behaviour of other vehicles on the road. In this\nwork, we rely on the ability of deep reinforcement learning to implicitly model\nsuch interactions and learn a continuous control policy over the action space\nof an autonomous vehicle. The application we consider requires our agent to\nnegotiate and open a gap in the road in order to successfully merge or change\nlanes. Our policy learns to repeatedly probe into the target road lane while\ntrying to find a safe spot to move in to. We compare against two\nmodel-predictive control-based algorithms and show that our policy outperforms\nthem in simulation.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 01:59:10 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 16:50:59 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Saxena", "Dhruv Mauria", ""], ["Bae", "Sangjae", ""], ["Nakhaei", "Alireza", ""], ["Fujimura", "Kikuo", ""], ["Likhachev", "Maxim", ""]]}, {"id": "1909.06717", "submitter": "Yuhong Guo", "authors": "Yan Yan and Yuhong Guo", "title": "Adversarial Partial Multi-Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial multi-label learning (PML), which tackles the problem of learning\nmulti-label prediction models from instances with overcomplete noisy\nannotations, has recently started gaining attention from the research\ncommunity. In this paper, we propose a novel adversarial learning model,\nPML-GAN, under a generalized encoder-decoder framework for partial multi-label\nlearning. The PML-GAN model uses a disambiguation network to identify noisy\nlabels and uses a multi-label prediction network to map the training instances\nto the disambiguated label vectors, while deploying a generative adversarial\nnetwork as an inverse mapping from label vectors to data samples in the input\nfeature space. The learning of the overall model corresponds to a minimax\nadversarial game, which enhances the correspondence of input features with the\noutput labels in a bi-directional mapping. Extensive experiments are conducted\non multiple datasets, while the proposed model demonstrates the\nstate-of-the-art performance for partial multi-label learning.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 02:34:07 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 04:11:26 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Yan", "Yan", ""], ["Guo", "Yuhong", ""]]}, {"id": "1909.06718", "submitter": "Rheeya Uppaal", "authors": "Rheeya Uppaal", "title": "LRS-DAG: Low Resource Supervised Domain Adaptation with Generalization\n  Across Domains", "comments": "10 pages, 3 figures. Accepted to NewInML Workshop at NeurIPS, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current state of the art methods in Domain Adaptation follow adversarial\napproaches, making training a challenge. Existing non-adversarial methods learn\nmappings between the source and target domains, to achieve reasonable\nperformance. However, even these methods do not focus on a key aspect:\nmaintaining performance on the source domain, even after optimizing over the\ntarget domain. Additionally, there exist very few methods in low resource\nsupervised domain adaptation. This work proposes a method, LRS-DAG, that aims\nto solve these current issues in the field. By adding a set of \"encoder layers\"\nwhich map the target domain to the source, and can be removed when dealing\ndirectly with the source data, the model learns to perform optimally on both\ndomains. LRS-DAG showcases its uniqueness by being a new algorithm for low\nresource domain adaptation which maintains performance over the source domain,\nwith a new metric for learning mappings between domains being introduced. We\nshow that, in the case of FCNs, when transferring from MNIST to SVHN, LRS-DAG\nperforms comparably to fine tuning, with the advantage of maintaining\nperformance over the source domain. LRS-DAG outperforms fine tuning when\ntransferring to a synthetic dataset similar to MNIST, which is a setting more\nrepresentative of low resource supervised domain adaptation.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 02:38:49 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 03:57:30 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Uppaal", "Rheeya", ""]]}, {"id": "1909.06722", "submitter": "Tian Xia", "authors": "Tian Xia, Shaodan Zhai, Shaojun Wang", "title": "Plackett-Luce model for learning-to-rank task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  List-wise based learning to rank methods are generally supposed to have\nbetter performance than point- and pair-wise based. However, in real-world\napplications, state-of-the-art systems are not from list-wise based camp. In\nthis paper, we propose a new non-linear algorithm in the list-wise based\nframework called ListMLE, which uses the Plackett-Luce (PL) loss. Our\nexperiments are conducted on the two largest publicly available real-world\ndatasets, Yahoo challenge 2010 and Microsoft 30K. This is the first time in the\nsingle model level for a list-wise based system to match or overpass\nstate-of-the-art systems in real-world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 03:23:49 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Xia", "Tian", ""], ["Zhai", "Shaodan", ""], ["Wang", "Shaojun", ""]]}, {"id": "1909.06723", "submitter": "Xiaosen Wang", "authors": "Xiaosen Wang, Hao Jin, Yichen Yang, Kun He", "title": "Natural Language Adversarial Defense through Synonym Encoding", "comments": "Accepted by UAI 2021, code is avaliable at\n  https://github.com/JHL-HUST/SEM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the area of natural language processing, deep learning models are recently\nknown to be vulnerable to various types of adversarial perturbations, but\nrelatively few works are done on the defense side. Especially, there exists few\neffective defense method against the successful synonym substitution based\nattacks that preserve the syntactic structure and semantic information of the\noriginal text while fooling the deep learning models. We contribute in this\ndirection and propose a novel adversarial defense method called Synonym\nEncoding Method (SEM). Specifically, SEM inserts an encoder before the input\nlayer of the target model to map each cluster of synonyms to a unique encoding\nand trains the model to eliminate possible adversarial perturbations without\nmodifying the network architecture or adding extra data. Extensive experiments\ndemonstrate that SEM can effectively defend the current synonym substitution\nbased attacks and block the transferability of adversarial examples. SEM is\nalso easy and efficient to scale to large models and big datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 03:35:18 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 06:11:54 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 01:23:25 GMT"}, {"version": "v4", "created": "Tue, 15 Jun 2021 02:08:45 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Wang", "Xiaosen", ""], ["Jin", "Hao", ""], ["Yang", "Yichen", ""], ["He", "Kun", ""]]}, {"id": "1909.06727", "submitter": "Sen Chen", "authors": "Qianyu Guo, Sen Chen, Xiaofei Xie, Lei Ma, Qiang Hu, Hongtao Liu, Yang\n  Liu, Jianjun Zhao, Xiaohong Li", "title": "An Empirical Study towards Characterizing Deep Learning Development and\n  Deployment across Different Frameworks and Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) has recently achieved tremendous success. A variety of DL\nframeworks and platforms play a key role to catalyze such progress. However,\nthe differences in architecture designs and implementations of existing\nframeworks and platforms bring new challenges for DL software development and\ndeployment. Till now, there is no study on how various mainstream frameworks\nand platforms influence both DL software development and deployment in\npractice. To fill this gap, we take the first step towards understanding how\nthe most widely-used DL frameworks and platforms support the DL software\ndevelopment and deployment. We conduct a systematic study on these frameworks\nand platforms by using two types of DNN architectures and three popular\ndatasets. (1) For development process, we investigate the prediction accuracy\nunder the same runtime training configuration or same model weights/biases. We\nalso study the adversarial robustness of trained models by leveraging the\nexisting adversarial attack techniques. The experimental results show that the\ncomputing differences across frameworks could result in an obvious prediction\naccuracy decline, which should draw the attention of DL developers. (2) For\ndeployment process, we investigate the prediction accuracy and performance\n(refers to time cost and memory consumption) when the trained models are\nmigrated/quantized from PC to real mobile devices and web browsers. The DL\nplatform study unveils that the migration and quantization still suffer from\ncompatibility and reliability issues. Meanwhile, we find several DL software\nbugs by using the results as a benchmark. We further validate the results\nthrough bug confirmation from stakeholders and industrial positive feedback to\nhighlight the implications of our study. Through our study, we summarize\npractical guidelines, identify challenges and pinpoint new research directions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 04:01:39 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Guo", "Qianyu", ""], ["Chen", "Sen", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Hu", "Qiang", ""], ["Liu", "Hongtao", ""], ["Liu", "Yang", ""], ["Zhao", "Jianjun", ""], ["Li", "Xiaohong", ""]]}, {"id": "1909.06730", "submitter": "Xiuting Li", "authors": "Ye Yuan, Junlin Li, Liang Li, Frank Jiang, Xiuchuan Tang, Fumin Zhang,\n  Sheng Liu, Jorge Goncalves, Henning U.Voss, Xiuting Li, J\\\"urgen Kurths, and\n  Han Ding", "title": "Machine Discovery of Partial Differential Equations from Spatiotemporal\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study presents a general framework for discovering underlying Partial\nDifferential Equations (PDEs) using measured spatiotemporal data. The method,\ncalled Sparse Spatiotemporal System Discovery ($\\text{S}^3\\text{d}$), decides\nwhich physical terms are necessary and which can be removed (because they are\nphysically negligible in the sense that they do not affect the dynamics too\nmuch) from a pool of candidate functions. The method is built on the recent\ndevelopment of Sparse Bayesian Learning; which enforces the sparsity in the\nto-be-identified PDEs, and therefore can balance the model complexity and\nfitting error with theoretical guarantees. Without leveraging prior knowledge\nor assumptions in the discovery process, we use an automated approach to\ndiscover ten types of PDEs, including the famous Navier-Stokes and sine-Gordon\nequations, from simulation data alone. Moreover, we demonstrate our data-driven\ndiscovery process with the Complex Ginzburg-Landau Equation (CGLE) using data\nmeasured from a traveling-wave convection experiment. Our machine discovery\napproach presents solutions that has the potential to inspire, support and\nassist physicists for the establishment of physical laws from measured\nspatiotemporal data, especially in notorious fields that are often too complex\nto allow a straightforward establishment of physical law, such as biophysics,\nfluid dynamics, neuroscience or nonlinear optics.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 04:30:48 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Yuan", "Ye", ""], ["Li", "Junlin", ""], ["Li", "Liang", ""], ["Jiang", "Frank", ""], ["Tang", "Xiuchuan", ""], ["Zhang", "Fumin", ""], ["Liu", "Sheng", ""], ["Goncalves", "Jorge", ""], ["Voss", "Henning U.", ""], ["Li", "Xiuting", ""], ["Kurths", "J\u00fcrgen", ""], ["Ding", "Han", ""]]}, {"id": "1909.06731", "submitter": "Yoshihiko Suhara", "authors": "Wataru Hirota, Yoshihiko Suhara, Behzad Golshan, Wang-Chiew Tan", "title": "Emu: Enhancing Multilingual Sentence Embeddings with Semantic\n  Specialization", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Emu, a system that semantically enhances multilingual sentence\nembeddings. Our framework fine-tunes pre-trained multilingual sentence\nembeddings using two main components: a semantic classifier and a language\ndiscriminator. The semantic classifier improves the semantic similarity of\nrelated sentences, whereas the language discriminator enhances the\nmultilinguality of the embeddings via multilingual adversarial training. Our\nexperimental results based on several language pairs show that our specialized\nembeddings outperform the state-of-the-art multilingual sentence embedding\nmodel on the task of cross-lingual intent classification using only monolingual\nlabeled data.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 04:31:21 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 17:21:37 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hirota", "Wataru", ""], ["Suhara", "Yoshihiko", ""], ["Golshan", "Behzad", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "1909.06737", "submitter": "Dongha Kim", "authors": "Dongha Kim, Yongchan Choi, Yongdai Kim", "title": "Understanding and Improving Virtual Adversarial Training", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In semi-supervised learning, virtual adversarial training (VAT) approach is\none of the most attractive method due to its intuitional simplicity and\npowerful performances. VAT finds a classifier which is robust to data\nperturbation toward the adversarial direction. In this study, we provide a\nfundamental explanation why VAT works well in semi-supervised learning case and\npropose new techniques which are simple but powerful to improve the VAT method.\nEspecially we employ the idea of Bad GAN approach, which utilizes bad samples\ndistributed on complement of the support of the input data, without any\nadditional deep generative architectures. We generate bad samples of\nhigh-quality by use of the adversarial training used in VAT and also give\ntheoretical explanations why the adversarial training is good at both\ngenerating bad samples. An advantage of our proposed method is to achieve the\ncompetitive performances compared with other recent studies with much fewer\ncomputations. We demonstrate advantages our method by various experiments with\nwell known benchmark image datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 05:03:08 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kim", "Dongha", ""], ["Choi", "Yongchan", ""], ["Kim", "Yongdai", ""]]}, {"id": "1909.06743", "submitter": "Harsh Jhamtani", "authors": "Harsh Jhamtani, Sanket Vaibhav Mehta, Jaime Carbonell, Taylor\n  Berg-Kirkpatrick", "title": "Learning Rhyming Constraints using Structured Adversaries", "comments": "EMNLP-IJCNLP 2019 Short Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing recurrent neural language models often fail to capture higher-level\nstructure present in text: for example, rhyming patterns present in poetry.\nMuch prior work on poetry generation uses manually defined constraints which\nare satisfied during decoding using either specialized decoding procedures or\nrejection sampling. The rhyming constraints themselves are typically not\nlearned by the generator. We propose an alternate approach that uses a\nstructured discriminator to learn a poetry generator that directly captures\nrhyming constraints in a generative adversarial setup. By causing the\ndiscriminator to compare poems based only on a learned similarity matrix of\npairs of line ending words, the proposed approach is able to successfully learn\nrhyming patterns in two different English poetry datasets (Sonnet and Limerick)\nwithout explicitly being provided with any phonetic information.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 05:58:09 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Jhamtani", "Harsh", ""], ["Mehta", "Sanket Vaibhav", ""], ["Carbonell", "Jaime", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1909.06761", "submitter": "Georgios Kapidis", "authors": "Georgios Kapidis, Ronald Poppe, Elsbeth van Dam, Lucas Noldus, Remco\n  Veltkamp", "title": "Multitask Learning to Improve Egocentric Action Recognition", "comments": "10 pages, 3 figures, accepted at the 5th Egocentric Perception,\n  Interaction and Computing (EPIC) workshop at ICCV 2019, code repository:\n  https://github.com/georkap/hand_track_classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we employ multitask learning to capitalize on the structure that\nexists in related supervised tasks to train complex neural networks. It allows\ntraining a network for multiple objectives in parallel, in order to improve\nperformance on at least one of them by capitalizing on a shared representation\nthat is developed to accommodate more information than it otherwise would for a\nsingle task. We employ this idea to tackle action recognition in egocentric\nvideos by introducing additional supervised tasks. We consider learning the\nverbs and nouns from which action labels consist of and predict coordinates\nthat capture the hand locations and the gaze-based visual saliency for all the\nframes of the input video segments. This forces the network to explicitly focus\non cues from secondary tasks that it might otherwise have missed resulting in\nimproved inference. Our experiments on EPIC-Kitchens and EGTEA Gaze+ show\nconsistent improvements when training with multiple tasks over the single-task\nbaseline. Furthermore, in EGTEA Gaze+ we outperform the state-of-the-art in\naction recognition by 3.84%. Apart from actions, our method produces accurate\nhand and gaze estimations as side tasks, without requiring any additional input\nat test time other than the RGB video clips.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 08:29:46 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kapidis", "Georgios", ""], ["Poppe", "Ronald", ""], ["van Dam", "Elsbeth", ""], ["Noldus", "Lucas", ""], ["Veltkamp", "Remco", ""]]}, {"id": "1909.06769", "submitter": "Voot Tangkaratt", "authors": "Voot Tangkaratt, Bo Han, Mohammad Emtiyaz Khan, and Masashi Sugiyama", "title": "VILD: Variational Imitation Learning with Diverse-quality Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of imitation learning (IL) is to learn a good policy from\nhigh-quality demonstrations. However, the quality of demonstrations in reality\ncan be diverse, since it is easier and cheaper to collect demonstrations from a\nmix of experts and amateurs. IL in such situations can be challenging,\nespecially when the level of demonstrators' expertise is unknown. We propose a\nnew IL method called \\underline{v}ariational \\underline{i}mitation\n\\underline{l}earning with \\underline{d}iverse-quality demonstrations (VILD),\nwhere we explicitly model the level of demonstrators' expertise with a\nprobabilistic graphical model and estimate it along with a reward function. We\nshow that a naive approach to estimation is not suitable to large state and\naction spaces, and fix its issues by using a variational approach which can be\neasily implemented using existing reinforcement learning methods. Experiments\non continuous-control benchmarks demonstrate that VILD outperforms\nstate-of-the-art methods. Our work enables scalable and data-efficient IL under\nmore realistic settings than before.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 09:42:33 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Tangkaratt", "Voot", ""], ["Han", "Bo", ""], ["Khan", "Mohammad Emtiyaz", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1909.06772", "submitter": "Orpaz Goldstein", "authors": "Orpaz Goldstein, Mohammad Kachuee, Kimmo Karkkainen, Majid Sarrafzadeh", "title": "Target-Focused Feature Selection Using a Bayesian Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world scenarios where data is high dimensional, test time\nacquisition of features is a non-trivial task due to costs associated with\nfeature acquisition and evaluating feature value. The need for highly confident\nmodels with an extremely frugal acquisition of features can be addressed by\nallowing a feature selection method to become target aware. We introduce an\napproach to feature selection that is based on Bayesian learning, allowing us\nto report target-specific levels of uncertainty, false positive, and false\nnegative rates. In addition, measuring uncertainty lifts the restriction on\nfeature selection being target agnostic, allowing for feature acquisition based\non a single target of focus out of many. We show that acquiring features for a\nspecific target is at least as good as common linear feature selection\napproaches for small non-sparse datasets, and surpasses these when faced with\nreal-world healthcare data that is larger in scale and in sparseness.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 09:58:35 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Goldstein", "Orpaz", ""], ["Kachuee", "Mohammad", ""], ["Karkkainen", "Kimmo", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1909.06788", "submitter": "Zhenyu Liao", "authors": "Zhenyu Liao, Romain Couillet", "title": "Inner-product Kernels are Asymptotically Equivalent to Binary Discrete\n  Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates the eigenspectrum of the inner product-type kernel\nmatrix $\\sqrt{p} \\mathbf{K}=\\{f( \\mathbf{x}_i^{\\sf T}\n\\mathbf{x}_j/\\sqrt{p})\\}_{i,j=1}^n $ under a binary mixture model in the high\ndimensional regime where the number of data $n$ and their dimension $p$ are\nboth large and comparable. Based on recent advances in random matrix theory, we\nshow that, for a wide range of nonlinear functions $f$, the eigenspectrum\nbehavior is asymptotically equivalent to that of an (at most) cubic function.\nThis sheds new light on the understanding of nonlinearity in large dimensional\nproblems. As a byproduct, we propose a simple function prototype valued in $\n(-1,0,1) $ that, while reducing both storage memory and running time, achieves\nthe same (asymptotic) classification performance as any arbitrary function $f$.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 11:52:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Liao", "Zhenyu", ""], ["Couillet", "Romain", ""]]}, {"id": "1909.06804", "submitter": "Jason Kuen", "authors": "Jason Kuen, Federico Perazzi, Zhe Lin, Jianming Zhang, Yap-Peng Tan", "title": "Scaling Object Detection by Transferring Classification Weights", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale object detection datasets are constantly increasing their size in\nterms of the number of classes and annotations count. Yet, the number of\nobject-level categories annotated in detection datasets is an order of\nmagnitude smaller than image-level classification labels. State-of-the art\nobject detection models are trained in a supervised fashion and this limits the\nnumber of object classes they can detect. In this paper, we propose a novel\nweight transfer network (WTN) to effectively and efficiently transfer knowledge\nfrom classification network's weights to detection network's weights to allow\ndetection of novel classes without box supervision. We first introduce input\nand feature normalization schemes to curb the under-fitting during training of\na vanilla WTN. We then propose autoencoder-WTN (AE-WTN) which uses\nreconstruction loss to preserve classification network's information over all\nclasses in the target latent space to ensure generalization to novel classes.\nCompared to vanilla WTN, AE-WTN obtains absolute performance gains of 6% on two\nOpen Images evaluation sets with 500 seen and 57 novel classes respectively,\nand 25% on a Visual Genome evaluation set with 200 novel classes. The code is\navailable at https://github.com/xternalz/AE-WTN.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 13:59:29 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kuen", "Jason", ""], ["Perazzi", "Federico", ""], ["Lin", "Zhe", ""], ["Zhang", "Jianming", ""], ["Tan", "Yap-Peng", ""]]}, {"id": "1909.06814", "submitter": "Leshem Choshen", "authors": "Leshem Choshen and Omri Abend", "title": "Automatically Extracting Challenge Sets for Non local Phenomena in\n  Neural Machine Translation", "comments": "Accepted for CoNLL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the state of the art Transformer Machine Translation (MT) model\nis not biased towards monotonic reordering (unlike previous recurrent neural\nnetwork models), but that nevertheless, long-distance dependencies remain a\nchallenge for the model. Since most dependencies are short-distance, common\nevaluation metrics will be little influenced by how well systems perform on\nthem. We, therefore, propose an automatic approach for extracting challenge\nsets replete with long-distance dependencies and argue that evaluation using\nthis methodology provides a complementary perspective on system performance. To\nsupport our claim, we compile challenge sets for English-German and\nGerman-English, which are much larger than any previously released challenge\nset for MT. The extracted sets are large enough to allow reliable automatic\nevaluation, which makes the proposed approach a scalable and practical solution\nfor evaluating MT performance on the long-tail of syntactic phenomena.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 15:21:20 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 08:26:01 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 06:29:07 GMT"}, {"version": "v4", "created": "Wed, 25 Sep 2019 08:18:21 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Choshen", "Leshem", ""], ["Abend", "Omri", ""]]}, {"id": "1909.06840", "submitter": "Konstantin Ushenin", "authors": "Alexander Karimov, Artem Razumov, Ruslana Manbatchurina, Ksenia\n  Simonova, Irina Donets, Anastasia Vlasova, Yulia Khramtsova, Konstantin\n  Ushenin", "title": "Comparison of UNet, ENet, and BoxENet for Segmentation of Mast Cells in\n  Scans of Histological Slices", "comments": "4 pages, 5 figures, 1 table", "journal-ref": null, "doi": "10.1109/SIBIRCON48586.2019.8958121", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks show high accuracy in theproblem of semantic and\ninstance segmentation of biomedicaldata. However, this approach is\ncomputationally expensive. Thecomputational cost may be reduced with network\nsimplificationafter training or choosing the proper architecture, which\nprovidessegmentation with less accuracy but does it much faster. In thepresent\nstudy, we analyzed the accuracy and performance ofUNet and ENet architectures\nfor the problem of semantic imagesegmentation. In addition, we investigated the\nENet architecture by replacing of some convolution layers with\nbox-convolutionlayers. The analysis performed on the original dataset consisted\nof histology slices with mast cells. These cells provide a region\nforsegmentation with different types of borders, which vary fromclearly visible\nto ragged. ENet was less accurate than UNet byonly about 1-2%, but ENet\nperformance was 8-15 times faster than UNet one.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 17:26:56 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 00:31:19 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 16:14:21 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Karimov", "Alexander", ""], ["Razumov", "Artem", ""], ["Manbatchurina", "Ruslana", ""], ["Simonova", "Ksenia", ""], ["Donets", "Irina", ""], ["Vlasova", "Anastasia", ""], ["Khramtsova", "Yulia", ""], ["Ushenin", "Konstantin", ""]]}, {"id": "1909.06841", "submitter": "Ernesto Araya Valdivia", "authors": "Ernesto Araya and Yohann De Castro", "title": "Latent Distance Estimation for Random Geometric Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random geometric graphs are a popular choice for a latent points generative\nmodel for networks. Their definition is based on a sample of $n$ points\n$X_1,X_2,\\cdots,X_n$ on the Euclidean sphere~$\\mathbb{S}^{d-1}$ which\nrepresents the latent positions of nodes of the network. The connection\nprobabilities between the nodes are determined by an unknown function (referred\nto as the \"link\" function) evaluated at the distance between the latent points.\nWe introduce a spectral estimator of the pairwise distance between latent\npoints and we prove that its rate of convergence is the same as the\nnonparametric estimation of a function on $\\mathbb{S}^{d-1}$, up to a\nlogarithmic factor. In addition, we provide an efficient spectral algorithm to\ncompute this estimator without any knowledge on the nonparametric link\nfunction. As a byproduct, our method can also consistently estimate the\ndimension $d$ of the latent space.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 17:30:03 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Araya", "Ernesto", ""], ["De Castro", "Yohann", ""]]}, {"id": "1909.06842", "submitter": "Yuxin Wang", "authors": "Yuxin Wang, Qiang Wang, Shaohuai Shi, Xin He, Zhenheng Tang, Kaiyong\n  Zhao, Xiaowen Chu", "title": "Benchmarking the Performance and Energy Efficiency of AI Accelerators\n  for AI Training", "comments": "Revised some minor issues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become widely used in complex AI applications. Yet,\ntraining a deep neural network (DNNs) model requires a considerable amount of\ncalculations, long running time, and much energy. Nowadays, many-core AI\naccelerators (e.g., GPUs and TPUs) are designed to improve the performance of\nAI training. However, processors from different vendors perform dissimilarly in\nterms of performance and energy consumption. To investigate the differences\namong several popular off-the-shelf processors (i.e., Intel CPU, NVIDIA GPU,\nAMD GPU, and Google TPU) in training DNNs, we carry out a comprehensive\nempirical study on the performance and energy efficiency of these processors by\nbenchmarking a representative set of deep learning workloads, including\ncomputation-intensive operations, classical convolutional neural networks\n(CNNs), recurrent neural networks (LSTM), Deep Speech 2, and Transformer.\nDifferent from the existing end-to-end benchmarks which only present the\ntraining time, We try to investigate the impact of hardware, vendor's software\nlibrary, and deep learning framework on the performance and energy consumption\nof AI training. Our evaluation methods and results not only provide an\ninformative guide for end-users to select proper AI accelerators, but also\nexpose some opportunities for the hardware vendors to improve their software\nlibrary.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 17:30:05 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 06:25:01 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 19:55:20 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 17:28:19 GMT"}, {"version": "v5", "created": "Thu, 21 Nov 2019 05:30:27 GMT"}, {"version": "v6", "created": "Sat, 23 May 2020 17:32:51 GMT"}, {"version": "v7", "created": "Tue, 26 May 2020 01:56:31 GMT"}, {"version": "v8", "created": "Fri, 10 Jul 2020 10:42:11 GMT"}, {"version": "v9", "created": "Thu, 8 Oct 2020 18:29:34 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Wang", "Yuxin", ""], ["Wang", "Qiang", ""], ["Shi", "Shaohuai", ""], ["He", "Xin", ""], ["Tang", "Zhenheng", ""], ["Zhao", "Kaiyong", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1909.06844", "submitter": "Michael Schaarschmidt", "authors": "Michael Schaarschmidt, Kai Fricke, Eiko Yoneki", "title": "Wield: Systematic Reinforcement Learning With Progressive Randomization", "comments": "10 pages, draft paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning frameworks have introduced abstractions to implement\nand execute algorithms at scale. They assume standardized simulator interfaces\nbut are not concerned with identifying suitable task representations. We\npresent Wield, a first-of-its kind system to facilitate task design for\npractical reinforcement learning. Through software primitives, Wield enables\npractitioners to decouple system-interface and deployment-specific\nconfiguration from state and action design. To guide experimentation, Wield\nfurther introduces a novel task design protocol and classification scheme\ncentred around staged randomization to incrementally evaluate model\ncapabilities.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 17:36:26 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Schaarschmidt", "Michael", ""], ["Fricke", "Kai", ""], ["Yoneki", "Eiko", ""]]}, {"id": "1909.06851", "submitter": "Zhizhong Li", "authors": "Lanxin Lei and Zhizhong Li and Dahua Lin", "title": "Biased Estimates of Advantages over Path Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of advantage is crucial for a number of reinforcement learning\nalgorithms, as it directly influences the choices of future paths. In this\nwork, we propose a family of estimates based on the order statistics over the\npath ensemble, which allows one to flexibly drive the learning process, towards\nor against risks. On top of this formulation, we systematically study the\nimpacts of different methods for estimating advantages. Our findings reveal\nthat biased estimates, when chosen appropriately, can result in significant\nbenefits. In particular, for the environments with sparse rewards, optimistic\nestimates would lead to more efficient exploration of the policy space; while\nfor those where individual actions can have critical impacts, conservative\nestimates are preferable. On various benchmarks, including MuJoCo continuous\ncontrol, Terrain locomotion, Atari games, and sparse-reward environments, the\nproposed biased estimation schemes consistently demonstrate improvement over\nmainstream methods, not only accelerating the learning process but also\nobtaining substantial performance gains.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 18:16:18 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Lei", "Lanxin", ""], ["Li", "Zhizhong", ""], ["Lin", "Dahua", ""]]}, {"id": "1909.06859", "submitter": "Shihao Zou", "authors": "Shihao Zou, Zhonghua Li, Mohammad Akbari, Jun Wang, Peng Zhang", "title": "MarlRank: Multi-agent Reinforced Learning to Rank", "comments": "CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When estimating the relevancy between a query and a document, ranking models\nlargely neglect the mutual information among documents. A common wisdom is that\nif two documents are similar in terms of the same query, they are more likely\nto have similar relevance score. To mitigate this problem, in this paper, we\npropose a multi-agent reinforced ranking model, named MarlRank. In particular,\nby considering each document as an agent, we formulate the ranking process as a\nmulti-agent Markov Decision Process (MDP), where the mutual interactions among\ndocuments are incorporated in the ranking process. To compute the ranking list,\neach document predicts its relevance to a query considering not only its own\nquery-document features but also its similar documents features and actions. By\ndefining reward as a function of NDCG, we can optimize our model directly on\nthe ranking performance measure. Our experimental results on two LETOR\nbenchmark datasets show that our model has significant performance gains over\nthe state-of-art baselines. We also find that the NDCG shows an overall\nincreasing trend along with the step of interactions, which demonstrates that\nthe mutual information among documents helps improve the ranking performance.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 19:08:08 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Zou", "Shihao", ""], ["Li", "Zhonghua", ""], ["Akbari", "Mohammad", ""], ["Wang", "Jun", ""], ["Zhang", "Peng", ""]]}, {"id": "1909.06860", "submitter": "Guido F. Montufar", "authors": "Alex Tong Lin, Yonatan Dukler, Wuchen Li, Guido Montufar", "title": "Wasserstein Diffusion Tikhonov Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose regularization strategies for learning discriminative models that\nare robust to in-class variations of the input data. We use the Wasserstein-2\ngeometry to capture semantically meaningful neighborhoods in the space of\nimages, and define a corresponding input-dependent additive noise data\naugmentation model. Expanding and integrating the augmented loss yields an\neffective Tikhonov-type Wasserstein diffusion smoothness regularizer. This\napproach allows us to apply high levels of regularization and train functions\nthat have low variability within classes but remain flexible across classes. We\nprovide efficient methods for computing the regularizer at a negligible cost in\ncomparison to training with adversarial data augmentation. Initial experiments\ndemonstrate improvements in generalization performance under adversarial\nperturbations and also large in-class variations of the input data.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 19:10:16 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Lin", "Alex Tong", ""], ["Dukler", "Yonatan", ""], ["Li", "Wuchen", ""], ["Montufar", "Guido", ""]]}, {"id": "1909.06861", "submitter": "Guy Rom", "authors": "Vincent Cohen-Addad, Benjamin Guedj, Varun Kanade, Guy Rom", "title": "Online k-means Clustering", "comments": "11 pages, 1 figure", "journal-ref": "Proceedings of The 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS), PMLR 130:1126-1134, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online clustering where a clustering algorithm has to\nassign a new point that arrives to one of $k$ clusters. The specific\nformulation we use is the $k$-means objective: At each time step the algorithm\nhas to maintain a set of k candidate centers and the loss incurred is the\nsquared distance between the new point and the closest center. The goal is to\nminimize regret with respect to the best solution to the $k$-means objective\n($\\mathcal{C}$) in hindsight. We show that provided the data lies in a bounded\nregion, an implementation of the Multiplicative Weights Update Algorithm (MWUA)\nusing a discretized grid achieves a regret bound of $\\tilde{O}(\\sqrt{T})$ in\nexpectation. We also present an online-to-offline reduction that shows that an\nefficient no-regret online algorithm (despite being allowed to choose a\ndifferent set of candidate centres at each round) implies an offline efficient\nalgorithm for the $k$-means problem. In light of this hardness, we consider the\nslightly weaker requirement of comparing regret with respect to $(1 + \\epsilon)\n\\mathcal{C}$ and present a no-regret algorithm with runtime\n$O\\left(T(\\mathrm{poly}(log(T),k,d,1/\\epsilon)^{k(d+O(1))}\\right)$. Our\nalgorithm is based on maintaining an incremental coreset and an adaptive\nvariant of the MWUA. We show that na\\\"{i}ve online algorithms, such as\n\\emph{Follow The Leader}, fail to produce sublinear regret in the worst case.\nWe also report preliminary experiments with synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 19:20:36 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Cohen-Addad", "Vincent", ""], ["Guedj", "Benjamin", ""], ["Kanade", "Varun", ""], ["Rom", "Guy", ""]]}, {"id": "1909.06865", "submitter": "Miles Q. Li", "authors": "Miles Q. Li, Benjamin C. M. Fung, Philippe Charland, Steven H.H. Ding", "title": "I-MAD: Interpretable Malware Detector Using Galaxy Transformer", "comments": "Published by Elsevier Computers & Security", "journal-ref": null, "doi": "10.1016/j.cose.2021.102371", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware currently presents a number of serious threats to computer users.\nSignature-based malware detection methods are limited in detecting new malware\nsamples that are significantly different from known ones. Therefore, machine\nlearning-based methods have been proposed, but there are two challenges these\nmethods face. The first is to model the full semantics behind the assembly code\nof malware. The second challenge is to provide interpretable results while\nkeeping excellent detection performance. In this paper, we propose an\nInterpretable MAlware Detector (I-MAD) that outperforms state-of-the-art static\nmalware detection models regarding accuracy with excellent interpretability. To\nimprove the detection performance, I-MAD incorporates a novel network component\ncalled the Galaxy Transformer network that can understand assembly code at the\nbasic block, function, and executable levels. It also incorporates our proposed\ninterpretable feed-forward neural network to provide interpretations for its\ndetection results by quantifying the impact of each feature with respect to the\nprediction. Experiment results show that our model significantly outperforms\nexisting state-of-the-art static malware detection models and presents\nmeaningful interpretations.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 19:40:38 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 14:37:26 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 01:33:26 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Li", "Miles Q.", ""], ["Fung", "Benjamin C. M.", ""], ["Charland", "Philippe", ""], ["Ding", "Steven H. H.", ""]]}, {"id": "1909.06868", "submitter": "Ali Khodadadi", "authors": "Ali Khodadadi, Seyed Abbas Hosseini, Ehsan Pajouheshgar, Farnam\n  Mansouri, and Hamid R. Rabiee", "title": "ChOracle: A Unified Statistical Framework for Churn Prediction", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User churn is an important issue in online services that threatens the health\nand profitability of services. Most of the previous works on churn prediction\nconvert the problem into a binary classification task where the users are\nlabeled as churned and non-churned. More recently, some works have tried to\nconvert the user churn prediction problem into the prediction of user return\ntime. In this approach which is more realistic in real world online services,\nat each time-step the model predicts the user return time instead of predicting\na churn label. However, the previous works in this category suffer from lack of\ngenerality and require high computational complexity. In this paper, we\nintroduce \\emph{ChOracle}, an oracle that predicts the user churn by modeling\nthe user return times to service by utilizing a combination of Temporal Point\nProcesses and Recurrent Neural Networks. Moreover, we incorporate latent\nvariables into the proposed recurrent neural network to model the latent user\nloyalty to the system. We also develop an efficient approximate variational\nalgorithm for learning parameters of the proposed RNN by using back propagation\nthrough time. Finally, we demonstrate the superior performance of ChOracle on a\nwide variety of real world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 19:59:13 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Khodadadi", "Ali", ""], ["Hosseini", "Seyed Abbas", ""], ["Pajouheshgar", "Ehsan", ""], ["Mansouri", "Farnam", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1909.06872", "submitter": "Gilad Cohen", "authors": "Gilad Cohen, Guillermo Sapiro, Raja Giryes", "title": "Detecting Adversarial Samples Using Influence Functions and Nearest\n  Neighbors", "comments": "Paper accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are notorious for their vulnerability to\nadversarial attacks, which are small perturbations added to their input images\nto mislead their prediction. Detection of adversarial examples is, therefore, a\nfundamental requirement for robust classification frameworks. In this work, we\npresent a method for detecting such adversarial attacks, which is suitable for\nany pre-trained neural network classifier. We use influence functions to\nmeasure the impact of every training sample on the validation set data. From\nthe influence scores, we find the most supportive training samples for any\ngiven validation example. A k-nearest neighbor (k-NN) model fitted on the DNN's\nactivation layers is employed to search for the ranking of these supporting\ntraining samples. We observe that these samples are highly correlated with the\nnearest neighbors of the normal inputs, while this correlation is much weaker\nfor adversarial inputs. We train an adversarial detector using the k-NN ranks\nand distances and show that it successfully distinguishes adversarial examples,\ngetting state-of-the-art results on six attack methods with three datasets.\nCode is available at https://github.com/giladcohen/NNIF_adv_defense.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 20:07:48 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 10:41:34 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Cohen", "Gilad", ""], ["Sapiro", "Guillermo", ""], ["Giryes", "Raja", ""]]}, {"id": "1909.06878", "submitter": "Yilun Du", "authors": "Yilun Du, Toru Lin, Igor Mordatch", "title": "Model Based Planning with Energy Based Models", "comments": "CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based planning holds great promise for improving both sample efficiency\nand generalization in reinforcement learning (RL). We show that energy-based\nmodels (EBMs) are a promising class of models to use for model-based planning.\nEBMs naturally support inference of intermediate states given start and goal\nstate distributions. We provide an online algorithm to train EBMs while\ninteracting with the environment, and show that EBMs allow for significantly\nbetter online learning than corresponding feed-forward networks. We further\nshow that EBMs support maximum entropy state inference and are able to generate\ndiverse state space plans. We show that inference purely in state space -\nwithout planning actions - allows for better generalization to previously\nunseen obstacles in the environment and prevents the planner from exploiting\nthe dynamics model by applying uncharacteristic action sequences. Finally, we\nshow that online EBM training naturally leads to intentionally planned state\nexploration which performs significantly better than random exploration.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 20:28:03 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 05:02:16 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Du", "Yilun", ""], ["Lin", "Toru", ""], ["Mordatch", "Igor", ""]]}, {"id": "1909.06886", "submitter": "Xueping Peng", "authors": "Xueping Peng, Guodong Long, Tao Shen, Sen Wang, Jing Jiang, Michael\n  Blumenstein", "title": "Temporal Self-Attention Network for Medical Concept Embedding", "comments": "10 pages, 7 figures, accepted at IEEE ICDM 2019", "journal-ref": null, "doi": "10.1109/ICDM.2019.00060", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In longitudinal electronic health records (EHRs), the event records of a\npatient are distributed over a long period of time and the temporal relations\nbetween the events reflect sufficient domain knowledge to benefit prediction\ntasks such as the rate of inpatient mortality. Medical concept embedding as a\nfeature extraction method that transforms a set of medical concepts with a\nspecific time stamp into a vector, which will be fed into a supervised learning\nalgorithm. The quality of the embedding significantly determines the learning\nperformance over the medical data. In this paper, we propose a medical concept\nembedding method based on applying a self-attention mechanism to represent each\nmedical concept. We propose a novel attention mechanism which captures the\ncontextual information and temporal relationships between medical concepts. A\nlight-weight neural net, \"Temporal Self-Attention Network (TeSAN)\", is then\nproposed to learn medical concept embedding based solely on the proposed\nattention mechanism. To test the effectiveness of our proposed methods, we have\nconducted clustering and prediction tasks on two public EHRs datasets comparing\nTeSAN against five state-of-the-art embedding methods. The experimental results\ndemonstrate that the proposed TeSAN model is superior to all the compared\nmethods. To the best of our knowledge, this work is the first to exploit\ntemporal self-attentive relations between medical events.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 21:20:09 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Peng", "Xueping", ""], ["Long", "Guodong", ""], ["Shen", "Tao", ""], ["Wang", "Sen", ""], ["Jiang", "Jing", ""], ["Blumenstein", "Michael", ""]]}, {"id": "1909.06892", "submitter": "Shubham Jain", "authors": "Shubham Jain, Sumeet Kumar Gupta, Anand Raghunathan", "title": "TiM-DNN: Ternary in-Memory accelerator for Deep Neural Networks", "comments": "12 pages, 18 figures, Accepted in IEEE Transactions on Very Large\n  Scale Integration (VLSI) Systems 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CV cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of lower precision has emerged as a popular technique to optimize the\ncompute and storage requirements of complex Deep Neural Networks (DNNs). In the\nquest for lower precision, recent studies have shown that ternary DNNs (which\nrepresent weights and activations by signed ternary values) represent a\npromising sweet spot, achieving accuracy close to full-precision networks on\ncomplex tasks. We propose TiM-DNN, a programmable in-memory accelerator that is\nspecifically designed to execute ternary DNNs. TiM-DNN supports various ternary\nrepresentations including unweighted {-1,0,1}, symmetric weighted {-a,0,a}, and\nasymmetric weighted {-a,0,b} ternary systems. The building blocks of TiM-DNN\nare TiM tiles -- specialized memory arrays that perform massively parallel\nsigned ternary vector-matrix multiplications with a single access. TiM tiles\nare in turn composed of Ternary Processing Cells (TPCs), bit-cells that\nfunction as both ternary storage units and signed ternary multiplication units.\nWe evaluate an implementation of TiM-DNN in 32nm technology using an\narchitectural simulator calibrated with SPICE simulations and RTL synthesis. We\nevaluate TiM-DNN across a suite of state-of-the-art DNN benchmarks including\nboth deep convolutional and recurrent neural networks. A 32-tile instance of\nTiM-DNN achieves a peak performance of 114 TOPs/s, consumes 0.9W power, and\noccupies 1.96mm2 chip area, representing a 300X and 388X improvement in TOPS/W\nand TOPS/mm2, respectively, compared to an NVIDIA Tesla V100 GPU. In comparison\nto specialized DNN accelerators, TiM-DNN achieves 55X-240X and 160X-291X\nimprovement in TOPS/W and TOPS/mm2, respectively. Finally, when compared to a\nwell-optimized near-memory accelerator for ternary DNNs, TiM-DNN demonstrates\n3.9x-4.7x improvement in system-level energy and 3.2x-4.2x speedup,\nunderscoring the potential of in-memory computing for ternary DNNs.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 21:43:19 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 03:59:26 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 02:42:18 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Jain", "Shubham", ""], ["Gupta", "Sumeet Kumar", ""], ["Raghunathan", "Anand", ""]]}, {"id": "1909.06893", "submitter": "Daniel Wilke", "authors": "Younghwan Chae and Daniel N. Wilke", "title": "Empirical study towards understanding line search approximations for\n  training neural networks", "comments": "30 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing appropriate step sizes is critical for reducing the computational\ncost of training large-scale neural network models. Mini-batch sub-sampling\n(MBSS) is often employed for computational tractability. However, MBSS\nintroduces a sampling error, that can manifest as a bias or variance in a line\nsearch. This is because MBSS can be performed statically, where the mini-batch\nis updated only when the search direction changes, or dynamically, where the\nmini-batch is updated every-time the function is evaluated. Static MBSS results\nin a smooth loss function along a search direction, reflecting low variance but\nlarge bias in the estimated \"true\" (or full batch) minimum. Conversely, dynamic\nMBSS results in a point-wise discontinuous function, with computable gradients\nusing backpropagation, along a search direction, reflecting high variance but\nlower bias in the estimated \"true\" (or full batch) minimum. In this study,\nquadratic line search approximations are considered to study the quality of\nfunction and derivative information to construct approximations for dynamic\nMBSS loss functions. An empirical study is conducted where function and\nderivative information are enforced in various ways for the quadratic\napproximations. The results for various neural network problems show that being\nselective on what information is enforced helps to reduce the variance of\npredicted step sizes.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 22:01:57 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Chae", "Younghwan", ""], ["Wilke", "Daniel N.", ""]]}, {"id": "1909.06900", "submitter": "Guannan Qu", "authors": "Guannan Qu and Na Li", "title": "Exploiting Fast Decaying and Locality in Multi-Agent MDP with Tree\n  Dependence Structure", "comments": "10 pages, 3 figures. Accepted to CDC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a multi-agent Markov Decision Process (MDP), where there\nare $n$ agents and each agent $i$ is associated with a state $s_i$ and action\n$a_i$ taking values from a finite set. Though the global state space size and\naction space size are exponential in $n$, we impose local dependence structures\nand focus on local policies that only depend on local states, and we propose a\nmethod that finds nearly optimal local policies in polynomial time (in $n$)\nwhen the dependence structure is a one directional tree. The algorithm builds\non approximated reward functions which are evaluated using locally truncated\nMarkov process. Further, under some special conditions, we prove that the gap\nbetween the approximated reward function and the true reward function is\ndecaying exponentially fast as the length of the truncated Markov process gets\nlonger. The intuition behind this is that under some assumptions, the effect of\nagent interactions decays exponentially in the distance between agents, which\nwe term \"fast decaying property\".\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 22:31:49 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Qu", "Guannan", ""], ["Li", "Na", ""]]}, {"id": "1909.06907", "submitter": "Arjun Akula", "authors": "Arjun R. Akula, Changsong Liu, Sari Saba-Sadiya, Hongjing Lu, Sinisa\n  Todorovic, Joyce Y. Chai, Song-Chun Zhu", "title": "X-ToM: Explaining with Theory-of-Mind for Gaining Justified Human Trust", "comments": "A short version of this was presented at CVPR 2019 Workshop on\n  Explainable AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new explainable AI (XAI) framework aimed at increasing justified\nhuman trust and reliance in the AI machine through explanations. We pose\nexplanation as an iterative communication process, i.e. dialog, between the\nmachine and human user. More concretely, the machine generates sequence of\nexplanations in a dialog which takes into account three important aspects at\neach dialog turn: (a) human's intention (or curiosity); (b) human's\nunderstanding of the machine; and (c) machine's understanding of the human\nuser. To do this, we use Theory of Mind (ToM) which helps us in explicitly\nmodeling human's intention, machine's mind as inferred by the human as well as\nhuman's mind as inferred by the machine. In other words, these explicit mental\nrepresentations in ToM are incorporated to learn an optimal explanation policy\nthat takes into account human's perception and beliefs. Furthermore, we also\nshow that ToM facilitates in quantitatively measuring justified human trust in\nthe machine by comparing all the three mental representations.\n  We applied our framework to three visual recognition tasks, namely, image\nclassification, action recognition, and human body pose estimation. We argue\nthat our ToM based explanations are practical and more natural for both expert\nand non-expert users to understand the internal workings of complex machine\nlearning models. To the best of our knowledge, this is the first work to derive\nexplanations using ToM. Extensive human study experiments verify our\nhypotheses, showing that the proposed explanations significantly outperform the\nstate-of-the-art XAI methods in terms of all the standard quantitative and\nqualitative XAI evaluation metrics including human trust, reliance, and\nexplanation satisfaction.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 23:24:32 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Akula", "Arjun R.", ""], ["Liu", "Changsong", ""], ["Saba-Sadiya", "Sari", ""], ["Lu", "Hongjing", ""], ["Todorovic", "Sinisa", ""], ["Chai", "Joyce Y.", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1909.06918", "submitter": "Konstantin Mishchenko", "authors": "Konstantin Mishchenko", "title": "Sinkhorn Algorithm as a Special Case of Stochastic Mirror Descent", "comments": "7 pages, 2 algorithms, 1 theorem, 1 lemma", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new perspective on the celebrated Sinkhorn algorithm by showing\nthat is a special case of incremental/stochastic mirror descent. In order to\nsee this, one should simply plug Kullback-Leibler divergence in both mirror map\nand the objective function. Since the problem has unbounded domain, the\nobjective function is neither smooth nor it has bounded gradients. However, one\ncan still approach the problem using the notion of relative smoothness,\nobtaining that the stochastic objective is 1-relative smooth. The discovered\nequivalence allows us to propose 1) new methods for optimal transport, 2) an\nextension of Sinkhorn algorithm beyond two constraints.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 00:58:17 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Mishchenko", "Konstantin", ""]]}, {"id": "1909.06927", "submitter": "Ece Calikus", "authors": "Ece Calikus, Slawomir Nowaczyk, Anita Sant'Anna and Onur Dikmen", "title": "No Free Lunch But A Cheaper Supper: A General Framework for Streaming\n  Anomaly Detection", "comments": "Submitted to Expert Systems with Applications", "journal-ref": null, "doi": "10.1016/j.eswa.2020.113453", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been increased research interest in detecting\nanomalies in temporal streaming data. A variety of algorithms have been\ndeveloped in the data mining community, which can be divided into two\ncategories (i.e., general and ad hoc). In most cases, general approaches assume\nthe one-size-fits-all solution model where a single anomaly detector can detect\nall anomalies in any domain. To date, there exists no single general method\nthat has been shown to outperform the others across different anomaly types,\nuse cases and datasets. In this paper, we propose SAFARI, a general framework\nformulated by abstracting and unifying the fundamental tasks in streaming\nanomaly detection, which provides a flexible and extensible anomaly detection\nprocedure to overcome the limitations of one-size-fits-all solutions. SAFARI\nhelps to facilitate more elaborate algorithm comparisons by allowing us to\nisolate the effects of shared and unique characteristics of different\nalgorithms on detection performance. Using SAFARI, we have implemented various\nanomaly detectors and identified a research gap that motivates us to propose a\nnovel learning strategy in this work. We conducted an extensive evaluation\nstudy of 20 detectors that are composed using SAFARI and compared their\nperformances using real-world benchmark datasets with different properties. The\nresults indicate that there is no single superior detector that works well for\nevery case, proving our hypothesis that \"there is no free lunch\" in the\nstreaming anomaly detection world. Finally, we discuss the benefits and\ndrawbacks of each method in-depth and draw a set of conclusions to guide future\nusers of SAFARI.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 01:40:02 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 12:38:15 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 17:06:44 GMT"}, {"version": "v4", "created": "Sat, 18 Apr 2020 16:46:44 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Calikus", "Ece", ""], ["Nowaczyk", "Slawomir", ""], ["Sant'Anna", "Anita", ""], ["Dikmen", "Onur", ""]]}, {"id": "1909.06929", "submitter": "Andrew Steen", "authors": "James K. Senter, Taylor M. Royalty, Andrew D. Steen, Amir Sadovnik", "title": "Unaligned Sequence Similarity Search Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene annotation has traditionally required direct comparison of DNA sequences\nbetween an unknown gene and a database of known ones using string comparison\nmethods. However, these methods do not provide useful information when a gene\ndoes not have a close match in the database. In addition, each comparison can\nbe costly when the database is large since it requires alignments and a series\nof string comparisons. In this work we propose a novel approach: using\nrecurrent neural networks to embed DNA or amino-acid sequences in a\nlow-dimensional space in which distances correlate with functional similarity.\nThis embedding space overcomes both shortcomings of the method of aligning\nsequences and comparing homology. First, it allows us to obtain information\nabout genes which do not have exact matches by measuring their similarity to\nother ones in the database. If our database is labeled this can provide labels\nfor a query gene as is done in traditional methods. However, even if the\ndatabase is unlabeled it allows us to find clusters and infer some\ncharacteristics of the gene population. In addition, each comparison is much\nfaster than traditional methods since the distance metric is reduced to the\nEuclidean distance, and thus efficient approximate nearest neighbor algorithms\ncan be used to find the best match. We present results showing the advantage of\nour algorithm. More specifically we show how our embedding can be useful for\nboth classification tasks when our labels are known, and clustering tasks where\nour sequences belong to classes which have not been seen before.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 01:42:17 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Senter", "James K.", ""], ["Royalty", "Taylor M.", ""], ["Steen", "Andrew D.", ""], ["Sadovnik", "Amir", ""]]}, {"id": "1909.06930", "submitter": "Rudrajit Das", "authors": "Rudrajit Das and Subhasis Chaudhuri", "title": "On the Separability of Classes with the Cross-Entropy Loss Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the separability of classes with the cross-entropy\nloss function for classification problems by theoretically analyzing the\nintra-class distance and inter-class distance (i.e. the distance between any\ntwo points belonging to the same class and different classes, respectively) in\nthe feature space, i.e. the space of representations learnt by neural networks.\nSpecifically, we consider an arbitrary network architecture having a fully\nconnected final layer with Softmax activation and trained using the\ncross-entropy loss. We derive expressions for the value and the distribution of\nthe squared L2 norm of the product of a network dependent matrix and a random\nintra-class and inter-class distance vector (i.e. the vector between any two\npoints belonging to the same class and different classes), respectively, in the\nlearnt feature space (or the transformation of the original data) just before\nSoftmax activation, as a function of the cross-entropy loss value. The main\nresult of our analysis is the derivation of a lower bound for the probability\nwith which the inter-class distance is more than the intra-class distance in\nthis feature space, as a function of the loss value. We do so by leveraging\nsome empirical statistical observations with mild assumptions and sound\ntheoretical analysis. As per intuition, the probability with which the\ninter-class distance is more than the intra-class distance decreases as the\nloss value increases, i.e. the classes are better separated when the loss value\nis low. To the best of our knowledge, this is the first work of theoretical\nnature trying to explain the separability of classes in the feature space\nlearnt by neural networks trained with the cross-entropy loss function.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 01:47:24 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Das", "Rudrajit", ""], ["Chaudhuri", "Subhasis", ""]]}, {"id": "1909.06933", "submitter": "Peter Florence", "authors": "Peter Florence, Lucas Manuelli, Russ Tedrake", "title": "Self-Supervised Correspondence in Visuomotor Policy Learning", "comments": "Video at: https://sites.google.com/view/visuomotor-correspondence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore using self-supervised correspondence for improving\nthe generalization performance and sample efficiency of visuomotor policy\nlearning. Prior work has primarily used approaches such as autoencoding,\npose-based losses, and end-to-end policy optimization in order to train the\nvisual portion of visuomotor policies. We instead propose an approach using\nself-supervised dense visual correspondence training, and show this enables\nvisuomotor policy learning with surprisingly high generalization performance\nwith modest amounts of data: using imitation learning, we demonstrate extensive\nhardware validation on challenging manipulation tasks with as few as 50\ndemonstrations. Our learned policies can generalize across classes of objects,\nreact to deformable object configurations, and manipulate textureless\nsymmetrical objects in a variety of backgrounds, all with closed-loop,\nreal-time vision-based policies. Simulated imitation learning experiments\nsuggest that correspondence training offers sample complexity and\ngeneralization benefits compared to autoencoding and end-to-end training.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 01:52:39 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Florence", "Peter", ""], ["Manuelli", "Lucas", ""], ["Tedrake", "Russ", ""]]}, {"id": "1909.06940", "submitter": "Zhao Kang", "authors": "Zhao Kang and Guoxin Shi and Shudong Huang and Wenyu Chen and Xiaorong\n  Pu and Joey Tianyi Zhou and Zenglin Xu", "title": "Multi-graph Fusion for Multi-view Spectral Clustering", "comments": "submitted to Knowledge-based Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A panoply of multi-view clustering algorithms has been developed to deal with\nprevalent multi-view data. Among them, spectral clustering-based methods have\ndrawn much attention and demonstrated promising results recently. Despite\nprogress, there are still two fundamental questions that stay unanswered to\ndate. First, how to fuse different views into one graph. More often than not,\nthe similarities between samples may be manifested differently by different\nviews. Many existing algorithms either simply take the average of multiple\nviews or just learn a common graph. These simple approaches fail to consider\nthe flexible local manifold structures of all views. Hence, the rich\nheterogeneous information is not fully exploited. Second, how to learn the\nexplicit cluster structure. Most existing methods don't pay attention to the\nquality of the graphs and perform graph learning and spectral clustering\nseparately. Those unreliable graphs might lead to suboptimal clustering\nresults. To fill these gaps, in this paper, we propose a novel multi-view\nspectral clustering model which performs graph fusion and spectral clustering\nsimultaneously. The fusion graph approximates the original graph of each\nindividual view but maintains an explicit cluster structure. Experiments on\nfour widely used data sets confirm the superiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 02:22:02 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kang", "Zhao", ""], ["Shi", "Guoxin", ""], ["Huang", "Shudong", ""], ["Chen", "Wenyu", ""], ["Pu", "Xiaorong", ""], ["Zhou", "Joey Tianyi", ""], ["Xu", "Zenglin", ""]]}, {"id": "1909.06943", "submitter": "Abdullahi Mohammad Mr.", "authors": "Abdullahi Mohammad, Christos Masouros and Yiannis Andreopoulos", "title": "Complexity-Scalable Neural Network Based MIMO Detection With Learnable\n  Weight Scaling", "comments": "14 pages, 12 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a framework for systematic complexity scaling of deep\nneural network(DNN) based MIMO detectors. The model uses a fraction of the DNN\ninputs by scaling their values through weights that follow monotonically\nnon-increasing functions. This allows for weight scaling across and within the\ndifferent DNN layers in order to achieve accuracy-vs.-complexity scalability\nduring inference. In order to further improve the performance of our proposal,\nwe introduce a sparsity-inducing regularization constraint in conjunction with\ntrainable weight-scaling functions. In this way, the network learns to balance\ndetection accuracy versus complexity while also increasing robustness to\nchanges in the activation patterns, leading to further improvement in the\ndetection accuracy and BER performance at the same inference complexity.\nNumerical results show that our approach is 10-foldand 100-fold less complex\nthan classical approaches based on semi-definite relaxation and ML detection,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 22:06:13 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 18:08:34 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Mohammad", "Abdullahi", ""], ["Masouros", "Christos", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1909.06945", "submitter": "Sim\\'on Rodr\\'iguez", "authors": "Sim\\'on Rodr\\'iguez Santana, Daniel Hern\\'andez-Lobato", "title": "Adversarial $\\alpha$-divergence Minimization for Bayesian Approximate\n  Inference", "comments": "47 pages, 10 figures (41 pages for the main article, 6 for the\n  supplementary material)", "journal-ref": null, "doi": "10.1016/j.neucom.2020.09.076", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are popular state-of-the-art models for many different\ntasks.They are often trained via back-propagation to find a value of the\nweights that correctly predicts the observed data. Although back-propagation\nhas shown good performance in many applications, it cannot easily output an\nestimate of the uncertainty in the predictions made. Estimating the uncertainty\nin the predictions is a critical aspect with important applications, and one\nmethod to obtain this information is following a Bayesian approach to estimate\na posterior distribution on the model parameters. This posterior distribution\nsummarizes which parameter values are compatible with the data, but is usually\nintractable and has to be approximated. Several mechanisms have been considered\nfor solving this problem. We propose here a general method for approximate\nBayesian inference that is based on minimizing{\\alpha}-divergences and that\nallows for flexible approximate distributions. The method is evaluated in the\ncontext of Bayesian neural networks on extensive experiments. The results show\nthat, in regression problems, it often gives better performance in terms of the\ntest log-likelihoodand sometimes in terms of the squared error. In\nclassification problems, however, it gives competitive results.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 08:27:58 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 08:39:51 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 16:45:25 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Santana", "Sim\u00f3n Rodr\u00edguez", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "1909.06946", "submitter": "Luo Luo", "authors": "Luo Luo, Cheng Chen, Yujun Li, Guangzeng Xie, Zhihua Zhang", "title": "A Stochastic Proximal Point Algorithm for Saddle-Point Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We consider saddle point problems which objective functions are the average\nof $n$ strongly convex-concave individual components. Recently, researchers\nexploit variance reduction methods to solve such problems and achieve\nlinear-convergence guarantees. However, these methods have a slow convergence\nwhen the condition number of the problem is very large. In this paper, we\npropose a stochastic proximal point algorithm, which accelerates the variance\nreduction method SAGA for saddle point problems. Compared with the catalyst\nframework, our algorithm reduces a logarithmic term of condition number for the\niteration complexity. We adopt our algorithm to policy evaluation and the\nempirical results show that our method is much more efficient than\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 11:50:13 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Luo", "Luo", ""], ["Chen", "Cheng", ""], ["Li", "Yujun", ""], ["Xie", "Guangzeng", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1909.06953", "submitter": "Zeyu Zhu", "authors": "Zeyu Zhu, Nan Li, Ruoyu Sun, Huijing Zhao, Donghao Xu", "title": "Off-road Autonomous Vehicles Traversability Analysis and Trajectory\n  Planning Based on Deep Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Terrain traversability analysis is a fundamental issue to achieve the\nautonomy of a robot at off-road environments. Geometry-based and\nappearance-based methods have been studied in decades, while behavior-based\nmethods exploiting learning from demonstration (LfD) are new trends.\nBehavior-based methods learn cost functions that guide trajectory planning in\ncompliance with experts' demonstrations, which can be more scalable to various\nscenes and driving behaviors. This research proposes a method of off-road\ntraversability analysis and trajectory planning using Deep Maximum Entropy\nInverse Reinforcement Learning. To incorporate vehicle's kinematics while\nsolving the problem of exponential increase of state-space complexity, two\nconvolutional neural networks, i.e., RL ConvNet and Svf ConvNet, are developed\nto encode kinematics into convolution kernels and achieve efficient forward\nreinforcement learning. We conduct experiments in off-road environments. Scene\nmaps are generated using 3D LiDAR data, and expert demonstrations are either\nthe vehicle's real driving trajectories at the scene or synthesized ones to\nrepresent specific behaviors such as crossing negative obstacles. Different\ncost functions of traversability analysis are learned and tested at various\nscenes of capability in guiding the trajectory planning of different behaviors.\nWe also demonstrate the performance and computation efficiency of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 02:46:02 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 08:50:33 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhu", "Zeyu", ""], ["Li", "Nan", ""], ["Sun", "Ruoyu", ""], ["Zhao", "Huijing", ""], ["Xu", "Donghao", ""]]}, {"id": "1909.06959", "submitter": "Dritjon Gruda", "authors": "Dritjon Gruda and Souleiman Hasan", "title": "Feeling Anxious? Perceiving Anxiety in Tweets using Machine Learning", "comments": "36 pages, 6 figures", "journal-ref": "Computers in Human Behavior, 98, 2019, 245-255", "doi": "10.1016/j.chb.2019.04.020", "report-no": null, "categories": "cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study provides a predictive measurement tool to examine perceived\nanxiety from a longitudinal perspective, using a non-intrusive machine learning\napproach to scale human rating of anxiety in microblogs. Results suggest that\nour chosen machine learning approach depicts perceived user state-anxiety\nfluctuations over time, as well as mean trait anxiety. We further find a\nreverse relationship between perceived anxiety and outcomes such as social\nengagement and popularity. Implications on the individual, organizational, and\nsocietal levels are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 10:38:55 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Gruda", "Dritjon", ""], ["Hasan", "Souleiman", ""]]}, {"id": "1909.06964", "submitter": "Qing Yang", "authors": "Qing Yang, Jiachen Mao, Zuoguan Wang, Hai Li", "title": "DASNet: Dynamic Activation Sparsity for Neural Network Efficiency\n  Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the execution speed and efficiency of neural networks in embedded\nsystems, it is crucial to decrease the model size and computational complexity.\nIn addition to conventional compression techniques, e.g., weight pruning and\nquantization, removing unimportant activations can reduce the amount of data\ncommunication and the computation cost. Unlike weight parameters, the pattern\nof activations is directly related to input data and thereby changes\ndynamically. To regulate the dynamic activation sparsity (DAS), in this work,\nwe propose a generic low-cost approach based on winners-take-all (WTA) dropout\ntechnique. The network enhanced by the proposed WTA dropout, namely\n\\textit{DASNet}, features structured activation sparsity with an improved\nsparsity level. Compared to the static feature map pruning methods, DASNets\nprovide better computation cost reduction. The WTA technique can be easily\napplied in deep neural networks without incurring additional training\nvariables. More importantly, DASNet can be seamlessly integrated with other\ncompression techniques, such as weight pruning and quantization, without\ncompromising on accuracy. Our experiments on various networks and datasets\npresent significant run-time speedups with negligible accuracy loss.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 03:53:39 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Yang", "Qing", ""], ["Mao", "Jiachen", ""], ["Wang", "Zuoguan", ""], ["Li", "Hai", ""]]}, {"id": "1909.06965", "submitter": "Nikos Ar\\'echiga PhD", "authors": "Nikos Arechiga, Jonathan DeCastro, Soonho Kong, Karen Leung", "title": "Better AI through Logical Scaffolding", "comments": "CAV Workshop on Formal Methods for ML-enabled Autonomous Systems 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the concept of logical scaffolds, which can be used to improve\nthe quality of software that relies on AI components. We explain how some of\nthe existing ideas on runtime monitors for perception systems can be seen as a\nspecific instance of logical scaffolds. Furthermore, we describe how logical\nscaffolds may be useful for improving AI programs beyond perception systems, to\ninclude general prediction systems and agent behavior models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 05:41:25 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Arechiga", "Nikos", ""], ["DeCastro", "Jonathan", ""], ["Kong", "Soonho", ""], ["Leung", "Karen", ""]]}, {"id": "1909.06970", "submitter": "Montserrat Alvarado", "authors": "Alicia Montserrat Alvarado-Gonzalez, Gibran Fuentes-Pineda and Jorge\n  Cervantes-Ojeda", "title": "A few filters are enough: Convolutional Neural Network for P300\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, convolutional neural networks (CNNs) have become the\ndriving force of an ever-increasing set of applications, achieving\nstate-of-the-art performance. Most of the modern CNN architectures are composed\nof many convolutional and fully connected layers and typically require\nthousands or millions of parameters to learn. CNNs have also been effective in\nthe detection of Event-Related Potentials from electroencephalogram (EEG)\nsignals, notably the P300 component which is frequently employed in\nBrain-Computer Interfaces (BCIs). However, for this task, the increase in\ndetection rates compared to approaches based on human-engineered features has\nnot been as impressive as in other areas and might not justify such a large\nnumber of parameters. In this paper, we study the performances of existing CNN\narchitectures with diverse complexities for single-trial within-subject and\ncross-subject P300 detection on four different datasets. We also proposed\nSepConv1D, a very simple CNN architecture consisting of a single depthwise\nseparable 1D convolutional layer followed by a fully connected Sigmoid\nclassification neuron. We found that with as few as four filters in its\nconvolutional layer and a small overall number of parameters, SepConv1D\nobtained competitive performances in the four datasets. We believe this may\nrepresent an important step towards building simpler, cheaper, faster, and more\nportable BCIs.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 03:48:28 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 01:27:09 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 19:38:37 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Alvarado-Gonzalez", "Alicia Montserrat", ""], ["Fuentes-Pineda", "Gibran", ""], ["Cervantes-Ojeda", "Jorge", ""]]}, {"id": "1909.06984", "submitter": "Bahman Moraffah", "authors": "Bahman Moraffah", "title": "Inference for multiple object tracking: A Bayesian nonparametric\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, multi object tracking (MOT) problem has drawn attention to\nit and has been studied in various research areas. However, some of the\nchallenging problems including time dependent cardinality, unordered\nmeasurement set, and object labeling remain unclear. In this paper, we propose\nrobust nonparametric methods to model the state prior for MOT problem. These\nmodels are shown to be more flexible and robust compared to existing methods.\nIn particular, the overall approach estimates time dependent object\ncardinality, provides object labeling, and identifies object associated\nmeasurements. Moreover, our proposed framework dynamically contends with the\nbirth/death and survival of the objects through dependent nonparametric\nprocesses. We present Inference algorithms that demonstrate the utility of the\ndependent nonparametric models for tracking. We employ Monte Carlo sampling\nmethods to demonstrate the proposed algorithms efficiently learn the trajectory\nof objects from noisy measurements. The computational results display the\nperformance of the proposed algorithms and comparison not only between one\nanother, but also between proposed algorithms and labeled multi Bernoulli\ntracker.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 04:42:02 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Moraffah", "Bahman", ""]]}, {"id": "1909.07018", "submitter": "Jing Liu", "authors": "Jing Liu, Fei Gao and Jiang Zhang", "title": "Gumbel-softmax Optimization: A Simple General Framework for\n  Combinatorial Optimization Problems on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in real life can be converted to combinatorial optimization\nproblems (COPs) on graphs, that is to find a best node state configuration or a\nnetwork structure such that the designed objective function is optimized under\nsome constraints. However, these problems are notorious for their hardness to\nsolve because most of them are NP-hard or NP-complete. Although traditional\ngeneral methods such as simulated annealing (SA), genetic algorithms (GA) and\nso forth have been devised to these hard problems, their accuracy and time\nconsumption are not satisfying in practice. In this work, we proposed a simple,\nfast, and general algorithm framework called Gumbel-softmax Optimization (GSO)\nfor COPs. By introducing Gumbel-softmax technique which is developed in machine\nlearning community, we can optimize the objective function directly by gradient\ndescent algorithm regardless of the discrete nature of variables. We test our\nalgorithm on four different problems including Sherrington-Kirkpatrick (SK)\nmodel, maximum independent set (MIS) problem, modularity optimization, and\nstructural optimization problem. High-quality solutions can be obtained with\nmuch less time consuming compared to traditional approaches.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 06:43:46 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Liu", "Jing", ""], ["Gao", "Fei", ""], ["Zhang", "Jiang", ""]]}, {"id": "1909.07031", "submitter": "Masashi Okada Dr", "authors": "Masashi Okada, Shinji Takenaka, Tadahiro Taniguchi", "title": "Multi-person Pose Tracking using Sequential Monte Carlo with\n  Probabilistic Neural Pose Predictor", "comments": "Accepted to ICRA2020; Camera-ready ver", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is an effective strategy for the multi-person pose tracking task in videos\nto employ prediction and pose matching in a frame-by-frame manner. For this\ntype of approach, uncertainty-aware modeling is essential because precise\nprediction is impossible. However, previous studies have relied on only a\nsingle prediction without incorporating uncertainty, which can cause critical\ntracking errors if the prediction is unreliable. This paper proposes an\nextension to this approach with Sequential Monte Carlo (SMC). This naturally\nreformulates the tracking scheme to handle multiple predictions (or hypotheses)\nof poses, thereby mitigating the negative effect of prediction errors. An\nimportant component of SMC, i.e., a proposal distribution, is designed as a\nprobabilistic neural pose predictor, which can propose diverse and plausible\nhypotheses by incorporating epistemic uncertainty and heteroscedastic aleatoric\nuncertainty. In addition, a recurrent architecture is introduced to our neural\nmodeling to utilize time-sequence information of poses to manage difficult\nsituations, such as the frequent disappearance and reappearances of poses.\nCompared to existing baselines, the proposed method achieves a state-of-the-art\nMOTA score on the PoseTrack2018 validation dataset by reducing approximately\n50% of tracking errors from a state-of-the art baseline method.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 07:25:28 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 07:54:14 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Okada", "Masashi", ""], ["Takenaka", "Shinji", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "1909.07040", "submitter": "Sayak Ray Chowdhury", "authors": "Sayak Ray Chowdhury and Aditya Gopalan", "title": "Bayesian Optimization under Heavy-tailed Payoffs", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider black box optimization of an unknown function in the\nnonparametric Gaussian process setting when the noise in the observed function\nvalues can be heavy tailed. This is in contrast to existing literature that\ntypically assumes sub-Gaussian noise distributions for queries. Under the\nassumption that the unknown function belongs to the Reproducing Kernel Hilbert\nSpace (RKHS) induced by a kernel, we first show that an adaptation of the\nwell-known GP-UCB algorithm with reward truncation enjoys sublinear\n$\\tilde{O}(T^{\\frac{2 + \\alpha}{2(1+\\alpha)}})$ regret even with only the\n$(1+\\alpha)$-th moments, $\\alpha \\in (0,1]$, of the reward distribution being\nbounded ($\\tilde{O}$ hides logarithmic factors). However, for the common\nsquared exponential (SE) and Mat\\'{e}rn kernels, this is seen to be\nsignificantly larger than a fundamental $\\Omega(T^{\\frac{1}{1+\\alpha}})$ lower\nbound on regret. We resolve this gap by developing novel Bayesian optimization\nalgorithms, based on kernel approximation techniques, with regret bounds\nmatching the lower bound in order for the SE kernel. We numerically benchmark\nthe algorithms on environments based on both synthetic models and real-world\ndata sets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 07:44:39 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Chowdhury", "Sayak Ray", ""], ["Gopalan", "Aditya", ""]]}, {"id": "1909.07053", "submitter": "Yuantao Fan", "authors": "Yuantao Fan and S{\\l}awomir Nowaczyk and Thorsteinn R\\\"ognvaldsson", "title": "Transfer learning for Remaining Useful Life Prediction Based on\n  Consensus Self-Organizing Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional paradigm for developing machine prognostics usually relies on\ngeneralization from data acquired in experiments under controlled conditions\nprior to deployment of the equipment. Detecting or predicting failures and\nestimating machine health in this way assumes that future field data will have\na very similar distribution to the experiment data. However, many complex\nmachines operate under dynamic environmental conditions and are used in many\ndifferent ways. This makes collecting comprehensive data very challenging, and\nthe assumption that pre-deployment data and post-deployment data follow very\nsimilar distributions is unlikely to hold. Transfer Learning (TL) refers to\nmethods for transferring knowledge learned in one setting (the source domain)\nto another setting (the target domain). In this work, we present a TL method\nfor predicting Remaining Useful Life (RUL) of equipment, under the assumption\nthat labels are available only for the source domain and not the target domain.\nThis setting corresponds to generalizing from a limited number of\nrun-to-failure experiments performed prior to deployment into making\nprognostics with data coming from deployed equipment that is being used under\nmultiple new operating conditions and experiencing previously unseen faults. We\nemploy a deviation detection method, Consensus Self-Organizing Models (COSMO),\nto create transferable features for building the RUL regression model. These\nfeatures capture how different target equipment is in comparison to its peers.\nThe efficiency of the proposed TL method is demonstrated using the NASA\nTurbofan Engine Degradation Simulation Data Set. Models using the COSMO\ntransferable features show better performance than other methods on predicting\nRUL when the target domain is more complex than the source domain.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 08:31:08 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 02:45:27 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 18:00:37 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Fan", "Yuantao", ""], ["Nowaczyk", "S\u0142awomir", ""], ["R\u00f6gnvaldsson", "Thorsteinn", ""]]}, {"id": "1909.07063", "submitter": "Marc Dymetman", "authors": "Tetiana Parshakova and Jean-Marc Andreoli and Marc Dymetman", "title": "Global Autoregressive Models for Data-Efficient Sequence Learning", "comments": "To appear in CONLL (The SIGNLL Conference on Computational Natural\n  Language Learning) Hong Kong, Nov. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard autoregressive seq2seq models are easily trained by max-likelihood,\nbut tend to show poor results under small-data conditions. We introduce a class\nof seq2seq models, GAMs (Global Autoregressive Models), which combine an\nautoregressive component with a log-linear component, allowing the use of\nglobal \\textit{a priori} features to compensate for lack of data. We train\nthese models in two steps. In the first step, we obtain an \\emph{unnormalized}\nGAM that maximizes the likelihood of the data, but is improper for fast\ninference or evaluation. In the second step, we use this GAM to train (by\ndistillation) a second autoregressive model that approximates the\n\\emph{normalized} distribution associated with the GAM, and can be used for\nfast inference and evaluation. Our experiments focus on language modelling\nunder synthetic conditions and show a strong perplexity reduction of using the\nsecond autoregressive model over the standard one.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 08:46:30 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 19:40:01 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Parshakova", "Tetiana", ""], ["Andreoli", "Jean-Marc", ""], ["Dymetman", "Marc", ""]]}, {"id": "1909.07068", "submitter": "Sen Yang", "authors": "Sen Yang, Wankou Yang and Zhen Cui", "title": "Pose Neural Fabrics Search", "comments": "11 pages, 8 figures, 7 tables. Code is available at\n  https://github.com/yangsenius/PoseNFS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) technologies have emerged in many domains to\njointly learn the architectures and weights of the neural network. However,\nmost existing NAS works claim they are task-specific and focus only on\noptimizing a single architecture to replace a human-designed neural network, in\nfact, their search processes are almost independent of domain knowledge of the\ntasks. In this paper, we propose Pose Neural Fabrics Search (PoseNFS). We\nexplore a new solution for NAS and human pose estimation task: part-specific\nneural architecture search, which can be seen as a variant of multi-task\nlearning. Firstly, we design a new neural architecture search space, Cell-based\nNeural Fabric (CNF), to learn micro as well as macro neural architecture using\na differentiable search strategy. Then, we view locating human keypoints as\nmultiple disentangled prediction sub-tasks, and then use prior knowledge of\nbody structure as guidance to search for multiple part-specific neural\narchitectures for different human parts. After search, all these part-specific\nCNFs have distinct micro and macro architecture parameters. The results show\nthat such knowledge-guided NAS-based architectures have obvious performance\nimprovements to a hand-designed part-based baseline model. The experiments on\nMPII and MS-COCO datasets demonstrate that PoseNFS\\footnote{Code is available\nat \\url{https://github.com/yangsenius/PoseNFS}} can achieve comparable\nperformance to some efficient and state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 08:56:14 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 12:14:31 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 01:56:06 GMT"}, {"version": "v4", "created": "Sat, 5 Dec 2020 05:40:24 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Yang", "Sen", ""], ["Yang", "Wankou", ""], ["Cui", "Zhen", ""]]}, {"id": "1909.07075", "submitter": "Dimitri Korsch", "authors": "Dimitri Korsch, Paul Bodesheim, Joachim Denzler", "title": "Classification-Specific Parts for Improving Fine-Grained Visual\n  Categorization", "comments": "Presented at the GCPR2019", "journal-ref": null, "doi": "10.1007/978-3-030-33676-9_5", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained visual categorization is a classification task for\ndistinguishing categories with high intra-class and small inter-class variance.\nWhile global approaches aim at using the whole image for performing the\nclassification, part-based solutions gather additional local information in\nterms of attentions or parts. We propose a novel classification-specific part\nestimation that uses an initial prediction as well as back-propagation of\nfeature importance via gradient computations in order to estimate relevant\nimage regions. The subsequently detected parts are then not only selected by\na-posteriori classification knowledge, but also have an intrinsic spatial\nextent that is determined automatically. This is in contrast to most part-based\napproaches and even to available ground-truth part annotations, which only\nprovide point coordinates and no additional scale information. We show in our\nexperiments on various widely-used fine-grained datasets the effectiveness of\nthe mentioned part selection method in conjunction with the extracted part\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 09:13:47 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Korsch", "Dimitri", ""], ["Bodesheim", "Paul", ""], ["Denzler", "Joachim", ""]]}, {"id": "1909.07079", "submitter": "Huan Xiong", "authors": "Huan Xiong, Mengyang Yu, Li Liu, Fan Zhu, Fumin Shen, Ling Shao", "title": "Fast Large-Scale Discrete Optimization Based on Principal Coordinate\n  Descent", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Binary optimization, a representative subclass of discrete optimization,\nplays an important role in mathematical optimization and has various\napplications in computer vision and machine learning. Usually, binary\noptimization problems are NP-hard and difficult to solve due to the binary\nconstraints, especially when the number of variables is very large. Existing\nmethods often suffer from high computational costs or large accumulated\nquantization errors, or are only designed for specific tasks. In this paper, we\npropose a fast algorithm to find effective approximate solutions for general\nbinary optimization problems. The proposed algorithm iteratively solves\nminimization problems related to the linear surrogates of loss functions, which\nleads to the updating of some binary variables most impacting the value of loss\nfunctions in each step. Our method supports a wide class of empirical objective\nfunctions with/without restrictions on the numbers of $1$s and $-1$s in the\nbinary variables. Furthermore, the theoretical convergence of our algorithm is\nproven, and the explicit convergence rates are derived, for objective functions\nwith Lipschitz continuous gradients, which are commonly adopted in practice.\nExtensive experiments on several binary optimization tasks and large-scale\ndatasets demonstrate the superiority of the proposed algorithm over several\nstate-of-the-art methods in terms of both effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 09:21:22 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 08:46:24 GMT"}, {"version": "v3", "created": "Sat, 15 May 2021 04:51:07 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Xiong", "Huan", ""], ["Yu", "Mengyang", ""], ["Liu", "Li", ""], ["Zhu", "Fan", ""], ["Shen", "Fumin", ""], ["Shao", "Ling", ""]]}, {"id": "1909.07082", "submitter": "Udo Schlegel", "authors": "Udo Schlegel, Hiba Arnout, Mennatallah El-Assady, Daniela Oelke,\n  Daniel A. Keim", "title": "Towards a Rigorous Evaluation of XAI Methods on Time Series", "comments": "5 Pages 1 Figure 1 Table 1 Page Reference - 2019 ICCV Workshop on\n  Interpreting and Explaining Visual Artificial Intelligence Models", "journal-ref": "2019 ICCV Workshop on Interpreting and Explaining Visual\n  Artificial Intelligence Models", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (XAI) methods are typically deployed to\nexplain and debug black-box machine learning models. However, most proposed XAI\nmethods are black-boxes themselves and designed for images. Thus, they rely on\nvisual interpretability to evaluate and prove explanations. In this work, we\napply XAI methods previously used in the image and text-domain on time series.\nWe present a methodology to test and evaluate various XAI methods on time\nseries by introducing new verification techniques to incorporate the temporal\ndimension. We further conduct preliminary experiments to assess the quality of\nselected XAI method explanations with various verification methods on a range\nof datasets and inspecting quality metrics on it. We demonstrate that in our\ninitial experiments, SHAP works robust for all models, but others like\nDeepLIFT, LRP, and Saliency Maps work better with specific architectures.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 09:26:00 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 14:24:01 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Schlegel", "Udo", ""], ["Arnout", "Hiba", ""], ["El-Assady", "Mennatallah", ""], ["Oelke", "Daniela", ""], ["Keim", "Daniel A.", ""]]}, {"id": "1909.07083", "submitter": "Bowen Li", "authors": "Bowen Li, Xiaojuan Qi, Thomas Lukasiewicz, Philip H. S. Torr", "title": "Controllable Text-to-Image Generation", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel controllable text-to-image generative\nadversarial network (ControlGAN), which can effectively synthesise high-quality\nimages and also control parts of the image generation according to natural\nlanguage descriptions. To achieve this, we introduce a word-level spatial and\nchannel-wise attention-driven generator that can disentangle different visual\nattributes, and allow the model to focus on generating and manipulating\nsubregions corresponding to the most relevant words. Also, a word-level\ndiscriminator is proposed to provide fine-grained supervisory feedback by\ncorrelating words with image regions, facilitating training an effective\ngenerator which is able to manipulate specific visual attributes without\naffecting the generation of other content. Furthermore, perceptual loss is\nadopted to reduce the randomness involved in the image generation, and to\nencourage the generator to manipulate specific attributes required in the\nmodified text. Extensive experiments on benchmark datasets demonstrate that our\nmethod outperforms existing state of the art, and is able to effectively\nmanipulate synthetic images using natural language descriptions. Code is\navailable at https://github.com/mrlibw/ControlGAN.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 09:29:52 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 18:30:18 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Li", "Bowen", ""], ["Qi", "Xiaojuan", ""], ["Lukasiewicz", "Thomas", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1909.07088", "submitter": "Chieh Yu Chen", "authors": "Hsin-Ying Hsieh, Chieh-Yu Chen, Yu-Shuen Wang, Jung-Hong Chuang", "title": "BasketballGAN: Generating Basketball Play Simulation Through Sketching", "comments": "9 pages, Accepted paper at ACMMM 2019, code is available at\n  https://github.com/chychen/BasketballGAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven basketball set play simulation. Given an offensive\nset play sketch, our method simulates potential scenarios that may occur in the\ngame. The simulation provides coaches and players with insights on how a given\nset play can be executed. To achieve the goal, we train a conditional\nadversarial network on NBA movement data to imitate the behaviors of how\nplayers move around the court through two major components: a generator that\nlearns to generate natural player movements based on a latent noise and a user\nsketched set play; and a discriminator that is used to evaluate the realism of\nthe basketball play. To improve the quality of simulation, we minimize 1.) a\ndribbler loss to prevent the ball from drifting away from the dribbler; 2.) a\ndefender loss to prevent the dribbler from not being defended; 3.) a ball\npassing loss to ensure the straightness of passing trajectories; and 4) an\nacceleration loss to minimize unnecessary players' movements. To evaluate our\nsystem, we objectively compared real and simulated basketball set plays.\nBesides, a subjective test was conducted to judge whether a set play was real\nor generated by our network. On average, the mean correct rates to the binary\ntests were 56.17 \\%. Experiment results and the evaluations demonstrated the\neffectiveness of our system.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 09:45:49 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 02:33:51 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Hsieh", "Hsin-Ying", ""], ["Chen", "Chieh-Yu", ""], ["Wang", "Yu-Shuen", ""], ["Chuang", "Jung-Hong", ""]]}, {"id": "1909.07102", "submitter": "Marco Dinarelli", "authors": "Marco Dinarelli and Lo\\\"ic Grobol", "title": "Hybrid Neural Models For Sequence Modelling: The Best Of Three Worlds", "comments": "12 pages + bibliography. English version, and slight improvement, of\n  the paper published at the French conference TALN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a neural architecture with the main characteristics of the most\nsuccessful neural models of the last years: bidirectional RNNs,\nencoder-decoder, and the Transformer model. Evaluation on three sequence\nlabelling tasks yields results that are close to the state-of-the-art for all\ntasks and better than it for some of them, showing the pertinence of this\nhybrid architecture for this kind of tasks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 10:19:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Dinarelli", "Marco", ""], ["Grobol", "Lo\u00efc", ""]]}, {"id": "1909.07105", "submitter": "Yu Yol Shin", "authors": "Yuyol Shin, Yoonjin Yoon", "title": "Incorporating dynamicity of transportation network with multi-weight\n  traffic graph convolutional network for traffic forecasting", "comments": "11 pages, 7 figures, Accepted to IEEE Transactions on Intelligent\n  Transportation Systems (2020)", "journal-ref": "IEEE Trans. Intell. Transp. Syst., 0 (2020) 1-11", "doi": "10.1109/TITS.2020.3031331", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting problem remains a challenging task in the intelligent\ntransportation system due to its spatio-temporal complexity. Although temporal\ndependency has been well studied and discussed, spatial dependency is\nrelatively less explored due to its large variations, especially in the urban\nenvironment. In this study, a novel graph convolutional network model,\nMulti-Weight Traffic Graph Convolutional (MW-TGC) network, is proposed and\napplied to two urban networks with contrasting geometric constraints. The model\nconducts graph convolution operations on speed data with multi-weighted\nadjacency matrices to combine the features, including speed limit, distance,\nand angle. The spatially isolated dimension reduction operation is conducted on\nthe combined features to learn the dependencies among the features and reduce\nthe size of the output to a computationally feasible level. The output of\nmulti-weight graph convolution is applied to the sequence-to-sequence model\nwith Long Short-Term Memory units to learn temporal dependencies. When applied\nto two urban sites, urban-core and urban-mix, MW-TGC network not only\noutperformed the comparative models in both sites but also reduced variance in\nthe heterogeneous urban-mix network. We conclude that MW-TGC network can\nprovide a robust traffic forecasting performance across the variations in\nspatial complexity, which can be a strong advantage in urban traffic\nforecasting.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 10:30:53 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 06:34:44 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 07:07:17 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Shin", "Yuyol", ""], ["Yoon", "Yoonjin", ""]]}, {"id": "1909.07115", "submitter": "YuChuan Chuang", "authors": "Yi-Ta Chen, Yu-Chuan Chuang, An-Yeu (Andy) Wu", "title": "AdaBoost-assisted Extreme Learning Machine for Efficient Online\n  Sequential Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an AdaBoost-assisted extreme learning machine for\nefficient online sequential classification (AOS-ELM). In order to achieve\nbetter accuracy in online sequential learning scenarios, we utilize the\ncost-sensitive algorithm-AdaBoost, which diversifying the weak classifiers, and\nadding the forgetting mechanism, which stabilizing the performance during the\ntraining procedure. Hence, AOS-ELM adapts better to sequentially arrived data\ncompared with other voting based methods. The experiment results show AOS-ELM\ncan achieve 94.41% accuracy on MNIST dataset, which is the theoretical accuracy\nbound performed by an original batch learning algorithm, AdaBoost-ELM.\nMoreover, with the forgetting mechanism, the standard deviation of accuracy\nduring the online sequential learning process is reduced to 8.26x.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 10:48:00 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Chen", "Yi-Ta", "", "Andy"], ["Chuang", "Yu-Chuan", "", "Andy"], ["An-Yeu", "", "", "Andy"], ["Wu", "", ""]]}, {"id": "1909.07116", "submitter": "Dattaraj Rao", "authors": "Dattaraj Rao", "title": "Leveraging human Domain Knowledge to model an empirical Reward function\n  for a Reinforcement Learning problem", "comments": "4 pages, 3 figures, code shared on Google colab", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Reinforcement Learning (RL) problems depend on an exhaustive\nsimulation environment that models real-world physics of the problem and trains\nthe RL agent by observing this environment. In this paper, we present a novel\napproach to creating an environment by modeling the reward function based on\nempirical rules extracted from human domain knowledge of the system under\nstudy. Using this empirical rewards function, we will build an environment and\ntrain the agent. We will first create an environment that emulates the effect\nof setting cabin temperature through thermostat. This is typically done in RL\nproblems by creating an exhaustive model of the system with detailed\nthermodynamic study. Instead, we propose an empirical approach to model the\nreward function based on human domain knowledge. We will document some rules of\nthumb that we usually exercise as humans while setting thermostat temperature\nand try and model these into our reward function. This modeling of empirical\nhuman domain rules into a reward function for RL is the unique aspect of this\npaper. This is a continuous action space problem and using deep deterministic\npolicy gradient (DDPG) method, we will solve for maximizing the reward\nfunction. We will create a policy network that predicts optimal temperature\nsetpoint given external temperature and humidity.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 10:57:26 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Rao", "Dattaraj", ""]]}, {"id": "1909.07122", "submitter": "Bin Liang", "authors": "Jingkai Weng, Yujiang Ding, Chengbo Hu, Xue-feng Zhu, Bin Liang, Jing\n  Yang, Jianchun Cheng", "title": "Meta-neural-network for Realtime and Passive Deep-learning-based Object\n  Recognition", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": "10.1038/s41467-020-19693-x", "report-no": null, "categories": "cs.NE cs.LG physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-learning recently show great success across disciplines yet\nconventionally require time-consuming computer processing or bulky-sized\ndiffractive elements. Here we theoretically propose and experimentally\ndemonstrate a purely-passive \"meta-neural-network\" with compactness and\nhigh-resolution for real-time recognizing complicated objects by analyzing\nacoustic scattering. We prove our meta-neural-network mimics standard neural\nnetwork despite its small footprint, thanks to unique capability of its\nmetamaterial unit cells, dubbed \"meta-neurons\", to produce\ndeep-subwavelength-distribution of discrete phase shift as learnable parameters\nduring training. The resulting device exhibits the \"intelligence\" to perform\ndesired tasks with potential to address the current trade-off between reducing\ndevice's size, cost and energy consumption and increasing recognition speed and\naccuracy, showcased by an example of handwritten digit recognition. Our\nmechanism opens the route to new metamaterial-based deep-learning paradigms and\nenable conceptual devices such as smart transducers automatically analyzing\nsignals, with far-reaching implications for acoustics, optics and related\nfields.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 11:07:57 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Weng", "Jingkai", ""], ["Ding", "Yujiang", ""], ["Hu", "Chengbo", ""], ["Zhu", "Xue-feng", ""], ["Liang", "Bin", ""], ["Yang", "Jing", ""], ["Cheng", "Jianchun", ""]]}, {"id": "1909.07131", "submitter": "Mohammad Aliannejadi", "authors": "Mohammad Aliannejadi and Dimitrios Rafailidis and Fabio Crestani", "title": "A Joint Two-Phase Time-Sensitive Regularized Collaborative Ranking Model\n  for Point of Interest Recommendation", "comments": "To appear in IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of location-based social networks (LBSNs) has led to a\ntremendous amount of user check-in data. Recommending points of interest (POIs)\nplays a key role in satisfying users' needs in LBSNs. While recent work has\nexplored the idea of adopting collaborative ranking (CR) for recommendation,\nthere have been few attempts to incorporate temporal information for POI\nrecommendation using CR. In this article, we propose a two-phase CR algorithm\nthat incorporates the geographical influence of POIs and is regularized based\non the variance of POIs popularity and users' activities over time. The\ntime-sensitive regularizer penalizes user and POIs that have been more\ntime-sensitive in the past, helping the model to account for their long-term\nbehavioral patterns while learning from user-POI interactions. Moreover, in the\nfirst phase, it attempts to rank visited POIs higher than the unvisited ones,\nand at the same time, apply the geographical influence. In the second phase,\nour algorithm tries to rank users' favorite POIs higher on the recommendation\nlist. Both phases employ a collaborative learning strategy that enables the\nmodel to capture complex latent associations from two different perspectives.\nExperiments on real-world datasets show that our proposed time-sensitive\ncollaborative ranking model beats state-of-the-art POI recommendation methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 11:33:14 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Aliannejadi", "Mohammad", ""], ["Rafailidis", "Dimitrios", ""], ["Crestani", "Fabio", ""]]}, {"id": "1909.07140", "submitter": "Thomas Parnell", "authors": "Dimitrios Sarigiannis, Thomas Parnell, Haris Pozidis", "title": "Weighted Sampling for Combined Model Selection and Hyperparameter Tuning", "comments": "Accepted for presentation at The Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combined algorithm selection and hyperparameter tuning (CASH) problem is\ncharacterized by large hierarchical hyperparameter spaces. Model-free\nhyperparameter tuning methods can explore such large spaces efficiently since\nthey are highly parallelizable across multiple machines. When no prior\nknowledge or meta-data exists to boost their performance, these methods\ncommonly sample random configurations following a uniform distribution. In this\nwork, we propose a novel sampling distribution as an alternative to uniform\nsampling and prove theoretically that it has a better chance of finding the\nbest configuration in a worst-case setting. In order to compare competing\nmethods rigorously in an experimental setting, one must perform statistical\nhypothesis testing. We show that there is little-to-no agreement in the\nautomated machine learning literature regarding which methods should be used.\nWe contrast this disparity with the methods recommended by the broader\nstatistics literature, and identify a suitable approach. We then select three\npopular model-free solutions to CASH and evaluate their performance, with\nuniform sampling as well as the proposed sampling scheme, across 67 datasets\nfrom the OpenML platform. We investigate the trade-off between exploration and\nexploitation across the three algorithms, and verify empirically that the\nproposed sampling distribution improves performance in all cases.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 12:01:12 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 07:57:49 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 12:19:57 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sarigiannis", "Dimitrios", ""], ["Parnell", "Thomas", ""], ["Pozidis", "Haris", ""]]}, {"id": "1909.07142", "submitter": "Shenglan Liu", "authors": "Shenglan Liu, Yang Yu, Yang Liu, Hong Qiao, Lin Feng, Jiashi Feng", "title": "Hierarchic Neighbors Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning now plays a very important role in machine learning and\nmany relevant applications. Although its superior performance in dealing with\nnonlinear data distribution, data sparsity is always a thorny knot. There are\nfew researches to well handle it in manifold learning. In this paper, we\npropose Hierarchic Neighbors Embedding (HNE), which enhance local connection by\nthe hierarchic combination of neighbors. After further analyzing topological\nconnection and reconstruction performance, three different versions of HNE are\ngiven. The experimental results show that our methods work well on both\nsynthetic data and high-dimensional real-world tasks. HNE develops the\noutstanding advantages in dealing with general data. Furthermore, comparing\nwith other popular manifold learning methods, the performance on sparse samples\nand weak-connected manifolds is better for HNE.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 12:07:08 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Liu", "Shenglan", ""], ["Yu", "Yang", ""], ["Liu", "Yang", ""], ["Qiao", "Hong", ""], ["Feng", "Lin", ""], ["Feng", "Jiashi", ""]]}, {"id": "1909.07155", "submitter": "Pankaj Malhotra", "authors": "Jyoti Narwariya, Pankaj Malhotra, Lovekesh Vig, Gautam Shroff, Vishnu\n  Tv", "title": "Meta-Learning for Few-Shot Time Series Classification", "comments": "CoDS COMAD 2020: Proceedings of the 7th ACM IKDD CoDS and 25th COMAD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved state-of-the-art results on time\nseries classification (TSC) tasks. In this work, we focus on leveraging DNNs in\nthe often-encountered practical scenario where access to labeled training data\nis difficult, and where DNNs would be prone to overfitting. We leverage recent\nadvancements in gradient-based meta-learning, and propose an approach to train\na residual neural network with convolutional layers as a meta-learning agent\nfor few-shot TSC. The network is trained on a diverse set of few-shot tasks\nsampled from various domains (e.g. healthcare, activity recognition, etc.) such\nthat it can solve a target task from another domain using only a small number\nof training samples from the target task. Most existing meta-learning\napproaches are limited in practice as they assume a fixed number of target\nclasses across tasks. We overcome this limitation in order to train a common\nagent across domains with each domain having different number of target\nclasses, we utilize a triplet-loss based learning procedure that does not\nrequire any constraints to be enforced on the number of classes for the\nfew-shot TSC tasks. To the best of our knowledge, we are the first to use\nmeta-learning based pre-training for TSC. Our approach sets a new benchmark for\nfew-shot TSC, outperforming several strong baselines on few-shot tasks sampled\nfrom 41 datasets in UCR TSC Archive. We observe that pre-training under the\nmeta-learning paradigm allows the network to quickly adapt to new unseen tasks\nwith small number of labeled instances.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:13:29 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 14:03:45 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 12:58:41 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Narwariya", "Jyoti", ""], ["Malhotra", "Pankaj", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""], ["Tv", "Vishnu", ""]]}, {"id": "1909.07156", "submitter": "Masanari Kimura", "authors": "Masanari Kimura, Masayuki Tanaka", "title": "New Perspective of Interpretability of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known as black-box models. In other words, it\nis difficult to interpret the internal state of the model. Improving the\ninterpretability of DNNs is one of the hot research topics. However, at\npresent, the definition of interpretability for DNNs is vague, and the question\nof what is a highly explanatory model is still controversial. To address this\nissue, we provide the definition of the human predictability of the model, as a\npart of the interpretability of the DNNs. The human predictability proposed in\nthis paper is defined by easiness to predict the change of the inference when\nperturbating the model of the DNNs. In addition, we introduce one example of\nhigh human-predictable DNNs. We discuss that our definition will help to the\nresearch of the interpretability of the DNNs considering various types of\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 07:24:20 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kimura", "Masanari", ""], ["Tanaka", "Masayuki", ""]]}, {"id": "1909.07157", "submitter": "Xianlong Zeng", "authors": "Xianlong Zeng, Soheil Moosavinasab, En-Ju D Lin, Simon Lin, Razvan\n  Bunescu, Chang Liu", "title": "Distributed representation of patients and its use for medical cost\n  prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient representation of patients is very important in the healthcare\ndomain and can help with many tasks such as medical risk prediction. Many\nexisting methods, such as diagnostic Cost Groups (DCG), rely on expert\nknowledge to build patient representation from medical data, which is resource\nconsuming and non-scalable. Unsupervised machine learning algorithms are a good\nchoice for automating the representation learning process. However, there is\nvery little research focusing on onpatient-level representation learning\ndirectly from medical claims. In this paper, weproposed a novel patient vector\nlearning architecture that learns high quality,fixed-length patient\nrepresentation from claims data. We conducted several experiments to test the\nquality of our learned representation, and the empirical results show that our\nlearned patient vectors are superior to vectors learned through other methods\nincluding a popular commercial model. Lastly, we provide potential clinical\ninterpretation for using our representation on predictive tasks, as\ninterpretability is vital in the healthcare domain\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 13:37:46 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Zeng", "Xianlong", ""], ["Moosavinasab", "Soheil", ""], ["Lin", "En-Ju D", ""], ["Lin", "Simon", ""], ["Bunescu", "Razvan", ""], ["Liu", "Chang", ""]]}, {"id": "1909.07158", "submitter": "Kristian Miok", "authors": "Kristian Miok, Dong Nguyen-Doan, Bla\\v{z} \\v{S}krlj, Daniela Zaharie\n  and Marko Robnik-\\v{S}ikonja", "title": "Prediction Uncertainty Estimation for Hate Speech Classification", "comments": "The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-31372-2_24", "journal-ref": "Statistical Language and Speech Processing 2019 Proceedings", "doi": "10.1007/978-3-030-31372-2_24", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a result of social network popularity, in recent years, hate speech\nphenomenon has significantly increased. Due to its harmful effect on minority\ngroups as well as on large communities, there is a pressing need for hate\nspeech detection and filtering. However, automatic approaches shall not\njeopardize free speech, so they shall accompany their decisions with\nexplanations and assessment of uncertainty. Thus, there is a need for\npredictive machine learning models that not only detect hate speech but also\nhelp users understand when texts cross the line and become unacceptable. The\nreliability of predictions is usually not addressed in text classification. We\nfill this gap by proposing the adaptation of deep neural networks that can\nefficiently estimate prediction uncertainty. To reliably detect hate speech, we\nuse Monte Carlo dropout regularization, which mimics Bayesian inference within\nneural networks. We evaluate our approach using different text embedding\nmethods. We visualize the reliability of results with a novel technique that\naids in understanding the classification reliability and errors.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 12:43:17 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 14:29:59 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 11:59:54 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Miok", "Kristian", ""], ["Nguyen-Doan", "Dong", ""], ["\u0160krlj", "Bla\u017e", ""], ["Zaharie", "Daniela", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "1909.07181", "submitter": "Praboda Rajapaksha", "authors": "Praboda Rajapaksha, Reza Farahbakhsh, Noel Crespi, Bruno Defude", "title": "Uncovering Flaming Events on News Media in Social Media", "comments": "This paper has been accepted in 38th IEEE International Performance\n  Computing and Communications Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networking sites (SNSs) facilitate the sharing of ideas and\ninformation through different types of feedback including publishing posts,\nleaving comments and other type of reactions. However, some comments or\nfeedback on SNSs are inconsiderate and offensive, and sometimes this type of\nfeedback has a very negative effect on a target user. The phenomenon known as\nflaming goes hand-in-hand with this type of posting that can trigger almost\ninstantly on SNSs. Most popular users such as celebrities, politicians and news\nmedia are the major victims of the flaming behaviors and so detecting these\ntypes of events will be useful and appreciated. Flaming event can be monitored\nand identified by analyzing negative comments received on a post. Thus, our\nmain objective of this study is to identify a way to detect flaming events in\nSNS using a sentiment prediction method. We use a deep Neural Network (NN)\nmodel that can identity sentiments of variable length sentences and classifies\nthe sentiment of SNSs content (both comments and posts) to discover flaming\nevents. Our deep NN model uses Word2Vec and FastText word embedding methods as\nits training to explore which method is the most appropriate. The labeled\ndataset for training the deep NN is generated using an enhanced lexicon based\napproach. Our deep NN model classifies the sentiment of a sentence into five\nclasses: Very Positive, Positive, Neutral, Negative and Very Negative. To\ndetect flaming incidents, we focus only on the comments classified into the\nNegative and Very Negative classes. As a use-case, we try to explore the\nflaming phenomena in the news media domain and therefore we focused on news\nitems posted by three popular news media on Facebook (BBCNews, CNN and FoxNews)\nto train and test the model.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 13:19:07 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Rajapaksha", "Praboda", ""], ["Farahbakhsh", "Reza", ""], ["Crespi", "Noel", ""], ["Defude", "Bruno", ""]]}, {"id": "1909.07182", "submitter": "Marco Henrique de Almeida In\\'acio", "authors": "Marco Henrique de Almeida In\\'acio and Rafael Izbicki and B\\'alint\n  Gyires-T\\'oth", "title": "Distance Assessment and Hypothesis Testing of High-Dimensional Samples\n  using Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two distinct datasets, an important question is if they have arisen\nfrom the the same data generating function or alternatively how their data\ngenerating functions diverge from one another. In this paper, we introduce an\napproach for measuring the distance between two datasets with high\ndimensionality using variational autoencoders. This approach is augmented by a\npermutation hypothesis test in order to check the hypothesis that the data\ngenerating distributions are the same within a significance level. We evaluate\nboth the distance measurement and hypothesis testing approaches on generated\nand on public datasets. According to the results the proposed approach can be\nused for data exploration (e.g. by quantifying the discrepancy/separability\nbetween categories of images), which can be particularly useful in the early\nphases of the pipeline of most machine learning projects.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 13:19:14 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["In\u00e1cio", "Marco Henrique de Almeida", ""], ["Izbicki", "Rafael", ""], ["Gyires-T\u00f3th", "B\u00e1lint", ""]]}, {"id": "1909.07192", "submitter": "Morteza Noshad Iranzad", "authors": "Morteza Noshad, Li Xu, Alfred Hero", "title": "Learning to Benchmark: Determining Best Achievable Misclassification\n  Error from Training Data", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning to benchmark the best achievable\nclassifier performance. In this problem the objective is to establish\nstatistically consistent estimates of the Bayes misclassification error rate\nwithout having to learn a Bayes-optimal classifier. Our learning to benchmark\nframework improves on previous work on learning bounds on Bayes\nmisclassification rate since it learns the {\\it exact} Bayes error rate instead\nof a bound on error rate. We propose a benchmark learner based on an ensemble\nof $\\epsilon$-ball estimators and Chebyshev approximation. Under a smoothness\nassumption on the class densities we show that our estimator achieves an\noptimal (parametric) mean squared error (MSE) rate of $O(N^{-1})$, where $N$ is\nthe number of samples. Experiments on both simulated and real datasets\nestablish that our proposed benchmark learning algorithm produces estimates of\nthe Bayes error that are more accurate than previous approaches for learning\nbounds on Bayes error probability.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 13:37:59 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Noshad", "Morteza", ""], ["Xu", "Li", ""], ["Hero", "Alfred", ""]]}, {"id": "1909.07208", "submitter": "Emna Rejaibi", "authors": "Emna Rejaibi, Ali Komaty, Fabrice Meriaudeau, Said Agrebi, and Alice\n  Othmani", "title": "MFCC-based Recurrent Neural Network for Automatic Clinical Depression\n  Recognition and Assessment from Speech", "comments": "14 pages, 7 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Clinical depression or Major Depressive Disorder (MDD) is a common and\nserious medical illness. In this paper, a deep recurrent neural network-based\nframework is presented to detect depression and to predict its severity level\nfrom speech. Low-level and high-level audio features are extracted from audio\nrecordings to predict the 24 scores of the Patient Health Questionnaire and the\nbinary class of depression diagnosis. To overcome the problem of the small size\nof Speech Depression Recognition (SDR) datasets, expanding training labels and\ntransferred features are considered. The proposed approach outperforms the\nstate-of-art approaches on the DAIC-WOZ database with an overall accuracy of\n76.27% and a root mean square error of 0.4 in assessing depression, while a\nroot mean square error of 0.168 is achieved in predicting the depression\nseverity levels. The proposed framework has several advantages (fastness,\nnon-invasiveness, and non-intrusion), which makes it convenient for real-time\napplications. The performances of the proposed approach are evaluated under a\nmulti-modal and a multi-features experiments. MFCC based high-level features\nhold relevant information related to depression. Yet, adding visual action\nunits and different other acoustic features further boosts the classification\nresults by 20% and 10% to reach an accuracy of 95.6% and 86%, respectively.\nConsidering visual-facial modality needs to be carefully studied as it sparks\npatient privacy concerns while adding more acoustic features increases the\ncomputation time.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:03:01 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 13:09:24 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Rejaibi", "Emna", ""], ["Komaty", "Ali", ""], ["Meriaudeau", "Fabrice", ""], ["Agrebi", "Said", ""], ["Othmani", "Alice", ""]]}, {"id": "1909.07214", "submitter": "Ari Ercole", "authors": "Jacob Deasy, Pietro Li\\`o, Ari Ercole", "title": "Dynamic survival prediction in intensive care units from heterogeneous\n  time series without the need for variable selection or pre-processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a machine learning pipeline and model that uses the entire\nuncurated EHR for prediction of in-hospital mortality at arbitrary time\nintervals, using all available chart, lab and output events, without the need\nfor pre-processing or feature engineering. Data for more than 45,000 American\nICU patients from the MIMIC-III database were used to develop an ICU mortality\nprediction model. All chart, lab and output events were treated by the model in\nthe same manner inspired by Natural Language Processing (NLP). Patient events\nwere discretized by percentile and mapped to learnt embeddings before being\npassed to a Recurrent Neural Network (RNN) to provide early prediction of\nin-patient mortality risk. We compared mortality predictions with the\nSimplified Acute Physiology Score II (SAPS II) and the Oxford Acute Severity of\nIllness Score (OASIS). Data were split into an independent test set (10%) and a\nten-fold cross-validation was carried out during training to avoid overfitting.\n13,233 distinct variables with heterogeneous data types were included without\nmanual selection or pre-processing. Recordings in the first few hours of a\npatient's stay were found to be strongly predictive of mortality, outperforming\nmodels using SAPS II and OASIS scores within just 2 hours and achieving a state\nof the art Area Under the Receiver Operating Characteristic (AUROC) value of\n0.80 (95% CI 0.79-0.80) at 12 hours vs 0.70 and 0.66 for SAPS II and OASIS at\n24 hours respectively. Our model achieves a very strong performance of AUROC\n0.86 (95% CI 0.85-0.86) for in-patient mortality prediction after 48 hours on\nthe MIMIC-III dataset. Predictive performance increases over the first 48 hours\nof the ICU stay, but suffers from diminishing returns, providing rationale for\ntime-limited trials of critical care and suggesting that the timing of decision\nmaking can be optimised and individualised.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 13:26:07 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 08:01:19 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Deasy", "Jacob", ""], ["Li\u00f2", "Pietro", ""], ["Ercole", "Ari", ""]]}, {"id": "1909.07218", "submitter": "Thomas Parnell", "authors": "Johanna Sommer, Dimitrios Sarigiannis, Thomas Parnell", "title": "Learning to Tune XGBoost with XGBoost", "comments": "Accepted for presentation at The 3rd Workshop on Meta-Learning\n  (Meta-Learn 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short paper we investigate whether meta-learning techniques can be\nused to more effectively tune the hyperparameters of machine learning models\nusing successive halving (SH). We propose a novel variant of the SH algorithm\n(MeSH), that uses meta-regressors to determine which candidate configurations\nshould be eliminated at each round. We apply MeSH to the problem of tuning the\nhyperparameters of a gradient-boosted decision tree model. By training and\ntuning our meta-regressors using existing tuning jobs from 95 datasets, we\ndemonstrate that MeSH can often find a superior solution to both SH and random\nsearch.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:09:55 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 09:47:33 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 08:20:12 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 13:00:45 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sommer", "Johanna", ""], ["Sarigiannis", "Dimitrios", ""], ["Parnell", "Thomas", ""]]}, {"id": "1909.07227", "submitter": "Phu H Phung", "authors": "Duc-Ly Vu, Trong-Kha Nguyen, Tam V. Nguyen, Tu N. Nguyen, Fabio\n  Massacci, and Phu H. Phung", "title": "A Convolutional Transformation Network for Malware Classification", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern malware evolves various detection avoidance techniques to bypass the\nstate-of-the-art detection methods. An emerging trend to deal with this issue\nis the combination of image transformation and machine learning techniques to\nclassify and detect malware. However, existing works in this field only perform\nsimple image transformation methods that limit the accuracy of the detection.\nIn this paper, we introduce a novel approach to classify malware by using a\ndeep network on images transformed from binary samples. In particular, we first\ndevelop a novel hybrid image transformation method to convert binaries into\ncolor images that convey the binary semantics. The images are trained by a deep\nconvolutional neural network that later classifies the test inputs into benign\nor malicious categories. Through the extensive experiments, our proposed method\nsurpasses all baselines and achieves 99.14% in terms of accuracy on the testing\nset.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:17:04 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Vu", "Duc-Ly", ""], ["Nguyen", "Trong-Kha", ""], ["Nguyen", "Tam V.", ""], ["Nguyen", "Tu N.", ""], ["Massacci", "Fabio", ""], ["Phung", "Phu H.", ""]]}, {"id": "1909.07231", "submitter": "Muhamad Risqi U. Saputra", "authors": "Muhamad Risqi U. Saputra, Pedro P.B. de Gusmao, Chris Xiaoxuan Lu,\n  Yasin Almalioglu, Stefano Rosa, Changhao Chen, Johan Wahlstr\\\"om, Wei Wang,\n  Andrew Markham, Niki Trigoni", "title": "DeepTIO: A Deep Thermal-Inertial Odometry with Visual Hallucination", "comments": "Accepted to IEEE Robotics and Automation Letters (RAL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual odometry shows excellent performance in a wide range of environments.\nHowever, in visually-denied scenarios (e.g. heavy smoke or darkness), pose\nestimates degrade or even fail. Thermal cameras are commonly used for\nperception and inspection when the environment has low visibility. However,\ntheir use in odometry estimation is hampered by the lack of robust visual\nfeatures. In part, this is as a result of the sensor measuring the ambient\ntemperature profile rather than scene appearance and geometry. To overcome this\nissue, we propose a Deep Neural Network model for thermal-inertial odometry\n(DeepTIO) by incorporating a visual hallucination network to provide the\nthermal network with complementary information. The hallucination network is\ntaught to predict fake visual features from thermal images by using Huber loss.\nWe also employ selective fusion to attentively fuse the features from three\ndifferent modalities, i.e thermal, hallucination, and inertial features.\nExtensive experiments are performed in hand-held and mobile robot data in\nbenign and smoke-filled environments, showing the efficacy of the proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:19:42 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 22:42:04 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Saputra", "Muhamad Risqi U.", ""], ["de Gusmao", "Pedro P. B.", ""], ["Lu", "Chris Xiaoxuan", ""], ["Almalioglu", "Yasin", ""], ["Rosa", "Stefano", ""], ["Chen", "Changhao", ""], ["Wahlstr\u00f6m", "Johan", ""], ["Wang", "Wei", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1909.07239", "submitter": "Florian K\\\"opf", "authors": "Florian K\\\"opf, Simon Ramsteiner, Michael Flad and S\\\"oren Hohmann", "title": "Adaptive Dynamic Programming for Model-free Tracking of Trajectories\n  with Time-varying Parameters", "comments": "This is a preprint submitted to the Int J Adapt Control Signal\n  Process. The substantially revised version will be published in the Int J\n  Adapt Control Signal Process (DOI: 10.1002/ACS.3106)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to autonomously learn to control unknown systems optimally w.r.t. an\nobjective function, Adaptive Dynamic Programming (ADP) is well-suited to adapt\ncontrollers based on experience from interaction with the system. In recent\nyears, many researchers focused on the tracking case, where the aim is to\nfollow a desired trajectory. So far, ADP tracking controllers assume that the\nreference trajectory follows time-invariant exo-system dynamics-an assumption\nthat does not hold for many applications. In order to overcome this limitation,\nwe propose a new Q-function which explicitly incorporates a parametrized\napproximation of the reference trajectory. This allows to learn to track a\ngeneral class of trajectories by means of ADP. Once our Q-function has been\nlearned, the associated controller copes with time-varying reference\ntrajectories without need of further training and independent of exo-system\ndynamics. After proposing our general model-free off-policy tracking method, we\nprovide analysis of the important special case of linear quadratic tracking. We\nconclude our paper with an example which demonstrates that our new method\nsuccessfully learns the optimal tracking controller and outperforms existing\napproaches in terms of tracking error and cost.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:37:31 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 12:14:37 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 17:44:44 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 09:10:08 GMT"}, {"version": "v5", "created": "Mon, 17 Feb 2020 08:13:03 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["K\u00f6pf", "Florian", ""], ["Ramsteiner", "Simon", ""], ["Flad", "Michael", ""], ["Hohmann", "S\u00f6ren", ""]]}, {"id": "1909.07245", "submitter": "Alun Preece", "authors": "Alun Preece", "title": "BMVC 2019: Workshop on Interpretable and Explainable Machine Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proceedings of the BMVC 2019 Workshop on Interpretable and Explainable\nMachine Vision, Cardiff, UK, September 12, 2019.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:44:19 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Preece", "Alun", ""]]}, {"id": "1909.07268", "submitter": "Jessica Rivera Villicana", "authors": "Jessica Rivera-Villicana, Fabio Zambetta, James Harland, Marsha Berry", "title": "Exploring Apprenticeship Learning for Player Modelling in Interactive\n  Narratives", "comments": "Extended Abstracts of the 2019 Annual Symposium on Computer-Human\n  Interaction in Play (CHI Play)", "journal-ref": null, "doi": "10.1145/3341215.3356314", "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an early Apprenticeship Learning approach to mimic\nthe behaviour of different players in a short adaption of the interactive\nfiction Anchorhead. Our motivation is the need to understand and simulate\nplayer behaviour to create systems to aid the design and personalisation of\nInteractive Narratives (INs). INs are partially observable for the players and\ntheir goals are dynamic as a result. We used Receding Horizon IRL (RHIRL) to\nlearn players' goals in the form of reward functions, and derive policies to\nimitate their behaviour. Our preliminary results suggest that RHIRL is able to\nlearn action sequences to complete a game, and provided insights towards\ngenerating behaviour more similar to specific players.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:15:57 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Rivera-Villicana", "Jessica", ""], ["Zambetta", "Fabio", ""], ["Harland", "James", ""], ["Berry", "Marsha", ""]]}, {"id": "1909.07278", "submitter": "Zhenjie Ren", "authors": "Kaitong Hu and Anna Kazeykina and Zhenjie Ren", "title": "Mean-field Langevin System, Optimal Control and Deep Neural Networks", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a regularised relaxed optimal control problem and, in\nparticular, we are concerned with the case where the control variable is of\nlarge dimension. We introduce a system of mean-field Langevin equations, the\ninvariant measure of which is shown to be the optimal control of the initial\nproblem under mild conditions. Therefore, this system of processes can be\nviewed as a continuous-time numerical algorithm for computing the optimal\ncontrol. As an application, this result endorses the solvability of the\nstochastic gradient descent algorithm for a wide class of deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:31:25 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 19:41:20 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Hu", "Kaitong", ""], ["Kazeykina", "Anna", ""], ["Ren", "Zhenjie", ""]]}, {"id": "1909.07279", "submitter": "Felipe Tobar", "authors": "Felipe Tobar", "title": "Band-Limited Gaussian Processes: The Sinc Kernel", "comments": "To appear at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel class of Gaussian processes (GPs) whose spectra have\ncompact support, meaning that their sample trajectories are almost-surely band\nlimited. As a complement to the growing literature on spectral design of\ncovariance kernels, the core of our proposal is to model power spectral\ndensities through a rectangular function, which results in a kernel based on\nthe sinc function with straightforward extensions to non-centred (around zero\nfrequency) and frequency-varying cases. In addition to its use in regression,\nthe relationship between the sinc kernel and the classic theory is illuminated,\nin particular, the Shannon-Nyquist theorem is interpreted as posterior\nreconstruction under the proposed kernel. Additionally, we show that the sinc\nkernel is instrumental in two fundamental signal processing applications:\nfirst, in stereo amplitude modulation, where the non-centred sinc kernel arises\nnaturally. Second, for band-pass filtering, where the proposed kernel allows\nfor a Bayesian treatment that is robust to observation noise and missing data.\nThe developed theory is complemented with illustrative graphic examples and\nvalidated experimentally using real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:31:58 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Tobar", "Felipe", ""]]}, {"id": "1909.07283", "submitter": "Paul Temple", "authors": "Paul Temple, Mathieu Acher, Gilles Perrouin, Battista Biggio,\n  Jean-marc Jezequel, Fabio Roli", "title": "Towards Quality Assurance of Software Product Lines with Adversarial\n  Configurations", "comments": "This is a preview version of a paper accepted and presented at\n  SPLC'19 that took place in Paris from 9th to 13th of September 2019. Some\n  minor changes might appear compared to the one from the proceedings of the\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software product line (SPL) engineers put a lot of effort to ensure that,\nthrough the setting of a large number of possible configuration options,\nproducts are acceptable and well-tailored to customers' needs. Unfortunately,\noptions and their mutual interactions create a huge configuration space which\nis intractable to exhaustively explore. Instead of testing all products,\nmachine learning techniques are increasingly employed to approximate the set of\nacceptable products out of a small training sample of configurations. Machine\nlearning (ML) techniques can refine a software product line through learned\nconstraints and a priori prevent non-acceptable products to be derived. In this\npaper, we use adversarial ML techniques to generate adversarial configurations\nfooling ML classifiers and pinpoint incorrect classifications of products\n(videos) derived from an industrial video generator. Our attacks yield (up to)\na 100% misclassification rate and a drop in accuracy of 5%. We discuss the\nimplications these results have on SPL quality assurance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:37:00 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Temple", "Paul", ""], ["Acher", "Mathieu", ""], ["Perrouin", "Gilles", ""], ["Biggio", "Battista", ""], ["Jezequel", "Jean-marc", ""], ["Roli", "Fabio", ""]]}, {"id": "1909.07294", "submitter": "Peter Morales", "authors": "Peter Morales, Rajmonda Sulo Caceres, Tina Eliassi-Rad", "title": "Selective Network Discovery via Deep Reinforcement Learning on Embedded\n  Spaces", "comments": "Submitted for review to the journal of applied network science\n  (2020). This adds several new sections from the original complex networks\n  submission which can be viewed under v1 or at\n  https://link.springer.com/chapter/10.1007/978-3-030-36687-2_75", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks are often either too large for full exploration, partially\naccessible, or partially observed. Downstream learning tasks on these\nincomplete networks can produce low quality results. In addition, reducing the\nincompleteness of the network can be costly and nontrivial. As a result,\nnetwork discovery algorithms optimized for specific downstream learning tasks\ngiven resource collection constraints are of great interest. In this paper, we\nformulate the task-specific network discovery problem in an incomplete network\nsetting as a sequential decision making problem. Our downstream task is\nselective harvesting, the optimal collection of vertices with a particular\nattribute. We propose a framework, called Network Actor Critic (NAC), which\nlearns a policy and notion of future reward in an offline setting via a deep\nreinforcement learning algorithm. The NAC paradigm utilizes a task-specific\nnetwork embedding to reduce the state space complexity. A detailed comparative\nanalysis of popular network embeddings is presented with respect to their role\nin supporting offline planning. Furthermore, a quantitative study is presented\non several synthetic and real benchmarks using NAC and several baselines. We\nshow that offline models of reward and network discovery policies lead to\nsignificantly improved performance when compared to competitive online\ndiscovery algorithms. Finally, we outline learning regimes where planning is\ncritical in addressing sparse and changing reward signals.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:51:27 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 21:47:28 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Morales", "Peter", ""], ["Caceres", "Rajmonda Sulo", ""], ["Eliassi-Rad", "Tina", ""]]}, {"id": "1909.07299", "submitter": "Alper Kamil Bozkurt", "authors": "Alper Kamil Bozkurt, Yu Wang, Michael M. Zavlanos, Miroslav Pajic", "title": "Control Synthesis from Linear Temporal Logic Specifications using\n  Model-Free Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning (RL) framework to synthesize a control\npolicy from a given linear temporal logic (LTL) specification in an unknown\nstochastic environment that can be modeled as a Markov Decision Process (MDP).\nSpecifically, we learn a policy that maximizes the probability of satisfying\nthe LTL formula without learning the transition probabilities. We introduce a\nnovel rewarding and path-dependent discounting mechanism based on the LTL\nformula such that (i) an optimal policy maximizing the total discounted reward\neffectively maximizes the probabilities of satisfying LTL objectives, and (ii)\na model-free RL algorithm using these rewards and discount factors is\nguaranteed to converge to such policy. Finally, we illustrate the applicability\nof our RL-based synthesis approach on two motion planning case studies.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 15:56:32 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 05:13:27 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Bozkurt", "Alper Kamil", ""], ["Wang", "Yu", ""], ["Zavlanos", "Michael M.", ""], ["Pajic", "Miroslav", ""]]}, {"id": "1909.07310", "submitter": "Ole-Christoffer Granmo", "authors": "Saeed Rahimi Gorji, Ole-Christoffer Granmo, Adrian Phoulady, Morten\n  Goodwin", "title": "A Tsetlin Machine with Multigranular Clauses", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced Tsetlin Machine (TM) has provided competitive pattern\nrecognition accuracy in several benchmarks, however, requires a 3-dimensional\nhyperparameter search. In this paper, we introduce the Multigranular Tsetlin\nMachine (MTM). The MTM eliminates the specificity hyperparameter, used by the\nTM to control the granularity of the conjunctive clauses that it produces for\nrecognizing patterns. Instead of using a fixed global specificity, we encode\nvarying specificity as part of the clauses, rendering the clauses\nmultigranular. This makes it easier to configure the TM because the\ndimensionality of the hyperparameter search space is reduced to only two\ndimensions. Indeed, it turns out that there is significantly less\nhyperparameter tuning involved in applying the MTM to new problems. Further, we\ndemonstrate empirically that the MTM provides similar performance to what is\nachieved with a finely specificity-optimized TM, by comparing their performance\non both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 16:09:34 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Gorji", "Saeed Rahimi", ""], ["Granmo", "Ole-Christoffer", ""], ["Phoulady", "Adrian", ""], ["Goodwin", "Morten", ""]]}, {"id": "1909.07328", "submitter": "Nuri Cingillioglu", "authors": "Nuri Cingillioglu and Alessandra Russo", "title": "Learning Invariants through Soft Unification", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human reasoning involves recognising common underlying principles across many\nexamples. The by-products of such reasoning are invariants that capture\npatterns such as \"if someone went somewhere then they are there\", expressed\nusing variables \"someone\" and \"somewhere\" instead of mentioning specific people\nor places. Humans learn what variables are and how to use them at a young age.\nThis paper explores whether machines can also learn and use variables solely\nfrom examples without requiring human pre-engineering. We propose Unification\nNetworks, an end-to-end differentiable neural network approach capable of\nlifting examples into invariants and using those invariants to solve a given\ntask. The core characteristic of our architecture is soft unification between\nexamples that enables the network to generalise parts of the input into\nvariables, thereby learning invariants. We evaluate our approach on five\ndatasets to demonstrate that learning invariants captures patterns in the data\nand can improve performance over baselines.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 16:48:52 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 10:24:14 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Cingillioglu", "Nuri", ""], ["Russo", "Alessandra", ""]]}, {"id": "1909.07330", "submitter": "Yashar Kiarashinejad", "authors": "Yashar Kiarashinejad, Mohammadreza Zandehshahvar, Sajjad\n  Abdollahramezani, Omid Hemmatyar, Reza Pourabolghasem, and Ali Adibi", "title": "Knowledge Discovery In Nanophotonics Using Geometric Deep Learning", "comments": "Adv. Intell. Syst. (2020)", "journal-ref": null, "doi": "10.1002/aisy.201900132", "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here a new approach for using the intelligence aspects of\nartificial intelligence for knowledge discovery rather than device optimization\nin electromagnetic (EM) nanostructures. This approach uses training data\nobtained through full-wave EM simulations of a series of nanostructures to\ntrain geometric deep learning algorithms to assess the range of feasible\nresponses as well as the feasibility of a desired response from a class of EM\nnanostructures. To facilitate the knowledge discovery and reduce the\ncomputation complexity, our approach combines the dimensionality reduction\ntechnique (using an autoencoder) with convex-hull and one-class\nsupport-vector-machine (SVM) algorithms to find the range of the feasible\nresponses in the latent (or the reduced) response space of the EM\nnanostructure. We show that by using a small set of training instances\n(compared to all possible structures), our approach can provide better than 95%\naccuracy in assessing the feasibility of a given response. More importantly,\nthe one-class SVM algorithm can be trained to provide the degree of feasibility\n(or unfeasibility) of a response from a given nanostructure. This important\ninformation can be used to modify the initial structure to an alternative one\nthat can enable an initially unfeasible response. To show the applicability of\nour approach, we apply it to two important classes of binary metasurfaces\n(MSs), formed by array of plasmonic nanostructures, and periodic MSs formed by\nan array of dielectric nanopillars. In addition to theoretical results, we show\nthe experimental results obtained by fabricating several MSs of the second\nclass. Our theoretical and experimental results confirm the unique features of\nthis approach for knowledge discovery in EM nanostructures.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 16:52:53 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kiarashinejad", "Yashar", ""], ["Zandehshahvar", "Mohammadreza", ""], ["Abdollahramezani", "Sajjad", ""], ["Hemmatyar", "Omid", ""], ["Pourabolghasem", "Reza", ""], ["Adibi", "Ali", ""]]}, {"id": "1909.07368", "submitter": "Madjid Khalilian", "authors": "Madjid Khalilian, Shiva Hassanzadeh", "title": "Document classification methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information on different fields which are collected by users requires\nappropriate management and organization to be structured in a standard way and\nretrieved fast and more easily. Document classification is a conventional\nmethod to separate text based on their subjects among scientific text, web\npages and digital library. Different methods and techniques are proposed for\ndocument classifications that have advantages and deficiencies. In this paper,\nseveral unsupervised and supervised document classification methods are studied\nand compared.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 20:42:57 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Khalilian", "Madjid", ""], ["Hassanzadeh", "Shiva", ""]]}, {"id": "1909.07369", "submitter": "Xingbo Fu", "authors": "Xingbo Fu, Feng Gao, Jiang Wu, Xinyu Wei, Fangwei Duan", "title": "Spatiotemporal Attention Networks for Wind Power Forecasting", "comments": "ICDM 2019 Workshop - DeepSpatial2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wind power is one of the most important renewable energy sources and accurate\nwind power forecasting is very significant for reliable and economic power\nsystem operation and control strategies. This paper proposes a novel framework\nwith spatiotemporal attention networks (STAN) for wind power forecasting. This\nmodel captures spatial correlations among wind farms and temporal dependencies\nof wind power time series. First of all, we employ a multi-head self-attention\nmechanism to extract spatial correlations among wind farms. Then, temporal\ndependencies are captured by the Sequence-to-Sequence (Seq2Seq) model with a\nglobal attention mechanism. Finally, experimental results demonstrate that our\nmodel achieves better performance than other baseline approaches. Our work\nprovides useful insights to capture non-Euclidean spatial correlations.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 02:29:49 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 05:51:57 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Fu", "Xingbo", ""], ["Gao", "Feng", ""], ["Wu", "Jiang", ""], ["Wei", "Xinyu", ""], ["Duan", "Fangwei", ""]]}, {"id": "1909.07370", "submitter": "Awais Ashfaq", "authors": "Awais Ashfaq, Slawomir Nowaczyk", "title": "Machine learning in healthcare -- a system's perspective", "comments": "ACM SIGKDD Workshop on Epidemiology meets Data Mining and Knowledge\n  Discovery (epiDAMIK), August 2019 Anchorage, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A consequence of the fragmented and siloed healthcare landscape is that\npatient care (and data) is split along multitude of different facilities and\ncomputer systems and enabling interoperability between these systems is hard.\nThe lack interoperability not only hinders continuity of care and burdens\nproviders, but also hinders effective application of Machine Learning (ML)\nalgorithms. Thus, most current ML algorithms, designed to understand patient\ncare and facilitate clinical decision-support, are trained on limited datasets.\nThis approach is analogous to the Newtonian paradigm of Reductionism in which a\nsystem is broken down into elementary components and a description of the whole\nis formed by understanding those components individually. A key limitation of\nthe reductionist approach is that it ignores the component-component\ninteractions and dynamics within the system which are often of prime\nsignificance in understanding the overall behaviour of complex adaptive systems\n(CAS). Healthcare is a CAS.\n  Though the application of ML on health data have shown incremental\nimprovements for clinical decision support, ML has a much a broader potential\nto restructure care delivery as a whole and maximize care value. However, this\nML potential remains largely untapped: primarily due to functional limitations\nof Electronic Health Records (EHR) and the inability to see the healthcare\nsystem as a whole. This viewpoint (i) articulates the healthcare as a complex\nsystem which has a biological and an organizational perspective, (ii) motivates\nwith examples, the need of a system's approach when addressing healthcare\nchallenges via ML and, (iii) emphasizes to unleash EHR functionality - while\nduly respecting all ethical and legal concerns - to reap full benefits of ML.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 06:13:53 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 21:50:27 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ashfaq", "Awais", ""], ["Nowaczyk", "Slawomir", ""]]}, {"id": "1909.07373", "submitter": "Zac Wellmer", "authors": "Zac Wellmer, James Kwok", "title": "Policy Prediction Network: Model-Free Behavior Policy with Model-Based\n  Learning in Continuous Action Space", "comments": "Published at ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel deep reinforcement learning architecture that was\ninspired by previous tree structured architectures which were only useable in\ndiscrete action spaces. Policy Prediction Network offers a way to improve\nsample complexity and performance on continuous control problems in exchange\nfor extra computation at training time but at no cost in computation at rollout\ntime. Our approach integrates a mix between model-free and model-based\nreinforcement learning. Policy Prediction Network is the first to introduce\nimplicit model-based learning to Policy Gradient algorithms for continuous\naction space and is made possible via the empirically justified clipping\nscheme. Our experiments are focused on the MuJoCo environments so that they can\nbe compared with similar work done in this area.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 12:39:02 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Wellmer", "Zac", ""], ["Kwok", "James", ""]]}, {"id": "1909.07374", "submitter": "Yanlong Huang", "authors": "Yanlong Huang and Darwin G. Caldwell", "title": "A Linearly Constrained Nonparametric Framework for Imitation Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a myriad of advanced results have been reported in the\ncommunity of imitation learning, ranging from parametric to non-parametric,\nprobabilistic to non-probabilistic and Bayesian to frequentist approaches.\nMeanwhile, ample applications (e.g., grasping tasks and human-robot\ncollaborations) further show the applicability of imitation learning in a wide\nrange of domains. While numerous literature is dedicated to the learning of\nhuman skills in unconstrained environment, the problem of learning constrained\nmotor skills, however, has not received equal attention yet. In fact,\nconstrained skills exist widely in robotic systems. For instance, when a robot\nis demanded to write letters on a board, its end-effector trajectory must\ncomply with the plane constraint from the board. In this paper, we aim to\ntackle the problem of imitation learning with linear constraints. Specifically,\nwe propose to exploit the probabilistic properties of multiple demonstrations,\nand subsequently incorporate them into a linearly constrained optimization\nproblem, which finally leads to a non-parametric solution. In addition, a\nconnection between our framework and the classical model predictive control is\nprovided. Several examples including simulated writing and locomotion tasks are\npresented to show the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 13:34:34 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Huang", "Yanlong", ""], ["Caldwell", "Darwin G.", ""]]}, {"id": "1909.07376", "submitter": "Niko S\\\"underhauf", "authors": "Niko S\\\"underhauf", "title": "Where are the Keys? -- Learning Object-Centric Navigation Policies on\n  Semantic Maps with Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging object-based SLAM algorithms can build a graph representation of an\nenvironment comprising nodes for robot poses and object landmarks. However,\nwhile this map will contain static objects such as furniture or appliances,\nmany moveable objects (e.g. the car keys, the glasses, or a magazine), are not\nsuitable as landmarks and will not be part of the map due to their non-static\nnature. We show that Graph Convolutional Networks can learn navigation policies\nto find such unmapped objects by learning to exploit the hidden probabilistic\nmodel that governs where these objects appear in the environment. The learned\npolicies can generalise to object classes unseen during training by using word\nvectors that express semantic similarity as representations for object nodes in\nthe graph. Furthermore, we show that the policies generalise to unseen\nenvironments with only minimal loss of performance. We demonstrate that\npre-training the policy network with a proxy task can significantly speed up\nlearning, improving sample efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 05:43:22 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 23:13:21 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["S\u00fcnderhauf", "Niko", ""]]}, {"id": "1909.07378", "submitter": "Mingzhu Shen", "authors": "Mingzhu Shen and Kai Han and Chunjing Xu and Yunhe Wang", "title": "Searching for Accurate Binary Neural Architectures", "comments": "Accepted by ICCV 2019 Neural Architects Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary neural networks have attracted tremendous attention due to the\nefficiency for deploying them on mobile devices. Since the weak expression\nability of binary weights and features, their accuracy is usually much lower\nthan that of full-precision (i.e. 32-bit) models. Here we present a new frame\nwork for automatically searching for compact but accurate binary neural\nnetworks. In practice, number of channels in each layer will be encoded into\nthe search space and optimized using the evolutionary algorithm. Experiments\nconducted on benchmark datasets and neural architectures demonstrate that our\nsearched binary networks can achieve the performance of full-precision models\nwith acceptable increments on model sizes and calculations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 09:15:53 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Shen", "Mingzhu", ""], ["Han", "Kai", ""], ["Xu", "Chunjing", ""], ["Wang", "Yunhe", ""]]}, {"id": "1909.07425", "submitter": "Abdul Fatir Ansari", "authors": "Abdul Fatir Ansari, Jonathan Scarlett, Harold Soh", "title": "A Characteristic Function Approach to Deep Implicit Generative Modeling", "comments": "CVPR 2020 (Oral), Code available at\n  https://github.com/clear-nus/OCFGAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit Generative Models (IGMs) such as GANs have emerged as effective\ndata-driven models for generating samples, particularly images. In this paper,\nwe formulate the problem of learning an IGM as minimizing the expected distance\nbetween characteristic functions. Specifically, we minimize the distance\nbetween characteristic functions of the real and generated data distributions\nunder a suitably-chosen weighting distribution. This distance metric, which we\nterm as the characteristic function distance (CFD), can be (approximately)\ncomputed with linear time-complexity in the number of samples, in contrast with\nthe quadratic-time Maximum Mean Discrepancy (MMD). By replacing the discrepancy\nmeasure in the critic of a GAN with the CFD, we obtain a model that is simple\nto implement and stable to train. The proposed metric enjoys desirable\ntheoretical properties including continuity and differentiability with respect\nto generator parameters, and continuity in the weak topology. We further\npropose a variation of the CFD in which the weighting distribution parameters\nare also optimized during training; this obviates the need for manual tuning,\nand leads to an improvement in test power relative to CFD. We demonstrate\nexperimentally that our proposed method outperforms WGAN and MMD-GAN variants\non a variety of unsupervised image generation benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 18:19:49 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 18:19:16 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Ansari", "Abdul Fatir", ""], ["Scarlett", "Jonathan", ""], ["Soh", "Harold", ""]]}, {"id": "1909.07440", "submitter": "Jeremy Welborn", "authors": "Jeremy Welborn, Michael Schaarschmidt, Eiko Yoneki", "title": "Learning Index Selection with Structured Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Configuration spaces for computer systems can be challenging for traditional\nand automatic tuning strategies. Injecting task-specific knowledge into the\ntuner for a task may allow for more efficient exploration of candidate\nconfigurations. We apply this idea to the task of index set selection to\naccelerate database workloads. Index set selection has been amenable to recent\napplications of vanilla deep RL, but real deployments remain out of reach. In\nthis paper, we explore how learning index selection can be enhanced with\ntask-specific inductive biases, specifically by encoding these inductive biases\nin better action structures. Index selection-specific action representations\narise when the problem is reformulated in terms of permutation learning and we\nrely on recent work for learning RL policies on permutations. Through this\napproach, we build an indexing agent that is able to achieve improved indexing\nand validate its behavior with task-specific statistics. Early experiments\nreveal that our agent can find configurations that are up to 40% smaller for\nthe same levels of latency as compared with other approaches and indicate more\nintuitive indexing behavior.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 19:16:41 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Welborn", "Jeremy", ""], ["Schaarschmidt", "Michael", ""], ["Yoneki", "Eiko", ""]]}, {"id": "1909.07444", "submitter": "Ephrem Admasu Yekun", "authors": "Ephrem Admasu Yekun and Abrahaley Teklay", "title": "Student Performance Prediction with Optimum Multilabel Ensemble Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the important measures of quality of education is the performance of\nstudents in the academic settings. Nowadays, abundant data is stored in\neducational institutions about students which can help to discover insight on\nhow students are learning and how to improve their performance ahead of time\nusing data mining techniques. In this paper, we developed a student performance\nprediction model that predicts the performance of high school students for the\nnext semester for five courses. We modeled our prediction system as a\nmulti-label classification task and used support vector machine (SVM), Random\nForest (RF), K-nearest Neighbors (KNN), and Mult-layer perceptron (MLP) as\nbase-classifiers to train our model. We further improved the performance of the\nprediction model using state-of-the-art partitioning schemes to divide the\nlabel space into smaller spaces and use Label Powerset (LP) transformation\nmethod to transform each labelset into a multi-class classification task. The\nproposed model achieved better performance in terms of different evaluation\nmetrics when compared to other multi-label learning tasks such as binary\nrelevance and classifier chains.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 11:59:26 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Yekun", "Ephrem Admasu", ""], ["Teklay", "Abrahaley", ""]]}, {"id": "1909.07452", "submitter": "Paritosh Ramanan", "authors": "Paritosh Ramanan, Kiyoshi Nakayama", "title": "BAFFLE : Blockchain Based Aggregator Free Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key aspect of Federated Learning (FL) is the requirement of a centralized\naggregator to maintain and update the global model. However, in many cases\norchestrating a centralized aggregator might be infeasible due to numerous\noperational constraints. In this paper, we introduce BAFFLE, an aggregator\nfree, blockchain driven, FL environment that is inherently decentralized.\nBAFFLE leverages Smart Contracts (SC) to coordinate the round delineation,\nmodel aggregation and update tasks in FL. BAFFLE boosts computational\nperformance by decomposing the global parameter space into distinct chunks\nfollowed by a score and bid strategy. In order to characterize the performance\nof BAFFLE, we conduct experiments on a private Ethereum network and use the\ncentralized and aggregator driven methods as our benchmark. We show that BAFFLE\nsignificantly reduces the gas costs for FL on the blockchain as compared to a\ndirect adaptation of the aggregator based method. Our results also show that\nBAFFLE achieves high scalability and computational efficiency while delivering\nsimilar accuracy as the benchmark methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 19:47:26 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 23:00:13 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 17:57:29 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ramanan", "Paritosh", ""], ["Nakayama", "Kiyoshi", ""]]}, {"id": "1909.07464", "submitter": "Xiaotong Liu", "authors": "Xiaotong Liu, Hong Xuan, Zeyu Zhang, Abby Stylianou, Robert Pless", "title": "Visualizing How Embeddings Generalize", "comments": "8 pages,4 figures, published in ICML workshop:Understanding and\n  Improving Generalization in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep metric learning is often used to learn an embedding function that\ncaptures the semantic differences within a dataset. A key factor in many\nproblem domains is how this embedding generalizes to new classes of data. In\nobserving many triplet selection strategies for Metric Learning, we find that\nthe best performance consistently arises from approaches that focus on a few,\nwell selected triplets.We introduce visualization tools to illustrate how an\nembedding generalizes beyond measuring accuracy on validation data, and we\nillustrate the behavior of a range of triplet selection strategies.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 20:18:38 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Liu", "Xiaotong", ""], ["Xuan", "Hong", ""], ["Zhang", "Zeyu", ""], ["Stylianou", "Abby", ""], ["Pless", "Robert", ""]]}, {"id": "1909.07471", "submitter": "Kunal Bagewadi", "authors": "Kunal Bagewadi, Joseph Campbell, Heni Ben Amor", "title": "Multimodal Dataset of Human-Robot Hugging Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": "AI-HRI/2019/09", "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hug is a tight embrace and an expression of warmth, sympathy and\ncamaraderie. Despite the fact that a hug often only takes a few seconds, it is\nfilled with details and nuances and is a highly complex process of coordination\nbetween two agents. For human-robot collaborative tasks, it is necessary for\nhumans to develop trust and see the robot as a partner to perform a given task\ntogether. Datasets representing agent-agent interaction are scarce and, if\navailable, of limited quality. To study the underlying phenomena and variations\nin a hug between a person and a robot, we deployed Baxter humanoid robot and\nwearable sensors on persons to record 353 episodes of hugging activity. 33\npeople were given minimal instructions to hug the humanoid robot for as natural\nhugging interaction as possible. In the paper, we present our methodology and\nanalysis of the collected dataset. The use of this dataset is to implement\nmachine learning methods for the humanoid robot to learn to anticipate and\nreact to the movements of a person approaching for a hug. In this regard, we\nshow the significance of the dataset by highlighting certain features in our\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 20:40:40 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Bagewadi", "Kunal", ""], ["Campbell", "Joseph", ""], ["Amor", "Heni Ben", ""]]}, {"id": "1909.07480", "submitter": "Xiao-Yun Zhou", "authors": "Peichao Li, Xiao-Yun Zhou, Zhao-Yang Wang and Guang-Zhong Yang", "title": "Z-Net: an Anisotropic 3D DCNN for Medical CT Volume Segmentation", "comments": "8 pages, 9 figures, two tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate volume segmentation from the Computed Tomography (CT) scan is a\ncommon prerequisite for pre-operative planning, intra-operative guidance and\nquantitative assessment of therapeutic outcomes in robot-assisted Minimally\nInvasive Surgery (MIS). 3D Deep Convolutional Neural Network (DCNN) is a viable\nsolution for this task, but is memory intensive. Small isotropic patches are\ncropped from the original and large CT volume to mitigate this issue in\npractice, but it may cause discontinuities between the adjacent patches and\nsevere class-imbalances within individual sub-volumes. This paper presents a\nnew 3D DCNN framework, namely Z-Net, to tackle the discontinuity and\nclass-imbalance issue by preserving a full field-of-view of the objects in the\nXY planes using anisotropic spatial separable convolutions. The proposed Z-Net\ncan be seamlessly integrated into existing 3D DCNNs with isotropic convolutions\nsuch as 3D U-Net and V-Net, with improved volume segmentation Intersection over\nUnion (IoU) - up to $12.6\\%$. Detailed validation of Z-Net is provided for CT\naortic, liver and lung segmentation, demonstrating the effectiveness and\npractical value of Z-Net for intra-operative 3D navigation in robot-assisted\nMIS.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 20:56:13 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 16:12:39 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Li", "Peichao", ""], ["Zhou", "Xiao-Yun", ""], ["Wang", "Zhao-Yang", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "1909.07481", "submitter": "Shenhao Wang", "authors": "Shenhao Wang, Baichuan Mo, Jinhua Zhao", "title": "Deep Neural Networks for Choice Analysis: Architectural Design with\n  Alternative-Specific Utility Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.GN q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas deep neural network (DNN) is increasingly applied to choice analysis,\nit is challenging to reconcile domain-specific behavioral knowledge with\ngeneric-purpose DNN, to improve DNN's interpretability and predictive power,\nand to identify effective regularization methods for specific tasks. This study\ndesigns a particular DNN architecture with alternative-specific utility\nfunctions (ASU-DNN) by using prior behavioral knowledge. Unlike a fully\nconnected DNN (F-DNN), which computes the utility value of an alternative k by\nusing the attributes of all the alternatives, ASU-DNN computes it by using only\nk's own attributes. Theoretically, ASU-DNN can dramatically reduce the\nestimation error of F-DNN because of its lighter architecture and sparser\nconnectivity. Empirically, ASU-DNN has 2-3% higher prediction accuracy than\nF-DNN over the whole hyperparameter space in a private dataset that we\ncollected in Singapore and a public dataset in R mlogit package. The\nalternative-specific connectivity constraint, as a domain-knowledge-based\nregularization method, is more effective than the most popular generic-purpose\nexplicit and implicit regularization methods and architectural hyperparameters.\nASU-DNN is also more interpretable because it provides a more regular\nsubstitution pattern of travel mode choices than F-DNN does. The comparison\nbetween ASU-DNN and F-DNN can also aid in testing the behavioral knowledge. Our\nresults reveal that individuals are more likely to compute utility by using an\nalternative's own attributes, supporting the long-standing practice in choice\nmodeling. Overall, this study demonstrates that prior behavioral knowledge\ncould be used to guide the architecture design of DNN, to function as an\neffective domain-knowledge-based regularization method, and to improve both the\ninterpretability and predictive power of DNN in choice analysis.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 21:01:23 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 22:38:28 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wang", "Shenhao", ""], ["Mo", "Baichuan", ""], ["Zhao", "Jinhua", ""]]}, {"id": "1909.07483", "submitter": "Benjamin Beyret", "authors": "Benjamin Beyret, Jos\\'e Hern\\'andez-Orallo, Lucy Cheke, Marta Halina,\n  Murray Shanahan, Matthew Crosby", "title": "The Animal-AI Environment: Training and Testing Animal-Like Artificial\n  Cognition", "comments": "14 pages, 34 figures (update: reduce images size)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence have been strongly driven by the\nuse of game environments for training and evaluating agents. Games are often\naccessible and versatile, with well-defined state-transitions and goals\nallowing for intensive training and experimentation. However, agents trained in\na particular environment are usually tested on the same or slightly varied\ndistributions, and solutions do not necessarily imply any understanding. If we\nwant AI systems that can model and understand their environment, we need\nenvironments that explicitly test for this. Inspired by the extensive\nliterature on animal cognition, we present an environment that keeps all the\npositive elements of standard gaming environments, but is explicitly designed\nfor the testing of animal-like artificial cognition.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 10:14:12 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 09:07:46 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Beyret", "Benjamin", ""], ["Hern\u00e1ndez-Orallo", "Jos\u00e9", ""], ["Cheke", "Lucy", ""], ["Halina", "Marta", ""], ["Shanahan", "Murray", ""], ["Crosby", "Matthew", ""]]}, {"id": "1909.07490", "submitter": "Rayan Mosli", "authors": "Rayan Mosli, Matthew Wright, Bo Yuan and Yin Pan", "title": "They Might NOT Be Giants: Crafting Black-Box Adversarial Examples with\n  Fewer Queries Using Particle Swarm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have been found to be susceptible to adversarial\nexamples that are often indistinguishable from the original inputs. These\nadversarial examples are created by applying adversarial perturbations to input\nsamples, which would cause them to be misclassified by the target models.\nAttacks that search and apply the perturbations to create adversarial examples\nare performed in both white-box and black-box settings, depending on the\ninformation available to the attacker about the target. For black-box attacks,\nthe only capability available to the attacker is the ability to query the\ntarget with specially crafted inputs and observing the labels returned by the\nmodel. Current black-box attacks either have low success rates, requires a high\nnumber of queries, or produce adversarial examples that are easily\ndistinguishable from their sources. In this paper, we present AdversarialPSO, a\nblack-box attack that uses fewer queries to create adversarial examples with\nhigh success rates. AdversarialPSO is based on the evolutionary search\nalgorithm Particle Swarm Optimization, a populationbased gradient-free\noptimization algorithm. It is flexible in balancing the number of queries\nsubmitted to the target vs the quality of imperceptible adversarial examples.\nThe attack has been evaluated using the image classification benchmark datasets\nCIFAR-10, MNIST, and Imagenet, achieving success rates of 99.6%, 96.3%, and\n82.0%, respectively, while submitting substantially fewer queries than the\nstate-of-the-art. We also present a black-box method for isolating salient\nfeatures used by models when making classifications. This method, called Swarms\nwith Individual Search Spaces or SWISS, creates adversarial examples by finding\nand modifying the most important features in the input.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 21:24:19 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Mosli", "Rayan", ""], ["Wright", "Matthew", ""], ["Yuan", "Bo", ""], ["Pan", "Yin", ""]]}, {"id": "1909.07492", "submitter": "Jakub Mare\\v{c}ek", "authors": "Olivier Massicot and Jakub Marecek", "title": "On-line Non-Convex Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-varying non-convex continuous-valued non-linear constrained optimization\nis a fundamental problem. We study conditions wherein a momentum-like\nregularising term allow for the tracking of local optima by considering an\nordinary differential equation (ODE). We then derive an efficient algorithm\nbased on a predictor-corrector method, to track the ODE solution.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 21:27:40 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Massicot", "Olivier", ""], ["Marecek", "Jakub", ""]]}, {"id": "1909.07502", "submitter": "Benjamin Shickel", "authors": "Benjamin Shickel, Scott Siegel, Martin Heesacker, Sherry Benton, and\n  Parisa Rashidi", "title": "Automatic Detection and Classification of Cognitive Distortions in\n  Mental Health Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cognitive psychology, automatic and self-reinforcing irrational thought\npatterns are known as cognitive distortions. Left unchecked, patients\nexhibiting these types of thoughts can become stuck in negative feedback loops\nof unhealthy thinking, leading to inaccurate perceptions of reality commonly\nassociated with anxiety and depression. In this paper, we present a machine\nlearning framework for the automatic detection and classification of 15 common\ncognitive distortions in two novel mental health free text datasets collected\nfrom both crowdsourcing and a real-world online therapy program. When\ndifferentiating between distorted and non-distorted passages, our model\nachieved a weighted F1 score of 0.88. For classifying distorted passages into\none of 15 distortion categories, our model yielded weighted F1 scores of 0.68\nin the larger crowdsourced dataset and 0.45 in the smaller online counseling\ndataset, both of which outperformed random baseline metrics by a large margin.\nFor both tasks, we also identified the most discriminative words and phrases\nbetween classes to highlight common thematic elements for improving targeted\nand therapist-guided mental health treatment. Furthermore, we performed an\nexploratory analysis using unsupervised content-based clustering and topic\nmodeling algorithms as first efforts towards a data-driven perspective on the\nthematic relationship between similar cognitive distortions traditionally\ndeemed unique. Finally, we highlight the difficulties in applying mental\nhealth-based machine learning in a real-world setting and comment on the\nimplications and benefits of our framework for improving automated delivery of\ntherapeutic treatment in conjunction with traditional cognitive-behavioral\ntherapy.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 22:21:27 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 00:50:07 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Shickel", "Benjamin", ""], ["Siegel", "Scott", ""], ["Heesacker", "Martin", ""], ["Benton", "Sherry", ""], ["Rashidi", "Parisa", ""]]}, {"id": "1909.07520", "submitter": "Adam Rupe", "authors": "Adam Rupe, Karthik Kashinath, Nalini Kumar, Victor Lee, Prabhat, James\n  P. Crutchfield", "title": "Towards Unsupervised Segmentation of Extreme Weather Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.ao-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme weather is one of the main mechanisms through which climate change\nwill directly impact human society. Coping with such change as a global\ncommunity requires markedly improved understanding of how global warming drives\nextreme weather events. While alternative climate scenarios can be simulated\nusing sophisticated models, identifying extreme weather events in these\nsimulations requires automation due to the vast amounts of complex\nhigh-dimensional data produced. Atmospheric dynamics, and hydrodynamic flows\nmore generally, are highly structured and largely organize around a lower\ndimensional skeleton of coherent structures. Indeed, extreme weather events are\na special case of more general hydrodynamic coherent structures. We present a\nscalable physics-based representation learning method that decomposes\nspatiotemporal systems into their structurally relevant components, which are\ncaptured by latent variables known as local causal states. For complex fluid\nflows we show our method is capable of capturing known coherent structures, and\nwith promising segmentation results on CAM5.1 water vapor data we outline the\npath to extreme weather identification from unlabeled climate model simulation\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 23:41:42 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Rupe", "Adam", ""], ["Kashinath", "Karthik", ""], ["Kumar", "Nalini", ""], ["Lee", "Victor", ""], ["Prabhat", "", ""], ["Crutchfield", "James P.", ""]]}, {"id": "1909.07523", "submitter": "Lianwei Wu", "authors": "Lianwei Wu, Yuan Rao, Ambreen Nazir, Haolin Jin", "title": "Discovering Differential Features: Adversarial Learning for Information\n  Credibility Evaluation", "comments": "Information Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A series of deep learning approaches extract a large number of credibility\nfeatures to detect fake news on the Internet. However, these extracted features\nstill suffer from many irrelevant and noisy features that restrict severely the\nperformance of the approaches. In this paper, we propose a novel model based on\nAdversarial Networks and inspirited by the Shared-Private model (ANSP), which\naims at reducing common, irrelevant features from the extracted features for\ninformation credibility evaluation. Specifically, ANSP involves two tasks: one\nis to prevent the binary classification of true and false information for\ncapturing common features relying on adversarial networks guided by\nreinforcement learning. Another extracts credibility features (henceforth,\nprivate features) from multiple types of credibility information and compares\nwith the common features through two strategies, i.e., orthogonality\nconstraints and KL-divergence for making the private features more\ndifferential. Experiments first on two six-label LIAR and Weibo datasets\ndemonstrate that ANSP achieves the state-of-the-art performance, boosting the\naccuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate\nthe robustness of the model with 1.8% performance improvements.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 23:53:59 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Wu", "Lianwei", ""], ["Rao", "Yuan", ""], ["Nazir", "Ambreen", ""], ["Jin", "Haolin", ""]]}, {"id": "1909.07528", "submitter": "Bowen Baker", "authors": "Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell,\n  Bob McGrew, Igor Mordatch", "title": "Emergent Tool Use From Multi-Agent Autocurricula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through multi-agent competition, the simple objective of hide-and-seek, and\nstandard reinforcement learning algorithms at scale, we find that agents create\na self-supervised autocurriculum inducing multiple distinct rounds of emergent\nstrategy, many of which require sophisticated tool use and coordination. We\nfind clear evidence of six emergent phases in agent strategy in our\nenvironment, each of which creates a new pressure for the opposing team to\nadapt; for instance, agents learn to build multi-object shelters using moveable\nboxes which in turn leads to agents discovering that they can overcome\nobstacles using ramps. We further provide evidence that multi-agent competition\nmay scale better with increasing environment complexity and leads to behavior\nthat centers around far more human-relevant skills than other self-supervised\nreinforcement learning methods such as intrinsic motivation. Finally, we\npropose transfer and fine-tuning as a way to quantitatively evaluate targeted\ncapabilities, and we compare hide-and-seek agents to both intrinsic motivation\nand random initialization baselines in a suite of domain-specific intelligence\ntests.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 00:17:02 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 00:56:50 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Baker", "Bowen", ""], ["Kanitscheider", "Ingmar", ""], ["Markov", "Todor", ""], ["Wu", "Yi", ""], ["Powell", "Glenn", ""], ["McGrew", "Bob", ""], ["Mordatch", "Igor", ""]]}, {"id": "1909.07543", "submitter": "Bogdan Mazoure", "authors": "Thang Doan, Bogdan Mazoure, Moloud Abdar, Audrey Durand, Joelle\n  Pineau, R Devon Hjelm", "title": "Attraction-Repulsion Actor-Critic for Continuous Control Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous control tasks in reinforcement learning are important because they\nprovide an important framework for learning in high-dimensional state spaces\nwith deceptive rewards, where the agent can easily become trapped into\nsuboptimal solutions. One way to avoid local optima is to use a population of\nagents to ensure coverage of the policy space, yet learning a population with\nthe \"best\" coverage is still an open problem. In this work, we present a novel\napproach to population-based RL in continuous control that leverages properties\nof normalizing flows to perform attractive and repulsive operations between\ncurrent members of the population and previously observed policies. Empirical\nresults on the MuJoCo suite demonstrate a high performance gain for our\nalgorithm compared to prior work, including Soft-Actor Critic (SAC).\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 01:28:20 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 16:29:36 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 13:51:16 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Doan", "Thang", ""], ["Mazoure", "Bogdan", ""], ["Abdar", "Moloud", ""], ["Durand", "Audrey", ""], ["Pineau", "Joelle", ""], ["Hjelm", "R Devon", ""]]}, {"id": "1909.07547", "submitter": "Abdelrhman Saleh", "authors": "Abdelrhman Saleh, Natasha Jaques, Asma Ghandeharioun, Judy Hanwen\n  Shen, Rosalind Picard", "title": "Hierarchical Reinforcement Learning for Open-Domain Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain dialog generation is a challenging problem; maximum likelihood\ntraining can lead to repetitive outputs, models have difficulty tracking\nlong-term conversational goals, and training on standard movie or online\ndatasets may lead to the generation of inappropriate, biased, or offensive\ntext. Reinforcement Learning (RL) is a powerful framework that could\npotentially address these issues, for example by allowing a dialog model to\noptimize for reducing toxicity and repetitiveness. However, previous approaches\nwhich apply RL to open-domain dialog generation do so at the word level, making\nit difficult for the model to learn proper credit assignment for long-term\nconversational rewards. In this paper, we propose a novel approach to\nhierarchical reinforcement learning, VHRL, which uses policy gradients to tune\nthe utterance-level embedding of a variational sequence model. This\nhierarchical approach provides greater flexibility for learning long-term,\nconversational rewards. We use self-play and RL to optimize for a set of\nhuman-centered conversation metrics, and show that our approach provides\nsignificant improvements -- in terms of both human evaluation and automatic\nmetrics -- over state-of-the-art dialog models, including Transformers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 01:57:18 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 14:25:28 GMT"}, {"version": "v3", "created": "Tue, 31 Dec 2019 21:23:04 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Saleh", "Abdelrhman", ""], ["Jaques", "Natasha", ""], ["Ghandeharioun", "Asma", ""], ["Shen", "Judy Hanwen", ""], ["Picard", "Rosalind", ""]]}, {"id": "1909.07554", "submitter": "Yining Wang", "authors": "Yining Wang, Mingzhe Chen, Zhaohui Yang, Xue Hao, Tao Luo, and Walid\n  Saad", "title": "Gated Recurrent Units Learning for Optimal Deployment of Visible Light\n  Communications Enabled UAVs", "comments": "This paper has been accepted by the 2019 IEEE Global Communications\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of optimizing the deployment of unmanned aerial\nvehicles (UAVs) equipped with visible light communication (VLC) capabilities is\nstudied. In the studied model, the UAVs can simultaneously provide\ncommunications and illumination to service ground users. Ambient illumination\nincreases the interference over VLC links while reducing the illumination\nthreshold of the UAVs. Therefore, it is necessary to consider the illumination\ndistribution of the target area for UAV deployment optimization. This problem\nis formulated as an optimization problem whose goal is to minimize the total\ntransmit power while meeting the illumination and communication requirements of\nusers. To solve this problem, an algorithm based on the machine learning\nframework of gated recurrent units (GRUs) is proposed. Using GRUs, the UAVs can\nmodel the long-term historical illumination distribution and predict the future\nillumination distribution. In order to reduce the complexity of the prediction\nalgorithm while accurately predicting the illumination distribution, a Gaussian\nmixture model (GMM) is used to fit the illumination distribution of the target\narea at each time slot. Based on the predicted illumination distribution, the\noptimization problem is proved to be a convex optimization problem that can be\nsolved by using duality. Simulations using real data from the Earth\nobservations group (EOG) at NOAA/NCEI show that the proposed approach can\nachieve up to 22.1% reduction in transmit power compared to a conventional\noptimal UAV deployment that does not consider the illumination distribution.\nThe results also show that UAVs must hover at areas having strong illumination,\nthus providing useful guidelines on the deployment of VLC-enabled UAVs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 02:22:09 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Wang", "Yining", ""], ["Chen", "Mingzhe", ""], ["Yang", "Zhaohui", ""], ["Hao", "Xue", ""], ["Luo", "Tao", ""], ["Saad", "Walid", ""]]}, {"id": "1909.07558", "submitter": "Kai Qiao", "authors": "Wanting Yu, Hongyi Yu, Lingyun Jiang, Mengli Zhang, Kai Qiao, Linyuan\n  Wang, Bin Yan", "title": "HAD-GAN: A Human-perception Auxiliary Defense GAN to Defend Adversarial\n  Examples", "comments": "There is some error in our work. For example,\"Notably, we linked a\n  fully connected discriminant network in parallel at the penultimate level of\n  the target classifier.\" (section 3.2) Incorrect description of the network\n  structure can mislead readers. For example, \"associate GAN with human\n  imagination\" is not true.(section 1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples reveal the vulnerability and unexplained nature of\nneural networks. Studying the defense of adversarial examples is of\nconsiderable practical importance. Most adversarial examples that misclassify\nnetworks are often undetectable by humans. In this paper, we propose a defense\nmodel to train the classifier into a human-perception classification model with\nshape preference. The proposed model comprising a texture transfer network\n(TTN) and an auxiliary defense generative adversarial networks (GAN) is called\nHuman-perception Auxiliary Defense GAN (HAD-GAN). The TTN is used to extend the\ntexture samples of a clean image and helps classifiers focus on its shape. GAN\nis utilized to form a training framework for the model and generate the\nnecessary images. A series of experiments conducted on MNIST, Fashion-MNIST and\nCIFAR10 show that the proposed model outperforms the state-of-the-art defense\nmethods for network robustness. The model also demonstrates a significant\nimprovement on defense capability of adversarial examples.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 02:46:34 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 01:07:05 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 01:58:48 GMT"}, {"version": "v4", "created": "Sun, 9 May 2021 07:12:44 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yu", "Wanting", ""], ["Yu", "Hongyi", ""], ["Jiang", "Lingyun", ""], ["Zhang", "Mengli", ""], ["Qiao", "Kai", ""], ["Wang", "Linyuan", ""], ["Yan", "Bin", ""]]}, {"id": "1909.07561", "submitter": "Jun Li", "authors": "Zixuan Song, Jun Li", "title": "Variable selection with false discovery rate control in deep neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are famous for their high prediction accuracy,\nbut they are also known for their black-box nature and poor interpretability.\nWe consider the problem of variable selection, that is, selecting the input\nvariables that have significant predictive power on the output, in DNNs. We\npropose a backward elimination procedure called SurvNet, which is based on a\nnew measure of variable importance that applies to a wide variety of networks.\nMore importantly, SurvNet is able to estimate and control the false discovery\nrate of selected variables, while no existing methods provide such a quality\ncontrol. Further, SurvNet adaptively determines how many variables to eliminate\nat each step in order to maximize the selection efficiency. To study its\nvalidity, SurvNet is applied to image data and gene expression data, as well as\nvarious simulation datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 03:00:16 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Song", "Zixuan", ""], ["Li", "Jun", ""]]}, {"id": "1909.07576", "submitter": "Scott Leask", "authors": "Scott B. Leask and Vincent G. McDonell", "title": "On the Physical Interpretation of Proper Orthogonal Decomposition and\n  Dynamic Mode Decomposition for Liquid Injection", "comments": "26 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modal decomposition techniques of proper orthogonal decomposition (POD)\nand dynamic mode decomposition (DMD) have become a common method for analysing\nthe spatio-temporal coherence of dynamical systems. In particular, these\ntechniques are of interest for liquid injection systems due to the inherent\ncomplexity of multiphase interactions and extracting the underlying flow\nprocesses is desired. Although numerous works investigating flow processes have\nimplemented POD and DMD, the results are often highly interpretive with limited\nlink between the decomposition theory and the interpreted physical meaning of\nthe extracted modes. Here, we provide insight into the interpretation of POD\nand DMD modes in a hierarchical structure. The interpretation of modes for\nsimple canonical systems is validated through knowledge of the underlying\nprocesses which dominate the systems. We show that modes which capture true\nunderlying phenomena produce subsequent modes at higher harmonics, up until the\nNyquist limit, whose modal structure scales decrease proportionally with\nincreasing modal frequency. These higher harmonics primarily encode motion\ninformation and may or may not capture additional structural information, which\nis dependent on the system. We demonstrate these findings first on canonical\nliquid injection systems to enhance the interpretation and understanding of\nresults extracted from practical jet in crossflow systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 03:52:08 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Leask", "Scott B.", ""], ["McDonell", "Vincent G.", ""]]}, {"id": "1909.07578", "submitter": "Amir Ghasemian", "authors": "Amir Ghasemian, Homa Hosseinmardi, Aram Galstyan, Edoardo M. Airoldi,\n  Aaron Clauset", "title": "Stacking Models for Nearly Optimal Link Prediction in Complex Networks", "comments": "30 pages, 9 figures, 22 tables", "journal-ref": "Proc. Natl. Acad. Sci. USA 117(38), 23393-23400 (2020)", "doi": "10.1073/pnas.1914950117", "report-no": null, "categories": "stat.ML cs.LG cs.SI physics.data-an q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real-world networks are incompletely observed. Algorithms that can\naccurately predict which links are missing can dramatically speedup the\ncollection of network data and improve the validity of network models. Many\nalgorithms now exist for predicting missing links, given a partially observed\nnetwork, but it has remained unknown whether a single best predictor exists,\nhow link predictability varies across methods and networks from different\ndomains, and how close to optimality current methods are. We answer these\nquestions by systematically evaluating 203 individual link predictor\nalgorithms, representing three popular families of methods, applied to a large\ncorpus of 548 structurally diverse networks from six scientific domains. We\nfirst show that individual algorithms exhibit a broad diversity of prediction\nerrors, such that no one predictor or family is best, or worst, across all\nrealistic inputs. We then exploit this diversity via meta-learning to construct\na series of \"stacked\" models that combine predictors into a single algorithm.\nApplied to a broad range of synthetic networks, for which we may analytically\ncalculate optimal performance, these stacked models achieve optimal or nearly\noptimal levels of accuracy. Applied to real-world networks, stacked models are\nalso superior, but their accuracy varies strongly by domain, suggesting that\nlink prediction may be fundamentally easier in social networks than in\nbiological or technological networks. These results indicate that the\nstate-of-the-art for link prediction comes from combining individual\nalgorithms, which achieves nearly optimal predictions. We close with a brief\ndiscussion of limitations and opportunities for further improvement of these\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:11:19 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Ghasemian", "Amir", ""], ["Hosseinmardi", "Homa", ""], ["Galstyan", "Aram", ""], ["Airoldi", "Edoardo M.", ""], ["Clauset", "Aaron", ""]]}, {"id": "1909.07583", "submitter": "Yuhong Guo", "authors": "Yaser Alwattar and Yuhong Guo", "title": "Inverse Visual Question Answering with Multi-Level Attentions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel deep multi-level attention model to address\ninverse visual question answering. The proposed model generates regional visual\nand semantic features at the object level and then enhances them with the\nanswer cue by using attention mechanisms. Two levels of multiple attentions are\nemployed in the model, including the dual attention at the partial question\nencoding step and the dynamic attention at the next question word generation\nstep. We evaluate the proposed model on the VQA V1 dataset. It demonstrates\nstate-of-the-art performance in terms of multiple commonly used metrics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:41:12 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 00:13:21 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Alwattar", "Yaser", ""], ["Guo", "Yuhong", ""]]}, {"id": "1909.07587", "submitter": "Sayan Putatunda PhD", "authors": "Sayan Putatunda", "title": "A Hybrid Deep Learning Approach for Diagnosis of the Erythemato-Squamous\n  Disease", "comments": "Pre-review version of the paper accepted at the 2020 IEEE\n  International Conference on Electronics, Computing and Communication\n  Technologies (CONECCT)", "journal-ref": "2020 IEEE International Conference on Electronics, Computing and\n  Communication Technologies (CONECCT)", "doi": "10.1109/CONECCT50063.2020.9198447", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diagnosis of the Erythemato-squamous disease (ESD) is accepted as a\ndifficult problem in dermatology. ESD is a form of skin disease. It generally\ncauses redness of the skin and also may cause loss of skin. They are generally\ndue to genetic or environmental factors. ESD comprises six classes of skin\nconditions namely, pityriasis rubra pilaris, lichen planus, chronic dermatitis,\npsoriasis, seboreic dermatitis and pityriasis rosea. The automated diagnosis of\nESD can help doctors and dermatologists in reducing the efforts from their end\nand in taking faster decisions for treatment. The literature is replete with\nworks that used conventional machine learning methods for the diagnosis of ESD.\nHowever, there isn't much instances of application of Deep learning for the\ndiagnosis of ESD. In this paper, we propose a novel hybrid deep learning\napproach i.e. Derm2Vec for the diagnosis of the ESD. Derm2Vec is a hybrid deep\nlearning model that consists of both Autoencoders and Deep Neural Networks. We\nalso apply a conventional Deep Neural Network (DNN) for the classification of\nESD. We apply both Derm2Vec and DNN along with other traditional machine\nlearning methods on a real world dermatology dataset. The Derm2Vec method is\nfound to be the best performer (when taking the prediction accuracy into\naccount) followed by DNN and Extreme Gradient Boosting.The mean CV score of\nDerm2Vec, DNN and Extreme Gradient Boosting are 96.92 percent, 96.65 percent\nand 95.80 percent respectively.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:50:28 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 04:52:54 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Putatunda", "Sayan", ""]]}, {"id": "1909.07588", "submitter": "Tianyi Chen", "authors": "Jun Sun, Tianyi Chen, Georgios B. Giannakis, and Zaiyue Yang", "title": "Communication-Efficient Distributed Learning via Lazily Aggregated\n  Quantized Gradients", "comments": "Accepted in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper develops a novel aggregated gradient approach for\ndistributed machine learning that adaptively compresses the gradient\ncommunication. The key idea is to first quantize the computed gradients, and\nthen skip less informative quantized gradient communications by reusing\noutdated gradients. Quantizing and skipping result in `lazy' worker-server\ncommunications, which justifies the term Lazily Aggregated Quantized gradient\nthat is henceforth abbreviated as LAQ. Our LAQ can provably attain the same\nlinear convergence rate as the gradient descent in the strongly convex case,\nwhile effecting major savings in the communication overhead both in transmitted\nbits as well as in communication rounds. Empirically, experiments with real\ndata corroborate a significant communication reduction compared to existing\ngradient- and stochastic gradient-based algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:53:24 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Sun", "Jun", ""], ["Chen", "Tianyi", ""], ["Giannakis", "Georgios B.", ""], ["Yang", "Zaiyue", ""]]}, {"id": "1909.07594", "submitter": "Lalith Srikanth Chintalapati", "authors": "Lalith Srikanth Chintalapati, Raghunatha Sarma Rachakonda", "title": "Conformal Prediction based Spectral Clustering", "comments": "Under review in a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral Clustering(SC) is a prominent data clustering technique of recent\ntimes which has attracted much attention from researchers. It is a highly\ndata-driven method and makes no strict assumptions on the structure of the data\nto be clustered. One of the central pieces of spectral clustering is the\nconstruction of an affinity matrix based on a similarity measure between data\npoints. The way the similarity measure is defined between data points has a\ndirect impact on the performance of the SC technique. Several attempts have\nbeen made in the direction of strengthening the pairwise similarity measure to\nenhance the spectral clustering. In this work, we have defined a novel affinity\nmeasure by employing the concept of non-conformity used in Conformal\nPrediction(CP) framework. The non-conformity based affinity captures the\nrelationship between neighborhoods of data points and has the power to\ngeneralize the notion of contextual similarity. We have shown that this\nformulation of affinity measure gives good results and compares well with the\nstate of the art methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:09:01 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Chintalapati", "Lalith Srikanth", ""], ["Rachakonda", "Raghunatha Sarma", ""]]}, {"id": "1909.07596", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem, Calton Pu", "title": "ASSED -- A Framework for Identifying Physical Events through Adaptive\n  Social Sensor Data Filtering", "comments": null, "journal-ref": "ACM DEBS 2019", "doi": "10.1145/3328905.3329510", "report-no": null, "categories": "cs.SI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical event detection has long been the domain of static event processors\noperating on numeric sensor data. This works well for large scale strong-signal\nevents such as hurricanes, and important classes of events such as earthquakes.\nHowever, for a variety of domains there is insufficient sensor coverage, e.g.,\nlandslides, wildfires, and flooding. Social networks have provided massive\nvolume of data from billions of users, but data from these generic social\nsensors contain much more noise than physical sensors. One of the most\ndifficult challenges presented by social sensors is \\textit{concept drift},\nwhere the terms associated with a phenomenon evolve and change over time,\nrendering static machine learning (ML) classifiers less effective. To address\nthis problem, we develop the ASSED (Adaptive Social Sensor Event Detection)\nframework with an ML-based event processing engine and show how it can perform\nsimple and complex physical event detection on strong- \\textit{and} weak-signal\nwith low-latency, high scalability, and accurate coverage. Specifically, ASSED\nis a framework to support continuous filter generation and updates with machine\nlearning using streaming data from high-confidence sources (physical and\nannotated sensors) and social networks. We build ASSED to support procedures\nfor integrating high-confidence sources into social sensor event detection to\ngenerate high-quality filters and to perform dynamic filter selection by\ntracking its own performance. We demonstrate ASSED capabilities through a\nlandslide detection application that detects almost 350\\% more landslides\ncompared to static approaches. More importantly, ASSED automates the handling\nof concept drift: four years after initial data collection and classifier\ntraining, ASSED achieves event detection accuracy of 0.988 (without expert\nmanual intervention), compared to 0.762 for static approaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:12:25 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Suprem", "Abhijit", ""], ["Pu", "Calton", ""]]}, {"id": "1909.07606", "submitter": "Weijie Liu", "authors": "Weijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju, Haotang Deng and\n  Ping Wang", "title": "K-BERT: Enabling Language Representation with Knowledge Graph", "comments": "8 pages, 20190917", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language representation models, such as BERT, capture a general\nlanguage representation from large-scale corpora, but lack domain-specific\nknowledge. When reading a domain text, experts make inferences with relevant\nknowledge. For machines to achieve this capability, we propose a\nknowledge-enabled language representation model (K-BERT) with knowledge graphs\n(KGs), in which triples are injected into the sentences as domain knowledge.\nHowever, too much knowledge incorporation may divert the sentence from its\ncorrect meaning, which is called knowledge noise (KN) issue. To overcome KN,\nK-BERT introduces soft-position and visible matrix to limit the impact of\nknowledge. K-BERT can easily inject domain knowledge into the models by\nequipped with a KG without pre-training by-self because it is capable of\nloading model parameters from the pre-trained BERT. Our investigation reveals\npromising results in twelve NLP tasks. Especially in domain-specific tasks\n(including finance, law, and medicine), K-BERT significantly outperforms BERT,\nwhich demonstrates that K-BERT is an excellent choice for solving the\nknowledge-driven problems that require experts.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 06:16:04 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Liu", "Weijie", ""], ["Zhou", "Peng", ""], ["Zhao", "Zhe", ""], ["Wang", "Zhiruo", ""], ["Ju", "Qi", ""], ["Deng", "Haotang", ""], ["Wang", "Ping", ""]]}, {"id": "1909.07622", "submitter": "Kaining Zhang", "authors": "Kaining Zhang, Min-Hsiu Hsieh, Liu Liu, Dacheng Tao", "title": "Quantum algorithm for finding the negative curvature direction in\n  non-convex optimization", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient quantum algorithm aiming to find the negative\ncurvature direction for escaping the saddle point, which is the critical\nsubroutine for many second-order non-convex optimization algorithms. We prove\nthat our algorithm could produce the target state corresponding to the negative\ncurvature direction with query complexity O(polylog(d) /{\\epsilon}), where d is\nthe dimension of the optimization function. The quantum negative curvature\nfinding algorithm is exponentially faster than any known classical method which\ntakes time at least O(d /\\sqrt{\\epsilon}). Moreover, we propose an efficient\nquantum algorithm to achieve the classical read-out of the target state. Our\nclassical read-out algorithm runs exponentially faster on the degree of d than\nexisting counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 07:23:58 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Zhang", "Kaining", ""], ["Hsieh", "Min-Hsiu", ""], ["Liu", "Liu", ""], ["Tao", "Dacheng", ""]]}, {"id": "1909.07627", "submitter": "Rahul Sharma", "authors": "Rahul Sharma, Abhishek Kumar, Piyush Rai", "title": "Refined $\\alpha$-Divergence Variational Inference via Rejection Sampling", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approximate inference method, based on a synergistic\ncombination of R\\'enyi $\\alpha$-divergence variational inference (RDVI) and\nrejection sampling (RS). RDVI is based on minimization of R\\'enyi\n$\\alpha$-divergence $D_\\alpha(p||q)$ between the true distribution $p(x)$ and a\nvariational approximation $q(x)$; RS draws samples from a distribution $p(x) =\n\\tilde{p}(x)/Z_{p}$ using a proposal $q(x)$, s.t. $Mq(x) \\geq \\tilde{p}(x),\n\\forall x$. Our inference method is based on a crucial observation that\n$D_\\infty(p||q)$ equals $\\log M(\\theta)$ where $M(\\theta)$ is the optimal value\nof the RS constant for a given proposal $q_\\theta(x)$. This enables us to\ndevelop a \\emph{two-stage} hybrid inference algorithm. Stage-1 performs RDVI to\nlearn $q_\\theta$ by minimizing an estimator of $D_\\alpha(p||q)$, and uses the\nlearned $q_\\theta$ to find an (approximately) optimal $\\tilde{M}(\\theta)$.\nStage-2 performs RS using the constant $\\tilde{M}(\\theta)$ to improve the\napproximate distribution $q_\\theta$ and obtain a sample-based approximation. We\nprove that this two-stage method allows us to learn considerably more accurate\napproximations of the target distribution as compared to RDVI. We demonstrate\nour method's efficacy via several experiments on synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 07:28:05 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 04:35:09 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 05:37:38 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Sharma", "Rahul", ""], ["Kumar", "Abhishek", ""], ["Rai", "Piyush", ""]]}, {"id": "1909.07632", "submitter": "Juncheng Shen", "authors": "Juncheng Shen, Juzheng Liu, Yiran Chen, Hai Li", "title": "Towards Efficient and Secure Delivery of Data for Deep Learning with\n  Privacy-Preserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy recently emerges as a severe concern in deep learning, that is,\nsensitive data must be prohibited from being shared with the third party during\ndeep neural network development. In this paper, we propose Morphed Learning\n(MoLe), an efficient and secure scheme to deliver deep learning data. MoLe has\ntwo main components: data morphing and Augmented Convolutional (Aug-Conv)\nlayer. Data morphing allows data providers to send morphed data without privacy\ninformation, while Aug-Conv layer helps deep learning developers to apply their\nnetworks on the morphed data without performance penalty. MoLe provides\nstronger security while introducing lower overhead compared to GAZELLE (USENIX\nSecurity 2018), which is another method with no performance penalty on the\nneural network. When using MoLe for VGG-16 network on CIFAR dataset, the\ncomputational overhead is only 9% and the data transmission overhead is 5.12%.\nAs a comparison, GAZELLE has computational overhead of 10,000 times and data\ntransmission overhead of 421,000 times. In this setting, the attack success\nrate of adversary is 7.9 x 10^{-90} for MoLe and 2.9 x 10^{-30} for GAZELLE,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 07:50:38 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Shen", "Juncheng", ""], ["Liu", "Juzheng", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1909.07633", "submitter": "Ziyue Huang", "authors": "Ziyue Huang, Ke Yi", "title": "Communication-Efficient Weighted Sampling and Quantile Summary for GBDT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosting decision tree (GBDT) is a powerful and widely-used machine\nlearning model, which has achieved state-of-the-art performance in many\nacademic areas and production environment. However, communication overhead is\nthe main bottleneck in distributed training which can handle the massive data\nnowadays. In this paper, we propose two novel communication-efficient methods\nover distributed dataset to mitigate this problem, a weighted sampling approach\nby which we can estimate the information gain over a small subset efficiently,\nand distributed protocols for weighted quantile problem used in approximate\ntree learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 07:55:04 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Huang", "Ziyue", ""], ["Yi", "Ke", ""]]}, {"id": "1909.07654", "submitter": "Tomaso Fontanini", "authors": "Tomaso Fontanini, Eleonora Iotti and Andrea Prati", "title": "MetalGAN: a Cluster-based Adaptive Training for Few-Shot Adversarial\n  Colorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the majority of works on deep-learning-based image\ncolorization have focused on how to make a good use of the enormous datasets\ncurrently available. What about when the data at disposal are scarce? The main\nobjective of this work is to prove that a network can be trained and can\nprovide excellent colorization results even without a large quantity of data.\nThe adopted approach is a mixed one, which uses an adversarial method for the\nactual colorization, and a meta-learning technique to enhance the generator\nmodel. Also, a clusterization a-priori of the training dataset ensures a\ntask-oriented division useful for meta-learning, and at the same time reduces\nthe per-step number of images. This paper describes in detail the method and\nits main motivations, and a discussion of results and future developments is\nprovided.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 08:54:12 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Fontanini", "Tomaso", ""], ["Iotti", "Eleonora", ""], ["Prati", "Andrea", ""]]}, {"id": "1909.07670", "submitter": "Tomoharu Iwata", "authors": "Tomoharu Iwata and Takuma Otsuka", "title": "Efficient Transfer Bayesian Optimization with Auxiliary Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient transfer Bayesian optimization method, which finds\nthe maximum of an expensive-to-evaluate black-box function by using data on\nrelated optimization tasks. Our method uses auxiliary information that\nrepresents the task characteristics to effectively transfer knowledge for\nestimating a distribution over target functions. In particular, we use a\nGaussian process, in which the mean and covariance functions are modeled with\nneural networks that simultaneously take both the auxiliary information and\nfeature vectors as input. With a neural network mean function, we can estimate\nthe target function even without evaluations. By using the neural network\ncovariance function, we can extract nonlinear correlation among feature vectors\nthat are shared across related tasks. Our Gaussian process-based formulation\nnot only enables an analytic calculation of the posterior distribution but also\nswiftly adapts the target function to observations. Our method is also\nadvantageous because the computational costs scale linearly with the number of\nsource tasks. Through experiments using a synthetic dataset and datasets for\nfinding the optimal pedestrian traffic regulations and optimal machine learning\nalgorithms, we demonstrate that our method identifies the optimal points with\nfewer target function evaluations than existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:28:42 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Iwata", "Tomoharu", ""], ["Otsuka", "Takuma", ""]]}, {"id": "1909.07683", "submitter": "Palakorn Achananuparp", "authors": "Yue Liu, Helena Lee, Palakorn Achananuparp, Ee-Peng Lim, Tzu-Ling\n  Cheng, Shou-De Lin", "title": "Characterizing and Predicting Repeat Food Consumption Behavior for\n  Just-in-Time Interventions", "comments": "To appear in the Proceedings of Digital Public Health 2019", "journal-ref": null, "doi": "10.1145/3357729.3357736", "report-no": null, "categories": "cs.IR cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human beings are creatures of habit. In their daily life, people tend to\nrepeatedly consume similar types of food items over several days and\noccasionally switch to consuming different types of items when the consumptions\nbecome overly monotonous. However, the novel and repeat consumption behaviors\nhave not been studied in food recommendation research. More importantly, the\nability to predict daily eating habits of individuals is crucial to improve the\neffectiveness of food recommender systems in facilitating healthy lifestyle\nchange. In this study, we analyze the patterns of repeat food consumptions\nusing large-scale consumption data from a popular online fitness community\ncalled MyFitnessPal (MFP), conduct an offline evaluation of various\nstate-of-the-art algorithms in predicting the next-day food consumption, and\nanalyze their performance across different demographic groups and contexts. The\nexperiment results show that algorithms incorporating the\nexploration-and-exploitation and temporal dynamics are more effective in the\nnext-day recommendation task than most state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:51:24 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Liu", "Yue", ""], ["Lee", "Helena", ""], ["Achananuparp", "Palakorn", ""], ["Lim", "Ee-Peng", ""], ["Cheng", "Tzu-Ling", ""], ["Lin", "Shou-De", ""]]}, {"id": "1909.07689", "submitter": "Sergio Garrido", "authors": "Sergio Garrido, Stanislav S. Borysov, Francisco C. Pereira, Jeppe Rich", "title": "Prediction of rare feature combinations in population synthesis:\n  Application of deep generative modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In population synthesis applications, when considering populations with many\nattributes, a fundamental problem is the estimation of rare combinations of\nfeature attributes. Unsurprisingly, it is notably more difficult to reliably\nrepresentthe sparser regions of such multivariate distributions and in\nparticular combinations of attributes which are absent from the original\nsample. In the literature this is commonly known as sampling zeros for which no\nsystematic solution has been proposed so far. In this paper, two machine\nlearning algorithms, from the family of deep generative models,are proposed for\nthe problem of population synthesis and with particular attention to the\nproblem of sampling zeros. Specifically, we introduce the Wasserstein\nGenerative Adversarial Network (WGAN) and the Variational Autoencoder(VAE), and\nadapt these algorithms for a large-scale population synthesis application. The\nmodels are implemented on a Danish travel survey with a feature-space of more\nthan 60 variables. The models are validated in a cross-validation scheme and a\nset of new metrics for the evaluation of the sampling-zero problem is proposed.\nResults show how these models are able to recover sampling zeros while keeping\nthe estimation of truly impossible combinations, the structural zeros, at a\ncomparatively low level. Particularly, for a low dimensional experiment, the\nVAE, the marginal sampler and the fully random sampler generate 5%, 21% and\n26%, respectively, more structural zeros per sampling zero generated by the\nWGAN, while for a high dimensional case, these figures escalate to 44%, 2217%\nand 170440%, respectively. This research directly supports the development of\nagent-based systems and in particular cases where detailed socio-economic or\ngeographical representations are required.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:58:45 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Garrido", "Sergio", ""], ["Borysov", "Stanislav S.", ""], ["Pereira", "Francisco C.", ""], ["Rich", "Jeppe", ""]]}, {"id": "1909.07694", "submitter": "V\\'aclav Barto\\v{s}", "authors": "Vaclav Bartos, Martin Zadnik, Sheikh Mahbub Habib, Emmanouil\n  Vasilomanolakis", "title": "Network entity characterization and attack prediction", "comments": "30 pages, 8 figures", "journal-ref": "Future Generation Computer Systems 97 (2019) 674-686", "doi": "10.1016/j.future.2019.03.016", "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The devastating effects of cyber-attacks, highlight the need for novel attack\ndetection and prevention techniques. Over the last years, considerable work has\nbeen done in the areas of attack detection as well as in collaborative defense.\nHowever, an analysis of the state of the art suggests that many challenges\nexist in prioritizing alert data and in studying the relation between a\nrecently discovered attack and the probability of it occurring again. In this\narticle, we propose a system that is intended for characterizing network\nentities and the likelihood that they will behave maliciously in the future.\nOur system, namely Network Entity Reputation Database System (NERDS), takes\ninto account all the available information regarding a network entity (e. g. IP\naddress) to calculate the probability that it will act maliciously. The latter\npart is achieved via the utilization of machine learning. Our experimental\nresults show that it is indeed possible to precisely estimate the probability\nof future attacks from each entity using information about its previous\nmalicious behavior and other characteristics. Ranking the entities by this\nprobability has practical applications in alert prioritization, assembly of\nhighly effective blacklists of a limited length and other use cases.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:12:55 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Bartos", "Vaclav", ""], ["Zadnik", "Martin", ""], ["Habib", "Sheikh Mahbub", ""], ["Vasilomanolakis", "Emmanouil", ""]]}, {"id": "1909.07697", "submitter": "Naif Alshammari PhD", "authors": "Naif Alshammari, Samet Ak\\c{c}ay, Toby P. Breckon", "title": "Multi-Task Learning for Automotive Foggy Scene Understanding via Domain\n  Adaptation to an Illumination-Invariant Representation", "comments": "Conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint scene understanding and segmentation for automotive applications is a\nchallenging problem in two key aspects:- (1) classifying every pixel in the\nentire scene and (2) performing this task under unstable weather and\nillumination changes (e.g. foggy weather), which results in poor outdoor scene\nvisibility. This poor outdoor scene visibility leads to a non-optimal\nperformance of deep convolutional neural network-based scene understanding and\nsegmentation. In this paper, we propose an efficient end-to-end contemporary\nautomotive semantic scene understanding approach under foggy weather\nconditions, employing domain adaptation and illumination-invariant image\nper-transformation. As a multi-task pipeline, our proposed model provides:- (1)\ntransferring images from extreme to clear-weather condition using domain\ntransfer approach and (2) semantically segmenting a scene using a competitive\nencoder-decoder convolutional neural network (CNN) with dense connectivity,\nskip connections and fusion-based techniques. We evaluate our approach on\nchallenging foggy datasets, including synthetic dataset (Foggy Cityscapes) as\nwell as real-world datasets (Foggy Zurich and Foggy Driving). By incorporating\nRGB, depth, and illumination-invariant information, our approach outperforms\nthe state-of-the-art within automotive scene understanding, under foggy weather\ncondition.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:18:14 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Alshammari", "Naif", ""], ["Ak\u00e7ay", "Samet", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1909.07698", "submitter": "Ieva Kazlauskaite", "authors": "Ivan Ustyuzhaninov, Ieva Kazlauskaite, Markus Kaiser, Erik Bodin,\n  Neill D. F. Campbell, Carl Henrik Ek", "title": "Compositional uncertainty in deep Gaussian processes", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are nonparametric priors over functions. Fitting a\nGP implies computing a posterior distribution of functions consistent with the\nobserved data. Similarly, deep Gaussian processes (DGPs) should allow us to\ncompute a posterior distribution of compositions of multiple functions giving\nrise to the observations. However, exact Bayesian inference is intractable for\nDGPs, motivating the use of various approximations. We show that the\napplication of simplifying mean-field assumptions across the hierarchy leads to\nthe layers of a DGP collapsing to near-deterministic transformations. We argue\nthat such an inference scheme is suboptimal, not taking advantage of the\npotential of the model to discover the compositional structure in the data. To\naddress this issue, we examine alternative variational inference schemes\nallowing for dependencies across different layers and discuss their advantages\nand limitations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:19:02 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 09:58:36 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 21:19:12 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Ustyuzhaninov", "Ivan", ""], ["Kazlauskaite", "Ieva", ""], ["Kaiser", "Markus", ""], ["Bodin", "Erik", ""], ["Campbell", "Neill D. F.", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "1909.07705", "submitter": "Zaiqiao Meng", "authors": "Zaiqiao Meng, Richard McCreadie, Craig Macdonald and Iadh Ounis", "title": "Variational Bayesian Context-aware Representation for Grocery\n  Recommendation", "comments": "Accepted for CARS 2.0 - Context-Aware Recommender Systems Workshop @\n  RecSys'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grocery recommendation is an important recommendation use-case, which aims to\npredict which items a user might choose to buy in the future, based on their\nshopping history. However, existing methods only represent each user and item\nby single deterministic points in a low-dimensional continuous space. In\naddition, most of these methods are trained by maximizing the co-occurrence\nlikelihood with a simple Skip-gram-based formulation, which limits the\nexpressive ability of their embeddings and the resulting recommendation\nperformance. In this paper, we propose the Variational Bayesian Context-Aware\nRepresentation (VBCAR) model for grocery recommendation, which is a novel\nvariational Bayesian model that learns the user and item latent vectors by\nleveraging basket context information from past user-item interactions. We\ntrain our VBCAR model based on the Bayesian Skip-gram framework coupled with\nthe amortized variational inference so that it can learn more expressive latent\nrepresentations that integrate both the non-linearity and Bayesian behaviour.\nExperiments conducted on a large real-world grocery recommendation dataset show\nthat our proposed VBCAR model can significantly outperform existing\nstate-of-the-art grocery recommendation methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:38:19 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 13:07:07 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Meng", "Zaiqiao", ""], ["McCreadie", "Richard", ""], ["Macdonald", "Craig", ""], ["Ounis", "Iadh", ""]]}, {"id": "1909.07707", "submitter": "Florin Leon", "authors": "Florin Leon, Marius Gavrilescu", "title": "A Review of Tracking, Prediction and Decision Making Methods for\n  Autonomous Driving", "comments": "36 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This literature review focuses on three important aspects of an autonomous\ncar system: tracking (assessing the identity of the actors such as cars,\npedestrians or obstacles in a sequence of observations), prediction (predicting\nthe future motion of surrounding vehicles in order to navigate through various\ntraffic scenarios) and decision making (analyzing the available actions of the\nego car and their consequences to the entire driving context). For tracking and\nprediction, approaches based on (deep) neural networks and other, especially\nstochastic techniques, are reported. For decision making, deep reinforcement\nlearning algorithms are presented, together with methods used to explore\ndifferent alternative actions, such as Monte Carlo Tree Search.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:41:40 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Leon", "Florin", ""], ["Gavrilescu", "Marius", ""]]}, {"id": "1909.07729", "submitter": "Abhisek Kundu", "authors": "Abhisek Kundu, Alex Heinecke, Dhiraj Kalamkar, Sudarshan Srinivasan,\n  Eric C. Qin, Naveen K. Mellempudi, Dipankar Das, Kunal Banerjee, Bharat Kaul,\n  Pradeep Dubey", "title": "K-TanH: Efficient TanH For Deep Learning", "comments": "6 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose K-TanH, a novel, highly accurate, hardware efficient approximation\nof popular activation function TanH for Deep Learning. K-TanH consists of\nparameterized low-precision integer operations, such as, shift and add/subtract\n(no floating point operation needed) where parameters are stored in very small\nlook-up tables that can fit in CPU registers. K-TanH can work on various\nnumerical formats, such as, Float32 and BFloat16. High quality approximations\nto other activation functions, e.g., Sigmoid, Swish and GELU, can be derived\nfrom K-TanH. Our AVX512 implementation of K-TanH demonstrates $>5\\times$ speed\nup over Intel SVML, and it is consistently superior in efficiency over other\napproximations that use floating point arithmetic. Finally, we achieve\nstate-of-the-art Bleu score and convergence results for training language\ntranslation model GNMT on WMT16 data sets with approximate TanH obtained via\nK-TanH on BFloat16 inputs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 11:43:23 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 05:05:39 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 10:02:50 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kundu", "Abhisek", ""], ["Heinecke", "Alex", ""], ["Kalamkar", "Dhiraj", ""], ["Srinivasan", "Sudarshan", ""], ["Qin", "Eric C.", ""], ["Mellempudi", "Naveen K.", ""], ["Das", "Dipankar", ""], ["Banerjee", "Kunal", ""], ["Kaul", "Bharat", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1909.07741", "submitter": "Yipeng Sun", "authors": "Yipeng Sun, Zihan Ni, Chee-Kheng Chng, Yuliang Liu, Canjie Luo, Chun\n  Chet Ng, Junyu Han, Errui Ding, Jingtuo Liu, Dimosthenis Karatzas, Chee Seng\n  Chan, Lianwen Jin", "title": "ICDAR 2019 Competition on Large-scale Street View Text with Partial\n  Labeling -- RRC-LSVT", "comments": "ICDAR 2019 Robust Reading Challenge in IAPR International Conference\n  on Document Analysis and Recognition (ICDAR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust text reading from street view images provides valuable information for\nvarious applications. Performance improvement of existing methods in such a\nchallenging scenario heavily relies on the amount of fully annotated training\ndata, which is costly and in-efficient to obtain. To scale up the amount of\ntraining data while keeping the labeling procedure cost-effective, this\ncompetition introduces a new challenge on Large-scale Street View Text with\nPartial Labeling (LSVT), providing 50, 000 and 400, 000 images in full and weak\nannotations, respectively. This competition aims to explore the abilities of\nstate-of-the-art methods to detect and recognize text instances from\nlarge-scale street view images, closing the gap between research benchmarks and\nreal applications. During the competition period, a total of 41 teams\nparticipated in the two proposed tasks with 132 valid submissions, i.e., text\ndetection and end-to-end text spotting. This paper includes dataset\ndescriptions, task definitions, evaluation protocols and results summaries of\nthe ICDAR 2019-LSVT challenge.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:09:33 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Sun", "Yipeng", ""], ["Ni", "Zihan", ""], ["Chng", "Chee-Kheng", ""], ["Liu", "Yuliang", ""], ["Luo", "Canjie", ""], ["Ng", "Chun Chet", ""], ["Han", "Junyu", ""], ["Ding", "Errui", ""], ["Liu", "Jingtuo", ""], ["Karatzas", "Dimosthenis", ""], ["Chan", "Chee Seng", ""], ["Jin", "Lianwen", ""]]}, {"id": "1909.07745", "submitter": "Ali Ghadirzadeh", "authors": "Xi Chen, Ali Ghadirzadeh, M{\\aa}rten Bj\\\"orkman and Patric Jensfelt", "title": "Adversarial Feature Training for Generalizable Robotic Visuomotor\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has enabled training action-selection\npolicies, end-to-end, by learning a function which maps image pixels to action\noutputs. However, it's application to visuomotor robotic policy training has\nbeen limited because of the challenge of large-scale data collection when\nworking with physical hardware. A suitable visuomotor policy should perform\nwell not just for the task-setup it has been trained for, but also for all\nvarieties of the task, including novel objects at different viewpoints\nsurrounded by task-irrelevant objects. However, it is impractical for a robotic\nsetup to sufficiently collect interactive samples in a RL framework to\ngeneralize well to novel aspects of a task. In this work, we demonstrate that\nby using adversarial training for domain transfer, it is possible to train\nvisuomotor policies based on RL frameworks, and then transfer the acquired\npolicy to other novel task domains. We propose to leverage the deep RL\ncapabilities to learn complex visuomotor skills for uncomplicated task setups,\nand then exploit transfer learning to generalize to new task domains provided\nonly still images of the task in the target domain. We evaluate our method on\ntwo real robotic tasks, picking and pouring, and compare it to a number of\nprior works, demonstrating its superiority.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:18:34 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Chen", "Xi", ""], ["Ghadirzadeh", "Ali", ""], ["Bj\u00f6rkman", "M\u00e5rten", ""], ["Jensfelt", "Patric", ""]]}, {"id": "1909.07746", "submitter": "Shobhit Jain", "authors": "Shobhit Jain, Sravan Babu Bodapati, Ramesh Nallapati, Anima Anandkumar", "title": "Multi Sense Embeddings from Topic Models", "comments": "Accepted at ACL supported conference for Natural Language & Speech\n  Processing. https://www.aclweb.org/anthology/W19-74, Year: 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed word embeddings have yielded state-of-the-art performance in many\nNLP tasks, mainly due to their success in capturing useful semantic\ninformation. These representations assign only a single vector to each word\nwhereas a large number of words are polysemous (i.e., have multiple meanings).\nIn this work, we approach this critical problem in lexical semantics, namely\nthat of representing various senses of polysemous words in vector spaces. We\npropose a topic modeling based skip-gram approach for learning multi-prototype\nword embeddings. We also introduce a method to prune the embeddings determined\nby the probabilistic representation of the word in each topic. We use our\nembeddings to show that they can capture the context and word similarity\nstrongly and outperform various state-of-the-art implementations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:23:33 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 17:14:17 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Jain", "Shobhit", ""], ["Bodapati", "Sravan Babu", ""], ["Nallapati", "Ramesh", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1909.07750", "submitter": "Raghu Rajan", "authors": "Raghu Rajan, Jessica Lizeth Borja Diaz, Suresh Guttikonda, Fabio\n  Ferreira, Andr\\'e Biedenkapp, Jan Ole von Hartz and Frank Hutter", "title": "MDP Playground: A Design and Debug Testbed for Reinforcement Learning", "comments": "NeurIPS 2021 Data and Benchmark Track submission (with slight\n  formatting differences, most notably citation style)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present \\emph{MDP Playground}, an efficient testbed for Reinforcement\nLearning (RL) agents with \\textit{orthogonal} dimensions that can be controlled\nindependently to challenge agents in different ways and obtain varying degrees\nof hardness in generated environments. We consider and allow control over a\nwide variety of dimensions, including \\textit{delayed rewards},\n\\textit{rewardable sequences}, \\textit{density of rewards},\n\\textit{stochasticity}, \\textit{image representations}, \\textit{irrelevant\nfeatures}, \\textit{time unit}, \\textit{action range} and more. We define a\nparameterised collection of fast-to-run toy environments in \\textit{OpenAI Gym}\nby varying these dimensions and propose to use these for the initial design and\ndevelopment of agents. We also provide wrappers that inject these dimensions\ninto complex environments from \\textit{Atari} and \\textit{Mujoco} to allow for\nevaluating agent robustness. We further provide various example use-cases and\ninstructions on how to use \\textit{MDP Playground} to design and debug agents.\nWe believe that \\textit{MDP Playground} is a valuable testbed for researchers\ndesigning new, adaptive and intelligent RL agents and those wanting to unit\ntest their agents.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:41:20 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 12:46:17 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 13:06:35 GMT"}, {"version": "v4", "created": "Fri, 25 Jun 2021 12:38:37 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Rajan", "Raghu", ""], ["Diaz", "Jessica Lizeth Borja", ""], ["Guttikonda", "Suresh", ""], ["Ferreira", "Fabio", ""], ["Biedenkapp", "Andr\u00e9", ""], ["von Hartz", "Jan Ole", ""], ["Hutter", "Frank", ""]]}, {"id": "1909.07755", "submitter": "Markus Eberts", "authors": "Markus Eberts, Adrian Ulges", "title": "Span-based Joint Entity and Relation Extraction with Transformer\n  Pre-training", "comments": "Published at ECAI 2020; marginally revised version; because of new\n  insights into evaluation metrics used in related work, we updated Table 1 and\n  report both micro/macro averaged entity values for the ADE dataset", "journal-ref": null, "doi": "10.3233/FAIA200321", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SpERT, an attention model for span-based joint entity and\nrelation extraction. Our key contribution is a light-weight reasoning on BERT\nembeddings, which features entity recognition and filtering, as well as\nrelation classification with a localized, marker-free context representation.\nThe model is trained using strong within-sentence negative samples, which are\nefficiently extracted in a single BERT pass. These aspects facilitate a search\nover all spans in the sentence.\n  In ablation studies, we demonstrate the benefits of pre-training, strong\nnegative sampling and localized context. Our model outperforms prior work by up\nto 2.6% F1 score on several datasets for joint entity and relation extraction.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 13:01:12 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 09:58:10 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 16:21:59 GMT"}, {"version": "v4", "created": "Mon, 28 Jun 2021 19:39:43 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Eberts", "Markus", ""], ["Ulges", "Adrian", ""]]}, {"id": "1909.07763", "submitter": "Guillaume Labb\\'e-Morissette", "authors": "Guillaume Labbe-Morissette, Sylvain Gauthier", "title": "A machine vision meta-algorithm for automated recognition of underwater\n  objects using sidescan sonar imagery", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper details a new method to recognize and detect underwater objects in\nreal-time sidescan sonar data imagery streams, with case-studies of\napplications for underwater archeology, and ghost fishing gear retrieval. We\nfirst synthesize images from sidescan data, apply geometric and radiometric\ncorrections, then use 2D feature detection algorithms to identify point clouds\nof descriptive visual microfeatures such as corners and edges in the sonar\nimages. We then apply a clustering algorithm on the feature point clouds to\ngroup feature sets into regions of interest, reject false positives, yielding a\ngeoreferenced inventory of objects.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 13:15:11 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Labbe-Morissette", "Guillaume", ""], ["Gauthier", "Sylvain", ""]]}, {"id": "1909.07766", "submitter": "Hieu Nguyen", "authors": "Hieu Nguyen, Hui Li, Qiang Qiu, Yuzeng Wang, and Zhaoyang Wang", "title": "Single-shot 3D shape reconstruction using deep convolutional neural\n  networks", "comments": "6 pages, 4 figures, 1 dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust single-shot 3D shape reconstruction technique integrating the fringe\nprojection profilometry (FPP) technique with the deep convolutional neural\nnetworks (CNNs) is proposed in this letter. The input of the proposed technique\nis a single FPP image, and the training and validation data sets are prepared\nby using the conventional multi-frequency FPP technique. Unlike the\nconventional 3D shape reconstruction methods which involve complex algorithms\nand intensive computation, the proposed approach uses an end-to-end network\narchitecture to directly carry out the transformation of a 2D images to its\ncorresponding 3D shape. Experiments have been conducted to demonstrate the\nvalidity and robustness of the proposed technique. It is capable of satisfying\nvarious 3D shape reconstruction demands in scientific research and engineering\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 13:19:31 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Nguyen", "Hieu", ""], ["Li", "Hui", ""], ["Qiu", "Qiang", ""], ["Wang", "Yuzeng", ""], ["Wang", "Zhaoyang", ""]]}, {"id": "1909.07774", "submitter": "Qidong Liu", "authors": "Qidong Liu and Ruisheng Zhang", "title": "Global Optimal Path-Based Clustering Algorithm", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial optimization problems for clustering are known to be NP-hard.\nMost optimization methods are not able to find the global optimum solution for\nall datasets. To solve this problem, we propose a global optimal path-based\nclustering (GOPC) algorithm in this paper. The GOPC algorithm is based on two\nfacts: (1) medoids have the minimum degree in their clusters; (2) the minimax\ndistance between two objects in one cluster is smaller than the minimax\ndistance between objects in different clusters. Extensive experiments are\nconducted on synthetic and real-world datasets to evaluate the performance of\nthe GOPC algorithm. The results on synthetic datasets show that the GOPC\nalgorithm can recognize all kinds of clusters regardless of their shapes,\nsizes, or densities. Experimental results on real-world datasets demonstrate\nthe effectiveness and efficiency of the GOPC algorithm. In addition, the GOPC\nalgorithm needs only one parameter, i.e., the number of clusters, which can be\nestimated by the decision graph. The advantages mentioned above make GOPC a\ngood candidate as a general clustering algorithm. Codes are available at\nhttps://github.com/Qidong-Liu/Clustering.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 13:24:48 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Liu", "Qidong", ""], ["Zhang", "Ruisheng", ""]]}, {"id": "1909.07782", "submitter": "Satya Narayan Shukla", "authors": "Satya Narayan Shukla and Benjamin M. Marlin", "title": "Interpolation-Prediction Networks for Irregularly Sampled Time Series", "comments": "International Conference on Learning Representations. arXiv admin\n  note: substantial text overlap with arXiv:1812.00531", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new deep learning architecture for addressing the\nproblem of supervised learning with sparse and irregularly sampled multivariate\ntime series. The architecture is based on the use of a semi-parametric\ninterpolation network followed by the application of a prediction network. The\ninterpolation network allows for information to be shared across multiple\ndimensions of a multivariate time series during the interpolation stage, while\nany standard deep learning model can be used for the prediction network. This\nwork is motivated by the analysis of physiological time series data in\nelectronic health records, which are sparse, irregularly sampled, and\nmultivariate. We investigate the performance of this architecture on both\nclassification and regression tasks, showing that our approach outperforms a\nrange of baseline and recently proposed models.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 21:18:06 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Shukla", "Satya Narayan", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "1909.07786", "submitter": "Giuseppe Jurman", "authors": "Andrea Gobbi, Marco Cristoforetti, Giuseppe Jurman, Cesare Furlanello", "title": "High Resolution Forecasting of Heat Waves impacts on Leaf Area Index by\n  Multiscale Multitemporal Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate change impacts could cause progressive decrease of crop quality and\nyield, up to harvest failures. In particular, heat waves and other climate\nextremes can lead to localized food shortages and even threaten food security\nof communities worldwide. In this study, we apply a deep learning architecture\nfor high resolution forecasting (300 m, 10 days) of the Leaf Area Index (LAI),\nwhose dynamics has been widely used to model the growth phase of crops and\nimpact of heat waves. LAI models can be computed at 0.1 degree spatial\nresolution with an auto regressive component adjusted with weather conditions,\nvalidated with remote sensing measurements. However model actionability is poor\nin regions of varying terrain morphology at this scale (about 8 km at the Alps\nlatitude). Our deep learning model aims instead at forecasting LAI by training\nmultiscale multitemporal (MSMT) data from the Copernicus Global Land Service\n(CGLS) project for all Europe at 300m resolution and medium-resolution\nhistorical weather data. Further, the deep learning model inputs integrate\nhigh-resolution land surface features, known to improve forecasts of\nagricultural productivity. The historical weather data are then replaced with\nforecast values to predict LAI values at 10 day horizon on Europe. We propose\nthe MSMT model to develop a high resolution crop-specific warning system for\nmitigating damage due to heat waves and other extreme events.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 15:06:33 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Gobbi", "Andrea", ""], ["Cristoforetti", "Marco", ""], ["Jurman", "Giuseppe", ""], ["Furlanello", "Cesare", ""]]}, {"id": "1909.07808", "submitter": "Yipeng Sun", "authors": "Yipeng Sun, Jiaming Liu, Wei Liu, Junyu Han, Errui Ding, Jingtuo Liu", "title": "Chinese Street View Text: Large-scale Chinese Text Reading with\n  Partially Supervised Learning", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing text reading benchmarks make it difficult to evaluate the\nperformance of more advanced deep learning models in large vocabularies due to\nthe limited amount of training data. To address this issue, we introduce a new\nlarge-scale text reading benchmark dataset named Chinese Street View Text\n(C-SVT) with 430,000 street view images, which is at least 14 times as large as\nthe existing Chinese text reading benchmarks. To recognize Chinese text in the\nwild while keeping large-scale datasets labeling cost-effective, we propose to\nannotate one part of the CSVT dataset (30,000 images) in locations and text\nlabels as full annotations and add 400,000 more images, where only the\ncorresponding text-of-interest in the regions is given as weak annotations. To\nexploit the rich information from the weakly annotated data, we design a text\nreading network in a partially supervised learning framework, which enables to\nlocalize and recognize text, learn from fully and weakly annotated data\nsimultaneously. To localize the best matched text proposals from weakly labeled\nimages, we propose an online proposal matching module incorporated in the whole\nmodel, spotting the keyword regions by sharing parameters for end-to-end\ntraining. Compared with fully supervised training algorithms, this model can\nimprove the end-to-end recognition performance remarkably by 4.03% in F-score\nat the same labeling cost. The proposed model can also achieve state-of-the-art\nresults on the ICDAR 2017-RCTW dataset, which demonstrates the effectiveness of\nthe proposed partially supervised learning framework.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 13:54:24 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 04:50:38 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Sun", "Yipeng", ""], ["Liu", "Jiaming", ""], ["Liu", "Wei", ""], ["Han", "Junyu", ""], ["Ding", "Errui", ""], ["Liu", "Jingtuo", ""]]}, {"id": "1909.07814", "submitter": "Nishanth Chandran", "authors": "Nishant Kumar, Mayank Rathee, Nishanth Chandran, Divya Gupta, Aseem\n  Rastogi, and Rahul Sharma", "title": "CrypTFlow: Secure TensorFlow Inference", "comments": "To appear at 41st IEEE Symposium on Security and Privacy 2020. Code\n  available at: https://github.com/mpc-msri/EzPC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CrypTFlow, a first of its kind system that converts TensorFlow\ninference code into Secure Multi-party Computation (MPC) protocols at the push\nof a button. To do this, we build three components. Our first component, Athos,\nis an end-to-end compiler from TensorFlow to a variety of semi-honest MPC\nprotocols. The second component, Porthos, is an improved semi-honest 3-party\nprotocol that provides significant speedups for TensorFlow like applications.\nFinally, to provide malicious secure MPC protocols, our third component,\nAramis, is a novel technique that uses hardware with integrity guarantees to\nconvert any semi-honest MPC protocol into an MPC protocol that provides\nmalicious security. The malicious security of the protocols output by Aramis\nrelies on integrity of the hardware and semi-honest security of MPC. Moreover,\nour system matches the inference accuracy of plaintext TensorFlow.\n  We experimentally demonstrate the power of our system by showing the secure\ninference of real-world neural networks such as ResNet50 and DenseNet121 over\nthe ImageNet dataset with running times of about 30 seconds for semi-honest\nsecurity and under two minutes for malicious security. Prior work in the area\nof secure inference has been limited to semi-honest security of small networks\nover tiny datasets such as MNIST or CIFAR. Even on MNIST/CIFAR, CrypTFlow\noutperforms prior work.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 03:55:05 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 02:13:56 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Kumar", "Nishant", ""], ["Rathee", "Mayank", ""], ["Chandran", "Nishanth", ""], ["Gupta", "Divya", ""], ["Rastogi", "Aseem", ""], ["Sharma", "Rahul", ""]]}, {"id": "1909.07815", "submitter": "Qi Gao", "authors": "Qi Gao and Qijie Li and Shaowu Pan and Hongping Wang and Runjie Wei\n  and Jinjun Wang", "title": "Particle reconstruction of volumetric particle image velocimetry with\n  strategy of machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three-dimensional particle reconstruction with limited two-dimensional\nprojects is an underdetermined inverse problem that the exact solution is often\ndifficulty to be obtained. In general, approximate solutions can be obtained by\noptimization methods. In the current work, a practical particle reconstruction\nmethod based on convolutional neural network (CNN) is proposed. The proposed\ntechnique can refine the particle reconstruction from a very coarse initial\nguess of particle distribution from any traditional algebraic reconstruction\ntechnique (ART) based methods. Compared with available ART-based algorithms,\nthe novel technique makes significant improvements in terms of reconstruction\nquality and at least an order of magnitude faster with dense particle\nconcentration.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 03:35:18 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Gao", "Qi", ""], ["Li", "Qijie", ""], ["Pan", "Shaowu", ""], ["Wang", "Hongping", ""], ["Wei", "Runjie", ""], ["Wang", "Jinjun", ""]]}, {"id": "1909.07817", "submitter": "Shantenu Jha", "authors": "Hyungro Lee, Heng Ma, Matteo Turilli, Debsindhu Bhowmik, Shantenu Jha,\n  Arvind Ramanathan", "title": "DeepDriveMD: Deep-Learning Driven Adaptive Molecular Simulations for\n  Protein Folding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulations of biological macromolecules play an important role in\nunderstanding the physical basis of a number of complex processes such as\nprotein folding. Even with increasing computational power and evolution of\nspecialized architectures, the ability to simulate protein folding at atomistic\nscales still remains challenging. This stems from the dual aspects of high\ndimensionality of protein conformational landscapes, and the inability of\natomistic molecular dynamics (MD) simulations to sufficiently sample these\nlandscapes to observe folding events. Machine learning/deep learning (ML/DL)\ntechniques, when combined with atomistic MD simulations offer the opportunity\nto potentially overcome these limitations by: (1) effectively reducing the\ndimensionality of MD simulations to automatically build latent representations\nthat correspond to biophysically relevant reaction coordinates (RCs), and (2)\ndriving MD simulations to automatically sample potentially novel conformational\nstates based on these RCs. We examine how coupling DL approaches with MD\nsimulations can fold small proteins effectively on supercomputers. In\nparticular, we study the computational costs and effectiveness of scaling\nDL-coupled MD workflows by folding two prototypical systems, viz., Fs-peptide\nand the fast-folding variant of the villin head piece protein. We demonstrate\nthat a DL driven MD workflow is able to effectively learn latent\nrepresentations and drive adaptive simulations. Compared to traditional\nMD-based approaches, our approach achieves an effective performance gain in\nsampling the folded states by at least 2.3x. Our study provides a quantitative\nbasis to understand how DL driven MD simulations, can lead to effective\nperformance gains and reduced times to solution on supercomputing resources.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 13:58:47 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Lee", "Hyungro", ""], ["Ma", "Heng", ""], ["Turilli", "Matteo", ""], ["Bhowmik", "Debsindhu", ""], ["Jha", "Shantenu", ""], ["Ramanathan", "Arvind", ""]]}, {"id": "1909.07820", "submitter": "Sisheng Liang Liang", "authors": "Sisheng Liang, Zhou Yang, Fang Jin, Yong Chen", "title": "Data Centers Job Scheduling with Deep Reinforcement Learning", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient job scheduling on data centers under heterogeneous complexity is\ncrucial but challenging since it involves the allocation of multi-dimensional\nresources over time and space. To adapt the complex computing environment in\ndata centers, we proposed an innovative Advantage Actor-Critic (A2C) deep\nreinforcement learning based approach called A2cScheduler for job scheduling.\nA2cScheduler consists of two agents, one of which, dubbed the actor, is\nresponsible for learning the scheduling policy automatically and the other one,\nthe critic, reduces the estimation error. Unlike previous policy gradient\napproaches, A2cScheduler is designed to reduce the gradient estimation variance\nand to update parameters efficiently. We show that the A2cScheduler can achieve\ncompetitive scheduling performance using both simulated workloads and real data\ncollected from an academic data center.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 02:09:58 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 20:05:26 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Liang", "Sisheng", ""], ["Yang", "Zhou", ""], ["Jin", "Fang", ""], ["Chen", "Yong", ""]]}, {"id": "1909.07830", "submitter": "Chee Seng Chan", "authors": "Lixin Fan, Kam Woh Ng, Chee Seng Chan", "title": "[Extended version] Rethinking Deep Neural Network Ownership\n  Verification: Embedding Passports to Defeat Ambiguity Attacks", "comments": "This paper is accepted by NeurIPS 2019; Our code is available at\n  https://github.com/kamwoh/DeepIPR. This is the extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With substantial amount of time, resources and human (team) efforts invested\nto explore and develop successful deep neural networks (DNN), there emerges an\nurgent need to protect these inventions from being illegally copied,\nredistributed, or abused without respecting the intellectual properties of\nlegitimate owners. Following recent progresses along this line, we investigate\na number of watermark-based DNN ownership verification methods in the face of\nambiguity attacks, which aim to cast doubts on the ownership verification by\nforging counterfeit watermarks. It is shown that ambiguity attacks pose serious\nthreats to existing DNN watermarking methods. As remedies to the\nabove-mentioned loophole, this paper proposes novel passport-based DNN\nownership verification schemes which are both robust to network modifications\nand resilient to ambiguity attacks. The gist of embedding digital passports is\nto design and train DNN models in a way such that, the DNN inference\nperformance of an original task will be significantly deteriorated due to\nforged passports. In other words, genuine passports are not only verified by\nlooking for the predefined signatures, but also reasserted by the unyielding\nDNN model inference performances. Extensive experimental results justify the\neffectiveness of the proposed passport-based DNN ownership verification\nschemes. Code and models are available at https://github.com/kamwoh/DeepIPR\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 13:48:08 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 10:28:38 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 16:03:32 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Fan", "Lixin", ""], ["Ng", "Kam Woh", ""], ["Chan", "Chee Seng", ""]]}, {"id": "1909.07843", "submitter": "Rui Chen", "authors": "Rui Chen, Wenshuo Wang, Zirui Zhao and Ding Zhao", "title": "Active Learning for Risk-Sensitive Inverse Reinforcement Learning", "comments": "8 pages without acknowledgment, 7 figures, submitted to RA-L and ICRA\n  2020 for the IEEE Robotics and Automation Letters (RA-L)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One typical assumption in inverse reinforcement learning (IRL) is that human\nexperts act to optimize the expected utility of a stochastic cost with a fixed\ndistribution. This assumption deviates from actual human behaviors under\nambiguity. Risk-sensitive inverse reinforcement learning (RS-IRL) bridges such\ngap by assuming that humans act according to a random cost with respect to a\nset of subjectively distorted distributions instead of a fixed one. Such\nassumption provides the additional flexibility to model human's risk\npreferences, represented by a risk envelope, in safe-critical tasks. However,\nlike other learning from demonstration techniques, RS-IRL could also suffer\ninefficient learning due to redundant demonstrations. Inspired by the concept\nof active learning, this research derives a probabilistic disturbance sampling\nscheme to enable an RS-IRL agent to query expert support that is likely to\nexpose unrevealed boundaries of the expert's risk envelope. Experimental\nresults confirm that our approach accelerates the convergence of RS-IRL\nalgorithms with lower variance while still guaranteeing unbiased convergence.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 00:57:50 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 23:45:50 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Chen", "Rui", ""], ["Wang", "Wenshuo", ""], ["Zhao", "Zirui", ""], ["Zhao", "Ding", ""]]}, {"id": "1909.07846", "submitter": "Wei-Hung Weng", "authors": "Wei-Hung Weng, Yuannan Cai, Angela Lin, Fraser Tan, Po-Hsuan Cameron\n  Chen", "title": "Multimodal Multitask Representation Learning for Pathology Biobank\n  Metadata Prediction", "comments": "preprint version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metadata are general characteristics of the data in a well-curated and\ncondensed format, and have been proven to be useful for decision making,\nknowledge discovery, and also heterogeneous data organization of biobank. Among\nall data types in the biobank, pathology is the key component of the biobank\nand also serves as the gold standard of diagnosis. To maximize the utility of\nbiobank and allow the rapid progress of biomedical science, it is essential to\norganize the data with well-populated pathology metadata. However, manual\nannotation of such information is tedious and time-consuming. In the study, we\ndevelop a multimodal multitask learning framework to predict four major\nslide-level metadata of pathology images. The framework learns generalizable\nrepresentations across tissue slides, pathology reports, and case-level\nstructured data. We demonstrate improved performance across all four tasks with\nthe proposed method compared to a single modal single task baseline on two test\nsets, one external test set from a distinct data source (TCGA) and one internal\nheld-out test set (TTH). In the test sets, the performance improvements on the\naveraged area under receiver operating characteristic curve across the four\ntasks are 16.48% and 9.05% on TCGA and TTH, respectively. Such pathology\nmetadata prediction system may be adopted to mitigate the effort of expert\nannotation and ultimately accelerate the data-driven research by better\nutilization of the pathology biobank.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 14:34:37 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Weng", "Wei-Hung", ""], ["Cai", "Yuannan", ""], ["Lin", "Angela", ""], ["Tan", "Fraser", ""], ["Chen", "Po-Hsuan Cameron", ""]]}, {"id": "1909.07866", "submitter": "Maximilian Bachl", "authors": "Maximilian Bachl, Alexander Hartl, Joachim Fabini, Tanja Zseby", "title": "Walling up Backdoors in Intrusion Detection Systems", "comments": null, "journal-ref": "3rd ACM CoNEXT Workshop on Big DAta, Machine Learning and\n  Artificial Intelligence for Data Communication Networks (Big-DAMA '19),\n  December 9, 2019, Orlando, FL, USA", "doi": "10.1145/3359992.3366638", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interest in poisoning attacks and backdoors recently resurfaced for Deep\nLearning (DL) applications. Several successful defense mechanisms have been\nrecently proposed for Convolutional Neural Networks (CNNs), for example in the\ncontext of autonomous driving. We show that visualization approaches can aid in\nidentifying a backdoor independent of the used classifier. Surprisingly, we\nfind that common defense mechanisms fail utterly to remove backdoors in DL for\nIntrusion Detection Systems (IDSs). Finally, we devise pruning-based approaches\nto remove backdoors for Decision Trees (DTs) and Random Forests (RFs) and\ndemonstrate their effectiveness for two different network security datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 14:57:32 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 11:36:46 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 18:49:28 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Bachl", "Maximilian", ""], ["Hartl", "Alexander", ""], ["Fabini", "Joachim", ""], ["Zseby", "Tanja", ""]]}, {"id": "1909.07869", "submitter": "Amin Babadi", "authors": "Perttu H\\\"am\\\"al\\\"ainen, Juuso Toikka, Amin Babadi, C. Karen Liu", "title": "Visualizing Movement Control Optimization Landscapes", "comments": "Accepted to IEEE Transactions on Visualization and Computer Graphics\n  (IEEE TVCG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of animation research focuses on optimization of movement\ncontrol, either as action sequences or policy parameters. However, as\nclosed-form expressions of the objective functions are often not available, our\nunderstanding of the optimization problems is limited. Building on recent work\non analyzing neural network training, we contribute novel visualizations of\nhigh-dimensional control optimization landscapes; this yields insights into why\ncontrol optimization is hard and why common practices like early termination\nand spline-based action parameterizations make optimization easier. For\nexample, our experiments show how trajectory optimization can become\nincreasingly ill-conditioned with longer trajectories, but parameterizing\ncontrol as partial target states---e.g., target angles converted to torques\nusing a PD-controller---can act as an efficient preconditioner. Both our\nvisualizations and quantitative empirical data also indicate that neural\nnetwork policy optimization scales better than trajectory optimization for long\nplanning horizons. Our work advances the understanding of movement optimization\nand our visualizations should also provide value in educational use.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:02:50 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 06:42:11 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 07:42:56 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Perttu", ""], ["Toikka", "Juuso", ""], ["Babadi", "Amin", ""], ["Liu", "C. Karen", ""]]}, {"id": "1909.07872", "submitter": "Markus L\\\"oning", "authors": "Markus L\\\"oning and Anthony Bagnall and Sajaysurya Ganesh and Viktor\n  Kazakov and Jason Lines and Franz J. Kir\\'aly", "title": "sktime: A Unified Interface for Machine Learning with Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present sktime -- a new scikit-learn compatible Python library with a\nunified interface for machine learning with time series. Time series data gives\nrise to various distinct but closely related learning tasks, such as\nforecasting and time series classification, many of which can be solved by\nreducing them to related simpler tasks. We discuss the main rationale for\ncreating a unified interface, including reduction, as well as the design of\nsktime's core API, supported by a clear overview of common time series tasks\nand reduction approaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:04:08 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["L\u00f6ning", "Markus", ""], ["Bagnall", "Anthony", ""], ["Ganesh", "Sajaysurya", ""], ["Kazakov", "Viktor", ""], ["Lines", "Jason", ""], ["Kir\u00e1ly", "Franz J.", ""]]}, {"id": "1909.07873", "submitter": "Prashanth Vijayaraghavan", "authors": "Prashanth Vijayaraghavan, Deb Roy", "title": "Generating Black-Box Adversarial Examples for Text Classifiers Using a\n  Deep Reinforced Model", "comments": "16 pages, 3 figures, ECML PKDD 2019", "journal-ref": "Joint European Conference on Machine Learning and Knowledge\n  Discovery in Databases. Springer, Cham, 2019", "doi": "10.1007/978-3-030-46147-8_43", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, generating adversarial examples has become an important means of\nmeasuring robustness of a deep learning model. Adversarial examples help us\nidentify the susceptibilities of the model and further counter those\nvulnerabilities by applying adversarial training techniques. In natural\nlanguage domain, small perturbations in the form of misspellings or paraphrases\ncan drastically change the semantics of the text. We propose a reinforcement\nlearning based approach towards generating adversarial examples in black-box\nsettings. We demonstrate that our method is able to fool well-trained models\nfor (a) IMDB sentiment classification task and (b) AG's news corpus news\ncategorization task with significantly high success rates. We find that the\nadversarial examples generated are semantics-preserving perturbations to the\noriginal text.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:05:31 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Vijayaraghavan", "Prashanth", ""], ["Roy", "Deb", ""]]}, {"id": "1909.07876", "submitter": "Matthew Wilson", "authors": "Matthew Wilson, Tucker Hermans", "title": "Learning to Manipulate Object Collections Using Grounded State\n  Representations", "comments": "Accepted to Conference on Robot Learning 2019 (Oral); Video results:\n  https://bit.ly/2khSKUs; v3: fix abstract and appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a method for sim-to-real robot learning which exploits simulator\nstate information in a way that scales to many objects. We first train a pair\nof encoder networks to capture multi-object state information in a latent\nspace. One of these encoders is a CNN, which enables our system to operate on\nRGB images in the real world; the other is a graph neural network (GNN) state\nencoder, which directly consumes a set of raw object poses and enables more\naccurate reward calculation and value estimation. Once trained, we use these\nencoders in a reinforcement learning algorithm to train image-based policies\nthat can manipulate many objects. We evaluate our method on the task of pushing\na collection of objects to desired tabletop regions. Compared to methods which\nrely only on images or use fixed-length state encodings, our method achieves\nhigher success rates, performs well in the real world without fine tuning, and\ngeneralizes to different numbers and types of objects not seen during training.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:06:25 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 21:39:08 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 21:54:44 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Wilson", "Matthew", ""], ["Hermans", "Tucker", ""]]}, {"id": "1909.07881", "submitter": "Palakorn Achananuparp", "authors": "Helena Lee, Palakorn Achananuparp, Yue Liu, Ee-Peng Lim, Lav R.\n  Varshney", "title": "Estimating Glycemic Impact of Cooking Recipes via Online Crowdsourcing\n  and Machine Learning", "comments": "To appear in the Proceedings of Digital Public Health 2019 as short\n  paper", "journal-ref": null, "doi": "10.1145/3357729.3357748", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumption of diets with low glycemic impact is highly recommended for\ndiabetics and pre-diabetics as it helps maintain their blood glucose levels.\nHowever, laboratory analysis of dietary glycemic potency is time-consuming and\nexpensive. In this paper, we explore a data-driven approach utilizing online\ncrowdsourcing and machine learning to estimate the glycemic impact of cooking\nrecipes. We show that a commonly used healthiness metric may not always be\neffective in determining recipes suitable for diabetics, thus emphasizing the\nimportance of the glycemic-impact estimation task. Our best classification\nmodel, trained on nutritional and crowdsourced data obtained from Amazon\nMechanical Turk (AMT), can accurately identify recipes which are unhealthful\nfor diabetics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:14:51 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Lee", "Helena", ""], ["Achananuparp", "Palakorn", ""], ["Liu", "Yue", ""], ["Lim", "Ee-Peng", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1909.07903", "submitter": "Yuanqing Wang", "authors": "Yuanqing Wang, Josh Fass, Chaya D. Stern, Kun Luo, John Chodera", "title": "Graph Nets for Partial Charge Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atomic partial charges are crucial parameters for Molecular Dynamics (MD)\nsimulations, molecular mechanics calculations, and virtual screening, as they\ndetermine the electrostatic contributions to interaction energies. Current\nmethods for calculating partial charges, however, are either slow and scale\npoorly with molecular size (quantum chemical methods) or unreliable (empirical\nmethods). Here, we present a new charge derivation method based on Graph\nNets---a set of update and aggregate functions that operate on molecular\ntopologies and propagate information thereon---that could approximate charges\nderived from Density Functional Theory (DFT) calculations with high accuracy\nand an over 500-fold speed up.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:44:47 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Wang", "Yuanqing", ""], ["Fass", "Josh", ""], ["Stern", "Chaya D.", ""], ["Luo", "Kun", ""], ["Chodera", "John", ""]]}, {"id": "1909.07908", "submitter": "Tayfun Gokmen", "authors": "Tayfun Gokmen, Wilfried Haensch", "title": "Algorithm for Training Neural Networks on Resistive Device Arrays", "comments": "26 pages, 7 fiures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware architectures composed of resistive cross-point device arrays can\nprovide significant power and speed benefits for deep neural network training\nworkloads using stochastic gradient descent (SGD) and backpropagation (BP)\nalgorithm. The training accuracy on this imminent analog hardware however\nstrongly depends on the switching characteristics of the cross-point elements.\nOne of the key requirements is that these resistive devices must change\nconductance in a symmetrical fashion when subjected to positive or negative\npulse stimuli. Here, we present a new training algorithm, so-called the\n\"Tiki-Taka\" algorithm, that eliminates this stringent symmetry requirement. We\nshow that device asymmetry introduces an unintentional implicit cost term into\nthe SGD algorithm, whereas in the \"Tiki-Taka\" algorithm a coupled dynamical\nsystem simultaneously minimizes the original objective function of the neural\nnetwork and the unintentional cost term due to device asymmetry in a\nself-consistent fashion. We tested the validity of this new algorithm on a\nrange of network architectures such as fully connected, convolutional and LSTM\nnetworks. Simulation results on these various networks show that whatever\naccuracy is achieved using the conventional SGD algorithm with symmetric\n(ideal) device switching characteristics the same accuracy is also achieved\nusing the \"Tiki-Taka\" algorithm with non-symmetric (non-ideal) device switching\ncharacteristics. Moreover, all the operations performed on the arrays are still\nparallel and therefore the implementation cost of this new algorithm on array\narchitectures is minimal; and it maintains the aforementioned power and speed\nbenefits. These algorithmic improvements are crucial to relax the material\nspecification and to realize technologically viable resistive crossbar arrays\nthat outperform digital accelerators for similar training tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:52:28 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Gokmen", "Tayfun", ""], ["Haensch", "Wilfried", ""]]}, {"id": "1909.07913", "submitter": "Danish Pruthi", "authors": "Danish Pruthi, Mansi Gupta, Bhuwan Dhingra, Graham Neubig, Zachary C.\n  Lipton", "title": "Learning to Deceive with Attention-Based Explanations", "comments": "Accepted to ACL 2020 as a long paper. Updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms are ubiquitous components in neural architectures\napplied to natural language processing. In addition to yielding gains in\npredictive accuracy, attention weights are often claimed to confer\ninterpretability, purportedly useful both for providing insights to\npractitioners and for explaining why a model makes its decisions to\nstakeholders. We call the latter use of attention mechanisms into question by\ndemonstrating a simple method for training models to produce deceptive\nattention masks. Our method diminishes the total weight assigned to designated\nimpermissible tokens, even when the models can be shown to nevertheless rely on\nthese features to drive predictions. Across multiple models and tasks, our\napproach manipulates attention weights while paying surprisingly little cost in\naccuracy. Through a human study, we show that our manipulated attention-based\nexplanations deceive people into thinking that predictions from a model biased\nagainst gender minorities do not rely on the gender. Consequently, our results\ncast doubt on attention's reliability as a tool for auditing algorithms in the\ncontext of fairness and accountability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:10:30 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 20:13:40 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Pruthi", "Danish", ""], ["Gupta", "Mansi", ""], ["Dhingra", "Bhuwan", ""], ["Neubig", "Graham", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1909.07922", "submitter": "Andrea Schioppa", "authors": "Andrea Schioppa", "title": "Distributed Function Minimization in Apache Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on an open-source implementation for distributed function\nminimization on top of Apache Spark by using gradient and quasi-Newton methods.\nWe show-case it with an application to Optimal Transport and some scalability\ntests on classification and regression problems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:38:13 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Schioppa", "Andrea", ""]]}, {"id": "1909.07926", "submitter": "Alexandre Gilotte", "authors": "Alexandre Gilotte", "title": "Ranking metrics on non-shuffled traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking metrics are a family of metrics largely used to evaluate recommender\nsystems. However they typically suffer from the fact the reward is affected by\nthe order in which recommended items are displayed to the user. A classical way\nto overcome this position bias is to uniformly shuffle a proportion of the\nrecommendations, but this method may result in a bad user experience. It is\nnevertheless common to use a stochastic policy to generate the recommendations,\nand we suggest a new method to overcome the position bias, by leveraging the\nstochasticity of the policy used to collect the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:46:47 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Gilotte", "Alexandre", ""]]}, {"id": "1909.07930", "submitter": "Piero Molino", "authors": "Piero Molino, Yaroslav Dudin, Sai Sumanth Miryala", "title": "Ludwig: a type-based declarative deep learning toolbox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present Ludwig, a flexible, extensible and easy to use\ntoolbox which allows users to train deep learning models and use them for\nobtaining predictions without writing code. Ludwig implements a novel approach\nto deep learning model building based on two main abstractions: data types and\ndeclarative configuration files. The data type abstraction allows for easier\ncode and sub-model reuse, and the standardized interfaces imposed by this\nabstraction allow for encapsulation and make the code easy to extend.\nDeclarative model definition configuration files enable inexperienced users to\nobtain effective models and increase the productivity of expert users.\nAlongside these two innovations, Ludwig introduces a general modularized deep\nlearning architecture called Encoder-Combiner-Decoder that can be instantiated\nto perform a vast amount of machine learning tasks. These innovations make it\npossible for engineers, scientists from other fields and, in general, a much\nbroader audience to adopt deep learning models for their tasks, concretely\nhelping in its democratization.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 16:54:29 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Molino", "Piero", ""], ["Dudin", "Yaroslav", ""], ["Miryala", "Sai Sumanth", ""]]}, {"id": "1909.07940", "submitter": "Eric Wallace", "authors": "Eric Wallace, Yizhong Wang, Sujian Li, Sameer Singh, Matt Gardner", "title": "Do NLP Models Know Numbers? Probing Numeracy in Embeddings", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to understand and work with numbers (numeracy) is critical for\nmany complex reasoning tasks. Currently, most NLP models treat numbers in text\nin the same way as other tokens---they embed them as distributed vectors. Is\nthis enough to capture numeracy? We begin by investigating the numerical\nreasoning capabilities of a state-of-the-art question answering model on the\nDROP dataset. We find this model excels on questions that require numerical\nreasoning, i.e., it already captures numeracy. To understand how this\ncapability emerges, we probe token embedding methods (e.g., BERT, GloVe) on\nsynthetic list maximum, number decoding, and addition tasks. A surprising\ndegree of numeracy is naturally present in standard embeddings. For example,\nGloVe and word2vec accurately encode magnitude for numbers up to 1,000.\nFurthermore, character-level embeddings are even more precise---ELMo captures\nnumeracy the best for all pre-trained methods---but BERT, which uses sub-word\nunits, is less exact.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 17:24:37 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 04:08:27 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wallace", "Eric", ""], ["Wang", "Yizhong", ""], ["Li", "Sujian", ""], ["Singh", "Sameer", ""], ["Gardner", "Matt", ""]]}, {"id": "1909.07944", "submitter": "Omid Shams Solari", "authors": "Omid Shams Solari, Rojin Safavi, James B. Brown", "title": "BLOCCS: Block Sparse Canonical Correlation Analysis With Application To\n  Interpretable Omics Integration", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Block Sparse Canonical Correlation Analysis which estimates\nmultiple pairs of canonical directions (together a \"block\") at once, resulting\nin significantly improved orthogonality of the sparse directions which, we\ndemonstrate, translates to more interpretable solutions. Our approach builds on\nthe sparse CCA method of (Solari, Brown, and Bickel 2019) in that we also\nexpress the bi-convex objective of our block formulation as a concave\nminimization problem over an orthogonal k-frame in a unit Euclidean ball, which\nin turn, due to concavity of the objective, is shrunk to a Stiefel manifold,\nwhich is optimized via gradient descent algorithm. Our simulations show that\nour method outperforms existing sCCA algorithms and implementations in terms of\ncomputational cost and stability, mainly due to the drastic shrinkage of our\nsearch space, and the correlation within and orthogonality between pairs of\nestimated canonical covariates. Finally, we apply our method, available as an\nR-package called BLOCCS, to multi-omic data on Lung Squamous Cell\nCarcinoma(LUSC) obtained via The Cancer Genome Atlas, and demonstrate its\ncapability in capturing meaningful biological associations relevant to the\nhypothesis under study rather than spurious dominant variations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 17:28:18 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 20:09:54 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Solari", "Omid Shams", ""], ["Safavi", "Rojin", ""], ["Brown", "James B.", ""]]}, {"id": "1909.07947", "submitter": "Omid Shams Solari", "authors": "Omid S. Solari, James B. Brown, Peter J. Bickel", "title": "Sparse Canonical Correlation Analysis via Concave Minimization", "comments": "45 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach to the sparse Canonical Correlation Analysis (sCCA)is proposed\nwith the aim of discovering interpretable associations in very high-dimensional\nmulti-view, i.e.observations of multiple sets of variables on the same\nsubjects, problems. Inspired by the sparse PCA approach of Journee et al.\n(2010), we also show that the sparse CCA formulation, while non-convex, is\nequivalent to a maximization program of a convex objective over a compact set\nfor which we propose a first-order gradient method. This result helps us reduce\nthe search space drastically to the boundaries of the set. Consequently, we\npropose a two-step algorithm, where we first infer the sparsity pattern of the\ncanonical directions using our fast algorithm, then we shrink each view, i.e.\nobservations of a set of covariates, to contain observations on the sets of\ncovariates selected in the previous step, and compute their canonical\ndirections via any CCA algorithm. We also introduceDirected Sparse CCA, which\nis able to find associations which are aligned with a specified experiment\ndesign, andMulti-View sCCA which is used to discover associations between\nmultiple sets of covariates. Our simulations establish the superior convergence\nproperties and computational efficiency of our algorithm as well as accuracy in\nterms of the canonical correlation and its ability to recover the supports of\nthe canonical directions. We study the associations between metabolomics,\ntrasncriptomics and microbiomics in a multi-omic study usingMuLe, which is an\nR-package that implements our approach, in order to form hypotheses on\nmechanisms of adaptations of Drosophila Melanogaster to high doses of\nenvironmental toxicants, specifically Atrazine, which is a commonly used\nchemical fertilizer.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 17:29:12 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Solari", "Omid S.", ""], ["Brown", "James B.", ""], ["Bickel", "Peter J.", ""]]}, {"id": "1909.07963", "submitter": "Xinliang Zhang", "authors": "Xinliang Zhang and Mojtaba Vaezi", "title": "Deep Learning based Precoding for the MIMO Gaussian Wiretap Channel", "comments": "To appear in IEEE Globecom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel precoding method based on supervised deep neural networks is\nintroduced for the multiple-input multiple-output Gaussian wiretap channel. The\nproposed deep learning (DL)-based precoding learns the input covariance matrix\nthrough offline training over a large set of input channels and their\ncorresponding covariance matrices for efficient, reliable, and secure\ntransmission of information. Furthermore, by spending time in offline training,\nthis method remarkably reduces the computation complexity in real-time\napplications. Compared to traditional precoding methods, the proposed DL-based\nprecoding is significantly faster and reaches near-capacity secrecy rates.\nDL-based precoding is also more robust than transitional precoding approaches\nto the number of antennas at the eavesdropper. This new approach to precoding\nis promising in applications in which delay and complexity are critical.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 17:52:58 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Zhang", "Xinliang", ""], ["Vaezi", "Mojtaba", ""]]}, {"id": "1909.07969", "submitter": "Linda Senigagliesi", "authors": "Linda Senigagliesi, Marco Baldi, Ennio Gambi", "title": "Statistical and Machine Learning-based Decision Techniques for Physical\n  Layer Authentication", "comments": "To be presented at IEEE Globecom 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we assess the security performance of key-less physical layer\nauthentication schemes in the case of time-varying fading channels, considering\nboth partial and no channel state information (CSI) on the receiver's side. We\nfirst present a generalization of a well-known protocol previously proposed for\nflat fading channels and we study different statistical decision methods and\nthe corresponding optimal attack strategies in order to improve the\nauthentication performance in the considered scenario. We then consider the\napplication of machine learning techniques in the same setting, exploiting\ndifferent one-class nearest neighbor (OCNN) classification algorithms. We\nobserve that, under the same probability of false alarm, one-class\nclassification (OCC) algorithms achieve the lowest probability of missed\ndetection when a low spatial correlation exists between the main channel and\nthe adversary one, while statistical methods are advantageous when the spatial\ncorrelation between the two channels is higher.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 20:15:54 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Senigagliesi", "Linda", ""], ["Baldi", "Marco", ""], ["Gambi", "Ennio", ""]]}, {"id": "1909.07972", "submitter": "Mingzhe Chen", "authors": "Mingzhe Chen, Zhaohui Yang, Walid Saad, Changchuan Yin, H. Vincent\n  Poor, and Shuguang Cui", "title": "A Joint Learning and Communications Framework for Federated Learning\n  over Wireless Networks", "comments": "This paper has been accepted by IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of training federated learning (FL) algorithms\nover a realistic wireless network is studied. In particular, in the considered\nmodel, wireless users execute an FL algorithm while training their local FL\nmodels using their own data and transmitting the trained local FL models to a\nbase station (BS) that will generate a global FL model and send it back to the\nusers. Since all training parameters are transmitted over wireless links, the\nquality of the training will be affected by wireless factors such as packet\nerrors and the availability of wireless resources. Meanwhile, due to the\nlimited wireless bandwidth, the BS must select an appropriate subset of users\nto execute the FL algorithm so as to build a global FL model accurately. This\njoint learning, wireless resource allocation, and user selection problem is\nformulated as an optimization problem whose goal is to minimize an FL loss\nfunction that captures the performance of the FL algorithm. To address this\nproblem, a closed-form expression for the expected convergence rate of the FL\nalgorithm is first derived to quantify the impact of wireless factors on FL.\nThen, based on the expected convergence rate of the FL algorithm, the optimal\ntransmit power for each user is derived, under a given user selection and\nuplink resource block (RB) allocation scheme. Finally, the user selection and\nuplink RB allocation is optimized so as to minimize the FL loss function.\nSimulation results show that the proposed joint federated learning and\ncommunication framework can reduce the FL loss function value by up to 10% and\n16%, respectively, compared to: 1) An optimal user selection algorithm with\nrandom resource allocation and 2) a standard FL algorithm with random user\nselection and resource allocation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 02:38:21 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 01:15:35 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 01:47:28 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Chen", "Mingzhe", ""], ["Yang", "Zhaohui", ""], ["Saad", "Walid", ""], ["Yin", "Changchuan", ""], ["Poor", "H. Vincent", ""], ["Cui", "Shuguang", ""]]}, {"id": "1909.07973", "submitter": "Xiaoyu Yu", "authors": "Xiaoyu Yu, Yuwei Wang, Jie Miao, Ephrem Wu, Heng Zhang, Yu Meng, Bo\n  Zhang, Biao Min, Dewei Chen, Jianlin Gao", "title": "A Data-Center FPGA Acceleration Platform for Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/FPL.2019.00032", "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intensive computation is entering data centers with multiple workloads of\ndeep learning. To balance the compute efficiency, performance, and total cost\nof ownership (TCO), the use of a field-programmable gate array (FPGA) with\nreconfigurable logic provides an acceptable acceleration capacity and is\ncompatible with diverse computation-sensitive tasks in the cloud. In this\npaper, we develop an FPGA acceleration platform that leverages a unified\nframework architecture for general-purpose convolutional neural network (CNN)\ninference acceleration at a data center. To overcome the computation bound,\n4,096 DSPs are assembled and shaped as supertile units (SUs) for different\ntypes of convolution, which provide up to 4.2 TOP/s 16-bit fixed-point\nperformance at 500 MHz. The interleaved-task-dispatching method is proposed to\nmap the computation across the SUs, and the memory bound is solved by a\ndispatching-assembling buffering model and broadcast caches. For various\nnon-convolution operators, a filter processing unit is designed for\ngeneral-purpose filter-like/pointwise operators. In the experiment, the\nperformances of CNN models running on server-class CPUs, a GPU, and an FPGA are\ncompared. The results show that our design achieves the best FPGA peak\nperformance and a throughput at the same level as that of the state-of-the-art\nGPU in data centers, with more than 50 times lower latency.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 03:32:21 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Yu", "Xiaoyu", ""], ["Wang", "Yuwei", ""], ["Miao", "Jie", ""], ["Wu", "Ephrem", ""], ["Zhang", "Heng", ""], ["Meng", "Yu", ""], ["Zhang", "Bo", ""], ["Min", "Biao", ""], ["Chen", "Dewei", ""], ["Gao", "Jianlin", ""]]}, {"id": "1909.07974", "submitter": "William Leeb", "authors": "William Leeb", "title": "Properties of Laplacian Pyramids for Extension and Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the Laplacian pyramids algorithm of Rabin and Coifman for\nextending and denoising a function sampled on a discrete set of points. We\nprovide mild conditions under which the algorithm converges, and prove\nstability bounds on the extended function. We also consider the iterative\napplication of truncated Laplacian pyramids kernels for denoising signals by\nnon-local means.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:28:24 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Leeb", "William", ""]]}, {"id": "1909.08028", "submitter": "Mai Nguyen", "authors": "Bosung Seo, Daniel Mariano, John Beckfield, Vinay Madenur, Yuming Hu,\n  Tony Reina, Marcus Bobar, Mai H. Nguyen, Ilkay Altintas", "title": "Cardiac MRI Image Segmentation for Left Ventricle and Right Ventricle\n  using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this project is to use magnetic resonance imaging (MRI) data to\nprovide an end-to-end analytics pipeline for left and right ventricle (LV and\nRV) segmentation. Another aim of the project is to find a model that would be\ngeneralizable across medical imaging datasets. We utilized a variety of models,\ndatasets, and tests to determine which one is well suited to this purpose.\nSpecifically, we implemented three models (2-D U-Net, 3-D U-Net, and DenseNet),\nand evaluated them on four datasets (Automated Cardiac Diagnosis Challenge,\nMICCAI 2009 LV, Sunnybrook Cardiac Data, MICCAI 2012 RV). While maintaining a\nconsistent preprocessing strategy, we tested the performance of each model when\ntrained on data from the same dataset as the test data, and when trained on\ndata from a different dataset than the test dataset. Data augmentation was also\nused to increase the adaptability of the models. The results were compared to\ndetermine performance and generalizability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 18:57:43 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Seo", "Bosung", ""], ["Mariano", "Daniel", ""], ["Beckfield", "John", ""], ["Madenur", "Vinay", ""], ["Hu", "Yuming", ""], ["Reina", "Tony", ""], ["Bobar", "Marcus", ""], ["Nguyen", "Mai H.", ""], ["Altintas", "Ilkay", ""]]}, {"id": "1909.08029", "submitter": "Qinyi Luo", "authors": "Qinyi Luo, Jiaao He, Youwei Zhuo, Xuehai Qian", "title": "Heterogeneity-Aware Asynchronous Decentralized Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed deep learning training usually adopts All-Reduce as the\nsynchronization mechanism for data parallel algorithms due to its high\nperformance in homogeneous environment. However, its performance is bounded by\nthe slowest worker among all workers, and is significantly slower in\nheterogeneous situations. AD-PSGD, a newly proposed synchronization method\nwhich provides numerically fast convergence and heterogeneity tolerance,\nsuffers from deadlock issues and high synchronization overhead. Is it possible\nto get the best of both worlds - designing a distributed training method that\nhas both high performance as All-Reduce in homogeneous environment and good\nheterogeneity tolerance as AD-PSGD? In this paper, we propose Ripples, a\nhigh-performance heterogeneity-aware asynchronous decentralized training\napproach. We achieve the above goal with intensive synchronization\noptimization, emphasizing the interplay between algorithm and system\nimplementation. To reduce synchronization cost, we propose a novel\ncommunication primitive Partial All-Reduce that allows a large group of workers\nto synchronize quickly. To reduce synchronization conflict, we propose static\ngroup scheduling in homogeneous environment and simple techniques (Group Buffer\nand Group Division) to avoid conflicts with slightly reduced randomness. Our\nexperiments show that in homogeneous environment, Ripples is 1.1 times faster\nthan the state-of-the-art implementation of All-Reduce, 5.1 times faster than\nParameter Server and 4.3 times faster than AD-PSGD. In a heterogeneous setting,\nRipples shows 2 times speedup over All-Reduce, and still obtains 3 times\nspeedup over the Parameter Server baseline.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 18:57:49 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Luo", "Qinyi", ""], ["He", "Jiaao", ""], ["Zhuo", "Youwei", ""], ["Qian", "Xuehai", ""]]}, {"id": "1909.08041", "submitter": "Yixin Nie", "authors": "Yixin Nie, Songhe Wang, Mohit Bansal", "title": "Revealing the Importance of Semantic Retrieval for Machine Reading at\n  Scale", "comments": "14 pages (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading at Scale (MRS) is a challenging task in which a system is\ngiven an input query and is asked to produce a precise output by \"reading\"\ninformation from a large knowledge base. The task has gained popularity with\nits natural combination of information retrieval (IR) and machine comprehension\n(MC). Advancements in representation learning have led to separated progress in\nboth IR and MC; however, very few studies have examined the relationship and\ncombined design of retrieval and comprehension at different levels of\ngranularity, for development of MRS systems. In this work, we give general\nguidelines on system design for MRS by proposing a simple yet effective\npipeline system with special consideration on hierarchical semantic retrieval\nat both paragraph and sentence level, and their potential effects on the\ndownstream task. The system is evaluated on both fact verification and\nopen-domain multihop QA, achieving state-of-the-art results on the leaderboard\ntest sets of both FEVER and HOTPOTQA. To further demonstrate the importance of\nsemantic retrieval, we present ablation and analysis studies to quantify the\ncontribution of neural retrieval modules at both paragraph-level and\nsentence-level, and illustrate that intermediate semantic retrieval modules are\nvital for not only effectively filtering upstream information and thus saving\ndownstream computation, but also for shaping upstream data distribution and\nproviding better data for downstream modeling. Code/data made publicly\navailable at: https://github.com/easonnie/semanticRetrievalMRS\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 19:21:11 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Nie", "Yixin", ""], ["Wang", "Songhe", ""], ["Bansal", "Mohit", ""]]}, {"id": "1909.08049", "submitter": "Shervin Minaee", "authors": "Amirhossein Khalilian-Gourtani, Shervin Minaee, Yao Wang", "title": "Masked-RPCA: Sparse and Low-rank Decomposition Under Overlaying Model\n  and Application to Moving Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Foreground detection in a given video sequence is a pivotal step in many\ncomputer vision applications such as video surveillance system. Robust\nPrincipal Component Analysis (RPCA) performs low-rank and sparse decomposition\nand accomplishes such a task when the background is stationary and the\nforeground is dynamic and relatively small. A fundamental issue with RPCA is\nthe assumption that the low-rank and sparse components are added at each\nelement, whereas in reality, the moving foreground is overlaid on the\nbackground. We propose the representation via masked decomposition (i.e. an\noverlaying model) where each element either belongs to the low-rank or the\nsparse component, decided by a mask. We propose the Masked-RPCA algorithm to\nrecover the mask and the low-rank components simultaneously, utilizing\nlinearizing and alternating direction techniques. We further extend our\nformulation to be robust to dynamic changes in the background and enforce\nspatial connectivity in the foreground component. Our study shows significant\nimprovement of the detected mask compared to post-processing on the sparse\ncomponent obtained by other frameworks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 19:39:15 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Khalilian-Gourtani", "Amirhossein", ""], ["Minaee", "Shervin", ""], ["Wang", "Yao", ""]]}, {"id": "1909.08050", "submitter": "Ross Cutler", "authors": "Chandan K. A. Reddy, Ebrahim Beyrami, Jamie Pool, Ross Cutler, Sriram\n  Srinivasan, Johannes Gehrke", "title": "A scalable noisy speech dataset and online subjective test framework", "comments": "InterSpeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background noise is a major source of quality impairments in Voice over\nInternet Protocol (VoIP) and Public Switched Telephone Network (PSTN) calls.\nRecent work shows the efficacy of deep learning for noise suppression, but the\ndatasets have been relatively small compared to those used in other domains\n(e.g., ImageNet) and the associated evaluations have been more focused. In\norder to better facilitate deep learning research in Speech Enhancement, we\npresent a noisy speech dataset (MS-SNSD) that can scale to arbitrary sizes\ndepending on the number of speakers, noise types, and Speech to Noise Ratio\n(SNR) levels desired. We show that increasing dataset sizes increases noise\nsuppression performance as expected. In addition, we provide an open-source\nevaluation methodology to evaluate the results subjectively at scale using\ncrowdsourcing, with a reference algorithm to normalize the results. To\ndemonstrate the dataset and evaluation framework we apply it to several noise\nsuppressors and compare the subjective Mean Opinion Score (MOS) with objective\nquality measures such as SNR, PESQ, POLQA, and VISQOL and show why MOS is still\nrequired. Our subjective MOS evaluation is the first large scale evaluation of\nSpeech Enhancement algorithms that we are aware of.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 19:40:34 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Reddy", "Chandan K. A.", ""], ["Beyrami", "Ebrahim", ""], ["Pool", "Jamie", ""], ["Cutler", "Ross", ""], ["Srinivasan", "Sriram", ""], ["Gehrke", "Johannes", ""]]}, {"id": "1909.08069", "submitter": "Hong-Ning Dai Prof.", "authors": "Hong-Ning Dai and Raymond Chi-Wing Wong and Hao Wang and Zibin Zheng\n  and Athanasios V. Vasilakos", "title": "Big Data Analytics for Large Scale Wireless Networks: Challenges and\n  Opportunities", "comments": "29 pages, 14 figures, 8 tables", "journal-ref": "ACM Computing Surveys, 2019", "doi": "10.1145/3337065", "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The wide proliferation of various wireless communication systems and wireless\ndevices has led to the arrival of big data era in large scale wireless\nnetworks. Big data of large scale wireless networks has the key features of\nwide variety, high volume, real-time velocity and huge value leading to the\nunique research challenges that are different from existing computing systems.\nIn this paper, we present a survey of the state-of-art big data analytics (BDA)\napproaches for large scale wireless networks. In particular, we categorize the\nlife cycle of BDA into four consecutive stages: Data Acquisition, Data\nPreprocessing, Data Storage and Data Analytics. We then present a detailed\nsurvey of the technical solutions to the challenges in BDA for large scale\nwireless networks according to each stage in the life cycle of BDA. Moreover,\nwe discuss the open research issues and outline the future directions in this\npromising area.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2019 13:25:23 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Dai", "Hong-Ning", ""], ["Wong", "Raymond Chi-Wing", ""], ["Wang", "Hao", ""], ["Zheng", "Zibin", ""], ["Vasilakos", "Athanasios V.", ""]]}, {"id": "1909.08072", "submitter": "Han Xu", "authors": "Han Xu, Yao Ma, Haochen Liu, Debayan Deb, Hui Liu, Jiliang Tang, Anil\n  K. Jain", "title": "Adversarial Attacks and Defenses in Images, Graphs and Text: A Review", "comments": "survey, adversarial attacks, defenses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have achieved unprecedented success in numerous\nmachine learning tasks in various domains. However, the existence of\nadversarial examples has raised concerns about applying deep learning to\nsafety-critical applications. As a result, we have witnessed increasing\ninterests in studying attack and defense mechanisms for DNN models on different\ndata types, such as images, graphs and text. Thus, it is necessary to provide a\nsystematic and comprehensive overview of the main threats of attacks and the\nsuccess of corresponding countermeasures. In this survey, we review the state\nof the art algorithms for generating adversarial examples and the\ncountermeasures against adversarial examples, for the three popular data types,\ni.e., images, graphs and text.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:07:23 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 15:58:43 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Xu", "Han", ""], ["Ma", "Yao", ""], ["Liu", "Haochen", ""], ["Deb", "Debayan", ""], ["Liu", "Hui", ""], ["Tang", "Jiliang", ""], ["Jain", "Anil K.", ""]]}, {"id": "1909.08074", "submitter": "Beakal Gizachew Assefa Dr", "authors": "Beakal Gizachew Assefa, Oznur Ozkasap", "title": "HyMER: A Hybrid Machine Learning Framework for Energy Efficient Routing\n  in SDN", "comments": "Double column 12 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-defined networks (SDN) with programmable data plane and machine\nlearning for discovering patterns are utilized in security, traffic\nclassification, quality of services prediction, and network performance, that\nhas increasing research attention. Addressing the significance of energy\nefficiency in networks, we propose a novel hybrid machine learning-based\nframework named HyMER that combines the capabilities of SDN and machine\nlearning for traffic-aware energy efficient routing. To the best of our\nknowledge, HyMER is the first that utilizes a hybrid machine learning solution\nwith supervised and reinforcement learning components for energy efficiency and\nnetwork performance in SDN. The supervised learning component consists of\nfeature extraction, training, and testing. The reinforcement learning component\nlearns from existing data or from scratch by iteratively interacting with the\nnetwork environment. The HyMER framework is developed on POX controller and is\nevaluated on Mininet using real-world topologies and dynamic traffic traces.\nExperimental results show that the supervised component achieves up to 70%\nfeature size reduction and more than 80\\% accuracy in parameter prediction. We\ndemonstrate that combining the supervised and reinforcement methods not only\ndoes capture the dynamic change more efficiently but also increases the\nconvergence speed. As compared to state-of-the-art utility based energy saving\napproaches, HyMER heuristics has shown up to 50% link saving, and also exhibits\nup to 14.7 watts less power consumption for realistic network topology and\ntraffic traces.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:42:36 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 09:57:02 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Assefa", "Beakal Gizachew", ""], ["Ozkasap", "Oznur", ""]]}, {"id": "1909.08079", "submitter": "Ugo Tanielian", "authors": "Ugo Tanielian, Flavian Vasile", "title": "Relaxed Softmax for learning from Positive and Unlabeled data", "comments": "9 pages, 5 figures, 2 tables, published at RecSys 2019", "journal-ref": "RecSys 2019 Proceedings of the 13th ACM Conference on Recommender\n  Systems", "doi": "10.1145/3298689.3347034", "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the softmax model and its fast approximations have become\nthe de-facto loss functions for deep neural networks when dealing with\nmulti-class prediction. This loss has been extended to language modeling and\nrecommendation, two fields that fall into the framework of learning from\nPositive and Unlabeled data. In this paper, we stress the different drawbacks\nof the current family of softmax losses and sampling schemes when applied in a\nPositive and Unlabeled learning setup. We propose both a Relaxed Softmax loss\n(RS) and a new negative sampling scheme based on Boltzmann formulation. We show\nthat the new training objective is better suited for the tasks of density\nestimation, item similarity and next-event prediction by driving uplifts in\nperformance on textual and recommendation datasets against classical softmax.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:29:57 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Tanielian", "Ugo", ""], ["Vasile", "Flavian", ""]]}, {"id": "1909.08081", "submitter": "Hui Hu", "authors": "Hui Hu, Yijun Liu, Zhen Wang, Chao Lan", "title": "A Distributed Fair Machine Learning Framework with Private Demographic\n  Data Protection", "comments": "9 pages,4 figures,International Conference of Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair machine learning has become a significant research topic with broad\nsocietal impact. However, most fair learning methods require direct access to\npersonal demographic data, which is increasingly restricted to use for\nprotecting user privacy (e.g. by the EU General Data Protection Regulation). In\nthis paper, we propose a distributed fair learning framework for protecting the\nprivacy of demographic data. We assume this data is privately held by a third\nparty, which can communicate with the data center (responsible for model\ndevelopment) without revealing the demographic information. We propose a\nprincipled approach to design fair learning methods under this framework,\nexemplify four methods and show they consistently outperform their existing\ncounterparts in both fairness and accuracy across three real-world data sets.\nWe theoretically analyze the framework, and prove it can learn models with high\nfairness or high accuracy, with their trade-offs balanced by a threshold\nvariable.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:30:16 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Hu", "Hui", ""], ["Liu", "Yijun", ""], ["Wang", "Zhen", ""], ["Lan", "Chao", ""]]}, {"id": "1909.08093", "submitter": "Rozhina Ghanavi", "authors": "Rozhina Ghanavi, Maryam Sabbaghian, and Halim Yanikomeroglu", "title": "Q-Learning Based Aerial Base Station Placement for Fairness Enhancement\n  in Mobile Networks", "comments": "Accepted in IEEE GlobalSIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use an aerial base station (aerial-BS) to enhance fairness\nin a dynamic environment with user mobility. The problem of optimally placing\nthe aerial-BS is a non-deterministic polynomial-time hard (NP-hard) problem.\nMoreover, the network topology is subject to continuous changes due to the user\nmobility. These issues intensify the quest to develop an adaptive and fast\nalgorithm for 3D placement of the aerial-BS. To this end, we propose a method\nbased on reinforcement learning to achieve these goals. Simulation results show\nthat our method increases fairness among users in a reasonable computing time,\nwhile the solution is comparatively close to the optimal solution obtained by\nexhaustive search.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 18:33:15 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Ghanavi", "Rozhina", ""], ["Sabbaghian", "Maryam", ""], ["Yanikomeroglu", "Halim", ""]]}, {"id": "1909.08097", "submitter": "Umar Asif", "authors": "Umar Asif, Jianbin Tang, and Stefan Harrer", "title": "Ensemble Knowledge Distillation for Learning Improved and Efficient\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble models comprising of deep Convolutional Neural Networks (CNN) have\nshown significant improvements in model generalization but at the cost of large\ncomputation and memory requirements. In this paper, we present a framework for\nlearning compact CNN models with improved classification performance and model\ngeneralization. For this, we propose a CNN architecture of a compact student\nmodel with parallel branches which are trained using ground truth labels and\ninformation from high capacity teacher networks in an ensemble learning\nfashion. Our framework provides two main benefits: i) Distilling knowledge from\ndifferent teachers into the student network promotes heterogeneity in feature\nlearning at different branches of the student network and enables the network\nto learn diverse solutions to the target problem. ii) Coupling the branches of\nthe student network through ensembling encourages collaboration and improves\nthe quality of the final predictions by reducing variance in the network\noutputs. Experiments on the well established CIFAR-10 and CIFAR-100 datasets\nshow that our Ensemble Knowledge Distillation (EKD) improves classification\naccuracy and model generalization especially in situations with limited\ntraining data. Experiments also show that our EKD based compact networks\noutperform in terms of mean accuracy on the test datasets compared to\nstate-of-the-art knowledge distillation based methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 21:03:19 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 08:03:56 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2020 03:41:59 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Asif", "Umar", ""], ["Tang", "Jianbin", ""], ["Harrer", "Stefan", ""]]}, {"id": "1909.08105", "submitter": "Iason Sarantopoulos", "authors": "Iason Sarantopoulos, Marios Kiatos, Zoe Doulgeri, and Sotiris\n  Malassiotis", "title": "Split Deep Q-Learning for Robust Object Singulation", "comments": "Accepted for presentation in 2020 International Conference on\n  Robotics and Automation (ICRA). Video attachment:\n  https://youtu.be/ef1MKgVkN0E", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting a known target object from a pile of other objects in a cluttered\nenvironment is a challenging robotic manipulation task encountered in many\nrobotic applications. In such conditions, the target object touches or is\ncovered by adjacent obstacle objects, thus rendering traditional grasping\ntechniques ineffective. In this paper, we propose a pushing policy aiming at\nsingulating the target object from its surrounding clutter, by means of lateral\npushing movements of both the neighboring objects and the target object until\nsufficient 'grasping room' has been achieved. To achieve the above goal we\nemploy reinforcement learning and particularly Deep Q-learning (DQN) to learn\noptimal push policies by trial and error. A novel Split DQN is proposed to\nimprove the learning rate and increase the modularity of the algorithm.\nExperiments show that although learning is performed in a simulated environment\nthe transfer of learned policies to a real environment is effective thanks to\nrobust feature selection. Finally, we demonstrate that the modularity of the\nalgorithm allows the addition of extra primitives without retraining the model\nfrom scratch.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 21:14:06 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 12:57:31 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Sarantopoulos", "Iason", ""], ["Kiatos", "Marios", ""], ["Doulgeri", "Zoe", ""], ["Malassiotis", "Sotiris", ""]]}, {"id": "1909.08112", "submitter": "Nikolaos Zioulis Mr.", "authors": "Nikolaos Zioulis, Antonis Karakottas, Dimitrios Zarpalas, Federico\n  Alvarez, Petros Daras", "title": "Spherical View Synthesis for Self-Supervised 360 Depth Estimation", "comments": "3DV19, code and data at\n  https://vcl3d.github.io/SphericalViewSynthesis/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning based approaches for depth perception are limited by the\navailability of clean training data. This has led to the utilization of view\nsynthesis as an indirect objective for learning depth estimation using\nefficient data acquisition procedures. Nonetheless, most research focuses on\npinhole based monocular vision, with scarce works presenting results for\nomnidirectional input. In this work, we explore spherical view synthesis for\nlearning monocular 360 depth in a self-supervised manner and demonstrate its\nfeasibility. Under a purely geometrically derived formulation we present\nresults for horizontal and vertical baselines, as well as for the trinocular\ncase. Further, we show how to better exploit the expressiveness of traditional\nCNNs when applied to the equirectangular domain in an efficient manner.\nFinally, given the availability of ground truth depth data, our work is\nuniquely positioned to compare view synthesis against direct supervision in a\nconsistent and fair manner. The results indicate that alternative research\ndirections might be better suited to enable higher quality depth perception.\nOur data, models and code are publicly available at\nhttps://vcl3d.github.io/SphericalViewSynthesis/.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 21:25:35 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Zioulis", "Nikolaos", ""], ["Karakottas", "Antonis", ""], ["Zarpalas", "Dimitrios", ""], ["Alvarez", "Federico", ""], ["Daras", "Petros", ""]]}, {"id": "1909.08128", "submitter": "Luke Merrick", "authors": "Luke Merrick and Ankur Taly", "title": "The Explanation Game: Explaining Machine Learning Models Using Shapley\n  Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of techniques have been proposed to explain a machine learning\nmodel's prediction by attributing it to the corresponding input features.\nPopular among these are techniques that apply the Shapley value method from\ncooperative game theory. While existing papers focus on the axiomatic\nmotivation of Shapley values, and efficient techniques for computing them, they\noffer little justification for the game formulations used, and do not address\nthe uncertainty implicit in their methods' outputs. For instance, the popular\nSHAP algorithm's formulation may give substantial attributions to features that\nplay no role in the model. In this work, we illustrate how subtle differences\nin the underlying game formulations of existing methods can cause large\ndifferences in the attributions for a prediction. We then present a general\ngame formulation that unifies existing methods, and enables straightforward\nconfidence intervals on their attributions. Furthermore, it allows us to\ninterpret the attributions as contrastive explanations of an input relative to\na distribution of reference inputs. We tie this idea to classic research in\ncognitive psychology on contrastive explanations, and propose a conceptual\nframework for generating and interpreting explanations for ML models, called\nformulate, approximate, explain (FAE). We apply this framework to explain\nblack-box models trained on two UCI datasets and a Lending Club dataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 22:15:09 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 20:09:55 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 23:18:21 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Merrick", "Luke", ""], ["Taly", "Ankur", ""]]}, {"id": "1909.08130", "submitter": "Hadi Kazemi", "authors": "Hadi Kazemi, Fariborz Taherkhani, Nasser M. Nasrabadi", "title": "Identity-Aware Deep Face Hallucination via Adversarial Face Verification", "comments": "BTAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of face hallucination by proposing a\nnovel multi-scale generative adversarial network (GAN) architecture optimized\nfor face verification. First, we propose a multi-scale generator architecture\nfor face hallucination with a high up-scaling ratio factor, which has multiple\nintermediate outputs at different resolutions. The intermediate outputs have\nthe growing goal of synthesizing small to large images. Second, we incorporate\na face verifier with the original GAN discriminator and propose a novel\ndiscriminator which learns to discriminate different identities while\ndistinguishing fake generated HR face images from their ground truth images. In\nparticular, the learned generator cares for not only the visual quality of\nhallucinated face images but also preserving the discriminative features in the\nhallucination process. In addition, to capture perceptually relevant\ndifferences we employ a perceptual similarity loss, instead of similarity in\npixel space. We perform a quantitative and qualitative evaluation of our\nframework on the LFW and CelebA datasets. The experimental results show the\nadvantages of our proposed method against the state-of-the-art methods on the\n8x downsampled testing dataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 22:17:58 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Kazemi", "Hadi", ""], ["Taherkhani", "Fariborz", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "1909.08156", "submitter": "Jiaoyang Huang", "authors": "Jiaoyang Huang and Horng-Tzer Yau", "title": "Dynamics of Deep Neural Networks and Neural Tangent Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of a deep neural network trained by the gradient descent can be\ndescribed by its neural tangent kernel (NTK) as introduced in [20], where it\nwas proven that in the infinite width limit the NTK converges to an explicit\nlimiting kernel and it stays constant during training. The NTK was also\nimplicit in some other recent papers [6,13,14]. In the overparametrization\nregime, a fully-trained deep neural network is indeed equivalent to the kernel\nregression predictor using the limiting NTK. And the gradient descent achieves\nzero training loss for a deep overparameterized neural network. However, it was\nobserved in [5] that there is a performance gap between the kernel regression\nusing the limiting NTK and the deep neural networks. This performance gap is\nlikely to originate from the change of the NTK along training due to the finite\nwidth effect. The change of the NTK along the training is central to describe\nthe generalization features of deep neural networks.\n  In the current paper, we study the dynamic of the NTK for finite width deep\nfully-connected neural networks. We derive an infinite hierarchy of ordinary\ndifferential equations, the neural tangent hierarchy (NTH) which captures the\ngradient descent dynamic of the deep neural network. Moreover, under certain\nconditions on the neural network width and the data set dimension, we prove\nthat the truncated hierarchy of NTH approximates the dynamic of the NTK up to\narbitrary precision. This description makes it possible to directly study the\nchange of the NTK for deep neural networks, and sheds light on the observation\nthat deep neural networks outperform kernel regressions using the corresponding\nlimiting NTK.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 00:51:05 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Huang", "Jiaoyang", ""], ["Yau", "Horng-Tzer", ""]]}, {"id": "1909.08159", "submitter": "Brent Davis", "authors": "Brent D. Davis, Ethan Jackson, Daniel J. Lizotte", "title": "Decision-Directed Data Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm, Decision-Directed Data Decomposition (D4), which\ndecomposes a dataset into two components. The first contains most of the useful\ninformation for a specified supervised learning task. The second orthogonal\ncomponent contains little information about the task but retains associations\nand information that were not targeted. The algorithm is simple and scalable.\nWe illustrate its application in image and text processing domains. Our results\nshow that 1) post-hoc application of D4 to an image representation space can\nremove information about specified concepts without impacting other concepts,\n2) D4 is able to improve predictive generalization in certain settings, and 3)\napplying D4 to word embedding representations produces state-of-the-art results\nin debiasing.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 01:20:27 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 20:10:09 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Davis", "Brent D.", ""], ["Jackson", "Ethan", ""], ["Lizotte", "Daniel J.", ""]]}, {"id": "1909.08167", "submitter": "Minlong Peng", "authors": "Minlong Peng, Qi Zhang, Xuanjing Huang", "title": "Weighed Domain-Invariant Representation Learning for Cross-domain\n  Sentiment Analysis", "comments": "Address the problem of the domain-invariant representation learning\n  framework under target shift", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain sentiment analysis is currently a hot topic in the research and\nengineering areas. One of the most popular frameworks in this field is the\ndomain-invariant representation learning (DIRL) paradigm, which aims to learn a\ndistribution-invariant feature representation across domains. However, in this\nwork, we find out that applying DIRL may harm domain adaptation when the label\ndistribution $\\rm{P}(\\rm{Y})$ changes across domains. To address this problem,\nwe propose a modification to DIRL, obtaining a novel weighted domain-invariant\nrepresentation learning (WDIRL) framework. We show that it is easy to transfer\nexisting SOTA DIRL models to WDIRL. Empirical studies on extensive cross-domain\nsentiment analysis tasks verified our statements and showed the effectiveness\nof our proposed solution.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 02:03:03 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Peng", "Minlong", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1909.08174", "submitter": "Zhonghui You", "authors": "Zhonghui You, Kun Yan, Jinmian Ye, Meng Ma, Ping Wang", "title": "Gate Decorator: Global Filter Pruning Method for Accelerating Deep\n  Convolutional Neural Networks", "comments": "Accepted by NeurIPS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filter pruning is one of the most effective ways to accelerate and compress\nconvolutional neural networks (CNNs). In this work, we propose a global filter\npruning algorithm called Gate Decorator, which transforms a vanilla CNN module\nby multiplying its output by the channel-wise scaling factors, i.e. gate. When\nthe scaling factor is set to zero, it is equivalent to removing the\ncorresponding filter. We use Taylor expansion to estimate the change in the\nloss function caused by setting the scaling factor to zero and use the\nestimation for the global filter importance ranking. Then we prune the network\nby removing those unimportant filters. After pruning, we merge all the scaling\nfactors into its original module, so no special operations or structures are\nintroduced. Moreover, we propose an iterative pruning framework called\nTick-Tock to improve pruning accuracy. The extensive experiments demonstrate\nthe effectiveness of our approaches. For example, we achieve the\nstate-of-the-art pruning ratio on ResNet-56 by reducing 70% FLOPs without\nnoticeable loss in accuracy. For ResNet-50 on ImageNet, our pruned model with\n40% FLOPs reduction outperforms the baseline model by 0.31% in top-1 accuracy.\nVarious datasets are used, including CIFAR-10, CIFAR-100, CUB-200, ImageNet\nILSVRC-12 and PASCAL VOC 2011. Code is available at\ngithub.com/youzhonghui/gate-decorator-pruning\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 02:28:56 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["You", "Zhonghui", ""], ["Yan", "Kun", ""], ["Ye", "Jinmian", ""], ["Ma", "Meng", ""], ["Wang", "Ping", ""]]}, {"id": "1909.08180", "submitter": "Chen Chen", "authors": "Chen Chen, Jaewoo Lee", "title": "Renyi Differentially Private ADMM for Non-Smooth Regularized\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of minimizing composite objective\nfunctions consisting of a convex differentiable loss function plus a non-smooth\nregularization term, such as $L_1$ norm or nuclear norm, under R\\'enyi\ndifferential privacy (RDP). To solve the problem, we propose two stochastic\nalternating direction method of multipliers (ADMM) algorithms: ssADMM based on\ngradient perturbation and mpADMM based on output perturbation. Both algorithms\ndecompose the original problem into sub-problems that have closed-form\nsolutions. The first algorithm, ssADMM, applies the recent privacy\namplification result for RDP to reduce the amount of noise to add. The second\nalgorithm, mpADMM, numerically computes the sensitivity of ADMM variable\nupdates and releases the updated parameter vector at the end of each epoch. We\ncompare the performance of our algorithms with several baseline algorithms on\nboth real and simulated datasets. Experimental results show that, in high\nprivacy regimes (small $\\epsilon$), ssADMM and mpADMM outperform other baseline\nalgorithms in terms of classification and feature selection performance,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 02:45:12 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 23:35:42 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Chen", "Chen", ""], ["Lee", "Jaewoo", ""]]}, {"id": "1909.08181", "submitter": "Long Nguyen", "authors": "Long H. Nguyen, Zhenhe Pan, Opeyemi Openiyi, Hashim Abu-gellban, Mahdi\n  Moghadasi, Fang Jin", "title": "Self-boosted Time-series Forecasting with Multi-task and Multi-view\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust model for time series forecasting is highly important in many\ndomains, including but not limited to financial forecast, air temperature and\nelectricity consumption. To improve forecasting performance, traditional\napproaches usually require additional feature sets. However, adding more\nfeature sets from different sources of data is not always feasible due to its\naccessibility limitation. In this paper, we propose a novel self-boosted\nmechanism in which the original time series is decomposed into multiple time\nseries. These time series played the role of additional features in which the\nclosely related time series group is used to feed into multi-task learning\nmodel, and the loosely related group is fed into multi-view learning part to\nutilize its complementary information. We use three real-world datasets to\nvalidate our model and show the superiority of our proposed method over\nexisting state-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 00:16:31 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Nguyen", "Long H.", ""], ["Pan", "Zhenhe", ""], ["Openiyi", "Opeyemi", ""], ["Abu-gellban", "Hashim", ""], ["Moghadasi", "Mahdi", ""], ["Jin", "Fang", ""]]}, {"id": "1909.08182", "submitter": "Anupiya Nugaliyadde Mr", "authors": "Anupiya Nugaliyadde, Upeka Somaratne and Kok Wai Wong", "title": "Predicting Electricity Consumption using Deep Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electricity consumption has increased exponentially during the past few\ndecades. This increase is heavily burdening the electricity distributors.\nTherefore, predicting the future demand for electricity consumption will\nprovide an upper hand to the electricity distributor. Predicting electricity\nconsumption requires many parameters. The paper presents two approaches with\none using a Recurrent Neural Network (RNN) and another one using a Long Short\nTerm Memory (LSTM) network, which only considers the previous electricity\nconsumption to predict the future electricity consumption. These models were\ntested on the publicly available London smart meter dataset. To assess the\napplicability of the RNN and the LSTM network to predict electricity\nconsumption, they were tested to predict for an individual house and a block of\nhouses for a given time period. The predictions were done for daily, trimester\nand 13 months, which covers short term, mid-term and long term prediction. Both\nthe RNN and the LSTM network have achieved an average Root Mean Square error of\n0.1.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 02:49:05 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Nugaliyadde", "Anupiya", ""], ["Somaratne", "Upeka", ""], ["Wong", "Kok Wai", ""]]}, {"id": "1909.08184", "submitter": "Jindong Wang Dr.", "authors": "Chaohui Yu, Jindong Wang, Yiqiang Chen, Meiyu Huang", "title": "Transfer Learning with Dynamic Adversarial Adaptation Network", "comments": "ICDM 2019 long paper (9.08% acceptance rate); 9 pages; code available\n  at http://transferlearning.xyz", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in deep transfer learning reveal that adversarial\nlearning can be embedded into deep networks to learn more transferable features\nto reduce the distribution discrepancy between two domains. Existing\nadversarial domain adaptation methods either learn a single domain\ndiscriminator to align the global source and target distributions or pay\nattention to align subdomains based on multiple discriminators. However, in\nreal applications, the marginal (global) and conditional (local) distributions\nbetween domains are often contributing differently to the adaptation. There is\ncurrently no method to dynamically and quantitatively evaluate the relative\nimportance of these two distributions for adversarial learning. In this paper,\nwe propose a novel Dynamic Adversarial Adaptation Network (DAAN) to dynamically\nlearn domain-invariant representations while quantitatively evaluate the\nrelative importance of global and local domain distributions. To the best of\nour knowledge, DAAN is the first attempt to perform dynamic adversarial\ndistribution adaptation for deep adversarial learning. DAAN is extremely easy\nto implement and train in real applications. We theoretically analyze the\neffectiveness of DAAN, and it can also be explained in an attention strategy.\nExtensive experiments demonstrate that DAAN achieves better classification\naccuracy compared to state-of-the-art deep and adversarial methods. Results\nalso imply the necessity and effectiveness of the dynamic distribution\nadaptation in adversarial transfer learning.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 03:00:46 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Yu", "Chaohui", ""], ["Wang", "Jindong", ""], ["Chen", "Yiqiang", ""], ["Huang", "Meiyu", ""]]}, {"id": "1909.08185", "submitter": "Chandra Murthy", "authors": "Rubin Jose Peter and Chandra R. Murthy", "title": "Learned-SBL: A Deep Learning Architecture for Sparse Signal Recovery", "comments": "13 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a computationally efficient sparse signal recovery\nscheme using Deep Neural Networks (DNN). The architecture of the introduced\nneural network is inspired from sparse Bayesian learning (SBL) and named as\nLearned-SBL (L-SBL). We design a common architecture to recover sparse as well\nas block sparse vectors from single measurement vector (SMV) or multiple\nmeasurement vectors (MMV) depending on the nature of the training data. In the\nMMV model, the L-SBL network can be trained to learn any underlying sparsity\npattern among the vectors including joint sparsity, block sparsity, etc. In\nparticular, for block sparse recovery, learned-SBL does not require any prior\nknowledge of block boundaries. In each layer of the L-SBL, an estimate of the\nsignal covariance matrix is obtained as the output of a neural network. Then a\nmaximum a posteriori (MAP) estimator of the unknown sparse vector is\nimplemented with non-trainable parameters. In many applications, the\nmeasurement matrix may be time-varying. The existing DNN based sparse signal\nrecovery schemes demand the retraining of the neural network using current\nmeasurement matrix. The architecture of L-SBL allows it to accept the\nmeasurement matrix as an input to the network, and thereby avoids the need for\nretraining. We also evaluate the performance of Learned-SBL in the detection of\nan extended target using a multiple-input multiple-output (MIMO) radar.\nSimulation results illustrate that the proposed approach offers superior sparse\nrecovery performance compared to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 04:05:30 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Peter", "Rubin Jose", ""], ["Murthy", "Chandra R.", ""]]}, {"id": "1909.08187", "submitter": "Yuhong Guo", "authors": "Xinyuan Lu and Yuhong Guo", "title": "Learning to Generate Questions with Adaptive Copying Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation is an important problem in natural language\nprocessing. In this paper we propose a novel adaptive copying recurrent neural\nnetwork model to tackle the problem of question generation from sentences and\nparagraphs. The proposed model adds a copying mechanism component onto a\nbidirectional LSTM architecture to generate more suitable questions adaptively\nfrom the input data. Our experimental results show the proposed model can\noutperform the state-of-the-art question generation methods in terms of BLEU\nand ROUGE evaluation scores.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:27:45 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Lu", "Xinyuan", ""], ["Guo", "Yuhong", ""]]}, {"id": "1909.08188", "submitter": "Abdelkerim Amari", "authors": "Abdelkerim Amari, Xiang Lin, Octavia A. Dobre, Ramachandran\n  Venkatesan, Alex Alvarado", "title": "Fiber Nonlinearity Mitigation via the Parzen Window Classifier for\n  Dispersion Managed and Unmanaged Links", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": "10.1109/ICTON.2019.8840250", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have recently received significant attention as\npromising approaches to deal with the optical channel impairments, and in\nparticular, the nonlinear effects. In this work, a machine learning-based\nclassification technique, known as the Parzen window (PW) classifier, is\napplied to mitigate the nonlinear effects in the optical channel. The PW\nclassifier is used as a detector with improved nonlinear decision boundaries\nmore adapted to the nonlinear fiber channel. Performance improvement is\nobserved when applying the PW in the context of dispersion managed and\ndispersion unmanaged systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:47:05 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Amari", "Abdelkerim", ""], ["Lin", "Xiang", ""], ["Dobre", "Octavia A.", ""], ["Venkatesan", "Ramachandran", ""], ["Alvarado", "Alex", ""]]}, {"id": "1909.08189", "submitter": "Libby Hemphill", "authors": "Libby Hemphill and Angela M. Sch\\\"opke-Gonzalez", "title": "Two Computational Models for Analyzing Political Attention in Social\n  Media", "comments": "Accepted for publication in the International AAAI Conference on Web\n  and Social Media (ICWSM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how political attention is divided and over what subjects is\ncrucial for research on areas such as agenda setting, framing, and political\nrhetoric. Existing methods for measuring attention, such as manual labeling\naccording to established codebooks, are expensive and can be restrictive. We\ndescribe two computational models that automatically distinguish topics in\npoliticians' social media content. Our models---one supervised classifier and\none unsupervised topic model---provide different benefits. The supervised\nclassifier reduces the labor required to classify content according to\npre-determined topic list. However, tweets do more than communicate policy\npositions. Our unsupervised model uncovers both political topics and other\nTwitter uses (e.g., constituent service). These models are effective,\ninexpensive computational tools for political communication and social media\nresearch. We demonstrate their utility and discuss the different analyses they\nafford by applying both models to the tweets posted by members of the 115th\nU.S. Congress.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:00:14 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Hemphill", "Libby", ""], ["Sch\u00f6pke-Gonzalez", "Angela M.", ""]]}, {"id": "1909.08190", "submitter": "Yueru Chen", "authors": "Yueru Chen, C.-C. Jay Kuo", "title": "PixelHop: A Successive Subspace Learning (SSL) Method for Object\n  Classification", "comments": "17 pages, 11 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new machine learning methodology, called successive subspace learning\n(SSL), is introduced in this work. SSL contains four key ingredients: 1)\nsuccessive near-to-far neighborhood expansion; 2) unsupervised dimension\nreduction via subspace approximation; 3) supervised dimension reduction via\nlabel-assisted regression (LAG); and 4) feature concatenation and decision\nmaking. An image-based object classification method, called PixelHop, is\nproposed to illustrate the SSL design. It is shown by experimental results that\nthe PixelHop method outperforms the classic CNN model of similar model\ncomplexity in three benchmarking datasets (MNIST, Fashion MNIST and CIFAR-10).\nAlthough SSL and deep learning (DL) have some high-level concept in common,\nthey are fundamentally different in model formulation, the training process and\ntraining complexity. Extensive discussion on the comparison of SSL and DL is\nmade to provide further insights into the potential of SSL.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 15:14:19 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Chen", "Yueru", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1909.08203", "submitter": "Yuhong Guo", "authors": "Yuan Wu, Yuhong Guo", "title": "Dual Adversarial Co-Learning for Multi-Domain Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel dual adversarial co-learning approach for\nmulti-domain text classification (MDTC). The approach learns shared-private\nnetworks for feature extraction and deploys dual adversarial regularizations to\nalign features across different domains and between labeled and unlabeled data\nsimultaneously under a discrepancy based co-learning framework, aiming to\nimprove the classifiers' generalization capacity with the learned features. We\nconduct experiments on multi-domain sentiment classification datasets. The\nresults show the proposed approach achieves the state-of-the-art MDTC\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 04:15:43 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wu", "Yuan", ""], ["Guo", "Yuhong", ""]]}, {"id": "1909.08210", "submitter": "Jiangsheng You Dr.", "authors": "Jiangsheng You", "title": "Data Mapping and Finite Difference Learning", "comments": "14 pages with 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Restricted Boltzmann machine (RBM) is a two-layer neural network constructed\nas a probabilistic model and its training is to maximize a product of\nprobabilities by the contrastive divergence (CD) scheme. In this paper a data\nmapping is proposed to describe the relationship between the visible and hidden\nlayers and the training is to minimize a squared error on the visible layer by\na finite difference learning. This paper presents three new properties in using\nthe RBM: 1) nodes on the visible and hidden layers can take real-valued matrix\ndata without a probabilistic interpretation; 2) the famous CD1 is a finite\ndifference approximation of the gradient descent; 3) the activation can take\nnon-sigmoid functions such as identity, relu and softsign. The data mapping\nprovides a unified framework on the dimensionality reduction, the feature\nextraction and the data representation pioneered and developed by Hinton and\nhis colleagues. As an approximation of the gradient descent, the finite\ndifference learning is applicable to both directed and undirected graphs.\nNumerical experiments are performed to verify these new properties on the very\nlow dimensionality reduction, the collinearity of timer series data and the use\nof flexible activations.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 04:58:25 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 01:04:01 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 01:21:51 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["You", "Jiangsheng", ""]]}, {"id": "1909.08216", "submitter": "Kaige Zhang", "authors": "Kaige Zhang, Yingtao Zhang, and Heng-Da Cheng", "title": "CrackGAN: Pavement Crack Detection Using Partially Accurate Ground\n  Truths Based on Generative Adversarial Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TITS.2020.2990703", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully convolutional network is a powerful tool for per-pixel semantic\nsegmentation/detection. However, it is problematic when coping with crack\ndetection using partially accurate ground truths (GTs): the network may easily\nconverge to the status that treats all the pixels as background (BG) and still\nachieves a very good loss, named \"All Black\" phenomenon, due to the\nunavailability of accurate GTs and the data imbalance. To tackle this problem,\nwe propose crack-patch-only (CPO) supervised generative adversarial learning\nfor end-to-end training, which forces the network to always produce crack-GT\nimages while reserves both crack and BG-image translation abilities by feeding\na larger-size crack image into an asymmetric U-shape generator to overcome the\n\"All Black\" issue. The proposed approach is validated using four crack\ndatasets; and achieves state-of-the-art performance comparing with that of the\nrecently published works in efficiency and accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 05:52:08 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 16:38:28 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Zhang", "Kaige", ""], ["Zhang", "Yingtao", ""], ["Cheng", "Heng-Da", ""]]}, {"id": "1909.08249", "submitter": "EPTCS", "authors": "Ariyam Das (University of California, Los Angeles, USA), Youfu Li\n  (University of California, Los Angeles, USA), Jin Wang (University of\n  California, Los Angeles, USA), Mingda Li (University of California, Los\n  Angeles, USA), Carlo Zaniolo (University of California, Los Angeles, USA)", "title": "BigData Applications from Graph Analytics to Machine Learning by\n  Aggregates in Recursion", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646. Paper presented at the\n  35th International Conference on Logic Programming (ICLP 2019), Las Cruces,\n  New Mexico, USA, 20-25 September 2019, 7 pages (short paper - applications\n  track)", "journal-ref": "EPTCS 306, 2019, pp. 273-279", "doi": "10.4204/EPTCS.306.32", "report-no": null, "categories": "cs.LO cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past, the semantic issues raised by the non-monotonic nature of\naggregates often prevented their use in the recursive statements of logic\nprograms and deductive databases. However, the recently introduced notion of\nPre-mappability (PreM) has shown that, in key applications of interest,\naggregates can be used in recursion to optimize the perfect-model semantics of\naggregate-stratified programs. Therefore we can preserve the declarative formal\nsemantics of such programs while achieving a highly efficient operational\nsemantics that is conducive to scalable implementations on parallel and\ndistributed platforms. In this paper, we show that with PreM, a wide spectrum\nof classical algorithms of practical interest, ranging from graph analytics and\ndynamic programming based optimization problems to data mining and machine\nlearning applications can be concisely expressed in declarative languages by\nusing aggregates in recursion. Our examples are also used to show that PreM can\nbe checked using simple techniques and templatized verification strategies. A\nwide range of advanced BigData applications can now be expressed declaratively\nin logic-based languages, including Datalog, Prolog, and even SQL, while\nenabling their execution with superior performance and scalability.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:08:44 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Das", "Ariyam", "", "University of California, Los Angeles, USA"], ["Li", "Youfu", "", "University of California, Los Angeles, USA"], ["Wang", "Jin", "", "University of\n  California, Los Angeles, USA"], ["Li", "Mingda", "", "University of California, Los\n  Angeles, USA"], ["Zaniolo", "Carlo", "", "University of California, Los Angeles, USA"]]}, {"id": "1909.08255", "submitter": "EPTCS", "authors": "Abeer Dyoub (University of L'Aquila), Stefania Costantini (University\n  of L'Aquila), Francesca A. Lisi (University of Bari)", "title": "Towards Ethical Machines Via Logic Programming", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646", "journal-ref": "EPTCS 306, 2019, pp. 333-339", "doi": "10.4204/EPTCS.306.39", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous intelligent agents are playing increasingly important roles in our\nlives. They contain information about us and start to perform tasks on our\nbehalves. Chatbots are an example of such agents that need to engage in a\ncomplex conversations with humans. Thus, we need to ensure that they behave\nethically. In this work we propose a hybrid logic-based approach for ethical\nchatbots.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:10:55 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Dyoub", "Abeer", "", "University of L'Aquila"], ["Costantini", "Stefania", "", "University\n  of L'Aquila"], ["Lisi", "Francesca A.", "", "University of Bari"]]}, {"id": "1909.08288", "submitter": "Pedro Machado", "authors": "Pedro Machado, Georgina Cosma, T.M McGinnity", "title": "NatCSNN: A Convolutional Spiking Neural Network for recognition of\n  objects extracted from natural images", "comments": "12 pages", "journal-ref": "Artificial Neural Networks and Machine Learning - ICANN 2019:\n  Theoretical Neural Computation. ICANN 2019. Lecture Notes in Computer\n  Science, vol 11727", "doi": "10.1007/978-3-030-30487-4_28", "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological image processing is performed by complex neural networks composed\nof thousands of neurons interconnected via thousands of synapses, some of which\nare excitatory and others inhibitory. Spiking neural models are distinguished\nfrom classical neurons by being biological plausible and exhibiting the same\ndynamics as those observed in biological neurons. This paper proposes a Natural\nConvolutional Neural Network (NatCSNN) which is a 3-layer bio-inspired\nConvolutional Spiking Neural Network (CSNN), for classifying objects extracted\nfrom natural images. A two-stage training algorithm is proposed using\nunsupervised Spike Timing Dependent Plasticity (STDP) learning (phase 1) and\nReSuMe supervised learning (phase 2). The NatCSNN was trained and tested on the\nCIFAR-10 dataset and achieved an average testing accuracy of 84.7% which is an\nimprovement over the 2-layer neural networks previously applied to this\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 08:52:42 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Machado", "Pedro", ""], ["Cosma", "Georgina", ""], ["McGinnity", "T. M", ""]]}, {"id": "1909.08314", "submitter": "Mark Collier", "authors": "Mark Collier and Joeran Beel", "title": "Memory-Augmented Neural Networks for Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-augmented neural networks (MANNs) have been shown to outperform other\nrecurrent neural network architectures on a series of artificial sequence\nlearning tasks, yet they have had limited application to real-world tasks. We\nevaluate direct application of Neural Turing Machines (NTM) and Differentiable\nNeural Computers (DNC) to machine translation. We further propose and evaluate\ntwo models which extend the attentional encoder-decoder with capabilities\ninspired by memory augmented neural networks. We evaluate our proposed models\non IWSLT Vietnamese to English and ACL Romanian to English datasets. Our\nproposed models and the memory augmented neural networks perform similarly to\nthe attentional encoder-decoder on the Vietnamese to English translation task\nwhile have a 0.3-1.9 lower BLEU score for the Romanian to English task.\nInterestingly, our analysis shows that despite being equipped with additional\nflexibility and being randomly initialized memory augmented neural networks\nlearn an algorithm for machine translation almost identical to the attentional\nencoder-decoder.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 09:39:14 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Collier", "Mark", ""], ["Beel", "Joeran", ""]]}, {"id": "1909.08315", "submitter": "Juan Maro\\~nas", "authors": "Daniel Ramos, Juan Maro\\~nas and Alicia Lozano-Diez", "title": "Bayesian Strategies for Likelihood Ratio Computation in Forensic Voice\n  Comparison with Automatic Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper explores several strategies for Forensic Voice Comparison (FVC),\naimed at improving the performance of the LRs when using generative Gaussian\nscore-to-LR models. First, different anchoring strategies are proposed, with\nthe objective of adapting the LR computation process to the case at hand,\nalways respecting the propositions defined for the particular case. Second, a\nfully-Bayesian Gaussian model is used to tackle the sparsity in the training\nscores that is often present when the proposed anchoring strategies are used.\nExperiments are performed using the 2014 i-Vector challenge set-up, which\npresents high variability in a telephone speech context. The results show that\nthe proposed fully-Bayesian model clearly outperforms a more common\nMaximum-Likelihood approach, leading to high robustness when the scores to\ntrain the model become sparse.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 09:39:41 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Ramos", "Daniel", ""], ["Maro\u00f1as", "Juan", ""], ["Lozano-Diez", "Alicia", ""]]}, {"id": "1909.08329", "submitter": "Renjie Gu", "authors": "Renjie Gu, Shuo Yang, Fan Wu", "title": "Distributed Machine Learning on Mobile Devices: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, mobile devices have gained increasingly development with\nstronger computation capability and larger storage. Some of the\ncomputation-intensive machine learning and deep learning tasks can now be run\non mobile devices. To take advantage of the resources available on mobile\ndevices and preserve users' privacy, the idea of mobile distributed machine\nlearning is proposed. It uses local hardware resources and local data to solve\nmachine learning sub-problems on mobile devices, and only uploads computation\nresults instead of original data to contribute to the optimization of the\nglobal model. This architecture can not only relieve computation and storage\nburden on servers, but also protect the users' sensitive information. Another\nbenefit is the bandwidth reduction, as various kinds of local data can now\nparticipate in the training process without being uploaded to the server. In\nthis paper, we provide a comprehensive survey on recent studies of mobile\ndistributed machine learning. We survey a number of widely-used mobile\ndistributed machine learning methods. We also present an in-depth discussion on\nthe challenges and future directions in this area. We believe that this survey\ncan demonstrate a clear overview of mobile distributed machine learning and\nprovide guidelines on applying mobile distributed machine learning to real\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:09:02 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Gu", "Renjie", ""], ["Yang", "Shuo", ""], ["Wu", "Fan", ""]]}, {"id": "1909.08332", "submitter": "Juan Cruz Barsce", "authors": "Juan Cruz Barsce and Jorge A. Palombarini and Ernesto Mart\\'inez", "title": "A Hierarchical Two-tier Approach to Hyper-parameter Optimization in\n  Reinforcement Learning", "comments": "Short paper presented in the Jornadas Argentinas de Inform\\'atica\n  (JAIIO) 2019 (Salta, Argentina), describing an ongoing research on RL\n  hyper-parameter tuning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of hyper-parameters in reinforcement learning (RL) algorithms is\na key task, because they determine how the agent will learn its policy by\ninteracting with its environment, and thus what data is gathered. In this work,\nan approach that uses Bayesian optimization to perform a two-step optimization\nis proposed: first, categorical RL structure hyper-parameters are taken as\nbinary variables and optimized with an acquisition function tailored for such\nvariables. Then, at a lower level of abstraction, solution-level\nhyper-parameters are optimized by resorting to the expected improvement\nacquisition function, while using the best categorical hyper-parameters found\nin the optimization at the upper-level of abstraction. This two-tier approach\nis validated in a simulated control task. Results obtained are promising and\nopen the way for more user-independent applications of reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:14:47 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Barsce", "Juan Cruz", ""], ["Palombarini", "Jorge A.", ""], ["Mart\u00ednez", "Ernesto", ""]]}, {"id": "1909.08349", "submitter": "Gaurav Verma", "authors": "Gaurav Verma, Balaji Vasan Srinivasan", "title": "A Lexical, Syntactic, and Semantic Perspective for Understanding Style\n  in Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a growing interest in modeling inherent subjectivity in natural\nlanguage, we present a linguistically-motivated process to understand and\nanalyze the writing style of individuals from three perspectives: lexical,\nsyntactic, and semantic. We discuss the stylistically expressive elements\nwithin each of these levels and use existing methods to quantify the linguistic\nintuitions related to some of these elements. We show that such a multi-level\nanalysis is useful for developing a well-knit understanding of style - which is\nindependent of the natural language task at hand, and also demonstrate its\nvalue in solving three downstream tasks: authors' style analysis, authorship\nattribution, and emotion prediction. We conduct experiments on a variety of\ndatasets, comprising texts from social networking sites, user reviews, legal\ndocuments, literary books, and newswire. The results on the aforementioned\ntasks and datasets illustrate that such a multi-level understanding of style,\nwhich has been largely ignored in recent works, models style-related\nsubjectivity in text and can be leveraged to improve performance on multiple\ndownstream tasks both qualitatively and quantitatively.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:55:46 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Verma", "Gaurav", ""], ["Srinivasan", "Balaji Vasan", ""]]}, {"id": "1909.08375", "submitter": "Thodoris Lykouris", "authors": "Avrim Blum, Thodoris Lykouris", "title": "Advancing subgroup fairness via sleeping experts", "comments": "To appear in ITCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study methods for improving fairness to subgroups in settings with\noverlapping populations and sequential predictions. Classical notions of\nfairness focus on the balance of some property across different populations.\nHowever, in many applications the goal of the different groups is not to be\npredicted equally but rather to be predicted well. We demonstrate that the task\nof satisfying this guarantee for multiple overlapping groups is not\nstraightforward and show that for the simple objective of unweighted average of\nfalse negative and false positive rate, satisfying this for overlapping\npopulations can be statistically impossible even when we are provided\npredictors that perform well separately on each subgroup. On the positive side,\nwe show that when individuals are equally important to the different groups\nthey belong to, this goal is achievable; to do so, we draw a connection to the\nsleeping experts literature in online learning. Motivated by the one-sided\nfeedback in natural settings of interest, we extend our results to such a\nfeedback model. We also provide a game-theoretic interpretation of our results,\nexamining the incentives of participants to join the system and to provide the\nsystem full information about predictors they may possess. We end with several\ninteresting open problems concerning the strength of guarantees that can be\nachieved in a computationally efficient manner.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 11:51:27 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 02:29:52 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Blum", "Avrim", ""], ["Lykouris", "Thodoris", ""]]}, {"id": "1909.08381", "submitter": "Laurenz Wiskott", "authors": "Laurenz Wiskott and Fabian Sch\\\"onfeld", "title": "Laplacian Matrix for Dimensionality Reduction and Clustering", "comments": "lecture notes, 30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in machine learning can be expressed by means of a graph with\nnodes representing training samples and edges representing the relationship\nbetween samples in terms of similarity, temporal proximity, or label\ninformation. Graphs can in turn be represented by matrices. A special example\nis the Laplacian matrix, which allows us to assign each node a value that\nvaries only little between strongly connected nodes and more between distant\nnodes. Such an assignment can be used to extract a useful feature\nrepresentation, find a good embedding of data in a low dimensional space, or\nperform clustering on the original samples. In these lecture notes we first\nintroduce the Laplacian matrix and then present a small number of algorithms\ndesigned around it.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 11:59:49 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wiskott", "Laurenz", ""], ["Sch\u00f6nfeld", "Fabian", ""]]}, {"id": "1909.08386", "submitter": "Cesar A. Gomez", "authors": "Cesar A. Gomez, Xianbin Wang, and Abdallah Shami", "title": "Intelligent Active Queue Management Using Explicit Congestion\n  Notification", "comments": "To be presented at the IEEE Global Communications Conference\n  -GLOBECOM- 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more end devices are getting connected, the Internet will become more\ncongested. Various congestion control techniques have been developed either on\ntransport or network layers. Active Queue Management (AQM) is a paradigm that\naims to mitigate the congestion on the network layer through active buffer\ncontrol to avoid overflow. However, finding the right parameters for an AQM\nscheme is challenging, due to the complexity and dynamics of the networks. On\nthe other hand, the Explicit Congestion Notification (ECN) mechanism is a\nsolution that makes visible incipient congestion on the network layer to the\ntransport layer. In this work, we propose to exploit the ECN information to\nimprove AQM algorithms by applying Machine Learning techniques. Our intelligent\nmethod uses an artificial neural network to predict congestion and an AQM\nparameter tuner based on reinforcement learning. The evaluation results show\nthat our solution can enhance the performance of deployed AQM, using the\nexisting TCP congestion control mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 00:16:48 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Gomez", "Cesar A.", ""], ["Wang", "Xianbin", ""], ["Shami", "Abdallah", ""]]}, {"id": "1909.08387", "submitter": "Jan Toenshoff", "authors": "Jan Toenshoff, Martin Ritzert, Hinrikus Wolf, Martin Grohe", "title": "Graph Neural Networks for Maximum Constraint Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many combinatorial optimization problems can be phrased in the language of\nconstraint satisfaction problems. We introduce a graph neural network\narchitecture for solving such optimization problems. The architecture is\ngeneric; it works for all binary constraint satisfaction problems. Training is\nunsupervised, and it is sufficient to train on relatively small instances; the\nresulting networks perform well on much larger instances (at least 10-times\nlarger). We experimentally evaluate our approach for a variety of problems,\nincluding Maximum Cut and Maximum Independent Set. Despite being generic, we\nshow that our approach matches or surpasses most greedy and semi-definite\nprogramming based algorithms and sometimes even outperforms state-of-the-art\nheuristics for the specific problems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 12:17:20 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 15:29:48 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 20:17:24 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Toenshoff", "Jan", ""], ["Ritzert", "Martin", ""], ["Wolf", "Hinrikus", ""], ["Grohe", "Martin", ""]]}, {"id": "1909.08399", "submitter": "Vassilios Tsounis Mr.", "authors": "Vassilios Tsounis, Mitja Alge, Joonho Lee, Farbod Farshidian and Marco\n  Hutter", "title": "DeepGait: Planning and Control of Quadrupedal Gaits using Deep\n  Reinforcement Learning", "comments": "In IEEE Robotics and Automation Letters (RA-L) and IEEE International\n  Conference on Robotics and Automation (ICRA) 2020 in Paris, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of legged locomotion in non-flat terrain. As\nlegged robots such as quadrupeds are to be deployed in terrains with geometries\nwhich are difficult to model and predict, the need arises to equip them with\nthe capability to generalize well to unforeseen situations. In this work, we\npropose a novel technique for training neural-network policies for\nterrain-aware locomotion, which combines state-of-the-art methods for\nmodel-based motion planning and reinforcement learning. Our approach is\ncentered on formulating Markov decision processes using the evaluation of\ndynamic feasibility criteria in place of physical simulation. We thus employ\npolicy-gradient methods to independently train policies which respectively plan\nand execute foothold and base motions in 3D environments using both\nproprioceptive and exteroceptive measurements. We apply our method within a\nchallenging suite of simulated terrain scenarios which contain features such as\nnarrow bridges, gaps and stepping-stones, and train policies which succeed in\nlocomoting effectively in all cases.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 12:36:58 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 17:11:31 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Tsounis", "Vassilios", ""], ["Alge", "Mitja", ""], ["Lee", "Joonho", ""], ["Farshidian", "Farbod", ""], ["Hutter", "Marco", ""]]}, {"id": "1909.08402", "submitter": "Malte Ostendorff", "authors": "Malte Ostendorff, Peter Bourgonje, Maria Berger, Julian\n  Moreno-Schneider, Georg Rehm, Bela Gipp", "title": "Enriching BERT with Knowledge Graph Embeddings for Document\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we focus on the classification of books using short\ndescriptive texts (cover blurbs) and additional metadata. Building upon BERT, a\ndeep neural language model, we demonstrate how to combine text representations\nwith metadata and knowledge graph embeddings, which encode author information.\nCompared to the standard BERT approach we achieve considerably better results\nfor the classification task. For a more coarse-grained classification using\neight labels we achieve an F1- score of 87.20, while a detailed classification\nusing 343 labels yields an F1-score of 64.70. We make the source code and\ntrained models of our experiments publicly available\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 12:40:39 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Ostendorff", "Malte", ""], ["Bourgonje", "Peter", ""], ["Berger", "Maria", ""], ["Moreno-Schneider", "Julian", ""], ["Rehm", "Georg", ""], ["Gipp", "Bela", ""]]}, {"id": "1909.08410", "submitter": "William Taylor", "authors": "William Taylor", "title": "Learnability Can Be Independent of ZFC Axioms: Explanations and\n  Implications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Ben-David et al.'s \"Learnability Can Be Undecidable,\" they prove an\nindependence result in theoretical machine learning. In particular, they define\na new type of learnability, called Estimating The Maximum (EMX) learnability.\nThey argue that this type of learnability fits in with other notions such as\nPAC learnability, Vapnik's statistical learning setting, and other general\nlearning settings. However, using some set-theoretic techniques, they show that\nsome learning problems in the EMX setting are independent of ZFC. Specifically\nthey prove that ZFC cannot prove or disprove EMX learnability of the finite\nsubsets on the [0,1] interval. Moreover, the way they prove it shows that there\ncan be no characteristic dimension for EMX; and, hence, for general learning\nsettings. Here, I will explain their findings, discuss some limitations on\nthose findings, and offer some suggestions about how to excise that\nundecidability. Parts 2-3 will explain the results of the paper, part 4-5 will\ndiscuss some limitations and next steps, and I will conclude in part 6.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 23:26:17 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Taylor", "William", ""]]}, {"id": "1909.08417", "submitter": "Hongwei Lin", "authors": "Zhetong Dong, Hongwei Lin, Chi Zhou", "title": "Persistence B-Spline Grids: Stable Vector Representation of Persistence\n  Diagrams Based on Data Fitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decades, many attempts have been made to optimally integrate\nmachine learning (ML) and topological data analysis. A prominent problem in\napplying persistent homology to ML tasks is finding a vector representation of\na persistence diagram (PD), which is a summary diagram for representing\ntopological features. From the perspective of data fitting, a stable vector\nrepresentation, persistence B-spline grid (PB), is proposed based on the\nefficient technique of progressive-iterative approximation for least-squares\nB-spline surface fitting. Meanwhile, we theoretically prove that the PB method\nis stable with respect to the metrics defined on the PD space, i.e., the\n$p$-Wasserstein distance and the bottleneck distance. The proposed method was\ntested on a synthetic dataset, datasets of randomly generated PDs, data of a\ndynamical system, and 3D CAD models.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 09:09:43 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Dong", "Zhetong", ""], ["Lin", "Hongwei", ""], ["Zhou", "Chi", ""]]}, {"id": "1909.08423", "submitter": "Jan Hermann", "authors": "Jan Hermann, Zeno Sch\\\"atzle, Frank No\\'e", "title": "Deep neural network solution of the electronic Schr\\\"odinger equation", "comments": "Add notice about new results in journal-published version", "journal-ref": null, "doi": "10.1038/s41557-020-0544-y", "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  [New and updated results were published in Nature Chemistry,\ndoi:10.1038/s41557-020-0544-y.] The electronic Schr\\\"odinger equation describes\nfundamental properties of molecules and materials, but can only be solved\nanalytically for the hydrogen atom. The numerically exact full\nconfiguration-interaction method is exponentially expensive in the number of\nelectrons. Quantum Monte Carlo is a possible way out: it scales well to large\nmolecules, can be parallelized, and its accuracy has, as yet, only been limited\nby the flexibility of the used wave function ansatz. Here we propose PauliNet,\na deep-learning wave function ansatz that achieves nearly exact solutions of\nthe electronic Schr\\\"odinger equation. PauliNet has a multireference\nHartree-Fock solution built in as a baseline, incorporates the physics of valid\nwave functions, and is trained using variational quantum Monte Carlo (VMC).\nPauliNet outperforms comparable state-of-the-art VMC ansatzes for atoms,\ndiatomic molecules and a strongly-correlated hydrogen chain by a margin and is\nyet computationally efficient. We anticipate that thanks to the favourable\nscaling with system size, this method may become a new leading method for\nhighly accurate electronic-strucutre calculations on medium-sized molecular\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 21:52:50 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 17:28:50 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 16:16:49 GMT"}, {"version": "v4", "created": "Thu, 30 Jul 2020 12:00:53 GMT"}, {"version": "v5", "created": "Wed, 23 Sep 2020 22:12:25 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Hermann", "Jan", ""], ["Sch\u00e4tzle", "Zeno", ""], ["No\u00e9", "Frank", ""]]}, {"id": "1909.08444", "submitter": "Zishuo Zhao", "authors": "Zishuo Zhao, Haoyun Wang", "title": "Musical Instrument Classification via Low-Dimensional Feature Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music is a mysterious language that conveys feeling and thoughts via\ndifferent tones and timbre. For better understanding of timbre in music, we\nchose music data of 6 representative instruments, analysed their timbre\nfeatures and classified them. Instead of the current trend of Neural Network\nfor black-box classification, our project is based on a combination of MFCC and\nLPC, and augmented with a 6-dimensional feature vector designed by ourselves\nfrom observation and attempts. In our white-box model, we observed significant\npatterns of sound that distinguish different timbres, and discovered some\nconnection between objective data and subjective senses. With a totally\n32-dimensional feature vector and a naive all-pairs SVM, we achieved improved\nclassification accuracy compared to a single tool. We also attempted to analyze\nmusic pieces downloaded from the Internet, found out different performance on\ndifferent instruments, explored the reasons and suggested possible ways to\nimprove the performance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 19:54:49 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Zhao", "Zishuo", ""], ["Wang", "Haoyun", ""]]}, {"id": "1909.08471", "submitter": "Olivier Jeunen", "authors": "Olivier Jeunen, Dmytro Mykhaylov, David Rohde, Flavian Vasile,\n  Alexandre Gilotte, Martin Bompaire", "title": "Learning from Bandit Feedback: An Overview of the State-of-the-art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning we often try to optimise a decision rule that would have\nworked well over a historical dataset; this is the so called empirical risk\nminimisation principle. In the context of learning from recommender system\nlogs, applying this principle becomes a problem because we do not have\navailable the reward of decisions we did not do. In order to handle this\n\"bandit-feedback\" setting, several Counterfactual Risk Minimisation (CRM)\nmethods have been proposed in recent years, that attempt to estimate the\nperformance of different policies on historical data. Through importance\nsampling and various variance reduction techniques, these methods allow more\nrobust learning and inference than classical approaches. It is difficult to\naccurately estimate the performance of policies that frequently perform actions\nthat were infrequently done in the past and a number of different types of\nestimators have been proposed.\n  In this paper, we review several methods, based on different off-policy\nestimators, for learning from bandit feedback. We discuss key differences and\ncommonalities among existing approaches, and compare their empirical\nperformance on the RecoGym simulation environment. To the best of our\nknowledge, this work is the first comparison study for bandit algorithms in a\nrecommender system setting.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 14:26:28 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Jeunen", "Olivier", ""], ["Mykhaylov", "Dmytro", ""], ["Rohde", "David", ""], ["Vasile", "Flavian", ""], ["Gilotte", "Alexandre", ""], ["Bompaire", "Martin", ""]]}, {"id": "1909.08478", "submitter": "Ankur Bapna", "authors": "Ankur Bapna, Naveen Arivazhagan, Orhan Firat", "title": "Simple, Scalable Adaptation for Neural Machine Translation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning pre-trained Neural Machine Translation (NMT) models is the\ndominant approach for adapting to new languages and domains. However,\nfine-tuning requires adapting and maintaining a separate model for each target\ntask. We propose a simple yet efficient approach for adaptation in NMT. Our\nproposed approach consists of injecting tiny task specific adapter layers into\na pre-trained model. These lightweight adapters, with just a small fraction of\nthe original model size, adapt the model to multiple individual tasks\nsimultaneously. We evaluate our approach on two tasks: (i) Domain Adaptation\nand (ii) Massively Multilingual NMT. Experiments on domain adaptation\ndemonstrate that our proposed approach is on par with full fine-tuning on\nvarious domains, dataset sizes and model capacities. On a massively\nmultilingual dataset of 103 languages, our adaptation approach bridges the gap\nbetween individual bilingual models and one massively multilingual model for\nmost language pairs, paving the way towards universal machine translation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 14:38:34 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Bapna", "Ankur", ""], ["Arivazhagan", "Naveen", ""], ["Firat", "Orhan", ""]]}, {"id": "1909.08491", "submitter": "William Havard", "authors": "William N. Havard, Jean-Pierre Chevrot, Laurent Besacier", "title": "Word Recognition, Competition, and Activation in a Model of Visually\n  Grounded Speech", "comments": "Accepted at CoNLL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study how word-like units are represented and activated in\na recurrent neural model of visually grounded speech. The model used in our\nexperiments is trained to project an image and its spoken description in a\ncommon representation space. We show that a recurrent model trained on spoken\nsentences implicitly segments its input into word-like units and reliably maps\nthem to their correct visual referents. We introduce a methodology originating\nfrom linguistics to analyse the representation learned by neural networks --\nthe gating paradigm -- and show that the correct representation of a word is\nonly activated if the network has access to first phoneme of the target word,\nsuggesting that the network does not rely on a global acoustic pattern.\nFurthermore, we find out that not all speech frames (MFCC vectors in our case)\nplay an equal role in the final encoded representation of a given word, but\nthat some frames have a crucial effect on it. Finally, we suggest that word\nrepresentation could be activated through a process of lexical competition.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 15:00:56 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Havard", "William N.", ""], ["Chevrot", "Jean-Pierre", ""], ["Besacier", "Laurent", ""]]}, {"id": "1909.08494", "submitter": "Jonathan Le Roux", "authors": "Ethan Manilow, Gordon Wichern, Prem Seetharaman, Jonathan Le Roux", "title": "Cutting Music Source Separation Some Slakh: A Dataset to Study the\n  Impact of Training Data Quality and Quantity", "comments": "Accepted for publication at WASPAA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music source separation performance has greatly improved in recent years with\nthe advent of approaches based on deep learning. Such methods typically require\nlarge amounts of labelled training data, which in the case of music consist of\nmixtures and corresponding instrument stems. However, stems are unavailable for\nmost commercial music, and only limited datasets have so far been released to\nthe public. It can thus be difficult to draw conclusions when comparing various\nsource separation methods, as the difference in performance may stem as much\nfrom better data augmentation techniques or training tricks to alleviate the\nlimited availability of training data, as from intrinsically better model\narchitectures and objective functions. In this paper, we present the\nsynthesized Lakh dataset (Slakh) as a new tool for music source separation\nresearch. Slakh consists of high-quality renderings of instrumental mixtures\nand corresponding stems generated from the Lakh MIDI dataset (LMD) using\nprofessional-grade sample-based virtual instruments. A first version,\nSlakh2100, focuses on 2100 songs, resulting in 145 hours of mixtures. While not\nfully comparable because it is purely instrumental, this dataset contains an\norder of magnitude more data than MUSDB18, the {\\it de facto} standard dataset\nin the field. We show that Slakh can be used to effectively augment existing\ndatasets for musical instrument separation, while opening the door to a wide\narray of data-intensive music signal analysis tasks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 15:14:27 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Manilow", "Ethan", ""], ["Wichern", "Gordon", ""], ["Seetharaman", "Prem", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "1909.08496", "submitter": "Huanrui Yang", "authors": "Jingyang Zhang, Huanrui Yang, Fan Chen, Yitu Wang, Hai Li", "title": "Exploring Bit-Slice Sparsity in Deep Neural Networks for Efficient\n  ReRAM-Based Deployment", "comments": "To be appeared in the 5th Workshop on Energy Efficient Machine\n  Learning and Cognitive Computing (EMC2) co-located with NeurIPS 2019,\n  Vancouver, Canada. (Oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging resistive random-access memory (ReRAM) has recently been intensively\ninvestigated to accelerate the processing of deep neural networks (DNNs). Due\nto the in-situ computation capability, analog ReRAM crossbars yield significant\nthroughput improvement and energy reduction compared to traditional digital\nmethods. However, the power hungry analog-to-digital converters (ADCs) prevent\nthe practical deployment of ReRAM-based DNN accelerators on end devices with\nlimited chip area and power budget. We observe that due to the limited\nbit-density of ReRAM cells, DNN weights are bit sliced and correspondingly\nstored on multiple ReRAM bitlines. The accumulated current on bitlines resulted\nby weights directly dictates the overhead of ADCs. As such, bitwise weight\nsparsity rather than the sparsity of the full weight, is desirable for\nefficient ReRAM deployment. In this work, we propose bit-slice L1, the first\nalgorithm to induce bit-slice sparsity during the training of dynamic\nfixed-point DNNs. Experiment results show that our approach achieves 2x\nsparsity improvement compared to previous algorithms. The resulting sparsity\nallows the ADC resolution to be reduced to 1-bit of the most significant\nbit-slice and down to 3-bit for the others bits, which significantly speeds up\nprocessing and reduces power and area overhead.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 15:19:22 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 19:04:27 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhang", "Jingyang", ""], ["Yang", "Huanrui", ""], ["Chen", "Fan", ""], ["Wang", "Yitu", ""], ["Li", "Hai", ""]]}, {"id": "1909.08518", "submitter": "Ashesh Rambachan", "authors": "Ashesh Rambachan and Jonathan Roth", "title": "Bias In, Bias Out? Evaluating the Folk Wisdom", "comments": null, "journal-ref": "1st Symposium on Foundations of Responsible Computing (FORC 2020)", "doi": "10.4230/LIPIcs.FORC.2020.6", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the folk wisdom that algorithmic decision rules trained on data\nproduced by biased human decision-makers necessarily reflect this bias. We\nconsider a setting where training labels are only generated if a biased\ndecision-maker takes a particular action, and so \"biased\" training data arise\ndue to discriminatory selection into the training data. In our baseline model,\nthe more biased the decision-maker is against a group, the more the algorithmic\ndecision rule favors that group. We refer to this phenomenon as \"bias\nreversal.\" We then clarify the conditions that give rise to bias reversal.\nWhether a prediction algorithm reverses or inherits bias depends critically on\nhow the decision-maker affects the training data as well as the label used in\ntraining. We illustrate our main theoretical results in a simulation study\napplied to the New York City Stop, Question and Frisk dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 15:50:19 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 02:45:01 GMT"}, {"version": "v3", "created": "Sat, 19 Dec 2020 19:19:02 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Rambachan", "Ashesh", ""], ["Roth", "Jonathan", ""]]}, {"id": "1909.08525", "submitter": "Guan Wang", "authors": "Guan Wang, Charlie Xiaoqian Dang, Ziye Zhou", "title": "Measure Contribution of Participants in Federated Learning", "comments": "arXiv admin note: text overlap with arXiv:1905.04519", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Machine Learning (FML) creates an ecosystem for multiple parties to\ncollaborate on building models while protecting data privacy for the\nparticipants. A measure of the contribution for each party in FML enables fair\ncredits allocation. In this paper we develop simple but powerful techniques to\nfairly calculate the contributions of multiple parties in FML, in the context\nof both horizontal FML and vertical FML. For Horizontal FML we use deletion\nmethod to calculate the grouped instance influence. For Vertical FML we use\nShapley Values to calculate the grouped feature importance. Our methods open\nthe door for research in model contribution and credit allocation in the\ncontext of federated machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 06:13:04 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wang", "Guan", ""], ["Dang", "Charlie Xiaoqian", ""], ["Zhou", "Ziye", ""]]}, {"id": "1909.08526", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia and Neil Zhenqiang Gong", "title": "Defending against Machine Learning based Inference Attacks via\n  Adversarial Examples: Opportunities and Challenges", "comments": "Book chapter. arXiv admin note: substantial text overlap with\n  arXiv:1805.04810", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) becomes more and more powerful and easily\naccessible, attackers increasingly leverage ML to perform automated large-scale\ninference attacks in various domains. In such an ML-equipped inference attack,\nan attacker has access to some data (called public data) of an individual, a\nsoftware, or a system; and the attacker uses an ML classifier to automatically\ninfer their private data. Inference attacks pose severe privacy and security\nthreats to individuals and systems. Inference attacks are successful because\nprivate data are statistically correlated with public data, and ML classifiers\ncan capture such statistical correlations. In this chapter, we discuss the\nopportunities and challenges of defending against ML-equipped inference attacks\nvia adversarial examples. Our key observation is that attackers rely on ML\nclassifiers in inference attacks. The adversarial machine learning community\nhas demonstrated that ML classifiers have various vulnerabilities. Therefore,\nwe can turn the vulnerabilities of ML into defenses against inference attacks.\nFor example, ML classifiers are vulnerable to adversarial examples, which add\ncarefully crafted noise to normal examples such that an ML classifier makes\npredictions for the examples as we desire. To defend against inference attacks,\nwe can add carefully crafted noise into the public data to turn them into\nadversarial examples, such that attackers' classifiers make incorrect\npredictions for the private data. However, existing methods to construct\nadversarial examples are insufficient because they did not consider the unique\nchallenges and requirements for the crafted noise at defending against\ninference attacks. In this chapter, we take defending against inference attacks\nin online social networks as an example to illustrate the opportunities and\nchallenges.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:34:06 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 02:26:14 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1909.08528", "submitter": "Peyman Hosseinzadeh Kassani", "authors": "Sara Hosseinzadeh Kassani, Farhood Rismanchian, Peyman Hosseinzadeh\n  Kassani", "title": "k-Relevance Vectors: Considering Relevancy Beside Nearness", "comments": "Will be submitted to Applied Soft Computing Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study combines two different learning paradigms, k-nearest neighbor\n(k-NN) rule, as memory-based learning paradigm and relevance vector machines\n(RVM), as statistical learning paradigm. This combination is performed in\nkernel space and is called k-relevance vector (k-RV). The purpose is to improve\nthe performance of k-NN rule. The proposed model significantly prunes\nirrelevant attributes. We also introduced a new parameter, responsible for\nearly stopping of iterations in RVM. We show that the new parameter improves\nthe classification accuracy of k-RV. Intensive experiments are conducted on\nseveral classification datasets from University of California Irvine (UCI)\nrepository and two real datasets from computer vision domain. The performance\nof k-RV is highly competitive compared to a few state-of-the-arts in terms of\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 16:03:35 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 21:34:57 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kassani", "Sara Hosseinzadeh", ""], ["Rismanchian", "Farhood", ""], ["Kassani", "Peyman Hosseinzadeh", ""]]}, {"id": "1909.08531", "submitter": "Jindong Wang", "authors": "Jindong Wang, Yiqiang Chen, Wenjie Feng, Han Yu, Meiyu Huang, Qiang\n  Yang", "title": "Transfer Learning with Dynamic Distribution Adaptation", "comments": "Accepted to ACM Transactions on Intelligent Systems and Technology\n  (ACM TIST) 2019, 25 pages. arXiv admin note: text overlap with\n  arXiv:1807.07258", "journal-ref": "ACM Transactions on Intelligent Systems and Technology (ACM TIST)\n  2019", "doi": "10.1145/3360309", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning aims to learn robust classifiers for the target domain by\nleveraging knowledge from a source domain. Since the source and the target\ndomains are usually from different distributions, existing methods mainly focus\non adapting the cross-domain marginal or conditional distributions. However, in\nreal applications, the marginal and conditional distributions usually have\ndifferent contributions to the domain discrepancy. Existing methods fail to\nquantitatively evaluate the different importance of these two distributions,\nwhich will result in unsatisfactory transfer performance. In this paper, we\npropose a novel concept called Dynamic Distribution Adaptation (DDA), which is\ncapable of quantitatively evaluating the relative importance of each\ndistribution. DDA can be easily incorporated into the framework of structural\nrisk minimization to solve transfer learning problems. On the basis of DDA, we\npropose two novel learning algorithms: (1) Manifold Dynamic Distribution\nAdaptation (MDDA) for traditional transfer learning, and (2) Dynamic\nDistribution Adaptation Network (DDAN) for deep transfer learning. Extensive\nexperiments demonstrate that MDDA and DDAN significantly improve the transfer\nlearning performance and setup a strong baseline over the latest deep and\nadversarial methods on digits recognition, sentiment analysis, and image\nclassification. More importantly, it is shown that marginal and conditional\ndistributions have different contributions to the domain divergence, and our\nDDA is able to provide good quantitative evaluation of their relative\nimportance which leads to better performance. We believe this observation can\nbe helpful for future research in transfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 02:59:22 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Wang", "Jindong", ""], ["Chen", "Yiqiang", ""], ["Feng", "Wenjie", ""], ["Yu", "Han", ""], ["Huang", "Meiyu", ""], ["Yang", "Qiang", ""]]}, {"id": "1909.08540", "submitter": "Pier Giuseppe Sessa", "authors": "Pier Giuseppe Sessa, Ilija Bogunovic, Maryam Kamgarpour, Andreas\n  Krause", "title": "No-Regret Learning in Unknown Games with Correlated Payoffs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning to play a repeated multi-agent game with\nan unknown reward function. Single player online learning algorithms attain\nstrong regret bounds when provided with full information feedback, which\nunfortunately is unavailable in many real-world scenarios. Bandit feedback\nalone, i.e., observing outcomes only for the selected action, yields\nsubstantially worse performance. In this paper, we consider a natural model\nwhere, besides a noisy measurement of the obtained reward, the player can also\nobserve the opponents' actions. This feedback model, together with a regularity\nassumption on the reward function, allows us to exploit the correlations among\ndifferent game outcomes by means of Gaussian processes (GPs). We propose a\nnovel confidence-bound based bandit algorithm GP-MW, which utilizes the GP\nmodel for the reward function and runs a multiplicative weight (MW) method. We\nobtain novel kernel-dependent regret bounds that are comparable to the known\nbounds in the full information setting, while substantially improving upon the\nexisting bandit results. We experimentally demonstrate the effectiveness of\nGP-MW in random matrix games, as well as real-world problems of traffic routing\nand movie recommendation. In our experiments, GP-MW consistently outperforms\nseveral baselines, while its performance is often comparable to methods that\nhave access to full information feedback.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 16:09:09 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 09:08:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Sessa", "Pier Giuseppe", ""], ["Bogunovic", "Ilija", ""], ["Kamgarpour", "Maryam", ""], ["Krause", "Andreas", ""]]}, {"id": "1909.08544", "submitter": "Leo Liberti", "authors": "Leo Liberti", "title": "Distance Geometry and Data Science", "comments": "This invited survey will appear in the journal TOP\n  <https://link.springer.com/journal/11750>, in 2020 issue 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data are often represented as graphs. Many common tasks in data science are\nbased on distances between entities. While some data science methodologies\nnatively take graphs as their input, there are many more that take their input\nin vectorial form. In this survey we discuss the fundamental problem of mapping\ngraphs to vectors, and its relation with mathematical programming. We discuss\napplications, solution methods, dimensional reduction techniques and some of\ntheir limits. We then present an application of some of these ideas to neural\nnetworks, showing that distance geometry techniques can give competitive\nperformance with respect to more traditional graph-to-vector mappings.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 16:11:33 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Liberti", "Leo", ""]]}, {"id": "1909.08573", "submitter": "Stefan Wolff", "authors": "Stefan Wolff, Fearghal O'Donncha, Bei Chen", "title": "Statistical and machine learning ensemble modelling to forecast sea\n  surface temperature", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmarsys.2020.103347", "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In situ and remotely sensed observations have potential to facilitate\ndata-driven predictive models for oceanography. A suite of machine learning\nmodels, including regression, decision tree and deep learning approaches were\ndeveloped to estimate sea surface temperatures (SST). Training data consisted\nof satellite-derived SST and atmospheric data from The Weather Company. Models\nwere evaluated in terms of accuracy and computational complexity. Predictive\nskill were assessed against observations and a state-of-the-art, physics-based\nmodel from the European Centre for Medium Weather Forecasting. Results\ndemonstrated that by combining automated feature engineering with\nmachine-learning approaches, accuracy comparable to existing state-of-the-art\ncan be achieved. Models captured seasonal patterns in the data and\nqualitatively reproduce short-term variations driven by atmospheric forcing.\nFurther, it demonstrated that machine-learning-based approaches can be used as\ntransportable prediction tools for ocean variables -- the data-driven nature of\nthe approach naturally integrates with automatic deployment frameworks, where\nmodel deployments are guided by data rather than user-parametrisation and\nexpertise. The low computational cost of inference makes the approach\nparticularly attractive for edge-based computing where predictive models could\nbe deployed on low-power devices in the marine environment.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:03:30 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 19:30:21 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Wolff", "Stefan", ""], ["O'Donncha", "Fearghal", ""], ["Chen", "Bei", ""]]}, {"id": "1909.08574", "submitter": "Kadierdan Kaheman", "authors": "Kadierdan Kaheman, Eurika Kaiser, Benjamin Strom, J. Nathan Kutz,\n  Steven L. Brunton", "title": "Learning Discrepancy Models From Experimental Data", "comments": "8 pages, 5 figures, accepted by Conference on Decision and Control\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First principles modeling of physical systems has led to significant\ntechnological advances across all branches of science. For nonlinear systems,\nhowever, small modeling errors can lead to significant deviations from the\ntrue, measured behavior. Even in mechanical systems, where the equations are\nassumed to be well-known, there are often model discrepancies corresponding to\nnonlinear friction, wind resistance, etc. Discovering models for these\ndiscrepancies remains an open challenge for many complex systems. In this work,\nwe use the sparse identification of nonlinear dynamics (SINDy) algorithm to\ndiscover a model for the discrepancy between a simplified model and measurement\ndata. In particular, we assume that the model mismatch can be sparsely\nrepresented in a library of candidate model terms. We demonstrate the efficacy\nof our approach on several examples including experimental data from a double\npendulum on a cart. We further design and implement a feed-forward controller\nin simulations, showing improvement with a discrepancy model.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:04:03 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Kaheman", "Kadierdan", ""], ["Kaiser", "Eurika", ""], ["Strom", "Benjamin", ""], ["Kutz", "J. Nathan", ""], ["Brunton", "Steven L.", ""]]}, {"id": "1909.08593", "submitter": "Daniel M. Ziegler", "authors": "Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec\n  Radford, Dario Amodei, Paul Christiano, Geoffrey Irving", "title": "Fine-Tuning Language Models from Human Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward learning enables the application of reinforcement learning (RL) to\ntasks where reward is defined by human judgment, building a model of reward by\nasking humans questions. Most work on reward learning has used simulated\nenvironments, but complex information about values is often expressed in\nnatural language, and we believe reward learning for language is a key to\nmaking RL practical and safe for real-world tasks. In this paper, we build on\nadvances in generative pretraining of language models to apply reward learning\nto four natural language tasks: continuing text with positive sentiment or\nphysically descriptive language, and summarization tasks on the TL;DR and\nCNN/Daily Mail datasets. For stylistic continuation we achieve good results\nwith only 5,000 comparisons evaluated by humans. For summarization, models\ntrained with 60,000 comparisons copy whole sentences from the input but skip\nirrelevant preamble; this leads to reasonable ROUGE scores and very good\nperformance according to our human labelers, but may be exploiting the fact\nthat labelers rely on simple heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:33:39 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 23:02:36 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ziegler", "Daniel M.", ""], ["Stiennon", "Nisan", ""], ["Wu", "Jeffrey", ""], ["Brown", "Tom B.", ""], ["Radford", "Alec", ""], ["Amodei", "Dario", ""], ["Christiano", "Paul", ""], ["Irving", "Geoffrey", ""]]}, {"id": "1909.08602", "submitter": "Girish Joshi", "authors": "Girish Joshi, Girish Chowdhary", "title": "Deep Model Reference Adaptive Control", "comments": "Accepted in IEEE CDC-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new neuroadaptive architecture: Deep Neural Network based Model\nReference Adaptive Control (DMRAC). Our architecture utilizes the power of deep\nneural network representations for modeling significant nonlinearities while\nmarrying it with the boundedness guarantees that characterize MRAC based\ncontrollers. We demonstrate through simulations and analysis that DMRAC can\nsubsume previously studied learning based MRAC methods, such as concurrent\nlearning and GP-MRAC. This makes DMRAC a highly powerful architecture for\nhigh-performance control of nonlinear systems with long-term learning\nproperties.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:45:22 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Joshi", "Girish", ""], ["Chowdhary", "Girish", ""]]}, {"id": "1909.08604", "submitter": "Oleh Lukianykhin", "authors": "Oleh Lukianykhin, Tetiana Bogodorova", "title": "ModelicaGym: Applying Reinforcement Learning to Modelica Models", "comments": "accepted at EOOLT'19", "journal-ref": null, "doi": "10.1145/3365984.3365985", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents ModelicaGym toolbox that was developed to employ\nReinforcement Learning (RL) for solving optimization and control tasks in\nModelica models. The developed tool allows connecting models using Functional\nMock-up Interface (FMI) toOpenAI Gym toolkit in order to exploit Modelica\nequation-based modelling and co-simulation together with RL algorithms as a\nfunctionality of the tools correspondingly. Thus, ModelicaGym facilitates fast\nand convenient development of RL algorithms and their comparison when solving\noptimal control problem for Modelicadynamic models. Inheritance structure\nofModelicaGymtoolbox's classes and the implemented methods are discussed in\ndetails. The toolbox functionality validation is performed on Cart-Pole\nbalancing problem. This includes physical system model description and its\nintegration using the toolbox, experiments on selection and influence of the\nmodel parameters (i.e. force magnitude, Cart-pole mass ratio, reward ratio, and\nsimulation time step) on the learning process of Q-learning algorithm supported\nwith the discussion of the simulation results.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:48:12 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Lukianykhin", "Oleh", ""], ["Bogodorova", "Tetiana", ""]]}, {"id": "1909.08606", "submitter": "Tejo Chalasani", "authors": "Tejo Chalasani and Aljosa Smolic", "title": "Simultaneous Segmentation and Recognition: Towards more accurate Ego\n  Gesture Recognition", "comments": "Accepted at ICCV Workshop for Egocentric Perception, Interaction and\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ego hand gestures can be used as an interface in AR and VR environments.\nWhile the context of an image is important for tasks like scene understanding,\nobject recognition, image caption generation and activity recognition, it plays\na minimal role in ego hand gesture recognition. An ego hand gesture used for AR\nand VR environments conveys the same information regardless of the background.\nWith this idea in mind, we present our work on ego hand gesture recognition\nthat produces embeddings from RBG images with ego hands, which are\nsimultaneously used for ego hand segmentation and ego gesture recognition. To\nthis extent, we achieved better recognition accuracy (96.9%) compared to the\nstate of the art (92.2%) on the biggest ego hand gesture dataset available\npublicly. We present a gesture recognition deep neural network which recognises\nego hand gestures from videos (videos containing a single gesture) by\ngenerating and recognising embeddings of ego hands from image sequences of\nvarying length. We introduce the concept of simultaneous segmentation and\nrecognition applied to ego hand gestures, present the network architecture, the\ntraining procedure and the results compared to the state of the art on the\nEgoGesture dataset\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:52:16 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Chalasani", "Tejo", ""], ["Smolic", "Aljosa", ""]]}, {"id": "1909.08610", "submitter": "Quanquan Gu", "authors": "Pan Xu and Felicia Gao and Quanquan Gu", "title": "Sample Efficient Policy Gradient Methods with Recursive Variance\n  Reduction", "comments": "22 pages, 2 figures, 3 tables. In ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the sample efficiency in reinforcement learning has been a\nlong-standing research problem. In this work, we aim to reduce the sample\ncomplexity of existing policy gradient methods. We propose a novel policy\ngradient algorithm called SRVR-PG, which only requires $O(1/\\epsilon^{3/2})$\nepisodes to find an $\\epsilon$-approximate stationary point of the nonconcave\nperformance function $J(\\boldsymbol{\\theta})$ (i.e., $\\boldsymbol{\\theta}$ such\nthat $\\|\\nabla J(\\boldsymbol{\\theta})\\|_2^2\\leq\\epsilon$). This sample\ncomplexity improves the existing result $O(1/\\epsilon^{5/3})$ for stochastic\nvariance reduced policy gradient algorithms by a factor of\n$O(1/\\epsilon^{1/6})$. In addition, we also propose a variant of SRVR-PG with\nparameter exploration, which explores the initial policy parameter from a prior\nprobability distribution. We conduct numerical experiments on classic control\nproblems in reinforcement learning to validate the performance of our proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:58:48 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 21:42:14 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Xu", "Pan", ""], ["Gao", "Felicia", ""], ["Gu", "Quanquan", ""]]}, {"id": "1909.08611", "submitter": "Alexandros Stergiou MSc", "authors": "Alexandros Stergiou, Georgios Kapidis, Grigorios Kalliatakis, Christos\n  Chrysoulas, Ronald Poppe, Remco Veltkamp", "title": "Class Feature Pyramids for Video Explanation", "comments": null, "journal-ref": null, "doi": "10.1109/ICCVW.2019.00524", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional networks are widely used in video action recognition. 3D\nconvolutions are one prominent approach to deal with the additional time\ndimension. While 3D convolutions typically lead to higher accuracies, the inner\nworkings of the trained models are more difficult to interpret. We focus on\ncreating human-understandable visual explanations that represent the\nhierarchical parts of spatio-temporal networks. We introduce Class Feature\nPyramids, a method that traverses the entire network structure and\nincrementally discovers kernels at different network depths that are\ninformative for a specific class. Our method does not depend on the network's\narchitecture or the type of 3D convolutions, supporting grouped and depth-wise\nconvolutions, convolutions in fibers, and convolutions in branches. We\ndemonstrate the method on six state-of-the-art 3D convolution neural networks\n(CNNs) on three action recognition (Kinetics-400, UCF-101, and HMDB-51) and two\negocentric action recognition datasets (EPIC-Kitchens and EGTEA Gaze+).\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:10:32 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Stergiou", "Alexandros", ""], ["Kapidis", "Georgios", ""], ["Kalliatakis", "Grigorios", ""], ["Chrysoulas", "Christos", ""], ["Poppe", "Ronald", ""], ["Veltkamp", "Remco", ""]]}, {"id": "1909.08612", "submitter": "Arnaud Belletoile PhD", "authors": "Arnaud Bell\\'etoile (for the Cdiscount datascience team)", "title": "Large e-retailer image dataset for visual search and product\n  classification", "comments": "5 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results of deep convolutional networks in visual recognition\nchallenges open the path to a whole new set of disruptive user experiences such\nas visual search or recommendation. The list of companies offering this type of\nservice is growing everyday but the adoption rate and the relevancy of results\nmay vary a lot. We believe that the availability of large and diverse datasets\nis a necessary condition to improve the relevancy of such recommendation\nsystems and facilitate their adoption. For that purpose, we wish to share with\nthe community this dataset of more than 12M images of the 7M products of our\nonline store classified into 5K categories. This original dataset is introduced\nin this article and several features are described. We also present some\naspects of the winning solutions of our image classification challenge that was\norganized on the Kaggle platform around this set of images.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 09:21:53 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Bell\u00e9toile", "Arnaud", "", "for the Cdiscount datascience team"]]}, {"id": "1909.08663", "submitter": "Matthew A. Kelly", "authors": "Wang Jing (Beijing Normal University), M. A. Kelly (The Pennsylvania\n  State University), David Reitter (Google Research)", "title": "Do We Need Neural Models to Explain Human Judgments of Acceptability?", "comments": "10 pages (8 pages + 2 pages of references), 1 figure, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Native speakers can judge whether a sentence is an acceptable instance of\ntheir language. Acceptability provides a means of evaluating whether\ncomputational language models are processing language in a human-like manner.\nWe test the ability of computational language models, simple language features,\nand word embeddings to predict native English speakers judgments of\nacceptability on English-language essays written by non-native speakers. We\nfind that much of the sentence acceptability variance can be captured by a\ncombination of features including misspellings, word order, and word similarity\n(Pearson's r = 0.494). While predictive neural models fit acceptability\njudgments well (r = 0.527), we find that a 4-gram model with statistical\nsmoothing is just as good (r = 0.528). Thanks to incorporating a count of\nmisspellings, our 4-gram model surpasses both the previous unsupervised\nstate-of-the art (Lau et al., 2015; r = 0.472), and the average non-expert\nnative speaker (r = 0.46). Our results demonstrate that acceptability is well\ncaptured by n-gram statistics and simple language features.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 19:02:53 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 19:30:15 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Jing", "Wang", "", "Beijing Normal University"], ["Kelly", "M. A.", "", "The Pennsylvania\n  State University"], ["Reitter", "David", "", "Google Research"]]}, {"id": "1909.08700", "submitter": "No\\'emien Kocher", "authors": "No\\'emien Kocher, Christian Scuito, Lorenzo Tarantino, Alexandros\n  Lazaridis, Andreas Fischer and Claudiu Musat", "title": "Alleviating Sequence Information Loss with Data Overlapping and Prime\n  Batch Sizes", "comments": null, "journal-ref": "Proceedings of the 23rd Conference on Computational Natural\n  Language Learning (CoNLL), Hong Kong, China, 2019, p. 890-899", "doi": "10.18653/v1/K19-1083", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In sequence modeling tasks the token order matters, but this information can\nbe partially lost due to the discretization of the sequence into data points.\nIn this paper, we study the imbalance between the way certain token pairs are\nincluded in data points and others are not. We denote this a token order\nimbalance (TOI) and we link the partial sequence information loss to a\ndiminished performance of the system as a whole, both in text and speech\nprocessing tasks. We then provide a mechanism to leverage the full token order\ninformation -Alleviated TOI- by iteratively overlapping the token composition\nof data points. For recurrent networks, we use prime numbers for the batch size\nto avoid redundancies when building batches from overlapped data points. The\nproposed method achieved state of the art performance in both text and speech\nrelated tasks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 20:50:51 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kocher", "No\u00e9mien", ""], ["Scuito", "Christian", ""], ["Tarantino", "Lorenzo", ""], ["Lazaridis", "Alexandros", ""], ["Fischer", "Andreas", ""], ["Musat", "Claudiu", ""]]}, {"id": "1909.08705", "submitter": "Arshit Gupta", "authors": "Arshit Gupta, Peng Zhang, Garima Lalwani and Mona Diab", "title": "CASA-NLU: Context-Aware Self-Attentive Natural Language Understanding\n  for Task-Oriented Chatbots", "comments": "To appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Understanding (NLU) is a core component of dialog systems.\nIt typically involves two tasks - intent classification (IC) and slot labeling\n(SL), which are then followed by a dialogue management (DM) component. Such NLU\nsystems cater to utterances in isolation, thus pushing the problem of context\nmanagement to DM. However, contextual information is critical to the correct\nprediction of intents and slots in a conversation. Prior work on contextual NLU\nhas been limited in terms of the types of contextual signals used and the\nunderstanding of their impact on the model. In this work, we propose a\ncontext-aware self-attentive NLU (CASA-NLU) model that uses multiple signals,\nsuch as previous intents, slots, dialog acts and utterances over a variable\ncontext window, in addition to the current user utterance. CASA-NLU outperforms\na recurrent contextual NLU baseline on two conversational datasets, yielding a\ngain of up to 7% on the IC task for one of the datasets. Moreover, a\nnon-contextual variant of CASA-NLU achieves state-of-the-art performance for IC\ntask on standard public datasets - Snips and ATIS.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 21:00:04 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Gupta", "Arshit", ""], ["Zhang", "Peng", ""], ["Lalwani", "Garima", ""], ["Diab", "Mona", ""]]}, {"id": "1909.08735", "submitter": "Macheng Shen", "authors": "Macheng Shen, Jonathan P. How", "title": "Robust Opponent Modeling via Adversarial Ensemble Reinforcement Learning\n  in Asymmetric Imperfect-Information Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an algorithmic framework for learning robust policies in\nasymmetric imperfect-information games, where the joint reward could depend on\nthe uncertain opponent type (a private information known only to the opponent\nitself and its ally). In order to maximize the reward, the protagonist agent\nhas to infer the opponent type through agent modeling. We use multiagent\nreinforcement learning (MARL) to learn opponent models through self-play, which\ncaptures the full strategy interaction and reasoning between agents. However,\nagent policies learned from self-play can suffer from mutual overfitting.\nEnsemble training methods can be used to improve the robustness of agent policy\nagainst different opponents, but it also significantly increases the\ncomputational overhead. In order to achieve a good trade-off between the\nrobustness of the learned policy and the computation complexity, we propose to\ntrain a separate opponent policy against the protagonist agent for evaluation\npurposes. The reward achieved by this opponent is a noisy measure of the\nrobustness of the protagonist agent policy due to the intrinsic stochastic\nnature of a reinforcement learner. To handle this stochasticity, we apply a\nstochastic optimization scheme to dynamically update the opponent ensemble to\noptimize an objective function that strikes a balance between robustness and\ncomputation complexity. We empirically show that, under the same limited\ncomputational budget, the proposed method results in more robust policy\nlearning than standard ensemble training.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 23:34:22 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 17:04:46 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 19:07:50 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 22:58:52 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Shen", "Macheng", ""], ["How", "Jonathan P.", ""]]}, {"id": "1909.08737", "submitter": "Nan Wang", "authors": "Nan Wang, Hongning Wang", "title": "BPMR: Bayesian Probabilistic Multivariate Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-aspect user preferences are attracting wider attention in recommender\nsystems, as they enable more detailed understanding of users' evaluations of\nitems. Previous studies show that incorporating multi-aspect preferences can\ngreatly improve the performance and explainability of recommendation. However,\nas recommendation is essentially a ranking problem, there is no principled\nsolution for ranking multiple aspects collectively to enhance the\nrecommendation.\n  In this work, we derive a multi-aspect ranking criterion. To maintain the\ndependency among different aspects, we propose to use a vectorized\nrepresentation of multi-aspect ratings and develop a probabilistic multivariate\ntensor factorization framework (PMTF). The framework naturally leads to a\nprobabilistic multi-aspect ranking criterion, which generalizes the\nsingle-aspect ranking to a multivariate fashion. Experiment results on a large\nmulti-aspect review rating dataset confirmed the effectiveness of our solution.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 23:40:59 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Wang", "Nan", ""], ["Wang", "Hongning", ""]]}, {"id": "1909.08749", "submitter": "Ashwin Pananjady", "authors": "Ashwin Pananjady, Martin J. Wainwright", "title": "Instance-dependent $\\ell_\\infty$-bounds for policy evaluation in tabular\n  reinforcement learning", "comments": "Version v2 is consistent with manuscript to appear in IEEE\n  Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov reward processes (MRPs) are used to model stochastic phenomena arising\nin operations research, control engineering, robotics, and artificial\nintelligence, as well as communication and transportation networks. In many of\nthese cases, such as in the policy evaluation problem encountered in\nreinforcement learning, the goal is to estimate the long-term value function of\nsuch a process without access to the underlying population transition and\nreward functions. Working with samples generated under the synchronous model,\nwe study the problem of estimating the value function of an infinite-horizon,\ndiscounted MRP on finitely many states in the $\\ell_\\infty$-norm. We analyze\nboth the standard plug-in approach to this problem and a more robust variant,\nand establish non-asymptotic bounds that depend on the (unknown) problem\ninstance, as well as data-dependent bounds that can be evaluated based on the\nobservations of state-transitions and rewards. We show that these approaches\nare minimax-optimal up to constant factors over natural sub-classes of MRPs.\nOur analysis makes use of a leave-one-out decoupling argument tailored to the\npolicy evaluation problem, one which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 00:38:10 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 18:20:33 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Pananjady", "Ashwin", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1909.08752", "submitter": "Sanghwan Bae", "authors": "Sanghwan Bae, Taeuk Kim, Jihoon Kim, Sang-goo Lee", "title": "Summary Level Training of Sentence Rewriting for Abstractive\n  Summarization", "comments": "EMNLP 2019 Workshop on New Frontiers in Summarization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an attempt to combine extractive and abstractive summarization, Sentence\nRewriting models adopt the strategy of extracting salient sentences from a\ndocument first and then paraphrasing the selected ones to generate a summary.\nHowever, the existing models in this framework mostly rely on sentence-level\nrewards or suboptimal labels, causing a mismatch between a training objective\nand evaluation metric. In this paper, we present a novel training signal that\ndirectly maximizes summary-level ROUGE scores through reinforcement learning.\nIn addition, we incorporate BERT into our model, making good use of its ability\non natural language understanding. In extensive experiments, we show that a\ncombination of our proposed model and training procedure obtains new\nstate-of-the-art performance on both CNN/Daily Mail and New York Times\ndatasets. We also demonstrate that it generalizes better on DUC-2002 test set.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 00:47:13 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 09:20:10 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 07:07:03 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Bae", "Sanghwan", ""], ["Kim", "Taeuk", ""], ["Kim", "Jihoon", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1909.08755", "submitter": "Banghua Zhu", "authors": "Banghua Zhu, Jiantao Jiao and Jacob Steinhardt", "title": "Generalized Resilience and Robust Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust statistics traditionally focuses on outliers, or perturbations in\ntotal variation distance. However, a dataset could be corrupted in many other\nways, such as systematic measurement errors and missing covariates. We\ngeneralize the robust statistics approach to consider perturbations under any\nWasserstein distance, and show that robust estimation is possible whenever a\ndistribution's population statistics are robust under a certain family of\nfriendly perturbations. This generalizes a property called resilience\npreviously employed in the special case of mean estimation with outliers. We\njustify the generalized resilience property by showing that it holds under\nmoment or hypercontractive conditions. Even in the total variation case, these\nsubsume conditions in the literature for mean estimation, regression, and\ncovariance estimation; the resulting analysis simplifies and sometimes improves\nthese known results in both population limit and finite-sample rate. Our robust\nestimators are based on minimum distance (MD) functionals (Donoho and Liu,\n1988), which project onto a set of distributions under a discrepancy related to\nthe perturbation. We present two approaches for designing MD estimators with\ngood finite-sample rates: weakening the discrepancy and expanding the set of\ndistributions. We also present connections to Gao et al. (2019)'s recent\nanalysis of generative adversarial networks for robust estimation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 01:08:06 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 06:36:12 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 07:50:19 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhu", "Banghua", ""], ["Jiao", "Jiantao", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "1909.08774", "submitter": "Nagender Aneja", "authors": "Nagender Aneja and Sandhya Aneja", "title": "Transfer Learning using CNN for Handwritten Devanagari Character\n  Recognition", "comments": null, "journal-ref": "IEEE International Conference on Advances in Information\n  Technology (ICAIT), ICAIT - 2019", "doi": "10.1109/ICAIT47043.2019.8987286", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents an analysis of pre-trained models to recognize\nhandwritten Devanagari alphabets using transfer learning for Deep Convolution\nNeural Network (DCNN). This research implements AlexNet, DenseNet, Vgg, and\nInception ConvNet as a fixed feature extractor. We implemented 15 epochs for\neach of AlexNet, DenseNet 121, DenseNet 201, Vgg 11, Vgg 16, Vgg 19, and\nInception V3. Results show that Inception V3 performs better in terms of\naccuracy achieving 99% accuracy with average epoch time 16.3 minutes while\nAlexNet performs fastest with 2.2 minutes per epoch and achieving 98\\%\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 02:04:55 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Aneja", "Nagender", ""], ["Aneja", "Sandhya", ""]]}, {"id": "1909.08786", "submitter": "Artem Lutov", "authors": "Artem Lutov, Mourad Khayati and Philippe Cudr\\'e-Mauroux", "title": "DAOC: Stable Clustering of Large Networks", "comments": "IEEE BigData'19, Special Session on Intelligent Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.LG physics.soc-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clustering is a crucial component of many data mining systems involving the\nanalysis and exploration of various data. Data diversity calls for clustering\nalgorithms to be accurate while providing stable (i.e., deterministic and\nrobust) results on arbitrary input networks. Moreover, modern systems often\noperate with large datasets, which implicitly constrains the complexity of the\nclustering algorithm. Existing clustering techniques are only partially stable,\nhowever, as they guarantee either determinism or robustness. To address this\nissue, we introduce DAOC, a Deterministic and Agglomerative Overlapping\nClustering algorithm. DAOC leverages a new technique called Overlap\nDecomposition to identify fine-grained clusters in a deterministic way\ncapturing multiple optima. In addition, it leverages a novel consensus\napproach, Mutual Maximal Gain, to ensure robustness and further improve the\nstability of the results while still being capable of identifying micro-scale\nclusters. Our empirical results on both synthetic and real-world networks show\nthat DAOC yields stable clusters while being on average 25% more accurate than\nstate-of-the-art deterministic algorithms without requiring any tuning. Our\napproach has the ambition to greatly simplify and speed up data analysis tasks\ninvolving iterative processing (need for determinism) as well as data\nfluctuations (need for robustness) and to provide accurate and reproducible\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 03:12:05 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 20:47:56 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Lutov", "Artem", ""], ["Khayati", "Mourad", ""], ["Cudr\u00e9-Mauroux", "Philippe", ""]]}, {"id": "1909.08787", "submitter": "Viet Huynh", "authors": "Viet Huynh and Nhat Ho and Nhan Dam and XuanLong Nguyen and Mikhail\n  Yurochkin and Hung Bui and and Dinh Phung", "title": "On Efficient Multilevel Clustering via Wasserstein Distances", "comments": "32 pages, 8 figures, JMLR submission. arXiv admin note: substantial\n  text overlap with arXiv:1706.03883", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel approach to the problem of multilevel clustering, which\naims to simultaneously partition data in each group and discover grouping\npatterns among groups in a potentially large hierarchically structured corpus\nof data. Our method involves a joint optimization formulation over several\nspaces of discrete probability measures, which are endowed with Wasserstein\ndistance metrics. We propose several variants of this problem, which admit fast\noptimization algorithms, by exploiting the connection to the problem of finding\nWasserstein barycenters. Consistency properties are established for the\nestimates of both local and global clusters. Finally, experimental results with\nboth synthetic and real data are presented to demonstrate the flexibility and\nscalability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 03:23:13 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 03:40:15 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Huynh", "Viet", ""], ["Ho", "Nhat", ""], ["Dam", "Nhan", ""], ["Nguyen", "XuanLong", ""], ["Yurochkin", "Mikhail", ""], ["Bui", "Hung", ""], ["Phung", "and Dinh", ""]]}, {"id": "1909.08792", "submitter": "Khaled Refaat", "authors": "Khaled S. Refaat, Kai Ding, Natalia Ponomareva, St\\'ephane Ross", "title": "Agent Prioritization for Autonomous Navigation", "comments": "8 pages, accepted to IEEE/RSJ International Conference on Robots and\n  Systems (IROS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In autonomous navigation, a planning system reasons about other agents to\nplan a safe and plausible trajectory. Before planning starts, agents are\ntypically processed with computationally intensive models for recognition,\ntracking, motion estimation and prediction. With limited computational\nresources and a large number of agents to process in real time, it becomes\nimportant to efficiently rank agents according to their impact on the decision\nmaking process. This allows spending more time processing the most important\nagents. We propose a system to rank agents around an autonomous vehicle (AV) in\nreal time. We automatically generate a ranking data set by running the planner\nin simulation on real-world logged data, where we can afford to run more\naccurate and expensive models on all the agents. The causes of various planner\nactions are logged and used for assigning ground truth importance scores. The\ngenerated data set can be used to learn ranking models. In particular, we show\nthe utility of combining learned features, via a convolutional neural network,\nwith engineered features designed to capture domain knowledge. We show the\nbenefits of various design choices experimentally. When tested on real AVs, our\nsystem demonstrates the capability of understanding complex driving situations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 03:51:57 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Refaat", "Khaled S.", ""], ["Ding", "Kai", ""], ["Ponomareva", "Natalia", ""], ["Ross", "St\u00e9phane", ""]]}, {"id": "1909.08824", "submitter": "Li Du", "authors": "Li Du, Xiao Ding, Ting Liu and Zhongyang Li", "title": "Modeling Event Background for If-Then Commonsense Reasoning Using\n  Context-aware Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Understanding event and event-centered commonsense reasoning are crucial for\nnatural language processing (NLP). Given an observed event, it is trivial for\nhuman to infer its intents and effects, while this type of If-Then reasoning\nstill remains challenging for NLP systems. To facilitate this, a If-Then\ncommonsense reasoning dataset Atomic is proposed, together with an RNN-based\nSeq2Seq model to conduct such reasoning. However, two fundamental problems\nstill need to be addressed: first, the intents of an event may be multiple,\nwhile the generations of RNN-based Seq2Seq models are always semantically\nclose; second, external knowledge of the event background may be necessary for\nunderstanding events and conducting the If-Then reasoning. To address these\nissues, we propose a novel context-aware variational autoencoder effectively\nlearning event background information to guide the If-Then reasoning.\nExperimental results show that our approach improves the accuracy and diversity\nof inferences compared with state-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 06:46:02 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 08:22:45 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 07:31:56 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Du", "Li", ""], ["Ding", "Xiao", ""], ["Liu", "Ting", ""], ["Li", "Zhongyang", ""]]}, {"id": "1909.08830", "submitter": "Sekitoshi Kanai", "authors": "Sekitoshi Kanai, Yasutoshi Ida, Yasuhiro Fujiwara, Masanori Yamada,\n  Shuichi Adachi", "title": "Absum: Simple Regularization Method for Reducing Structural Sensitivity\n  of Convolutional Neural Networks", "comments": "16 pages, 39 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Absum, which is a regularization method for improving adversarial\nrobustness of convolutional neural networks (CNNs). Although CNNs can\naccurately recognize images, recent studies have shown that the convolution\noperations in CNNs commonly have structural sensitivity to specific noise\ncomposed of Fourier basis functions. By exploiting this sensitivity, they\nproposed a simple black-box adversarial attack: Single Fourier attack. To\nreduce structural sensitivity, we can use regularization of convolution filter\nweights since the sensitivity of linear transform can be assessed by the norm\nof the weights. However, standard regularization methods can prevent\nminimization of the loss function because they impose a tight constraint for\nobtaining high robustness. To solve this problem, Absum imposes a loose\nconstraint; it penalizes the absolute values of the summation of the parameters\nin the convolution layers. Absum can improve robustness against single Fourier\nattack while being as simple and efficient as standard regularization methods\n(e.g., weight decay and L1 regularization). Our experiments demonstrate that\nAbsum improves robustness against single Fourier attack more than standard\nregularization methods. Furthermore, we reveal that robust CNNs with Absum are\nmore robust against transferred attacks due to decreasing the common\nsensitivity and against high-frequency noise than standard regularization\nmethods. We also reveal that Absum can improve robustness against\ngradient-based attacks (projected gradient descent) when used with adversarial\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 07:05:14 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Kanai", "Sekitoshi", ""], ["Ida", "Yasutoshi", ""], ["Fujiwara", "Yasuhiro", ""], ["Yamada", "Masanori", ""], ["Adachi", "Shuichi", ""]]}, {"id": "1909.08855", "submitter": "Pratyay Banerjee", "authors": "Arindam Mitra, Pratyay Banerjee, Kuntal Kumar Pal, Swaroop Mishra and\n  Chitta Baral", "title": "How Additional Knowledge can Improve Natural Language Commonsense\n  Question Answering?", "comments": "14 pages, 14 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently several datasets have been proposed to encourage research in\nQuestion Answering domains where commonsense knowledge is expected to play an\nimportant role. Recent language models such as ROBERTA, BERT and GPT that have\nbeen pre-trained on Wikipedia articles and books have shown reasonable\nperformance with little fine-tuning on several such Multiple Choice\nQuestion-Answering (MCQ) datasets. Our goal in this work is to develop methods\nto incorporate additional (commonsense) knowledge into language model-based\napproaches for better question-answering in such domains. In this work, we\nfirst categorize external knowledge sources, and show performance does improve\non using such sources. We then explore three different strategies for knowledge\nincorporation and four different models for question-answering using external\ncommonsense knowledge. We analyze our predictions to explore the scope of\nfurther improvements.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:25:47 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 03:14:58 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 07:26:45 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Mitra", "Arindam", ""], ["Banerjee", "Pratyay", ""], ["Pal", "Kuntal Kumar", ""], ["Mishra", "Swaroop", ""], ["Baral", "Chitta", ""]]}, {"id": "1909.08857", "submitter": "Frank Nielsen", "authors": "Frank Nielsen and Ga\\\"etan Hadjeres", "title": "A note on the quasiconvex Jensen divergences and the quasiconvex Bregman\n  divergences derived thereof", "comments": "19 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first introduce the class of strictly quasiconvex and strictly\nquasiconcave Jensen divergences which are oriented (asymmetric) distances, and\nstudy some of their properties. We then define the strictly quasiconvex Bregman\ndivergences as the limit case of scaled and skewed quasiconvex Jensen\ndivergences, and report a simple closed-form formula which shows that these\ndivergences are only pseudo-divergences at countably many inflection points of\nthe generators. To remedy this problem, we propose the $\\delta$-averaged\nquasiconvex Bregman divergences which integrate the pseudo-divergences over a\nsmall neighborhood in order obtain a proper divergence. The formula of\n$\\delta$-averaged quasiconvex Bregman divergences extend even to\nnon-differentiable strictly quasiconvex generators. These quasiconvex Bregman\ndivergences between distinct elements have the property to always have one\norientation finite while the other orientation is infinite. We show that these\nquasiconvex Bregman divergences can also be interpreted as limit cases of\ngeneralized skewed Jensen divergences with respect to comparative convexity by\nusing power means. Finally, we illustrate how these quasiconvex Bregman\ndivergences naturally appear as equivalent divergences for the Kullback-Leibler\ndivergences between probability densities belonging to a same parametric family\nof distributions with nested supports.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:32:44 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 23:06:57 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Nielsen", "Frank", ""], ["Hadjeres", "Ga\u00ebtan", ""]]}, {"id": "1909.08863", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee", "title": "ASU at TextGraphs 2019 Shared Task: Explanation ReGeneration using\n  Language Models and Iterative Re-Ranking", "comments": "6+1 pages, 1 figures, Shared Task on Proceedings of the Thirteenth\n  Workshop on Graph-Based Methods for Natural Language Processing\n  (TextGraphs-13)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we describe the system from Natural Language Processing group at\nArizona State University for the TextGraphs 2019 Shared Task. The task focuses\non Explanation Regeneration, an intermediate step towards general multi-hop\ninference on large graphs. Our approach consists of modeling the explanation\nregeneration task as a \\textit{learning to rank} problem, for which we use\nstate-of-the-art language models and explore dataset preparation techniques. We\nutilize an iterative re-ranking based approach to further improve the rankings.\nOur system secured 2nd rank in the task with a mean average precision (MAP) of\n41.3\\% on the test set.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:47:16 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Banerjee", "Pratyay", ""]]}, {"id": "1909.08864", "submitter": "Michael Smith", "authors": "Michael Thomas Smith, Kathrin Grosse, Michael Backes, Mauricio A\n  Alvarez", "title": "Adversarial Vulnerability Bounds for Gaussian Process Classification", "comments": "10 pages + 2 pages references + 7 pages of supplementary. 12 figures.\n  Submitted to AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) classification is increasingly used in safety-critical\nsystems. Protecting ML classifiers from adversarial examples is crucial. We\npropose that the main threat is that of an attacker perturbing a confidently\nclassified input to produce a confident misclassification. To protect against\nthis we devise an adversarial bound (AB) for a Gaussian process classifier,\nthat holds for the entire input domain, bounding the potential for any future\nadversarial method to cause such misclassification. This is a formal guarantee\nof robustness, not just an empirically derived result. We investigate how to\nconfigure the classifier to maximise the bound, including the use of a sparse\napproximation, leading to the method producing a practical, useful and provably\nrobust classifier, which we test using a variety of datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:50:01 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Smith", "Michael Thomas", ""], ["Grosse", "Kathrin", ""], ["Backes", "Michael", ""], ["Alvarez", "Mauricio A", ""]]}, {"id": "1909.08868", "submitter": "Jan-Nico Zaech", "authors": "Jan-Nico Zaech, Cong Gao, Bastian Bier, Russell Taylor, Andreas Maier,\n  Nassir Navab, Mathias Unberath", "title": "Learning to Avoid Poor Images: Towards Task-aware C-arm Cone-beam CT\n  Trajectories", "comments": "Accepted for oral presentation at the International Conference on\n  Medical Image Computing and Computer Assisted Intervention (MICCAI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metal artifacts in computed tomography (CT) arise from a mismatch between\nphysics of image formation and idealized assumptions during tomographic\nreconstruction. These artifacts are particularly strong around metal implants,\ninhibiting widespread adoption of 3D cone-beam CT (CBCT) despite clear\nopportunity for intra-operative verification of implant positioning, e.g. in\nspinal fusion surgery. On synthetic and real data, we demonstrate that much of\nthe artifact can be avoided by acquiring better data for reconstruction in a\ntask-aware and patient-specific manner, and describe the first step towards the\nenvisioned task-aware CBCT protocol. The traditional short-scan CBCT trajectory\nis planar, with little room for scene-specific adjustment. We extend this\ntrajectory by autonomously adjusting out-of-plane angulation. This enables\nC-arm source trajectories that are scene-specific in that they avoid acquiring\n\"poor images\", characterized by beam hardening, photon starvation, and noise.\nThe recommendation of ideal out-of-plane angulation is performed on-the-fly\nusing a deep convolutional neural network that regresses a detectability-rank\nderived from imaging physics.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 09:00:44 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Zaech", "Jan-Nico", ""], ["Gao", "Cong", ""], ["Bier", "Bastian", ""], ["Taylor", "Russell", ""], ["Maier", "Andreas", ""], ["Navab", "Nassir", ""], ["Unberath", "Mathias", ""]]}, {"id": "1909.08891", "submitter": "\\'Alvaro Parafita Mart\\'inez", "authors": "\\'Alvaro Parafita, Jordi Vitri\\`a", "title": "Explaining Visual Models by Causal Attribution", "comments": "2019 ICCV Workshop on Interpreting and Explaining Visual Artificial\n  Intelligence Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model explanations based on pure observational data cannot compute the\neffects of features reliably, due to their inability to estimate how each\nfactor alteration could affect the rest. We argue that explanations should be\nbased on the causal model of the data and the derived intervened causal models,\nthat represent the data distribution subject to interventions. With these\nmodels, we can compute counterfactuals, new samples that will inform us how the\nmodel reacts to feature changes on our input. We propose a novel explanation\nmethodology based on Causal Counterfactuals and identify the limitations of\ncurrent Image Generative Models in their application to counterfactual\ncreation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 09:52:31 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Parafita", "\u00c1lvaro", ""], ["Vitri\u00e0", "Jordi", ""]]}, {"id": "1909.08898", "submitter": "Hans Meine", "authors": "Hans Meine, Alessa Hering", "title": "Efficient Prealignment of CT Scans for Registration through a Bodypart\n  Regressor", "comments": "Extended Abstract accepted at MIDL 2019", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/r1xYAvZXqN", "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Convolutional neural networks have not only been applied for classification\nof voxels, objects, or images, for instance, but have also been proposed as a\nbodypart regressor. We pick up this underexplored idea and evaluate its value\nfor registration: A CNN is trained to output the relative height within the\nhuman body in axial CT scans, and the resulting scores are used for quick\nalignment between different timepoints. Preliminary results confirm that this\nallows both fast and robust prealignment compared with iterative approaches.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 10:02:58 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Meine", "Hans", ""], ["Hering", "Alessa", ""]]}, {"id": "1909.08929", "submitter": "Yong Goo Kang", "authors": "Yong Goo Kang, Kyung Ho Park, Huy Kang Kim", "title": "Automobile Theft Detection by Clustering Owner Driver Data", "comments": "15 pages, 7 figures, 3 tables, In Proceedings of the 17th escar\n  Europe 2019", "journal-ref": null, "doi": "10.13154/294-6675", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As automobiles become intelligent, automobile theft methods are evolving\nintelligently. Therefore automobile theft detection has become a major research\nchallenge. Data-mining, biometrics, and additional authentication methods have\nbeen proposed to address automobile theft, in previous studies. Among these\nmethods, data-mining can be used to analyze driving characteristics and\nidentify a driver comprehensively. However, it requires a labeled driving\ndataset to achieve high accuracy. It is impractical to use the actual\nautomobile theft detection system because real theft driving data cannot be\ncollected in advance. Hence, we propose a method to detect an automobile theft\nattempt using only owner driving data. We cluster the key features of the owner\ndriving data using the k-means algorithm. After reconstructing the driving data\ninto one of these clusters, theft is detected using an error from the original\ndriving data. To validate the proposed models, we tested our actual driving\ndata and obtained 99% accuracy from the best model. This result demonstrates\nthat our proposed method can detect vehicle theft by using only the car owner's\ndriving data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 11:56:57 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Kang", "Yong Goo", ""], ["Park", "Kyung Ho", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1909.08959", "submitter": "Micha{\\l} Marcinkiewicz", "authors": "Micha{\\l} Marcinkiewicz, Grzegorz Mrukwa", "title": "Quantitative Impact of Label Noise on the Quality of Segmentation of\n  Brain Tumors on MRI scans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, deep learning has proven to be a great solution to\nmany problems, such as image or text classification. Recently, deep\nlearning-based solutions have outperformed humans on selected benchmark\ndatasets, yielding a promising future for scientific and real-world\napplications. Training of deep learning models requires vast amounts of high\nquality data to achieve such supreme performance. In real-world scenarios,\nobtaining a large, coherent, and properly labeled dataset is a challenging\ntask. This is especially true in medical applications, where high-quality data\nand annotations are scarce and the number of expert annotators is limited. In\nthis paper, we investigate the impact of corrupted ground-truth masks on the\nperformance of a neural network for a brain tumor segmentation task. Our\nfindings suggest that a) the performance degrades about 8% less than it could\nbe expected from simulations, b) a neural network learns the simulated biases\nof annotators, c) biases can be partially mitigated by using an\ninversely-biased dice loss function.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 09:48:58 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Marcinkiewicz", "Micha\u0142", ""], ["Mrukwa", "Grzegorz", ""]]}, {"id": "1909.08961", "submitter": "Weimin Wang", "authors": "Weimin Wang, Weiran Wang, Ming Sun, Chao Wang", "title": "Acoustic scene analysis with multi-head attention networks", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic Scene Classification (ASC) is a challenging task, as a single scene\nmay involve multiple events that contain complex sound patterns. For example, a\ncooking scene may contain several sound sources including silverware clinking,\nchopping, frying, etc. What complicates ASC more is that classes of different\nactivities could have overlapping sounds patterns (e.g. both cooking and\ndishwashing could have silverware clinking sound). In this paper, we propose a\nmulti-head attention network to model the complex temporal input structures for\nASC. The proposed network takes the audio's time-frequency representation as\ninput, and it leverages standard VGG plus LSTM layers to extract high-level\nfeature representation. Further more, it applies multiple attention heads to\nsummarize various patterns of sound events into fixed dimensional\nrepresentation, for the purpose of final scene classification. The whole\nnetwork is trained in an end-to-end fashion with back-propagation. Experimental\nresults confirm that our model discovers meaningful sound patterns through the\nattention mechanism, without using explicit supervision in the alignment. We\nevaluated our proposed model using DCASE 2018 Task 5 dataset, and achieved\ncompetitive performance on par with previous winner's results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:53:18 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Wang", "Weimin", ""], ["Wang", "Weiran", ""], ["Sun", "Ming", ""], ["Wang", "Chao", ""]]}, {"id": "1909.08962", "submitter": "Boris Chidlovskii", "authors": "Boris Chidlovskii", "title": "Using Latent Codes for Class Imbalance Problem in Unsupervised Domain\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of severe class imbalance in unsupervised domain\nadaptation, when the class spaces in source and target domains diverge\nconsiderably. Till recently, domain adaptation methods assumed the aligned\nclass spaces, such that reducing distribution divergence makes the transfer\nbetween domains easier. Such an alignment assumption is invalidated in real\nworld scenarios where some source classes are often under-represented or simply\nabsent in the target domain. We revise the current approaches to class\nimbalance and propose a new one that uses latent codes in the adversarial\ndomain adaptation framework. We show how the latent codes can be used to\ndisentangle the silent structure of the target domain and to identify\nunder-represented classes. We show how to learn the latent code reconstruction\njointly with the domain invariant representation and use them to accurately\nestimate the target labels.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:26:53 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Chidlovskii", "Boris", ""]]}, {"id": "1909.08964", "submitter": "Loc Tran H", "authors": "Loc Tran, Linh Tran", "title": "To Detect Irregular Trade Behaviors In Stock Market By Using Graph Based\n  Ranking Methods", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To detect the irregular trade behaviors in the stock market is the important\nproblem in machine learning field. These irregular trade behaviors are\nobviously illegal. To detect these irregular trade behaviors in the stock\nmarket, data scientists normally employ the supervised learning techniques. In\nthis paper, we employ the three graph Laplacian based semi-supervised ranking\nmethods to solve the irregular trade behavior detection problem. Experimental\nresults show that that the un-normalized and symmetric normalized graph\nLaplacian based semi-supervised ranking methods outperform the random walk\nLaplacian based semi-supervised ranking method.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 03:47:27 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Tran", "Loc", ""], ["Tran", "Linh", ""]]}, {"id": "1909.08981", "submitter": "Jacob Deasy", "authors": "Jacob Deasy, Ari Ercole and Pietro Li\\`o", "title": "Impact of novel aggregation methods for flexible, time-sensitive EHR\n  prediction without variable selection or cleaning", "comments": "5 pages, 3 tables, 1 figure, preprint under review at the Machine\n  Learning for Health workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic assessment of patient status (e.g. by an automated, continuously\nupdated assessment of outcome) in the Intensive Care Unit (ICU) is of paramount\nimportance for early alerting, decision support and resource allocation.\nExtraction and cleaning of expert-selected clinical variables discards\ninformation and protracts collaborative efforts to introduce machine learning\nin medicine. We present improved aggregation methods for a flexible deep\nlearning architecture which learns a joint representation of patient chart, lab\nand output events. Our models outperform recent deep learning models for\npatient mortality classification using ICU timeseries, by embedding and\naggregating all events with no pre-processing or variable selection. Our model\nachieves a strong performance of AUROC 0.87 at 48 hours on the MIMIC-III\ndataset while using 13,233 unique un-preprocessed variables in an interpretable\nmanner via hourly softmax aggregation. This demonstrates how our method can be\neasily combined with existing electronic health record systems for automated,\ndynamic patient risk analysis.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 12:48:48 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Deasy", "Jacob", ""], ["Ercole", "Ari", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1909.08982", "submitter": "Vasileios Iosifidis", "authors": "Vasileios Iosifidis and Eirini Ntoutsi", "title": "AdaFair: Cumulative Fairness Adaptive Boosting", "comments": "10 pages, to appear in proceedings of the 28th ACM International\n  Conference on Information and Knowledge Management (CIKM)", "journal-ref": null, "doi": "10.1145/3357384.3357974", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of ML-based decision making in domains with high societal\nimpact such as recidivism, job hiring and loan credit has raised a lot of\nconcerns regarding potential discrimination. In particular, in certain cases it\nhas been observed that ML algorithms can provide different decisions based on\nsensitive attributes such as gender or race and therefore can lead to\ndiscrimination. Although, several fairness-aware ML approaches have been\nproposed, their focus has been largely on preserving the overall classification\naccuracy while improving fairness in predictions for both protected and\nnon-protected groups (defined based on the sensitive attribute(s)). The overall\naccuracy however is not a good indicator of performance in case of class\nimbalance, as it is biased towards the majority class. As we will see in our\nexperiments, many of the fairness-related datasets suffer from class imbalance\nand therefore, tackling fairness requires also tackling the imbalance problem.\n  To this end, we propose AdaFair, a fairness-aware classifier based on\nAdaBoost that further updates the weights of the instances in each boosting\nround taking into account a cumulative notion of fairness based upon all\ncurrent ensemble members, while explicitly tackling class-imbalance by\noptimizing the number of ensemble members for balanced classification error.\nOur experiments show that our approach can achieve parity in true positive and\ntrue negative rates for both protected and non-protected groups, while it\nsignificantly outperforms existing fairness-aware methods up to 25% in terms of\nbalanced error.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 10:09:05 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Iosifidis", "Vasileios", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "1909.08986", "submitter": "Xiao-Yun Zhou", "authors": "Zhao-Yang Wang, Xiao-Yun Zhou, Peichao Li, and Celia Riga, and\n  Guang-Zhong Yang", "title": "Instantiation-Net: 3D Mesh Reconstruction from Single 2D Image for Right\n  Ventricle", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D shape instantiation which reconstructs the 3D shape of a target from\nlimited 2D images or projections is an emerging technique for surgical\nintervention. It improves the currently less-informative and insufficient 2D\nnavigation schemes for robot-assisted Minimally Invasive Surgery (MIS) to 3D\nnavigation. Previously, a general and registration-free framework was proposed\nfor 3D shape instantiation based on Kernel Partial Least Square Regression\n(KPLSR), requiring manually segmented anatomical structures as the\npre-requisite. Two hyper-parameters including the Gaussian width and component\nnumber also need to be carefully adjusted. Deep Convolutional Neural Network\n(DCNN) based framework has also been proposed to reconstruct a 3D point cloud\nfrom a single 2D image, with end-to-end and fully automatic learning. In this\npaper, an Instantiation-Net is proposed to reconstruct the 3D mesh of a target\nfrom its a single 2D image, by using DCNN to extract features from the 2D image\nand Graph Convolutional Network (GCN) to reconstruct the 3D mesh, and using\nFully Connected (FC) layers to connect the DCNN to GCN. Detailed validation was\nperformed to demonstrate the practical strength of the method and its potential\nclinical use.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 21:22:53 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Wang", "Zhao-Yang", ""], ["Zhou", "Xiao-Yun", ""], ["Li", "Peichao", ""], ["Riga", "Celia", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "1909.08987", "submitter": "Mohammed Zubair Mohammed Shamim", "authors": "Mohammed Zubair M. Shamim, Sadatullah Syed, Mohammad Shiblee, Mohammed\n  Usman and Syed Ali", "title": "Automated detection of oral pre-cancerous tongue lesions using deep\n  learning for early diagnosis of oral cavity cancer", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.28808.16643", "report-no": "01", "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering oral cavity cancer (OCC) at an early stage is an effective way to\nincrease patient survival rate. However, current initial screening process is\ndone manually and is expensive for the average individual, especially in\ndeveloping countries worldwide. This problem is further compounded due to the\nlack of specialists in such areas. Automating the initial screening process\nusing artificial intelligence (AI) to detect pre-cancerous lesions can prove to\nbe an effective and inexpensive technique that would allow patients to be\ntriaged accordingly to receive appropriate clinical management. In this study,\nwe have applied and evaluated the efficacy of six deep convolutional neural\nnetwork (DCNN) models using transfer learning, for identifying pre-cancerous\ntongue lesions directly using a small data set of clinically annotated\nphotographic images to diagnose early signs of OCC. DCNN model based on Vgg19\narchitecture was able to differentiate between benign and pre-cancerous tongue\nlesions with a mean classification accuracy of 0.98, sensitivity 0.89 and\nspecificity 0.97. Additionally, the ResNet50 DCNN model was able to distinguish\nbetween five types of tongue lesions i.e. hairy tongue, fissured tongue,\ngeographic tongue, strawberry tongue and oral hairy leukoplakia with a mean\nclassification accuracy of 0.97. Preliminary results using an (AI+Physician)\nensemble model demonstrate that an automated initial screening process of\ntongue lesions using DCNNs can achieve near-human level classification\nperformance for diagnosing early signs of OCC in patients.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:35:18 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Shamim", "Mohammed Zubair M.", ""], ["Syed", "Sadatullah", ""], ["Shiblee", "Mohammad", ""], ["Usman", "Mohammed", ""], ["Ali", "Syed", ""]]}, {"id": "1909.08994", "submitter": "Mark Collier", "authors": "Mark Collier and Hector Urdiales", "title": "Scalable Deep Unsupervised Clustering with Concrete GMVAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete random variables are natural components of probabilistic clustering\nmodels. A number of VAE variants with discrete latent variables have been\ndeveloped. Training such methods requires marginalizing over the discrete\nlatent variables, causing training time complexity to be linear in the number\nclusters. By applying a continuous relaxation to the discrete variables in\nthese methods we can achieve a reduction in the training time complexity to be\nconstant in the number of clusters used. We demonstrate that in practice for\none such method, the Gaussian Mixture VAE, the use of a continuous relaxation\nhas no negative effect on the quality of the clustering but provides a\nsubstantial reduction in training time, reducing training time on CIFAR-100\nwith 20 clusters from 47 hours to less than 6 hours.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 09:29:36 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Collier", "Mark", ""], ["Urdiales", "Hector", ""]]}, {"id": "1909.08996", "submitter": "Andrea Loreggia", "authors": "Cristina Cornelio, Michele Donini, Andrea Loreggia, Maria Silvia Pini\n  and Francesca Rossi", "title": "Voting with Random Classifiers (VORACE): Theoretical and Experimental\n  Analysis", "comments": null, "journal-ref": "Autonomous Agents and Multi-Agent Systems volume 35, Article\n  number: 22 (2021)", "doi": "10.1007/s10458-021-09504-y", "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many machine learning scenarios, looking for the best classifier that fits\na particular dataset can be very costly in terms of time and resources.\nMoreover, it can require deep knowledge of the specific domain. We propose a\nnew technique which does not require profound expertise in the domain and\navoids the commonly used strategy of hyper-parameter tuning and model\nselection. Our method is an innovative ensemble technique that uses voting\nrules over a set of randomly-generated classifiers. Given a new input sample,\nwe interpret the output of each classifier as a ranking over the set of\npossible classes. We then aggregate these output rankings using a voting rule,\nwhich treats them as preferences over the classes. We show that our approach\nobtains good results compared to the state-of-the-art, both providing a\ntheoretical analysis and an empirical evaluation of the approach on several\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 08:13:53 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 09:37:08 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 08:00:06 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Cornelio", "Cristina", ""], ["Donini", "Michele", ""], ["Loreggia", "Andrea", ""], ["Pini", "Maria Silvia", ""], ["Rossi", "Francesca", ""]]}, {"id": "1909.09003", "submitter": "Luis J. Manso", "authors": "Luis J. Manso, Ronit R. Jorvekar, Diego R. Faria, Pablo Bustos and\n  Pilar Bachiller", "title": "Graph Neural Networks for Human-aware Social Navigation", "comments": "Accepted for publication in the 21st International Workshop of\n  Physical Agents (WAF2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous navigation is a key skill for assistive and service robots. To be\nsuccessful, robots have to navigate avoiding going through the personal spaces\nof the people surrounding them. Complying with social rules such as not getting\nin the middle of human-to-human and human-to-object interactions is also\nimportant. This paper suggests using Graph Neural Networks to model how\ninconvenient the presence of a robot would be in a particular scenario\naccording to learned human conventions so that it can be used by path planning\nalgorithms. To do so, we propose two ways of modelling social interactions\nusing graphs and benchmark them with different Graph Neural Networks using the\nSocNav1 dataset. We achieve close-to-human performance in the dataset and argue\nthat, in addition to promising results, the main advantage of the approach is\nits scalability in terms of the number of social factors that can be considered\nand easily embedded in code, in comparison with model-based approaches. The\ncode used to train and test the resulting graph neural network is available in\na public repository.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 14:00:00 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 12:48:39 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 17:28:17 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Manso", "Luis J.", ""], ["Jorvekar", "Ronit R.", ""], ["Faria", "Diego R.", ""], ["Bustos", "Pablo", ""], ["Bachiller", "Pilar", ""]]}, {"id": "1909.09017", "submitter": "EPTCS", "authors": "Farhad Shakerin (The University of Texas at Dallas)", "title": "Induction of Non-monotonic Logic Programs To Explain Statistical\n  Learning Models", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646. arXiv admin note:\n  substantial text overlap with arXiv:1808.00629, arXiv:1905.11226,\n  arXiv:1802.06462, arXiv:1707.02693", "journal-ref": "EPTCS 306, 2019, pp. 379-388", "doi": "10.4204/EPTCS.306.51", "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fast and scalable algorithm to induce non-monotonic logic\nprograms from statistical learning models. We reduce the problem of search for\nbest clauses to instances of the High-Utility Itemset Mining (HUIM) problem. In\nthe HUIM problem, feature values and their importance are treated as\ntransactions and utilities respectively. We make use of TreeExplainer, a fast\nand scalable implementation of the Explainable AI tool SHAP, to extract locally\nimportant features and their weights from ensemble tree models. Our experiments\nwith UCI standard benchmarks suggest a significant improvement in terms of\nclassification evaluation metrics and running time of the training algorithm\ncompared to ALEPH, a state-of-the-art Inductive Logic Programming (ILP) system.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:12:42 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Shakerin", "Farhad", "", "The University of Texas at Dallas"]]}, {"id": "1909.09018", "submitter": "Kuruparan Shanmugalingam", "authors": "Kuruparan Shanmugalingam, Nisal Chandrasekara, Calvin Hindle, Gihan\n  Fernando, Chanaka Gunawardhana", "title": "Corporate IT-support Help-Desk Process Hybrid-Automation Solution with\n  Machine Learning Approach", "comments": "7 pages, 8 Figures, 2 Tables", "journal-ref": "The International Conference on Digital Image Computing:\n  Techniques and Applications (DICTA) 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehensive IT support teams in large scale organizations require more man\npower for handling engagement and requests of employees from different channels\non a 24*7 basis. Automated email technical queries help desk is proposed to\nhave instant real-time quick solutions and email categorisation. Email topic\nmodelling with various machine learning, deep-learning approaches are compared\nwith different features for a scalable, generalised solution along with\nsure-shot static rules. Email's title, body, attachment, OCR text, and some\nfeature engineered custom features are given as input elements. XGBoost\ncascaded hierarchical models, Bi-LSTM model with word embeddings perform well\nshowing 77.3 overall accuracy For the real world corporate email data set. By\nintroducing the thresholding techniques, the overall automation system\narchitecture provides 85.6 percentage of accuracy for real world corporate\nemails. Combination of quick fixes, static rules, ML categorization as a low\ncost inference solution reduces 81 percentage of the human effort in the\nprocess of automation and real time implementation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:07:01 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Shanmugalingam", "Kuruparan", ""], ["Chandrasekara", "Nisal", ""], ["Hindle", "Calvin", ""], ["Fernando", "Gihan", ""], ["Gunawardhana", "Chanaka", ""]]}, {"id": "1909.09020", "submitter": "Vincent Le Guen", "authors": "Vincent Le Guen (CNAM, EDF R&D), Nicolas Thome (CNAM)", "title": "Shape and Time Distortion Loss for Training Deep Time Series Forecasting\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of time series forecasting for\nnon-stationary signals and multiple future steps prediction. To handle this\nchallenging task, we introduce DILATE (DIstortion Loss including shApe and\nTimE), a new objective function for training deep neural networks. DILATE aims\nat accurately predicting sudden changes, and explicitly incorporates two terms\nsupporting precise shape and temporal change detection. We introduce a\ndifferentiable loss function suitable for training deep neural nets, and\nprovide a custom back-prop implementation for speeding up optimization. We also\nintroduce a variant of DILATE, which provides a smooth generalization of\ntemporally-constrained Dynamic Time Warping (DTW). Experiments carried out on\nvarious non-stationary datasets reveal the very good behaviour of DILATE\ncompared to models trained with the standard Mean Squared Error (MSE) loss\nfunction, and also to DTW and variants. DILATE is also agnostic to the choice\nof the model, and we highlight its benefit for training fully connected\nnetworks as well as specialized recurrent architectures, showing its capacity\nto improve over state-of-the-art trajectory forecasting approaches.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 14:35:30 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 20:53:26 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 21:40:17 GMT"}, {"version": "v4", "created": "Sun, 10 Nov 2019 22:10:14 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Guen", "Vincent Le", "", "CNAM, EDF R&D"], ["Thome", "Nicolas", "", "CNAM"]]}, {"id": "1909.09024", "submitter": "Stephen Voran", "authors": "Andrew A. Catellier and Stephen D. Voran", "title": "WEnets: A Convolutional Framework for Evaluating Audio Waveforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new convolutional framework for waveform evaluation, WEnets,\nand build a Narrowband Audio Waveform Evaluation Network, or NAWEnet, using\nthis framework. NAWEnet is single-ended (or no-reference) and was trained three\nseparate times in order to emulate PESQ, POLQA, or STOI with testing\ncorrelations 0.95, 0.92, and 0.95, respectively when training on only 50% of\navailable data and testing on 40%. Stacks of 1-D convolutional layers and\nnon-linear downsampling learn which features are important for quality or\nintelligibility estimation. This straightforward architecture simplifies the\ninterpretation of its inner workings and paves the way for future\ninvestigations into higher sample rates and accurate no-reference subjective\nspeech quality predictions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 14:45:59 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Catellier", "Andrew A.", ""], ["Voran", "Stephen D.", ""]]}, {"id": "1909.09034", "submitter": "Aishan Liu", "authors": "Aishan Liu, Xianglong Liu, Chongzhi Zhang, Hang Yu, Qiang Liu, Dacheng\n  Tao", "title": "Training Robust Deep Neural Networks via Adversarial Noise Propagation", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, deep neural networks have been found to be vulnerable to various\ntypes of noise, such as adversarial examples and corruption. Various\nadversarial defense methods have accordingly been developed to improve\nadversarial robustness for deep models. However, simply training on data mixed\nwith adversarial examples, most of these models still fail to defend against\nthe generalized types of noise. Motivated by the fact that hidden layers play a\nhighly important role in maintaining a robust model, this paper proposes a\nsimple yet powerful training algorithm, named \\emph{Adversarial Noise\nPropagation} (ANP), which injects noise into the hidden layers in a layer-wise\nmanner. ANP can be implemented efficiently by exploiting the nature of the\nbackward-forward training style. Through thorough investigations, we determine\nthat different hidden layers make different contributions to model robustness\nand clean accuracy, while shallow layers are comparatively more critical than\ndeep layers. Moreover, our framework can be easily combined with other\nadversarial training methods to further improve model robustness by exploiting\nthe potential of hidden layers. Extensive experiments on MNIST, CIFAR-10,\nCIFAR-10-C, CIFAR-10-P, and ImageNet demonstrate that ANP enables the strong\nrobustness for deep models against both adversarial and corrupted ones, and\nalso significantly outperforms various adversarial defense methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 15:08:07 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 01:17:53 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Liu", "Aishan", ""], ["Liu", "Xianglong", ""], ["Zhang", "Chongzhi", ""], ["Yu", "Hang", ""], ["Liu", "Qiang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1909.09036", "submitter": "Eliya Nachmani", "authors": "Eliya Nachmani, Lior Wolf", "title": "Hyper-Graph-Network Decoders for Block Codes", "comments": "Accepted to NeurIPS 2019. Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural decoders were shown to outperform classical message passing techniques\nfor short BCH codes. In this work, we extend these results to much larger\nfamilies of algebraic block codes, by performing message passing with graph\nneural networks. The parameters of the sub-network at each variable-node in the\nTanner graph are obtained from a hypernetwork that receives the absolute values\nof the current message as input. To add stability, we employ a simplified\nversion of the arctanh activation that is based on a high order Taylor\napproximation of this activation function. Our results show that for a large\nnumber of algebraic block codes, from diverse families of codes (BCH, LDPC,\nPolar), the decoding obtained with our method outperforms the vanilla belief\npropagation method as well as other learning techniques from the literature.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 21:47:35 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 12:30:20 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Nachmani", "Eliya", ""], ["Wolf", "Lior", ""]]}, {"id": "1909.09047", "submitter": "Brian Powell", "authors": "Brian A. Powell", "title": "Detecting malicious logins as graph anomalies", "comments": "10 pages, 8 figures. Major revisions, expanded analysis", "journal-ref": "Journal of Information Security and Applications, 54, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authenticated lateral movement via compromised accounts is a common\nadversarial maneuver that is challenging to discover with signature- or\nrules-based intrusion detection systems. In this work a behavior-based approach\nto detecting malicious logins to novel systems indicative of lateral movement\nis presented, in which a user's historical login activity is used to build a\nmodel of putative \"normal\" behavior. This historical login activity is\nrepresented as a collection of daily login graphs, which encode authentications\namong accessed systems. Each system, or graph vertex, is described by a set of\ngraph centrality measures that characterize it and the local topology of its\nlogin graph. The unsupervised technique of non-negative matrix factorization is\nthen applied to this set of features to assign each vertex to a role that\nsummarizes how the system participates in logins. The reconstruction error\nquantifying how well each vertex fits into its role is then computed, and the\nstatistics of this error can be used to identify outlier vertices that\ncorrespond to systems involved in unusual logins. We test this technique with a\nsmall cohort of privileged accounts using real login data from an operational\nenterprise network. The ability of the method to identify malicious logins\namong normal activity is tested with simulated graphs of login activity\nrepresentative of adversarial lateral movement. We find that the method is\ngenerally successful at detecting a broad range of lateral movement for each\nuser, with false positive rates significantly lower than those resulting from\nalerts based solely on login novelty.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 15:28:59 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 01:04:45 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Powell", "Brian A.", ""]]}, {"id": "1909.09063", "submitter": "Ziyao Zhang Mr.", "authors": "Ziyao Zhang, Liang Ma, Konstantinos Poularakis, Kin K. Leung, Jeremy\n  Tucker, Ananthram Swami", "title": "MACS: Deep Reinforcement Learning based SDN Controller Synchronization\n  Policy Design", "comments": "Published as a conference paper at ICNP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed software-defined networks (SDN), multiple physical SDN\ncontrollers, each managing a network domain, are implemented to balance\ncentralised control, scalability, and reliability requirements. In such\nnetworking paradigms, controllers synchronize with each other, in attempts to\nmaintain a logically centralised network view. Despite the presence of various\ndesign proposals for distributed SDN controller architectures, most existing\nworks only aim at eliminating anomalies arising from the inconsistencies in\ndifferent controllers' network views. However, the performance aspect of\ncontroller synchronization designs with respect to given SDN applications are\ngenerally missing. To fill this gap, we formulate the controller\nsynchronization problem as a Markov decision process (MDP) and apply\nreinforcement learning techniques combined with deep neural networks (DNNs) to\ntrain a smart, scalable, and fine-grained controller synchronization policy,\ncalled the Multi-Armed Cooperative Synchronization (MACS), whose goal is to\nmaximise the performance enhancements brought by controller synchronizations.\nEvaluation results confirm the DNN's exceptional ability in abstracting latent\npatterns in the distributed SDN environment, rendering significant superiority\nto MACS-based synchronization policy, which are 56% and 30% performance\nimprovements over ONOS and greedy SDN controller synchronization heuristics.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 16:01:43 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Zhang", "Ziyao", ""], ["Ma", "Liang", ""], ["Poularakis", "Konstantinos", ""], ["Leung", "Kin K.", ""], ["Tucker", "Jeremy", ""], ["Swami", "Ananthram", ""]]}, {"id": "1909.09065", "submitter": "Adrien Bennetot", "authors": "Adrien Bennetot, Jean-Luc Laurent, Raja Chatila, Natalia\n  D\\'iaz-Rodr\\'iguez", "title": "Towards Explainable Neural-Symbolic Visual Reasoning", "comments": "Accepted at IJCAI19 Neural-Symbolic Learning and Reasoning Workshop\n  (https://sites.google.com/view/nesy2019/home)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many high-performance models suffer from a lack of interpretability. There\nhas been an increasing influx of work on explainable artificial intelligence\n(XAI) in order to disentangle what is meant and expected by XAI. Nevertheless,\nthere is no general consensus on how to produce and judge explanations. In this\npaper, we discuss why techniques integrating connectionist and symbolic\nparadigms are the most efficient solutions to produce explanations for\nnon-technical users and we propose a reasoning model, based on definitions by\nDoran et al. [2017] (arXiv:1710.00794) to explain a neural network's decision.\nWe use this explanation in order to correct bias in the network's decision\nrationale. We accompany this model with an example of its potential use, based\non the image captioning method in Burns et al. [2018] (arXiv:1803.09797).\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 16:04:57 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 15:23:49 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Bennetot", "Adrien", ""], ["Laurent", "Jean-Luc", ""], ["Chatila", "Raja", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""]]}, {"id": "1909.09072", "submitter": "Xudong Liu", "authors": "Ahmed Moussa, Xudong Liu", "title": "Learning Optimal and Near-Optimal Lexicographic Preference Lists", "comments": "Published in the Proceedings of the 32nd International Florida\n  Artificial Intelligence Research Society Conference, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning problems of an intuitive and concise preference model,\ncalled lexicographic preference lists (LP-lists). Given a set of examples that\nare pairwise ordinal preferences over a universe of objects built of attributes\nof discrete values, we want to learn (1) an optimal LP-list that decides the\nmaximum number of these examples, or (2) a near-optimal LP-list that decides as\nmany examples as it can. To this end, we introduce a dynamic programming based\nalgorithm and a genetic algorithm for these two learning problems,\nrespectively. Furthermore, we empirically demonstrate that the sub-optimal\nmodels computed by the genetic algorithm very well approximate the de facto\noptimal models computed by our dynamic programming based algorithm, and that\nthe genetic algorithm outperforms the baseline greedy heuristic with higher\naccuracy predicting new preferences.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 16:10:46 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Moussa", "Ahmed", ""], ["Liu", "Xudong", ""]]}, {"id": "1909.09116", "submitter": "Jacob Kahn", "authors": "Jacob Kahn, Ann Lee, Awni Hannun", "title": "Self-Training for End-to-End Speech Recognition", "comments": "To be published in the 45th IEEE International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP) 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054295", "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit self-training in the context of end-to-end speech recognition. We\ndemonstrate that training with pseudo-labels can substantially improve the\naccuracy of a baseline model. Key to our approach are a strong baseline\nacoustic and language model used to generate the pseudo-labels, filtering\nmechanisms tailored to common errors from sequence-to-sequence models, and a\nnovel ensemble approach to increase pseudo-label diversity. Experiments on the\nLibriSpeech corpus show that with an ensemble of four models and label\nfiltering, self-training yields a 33.9% relative improvement in WER compared\nwith a baseline trained on 100 hours of labelled data in the noisy speech\nsetting. In the clean speech setting, self-training recovers 59.3% of the gap\nbetween the baseline and an oracle model, which is at least 93.8% relatively\nhigher than what previous approaches can achieve.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 17:42:56 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 22:16:10 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Kahn", "Jacob", ""], ["Lee", "Ann", ""], ["Hannun", "Awni", ""]]}, {"id": "1909.09123", "submitter": "Richard Matovu", "authors": "Richard Matovu, Isaac Griswold-Steiner, Abdul Serwadda", "title": "Kinetic Song Comprehension: Deciphering Personal Listening Habits via\n  Phone Vibrations", "comments": "25 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music is an expression of our identity, showing a significant correlation\nwith other personal traits, beliefs, and habits. If accessed by a malicious\nentity, an individual's music listening habits could be used to make critical\ninferences about the user. In this paper, we showcase an attack in which the\nvibrations propagated through a user's phone while playing music via its\nspeakers can be used to detect and classify songs.\n  Our attack shows that known songs can be detected with an accuracy of just\nunder 80%, while a corpus of 100 songs can be classified with an accuracy\ngreater than 80%. We investigate such questions under a wide variety of\nexperimental scenarios involving three surfaces and five phone speaker volumes.\nAlthough users can mitigate some of the risk by using a phone cover to dampen\nthe vibrations, we show that a sophisticated attacker could adapt the attack to\nstill classify songs with a decent accuracy.\n  This paper demonstrates a new way in which motion sensor data can be\nleveraged to intrude on user music preferences without their express\npermission. Whether this information is leveraged for financial gain or\npolitical purposes, our research makes a case for why more rigorous methods of\nprotecting user data should be utilized by companies, and if necessary,\nindividuals.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 17:52:56 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Matovu", "Richard", ""], ["Griswold-Steiner", "Isaac", ""], ["Serwadda", "Abdul", ""]]}, {"id": "1909.09132", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Yan Han, Mason Carnahan, Ahmed H Tewfik", "title": "Spoken Speech Enhancement using EEG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate spoken speech enhancement using\nelectroencephalography (EEG) signals using a generative adversarial network\n(GAN) based model, gated recurrent unit (GRU) regression based model, temporal\nconvolutional network (TCN) regression model and finally using a mixed TCN GRU\nregression model.\n  We compare our EEG based speech enhancement results with traditional log\nminimum mean-square error (MMSE) speech enhancement algorithm and our proposed\nmethods demonstrate significant improvement in speech enhancement quality\ncompared to the traditional method. Our overall results demonstrate that EEG\nfeatures can be used to clean speech recorded in presence of background noise.\nTo the best of our knowledge this is the first time a spoken speech enhancement\nis demonstrated using EEG features recorded in parallel with spoken speech.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 21:44:08 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 04:08:20 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 14:59:14 GMT"}, {"version": "v4", "created": "Sun, 3 Nov 2019 00:05:28 GMT"}, {"version": "v5", "created": "Wed, 13 Nov 2019 04:59:40 GMT"}, {"version": "v6", "created": "Fri, 14 Feb 2020 04:57:06 GMT"}, {"version": "v7", "created": "Wed, 19 Feb 2020 19:41:15 GMT"}, {"version": "v8", "created": "Sun, 19 Apr 2020 21:12:56 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Han", "Yan", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "1909.09136", "submitter": "Herbert Gish", "authors": "Herbert Gish, Jan Silovsky, Man-Ling Sung, Man-Hung Siu, William\n  Hartmann and Zhuolin Jiang", "title": "Towards a New Understanding of the Training of Neural Networks with\n  Mislabeled Training Data", "comments": "13 pages with 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of machine learning with mislabeled training data.\nWe try to make the effects of mislabeled training better understood through\nanalysis of the basic model and equations that characterize the problem. This\nincludes results about the ability of the noisy model to make the same\ndecisions as the clean model and the effects of noise on model performance. In\naddition to providing better insights we also are able to show that the Maximum\nLikelihood (ML) estimate of the parameters of the noisy model determine those\nof the clean model. This property is obtained through the use of the ML\ninvariance property and leads to an approach to developing a classifier when\ntraining has been mislabeled: namely train the classifier on noisy data and\nadjust the decision threshold based on the noise levels and/or class priors. We\nshow how our approach to mislabeled training works with multi-layered\nperceptrons (MLPs).\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 18:30:14 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Gish", "Herbert", ""], ["Silovsky", "Jan", ""], ["Sung", "Man-Ling", ""], ["Siu", "Man-Hung", ""], ["Hartmann", "William", ""], ["Jiang", "Zhuolin", ""]]}, {"id": "1909.09137", "submitter": "Agnieszka Maria S{\\l}owik", "authors": "Agnieszka S{\\l}owik, Chaitanya Mangla, Mateja Jamnik, Sean B. Holden,\n  Lawrence C. Paulson", "title": "Bayesian Optimisation with Gaussian Processes for Premise Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heuristics in theorem provers are often parameterised. Modern theorem provers\nsuch as Vampire utilise a wide array of heuristics to control the search space\nexplosion, thereby requiring optimisation of a large set of parameters. An\nexhaustive search in this multi-dimensional parameter space is intractable in\nmost cases, yet the performance of the provers is highly dependent on the\nparameter assignment. In this work, we introduce a principled probablistic\nframework for heuristics optimisation in theorem provers. We present results\nusing a heuristic for premise selection and The Archive of Formal Proofs (AFP)\nas a case study.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 18:41:47 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["S\u0142owik", "Agnieszka", ""], ["Mangla", "Chaitanya", ""], ["Jamnik", "Mateja", ""], ["Holden", "Sean B.", ""], ["Paulson", "Lawrence C.", ""]]}, {"id": "1909.09138", "submitter": "Jennie Brand", "authors": "Jennie E. Brand, Jiahui Xu, Bernard Koch, and Pablo Geraldo", "title": "Uncovering Sociological Effect Heterogeneity using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individuals do not respond uniformly to treatments, events, or interventions.\nSociologists routinely partition samples into subgroups to explore how the\neffects of treatments vary by covariates like race, gender, and socioeconomic\nstatus. In so doing, analysts determine the key subpopulations based on\ntheoretical priors. Data-driven discoveries are also routine, yet the analyses\nby which sociologists typically go about them are problematic and seldom move\nus beyond our expectations, and biases, to explore new meaningful subgroups.\nEmerging machine learning methods allow researchers to explore sources of\nvariation that they may not have previously considered, or envisaged. In this\npaper, we use causal trees to recursively partition the sample and uncover\nsources of treatment effect heterogeneity. We use honest estimation, splitting\nthe sample into a training sample to grow the tree and an estimation sample to\nestimate leaf-specific effects. Assessing a central topic in the social\ninequality literature, college effects on wages, we compare what we learn from\nconventional approaches for exploring variation in effects to causal trees.\nGiven our use of observational data, we use leaf-specific matching and\nsensitivity analyses to address confounding and offer interpretations of\neffects based on observed and unobserved heterogeneity. We encourage\nresearchers to follow similar practices in their work on variation in\nsociological effects.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 19:09:17 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Brand", "Jennie E.", ""], ["Xu", "Jiahui", ""], ["Koch", "Bernard", ""], ["Geraldo", "Pablo", ""]]}, {"id": "1909.09139", "submitter": "Eyy\\\"ub Sari", "authors": "Eyy\\\"ub Sari, Mouloud Belbahri, Vahid Partovi Nia", "title": "How Does Batch Normalization Help Binary Training?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary Neural Networks (BNNs) are difficult to train, and suffer from drop of\naccuracy. It appears in practice that BNNs fail to train in the absence of\nBatch Normalization (BatchNorm) layer. We find the main role of BatchNorm is to\navoid exploding gradients in the case of BNNs. This finding suggests that the\ncommon initialization methods developed for full-precision networks are\nirrelevant to BNNs. We build a theoretical study on the role of BatchNorm in\nbinary training, backed up by numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 19:15:35 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 13:41:48 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 14:03:27 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Sari", "Eyy\u00fcb", ""], ["Belbahri", "Mouloud", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "1909.09140", "submitter": "Siyuan Shan", "authors": "Siyuan Shan and Yang Li and Junier Oliva", "title": "Meta-Neighborhoods", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making an adaptive prediction based on one's input is an important ability\nfor general artificial intelligence. In this work, we step forward in this\ndirection and propose a semi-parametric method, Meta-Neighborhoods, where\npredictions are made adaptively to the neighborhood of the input. We show that\nMeta-Neighborhoods is a generalization of $k$-nearest-neighbors. Due to the\nsimpler manifold structure around a local neighborhood, Meta-Neighborhoods\nrepresent the predictive distribution $p(y \\mid x)$ more accurately. To reduce\nmemory and computation overhead, we propose induced neighborhoods that\nsummarize the training data into a much smaller dictionary. A meta-learning\nbased training mechanism is then exploited to jointly learn the induced\nneighborhoods and the model. Extensive studies demonstrate the superiority of\nour method.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 19:37:00 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 18:47:41 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 21:01:45 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Shan", "Siyuan", ""], ["Li", "Yang", ""], ["Oliva", "Junier", ""]]}, {"id": "1909.09141", "submitter": "Elliot Creager", "authors": "Elliot Creager, David Madras, Toniann Pitassi, Richard Zemel", "title": "Causal Modeling for Fairness in Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many application areas---lending, education, and online recommenders, for\nexample---fairness and equity concerns emerge when a machine learning system\ninteracts with a dynamically changing environment to produce both immediate and\nlong-term effects for individuals and demographic groups. We discuss causal\ndirected acyclic graphs (DAGs) as a unifying framework for the recent\nliterature on fairness in such dynamical systems. We show that this formulation\naffords several new directions of inquiry to the modeler, where causal\nassumptions can be expressed and manipulated. We emphasize the importance of\ncomputing interventional quantities in the dynamical fairness setting, and show\nhow causal assumptions enable simulation (when environment dynamics are known)\nand off-policy estimation (when dynamics are unknown) of intervention on short-\nand long-term outcomes, at both the group and individual levels.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 20:21:56 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 17:43:02 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Creager", "Elliot", ""], ["Madras", "David", ""], ["Pitassi", "Toniann", ""], ["Zemel", "Richard", ""]]}, {"id": "1909.09142", "submitter": "Sai Krishnan Chandrasekar", "authors": "Hao Ren, Sai Krishnan Chandrasekar, Anitha Murugesan", "title": "Using Quantifier Elimination to Enhance the Safety Assurance of Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in the field of Machine Learning and Deep Neural Networks (DNNs) has\nenabled rapid development of sophisticated and autonomous systems. However, the\ninherent complexity to rigorously assure the safe operation of such systems\nhinders their real-world adoption in safety-critical domains such as aerospace\nand medical devices. Hence, there is a surge in interest to explore the use of\nadvanced mathematical techniques such as formal methods to address this\nchallenge. In fact, the initial results of such efforts are promising. Along\nthese lines, we propose the use of quantifier elimination (QE) - a formal\nmethod technique, as a complimentary technique to the state-of-the-art static\nanalysis and verification procedures. Using an airborne collision avoidance DNN\nas a case example, we illustrate the use of QE to formulate the precise range\nforward propagation through a network as well as analyze its robustness. We\ndiscuss the initial results of this ongoing work and explore the future\npossibilities of extending this approach and/or integrating it with other\napproaches to perform advanced safety assurance of DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 20:54:10 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Ren", "Hao", ""], ["Chandrasekar", "Sai Krishnan", ""], ["Murugesan", "Anitha", ""]]}, {"id": "1909.09143", "submitter": "Deepak Muralidharan", "authors": "Deepak Muralidharan, Justine Kao, Xiao Yang, Lin Li, Lavanya\n  Viswanathan, Mubarak Seyed Ibrahim, Kevin Luikens, Stephen Pulman, Ashish\n  Garg, Atish Kothari and Jason Williams", "title": "Leveraging User Engagement Signals For Entity Labeling in a Virtual\n  Assistant", "comments": "NeurIPS 2018 Conversational AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal assistant AI systems such as Siri, Cortana, and Alexa have become\nwidely used as a means to accomplish tasks through natural language commands.\nHowever, components in these systems generally rely on supervised machine\nlearning algorithms that require large amounts of hand-annotated training data,\nwhich is expensive and time consuming to collect. The ability to incorporate\nunsupervised, weakly supervised, or distantly supervised data holds significant\npromise in overcoming this bottleneck. In this paper, we describe a framework\nthat leverages user engagement signals (user behaviors that demonstrate a\npositive or negative response to content) to automatically create granular\nentity labels for training data augmentation. Strategies such as multi-task\nlearning and validation using an external knowledge base are employed to\nincorporate the engagement annotated data and to boost the model's accuracy on\na sequence labeling task. Our results show that learning from data\nautomatically labeled by user engagement signals achieves significant accuracy\ngains in a production deep learning system, when measured on both the sequence\nlabeling task as well as on user facing results produced by the system\nend-to-end. We believe this is the first use of user engagement signals to help\ngenerate training data for a sequence labeling task on a large scale, and can\nbe applied in practical settings to speed up new feature deployment when little\nhuman annotated data is available.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 21:02:35 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Muralidharan", "Deepak", ""], ["Kao", "Justine", ""], ["Yang", "Xiao", ""], ["Li", "Lin", ""], ["Viswanathan", "Lavanya", ""], ["Ibrahim", "Mubarak Seyed", ""], ["Luikens", "Kevin", ""], ["Pulman", "Stephen", ""], ["Garg", "Ashish", ""], ["Kothari", "Atish", ""], ["Williams", "Jason", ""]]}, {"id": "1909.09144", "submitter": "Romit Maulik", "authors": "Romit Maulik, Vishwas Rao, Sandeep Madireddy, Bethany Lusch, Prasanna\n  Balaprakash", "title": "Using recurrent neural networks for nonlinear component computation in\n  advection-dominated reduced-order models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid simulations of advection-dominated problems are vital for multiple\nengineering and geophysical applications. In this paper, we present a long\nshort-term memory neural network to approximate the nonlinear component of the\nreduced-order model (ROM) of an advection-dominated partial differential\nequation. This is motivated by the fact that the nonlinear term is the most\nexpensive component of a successful ROM. For our approach, we utilize a\nGalerkin projection to isolate the linear and the transient components of the\ndynamical system and then use discrete empirical interpolation to generate\ntraining data for supervised learning. We note that the numerical\ntime-advancement and linear-term computation of the system ensure a greater\npreservation of physics than does a process that is fully modeled. Our results\nshow that the proposed framework recovers transient dynamics accurately without\nnonlinear term computations in full-order space and represents a cost-effective\nalternative to solely equation-based ROMs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 21:37:37 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 05:02:39 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Maulik", "Romit", ""], ["Rao", "Vishwas", ""], ["Madireddy", "Sandeep", ""], ["Lusch", "Bethany", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1909.09145", "submitter": "Praneeth Vepakomma", "authors": "Abhishek Singh, Praneeth Vepakomma, Otkrist Gupta, Ramesh Raskar", "title": "Detailed comparison of communication efficiency of split learning and\n  federated learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare communication efficiencies of two compelling distributed machine\nlearning approaches of split learning and federated learning. We show useful\nsettings under which each method outperforms the other in terms of\ncommunication efficiency. We consider various practical scenarios of\ndistributed learning setup and juxtapose the two methods under various\nreal-life scenarios. We consider settings of small and large number of clients\nas well as small models (1M - 6M parameters), large models (10M - 200M\nparameters) and very large models (1 Billion-100 Billion parameters). We show\nthat increasing number of clients or increasing model size favors split\nlearning setup over the federated while increasing the number of data samples\nwhile keeping the number of clients or model size low makes federated learning\nmore communication efficient.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 21:43:33 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Singh", "Abhishek", ""], ["Vepakomma", "Praneeth", ""], ["Gupta", "Otkrist", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1909.09146", "submitter": "Olivier Cappe", "authors": "Yoan Russac (DI-ENS, VALDA), Claire Vernade, Olivier Capp\\'e (DI-ENS,\n  VALDA)", "title": "Weighted Linear Bandits for Non-Stationary Environments", "comments": null, "journal-ref": "NeurIPS 2019 - 33rd Conference on Neural Information Processing\n  Systems, Dec 2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic linear bandit model in which the available actions\ncorrespond to arbitrary context vectors whose associated rewards follow a\nnon-stationary linear regression model. In this setting, the unknown regression\nparameter is allowed to vary in time. To address this problem, we propose\nD-LinUCB, a novel optimistic algorithm based on discounted linear regression,\nwhere exponential weights are used to smoothly forget the past. This involves\nstudying the deviations of the sequential weighted least-squares estimator\nunder generic assumptions. As a by-product, we obtain novel deviation results\nthat can be used beyond non-stationary environments. We provide theoretical\nguarantees on the behavior of D-LinUCB in both slowly-varying and\nabruptly-changing environments. We obtain an upper bound on the dynamic regret\nthat is of order d^{2/3} B\\_T^{1/3}T^{2/3}, where B\\_T is a measure of\nnon-stationarity (d and T being, respectively, dimension and horizon). This\nrate is known to be optimal. We also illustrate the empirical performance of\nD-LinUCB and compare it with recently proposed alternatives in simulated\nenvironments.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 06:57:33 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 13:49:18 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Russac", "Yoan", "", "DI-ENS, VALDA"], ["Vernade", "Claire", "", "DI-ENS,\n  VALDA"], ["Capp\u00e9", "Olivier", "", "DI-ENS,\n  VALDA"]]}, {"id": "1909.09147", "submitter": "Michael Smith", "authors": "Michael Thomas Smith, Mauricio A. Alvarez, Neil D. Lawrence", "title": "Differentially Private Regression and Classification with Sparse\n  Gaussian Processes", "comments": "26 pages, 6 figures. Submitted to JMLR 4th January, 2019 (in review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A continuing challenge for machine learning is providing methods to perform\ncomputation on data while ensuring the data remains private. In this paper we\nbuild on the provable privacy guarantees of differential privacy which has been\ncombined with Gaussian processes through the previously published\n\\emph{cloaking method}. In this paper we solve several shortcomings of this\nmethod, starting with the problem of predictions in regions with low data\ndensity. We experiment with the use of inducing points to provide a sparse\napproximation and show that these can provide robust differential privacy in\noutlier areas and at higher dimensions. We then look at classification, and\nmodify the Laplace approximation approach to provide differentially private\npredictions. We then combine this with the sparse approximation and demonstrate\nthe capability to perform classification in high dimensions. We finally explore\nthe issue of hyperparameter selection and develop a method for their private\nselection. This paper and associated libraries provide a robust toolkit for\ncombining differential privacy and GPs in a practical manner.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 07:20:38 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Smith", "Michael Thomas", ""], ["Alvarez", "Mauricio A.", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1909.09148", "submitter": "Zhuoxun He", "authors": "Zhuoxun He, Lingxi Xie, Xin Chen, Ya Zhang, Yanfeng Wang and Qi Tian", "title": "Data Augmentation Revisited: Rethinking the Distribution Gap between\n  Clean and Augmented Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation has been widely applied as an effective methodology to\nimprove generalization in particular when training deep neural networks.\nRecently, researchers proposed a few intensive data augmentation techniques,\nwhich indeed improved accuracy, yet we notice that these methods augment data\nhave also caused a considerable gap between clean and augmented data. In this\npaper, we revisit this problem from an analytical perspective, for which we\nestimate the upper-bound of expected risk using two terms, namely, empirical\nrisk and generalization error, respectively. We develop an understanding of\ndata augmentation as regularization, which highlights the major features. As a\nresult, data augmentation significantly reduces the generalization error, but\nmeanwhile leads to a slightly higher empirical risk. On the assumption that\ndata augmentation helps models converge to a better region, the model can\nbenefit from a lower empirical risk achieved by a simple method, i.e., using\nless-augmented data to refine the model trained on fully-augmented data. Our\napproach achieves consistent accuracy gain on a few standard image\nclassification benchmarks, and the gain transfers to object detection.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:36:45 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 15:56:49 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["He", "Zhuoxun", ""], ["Xie", "Lingxi", ""], ["Chen", "Xin", ""], ["Zhang", "Ya", ""], ["Wang", "Yanfeng", ""], ["Tian", "Qi", ""]]}, {"id": "1909.09149", "submitter": "Sebastian Bayerl", "authors": "Marc Wenninger, Sebastian P. Bayerl, Jochen Schmidt, Korbinian\n  Riedhammer", "title": "Timage -- A Robust Time Series Classification Pipeline", "comments": "ICANN19, 28th International Conference on Artificial Neural Networks", "journal-ref": null, "doi": "10.1007/978-3-030-30490-4_36", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series are series of values ordered by time. This kind of data can be\nfound in many real world settings. Classifying time series is a difficult task\nand an active area of research. This paper investigates the use of transfer\nlearning in Deep Neural Networks and a 2D representation of time series known\nas Recurrence Plots. In order to utilize the research done in the area of image\nclassification, where Deep Neural Networks have achieved very good results, we\nuse a Residual Neural Networks architecture known as ResNet. As preprocessing\nof time series is a major part of every time series classification pipeline,\nthe method proposed simplifies this step and requires only few parameters. For\nthe first time we propose a method for multi time series classification:\nTraining a single network to classify all datasets in the archive with one\nnetwork. We are among the first to evaluate the method on the latest 2018\nrelease of the UCR archive, a well established time series classification\nbenchmarking dataset.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 08:37:54 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Wenninger", "Marc", ""], ["Bayerl", "Sebastian P.", ""], ["Schmidt", "Jochen", ""], ["Riedhammer", "Korbinian", ""]]}, {"id": "1909.09150", "submitter": "Anne Marie Delaney Ms", "authors": "Anne Marie Delaney, Eoin Brophy, Tomas E. Ward", "title": "Synthesis of Realistic ECG using Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to medical data is highly restricted due to its sensitive nature,\npreventing communities from using this data for research or clinical training.\nCommon methods of de-identification implemented to enable the sharing of data\nare sometimes inadequate to protect the individuals contained in the data. For\nour research, we investigate the ability of generative adversarial networks\n(GANs) to produce realistic medical time series data which can be used without\nconcerns over privacy. The aim is to generate synthetic ECG signals\nrepresentative of normal ECG waveforms. GANs have been used successfully to\ngenerate good quality synthetic time series and have been shown to prevent\nre-identification of individual records. In this work, a range of GAN\narchitectures are developed to generate synthetic sine waves and synthetic ECG.\nTwo evaluation metrics are then used to quantitatively assess how suitable the\nsynthetic data is for real world applications such as clinical training and\ndata analysis. Finally, we discuss the privacy concerns associated with sharing\nsynthetic data produced by GANs and test their ability to withstand a simple\nmembership inference attack. For the first time we both quantitatively and\nqualitatively demonstrate that GAN architecture can successfully generate time\nseries signals that are not only structurally similar to the training sets but\nalso diverse in nature across generated samples. We also report on their\nability to withstand a simple membership inference attack, protecting the\nprivacy of the training set.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 09:28:36 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Delaney", "Anne Marie", ""], ["Brophy", "Eoin", ""], ["Ward", "Tomas E.", ""]]}, {"id": "1909.09153", "submitter": "Denis Kleyko", "authors": "Denis Kleyko, Mansour Kheffache, E. Paxon Frady, Urban Wiklund, and\n  Evgeny Osipov", "title": "Density Encoding Enables Resource-Efficient Randomly Connected Neural\n  Networks", "comments": "7 pages, 7 figures", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (2020)", "doi": "10.1109/TNNLS.2020.3015971", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of machine learning algorithms on resource-constrained edge\ndevices is an important challenge from both theoretical and applied points of\nview. In this article, we focus on resource-efficient randomly connected neural\nnetworks known as Random Vector Functional Link (RVFL) networks since their\nsimple design and extremely fast training time make them very attractive for\nsolving many applied classification tasks. We propose to represent input\nfeatures via the density-based encoding known in the area of stochastic\ncomputing and use the operations of binding and bundling from the area of\nhyperdimensional computing for obtaining the activations of the hidden neurons.\nUsing a collection of 121 real-world datasets from the UCI Machine Learning\nRepository, we empirically show that the proposed approach demonstrates higher\naverage accuracy than the conventional RVFL. We also demonstrate that it is\npossible to represent the readout matrix using only integers in a limited range\nwith minimal loss in the accuracy. In this case, the proposed approach operates\nonly on small n-bits integers, which results in a computationally efficient\narchitecture. Finally, through hardware FPGA implementations, we show that such\nan approach consumes approximately eleven times less energy than that of the\nconventional RVFL.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 10:57:34 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Kleyko", "Denis", ""], ["Kheffache", "Mansour", ""], ["Frady", "E. Paxon", ""], ["Wiklund", "Urban", ""], ["Osipov", "Evgeny", ""]]}, {"id": "1909.09154", "submitter": "Alexander Schulz", "authors": "Alexander Schulz, Fabian Hinder, Barbara Hammer", "title": "DeepView: Visualizing Classification Boundaries of Deep Neural Networks\n  as Scatter Plots Using Discriminative Dimensionality Reduction", "comments": "This is published at IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/319", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms using deep architectures have been able to\nimplement increasingly powerful and successful models. However, they also\nbecome increasingly more complex, more difficult to comprehend and easier to\nfool. So far, most methods in the literature investigate the decision of the\nmodel for a single given input datum. In this paper, we propose to visualize a\npart of the decision function of a deep neural network together with a part of\nthe data set in two dimensions with discriminative dimensionality reduction.\nThis enables us to inspect how different properties of the data are treated by\nthe model, such as outliers, adversaries or poisoned data. Further, the\npresented approach is complementary to the mentioned interpretation methods\nfrom the literature and hence might be even more useful in combination with\nthose. Code is available at https://github.com/LucaHermes/DeepView .\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 11:22:56 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 15:41:21 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Schulz", "Alexander", ""], ["Hinder", "Fabian", ""], ["Hammer", "Barbara", ""]]}, {"id": "1909.09156", "submitter": "Amos Azaria", "authors": "Moshe Hanukoglu, Nissan Goldberg, Aviv Rovshitz, Amos Azaria", "title": "Learning to Conceal: A Deep Learning Based Method for Preserving Privacy\n  and Avoiding Prejudice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a learning model able to conceals personal\ninformation (e.g. gender, age, ethnicity, etc.) from an image, while\nmaintaining any additional information present in the image (e.g. smile,\nhair-style, brightness). Our trained model is not provided the information that\nit is concealing, and does not try learning it either. Namely, we created a\nvariational autoencoder (VAE) model that is trained on a dataset including\nlabels of the information one would like to conceal (e.g. gender, ethnicity,\nage). These labels are directly added to the VAE's sampled latent vector. Due\nto the limited number of neurons in the latent vector and its appended noise,\nthe VAE avoids learning any relation between the given images and the given\nlabels, as those are given directly. Therefore, the encoded image lacks any of\nthe information one wishes to conceal. The encoding may be decoded back into an\nimage according to any provided properties (e.g. a 40 year old woman).\n  The proposed architecture can be used as a mean for privacy preserving and\ncan serve as an input to systems, which will become unbiased and not suffer\nfrom prejudice. We believe that privacy and discrimination are two of the most\nimportant aspects in which the community should try and develop methods to\nprevent misuse of technological advances.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 13:54:18 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Hanukoglu", "Moshe", ""], ["Goldberg", "Nissan", ""], ["Rovshitz", "Aviv", ""], ["Azaria", "Amos", ""]]}, {"id": "1909.09157", "submitter": "Aniruddh Raghu", "authors": "Aniruddh Raghu, Maithra Raghu, Samy Bengio, Oriol Vinyals", "title": "Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness\n  of MAML", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important research direction in machine learning has centered around\ndeveloping meta-learning algorithms to tackle few-shot learning. An especially\nsuccessful algorithm has been Model Agnostic Meta-Learning (MAML), a method\nthat consists of two optimization loops, with the outer loop finding a\nmeta-initialization, from which the inner loop can efficiently learn new tasks.\nDespite MAML's popularity, a fundamental open question remains -- is the\neffectiveness of MAML due to the meta-initialization being primed for rapid\nlearning (large, efficient changes in the representations) or due to feature\nreuse, with the meta initialization already containing high quality features?\nWe investigate this question, via ablation studies and analysis of the latent\nrepresentations, finding that feature reuse is the dominant factor. This leads\nto the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we\nremove the inner loop for all but the (task-specific) head of a MAML-trained\nnetwork. ANIL matches MAML's performance on benchmark few-shot image\nclassification and RL and offers computational improvements over MAML. We\nfurther study the precise contributions of the head and body of the network,\nshowing that performance on the test tasks is entirely determined by the\nquality of the learned features, and we can remove even the head of the network\n(the NIL algorithm). We conclude with a discussion of the rapid learning vs\nfeature reuse question for meta-learning algorithms more broadly.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 16:30:42 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 15:29:39 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Raghu", "Aniruddh", ""], ["Raghu", "Maithra", ""], ["Bengio", "Samy", ""], ["Vinyals", "Oriol", ""]]}, {"id": "1909.09172", "submitter": "Peixin Chang", "authors": "Peixin Chang, Shuijing Liu, Haonan Chen, Katherine Driggs-Campbell", "title": "Robot Sound Interpretation: Combining Sight and Sound in Learning-Based\n  Control", "comments": "Published as a conference paper in IEEE/RSJ International Conference\n  on Intelligent Robots and Systems (IROS), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore the interpretation of sound for robot decision making, inspired by\nhuman speech comprehension. While previous methods separate sound processing\nunit and robot controller, we propose an end-to-end deep neural network which\ndirectly interprets sound commands for visual-based decision making. The\nnetwork is trained using reinforcement learning with auxiliary losses on the\nsight and sound networks. We demonstrate our approach on two robots, a\nTurtleBot3 and a Kuka-IIWA arm, which hear a command word, identify the\nassociated target object, and perform precise control to reach the target. For\nboth robots, we show the effectiveness of our network in generalization to\nsound types and robotic tasks empirically. We successfully transfer the policy\nlearned in simulator to a real-world TurtleBot3.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 18:00:22 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 02:28:07 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Chang", "Peixin", ""], ["Liu", "Shuijing", ""], ["Chen", "Haonan", ""], ["Driggs-Campbell", "Katherine", ""]]}, {"id": "1909.09177", "submitter": "Qi Lyu", "authors": "Qi Lyu and Xiao Fu", "title": "Nonlinear Multiview Analysis: Identifiability and Neural\n  Network-assisted Implementation", "comments": "accepted version; IEEE transactions on signal processing", "journal-ref": null, "doi": "10.1109/TSP.2020.2986351", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiview analysis aims at extracting shared latent components from data\nsamples that are acquired in different domains, e.g., image, text, and audio.\nClassic multiview analysis, e.g., canonical correlation analysis (CCA), tackles\nthis problem via matching the linearly transformed views in a certain latent\ndomain. More recently, powerful nonlinear learning tools such as kernel methods\nand neural networks are utilized for enhancing the classic CCA. However, unlike\nlinear CCA whose theoretical aspects are clearly understood, nonlinear CCA\napproaches are largely intuition-driven. In particular, it is unclear under\nwhat conditions the shared latent components across the views can be\nidentified---while identifiability plays an essential role in many\napplications. In this work, we revisit nonlinear multiview analysis and address\nboth the theoretical and computational aspects. Our work leverages a useful\nnonlinear model, namely, the post-nonlinear model, from the nonlinear mixture\nseparation literature. Combining with multiview data, we take a nonlinear\nmultiview mixture learning viewpoint, which is a natural extension of the\nclassic generative models for linear CCA. From there, we derive a learning\ncriterion. We show that minimizing this criterion leads to identification of\nthe latent shared components up to certain ambiguities, under reasonable\nconditions. Our derivation and formulation also offer new insights and\ninterpretations to existing deep neural network-based CCA formulations. On the\ncomputation side, we propose an effective algorithm with simple and scalable\nupdate rules. A series of simulations and real-data experiments corroborate our\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 18:08:41 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 06:25:14 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lyu", "Qi", ""], ["Fu", "Xiao", ""]]}, {"id": "1909.09186", "submitter": "Sitao Luan", "authors": "Sitao Luan, Xiao-Wen Chang, Doina Precup", "title": "Revisit Policy Optimization in Matrix Form", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In tabular case, when the reward and environment dynamics are known, policy\nevaluation can be written as $\\bm{V}_{\\bm{\\pi}} = (I - \\gamma\nP_{\\bm{\\pi}})^{-1} \\bm{r}_{\\bm{\\pi}}$, where $P_{\\bm{\\pi}}$ is the state\ntransition matrix given policy ${\\bm{\\pi}}$ and $\\bm{r}_{\\bm{\\pi}}$ is the\nreward signal given ${\\bm{\\pi}}$. What annoys us is that $P_{\\bm{\\pi}}$ and\n$\\bm{r}_{\\bm{\\pi}}$ are both mixed with ${\\bm{\\pi}}$, which means every time\nwhen we update ${\\bm{\\pi}}$, they will change together. In this paper, we\nleverage the notation from \\cite{wang2007dual} to disentangle ${\\bm{\\pi}}$ and\nenvironment dynamics which makes optimization over policy more straightforward.\nWe show that policy gradient theorem \\cite{sutton2018reinforcement} and TRPO\n\\cite{schulman2015trust} can be put into a more general framework and such\nnotation has good potential to be extended to model-based reinforcement\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 18:43:56 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Luan", "Sitao", ""], ["Chang", "Xiao-Wen", ""], ["Precup", "Doina", ""]]}, {"id": "1909.09192", "submitter": "Vardaan Pahuja", "authors": "Vardaan Pahuja, Jie Fu, Christopher J. Pal", "title": "Learning Sparse Mixture of Experts for Visual Question Answering", "comments": "Accepted in Visual Question Answering and Dialog Workshop, CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a rapid progress in the task of Visual Question Answering with\nimproved model architectures. Unfortunately, these models are usually\ncomputationally intensive due to their sheer size which poses a serious\nchallenge for deployment. We aim to tackle this issue for the specific task of\nVisual Question Answering (VQA). A Convolutional Neural Network (CNN) is an\nintegral part of the visual processing pipeline of a VQA model (assuming the\nCNN is trained along with entire VQA model). In this project, we propose an\nefficient and modular neural architecture for the VQA task with focus on the\nCNN module. Our experiments demonstrate that a sparsely activated CNN based VQA\nmodel achieves comparable performance to a standard CNN based VQA model\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 18:55:54 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Pahuja", "Vardaan", ""], ["Fu", "Jie", ""], ["Pal", "Christopher J.", ""]]}, {"id": "1909.09209", "submitter": "EPTCS", "authors": "Daoming Lyu (Auburn University), Fangkai Yang (NVIDIA Corporation), Bo\n  Liu (Auburn University), Steven Gustafson (Maana Inc.)", "title": "A Human-Centered Data-Driven Planner-Actor-Critic Architecture via Logic\n  Programming", "comments": "In Proceedings ICLP 2019, arXiv:1909.07646. arXiv admin note:\n  significant text overlap with arXiv:1906.07268", "journal-ref": "EPTCS 306, 2019, pp. 182-195", "doi": "10.4204/EPTCS.306.23", "report-no": null, "categories": "cs.AI cs.HC cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes of Reinforcement Learning (RL) allow an agent to learn\npolicies that surpass human experts but suffers from being time-hungry and\ndata-hungry. By contrast, human learning is significantly faster because prior\nand general knowledge and multiple information resources are utilized. In this\npaper, we propose a Planner-Actor-Critic architecture for huMAN-centered\nplanning and learning (PACMAN), where an agent uses its prior, high-level,\ndeterministic symbolic knowledge to plan for goal-directed actions, and also\nintegrates the Actor-Critic algorithm of RL to fine-tune its behavior towards\nboth environmental rewards and human feedback. This work is the first unified\nframework where knowledge-based planning, RL, and human teaching jointly\ncontribute to the policy learning of an agent. Our experiments demonstrate that\nPACMAN leads to a significant jump-start at the early stage of learning,\nconverges rapidly and with small variance, and is robust to inconsistent,\ninfrequent, and misleading feedback.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 07:06:06 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Lyu", "Daoming", "", "Auburn University"], ["Yang", "Fangkai", "", "NVIDIA Corporation"], ["Liu", "Bo", "", "Auburn University"], ["Gustafson", "Steven", "", "Maana Inc."]]}, {"id": "1909.09218", "submitter": "Babak Hosseini", "authors": "Babak Hosseini, Barbara Hammer", "title": "Interpretable Discriminative Dimensionality Reduction and Feature\n  Selection on the Manifold", "comments": "16 pages, ECML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction (DR) on the manifold includes effective methods\nwhich project the data from an implicit relational space onto a vectorial\nspace. Regardless of the achievements in this area, these algorithms suffer\nfrom the lack of interpretation of the projection dimensions. Therefore, it is\noften difficult to explain the physical meaning behind the embedding\ndimensions. In this research, we propose the interpretable kernel DR algorithm\n(I-KDR) as a new algorithm which maps the data from the feature space to a\nlower dimensional space where the classes are more condensed with less\noverlapping. Besides, the algorithm creates the dimensions upon local\ncontributions of the data samples, which makes it easier to interpret them by\nclass labels. Additionally, we efficiently fuse the DR with feature selection\ntask to select the most relevant features of the original space to the\ndiscriminative objective. Based on the empirical evidence, I-KDR provides\nbetter interpretations for embedding dimensions as well as higher\ndiscriminative performance in the embedded space compared to the\nstate-of-the-art and popular DR algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 20:02:28 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Hosseini", "Babak", ""], ["Hammer", "Barbara", ""]]}, {"id": "1909.09223", "submitter": "Harsha Nori", "authors": "Harsha Nori and Samuel Jenkins and Paul Koch and Rich Caruana", "title": "InterpretML: A Unified Framework for Machine Learning Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  InterpretML is an open-source Python package which exposes machine learning\ninterpretability algorithms to practitioners and researchers. InterpretML\nexposes two types of interpretability - glassbox models, which are machine\nlearning models designed for interpretability (ex: linear models, rule lists,\ngeneralized additive models), and blackbox explainability techniques for\nexplaining existing systems (ex: Partial Dependence, LIME). The package enables\npractitioners to easily compare interpretability algorithms by exposing\nmultiple methods under a unified API, and by having a built-in, extensible\nvisualization platform. InterpretML also includes the first implementation of\nthe Explainable Boosting Machine, a powerful, interpretable, glassbox model\nthat can be as accurate as many blackbox models. The MIT licensed source code\ncan be downloaded from github.com/microsoft/interpret.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 20:22:32 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Nori", "Harsha", ""], ["Jenkins", "Samuel", ""], ["Koch", "Paul", ""], ["Caruana", "Rich", ""]]}, {"id": "1909.09246", "submitter": "Wei-Hung Weng", "authors": "Wei-Hung Weng", "title": "Machine Learning for Clinical Predictive Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we provide a brief overview of applying machine learning\ntechniques for clinical prediction tasks. We begin with a quick introduction to\nthe concepts of machine learning and outline some of the most common machine\nlearning algorithms. Next, we demonstrate how to apply the algorithms with\nappropriate toolkits to conduct machine learning experiments for clinical\nprediction tasks. The objectives of this chapter are to (1) understand the\nbasics of machine learning techniques and the reasons behind why they are\nuseful for solving clinical prediction problems, (2) understand the intuition\nbehind some machine learning models, including regression, decision trees, and\nsupport vector machines, and (3) understand how to apply these models to\nclinical prediction problems using publicly available datasets via case\nstudies.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 22:02:00 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Weng", "Wei-Hung", ""]]}, {"id": "1909.09248", "submitter": "Wei-Hung Weng", "authors": "Wei-Hung Weng, Peter Szolovits", "title": "Representation Learning for Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information in electronic health records (EHR), such as clinical narratives,\nexamination reports, lab measurements, demographics, and other patient\nencounter entries, can be transformed into appropriate data representations\nthat can be used for downstream clinical machine learning tasks using\nrepresentation learning. Learning better representations is critical to improve\nthe performance of downstream tasks. Due to the advances in machine learning,\nwe now can learn better and meaningful representations from EHR through\ndisentangling the underlying factors inside data and distilling large amounts\nof information and knowledge from heterogeneous EHR sources. In this chapter,\nwe first introduce the background of learning representations and reasons why\nwe need good EHR representations in machine learning for medicine and\nhealthcare in Section 1. Next, we explain the commonly-used machine learning\nand evaluation methods for representation learning using a deep learning\napproach in Section 2. Following that, we review recent related studies of\nlearning patient state representation from EHR for clinical machine learning\ntasks in Section 3. Finally, in Section 4 we discuss more techniques, studies,\nand challenges for learning natural language representations when free texts,\nsuch as clinical notes, examination reports, or biomedical literature are used.\nWe also discuss challenges and opportunities in these rapidly growing research\nfields.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 22:12:30 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Weng", "Wei-Hung", ""], ["Szolovits", "Peter", ""]]}, {"id": "1909.09251", "submitter": "Eric Wallace", "authors": "Eric Wallace, Jens Tuyls, Junlin Wang, Sanjay Subramanian, Matt\n  Gardner, Sameer Singh", "title": "AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models", "comments": "EMNLP 2019 Demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural NLP models are increasingly accurate but are imperfect and\nopaque---they break in counterintuitive ways and leave end users puzzled at\ntheir behavior. Model interpretation methods ameliorate this opacity by\nproviding explanations for specific model predictions. Unfortunately, existing\ninterpretation codebases make it difficult to apply these methods to new models\nand tasks, which hinders adoption for practitioners and burdens\ninterpretability researchers. We introduce AllenNLP Interpret, a flexible\nframework for interpreting NLP models. The toolkit provides interpretation\nprimitives (e.g., input gradients) for any AllenNLP model and task, a suite of\nbuilt-in interpretation methods, and a library of front-end visualization\ncomponents. We demonstrate the toolkit's flexibility and utility by\nimplementing live demos for five interpretation methods (e.g., saliency maps\nand adversarial attacks) on a variety of models and tasks (e.g., masked\nlanguage modeling using BERT and reading comprehension using BiDAF). These\ndemos, alongside our code and tutorials, are available at\nhttps://allennlp.org/interpret .\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 22:35:36 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Wallace", "Eric", ""], ["Tuyls", "Jens", ""], ["Wang", "Junlin", ""], ["Subramanian", "Sanjay", ""], ["Gardner", "Matt", ""], ["Singh", "Sameer", ""]]}, {"id": "1909.09252", "submitter": "Devanshu Arya", "authors": "Devanshu Arya, Stevan Rudinac and Marcel Worring", "title": "HyperLearn: A Distributed Approach for Representation Learning in\n  Datasets With Many Modalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal datasets contain an enormous amount of relational information,\nwhich grows exponentially with the introduction of new modalities. Learning\nrepresentations in such a scenario is inherently complex due to the presence of\nmultiple heterogeneous information channels. These channels can encode both (a)\ninter-relations between the items of different modalities and (b)\nintra-relations between the items of the same modality. Encoding multimedia\nitems into a continuous low-dimensional semantic space such that both types of\nrelations are captured and preserved is extremely challenging, especially if\nthe goal is a unified end-to-end learning framework. The two key challenges\nthat need to be addressed are: 1) the framework must be able to merge complex\nintra and inter relations without losing any valuable information and 2) the\nlearning model should be invariant to the addition of new and potentially very\ndifferent modalities. In this paper, we propose a flexible framework which can\nscale to data streams from many modalities. To that end we introduce a\nhypergraph-based model for data representation and deploy Graph Convolutional\nNetworks to fuse relational information within and across modalities. Our\napproach provides an efficient solution for distributing otherwise extremely\ncomputationally expensive or even unfeasible training processes across\nmultiple-GPUs, without any sacrifices in accuracy. Moreover, adding new\nmodalities to our model requires only an additional GPU unit keeping the\ncomputational time unchanged, which brings representation learning to truly\nmultimodal datasets. We demonstrate the feasibility of our approach in the\nexperiments on multimedia datasets featuring second, third and fourth order\nrelations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 22:45:21 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Arya", "Devanshu", ""], ["Rudinac", "Stevan", ""], ["Worring", "Marcel", ""]]}, {"id": "1909.09263", "submitter": "Kyungyul Kim", "authors": "Jihyeun Yoon, Kyungyul Kim, Jongseong Jang", "title": "Propagated Perturbation of Adversarial Attack for well-known CNNs:\n  Empirical Study and its Explanation", "comments": null, "journal-ref": "ICCV 2019 Workshop on Interpreting and Explaining Visual\n  Artificial Intelligence Models", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network based classifiers are known to be vulnerable to\nperturbations of inputs constructed by an adversarial attack to force\nmisclassification. Most studies have focused on how to make vulnerable noise by\ngradient based attack methods or to defense model from adversarial attack. The\nuse of the denoiser model is one of a well-known solution to reduce the\nadversarial noise although classification performance had not significantly\nimproved. In this study, we aim to analyze the propagation of adversarial\nattack as an explainable AI(XAI) point of view. Specifically, we examine the\ntrend of adversarial perturbations through the CNN architectures. To analyze\nthe propagated perturbation, we measured normalized Euclidean Distance and\ncosine distance in each CNN layer between the feature map of the perturbed\nimage passed through denoiser and the non-perturbed original image. We used\nfive well-known CNN based classifiers and three gradient-based adversarial\nattacks. From the experimental results, we observed that in most cases,\nEuclidean Distance explosively increases in the final fully connected layer\nwhile cosine distance fluctuated and disappeared at the last layer. This means\nthat the use of denoiser can decrease the amount of noise. However, it failed\nto defense accuracy degradation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 23:51:07 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 07:18:24 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Yoon", "Jihyeun", ""], ["Kim", "Kyungyul", ""], ["Jang", "Jongseong", ""]]}, {"id": "1909.09264", "submitter": "Meyer Scetbon", "authors": "M. Scetbon, G. Varoquaux", "title": "Comparing distributions: $\\ell_1$ geometry improves kernel two-sample\n  testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Are two sets of observations drawn from the same distribution? This problem\nis a two-sample test. Kernel methods lead to many appealing properties. Indeed\nstate-of-the-art approaches use the $L^2$ distance between kernel-based\ndistribution representatives to derive their test statistics. Here, we show\nthat $L^p$ distances (with $p\\geq 1$) between these distribution\nrepresentatives give metrics on the space of distributions that are\nwell-behaved to detect differences between distributions as they metrize the\nweak convergence. Moreover, for analytic kernels, we show that the $L^1$\ngeometry gives improved testing power for scalable computational procedures.\nSpecifically, we derive a finite dimensional approximation of the metric given\nas the $\\ell_1$ norm of a vector which captures differences of expectations of\nanalytic functions evaluated at spatial locations or frequencies (i.e,\nfeatures). The features can be chosen to maximize the differences of the\ndistributions and give interpretable indications of how they differs. Using an\n$\\ell_1$ norm gives better detection because differences between\nrepresentatives are dense as we use analytic kernels (non-zero almost\neverywhere). The tests are consistent, while much faster than state-of-the-art\nquadratic-time kernel-based tests. Experiments on artificial and real-world\nproblems demonstrate improved power/time tradeoff than the state of the art,\nbased on $\\ell_2$ norms, and in some cases, better outright power than even the\nmost expensive quadratic-time tests.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 23:59:44 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 01:17:31 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Scetbon", "M.", ""], ["Varoquaux", "G.", ""]]}, {"id": "1909.09268", "submitter": "Hassan Kane", "authors": "Hassan Kan\\'e, Yusuf Kocyigit, Pelkins Ajanoh, Ali Abdalla, Mohamed\n  Coulibali", "title": "Towards Neural Language Evaluators", "comments": "Accepted to NeurIPS 2019 Document Intelligence Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review three limitations of BLEU and ROUGE -- the most popular metrics\nused to assess reference summaries against hypothesis summaries, come up with\ncriteria for what a good metric should behave like and propose concrete ways to\nuse recent Transformers-based Language Models to assess reference summaries\nagainst hypothesis summaries.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 00:24:59 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 19:56:02 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Kan\u00e9", "Hassan", ""], ["Kocyigit", "Yusuf", ""], ["Ajanoh", "Pelkins", ""], ["Abdalla", "Ali", ""], ["Coulibali", "Mohamed", ""]]}, {"id": "1909.09270", "submitter": "Stephen Mayhew", "authors": "Stephen Mayhew, Snigdha Chaturvedi, Chen-Tse Tsai, Dan Roth", "title": "Named Entity Recognition with Partially Annotated Training Data", "comments": "Accepted to CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Supervised machine learning assumes the availability of fully-labeled data,\nbut in many cases, such as low-resource languages, the only data available is\npartially annotated. We study the problem of Named Entity Recognition (NER)\nwith partially annotated training data in which a fraction of the named\nentities are labeled, and all other tokens, entities or otherwise, are labeled\nas non-entity by default. In order to train on this noisy dataset, we need to\ndistinguish between the true and false negatives. To this end, we introduce a\nconstraint-driven iterative algorithm that learns to detect false negatives in\nthe noisy set and downweigh them, resulting in a weighted training set. With\nthis set, we train a weighted NER model. We evaluate our algorithm with\nweighted variants of neural and non-neural NER models on data in 8 languages\nfrom several language and script families, showing strong ability to learn from\npartial data. Finally, to show real-world efficacy, we evaluate on a Bengali\nNER corpus annotated by non-speakers, outperforming the prior state-of-the-art\nby over 5 points F1.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 00:39:07 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Mayhew", "Stephen", ""], ["Chaturvedi", "Snigdha", ""], ["Tsai", "Chen-Tse", ""], ["Roth", "Dan", ""]]}, {"id": "1909.09282", "submitter": "William Lewis Ii", "authors": "W. Cannon Lewis II, Mark Moll, and Lydia E. Kavraki", "title": "How Much Do Unstated Problem Constraints Limit Deep Robotic\n  Reinforcement Learning?", "comments": "Rice University technical report", "journal-ref": null, "doi": "10.25611/az5z-xt37", "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning is a promising paradigm for robotic control which\nhas been shown to be capable of learning policies for high-dimensional,\ncontinuous control of unmodeled systems. However, RoboticReinforcement Learning\ncurrently lacks clearly defined benchmark tasks, which makes it difficult for\nresearchers to reproduce and compare against prior work. ``Reacher'' tasks,\nwhich are fundamental to robotic manipulation, are commonly used as benchmarks,\nbut the lack of a formal specification elides details that are crucial to\nreplication. In this paper we present a novel empirical analysis which shows\nthat the unstated spatial constraints in commonly used implementations of\nReacher tasks make it dramatically easier to learn a successful control policy\nwith DeepDeterministic Policy Gradients (DDPG), a state-of-the-art Deep RL\nalgorithm. Our analysis suggests that less constrained Reacher tasks are\nsignificantly more difficult to learn, and hence that existing de facto\nbenchmarks are not representative of the difficulty of general robotic\nmanipulation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 01:12:25 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Lewis", "W. Cannon", "II"], ["Moll", "Mark", ""], ["Kavraki", "Lydia E.", ""]]}, {"id": "1909.09285", "submitter": "Asma Ghandeharioun", "authors": "Asma Ghandeharioun, Brian Eoff, Brendan Jou, Rosalind W. Picard", "title": "Characterizing Sources of Uncertainty to Proxy Calibration and\n  Disambiguate Annotator and Data Bias", "comments": "Accepted for presentation at 2019 ICCV Workshop on Interpreting and\n  Explaining Visual Artificial Intelligence Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supporting model interpretability for complex phenomena where annotators can\nlegitimately disagree, such as emotion recognition, is a challenging machine\nlearning task. In this work, we show that explicitly quantifying the\nuncertainty in such settings has interpretability benefits. We use a simple\nmodification of a classical network inference using Monte Carlo dropout to give\nmeasures of epistemic and aleatoric uncertainty. We identify a significant\ncorrelation between aleatoric uncertainty and human annotator disagreement\n($r\\approx.3$). Additionally, we demonstrate how difficult and subjective\ntraining samples can be identified using aleatoric uncertainty and how\nepistemic uncertainty can reveal data bias that could result in unfair\npredictions. We identify the total uncertainty as a suitable surrogate for\nmodel calibration, i.e. the degree we can trust model's predicted confidence.\nIn addition to explainability benefits, we observe modest performance boosts\nfrom incorporating model uncertainty.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 01:22:53 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 18:33:32 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ghandeharioun", "Asma", ""], ["Eoff", "Brian", ""], ["Jou", "Brendan", ""], ["Picard", "Rosalind W.", ""]]}, {"id": "1909.09292", "submitter": "Haiqin Yang", "authors": "Haiqin Yang", "title": "BERT Meets Chinese Word Segmentation", "comments": "13 pages; 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese word segmentation (CWS) is a fundamental task for Chinese language\nunderstanding. Recently, neural network-based models have attained superior\nperformance in solving the in-domain CWS task. Last year, Bidirectional Encoder\nRepresentation from Transformers (BERT), a new language representation model,\nhas been proposed as a backbone model for many natural language tasks and\nredefined the corresponding performance. The excellent performance of BERT\nmotivates us to apply it to solve the CWS task. By conducting intensive\nexperiments in the benchmark datasets from the second International Chinese\nWord Segmentation Bake-off, we obtain several keen observations. BERT can\nslightly improve the performance even when the datasets contain the issue of\nlabeling inconsistency. When applying sufficiently learned features, Softmax, a\nsimpler classifier, can attain the same performance as that of a more\ncomplicated classifier, e.g., Conditional Random Field (CRF). The performance\nof BERT usually increases as the model size increases. The features extracted\nby BERT can be also applied as good candidates for other neural network models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 01:53:19 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Yang", "Haiqin", ""]]}, {"id": "1909.09293", "submitter": "Xiaoming Li", "authors": "Xiaoming Li, Chun Wang, Xiao Huang", "title": "A Two-Stage Stochastic Programming Model for Car-Sharing Problem using\n  Kernel Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Car-sharing problem is a popular research field in sharing economy. In this\npaper, we investigate the car-sharing re-balancing problem under uncertain\ndemands. An innovative framework that integrates a non-parametric approach -\nkernel density estimation (KDE) and a two-stage stochastic programming (SP)\nmodel are proposed. Specifically, the probability distributions are derived\nfrom New York taxi trip data sets by KDE, which is used as the input uncertain\nparameters for SP. Additionally, the car-sharing problem is formulated as a\ntwo-stage SP model which aims to maximize the overall profit. Meanwhile, a\nMonte Carlo method called sample average approximation (SAA) and Benders\ndecomposition algorithm is introduced to solve the large-scale optimization\nmodel. Finally, the experimental validations show that the proposed framework\noutperforms the existing works in terms of outcomes.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 02:05:11 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Li", "Xiaoming", ""], ["Wang", "Chun", ""], ["Huang", "Xiao", ""]]}, {"id": "1909.09295", "submitter": "Jingxi Xu", "authors": "David Watkins-Valls, Jingxi Xu, Nicholas Waytowich and Peter Allen", "title": "Learning Your Way Without Map or Compass: Panoramic Target Driven Visual\n  Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a robot navigation system that uses an imitation learning\nframework to successfully navigate in complex environments. Our framework takes\na pre-built 3D scan of a real environment and trains an agent from\npre-generated expert trajectories to navigate to any position given a panoramic\nview of the goal and the current visual input without relying on map, compass,\nodometry, or relative position of the target at runtime. Our end-to-end trained\nagent uses RGB and depth (RGBD) information and can handle large environments\n(up to $1031m^2$) across multiple rooms (up to $40$) and generalizes to unseen\ntargets. We show that when compared to several baselines our method (1)\nrequires fewer training examples and less training time, (2) reaches the goal\nlocation with higher accuracy, and (3) produces better solutions with shorter\npaths for long-range navigation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 02:17:20 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 08:52:13 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Watkins-Valls", "David", ""], ["Xu", "Jingxi", ""], ["Waytowich", "Nicholas", ""], ["Allen", "Peter", ""]]}, {"id": "1909.09300", "submitter": "Tianhong Li", "authors": "Tianhong Li, Lijie Fan, Mingmin Zhao, Yingcheng Liu, Dina Katabi", "title": "Making the Invisible Visible: Action Recognition Through Walls and\n  Occlusions", "comments": "ICCV 2019. The first two authors contributed equally to this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding people's actions and interactions typically depends on seeing\nthem. Automating the process of action recognition from visual data has been\nthe topic of much research in the computer vision community. But what if it is\ntoo dark, or if the person is occluded or behind a wall? In this paper, we\nintroduce a neural network model that can detect human actions through walls\nand occlusions, and in poor lighting conditions. Our model takes radio\nfrequency (RF) signals as input, generates 3D human skeletons as an\nintermediate representation, and recognizes actions and interactions of\nmultiple people over time. By translating the input to an intermediate\nskeleton-based representation, our model can learn from both vision-based and\nRF-based datasets, and allow the two tasks to help each other. We show that our\nmodel achieves comparable accuracy to vision-based action recognition systems\nin visible scenarios, yet continues to work accurately when people are not\nvisible, hence addressing scenarios that are beyond the limit of today's\nvision-based action recognition.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 02:49:55 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Li", "Tianhong", ""], ["Fan", "Lijie", ""], ["Zhao", "Mingmin", ""], ["Liu", "Yingcheng", ""], ["Katabi", "Dina", ""]]}, {"id": "1909.09314", "submitter": "Lantao Yu", "authors": "Lantao Yu, Tianhe Yu, Chelsea Finn, Stefano Ermon", "title": "Meta-Inverse Reinforcement Learning with Probabilistic Context Variables", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing a suitable reward function to reinforcement learning can be\ndifficult in many real world applications. While inverse reinforcement learning\n(IRL) holds promise for automatically learning reward functions from\ndemonstrations, several major challenges remain. First, existing IRL methods\nlearn reward functions from scratch, requiring large numbers of demonstrations\nto correctly infer the reward for each task the agent may need to perform.\nSecond, existing methods typically assume homogeneous demonstrations for a\nsingle behavior or task, while in practice, it might be easier to collect\ndatasets of heterogeneous but related behaviors. To this end, we propose a deep\nlatent variable model that is capable of learning rewards from demonstrations\nof distinct but related tasks in an unsupervised way. Critically, our model can\ninfer rewards for new, structurally-similar tasks from a single demonstration.\nOur experiments on multiple continuous control tasks demonstrate the\neffectiveness of our approach compared to state-of-the-art imitation and\ninverse reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 04:22:13 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 21:15:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Yu", "Lantao", ""], ["Yu", "Tianhe", ""], ["Finn", "Chelsea", ""], ["Ermon", "Stefano", ""]]}, {"id": "1909.09338", "submitter": "Yucen Luo", "authors": "Yucen Luo, Jun Zhu, Tomas Pfister", "title": "A Simple yet Effective Baseline for Robust Deep Learning with Noisy\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep neural networks have shown their capacity to memorize training\ndata, even with noisy labels, which hurts generalization performance. To\nmitigate this issue, we provide a simple but effective baseline method that is\nrobust to noisy labels, even with severe noise. Our objective involves a\nvariance regularization term that implicitly penalizes the Jacobian norm of the\nneural network on the whole training set (including the noisy-labeled data),\nwhich encourages generalization and prevents overfitting to the corrupted\nlabels. Experiments on both synthetically generated incorrect labels and\nrealistic large-scale noisy datasets demonstrate that our approach achieves\nstate-of-the-art performance with a high tolerance to severe noise.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 06:15:13 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 04:29:39 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Luo", "Yucen", ""], ["Zhu", "Jun", ""], ["Pfister", "Tomas", ""]]}, {"id": "1909.09345", "submitter": "Shuaiwen Wang", "authors": "Shuaiwen Wang, Haolei Weng, Arian Maleki", "title": "Does SLOPE outperform bridge regression?", "comments": "51 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently proposed SLOPE estimator (arXiv:1407.3824) has been shown to\nadaptively achieve the minimax $\\ell_2$ estimation rate under high-dimensional\nsparse linear regression models (arXiv:1503.08393). Such minimax optimality\nholds in the regime where the sparsity level $k$, sample size $n$, and\ndimension $p$ satisfy $k/p \\rightarrow 0$, $k\\log p/n \\rightarrow 0$. In this\npaper, we characterize the estimation error of SLOPE under the complementary\nregime where both $k$ and $n$ scale linearly with $p$, and provide new insights\ninto the performance of SLOPE estimators. We first derive a concentration\ninequality for the finite sample mean square error (MSE) of SLOPE. The quantity\nthat MSE concentrates around takes a complicated and implicit form. With\ndelicate analysis of the quantity, we prove that among all SLOPE estimators,\nLASSO is optimal for estimating $k$-sparse parameter vectors that do not have\ntied non-zero components in the low noise scenario. On the other hand, in the\nlarge noise scenario, the family of SLOPE estimators are sub-optimal compared\nwith bridge regression such as the Ridge estimator.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 07:01:51 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 06:50:30 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Wang", "Shuaiwen", ""], ["Weng", "Haolei", ""], ["Maleki", "Arian", ""]]}, {"id": "1909.09347", "submitter": "Yohei Kawaguchi", "authors": "Harsh Purohit, Ryo Tanabe, Kenji Ichige, Takashi Endo, Yuki Nikaido,\n  Kaori Suefusa, and Yohei Kawaguchi", "title": "MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine\n  Investigation and Inspection", "comments": "5 pages, to appear in DCASE 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factory machinery is prone to failure or breakdown, resulting in significant\nexpenses for companies. Hence, there is a rising interest in machine monitoring\nusing different sensors including microphones. In the scientific community, the\nemergence of public datasets has led to advancements in acoustic detection and\nclassification of scenes and events, but there are no public datasets that\nfocus on the sound of industrial machines under normal and anomalous operating\nconditions in real factory environments. In this paper, we present a new\ndataset of industrial machine sounds that we call a sound dataset for\nmalfunctioning industrial machine investigation and inspection (MIMII dataset).\nNormal sounds were recorded for different types of industrial machines (i.e.,\nvalves, pumps, fans, and slide rails), and to resemble a real-life scenario,\nvarious anomalous sounds were recorded (e.g., contamination, leakage, rotating\nunbalance, and rail damage). The purpose of releasing the MIMII dataset is to\nassist the machine-learning and signal-processing community with their\ndevelopment of automated facility maintenance. The MIMII dataset is freely\navailable for download at: https://zenodo.org/record/3384388\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 07:17:34 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Purohit", "Harsh", ""], ["Tanabe", "Ryo", ""], ["Ichige", "Kenji", ""], ["Endo", "Takashi", ""], ["Nikaido", "Yuki", ""], ["Suefusa", "Kaori", ""], ["Kawaguchi", "Yohei", ""]]}, {"id": "1909.09365", "submitter": "Eugene Ndiaye", "authors": "Eugene Ndiaye and Ichiro Takeuchi", "title": "Computing Full Conformal Prediction Set with Approximate Homotopy", "comments": "Conference on Neural Information Processing Systems (NeurIPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If you are predicting the label $y$ of a new object with $\\hat y$, how\nconfident are you that $y = \\hat y$? Conformal prediction methods provide an\nelegant framework for answering such question by building a $100 (1 -\n\\alpha)\\%$ confidence region without assumptions on the distribution of the\ndata. It is based on a refitting procedure that parses all the possibilities\nfor $y$ to select the most likely ones. Although providing strong coverage\nguarantees, conformal set is impractical to compute exactly for many regression\nproblems. We propose efficient algorithms to compute conformal prediction set\nusing approximated solution of (convex) regularized empirical risk\nminimization. Our approaches rely on a new homotopy continuation technique for\ntracking the solution path with respect to sequential changes of the\nobservations. We also provide a detailed analysis quantifying its complexity.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 08:15:37 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 06:40:07 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Ndiaye", "Eugene", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1909.09369", "submitter": "Rafael Poyiadzi", "authors": "Rafael Poyiadzi, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie,\n  Peter Flach", "title": "FACE: Feasible and Actionable Counterfactual Explanations", "comments": "Presented at AAAI/ACM Conference on AI, Ethics, and Society 2020", "journal-ref": null, "doi": "10.1145/3375627.3375850", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Work in Counterfactual Explanations tends to focus on the principle of \"the\nclosest possible world\" that identifies small changes leading to the desired\noutcome. In this paper we argue that while this approach might initially seem\nintuitively appealing it exhibits shortcomings not addressed in the current\nliterature. First, a counterfactual example generated by the state-of-the-art\nsystems is not necessarily representative of the underlying data distribution,\nand may therefore prescribe unachievable goals(e.g., an unsuccessful life\ninsurance applicant with severe disability may be advised to do more sports).\nSecondly, the counterfactuals may not be based on a \"feasible path\" between the\ncurrent state of the subject and the suggested one, making actionable recourse\ninfeasible (e.g., low-skilled unsuccessful mortgage applicants may be told to\ndouble their salary, which may be hard without first increasing their skill\nlevel). These two shortcomings may render counterfactual explanations\nimpractical and sometimes outright offensive. To address these two major flaws,\nfirst of all, we propose a new line of Counterfactual Explanations research\naimed at providing actionable and feasible paths to transform a selected\ninstance into one that meets a certain goal. Secondly, we propose FACE: an\nalgorithmically sound way of uncovering these \"feasible paths\" based on the\nshortest path distances defined via density-weighted metrics. Our approach\ngenerates counterfactuals that are coherent with the underlying data\ndistribution and supported by the \"feasible paths\" of change, which are\nachievable and can be tailored to the problem at hand.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 08:29:35 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 15:39:07 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Poyiadzi", "Rafael", ""], ["Sokol", "Kacper", ""], ["Santos-Rodriguez", "Raul", ""], ["De Bie", "Tijl", ""], ["Flach", "Peter", ""]]}, {"id": "1909.09389", "submitter": "Ameya Prabhu", "authors": "Ameya Prabhu, Charles Dognin and Maneesh Singh", "title": "Sampling Bias in Deep Active Classification: An Empirical Study", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The exploding cost and time needed for data labeling and model training are\nbottlenecks for training DNN models on large datasets. Identifying smaller\nrepresentative data samples with strategies like active learning can help\nmitigate such bottlenecks. Previous works on active learning in NLP identify\nthe problem of sampling bias in the samples acquired by uncertainty-based\nquerying and develop costly approaches to address it. Using a large empirical\nstudy, we demonstrate that active set selection using the posterior entropy of\ndeep models like FastText.zip (FTZ) is robust to sampling biases and to various\nalgorithmic choices (query size and strategies) unlike that suggested by\ntraditional literature. We also show that FTZ based query strategy produces\nsample sets similar to those from more sophisticated approaches (e.g ensemble\nnetworks). Finally, we show the effectiveness of the selected samples by\ncreating tiny high-quality datasets, and utilizing them for fast and cheap\ntraining of large models. Based on the above, we propose a simple baseline for\ndeep active text classification that outperforms the state-of-the-art. We\nexpect the presented work to be useful and informative for dataset compression\nand for problems involving active, semi-supervised or online learning\nscenarios. Code and models are available at:\nhttps://github.com/drimpossible/Sampling-Bias-Active-Learning\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 09:35:20 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Prabhu", "Ameya", ""], ["Dognin", "Charles", ""], ["Singh", "Maneesh", ""]]}, {"id": "1909.09399", "submitter": "Mehul S. Raval", "authors": "Rupal Agravat, Mehul S Raval", "title": "Brain Tumor Segmentation and Survival Prediction", "comments": "9 Pages", "journal-ref": "BraTS 2019", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper demonstrates the use of the fully convolutional neural network for\nglioma segmentation on the BraTS 2019 dataset. Three-layers deep\nencoder-decoder architecture is used along with dense connection at encoder\npart to propagate the information from coarse layer to deep layers. This\narchitecture is used to train three tumor sub-components separately.\nSubcomponent training weights are initialized with whole tumor weights to get\nthe localization of the tumor within the brain. At the end, three segmentation\nresults were merged to get the entire tumor segmentation. Dice Similarity of\ntraining dataset with focal loss implementation for whole tumor, tumor core and\nenhancing tumor is 0.92, 0.90 and 0.79 respectively. Radiomic features along\nwith segmentation results and age are used to predict the overall survival of\npatients using random forest regressor to classify survival of patients in\nlong, medium and short survival classes. 55.4% of classification accuracy is\nreported for training dataset with the scans whose resection status is\ngross-total resection.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 10:00:32 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Agravat", "Rupal", ""], ["Raval", "Mehul S", ""]]}, {"id": "1909.09420", "submitter": "Konstantin Schall", "authors": "Konstantin Schall, Kai Uwe Barthel, Nico Hezel, Klaus Jung", "title": "Deep Aggregation of Regional Convolutional Activations for Content Based\n  Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges of deep learning based image retrieval remains in\naggregating convolutional activations into one highly representative feature\nvector. Ideally, this descriptor should encode semantic, spatial and low level\ninformation. Even though off-the-shelf pre-trained neural networks can already\nproduce good representations in combination with aggregation methods,\nappropriate fine tuning for the task of image retrieval has shown to\nsignificantly boost retrieval performance. In this paper, we present a simple\nyet effective supervised aggregation method built on top of existing regional\npooling approaches. In addition to the maximum activation of a given region, we\ncalculate regional average activations of extracted feature maps. Subsequently,\nweights for each of the pooled feature vectors are learned to perform a\nweighted aggregation to a single feature vector. Furthermore, we apply our\nnewly proposed NRA loss function for deep metric learning to fine tune the\nbackbone neural network and to learn the aggregation weights. Our method\nachieves state-of-the-art results for the INRIA Holidays data set and\ncompetitive results for the Oxford Buildings and Paris data sets while reducing\nthe training time significantly.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 10:43:00 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 06:53:16 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Schall", "Konstantin", ""], ["Barthel", "Kai Uwe", ""], ["Hezel", "Nico", ""], ["Jung", "Klaus", ""]]}, {"id": "1909.09427", "submitter": "Konstantin Schall", "authors": "Konstantin Schall, Kai Uwe Barthel, Nico Hezel, Klaus Jung", "title": "Deep Metric Learning using Similarities from Nonlinear Rank\n  Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep metric learning has achieved promising results in\nlearning high dimensional semantic feature embeddings where the spatial\nrelationships of the feature vectors match the visual similarities of the\nimages. Similarity search for images is performed by determining the vectors\nwith the smallest distances to a query vector. However, high retrieval quality\ndoes not depend on the actual distances of the feature vectors, but rather on\nthe ranking order of the feature vectors from similar images. In this paper, we\nintroduce a metric learning algorithm that focuses on identifying and modifying\nthose feature vectors that most strongly affect the retrieval quality. We\ncompute normalized approximated ranks and convert them to similarities by\napplying a nonlinear transfer function. These similarities are used in a newly\nproposed loss function that better contracts similar and disperses dissimilar\nsamples. Experiments demonstrate significant improvement over existing deep\nfeature embedding methods on the CUB-200-2011, Cars196, and Stanford Online\nProducts data sets for all embedding sizes.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 11:07:15 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 06:49:42 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Schall", "Konstantin", ""], ["Barthel", "Kai Uwe", ""], ["Hezel", "Nico", ""], ["Jung", "Klaus", ""]]}, {"id": "1909.09428", "submitter": "Chris Dyer", "authors": "Chris Dyer, G\\'abor Melis, Phil Blunsom", "title": "A Critical Analysis of Biased Parsers in Unsupervised Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A series of recent papers has used a parsing algorithm due to Shen et al.\n(2018) to recover phrase-structure trees based on proxies for \"syntactic\ndepth.\" These proxy depths are obtained from the representations learned by\nrecurrent language models augmented with mechanisms that encourage the\n(unsupervised) discovery of hierarchical structure latent in natural language\nsentences. Using the same parser, we show that proxies derived from a\nconventional LSTM language model produce trees comparably well to the\nspecialized architectures used in previous work. However, we also provide a\ndetailed analysis of the parsing algorithm, showing (1) that it is\nincomplete---that is, it can recover only a fraction of possible trees---and\n(2) that it has a marked bias for right-branching structures which results in\ninflated performance in right-branching languages like English. Our analysis\nshows that evaluating with biased parsing algorithms can inflate the apparent\nstructural competence of language models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 11:09:52 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Dyer", "Chris", ""], ["Melis", "G\u00e1bor", ""], ["Blunsom", "Phil", ""]]}, {"id": "1909.09432", "submitter": "SeyedAbolghasem Mirroshandel", "authors": "Erfan Miahi, Seyed Abolghasem Mirroshandel, Alexis Nasr", "title": "Genetic Neural Architecture Search for automatic assessment of human\n  sperm images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Male infertility is a disease which affects approximately 7% of men. Sperm\nmorphology analysis (SMA) is one of the main diagnosis methods for this\nproblem. Manual SMA is an inexact, subjective, non-reproducible, and hard to\nteach process. As a result, in this paper, we introduce a novel automatic SMA\nbased on a neural architecture search algorithm termed Genetic Neural\nArchitecture Search (GeNAS). For this purpose, we used a collection of images\ncalled MHSMA dataset contains 1,540 sperm images which have been collected from\n235 patients with infertility problems. GeNAS is a genetic algorithm that acts\nas a meta-controller which explores the constrained search space of plain\nconvolutional neural network architectures. Every individual of the genetic\nalgorithm is a convolutional neural network trained to predict morphological\ndeformities in different segments of human sperm (head, vacuole, and acrosome),\nand its fitness is calculated by a novel proposed method named GeNAS-WF\nespecially designed for noisy, low resolution, and imbalanced datasets. Also, a\nhashing method is used to save each trained neural architecture fitness, so we\ncould reuse them during fitness evaluation and speed up the algorithm. Besides,\nin terms of running time and computation power, our proposed architecture\nsearch method is far more efficient than most of the other existing neural\narchitecture search algorithms. Additionally, other proposed methods have been\nevaluated on balanced datasets, whereas GeNAS is built specifically for noisy,\nlow quality, and imbalanced datasets which are common in the field of medical\nimaging. In our experiments, the best neural architecture found by GeNAS has\nreached an accuracy of 91.66%, 77.33%, and 77.66% in the vacuole, head, and\nacrosome abnormality detection, respectively. In comparison to other proposed\nalgorithms for MHSMA dataset, GeNAS achieved state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 11:25:05 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 11:12:35 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Miahi", "Erfan", ""], ["Mirroshandel", "Seyed Abolghasem", ""], ["Nasr", "Alexis", ""]]}, {"id": "1909.09436", "submitter": "Miltiadis Allamanis", "authors": "Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, Marc\n  Brockschmidt", "title": "CodeSearchNet Challenge: Evaluating the State of Semantic Code Search", "comments": "Updated evaluation numbers after fixing indexing bug", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic code search is the task of retrieving relevant code given a natural\nlanguage query. While related to other information retrieval tasks, it requires\nbridging the gap between the language used in code (often abbreviated and\nhighly technical) and natural language more suitable to describe vague concepts\nand ideas.\n  To enable evaluation of progress on code search, we are releasing the\nCodeSearchNet Corpus and are presenting the CodeSearchNet Challenge, which\nconsists of 99 natural language queries with about 4k expert relevance\nannotations of likely results from CodeSearchNet Corpus. The corpus contains\nabout 6 million functions from open-source code spanning six programming\nlanguages (Go, Java, JavaScript, PHP, Python, and Ruby). The CodeSearchNet\nCorpus also contains automatically generated query-like natural language for 2\nmillion functions, obtained from mechanically scraping and preprocessing\nassociated function documentation. In this article, we describe the methodology\nused to obtain the corpus and expert labels, as well as a number of simple\nbaseline solutions for the task.\n  We hope that CodeSearchNet Challenge encourages researchers and practitioners\nto study this interesting task further and will host a competition and\nleaderboard to track the progress on the challenge. We are also keen on\nextending CodeSearchNet Challenge to more queries and programming languages in\nthe future.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 11:52:45 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 09:21:21 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 09:09:28 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Husain", "Hamel", ""], ["Wu", "Ho-Hsiang", ""], ["Gazit", "Tiferet", ""], ["Allamanis", "Miltiadis", ""], ["Brockschmidt", "Marc", ""]]}, {"id": "1909.09444", "submitter": "Hojjat Rakhshani", "authors": "Hojjat Rakhshani, Lhassane Idoumghar, Julien Lepagnot, and Mathieu\n  Brevilliers", "title": "From feature selection to continuous optimization", "comments": "Accepted for EA2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metaheuristic algorithms (MAs) have seen unprecedented growth thanks to their\nsuccessful applications in fields including engineering and health sciences. In\nthis work, we investigate the use of a deep learning (DL) model as an\nalternative tool to do so. The proposed method, called MaNet, is motivated by\nthe fact that most of the DL models often need to solve massive nasty\noptimization problems consisting of millions of parameters. Feature selection\nis the main adopted concepts in MaNet that helps the algorithm to skip\nirrelevant or partially relevant evolutionary information and uses those which\ncontribute most to the overall performance. The introduced model is applied on\nseveral unimodal and multimodal continuous problems. The experiments indicate\nthat MaNet is able to yield competitive results compared to one of the best\nhand-designed algorithms for the aforementioned problems, in terms of the\nsolution accuracy and scalability.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 12:13:27 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 09:49:30 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Rakhshani", "Hojjat", ""], ["Idoumghar", "Lhassane", ""], ["Lepagnot", "Julien", ""], ["Brevilliers", "Mathieu", ""]]}, {"id": "1909.09448", "submitter": "Kjetil Olsen Lye", "authors": "Kjetil O. Lye, Siddhartha Mishra, Roberto Molinaro", "title": "A Multi-level procedure for enhancing accuracy of machine learning\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-level method to increase the accuracy of machine learning\nalgorithms for approximating observables in scientific computing, particularly\nthose that arise in systems modeled by differential equations. The algorithm\nrelies on judiciously combining a large number of computationally cheap\ntraining data on coarse resolutions with a few expensive training samples on\nfine grid resolutions. Theoretical arguments for lowering the generalization\nerror, based on reducing the variance of the underlying maps, are provided and\nnumerical evidence, indicating significant gains over underlying single-level\nmachine learning algorithms, are presented. Moreover, we also apply the\nmulti-level algorithm in the context of forward uncertainty quantification and\nobserve a considerable speed-up over competing algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 12:21:14 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 13:00:12 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Lye", "Kjetil O.", ""], ["Mishra", "Siddhartha", ""], ["Molinaro", "Roberto", ""]]}, {"id": "1909.09453", "submitter": "Rahul Sucharitha", "authors": "Rahul Srinivas Sucharitha, Seokcheon Lee", "title": "Application of Clustering Analysis for Investigation of Food\n  Accessibility", "comments": "8 pages, 25th International Conference on Production Research\n  Manufacturing Innovation: Cyber Physical Manufacturing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to food assistance programs such as food pantries and food banks needs\nfocus in order to mitigate food insecurity. Accessibility to the food\nassistance programs is impacted by demographics of the population and geography\nof the location. It hence becomes imperative to define and identify food\nassistance deserts (Under-served areas) within a given region to find out the\nways to improve the accessibility of food. Food banks, the supplier of food to\nthe food agencies serving the people, can manage its resources more efficiently\nby targeting the food assistance deserts and increase the food supply in those\nregions. This paper will examine the characteristics and structure of the food\nassistance network in the region of Ohio by presenting the possible reasons of\nfood insecurity in this region and identify areas wherein food agencies are\nneeded or may not be needed. Gaussian Mixture Model (GMM) clustering technique\nis employed to identify the possible reasons and address this problem of food\naccessibility.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 18:09:45 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Sucharitha", "Rahul Srinivas", ""], ["Lee", "Seokcheon", ""]]}, {"id": "1909.09459", "submitter": "Qiang Zheng", "authors": "Qiang Zheng, Lingzao Zeng, Zhendan Cao, George Em Karniadakis", "title": "Physics-informed semantic inpainting: Application to geostatistical\n  modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in geostatistical modeling is to infer the\nheterogeneous geological field based on limited measurements and some prior\nspatial statistics. Semantic inpainting, a technique for image processing using\ndeep generative models, has been recently applied for this purpose,\ndemonstrating its effectiveness in dealing with complex spatial patterns.\nHowever, the original semantic inpainting framework incorporates only\ninformation from direct measurements, while in geostatistics indirect\nmeasurements are often plentiful. To overcome this limitation, here we propose\na physics-informed semantic inpainting framework, employing the Wasserstein\nGenerative Adversarial Network with Gradient Penalty (WGAN-GP) and jointly\nincorporating the direct and indirect measurements by exploiting the underlying\nphysical laws. Our simulation results for a high-dimensional problem with 512\ndimensions show that in the new method, the physical conservation laws are\nsatisfied and contribute in enhancing the inpainting performance compared to\nusing only the direct measurements.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 15:50:01 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 12:21:44 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Zheng", "Qiang", ""], ["Zeng", "Lingzao", ""], ["Cao", "Zhendan", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1909.09482", "submitter": "Christopher Ormerod", "authors": "Pedro Uria Rodriguez, Amir Jafari and Christopher M. Ormerod", "title": "Language models and Automated Essay Scoring", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new comparative study on automatic essay scoring\n(AES). The current state-of-the-art natural language processing (NLP) neural\nnetwork architectures are used in this work to achieve above human-level\naccuracy on the publicly available Kaggle AES dataset. We compare two powerful\nlanguage models, BERT and XLNet, and describe all the layers and network\narchitectures in these models. We elucidate the network architectures of BERT\nand XLNet using clear notation and diagrams and explain the advantages of\ntransformer architectures over traditional recurrent neural network\narchitectures. Linear algebra notation is used to clarify the functions of\ntransformers and attention mechanisms. We compare the results with more\ntraditional methods, such as bag of words (BOW) and long short term memory\n(LSTM) networks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 18:50:18 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Rodriguez", "Pedro Uria", ""], ["Jafari", "Amir", ""], ["Ormerod", "Christopher M.", ""]]}, {"id": "1909.09485", "submitter": "Iftitahu Ni'mah", "authors": "Iftitahu Ni'mah, Vlado Menkovski, Mykola Pechenizkiy", "title": "BSDAR: Beam Search Decoding with Attention Reward in Neural Keyphrase\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study mainly investigates two decoding problems in neural keyphrase\ngeneration: sequence length bias and beam diversity. We introduce an extension\nof beam search inference based on word-level and n-gram level attention score\nto adjust and constrain Seq2Seq prediction at test time. Results show that our\nproposed solution can overcome the algorithm bias to shorter and nearly\nidentical sequences, resulting in a significant improvement of the decoding\nperformance on generating keyphrases that are present and absent in source\ntext.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 18:44:54 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Ni'mah", "Iftitahu", ""], ["Menkovski", "Vlado", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1909.09490", "submitter": "Hussein Al-Natsheh", "authors": "Hesham Al-Bataineh, Wael Farhan, Ahmad Mustafa, Haitham Seelawi,\n  Hussein T. Al-Natsheh", "title": "Deep Contextualized Pairwise Semantic Similarity for Arabic Language\n  Questions", "comments": "Accepted at ICTAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question semantic similarity is a challenging and active research problem\nthat is very useful in many NLP applications, such as detecting duplicate\nquestions in community question answering platforms such as Quora. Arabic is\nconsidered to be an under-resourced language, has many dialects, and rich in\nmorphology. Combined together, these challenges make identifying semantically\nsimilar questions in Arabic even more difficult. In this paper, we introduce a\nnovel approach to tackle this problem, and test it on two benchmarks; one for\nModern Standard Arabic (MSA), and another for the 24 major Arabic dialects. We\nare able to show that our new system outperforms state-of-the-art approaches by\nachieving 93% F1-score on the MSA benchmark and 82% on the dialectical one.\nThis is achieved by utilizing contextualized word representations (ELMo\nembeddings) trained on a text corpus containing MSA and dialectic sentences.\nThis in combination with a pairwise fine-grained similarity layer, helps our\nquestion-to-question similarity model to generalize predictions on different\ndialects while being trained only on question-to-question MSA data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 11:58:18 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Al-Bataineh", "Hesham", ""], ["Farhan", "Wael", ""], ["Mustafa", "Ahmad", ""], ["Seelawi", "Haitham", ""], ["Al-Natsheh", "Hussein T.", ""]]}, {"id": "1909.09493", "submitter": "Pierre Gouedard", "authors": "Pierre Gouedard", "title": "On Recovering Latent Factors From Sampling And Firing Graph", "comments": "38 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": "01", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a set of latent factors whose observable effect of activation is\ncaught on a measure space that appears as a grid of bits tacking value in $\\{0,\n1 \\}$. This paper intend to deliver a theoretical and practical answer to the\nquestion: Given that we have access to a perfect indicator of the activation of\nlatent factors that label a finite dataset of grid's activity, can we imagine a\nprocedure to build a generic identificator of factor's activations ?\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 13:23:14 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Gouedard", "Pierre", ""]]}, {"id": "1909.09501", "submitter": "Mario Lezcano-Casado", "authors": "Mario Lezcano-Casado", "title": "Trivializations for Gradient-Based Optimization on Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a framework to study the transformation of problems with\nmanifold constraints into unconstrained problems through parametrizations in\nterms of a Euclidean space. We call these parametrizations \"trivializations\".\nWe prove conditions under which a trivialization is sound in the context of\ngradient-based optimization and we show how two large families of\ntrivializations have overall favorable properties, but also suffer from a\nperformance issue. We then introduce \"dynamic trivializations\", which solve\nthis problem, and we show how these form a family of optimization methods that\nlie between trivializations and Riemannian gradient descent, and combine the\nbenefits of both of them. We then show how to implement these two families of\ntrivializations in practice for different matrix manifolds. To this end, we\nprove a formula for the gradient of the exponential of matrices, which can be\nof practical interest on its own. Finally, we show how dynamic trivializations\nimprove the performance of existing methods on standard tasks designed to test\nlong-term memory within neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 13:41:43 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 19:42:08 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Lezcano-Casado", "Mario", ""]]}, {"id": "1909.09505", "submitter": "Keigo Matsumoto", "authors": "Yuchen Chang, Keigo Matsumoto, Takuji Narumi, Tomohiro Tanikawa, and\n  Michitaka Hirose", "title": "Redirection Controller Using Reinforcement Learning", "comments": "13 pages, 9 figures, IEEE Access under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing demand for planning redirected walking techniques and\napplying them to physical environments with obstacles. Such techniques are\nmainly managed using three kinds of methods: direct scripting, generalized\ncontroller, and physical- or virtual-environment analysis to determine user\nredirection. The first approach is effective when a user's path and both\nphysical and virtual environments are fixed; however, it is difficult to handle\nirregular movements and reuse other environments. The second approach has the\npotential of reusing any environment but is less optimized. The last approach\nis highly anticipated and versatile, although it has not been sufficiently\ndeveloped. In this study, we propose a novel redirection controller using\nreinforcement learning with advanced plannability/versatility. Our simulation\nexperiments show that the proposed strategy can reduce the number of resets by\n20.3% for physical-space conditions with multiple obstacles.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 13:49:50 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 03:49:44 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Chang", "Yuchen", ""], ["Matsumoto", "Keigo", ""], ["Narumi", "Takuji", ""], ["Tanikawa", "Tomohiro", ""], ["Hirose", "Michitaka", ""]]}, {"id": "1909.09524", "submitter": "Yunsu Kim", "authors": "Yunsu Kim, Petre Petrov, Pavel Petrushkov, Shahram Khadivi, Hermann\n  Ney", "title": "Pivot-based Transfer Learning for Neural Machine Translation between\n  Non-English Languages", "comments": "EMNLP 2019 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present effective pre-training strategies for neural machine translation\n(NMT) using parallel corpora involving a pivot language, i.e., source-pivot and\npivot-target, leading to a significant improvement in source-target\ntranslation. We propose three methods to increase the relation among source,\npivot, and target languages in the pre-training: 1) step-wise training of a\nsingle model for different language pairs, 2) additional adapter component to\nsmoothly connect pre-trained encoder and decoder, and 3) cross-lingual encoder\ntraining via autoencoding of the pivot language. Our methods greatly outperform\nmultilingual models up to +2.6% BLEU in WMT 2019 French-German and German-Czech\ntasks. We show that our improvements are valid also in zero-shot/zero-resource\nscenarios.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 14:16:27 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Kim", "Yunsu", ""], ["Petrov", "Petre", ""], ["Petrushkov", "Pavel", ""], ["Khadivi", "Shahram", ""], ["Ney", "Hermann", ""]]}, {"id": "1909.09534", "submitter": "Suzana Ilic", "authors": "Asir Saeed, Suzana Ili\\'c, Eva Zangerle", "title": "Creative GANs for generating poems, lyrics, and metaphors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models for text have substantially contributed to tasks like\nmachine translation and language modeling, using maximum likelihood\noptimization (MLE). However, for creative text generation, where multiple\noutputs are possible and originality and uniqueness are encouraged, MLE falls\nshort. Methods optimized for MLE lead to outputs that can be generic,\nrepetitive and incoherent. In this work, we use a Generative Adversarial\nNetwork framework to alleviate this problem. We evaluate our framework on\npoetry, lyrics and metaphor datasets, each with widely different\ncharacteristics, and report better performance of our objective function over\nother generative models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 14:40:18 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Saeed", "Asir", ""], ["Ili\u0107", "Suzana", ""], ["Zangerle", "Eva", ""]]}, {"id": "1909.09540", "submitter": "Shin-Ichi Maeda", "authors": "Shin-ichi Maeda, Hayato Watahiki, Shintarou Okada, Masanori Koyama", "title": "Reconnaissance and Planning algorithm for constrained MDP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practical reinforcement learning problems are often formulated as constrained\nMarkov decision process (CMDP) problems, in which the agent has to maximize the\nexpected return while satisfying a set of prescribed safety constraints. In\nthis study, we propose a novel simulator-based method to approximately solve a\nCMDP problem without making any compromise on the safety constraints. We\nachieve this by decomposing the CMDP into a pair of MDPs; reconnaissance MDP\nand planning MDP. The purpose of reconnaissance MDP is to evaluate the set of\nactions that are safe, and the purpose of planning MDP is to maximize the\nreturn while using the actions authorized by reconnaissance MDP. RMDP can\ndefine a set of safe policies for any given set of safety constraint, and this\nset of safe policies can be used to solve another CMDP problem with different\nreward. Our method is not only computationally less demanding than the previous\nsimulator-based approaches to CMDP, but also capable of finding a competitive\nreward-seeking policy in a high dimensional environment, including those\ninvolving multiple moving obstacles.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 14:44:36 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Maeda", "Shin-ichi", ""], ["Watahiki", "Hayato", ""], ["Okada", "Shintarou", ""], ["Koyama", "Masanori", ""]]}, {"id": "1909.09541", "submitter": "Farzad Khalvati", "authors": "Saman Motamed, Isha Gujrathi, Dominik Deniffel, Anton Oentoro, Masoom\n  A. Haider, Farzad Khalvati", "title": "A Transfer Learning Approach for Automated Segmentation of Prostate\n  Whole Gland and Transition Zone in Diffusion Weighted MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The segmentation of prostate whole gland and transition zone in Diffusion\nWeighted MRI (DWI) are the first step in designing computer-aided detection\nalgorithms for prostate cancer. However, variations in MRI acquisition\nparameters and scanner manufacturing result in different appearances of\nprostate tissue in the images. Convolutional neural networks (CNNs) which have\nshown to be successful in various medical image analysis tasks including\nsegmentation are typically sensitive to the variations in imaging parameters.\nThis sensitivity leads to poor segmentation performance of CNNs trained on a\nsource cohort and tested on a target cohort from a different scanner and hence,\nit limits the applicability of CNNs for cross-cohort training and testing.\nContouring prostate whole gland and transition zone in DWI images are\ntime-consuming and expensive. Thus, it is important to enable CNNs pretrained\non images of source domain, to segment images of target domain with minimum\nrequirement for manual segmentation of images from the target domain. In this\nwork, we propose a transfer learning method based on a modified U-net\narchitecture and loss function, for segmentation of prostate whole gland and\ntransition zone in DWIs using a CNN pretrained on a source dataset and tested\non the target dataset. We explore the effect of the size of subset of target\ndataset used for fine-tuning the pre-trained CNN on the overall segmentation\naccuracy. Our results show that with a fine-tuning data as few as 30 patients\nfrom the target domain, the proposed transfer learning-based algorithm can\nreach dice score coefficient of 0.80 for both prostate whole gland and\ntransition zone segmentation. Using a fine-tuning data of 115 patients from the\ntarget domain, dice score coefficient of 0.85 and 0.84 are achieved for\nsegmentation of whole gland and transition zone, respectively, in the target\ndomain.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 14:44:50 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 15:45:32 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Motamed", "Saman", ""], ["Gujrathi", "Isha", ""], ["Deniffel", "Dominik", ""], ["Oentoro", "Anton", ""], ["Haider", "Masoom A.", ""], ["Khalvati", "Farzad", ""]]}, {"id": "1909.09552", "submitter": "Tong Wu", "authors": "Tong Wu, Liang Tong, Yevgeniy Vorobeychik", "title": "Defending Against Physically Realizable Attacks on Image Classification", "comments": "camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of defending deep neural network approaches for image\nclassification from physically realizable attacks. First, we demonstrate that\nthe two most scalable and effective methods for learning robust models,\nadversarial training with PGD attacks and randomized smoothing, exhibit very\nlimited effectiveness against three of the highest profile physical attacks.\nNext, we propose a new abstract adversarial model, rectangular occlusion\nattacks, in which an adversary places a small adversarially crafted rectangle\nin an image, and develop two approaches for efficiently computing the resulting\nadversarial examples. Finally, we demonstrate that adversarial training using\nour new attack yields image classification models that exhibit high robustness\nagainst the physically realizable attacks we study, offering the first\neffective generic defense against such attacks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 15:11:09 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 20:07:55 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wu", "Tong", ""], ["Tong", "Liang", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1909.09557", "submitter": "Shigehiko Schamoni", "authors": "Shigehiko Schamoni, Holger A. Lindner, Verena Schneider-Lindner,\n  Manfred Thiel, Stefan Riezler", "title": "Leveraging Implicit Expert Knowledge for Non-Circular Machine Learning\n  in Sepsis Prediction", "comments": "Accepted for publication in Journal of Artificial Intelligence in\n  Medicine", "journal-ref": "Artificial Intelligence in Medicine, Volume 100, September 2019,\n  Pages 101725", "doi": "10.1016/j.artmed.2019.101725", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is the leading cause of death in non-coronary intensive care units.\nMoreover, a delay of antibiotic treatment of patients with severe sepsis by\nonly few hours is associated with increased mortality. This insight makes\naccurate models for early prediction of sepsis a key task in machine learning\nfor healthcare. Previous approaches have achieved high AUROC by learning from\nelectronic health records where sepsis labels were defined automatically\nfollowing established clinical criteria. We argue that the practice of\nincorporating the clinical criteria that are used to automatically define\nground truth sepsis labels as features of severity scoring models is inherently\ncircular and compromises the validity of the proposed approaches. We propose to\ncreate an independent ground truth for sepsis research by exploiting implicit\nknowledge of clinical practitioners via an electronic questionnaire which\nrecords attending physicians' daily judgements of patients' sepsis status. We\nshow that despite its small size, our dataset allows to achieve\nstate-of-the-art AUROC scores. An inspection of learned weights for\nstandardized features of the linear model lets us infer potentially surprising\nfeature contributions and allows to interpret seemingly counterintuitive\nfindings.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 15:20:09 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Schamoni", "Shigehiko", ""], ["Lindner", "Holger A.", ""], ["Schneider-Lindner", "Verena", ""], ["Thiel", "Manfred", ""], ["Riezler", "Stefan", ""]]}, {"id": "1909.09563", "submitter": "Jialin Liu", "authors": "Jialin Liu, Chih-Min Lin and Fei Chao", "title": "Gradient Boost with Convolution Neural Network for Stock Forecast", "comments": "UKCL2019.11pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Market economy closely connects aspects to all walks of life. The stock\nforecast is one of task among studies on the market economy. However,\ninformation on markets economy contains a lot of noise and uncertainties, which\nlead economy forecasting to become a challenging task. Ensemble learning and\ndeep learning are the most methods to solve the stock forecast task. In this\npaper, we present a model combining the advantages of two methods to forecast\nthe change of stock price. The proposed method combines CNN and GBoost. The\nexperimental results on six market indexes show that the proposed method has\nbetter performance against current popular methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 13:58:49 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Liu", "Jialin", ""], ["Lin", "Chih-Min", ""], ["Chao", "Fei", ""]]}, {"id": "1909.09569", "submitter": "Yao Shu", "authors": "Yao Shu, Wei Wang and Shaofeng Cai", "title": "Understanding Architectures Learnt by Cell-based Neural Architecture\n  Search", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) searches architectures automatically for\ngiven tasks, e.g., image classification and language modeling. Improving the\nsearch efficiency and effectiveness have attracted increasing attention in\nrecent years. However, few efforts have been devoted to understanding the\ngenerated architectures. In this paper, we first reveal that existing NAS\nalgorithms (e.g., DARTS, ENAS) tend to favor architectures with wide and\nshallow cell structures. These favorable architectures consistently achieve\nfast convergence and are consequently selected by NAS algorithms. Our empirical\nand theoretical study further confirms that their fast convergence derives from\ntheir smooth loss landscape and accurate gradient information. Nonetheless,\nthese architectures may not necessarily lead to better generalization\nperformance compared with other candidate architectures in the same search\nspace, and therefore further improvement is possible by revising existing NAS\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 15:49:45 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 12:14:40 GMT"}, {"version": "v3", "created": "Wed, 1 Jan 2020 13:57:23 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Shu", "Yao", ""], ["Wang", "Wei", ""], ["Cai", "Shaofeng", ""]]}, {"id": "1909.09571", "submitter": "Angelos Filos", "authors": "Angelos Filos", "title": "Reinforcement Learning for Portfolio Management", "comments": "Imperial College London MEng Thesis 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this thesis, we develop a comprehensive account of the expressive power,\nmodelling efficiency, and performance advantages of so-called trading agents\n(i.e., Deep Soft Recurrent Q-Network (DSRQN) and Mixture of Score Machines\n(MSM)), based on both traditional system identification (model-based approach)\nas well as on context-independent agents (model-free approach). The analysis\nprovides conclusive support for the ability of model-free reinforcement\nlearning methods to act as universal trading agents, which are not only capable\nof reducing the computational and memory complexity (owing to their linear\nscaling with the size of the universe), but also serve as generalizing\nstrategies across assets and markets, regardless of the trading universe on\nwhich they have been trained. The relatively low volume of daily returns in\nfinancial market data is addressed via data augmentation (a generative\napproach) and a choice of pre-training strategies, both of which are validated\nagainst current state-of-the-art models. For rigour, a risk-sensitive framework\nwhich includes transaction costs is considered, and its performance advantages\nare demonstrated in a variety of scenarios, from synthetic time-series\n(sinusoidal, sawtooth and chirp waves), simulated market series (surrogate data\nbased), through to real market data (S\\&P 500 and EURO STOXX 50). The analysis\nand simulations confirm the superiority of universal model-free reinforcement\nlearning agents over current portfolio management model in asset allocation\nstrategies, with the achieved performance advantage of as much as 9.2\\% in\nannualized cumulative returns and 13.4\\% in annualized Sharpe Ratio.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:28:24 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Filos", "Angelos", ""]]}, {"id": "1909.09577", "submitter": "Oleksii Kuchaiev", "authors": "Oleksii Kuchaiev, Jason Li, Huyen Nguyen, Oleksii Hrinchuk, Ryan\n  Leary, Boris Ginsburg, Samuel Kriman, Stanislav Beliaev, Vitaly Lavrukhin,\n  Jack Cook, Patrice Castonguay, Mariya Popova, Jocelyn Huang, Jonathan M.\n  Cohen", "title": "NeMo: a toolkit for building AI applications using Neural Modules", "comments": "6 pages plus references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NeMo (Neural Modules) is a Python framework-agnostic toolkit for creating AI\napplications through re-usability, abstraction, and composition. NeMo is built\naround neural modules, conceptual blocks of neural networks that take typed\ninputs and produce typed outputs. Such modules typically represent data layers,\nencoders, decoders, language models, loss functions, or methods of combining\nactivations. NeMo makes it easy to combine and re-use these building blocks\nwhile providing a level of semantic correctness checking via its neural type\nsystem. The toolkit comes with extendable collections of pre-built modules for\nautomatic speech recognition and natural language processing. Furthermore, NeMo\nprovides built-in support for distributed training and mixed precision on\nlatest NVIDIA GPUs. NeMo is open-source https://github.com/NVIDIA/NeMo\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 03:51:46 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Kuchaiev", "Oleksii", ""], ["Li", "Jason", ""], ["Nguyen", "Huyen", ""], ["Hrinchuk", "Oleksii", ""], ["Leary", "Ryan", ""], ["Ginsburg", "Boris", ""], ["Kriman", "Samuel", ""], ["Beliaev", "Stanislav", ""], ["Lavrukhin", "Vitaly", ""], ["Cook", "Jack", ""], ["Castonguay", "Patrice", ""], ["Popova", "Mariya", ""], ["Huang", "Jocelyn", ""], ["Cohen", "Jonathan M.", ""]]}, {"id": "1909.09586", "submitter": "Ralf C. Staudemeyer", "authors": "Ralf C. Staudemeyer and Eric Rothstein Morris", "title": "Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent\n  Neural Networks", "comments": "42 pages, 11 figures, tutorial", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) are one of the\nmost powerful dynamic classifiers publicly known. The network itself and the\nrelated learning algorithms are reasonably well documented to get an idea how\nit works. This paper will shed more light into understanding how LSTM-RNNs\nevolved and why they work impressively well, focusing on the early,\nground-breaking publications. We significantly improved documentation and fixed\na number of errors and inconsistencies that accumulated in previous\npublications. To support understanding we as well revised and unified the\nnotation used.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 15:44:51 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Staudemeyer", "Ralf C.", ""], ["Morris", "Eric Rothstein", ""]]}, {"id": "1909.09587", "submitter": "Tsung-Yuan Hsu", "authors": "Tsung-yuan Hsu, Chi-liang Liu, Hung-yi Lee", "title": "Zero-shot Reading Comprehension by Cross-lingual Transfer Learning with\n  Multi-lingual Language Representation Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because it is not feasible to collect training data for every language, there\nis a growing interest in cross-lingual transfer learning. In this paper, we\nsystematically explore zero-shot cross-lingual transfer learning on reading\ncomprehension tasks with a language representation model pre-trained on\nmulti-lingual corpus. The experimental results show that with pre-trained\nlanguage representation zero-shot learning is feasible, and translating the\nsource data into the target language is not necessary and even degrades the\nperformance. We further explore what does the model learn in zero-shot setting.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 10:33:05 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Hsu", "Tsung-yuan", ""], ["Liu", "Chi-liang", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1909.09588", "submitter": "Rene Schaub", "authors": "Rene Schaub", "title": "What are Neural Networks made of?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of Deep Learning methods is not well understood, though various\nattempts at explaining it have been made, typically centered on properties of\nstochastic gradient descent. Even less clear is why certain neural network\narchitectures perform better than others. We provide a potential opening with\nthe hypothesis that neural network training is a form of Genetic Programming.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 21:59:26 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Schaub", "Rene", ""]]}, {"id": "1909.09593", "submitter": "Vu Nguyen", "authors": "Vu Nguyen and Sebastian Schulze and Michael A Osborne", "title": "Bayesian Optimization for Iterative Learning", "comments": "Camera ready NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of deep (reinforcement) learning systems crucially depends on\nthe choice of hyperparameters. Their tuning is notoriously expensive, typically\nrequiring an iterative training process to run for numerous steps to\nconvergence. Traditional tuning algorithms only consider the final performance\nof hyperparameters acquired after many expensive iterations and ignore\nintermediate information from earlier training steps. In this paper, we present\na Bayesian optimization (BO) approach which exploits the iterative structure of\nlearning algorithms for efficient hyperparameter tuning. We propose to learn an\nevaluation function compressing learning progress at any stage of the training\nprocess into a single numeric score according to both training success and\nstability. Our BO framework is then balancing the benefit of assessing a\nhyperparameter setting over additional training steps against their computation\ncost. We further increase model efficiency by selectively including scores from\ndifferent training steps for any evaluated hyperparameter set. We demonstrate\nthe efficiency of our algorithm by tuning hyperparameters for the training of\ndeep reinforcement learning agents and convolutional neural networks. Our\nalgorithm outperforms all existing baselines in identifying optimal\nhyperparameters in minimal time.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 16:14:34 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 13:48:56 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 21:15:58 GMT"}, {"version": "v4", "created": "Thu, 18 Jun 2020 16:10:30 GMT"}, {"version": "v5", "created": "Sat, 16 Jan 2021 11:42:27 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Nguyen", "Vu", ""], ["Schulze", "Sebastian", ""], ["Osborne", "Michael A", ""]]}, {"id": "1909.09595", "submitter": "Cheonbok  Park", "authors": "Cheonbok Park, Inyoup Na, Yongjang Jo, Sungbok Shin, Jaehyo Yoo, Bum\n  Chul Kwon, Jian Zhao, Hyungjong Noh, Yeonsoo Lee, Jaegul Choo", "title": "SANVis: Visual Analytics for Understanding Self-Attention Networks", "comments": "VAST Short - IEEE VIS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention networks, a deep neural network architecture inspired by humans'\nattention mechanism, have seen significant success in image captioning, machine\ntranslation, and many other applications. Recently, they have been further\nevolved into an advanced approach called multi-head self-attention networks,\nwhich can encode a set of input vectors, e.g., word vectors in a sentence, into\nanother set of vectors. Such encoding aims at simultaneously capturing diverse\nsyntactic and semantic features within a set, each of which corresponds to a\nparticular attention head, forming altogether multi-head attention. Meanwhile,\nthe increased model complexity prevents users from easily understanding and\nmanipulating the inner workings of models. To tackle the challenges, we present\na visual analytics system called SANVis, which helps users understand the\nbehaviors and the characteristics of multi-head self-attention networks. Using\na state-of-the-art self-attention model called Transformer, we demonstrate\nusage scenarios of SANVis in machine translation tasks. Our system is available\nat http://short.sanvis.org\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 05:59:40 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Park", "Cheonbok", ""], ["Na", "Inyoup", ""], ["Jo", "Yongjang", ""], ["Shin", "Sungbok", ""], ["Yoo", "Jaehyo", ""], ["Kwon", "Bum Chul", ""], ["Zhao", "Jian", ""], ["Noh", "Hyungjong", ""], ["Lee", "Yeonsoo", ""], ["Choo", "Jaegul", ""]]}, {"id": "1909.09596", "submitter": "Konstantinos Nikolakakis", "authors": "Konstantinos E. Nikolakakis, Dionysios S. Kalogerias, Anand D. Sarwate", "title": "Optimal Rates for Learning Hidden Tree Structures", "comments": "33 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide high probability finite sample complexity guarantees for hidden\nnon-parametric structure learning of tree-shaped graphical models, whose hidden\nand observable nodes are discrete random variables with either finite or\ncountable alphabets. We study a fundamental quantity called the (noisy)\ninformation threshold, which arises naturally from the error analysis of the\nChow-Liu algorithm and, as we discuss, provides explicit necessary and\nsufficient conditions on sample complexity, by effectively summarizing the\ndifficulty of the tree-structure learning problem. Specifically, we show that\nthe finite sample complexity of the Chow-Liu algorithm for ensuring exact\nstructure recovery from noisy data is inversely proportional to the information\nthreshold squared (provided it is positive), and scales almost logarithmically\nrelative to the number of nodes over a given probability of failure.\nConversely, we show that, if the number of samples is less than an absolute\nconstant times the inverse of information threshold squared, then no algorithm\ncan recover the hidden tree structure with probability greater than one half.\nAs a consequence, our upper and lower bounds match with respect to the\ninformation threshold, indicating that it is a fundamental quantity for the\nproblem of learning hidden tree-structured models. Further, the Chow-Liu\nalgorithm with noisy data as input achieves the optimal rate with respect to\nthe information threshold. Lastly, as a byproduct of our analysis, we resolve\nthe problem of tree structure learning in the presence of non-identically\ndistributed observation noise, providing conditions for convergence of the\nChow-Liu algorithm under this setting, as well.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 16:18:26 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 23:19:15 GMT"}, {"version": "v3", "created": "Sun, 7 Mar 2021 17:47:58 GMT"}, {"version": "v4", "created": "Wed, 31 Mar 2021 17:36:48 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Nikolakakis", "Konstantinos E.", ""], ["Kalogerias", "Dionysios S.", ""], ["Sarwate", "Anand D.", ""]]}, {"id": "1909.09598", "submitter": "Heon Lee", "authors": "Samuel Yu, Heon Lee, Jung Hoon Kim", "title": "Street Crossing Aid Using Light-weight CNNs for the Visually Impaired", "comments": "10 pages, 5 figures, 7 tables, ICCV 2019 - 7th International Workshop\n  on Assistive Computer Vision and Robotics (ACVR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we address an issue that the visually impaired commonly face\nwhile crossing intersections and propose a solution that takes form as a mobile\napplication. The application utilizes a deep learning convolutional neural\nnetwork model, LytNetV2, to output necessary information that the visually\nimpaired may lack when without human companions or guide-dogs. A prototype of\nthe application runs on iOS devices of versions 11 or above. It is designed for\ncomprehensiveness, concision, accuracy, and computational efficiency through\ndelivering the two most important pieces of information, pedestrian traffic\nlight color and direction, required to cross the road in real-time.\nFurthermore, it is specifically aimed to support those facing financial burden\nas the solution takes the form of a free mobile application. Through the\nmodification and utilization of key principles in MobileNetV3 such as depthwise\nseperable convolutions and squeeze-excite layers, the deep neural network model\nachieves a classification accuracy of 96% and average angle error of 6.15\ndegrees, while running at a frame rate of 16.34 frames per second.\nAdditionally, the model is trained as an image classifier, allowing for a\nfaster and more accurate model. The network is able to outperform other methods\nsuch as object detection and non-deep learning algorithms in both accuracy and\nthoroughness. The information is delivered through both auditory signals and\nvibrations, and it has been tested on seven visually impaired and has received\nabove satisfactory responses.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 11:29:33 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Yu", "Samuel", ""], ["Lee", "Heon", ""], ["Kim", "Jung Hoon", ""]]}, {"id": "1909.09602", "submitter": "Brian Hutchinson", "authors": "Chris Careaga, Brian Hutchinson, Nathan Hodas and Lawrence Phillips", "title": "Metric-Based Few-Shot Learning for Video Action Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the few-shot scenario, a learner must effectively generalize to unseen\nclasses given a small support set of labeled examples. While a relatively large\namount of research has gone into few-shot learning for image classification,\nlittle work has been done on few-shot video classification. In this work, we\naddress the task of few-shot video action recognition with a set of two-stream\nmodels. We evaluate the performance of a set of convolutional and recurrent\nneural network video encoder architectures used in conjunction with three\npopular metric-based few-shot algorithms. We train and evaluate using a\nfew-shot split of the Kinetics 600 dataset. Our experiments confirm the\nimportance of the two-stream setup, and find prototypical networks and pooled\nlong short-term memory network embeddings to give the best performance as\nfew-shot method and video encoder, respectively. For a 5-shot 5-way task, this\nsetup obtains 84.2% accuracy on the test set and 59.4% on a special \"challenge\"\ntest set, composed of highly confusable classes.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 17:53:16 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Careaga", "Chris", ""], ["Hutchinson", "Brian", ""], ["Hodas", "Nathan", ""], ["Phillips", "Lawrence", ""]]}, {"id": "1909.09621", "submitter": "Elena Smirnova", "authors": "Elena Smirnova and Elvis Dohmatob", "title": "On the Convergence of Approximate and Regularized Policy Iteration\n  Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy regularized algorithms such as Soft Q-learning and Soft Actor-Critic,\nrecently showed state-of-the-art performance on a number of challenging\nreinforcement learning (RL) tasks. The regularized formulation modifies the\nstandard RL objective and thus generally converges to a policy different from\nthe optimal greedy policy of the original RL problem. Practically, it is\nimportant to control the sub-optimality of the regularized optimal policy. In\nthis paper, we establish sufficient conditions for convergence of a large class\nof regularized dynamic programming algorithms, unified under regularized\nmodified policy iteration (MPI) and conservative value iteration (VI) schemes.\nWe provide explicit convergence rates to the optimality depending on the\ndecrease rate of the regularization parameter. Our experiments show that the\nempirical error closely follows the established theoretical convergence rates.\nIn addition to optimality, we demonstrate two desirable behaviours of the\nregularized algorithms even in the absence of approximations: robustness to\nstochasticity of environment and safety of trajectories induced by the policy\niterates.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 17:13:59 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 12:04:49 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Smirnova", "Elena", ""], ["Dohmatob", "Elvis", ""]]}, {"id": "1909.09638", "submitter": "Sobhan Moosavi", "authors": "Sobhan Moosavi, Mohammad Hossein Samavatian, Srinivasan Parthasarathy,\n  Radu Teodorescu, Rajiv Ramnath", "title": "Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset\n  and Insights", "comments": "In Proceedings of the 27th ACM SIGSPATIAL, International Conference\n  on Advances in Geographic Information Systems (2019). arXiv admin note:\n  substantial text overlap with arXiv:1906.05409", "journal-ref": null, "doi": "10.1145/3347146.3359078", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing traffic accidents is an important public safety challenge,\ntherefore, accident analysis and prediction has been a topic of much research\nover the past few decades. Using small-scale datasets with limited coverage,\nbeing dependent on extensive set of data, and being not applicable for\nreal-time purposes are the important shortcomings of the existing studies. To\naddress these challenges, we propose a new solution for real-time traffic\naccident prediction using easy-to-obtain, but sparse data. Our solution relies\non a deep-neural-network model (which we have named DAP, for Deep Accident\nPrediction); which utilizes a variety of data attributes such as traffic\nevents, weather data, points-of-interest, and time. DAP incorporates multiple\ncomponents including a recurrent (for time-sensitive data), a fully connected\n(for time-insensitive data), and a trainable embedding component (to capture\nspatial heterogeneity). To fill the data gap, we have - through a comprehensive\nprocess of data collection, integration, and augmentation - created a\nlarge-scale publicly available database of accident information named\nUS-Accidents. By employing the US-Accidents dataset and through an extensive\nset of experiments across several large cities, we have evaluated our proposal\nagainst several baselines. Our analysis and results show significant\nimprovements to predict rare accident events. Further, we have shown the impact\nof traffic information, time, and points-of-interest data for real-time\naccident prediction.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 22:41:41 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Moosavi", "Sobhan", ""], ["Samavatian", "Mohammad Hossein", ""], ["Parthasarathy", "Srinivasan", ""], ["Teodorescu", "Radu", ""], ["Ramnath", "Rajiv", ""]]}, {"id": "1909.09656", "submitter": "Arber Zela", "authors": "Arber Zela, Thomas Elsken, Tonmoy Saikia, Yassine Marrakchi, Thomas\n  Brox, Frank Hutter", "title": "Understanding and Robustifying Differentiable Architecture Search", "comments": "In: International Conference on Learning Representations (ICLR 2020);\n  28 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable Architecture Search (DARTS) has attracted a lot of attention\ndue to its simplicity and small search costs achieved by a continuous\nrelaxation and an approximation of the resulting bi-level optimization problem.\nHowever, DARTS does not work robustly for new problems: we identify a wide\nrange of search spaces for which DARTS yields degenerate architectures with\nvery poor test performance. We study this failure mode and show that, while\nDARTS successfully minimizes validation loss, the found solutions generalize\npoorly when they coincide with high validation loss curvature in the\narchitecture space. We show that by adding one of various types of\nregularization we can robustify DARTS to find solutions with less curvature and\nbetter generalization properties. Based on these observations, we propose\nseveral simple variations of DARTS that perform substantially more robustly in\npractice. Our observations are robust across five search spaces on three image\nclassification tasks and also hold for the very different domains of disparity\nestimation (a dense regression task) and language modelling.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 18:03:06 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 14:14:05 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Zela", "Arber", ""], ["Elsken", "Thomas", ""], ["Saikia", "Tonmoy", ""], ["Marrakchi", "Yassine", ""], ["Brox", "Thomas", ""], ["Hutter", "Frank", ""]]}, {"id": "1909.09667", "submitter": "Anand Rajagopalan", "authors": "Aditya Krishna Menon, Anand Rajagopalan, Baris Sumengen, Gui Citovsky,\n  Qin Cao, Sanjiv Kumar", "title": "Online Hierarchical Clustering Approximations", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Hierarchical clustering is a widely used approach for clustering datasets at\nmultiple levels of granularity. Despite its popularity, existing algorithms\nsuch as hierarchical agglomerative clustering (HAC) are limited to the offline\nsetting, and thus require the entire dataset to be available. This prohibits\ntheir use on large datasets commonly encountered in modern learning\napplications. In this paper, we consider hierarchical clustering in the online\nsetting, where points arrive one at a time. We propose two algorithms that seek\nto optimize the Moseley and Wang (MW) revenue function, a variant of the\nDasgupta cost. These algorithms offer different tradeoffs between efficiency\nand MW revenue performance. The first algorithm, OTD, is a highly efficient\nOnline Top Down algorithm which provably achieves a 1/3-approximation to the MW\nrevenue under a data separation assumption. The second algorithm, OHAC, is an\nonline counterpart to offline HAC, which is known to yield a 1/3-approximation\nto the MW revenue, and produce good quality clusters in practice. We show that\nOHAC approximates offline HAC by leveraging a novel split-merge procedure. We\nempirically show that OTD and OHAC offer significant efficiency and cluster\nquality gains respectively over baselines.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 18:29:59 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Menon", "Aditya Krishna", ""], ["Rajagopalan", "Anand", ""], ["Sumengen", "Baris", ""], ["Citovsky", "Gui", ""], ["Cao", "Qin", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1909.09690", "submitter": "Hossein Keshavarz", "authors": "Hossein Keshavarz, Shohreh Tabatabayi Seifi, Mohammad Izadi", "title": "A Deep Learning-Based Approach for Measuring the Domain Similarity of\n  Persian Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach for measuring the degree of\nsimilarity between categories of two pieces of Persian text, which were\npublished as descriptions of two separate advertisements. We built an\nappropriate dataset for this work using a dataset which consists of\nadvertisements posted on an e-commerce website. We generated a significant\nnumber of paired texts from this dataset and assigned each pair a score from 0\nto 3, which demonstrates the degree of similarity between the domains of the\npair. In this work, we represent words with word embedding vectors derived from\nword2vec. Then deep neural network models are used to represent texts.\nEventually, we employ concatenation of absolute difference and bit-wise\nmultiplication and a fully-connected neural network to produce a probability\ndistribution vector for the score of the pairs. Through a supervised learning\napproach, we trained our model on a GPU, and our best model achieved an F1\nscore of 0.9865.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 16:29:14 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 06:20:11 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Keshavarz", "Hossein", ""], ["Seifi", "Shohreh Tabatabayi", ""], ["Izadi", "Mohammad", ""]]}, {"id": "1909.09691", "submitter": "Hussein Al-Natsheh", "authors": "Haitham Seelawi, Ahmad Mustafa, Hesham Al-Bataineh, Wael Farhan,\n  Hussein T. Al-Natsheh", "title": "NSURL-2019 Shared Task 8: Semantic Question Similarity in Arabic", "comments": "8 pages, 2 figure, 3 tables, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question semantic similarity (Q2Q) is a challenging task that is very useful\nin many NLP applications, such as detecting duplicate questions and question\nanswering systems. In this paper, we present the results and findings of the\nshared task (Semantic Question Similarity in Arabic). The task was organized as\npart of the first workshop on NLP Solutions for Under Resourced Languages\n(NSURL 2019) The goal of the task is to predict whether two questions are\nsemantically similar or not, even if they are phrased differently. A total of 9\nteams participated in the task. The datasets created for this task are made\npublicly available to support further research on Arabic Q2Q.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:45:43 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Seelawi", "Haitham", ""], ["Mustafa", "Ahmad", ""], ["Al-Bataineh", "Hesham", ""], ["Farhan", "Wael", ""], ["Al-Natsheh", "Hussein T.", ""]]}, {"id": "1909.09699", "submitter": "Khyathi Raghavi Chandu", "authors": "Ruo-Ping Dong, Khyathi Raghavi Chandu, Alan W Black", "title": "Induction and Reference of Entities in a Visual Story", "comments": "9 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are enveloped by stories of visual interpretations in our everyday lives.\nThe way we narrate a story often comprises of two stages, which are, forming a\ncentral mind map of entities and then weaving a story around them. A\ncontributing factor to coherence is not just basing the story on these entities\nbut also, referring to them using appropriate terms to avoid repetition. In\nthis paper, we address these two stages of introducing the right entities at\nseemingly reasonable junctures and also referring them coherently in the\ncontext of visual storytelling. The building blocks of the central mind map,\nalso known as entity skeleton are entity chains including nominal and\ncoreference expressions. This entity skeleton is also represented in different\nlevels of abstractions to compose a generalized frame to weave the story. We\nbuild upon an encoder-decoder framework to penalize the model when the decoded\nstory does not adhere to this entity skeleton. We establish a strong baseline\nfor skeleton informed generation and then extend this to have the capability of\nmultitasking by predicting the skeleton in addition to generating the story.\nFinally, we build upon this model and propose a glocal hierarchical attention\nmodel that attends to the skeleton both at the sentence (local) and the story\n(global) levels. We observe that our proposed models outperform the baseline in\nterms of automatic evaluation metric, METEOR. We perform various analysis\ntargeted to evaluate the performance of our task of enforcing the entity\nskeleton such as the number and diversity of the entities generated. We also\nconduct human evaluation from which it is concluded that the visual stories\ngenerated by our model are preferred 82% of the times. In addition, we show\nthat our glocal hierarchical attention model improves coherence by introducing\nmore pronouns as required by the presence of nouns.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 01:09:01 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Dong", "Ruo-Ping", ""], ["Chandu", "Khyathi Raghavi", ""], ["Black", "Alan W", ""]]}, {"id": "1909.09702", "submitter": "Karan Aggarwal", "authors": "Swaraj Khadanga, Karan Aggarwal, Shafiq Joty, Jaideep Srivastava", "title": "Using Clinical Notes with Time Series Data for ICU Management", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring patients in ICU is a challenging and high-cost task. Hence,\npredicting the condition of patients during their ICU stay can help provide\nbetter acute care and plan the hospital's resources. There has been continuous\nprogress in machine learning research for ICU management, and most of this work\nhas focused on using time series signals recorded by ICU instruments. In our\nwork, we show that adding clinical notes as another modality improves the\nperformance of the model for three benchmark tasks: in-hospital mortality\nprediction, modeling decompensation, and length of stay forecasting that play\nan important role in ICU management. While the time-series data is measured at\nregular intervals, doctor notes are charted at irregular times, making it\nchallenging to model them together. We propose a method to model them jointly,\nachieving considerable improvement across benchmark tasks over baseline\ntime-series model. Our implementation can be found at\n\\url{https://github.com/kaggarwal/ClinicalNotesICU}.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 04:27:32 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 18:21:02 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Khadanga", "Swaraj", ""], ["Aggarwal", "Karan", ""], ["Joty", "Shafiq", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "1909.09704", "submitter": "Stefan Hosein", "authors": "Stefan Hosein, Daniel Andor, and Ryan McDonald", "title": "Measuring Domain Portability and ErrorPropagation in Biomedical QA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we present Google's submission to the BioASQ 7 biomedical\nquestion answering (QA) task (specifically Task 7b, Phase B). The core of our\nsystems are based on BERT QA models, specifically the model of\n\\cite{alberti2019bert}. In this report, and via our submissions, we aimed to\ninvestigate two research questions. We start by studying how domain portable\nare QA systems that have been pre-trained and fine-tuned on general texts,\ne.g., Wikipedia. We measure this via two submissions. The first is a\nnon-adapted model that uses a public pre-trained BERT model and is fine-tuned\non the Natural Questions data set \\cite{kwiatkowski2019natural}. The second\nsystem takes this non-adapted model and fine-tunes it with the BioASQ training\ndata. Next, we study the impact of error propagation in end-to-end retrieval\nand QA systems. Again we test this via two submissions. The first uses human\nannotated relevant documents and snippets as input to the model and the second\npredicted documents and snippets. Our main findings are that domain specific\nfine-tuning can benefit Biomedical QA. However, the biggest quality bottleneck\nis at the retrieval stage, where we see large drops in metrics -- over 10pts\nabsolute -- when using non gold inputs to the QA model.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 17:25:24 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 09:23:45 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Hosein", "Stefan", ""], ["Andor", "Daniel", ""], ["McDonald", "Ryan", ""]]}, {"id": "1909.09705", "submitter": "Hossein K. Mousavi", "authors": "Hossein K. Mousavi, Guangyi Liu, Weihang Yuan, Martin Tak\\'a\\v{c},\n  H\\'ector Mu\\~noz-Avila, Nader Motee", "title": "A Layered Architecture for Active Perception: Image Classification using\n  Deep Reinforcement Learning", "comments": "Submitted to ICRA-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a planning and perception mechanism for a robot (agent), that can\nonly observe the underlying environment partially, in order to solve an image\nclassification problem. A three-layer architecture is suggested that consists\nof a meta-layer that decides the intermediate goals, an action-layer that\nselects local actions as the agent navigates towards a goal, and a\nclassification-layer that evaluates the reward and makes a prediction. We\ndesign and implement these layers using deep reinforcement learning. A\ngeneralized policy gradient algorithm is utilized to learn the parameters of\nthese layers to maximize the expected reward. Our proposed methodology is\ntested on the MNIST dataset of handwritten digits, which provides us with a\nlevel of explainability while interpreting the agent's intermediate goals and\ncourse of action.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 19:52:41 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Mousavi", "Hossein K.", ""], ["Liu", "Guangyi", ""], ["Yuan", "Weihang", ""], ["Tak\u00e1\u010d", "Martin", ""], ["Mu\u00f1oz-Avila", "H\u00e9ctor", ""], ["Motee", "Nader", ""]]}, {"id": "1909.09706", "submitter": "Hassan Hafez Kolahi", "authors": "Hassan Hafez-Kolahi, Shohreh Kasaei, Mahdiyeh Soleymani-Baghshah", "title": "Do Compressed Representations Generalize Better?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most studied problems in machine learning is finding reasonable\nconstraints that guarantee the generalization of a learning algorithm. These\nconstraints are usually expressed as some simplicity assumptions on the target.\nFor instance, in the Vapnik-Chervonenkis (VC) theory the space of possible\nhypotheses is considered to have a limited VC dimension. In this paper, the\nconstraint on the entropy $H(X)$ of the input variable $X$ is studied as a\nsimplicity assumption. It is proven that the sample complexity to achieve an\n$\\epsilon$-$\\delta$ Probably Approximately Correct (PAC) hypothesis is bounded\nby $\\frac{2^{\n\\left.6H(X)\\middle/\\epsilon\\right.}+\\log{\\frac{1}{\\delta}}}{\\epsilon^2}$ which\nis sharp up to the $\\frac{1}{\\epsilon^2}$ factor. Morever, it is shown that if\na feature learning process is employed to learn the compressed representation\nfrom the dataset, this bound no longer exists. These findings have important\nimplications on the Information Bottleneck (IB) theory which had been utilized\nto explain the generalization power of Deep Neural Networks (DNNs), but its\napplicability for this purpose is currently under debate by researchers. In\nparticular, this is a rigorous proof for the previous heuristic that compressed\nrepresentations are exponentially easier to be learned. However, our analysis\npinpoints two factors preventing the IB, in its current form, to be applicable\nin studying neural networks. Firstly, the exponential dependence of sample\ncomplexity on $\\frac{1}{\\epsilon}$, which can lead to a dramatic effect on the\nbounds in practical applications when $\\epsilon$ is small. Secondly, our\nanalysis reveals that arguments based on input compression are inherently\ninsufficient to explain generalization of methods like DNNs in which the\nfeatures are also learned using available data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 19:54:42 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 09:38:27 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Hafez-Kolahi", "Hassan", ""], ["Kasaei", "Shohreh", ""], ["Soleymani-Baghshah", "Mahdiyeh", ""]]}, {"id": "1909.09712", "submitter": "Zhen Xu", "authors": "Zhen Xu, Andrew M. Dai, Jonas Kemp, Luke Metz", "title": "Learning an Adaptive Learning Rate Schedule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning rate is one of the most important hyper-parameters for model\ntraining and generalization. However, current hand-designed parametric learning\nrate schedules offer limited flexibility and the predefined schedule may not\nmatch the training dynamics of high dimensional and non-convex optimization\nproblems. In this paper, we propose a reinforcement learning based framework\nthat can automatically learn an adaptive learning rate schedule by leveraging\nthe information from past training histories. The learning rate dynamically\nchanges based on the current training dynamics. To validate this framework, we\nconduct experiments with different neural network architectures on the Fashion\nMINIST and CIFAR10 datasets. Experimental results show that the auto-learned\nlearning rate controller can achieve better test results. In addition, the\ntrained controller network is generalizable -- able to be trained on one data\nset and transferred to new problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 20:45:31 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Xu", "Zhen", ""], ["Dai", "Andrew M.", ""], ["Kemp", "Jonas", ""], ["Metz", "Luke", ""]]}, {"id": "1909.09721", "submitter": "Renhao Wang", "authors": "Renhao Wang, Adam Scibior, Frank Wood", "title": "Safer End-to-End Autonomous Driving via Conditional Imitation Learning\n  and Command Augmentation", "comments": "Architecture fails to sufficiently disentangle representations and\n  obey varied commands", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is a promising approach to end-to-end training of\nautonomous vehicle controllers. Typically the driving process with such\napproaches is entirely automatic and black-box, although in practice it is\ndesirable to control the vehicle through high-level commands, such as telling\nit which way to go at an intersection. In existing work this has been\naccomplished by the application of a branched neural architecture, since\ndirectly providing the command as an additional input to the controller often\nresults in the command being ignored. In this work we overcome this limitation\nby learning a disentangled probabilistic latent variable model that generates\nthe steering commands. We achieve faithful command-conditional generation\nwithout using a branched architecture and demonstrate improved stability of the\ncontroller, applying only a variational objective without any domain-specific\nadjustments. On top of that, we extend our model with an additional latent\nvariable and augment the dataset to train a controller that is robust to unsafe\ncommands, such as asking it to turn into a wall. The main contribution of this\nwork is a recipe for building controllable imitation driving agents that\nimproves upon multiple aspects of the current state of the art relating to\nrobustness and interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 21:24:05 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 08:33:10 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2020 17:50:16 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Wang", "Renhao", ""], ["Scibior", "Adam", ""], ["Wood", "Frank", ""]]}, {"id": "1909.09734", "submitter": "Antonio Moretti", "authors": "Antonio Khalil Moretti, Zizhao Wang, Luhuan Wu, Iddo Drori, Itsik\n  Pe'er", "title": "Particle Smoothing Variational Objectives", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A body of recent work has focused on constructing a variational family of\nfiltered distributions using Sequential Monte Carlo (SMC). Inspired by this\nwork, we introduce Particle Smoothing Variational Objectives (SVO), a novel\nbackward simulation technique and smoothed approximate posterior defined\nthrough a subsampling process. SVO augments support of the proposal and boosts\nparticle diversity. Recent literature argues that increasing the number of\nsamples K to obtain tighter variational bounds may hurt the proposal learning,\ndue to a signal-to-noise ratio (SNR) of gradient estimators decreasing at the\nrate $\\mathcal{O}(1/\\sqrt{K})$. As a second contribution, we develop\ntheoretical and empirical analysis of the SNR in filtering SMC, which motivates\nour choice of biased gradient estimators. We prove that introducing bias by\ndropping Categorical terms from the gradient estimate or using Gumbel-Softmax\nmitigates the adverse effect on the SNR. We apply SVO to three nonlinear latent\ndynamics tasks and provide statistics to rigorously quantify the predictions of\nfiltered and smoothed objectives. SVO consistently outperforms filtered\nobjectives when given fewer Monte Carlo samples on three nonlinear systems of\nincreasing complexity.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 22:31:46 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Moretti", "Antonio Khalil", ""], ["Wang", "Zizhao", ""], ["Wu", "Luhuan", ""], ["Drori", "Iddo", ""], ["Pe'er", "Itsik", ""]]}, {"id": "1909.09735", "submitter": "Ahmed Abusnaina", "authors": "Aminollah Khormali, Ahmed Abusnaina, Songqing Chen, DaeHun Nyang, Aziz\n  Mohaisen", "title": "COPYCAT: Practical Adversarial Attacks on Visualization-Based Malware\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite many attempts, the state-of-the-art of adversarial machine learning\non malware detection systems generally yield unexecutable samples. In this\nwork, we set out to examine the robustness of visualization-based malware\ndetection system against adversarial examples (AEs) that not only are able to\nfool the model, but also maintain the executability of the original input. As\nsuch, we first investigate the application of existing off-the-shelf\nadversarial attack approaches on malware detection systems through which we\nfound that those approaches do not necessarily maintain the functionality of\nthe original inputs. Therefore, we proposed an approach to generate adversarial\nexamples, COPYCAT, which is specifically designed for malware detection systems\nconsidering two main goals; achieving a high misclassification rate and\nmaintaining the executability and functionality of the original input. We\ndesigned two main configurations for COPYCAT, namely AE padding and sample\ninjection. While the first configuration results in untargeted\nmisclassification attacks, the sample injection configuration is able to force\nthe model to generate a targeted output, which is highly desirable in the\nmalware attribution setting. We evaluate the performance of COPYCAT through an\nextensive set of experiments on two malware datasets, and report that we were\nable to generate adversarial samples that are misclassified at a rate of 98.9%\nand 96.5% with Windows and IoT binary datasets, respectively, outperforming the\nmisclassification rates in the literature. Most importantly, we report that\nthose AEs were executable unlike AEs generated by off-the-shelf approaches. Our\ntransferability study demonstrates that the generated AEs through our proposed\nmethod can be generalized to other models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 22:40:33 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Khormali", "Aminollah", ""], ["Abusnaina", "Ahmed", ""], ["Chen", "Songqing", ""], ["Nyang", "DaeHun", ""], ["Mohaisen", "Aziz", ""]]}, {"id": "1909.09736", "submitter": "Yinsong Wang", "authors": "Yinsong Wang, Shahin Shahrampour", "title": "Distributed Parameter Estimation in Randomized One-hidden-layer Neural\n  Networks", "comments": "6 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses distributed parameter estimation in randomized\none-hidden-layer neural networks. A group of agents sequentially receive\nmeasurements of an unknown parameter that is only partially observable to them.\nIn this paper, we present a fully distributed estimation algorithm where agents\nexchange local estimates with their neighbors to collectively identify the true\nvalue of the parameter. We prove that this distributed update provides an\nasymptotically unbiased estimator of the unknown parameter, i.e., the first\nmoment of the expected global error converges to zero asymptotically. We\nfurther analyze the efficiency of the proposed estimation scheme by\nestablishing an asymptotic upper bound on the variance of the global error.\nApplying our method to a real-world dataset related to appliances energy\nprediction, we observe that our empirical findings verify the theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 22:53:52 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 06:52:18 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Wang", "Yinsong", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "1909.09743", "submitter": "Jianshu Chen", "authors": "Shiyang Li, Jianshu Chen, Dian Yu", "title": "Teaching Pretrained Models with Commonsense Reasoning: A Preliminary\n  KB-Based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, pretrained language models (e.g., BERT) have achieved great success\non many downstream natural language understanding tasks and exhibit a certain\nlevel of commonsense reasoning ability. However, their performance on\ncommonsense tasks is still far from that of humans. As a preliminary attempt,\nwe propose a simple yet effective method to teach pretrained models with\ncommonsense reasoning by leveraging the structured knowledge in ConceptNet, the\nlargest commonsense knowledge base (KB). Specifically, the structured knowledge\nin KB allows us to construct various logical forms, and then generate\nmultiple-choice questions requiring commonsense logical reasoning. Experimental\nresults demonstrate that, when refined on these training examples, the\npretrained models consistently improve their performance on tasks that require\ncommonsense reasoning, especially in the few-shot learning setting. Besides, we\nalso perform analysis to understand which logical relations are more relevant\nto commonsense reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 23:58:11 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Li", "Shiyang", ""], ["Chen", "Jianshu", ""], ["Yu", "Dian", ""]]}, {"id": "1909.09756", "submitter": "Sameer Kumar", "authors": "Sameer Kumar, Victor Bitorff, Dehao Chen, Chiachen Chou, Blake\n  Hechtman, HyoukJoong Lee, Naveen Kumar, Peter Mattson, Shibo Wang, Tao Wang,\n  Yuanzhong Xu, Zongwei Zhou", "title": "Scale MLPerf-0.6 models on Google TPU-v3 Pods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent submission of Google TPU-v3 Pods to the industry wide MLPerf v0.6\ntraining benchmark demonstrates the scalability of a suite of industry relevant\nML models. MLPerf defines a suite of models, datasets and rules to follow when\nbenchmarking to ensure results are comparable across hardware, frameworks and\ncompanies. Using this suite of models, we discuss the optimizations and\ntechniques including choice of optimizer, spatial partitioning and weight\nupdate sharding necessary to scale to 1024 TPU chips. Furthermore, we identify\nproperties of models that make scaling them challenging, such as limited data\nparallelism and unscaled weights. These optimizations contribute to record\nperformance in transformer, Resnet-50 and SSD in the Google MLPerf-0.6\nsubmission.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 01:12:38 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 17:03:37 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 18:37:01 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Kumar", "Sameer", ""], ["Bitorff", "Victor", ""], ["Chen", "Dehao", ""], ["Chou", "Chiachen", ""], ["Hechtman", "Blake", ""], ["Lee", "HyoukJoong", ""], ["Kumar", "Naveen", ""], ["Mattson", "Peter", ""], ["Wang", "Shibo", ""], ["Wang", "Tao", ""], ["Xu", "Yuanzhong", ""], ["Zhou", "Zongwei", ""]]}, {"id": "1909.09757", "submitter": "Yixing Xu", "authors": "Yixing Xu, Yunhe Wang, Hanting Chen, Kai Han, Chunjing Xu, Dacheng\n  Tao, Chang Xu", "title": "Positive-Unlabeled Compression on the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many attempts have been done to extend the great success of convolutional\nneural networks (CNNs) achieved on high-end GPU servers to portable devices\nsuch as smart phones. Providing compression and acceleration service of deep\nlearning models on the cloud is therefore of significance and is attractive for\nend users. However, existing network compression and acceleration approaches\nusually fine-tuning the svelte model by requesting the entire original training\ndata (\\eg ImageNet), which could be more cumbersome than the network itself and\ncannot be easily uploaded to the cloud. In this paper, we present a novel\npositive-unlabeled (PU) setting for addressing this problem. In practice, only\na small portion of the original training set is required as positive examples\nand more useful training examples can be obtained from the massive unlabeled\ndata on the cloud through a PU classifier with an attention based multi-scale\nfeature extractor. We further introduce a robust knowledge distillation (RKD)\nscheme to deal with the class imbalance problem of these newly augmented\ntraining examples. The superiority of the proposed method is verified through\nexperiments conducted on the benchmark models and datasets. We can use only\n$8\\%$ of uniformly selected data from the ImageNet to obtain an efficient model\nwith comparable performance to the baseline ResNet-34.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 01:21:16 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 03:06:55 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Xu", "Yixing", ""], ["Wang", "Yunhe", ""], ["Chen", "Hanting", ""], ["Han", "Kai", ""], ["Xu", "Chunjing", ""], ["Tao", "Dacheng", ""], ["Xu", "Chang", ""]]}, {"id": "1909.09785", "submitter": "Hunter Lang", "authors": "Hunter Lang, Pengchuan Zhang, Lin Xiao", "title": "Using Statistics to Automate Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the development of numerous adaptive optimizers, tuning the learning\nrate of stochastic gradient methods remains a major roadblock to obtaining good\npractical performance in machine learning. Rather than changing the learning\nrate at each iteration, we propose an approach that automates the most common\nhand-tuning heuristic: use a constant learning rate until \"progress stops,\"\nthen drop. We design an explicit statistical test that determines when the\ndynamics of stochastic gradient descent reach a stationary distribution. This\ntest can be performed easily during training, and when it fires, we decrease\nthe learning rate by a constant multiplicative factor. Our experiments on\nseveral deep learning tasks demonstrate that this statistical adaptive\nstochastic approximation (SASA) method can automatically find good learning\nrate schedules and match the performance of hand-tuned methods using default\nsettings of its parameters. The statistical testing helps to control the\nvariance of this procedure and improves its robustness.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 07:27:48 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Lang", "Hunter", ""], ["Zhang", "Pengchuan", ""], ["Xiao", "Lin", ""]]}, {"id": "1909.09804", "submitter": "Mengyao Zheng", "authors": "Mengyao Zheng, Dixing Xu, Linshan Jiang, Chaojie Gu, Rui Tan, Peng\n  Cheng", "title": "Challenges of Privacy-Preserving Machine Learning in IoT", "comments": "In First International Workshop on Challenges in Artificial\n  Intelligence and Machine Learning (AIChallengeIoT'19) November 10-13, 2019. 7\n  pages", "journal-ref": null, "doi": "10.1145/3363347.3363357", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) will be a main data generation infrastructure\nfor achieving better system intelligence. However, the extensive data\ncollection and processing in IoT also engender various privacy concerns. This\npaper provides a taxonomy of the existing privacy-preserving machine learning\napproaches developed in the context of cloud computing and discusses the\nchallenges of applying them in the context of IoT. Moreover, we present a\nprivacy-preserving inference approach that runs a lightweight neural network at\nIoT objects to obfuscate the data before transmission and a deep neural network\nin the cloud to classify the obfuscated data. Evaluation based on the MNIST\ndataset shows satisfactory performance.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 10:12:48 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Zheng", "Mengyao", ""], ["Xu", "Dixing", ""], ["Jiang", "Linshan", ""], ["Gu", "Chaojie", ""], ["Tan", "Rui", ""], ["Cheng", "Peng", ""]]}, {"id": "1909.09814", "submitter": "Diego Marcheggiani", "authors": "Diego Marcheggiani, Ivan Titov", "title": "Graph Convolutions over Constituent Trees for Syntax-Aware Semantic Role\n  Labeling", "comments": "Published in proceedings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) is the task of identifying predicates and\nlabeling argument spans with semantic roles. Even though most semantic-role\nformalisms are built upon constituent syntax and only syntactic constituents\ncan be labeled as arguments (e.g., FrameNet and PropBank), all the recent work\non syntax-aware SRL relies on dependency representations of syntax. In\ncontrast, we show how graph convolutional networks (GCNs) can be used to encode\nconstituent structures and inform an SRL system. Nodes in our SpanGCN\ncorrespond to constituents. The computation is done in 3 stages. First, initial\nnode representations are produced by `composing' word representations of the\nfirst and the last word in the constituent. Second, graph convolutions relying\non the constituent tree are performed, yielding syntactically-informed\nconstituent representations. Finally, the constituent representations are\n`decomposed' back into word representations which in turn are used as input to\nthe SRL classifier. We evaluate SpanGCN against alternatives, including a model\nusing GCNs over dependency trees, and show its effectiveness on standard\nCoNLL-2005, CoNLL-2012, and FrameNet benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 11:37:23 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 16:54:01 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 11:33:45 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Marcheggiani", "Diego", ""], ["Titov", "Ivan", ""]]}, {"id": "1909.09816", "submitter": "Ioannis Ivrissimtzis", "authors": "Luma Omar and Ioannis Ivrissimtzis", "title": "Using theoretical ROC curves for analysing machine learning binary\n  classifiers", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most binary classifiers work by processing the input to produce a scalar\nresponse and comparing it to a threshold value. The various measures of\nclassifier performance assume, explicitly or implicitly, probability\ndistributions $P_s$ and $P_n$ of the response belonging to either class,\nprobability distributions for the cost of each type of misclassification, and\ncompute a performance score from the expected cost.\n  In machine learning, classifier responses are obtained experimentally and\nperformance scores are computed directly from them, without any assumptions on\n$P_s$ and $P_n$. Here, we argue that the omitted step of estimating theoretical\ndistributions for $P_s$ and $P_n$ can be useful. In a biometric security\nexample, we fit beta distributions to the responses of two classifiers, one\nbased on logistic regression and one on ANNs, and use them to establish a\ncategorisation into a small number of classes with different extremal\nbehaviours at the ends of the ROC curves.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 11:48:19 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Omar", "Luma", ""], ["Ivrissimtzis", "Ioannis", ""]]}, {"id": "1909.09819", "submitter": "Beyrem Khalfaoui", "authors": "Beyrem Khalfaoui, Joseph Boyd and Jean-Philippe Vert", "title": "ASNI: Adaptive Structured Noise Injection for shallow and deep neural\n  networks", "comments": "All code concerning the real data experiments is available at\n  \\url{https://github.com/BeyremKh/ASNI}\\\\", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a regularisation technique in neural network training where unit\nactivations are randomly set to zero with a given probability\n\\emph{independently}. In this work, we propose a generalisation of dropout and\nother multiplicative noise injection schemes for shallow and deep neural\nnetworks, where the random noise applied to different units is not independent\nbut follows a joint distribution that is either fixed or estimated during\ntraining. We provide theoretical insights on why such adaptive structured noise\ninjection (ASNI) may be relevant, and empirically confirm that it helps boost\nthe accuracy of simple feedforward and convolutional neural networks,\ndisentangles the hidden layer representations, and leads to sparser\nrepresentations. Our proposed method is a straightforward modification of the\nclassical dropout and does not require additional computational overhead.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 13:02:56 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Khalfaoui", "Beyrem", ""], ["Boyd", "Joseph", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "1909.09823", "submitter": "Manu Airaksinen", "authors": "Manu Airaksinen, Okko R\\\"as\\\"anen, Elina Il\\'en, Taru H\\\"ayrinen, Anna\n  Kivi, Viviana Marchi, Anastasia Gallen, Sonja Blom, Anni Varhe, Nico\n  Kaartinen, Leena Haataja, Sampsa Vanhatalo", "title": "Automatic Posture and Movement Tracking of Infants with Wearable\n  Movement Sensors", "comments": "17 pages, 8 figures, preprint of manuscript accepted for publication\n  for publication in Nature Scientific Reports", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Infants' spontaneous and voluntary movements mirror developmental integrity\nof brain networks since they require coordinated activation of multiple sites\nin the central nervous system. Accordingly, early detection of infants with\natypical motor development holds promise for recognizing those infants who are\nat risk for a wide range of neurodevelopmental disorders (e.g., cerebral palsy,\nautism spectrum disorders). Previously, novel wearable technology has shown\npromise for offering efficient, scalable and automated methods for movement\nassessment in adults. Here, we describe the development of an infant wearable,\na multi-sensor smart jumpsuit that allows mobile accelerometer and gyroscope\ndata collection during movements. Using this suit, we first recorded play\nsessions of 22 typically developing infants of approximately 7 months of age.\nThese data were manually annotated for infant posture and movement based on\nvideo recordings of the sessions, and using a novel annotation scheme\nspecifically designed to assess the overall movement pattern of infants in the\ngiven age group. A machine learning algorithm, based on deep convolutional\nneural networks (CNNs) was then trained for automatic detection of posture and\nmovement classes using the data and annotations. Our experiments show that the\nsetup can be used for quantitative tracking of infant movement activities with\na human equivalent accuracy, i.e., it meets the human inter-rater agreement\nlevels in infant posture and movement classification. We also quantify the\nambiguity of human observers in analyzing infant movements, and propose a\nmethod for utilizing this uncertainty for performance improvements in training\nof the automated classifier. Comparison of different sensor configurations also\nshows that four-limb recording leads to the best performance in posture and\nmovement classification.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 13:37:28 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 13:42:39 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Airaksinen", "Manu", ""], ["R\u00e4s\u00e4nen", "Okko", ""], ["Il\u00e9n", "Elina", ""], ["H\u00e4yrinen", "Taru", ""], ["Kivi", "Anna", ""], ["Marchi", "Viviana", ""], ["Gallen", "Anastasia", ""], ["Blom", "Sonja", ""], ["Varhe", "Anni", ""], ["Kaartinen", "Nico", ""], ["Haataja", "Leena", ""], ["Vanhatalo", "Sampsa", ""]]}, {"id": "1909.09836", "submitter": "Dana Yang", "authors": "Jiaming Xu, Kuang Xu and Dana Yang", "title": "Optimal query complexity for private sequential learning against\n  eavesdropping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the query complexity of a learner-private sequential learning\nproblem, motivated by the privacy and security concerns due to eavesdropping\nthat arise in practical applications such as pricing and Federated Learning. A\nlearner tries to estimate an unknown scalar value, by sequentially querying an\nexternal database and receiving binary responses; meanwhile, a third-party\nadversary observes the learner's queries but not the responses. The learner's\ngoal is to design a querying strategy with the minimum number of queries\n(optimal query complexity) so that she can accurately estimate the true value,\nwhile the eavesdropping adversary even with the complete knowledge of her\nquerying strategy cannot.\n  We develop new querying strategies and analytical techniques and use them to\nprove tight upper and lower bounds on the optimal query complexity. The bounds\nalmost match across the entire parameter range, substantially improving upon\nexisting results. We thus obtain a complete picture of the optimal query\ncomplexity as a function of the estimation accuracy and the desired levels of\nprivacy. We also extend the results to sequential learning models in higher\ndimensions, and where the binary responses are noisy. Our analysis leverages a\ncrucial insight into the nature of private learning problem, which suggests\nthat the query trajectory of an optimal learner can be divided into distinct\nphases that focus on pure learning versus learning and obfuscation,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 14:39:02 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 00:28:08 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Xu", "Jiaming", ""], ["Xu", "Kuang", ""], ["Yang", "Dana", ""]]}, {"id": "1909.09849", "submitter": "Shayegan Omidshafiei", "authors": "Mark Rowland, Shayegan Omidshafiei, Karl Tuyls, Julien Perolat, Michal\n  Valko, Georgios Piliouras, Remi Munos", "title": "Multiagent Evaluation under Incomplete Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the evaluation of learned multiagent strategies in\nthe incomplete information setting, which plays a critical role in ranking and\ntraining of agents. Traditionally, researchers have relied on Elo ratings for\nthis purpose, with recent works also using methods based on Nash equilibria.\nUnfortunately, Elo is unable to handle intransitive agent interactions, and\nother techniques are restricted to zero-sum, two-player settings or are limited\nby the fact that the Nash equilibrium is intractable to compute. Recently, a\nranking method called {\\alpha}-Rank, relying on a new graph-based\ngame-theoretic solution concept, was shown to tractably apply to general games.\nHowever, evaluations based on Elo or {\\alpha}-Rank typically assume noise-free\ngame outcomes, despite the data often being collected from noisy simulations,\nmaking this assumption unrealistic in practice. This paper investigates\nmultiagent evaluation in the incomplete information regime, involving\ngeneral-sum many-player games with noisy outcomes. We derive sample complexity\nguarantees required to confidently rank agents in this setting. We propose\nadaptive algorithms for accurate ranking, provide correctness and sample\ncomplexity guarantees, then introduce a means of connecting uncertainties in\nnoisy match outcomes to uncertainties in rankings. We evaluate the performance\nof these approaches in several domains, including Bernoulli games, a soccer\nmeta-game, and Kuhn poker.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 16:05:31 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 16:21:02 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 10:05:19 GMT"}, {"version": "v4", "created": "Fri, 10 Jan 2020 09:59:37 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Rowland", "Mark", ""], ["Omidshafiei", "Shayegan", ""], ["Tuyls", "Karl", ""], ["Perolat", "Julien", ""], ["Valko", "Michal", ""], ["Piliouras", "Georgios", ""], ["Munos", "Remi", ""]]}, {"id": "1909.09851", "submitter": "Anru Zhang", "authors": "T. Tony Cai, Anru Zhang, Yuchen Zhou", "title": "Sparse Group Lasso: Optimal Sample Complexity, Convergence Rate, and\n  Statistical Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we study sparse group Lasso for high-dimensional double sparse\nlinear regression, where the parameter of interest is simultaneously\nelement-wise and group-wise sparse. This problem is an important instance of\nthe simultaneously structured model -- an actively studied topic in statistics\nand machine learning. In the noiseless case, we provide matching upper and\nlower bounds on sample complexity for the exact recovery of sparse vectors and\nfor stable estimation of approximately sparse vectors, respectively. In the\nnoisy case, we develop upper and matching minimax lower bounds for estimation\nerror. We also consider the debiased sparse group Lasso and investigate its\nasymptotic property for the purpose of statistical inference. Finally,\nnumerical studies are provided to support the theoretical results.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 16:17:04 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Cai", "T. Tony", ""], ["Zhang", "Anru", ""], ["Zhou", "Yuchen", ""]]}, {"id": "1909.09852", "submitter": "Ashish Mani Dr.", "authors": "Arit Kumar Bishwas, Ashish Mani, and Vasile Palade", "title": "An Investigation of Quantum Deep Clustering Framework with Quantum Deep\n  SVM & Convolutional Neural Network Feature Extractor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have proposed a deep quantum SVM formulation, and further\ndemonstrated a quantum-clustering framework based on the quantum deep SVM\nformulation, deep convolutional neural networks, and quantum K-Means\nclustering. We have investigated the run time computational complexity of the\nproposed quantum deep clustering framework and compared with the possible\nclassical implementation. Our investigation shows that the proposed quantum\nversion of deep clustering formulation demonstrates a significant performance\ngain (exponential speed up gains in many sections) against the possible\nclassical implementation. The proposed theoretical quantum deep clustering\nframework is also interesting & novel research towards the quantum-classical\nmachine learning formulation to articulate the maximum performance.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 16:19:43 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Bishwas", "Arit Kumar", ""], ["Mani", "Ashish", ""], ["Palade", "Vasile", ""]]}, {"id": "1909.09862", "submitter": "Sauptik Dhar", "authors": "Sauptik Dhar and Vladimir Cherkassky", "title": "Single Class Universum-SVM", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the idea of Universum learning [1, 2] to single-class\nlearning problems. We propose Single Class Universum-SVM setting that\nincorporates a priori knowledge (in the form of additional data samples) into\nthe single class estimation problem. These additional data samples or Universum\nbelong to the same application domain as (positive) data samples from a single\nclass (of interest), but they follow a different distribution. Proposed\nmethodology for single class U-SVM is based on the known connection between\nbinary classification and single class learning formulations [3]. Several\nempirical comparisons are presented to illustrate the utility of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 18:00:46 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Dhar", "Sauptik", ""], ["Cherkassky", "Vladimir", ""]]}, {"id": "1909.09868", "submitter": "Mithun Paul Panenghat", "authors": "Sandeep Suntwal, Mithun Paul, Rebecca Sharp, Mihai Surdeanu", "title": "On the Importance of Delexicalization for Fact Verification", "comments": "published in the proceedings at EMNLP2019", "journal-ref": null, "doi": "10.18653/v1/D19-1340", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we aim to understand and estimate the importance that a neural\nnetwork assigns to various aspects of the data while learning and making\npredictions. Here we focus on the recognizing textual entailment (RTE) task and\nits application to fact verification. In this context, the contributions of\nthis work are as follows. We investigate the attention weights a state of the\nart RTE method assigns to input tokens in the RTE component of fact\nverification systems, and confirm that most of the weight is assigned to POS\ntags of nouns (e.g., NN, NNP etc.) or their phrases. To verify that these\nlexicalized models transfer poorly, we implement a domain transfer experiment\nwhere a RTE component is trained on the FEVER data, and tested on the Fake News\nChallenge (FNC) dataset. As expected, even though this method achieves high\naccuracy when evaluated in the same domain, the performance in the target\ndomain is poor, marginally above chance.To mitigate this dependence on\nlexicalized information, we experiment with several strategies for masking out\nnames by replacing them with their semantic category, coupled with a unique\nidentifier to mark that the same or new entities are referenced between claim\nand evidence. The results show that, while the performance on the FEVER dataset\nremains at par with that of the model trained on lexicalized data, it improves\nsignificantly when tested in the FNC dataset. Thus our experiments demonstrate\nthat our strategy is successful in mitigating the dependency on lexical\ninformation.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 18:47:34 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 01:44:57 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Suntwal", "Sandeep", ""], ["Paul", "Mithun", ""], ["Sharp", "Rebecca", ""], ["Surdeanu", "Mihai", ""]]}, {"id": "1909.09877", "submitter": "Yifeng Shi", "authors": "Yifeng Shi, Junier Oliva, Marc Niethammer", "title": "Deep Message Passing on Sets", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern methods for learning over graph input data have shown the fruitfulness\nof accounting for relationships among elements in a collection. However, most\nmethods that learn over set input data use only rudimentary approaches to\nexploit intra-collection relationships. In this work we introduce Deep Message\nPassing on Sets (DMPS), a novel method that incorporates relational learning\nfor sets. DMPS not only connects learning on graphs with learning on sets via\ndeep kernel learning, but it also bridges message passing on sets and\ntraditional diffusion dynamics commonly used in denoising models. Based on\nthese connections, we develop two new blocks for relational learning on sets:\nthe set-denoising block and the set-residual block. The former is motivated by\nthe connection between message passing on general graphs and diffusion-based\ndenoising models, whereas the latter is inspired by the well-known residual\nnetwork. In addition to demonstrating the interpretability of our model by\nlearning the true underlying relational structure experimentally, we also show\nthe effectiveness of our approach on both synthetic and real-world datasets by\nachieving results that are competitive with or outperform the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 19:35:35 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Shi", "Yifeng", ""], ["Oliva", "Junier", ""], ["Niethammer", "Marc", ""]]}, {"id": "1909.09884", "submitter": "Rhiannon Michelmore", "authors": "Rhiannon Michelmore, Matthew Wicker, Luca Laurenti, Luca Cardelli,\n  Yarin Gal, Marta Kwiatkowska", "title": "Uncertainty Quantification with Statistical Guarantees in End-to-End\n  Autonomous Driving Control", "comments": "7 pages, 3 figures, submitted to ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network controllers for autonomous driving have recently\nbenefited from significant performance improvements, and have begun deployment\nin the real world. Prior to their widespread adoption, safety guarantees are\nneeded on the controller behaviour that properly take account of the\nuncertainty within the model as well as sensor noise. Bayesian neural networks,\nwhich assume a prior over the weights, have been shown capable of producing\nsuch uncertainty measures, but properties surrounding their safety have not yet\nbeen quantified for use in autonomous driving scenarios. In this paper, we\ndevelop a framework based on a state-of-the-art simulator for evaluating\nend-to-end Bayesian controllers. In addition to computing pointwise uncertainty\nmeasures that can be computed in real time and with statistical guarantees, we\nalso provide a method for estimating the probability that, given a scenario,\nthe controller keeps the car safe within a finite horizon. We experimentally\nevaluate the quality of uncertainty computation by several Bayesian inference\nmethods in different scenarios and show how the uncertainty measures can be\ncombined and calibrated for use in collision avoidance. Our results suggest\nthat uncertainty estimates can greatly aid decision making in autonomous\ndriving.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 20:05:50 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Michelmore", "Rhiannon", ""], ["Wicker", "Matthew", ""], ["Laurenti", "Luca", ""], ["Cardelli", "Luca", ""], ["Gal", "Yarin", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "1909.09895", "submitter": "Salar Fattahi", "authors": "Salar Fattahi and Nikolai Matni and Somayeh Sojoudi", "title": "Efficient Learning of Distributed Linear-Quadratic Controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a robust approach to design distributed controllers\nfor unknown-but-sparse linear and time-invariant systems. By leveraging modern\ntechniques in distributed controller synthesis and structured linear inverse\nproblems as applied to system identification, we show that near-optimal\ndistributed controllers can be learned with sub-linear sample complexity and\ncomputed with near-linear time complexity, both measured with respect to the\ndimension of the system. In particular, we provide sharp end-to-end guarantees\non the stability and the performance of the designed distributed controller and\nprove that for sparse systems, the number of samples needed to guarantee robust\nand near optimal performance of the designed controller can be significantly\nsmaller than the dimension of the system. Finally, we show that the proposed\noptimization problem can be solved to global optimality with near-linear time\ncomplexity by iteratively solving a series of small quadratic programs.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 20:58:45 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 03:11:35 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Fattahi", "Salar", ""], ["Matni", "Nikolai", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "1909.09902", "submitter": "Pawel Ladosz", "authors": "Pawel Ladosz, Eseoghene Ben-Iwhiwhu, Jeffery Dick, Yang Hu, Nicholas\n  Ketz, Soheil Kolouri, Jeffrey L. Krichmar, Praveen Pilly, and Andrea\n  Soltoggio", "title": "Deep Reinforcement Learning with Modulated Hebbian plus Q Network\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new neural architecture that combines a modulated\nHebbian network (MOHN) with DQN, which we call modulated Hebbian plus Q network\narchitecture (MOHQA). The hypothesis is that such a combination allows MOHQA to\nsolve difficult partially observable Markov decision process (POMDP) problems\nwhich impair temporal difference (TD)-based RL algorithms such as DQN, as the\nTD error cannot be easily derived from observations. The key idea is to use a\nHebbian network with bio-inspired neural traces in order to bridge temporal\ndelays between actions and rewards when confounding observations and sparse\nrewards result in inaccurate TD errors. In MOHQA, DQN learns low level features\nand control, while the MOHN contributes to the high-level decisions by\nassociating rewards with past states and actions. Thus the proposed\narchitecture combines two modules with significantly different learning\nalgorithms, a Hebbian associative network and a classical DQN pipeline,\nexploiting the advantages of both. Simulations on a set of POMDPs and on the\nMALMO environment show that the proposed algorithm improved DQN's results and\neven outperformed control tests with A2C, QRDQN+LSTM and REINFORCE algorithms\non some POMDPs with confounding stimuli and sparse rewards.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 21:32:47 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:05:14 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 14:29:30 GMT"}, {"version": "v4", "created": "Thu, 23 Apr 2020 20:42:17 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Ladosz", "Pawel", ""], ["Ben-Iwhiwhu", "Eseoghene", ""], ["Dick", "Jeffery", ""], ["Hu", "Yang", ""], ["Ketz", "Nicholas", ""], ["Kolouri", "Soheil", ""], ["Krichmar", "Jeffrey L.", ""], ["Pilly", "Praveen", ""], ["Soltoggio", "Andrea", ""]]}, {"id": "1909.09903", "submitter": "Jeancarlo Campos Le\\~ao", "authors": "Jeancarlo Campos Le\\~ao (1), Alberto H. F. Laender (2), Pedro O. S.\n  Vaz de Melo (2) ((1) Instituto Federal do Norte de Minas, (2) Universidade\n  Federal de Minas Gerais)", "title": "A Multi-Strategy Approach to Overcoming Bias in Community Detection\n  Evaluation", "comments": "12 pages, 6 figures, 3 tables. This paper has been submitted to the\n  34th Brazilian Symposium on Databases, 2019 (SBBD2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is key to understand the structure of complex networks.\nHowever, the lack of appropriate evaluation strategies for this specific task\nmay produce biased and incorrect results that might invalidate further analyses\nor applications based on such networks. In this context, the main contribution\nof this paper is an approach that supports a robust quality evaluation when\ndetecting communities in real-world networks. In our approach, we use multiple\nstrategies that capture distinct aspects of the communities. The conclusion on\nthe quality of these communities is based on the consensus among the strategies\nadopted for the structural evaluation, as well as on the comparison with\ncommunities detected by different methods and with their existing ground\ntruths. In this way, our approach allows one to overcome biases in network\ndata, detection algorithms and evaluation metrics, thus providing more\nconsistent conclusions about the quality of the detected communities.\nExperiments conducted with several real and synthetic networks provided results\nthat show the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 21:36:50 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Le\u00e3o", "Jeancarlo Campos", ""], ["Laender", "Alberto H. F.", ""], ["de Melo", "Pedro O. S. Vaz", ""]]}, {"id": "1909.09906", "submitter": "Faraz Torabi", "authors": "Ruohan Zhang, Faraz Torabi, Lin Guan, Dana H. Ballard, Peter Stone", "title": "Leveraging Human Guidance for Deep Reinforcement Learning Tasks", "comments": "Proceedings of the 28th International Joint Conference on Artificial\n  Intelligence (IJCAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents can learn to solve sequential decision tasks by\ninteracting with the environment. Human knowledge of how to solve these tasks\ncan be incorporated using imitation learning, where the agent learns to imitate\nhuman demonstrated decisions. However, human guidance is not limited to the\ndemonstrations. Other types of guidance could be more suitable for certain\ntasks and require less human effort. This survey provides a high-level overview\nof five recent learning frameworks that primarily rely on human guidance other\nthan conventional, step-by-step action demonstrations. We review the\nmotivation, assumption, and implementation of each framework. We then discuss\npossible future research directions.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 21:48:52 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Zhang", "Ruohan", ""], ["Torabi", "Faraz", ""], ["Guan", "Lin", ""], ["Ballard", "Dana H.", ""], ["Stone", "Peter", ""]]}, {"id": "1909.09910", "submitter": "Mohsen Jafarzadeh", "authors": "Mohsen Jafarzadeh, Daniel Curtiss Hussey, Yonas Tadesse", "title": "Deep learning approach to control of prosthetic hands with\n  electromyography signals", "comments": "Conference. Houston, Texas, USA. September, 2019", "journal-ref": "2019 IEEE International Symposium on Measurement and Control in\n  Robotics (ISMCR)", "doi": "10.1109/ISMCR47492.2019.8955725", "report-no": null, "categories": "eess.SP cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural muscles provide mobility in response to nerve impulses.\nElectromyography (EMG) measures the electrical activity of muscles in response\nto a nerve's stimulation. In the past few decades, EMG signals have been used\nextensively in the identification of user intention to potentially control\nassistive devices such as smart wheelchairs, exoskeletons, and prosthetic\ndevices. In the design of conventional assistive devices, developers optimize\nmultiple subsystems independently. Feature extraction and feature description\nare essential subsystems of this approach. Therefore, researchers proposed\nvarious hand-crafted features to interpret EMG signals. However, the\nperformance of conventional assistive devices is still unsatisfactory. In this\npaper, we propose a deep learning approach to control prosthetic hands with raw\nEMG signals. We use a novel deep convolutional neural network to eschew the\nfeature-engineering step. Removing the feature extraction and feature\ndescription is an important step toward the paradigm of end-to-end\noptimization. Fine-tuning and personalization are additional advantages of our\napproach. The proposed approach is implemented in Python with TensorFlow deep\nlearning library, and it runs in real-time in general-purpose graphics\nprocessing units of NVIDIA Jetson TX2 developer kit. Our results demonstrate\nthe ability of our system to predict fingers position from raw EMG signals. We\nanticipate our EMG-based control system to be a starting point to design more\nsophisticated prosthetic hands. For example, a pressure measurement unit can be\nadded to transfer the perception of the environment to the user. Furthermore,\nour system can be modified for other prosthetic devices.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 22:28:00 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 15:58:08 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Jafarzadeh", "Mohsen", ""], ["Hussey", "Daniel Curtiss", ""], ["Tadesse", "Yonas", ""]]}, {"id": "1909.09912", "submitter": "Charalampos Tsourakakis", "authors": "Kasper Green Larsen, Michael Mitzenmacher, Charalampos E. Tsourakakis", "title": "Optimal Learning of Joint Alignments with a Faulty Oracle", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following problem, which is useful in applications such as\njoint image and shape alignment. The goal is to recover $n$ discrete variables\n$g_i \\in \\{0, \\ldots, k-1\\}$ (up to some global offset) given noisy\nobservations of a set of their pairwise differences $\\{(g_i - g_j) \\bmod k\\}$;\nspecifically, with probability $\\frac{1}{k}+\\delta$ for some $\\delta > 0$ one\nobtains the correct answer, and with the remaining probability one obtains a\nuniformly random incorrect answer. We consider a learning-based formulation\nwhere one can perform a query to observe a pairwise difference, and the goal is\nto perform as few queries as possible while obtaining the exact joint\nalignment. We provide an easy-to-implement, time efficient algorithm that\nperforms $O\\big(\\frac{n \\lg n}{k \\delta^2}\\big)$ queries, and recovers the\njoint alignment with high probability. We also show that our algorithm is\noptimal by proving a general lower bound that holds for all non-adaptive\nalgorithms. Our work improves significantly recent work by Chen and Cand\\'{e}s\n\\cite{chen2016projected}, who view the problem as a constrained principal\ncomponents analysis problem that can be solved using the power method.\nSpecifically, our approach is simpler both in the algorithm and the analysis,\nand provides additional insights into the problem structure.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 23:41:19 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Larsen", "Kasper Green", ""], ["Mitzenmacher", "Michael", ""], ["Tsourakakis", "Charalampos E.", ""]]}, {"id": "1909.09922", "submitter": "Chan Hee Song", "authors": "Arijit Sehanobish, Chan Hee Song", "title": "Using Chinese Glyphs for Named Entity Recognition", "comments": "Extended abstract accepted to AAAI-2020, student track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most Named Entity Recognition (NER) systems use additional features like\npart-of-speech (POS) tags, shallow parsing, gazetteers, etc. Such kind of\ninformation requires external knowledge like unlabeled texts and trained\ntaggers. Adding these features to NER systems have been shown to have a\npositive impact. However, sometimes creating gazetteers or taggers can take a\nlot of time and may require extensive data cleaning. In this paper for Chinese\nNER systems, we do not use these traditional features but we use lexicographic\nfeatures of Chinese characters. Chinese characters are composed of graphical\ncomponents called radicals and these components often have some semantic\nindicators. We propose CNN based models that incorporate this semantic\ninformation and use them for NER. Our models show an improvement over the\nbaseline BERT-BiLSTM-CRF model. We set a new baseline score for Chinese\nOntoNotes v5.0 and show an improvement of +.64 F1 score. We present a\nstate-of-the-art F1 score on Weibo dataset of 71.81 and show a competitive\nimprovement of +0.72 over baseline on ResumeNER dataset.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 01:12:18 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 03:41:14 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Sehanobish", "Arijit", ""], ["Song", "Chan Hee", ""]]}, {"id": "1909.09925", "submitter": "Andrey Kuehlkamp", "authors": "Evan Brinckman, Andrey Kuehlkamp, Jarek Nabrzyski, Ian J. Taylor", "title": "Techniques and Applications for Crawling, Ingesting and Analyzing\n  Blockchain Data", "comments": "Manuscript accepted for publication at ICTC 2019 (ictc.org)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the public Ethereum network surpasses half a billion transactions and\nenterprise Blockchain systems becoming highly capable of meeting the demands of\nglobal deployments, production Blockchain applications are fast becoming\ncommonplace across a diverse range of business and scientific verticals. In\nthis paper, we reflect on work we have been conducting recently surrounding the\ningestion, retrieval and analysis of Blockchain data. We describe the scaling\nand semantic challenges when extracting Blockchain data in a way that preserves\nthe original metadata of each transaction by cross referencing the Smart\nContract interface with the on-chain data. We then discuss a scientific use\ncase in the area of Scientific workflows by describing how we can harvest data\nfrom tasks and dependencies in a generic way. We then discuss how crawled\npublic blockchain data can be analyzed using two unsupervised machine learning\nalgorithms, which are designed to identify outlier accounts or smart contracts\nin the system. We compare and contrast the two machine learning methods and\ncross correlate with public Websites to illustrate the effectiveness such\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 01:38:08 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Brinckman", "Evan", ""], ["Kuehlkamp", "Andrey", ""], ["Nabrzyski", "Jarek", ""], ["Taylor", "Ian J.", ""]]}, {"id": "1909.09929", "submitter": "Prasanna Balaprakash", "authors": "Shashi M. Aithal and Prasanna Balaprakash", "title": "MaLTESE: Large-Scale Simulation-Driven Machine Learning for Transient\n  Driving Cycles", "comments": null, "journal-ref": "In M. Weiland, G. Juckeland, C. Trinitis, and P. Sadayappan,\n  editors, High Performance Computing, pages 186--205, Cham, 2019. Springer\n  International Publishing", "doi": "10.1007/978-3-030-20656-7_10", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal engine operation during a transient driving cycle is the key to\nachieving greater fuel economy, engine efficiency, and reduced emissions. In\norder to achieve continuously optimal engine operation, engine calibration\nmethods use a combination of static correlations obtained from dynamometer\ntests for steady-state operating points and road and/or track performance data.\nAs the parameter space of control variables, design variable constraints, and\nobjective functions increases, the cost and duration for optimal calibration\nbecome prohibitively large. In order to reduce the number of dynamometer tests\nrequired for calibrating modern engines, a large-scale simulation-driven\nmachine learning approach is presented in this work. A parallel, fast, robust,\nphysics-based reduced-order engine simulator is used to obtain performance and\nemission characteristics of engines over a wide range of control parameters\nunder various transient driving conditions (drive cycles). We scale the\nsimulation up to 3,906 nodes of the Theta supercomputer at the Argonne\nLeadership Computing Facility to generate data required to train a machine\nlearning model. The trained model is then used to predict various engine\nparameters of interest. Our results show that a deep-neural-network-based\nsurrogate model achieves high accuracy for various engine parameters such as\nexhaust temperature, exhaust pressure, nitric oxide, and engine torque. Once\ntrained, the deep-neural-network-based surrogate model is fast for inference:\nit requires about 16 micro sec for predicting the engine performance and\nemissions for a single design configuration compared with about 0.5 s per\nconfiguration with the engine simulator. Moreover, we demonstrate that transfer\nlearning and retraining can be leveraged to incrementally retrain the surrogate\nmodel to cope with new configurations that fall outside the training data\nspace.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 01:58:20 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Aithal", "Shashi M.", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1909.09938", "submitter": "Saurabh Bagchi", "authors": "Jinkyu Koo, Michael Roth and Saurabh Bagchi", "title": "HAWKEYE: Adversarial Example Detector for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples (AEs) are images that can mislead deep neural network\n(DNN) classifiers via introducing slight perturbations into original images.\nRecent work has shown that detecting AEs can be more effective against AEs than\npreventing them from being generated. However, the state-of-the-art AE\ndetection still shows a high false positive rate, thereby rejecting a\nconsiderable amount of normal images. To address this issue, we propose\nHAWKEYE, which is a separate neural network that analyzes the output layer of\nthe DNN, and detects AEs. HAWKEYE's AE detector utilizes a quantized version of\nan input image as a reference, and is trained to distinguish the variation\ncharacteristics of the DNN output on an input image from the DNN output on its\nreference image. We also show that cascading our AE detectors that are trained\nfor different quantization step sizes can drastically reduce a false positive\nrate, while keeping a detection rate high.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 04:19:33 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Koo", "Jinkyu", ""], ["Roth", "Michael", ""], ["Bagchi", "Saurabh", ""]]}, {"id": "1909.09962", "submitter": "Gaurav Verma", "authors": "Bakhtiyar Syed, Gaurav Verma, Balaji Vasan Srinivasan, Anandhavelu\n  Natarajan, Vasudeva Varma", "title": "Adapting Language Models for Non-Parallel Author-Stylized Rewriting", "comments": "Accepted for publication in Main Technical Track at AAAI 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the recent progress in language modeling using Transformer-based neural\nmodels and an active interest in generating stylized text, we present an\napproach to leverage the generalization capabilities of a language model to\nrewrite an input text in a target author's style. Our proposed approach adapts\na pre-trained language model to generate author-stylized text by fine-tuning on\nthe author-specific corpus using a denoising autoencoder (DAE) loss in a\ncascaded encoder-decoder framework. Optimizing over DAE loss allows our model\nto learn the nuances of an author's style without relying on parallel data,\nwhich has been a severe limitation of the previous related works in this space.\nTo evaluate the efficacy of our approach, we propose a linguistically-motivated\nframework to quantify stylistic alignment of the generated text to the target\nauthor at lexical, syntactic and surface levels. The evaluation framework is\nboth interpretable as it leads to several insights about the model, and\nself-contained as it does not rely on external classifiers, e.g. sentiment or\nformality classifiers. Qualitative and quantitative assessment indicates that\nthe proposed approach rewrites the input text with better alignment to the\ntarget style while preserving the original content better than state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 08:13:28 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 09:19:29 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 06:43:02 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Syed", "Bakhtiyar", ""], ["Verma", "Gaurav", ""], ["Srinivasan", "Balaji Vasan", ""], ["Natarajan", "Anandhavelu", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1909.09969", "submitter": "Shira Ozeri", "authors": "Lee-Ad Gottlieb, Shira Ozeri", "title": "Classification in asymmetric spaces via sample compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the rigorous study of classification in quasi-metric spaces.\nThese are point sets endowed with a distance function that is non-negative and\nalso satisfies the triangle inequality, but is asymmetric. We develop and\nrefine a learning algorithm for quasi-metrics based on sample compression and\nnearest neighbor, and prove that it has favorable statistical properties.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 09:07:21 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Ozeri", "Shira", ""]]}, {"id": "1909.09974", "submitter": "Gerasimos Spanakis", "authors": "Cedric Oeldorf and Gerasimos Spanakis", "title": "LoGANv2: Conditional Style-Based Logo Generation with Generative\n  Adversarial Networks", "comments": "accepted for poster presentation at ICMLA 2019, data+code available:\n  https://github.com/cedricoeldorf/ConditionalStyleGAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domains such as logo synthesis, in which the data has a high degree of\nmulti-modality, still pose a challenge for generative adversarial networks\n(GANs). Recent research shows that progressive training (ProGAN) and mapping\nnetwork extensions (StyleGAN) enable both increased training stability for\nhigher dimensional problems and better feature separation within the embedded\nlatent space. However, these architectures leave limited control over shaping\nthe output of the network, which is an undesirable trait in the case of logo\nsynthesis. This paper explores a conditional extension to the StyleGAN\narchitecture with the aim of firstly, improving on the low resolution results\nof previous research and, secondly, increasing the controllability of the\noutput through the use of synthetic class-conditions. Furthermore, methods of\nextracting such class conditions are explored with a focus on the human\ninterpretability, where the challenge lies in the fact that, by nature, visual\nlogo characteristics are hard to define. The introduced conditional style-based\ngenerator architecture is trained on the extracted class-conditions in two\nexperiments and studied relative to the performance of an unconditional model.\nResults show that, whilst the unconditional model more closely matches the\ntraining distribution, high quality conditions enabled the embedding of finer\ndetails onto the latent space, leading to more diverse output.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 10:29:19 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Oeldorf", "Cedric", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1909.09978", "submitter": "Joonas H\\\"am\\\"al\\\"ainen", "authors": "Joonas H\\\"am\\\"al\\\"ainen, Alisson S. C. Alencar, Tommi K\\\"arkk\\\"ainen,\n  C\\'esar L. C. Mattos, Amauri H. Souza J\\'unior, Jo\\~ao P. P. Gomes", "title": "Minimal Learning Machine: Theoretical Results and Clustering-Based\n  Reference Point Selection", "comments": "29 pages, Accepted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Minimal Learning Machine (MLM) is a nonlinear supervised approach based\non learning a linear mapping between distance matrices computed in the input\nand output data spaces, where distances are calculated using a subset of points\ncalled reference points. Its simple formulation has attracted several recent\nworks on extensions and applications. In this paper, we aim to address some\nopen questions related to the MLM. First, we detail theoretical aspects that\nassure the interpolation and universal approximation capabilities of the MLM,\nwhich were previously only empirically verified. Second, we identify the task\nof selecting reference points as having major importance for the MLM's\ngeneralization capability. Several clustering-based methods for reference point\nselection in regression scenarios are then proposed and analyzed. Based on an\nextensive empirical evaluation, we conclude that the evaluated methods are both\nscalable and useful. Specifically, for a small number of reference points, the\nclustering-based methods outperformed the standard random selection of the\noriginal MLM formulation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 10:52:30 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 20:59:01 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Joonas", ""], ["Alencar", "Alisson S. C.", ""], ["K\u00e4rkk\u00e4inen", "Tommi", ""], ["Mattos", "C\u00e9sar L. C.", ""], ["J\u00fanior", "Amauri H. Souza", ""], ["Gomes", "Jo\u00e3o P. P.", ""]]}, {"id": "1909.10000", "submitter": "Nan Gao", "authors": "Dongwei Li, Shuliang Wang, Nan Gao, Qiang He, Yun Yang", "title": "Cutting the Unnecessary Long Tail: Cost-Effective Big Data Clustering in\n  the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering big data often requires tremendous computational resources where\ncloud computing is undoubtedly one of the promising solutions. However, the\ncomputation cost in the cloud can be unexpectedly high if it cannot be managed\nproperly. The long tail phenomenon has been observed widely in the big data\nclustering area, which indicates that the majority of time is often consumed in\nthe middle to late stages in the clustering process. In this research, we try\nto cut the unnecessary long tail in the clustering process to achieve a\nsufficiently satisfactory accuracy at the lowest possible computation cost. A\nnovel approach is proposed to achieve cost-effective big data clustering in the\ncloud. By training the regression model with the sampling data, we can make\nwidely used k-means and EM (Expectation-Maximization) algorithms stop\nautomatically at an early point when the desired accuracy is obtained.\nExperiments are conducted on four popular data sets and the results demonstrate\nthat both k-means and EM algorithms can achieve high cost-effectiveness in the\ncloud with our proposed approach. For example, in the case studies with the\nmuch more efficient k-means algorithm, we find that achieving a 99% accuracy\nneeds only 47.71%-71.14% of the computation cost required for achieving a 100%\naccuracy while the less efficient EM algorithm needs 16.69%-32.04% of the\ncomputation cost. To put that into perspective, in the United States land use\nclassification example, our approach can save up to $94,687.49 for the\ngovernment in each use.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 13:22:24 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Li", "Dongwei", ""], ["Wang", "Shuliang", ""], ["Gao", "Nan", ""], ["He", "Qiang", ""], ["Yang", "Yun", ""]]}, {"id": "1909.10008", "submitter": "Jo\\~ao Ribeiro", "authors": "Jo\\~ao Ribeiro, Francisco S. Melo and Jo\\~ao Dias", "title": "Multi-task Learning and Catastrophic Forgetting in Continual\n  Reinforcement Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate two hypothesis regarding the use of deep\nreinforcement learning in multiple tasks. The first hypothesis is driven by the\nquestion of whether a deep reinforcement learning algorithm, trained on two\nsimilar tasks, is able to outperform two single-task, individually trained\nalgorithms, by more efficiently learning a new, similar task, that none of the\nthree algorithms has encountered before. The second hypothesis is driven by the\nquestion of whether the same multi-task deep RL algorithm, trained on two\nsimilar tasks and augmented with elastic weight consolidation (EWC), is able to\nretain similar performance on the new task, as a similar algorithm without EWC,\nwhilst being able to overcome catastrophic forgetting in the two previous\ntasks. We show that a multi-task Asynchronous Advantage Actor-Critic (GA3C)\nalgorithm, trained on Space Invaders and Demon Attack, is in fact able to\noutperform two single-tasks GA3C versions, trained individually for each\nsingle-task, when evaluated on a new, third task, namely, Phoenix. We also show\nthat, when training two trained multi-task GA3C algorithms on the third task,\nif one is augmented with EWC, it is not only able to achieve similar\nperformance on the new task, but also capable of overcoming a substantial\namount of catastrophic forgetting on the two previous tasks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 14:00:29 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Ribeiro", "Jo\u00e3o", ""], ["Melo", "Francisco S.", ""], ["Dias", "Jo\u00e3o", ""]]}, {"id": "1909.10023", "submitter": "Guoliang Dong", "authors": "Guoliang Dong, Jingyi Wang, Jun Sun, Yang Zhang, Xinyu Wang, Ting Dai,\n  Jin Song Dong, Xingen Wang", "title": "Towards Interpreting Recurrent Neural Networks through Probabilistic\n  Abstraction", "comments": "Accepted by ASE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are becoming a popular tool for solving many real-world\nproblems such as object recognition and machine translation, thanks to its\nexceptional performance as an end-to-end solution. However, neural networks are\ncomplex black-box models, which hinders humans from interpreting and\nconsequently trusting them in making critical decisions. Towards interpreting\nneural networks, several approaches have been proposed to extract simple\ndeterministic models from neural networks. The results are not encouraging\n(e.g., low accuracy and limited scalability), fundamentally due to the limited\nexpressiveness of such simple models.\n  In this work, we propose an approach to extract probabilistic automata for\ninterpreting an important class of neural networks, i.e., recurrent neural\nnetworks. Our work distinguishes itself from existing approaches in two\nimportant ways. One is that probability is used to compensate for the loss of\nexpressiveness. This is inspired by the observation that human reasoning is\noften `probabilistic'. The other is that we adaptively identify the right level\nof abstraction so that a simple model is extracted in a request-specific way.\nWe conduct experiments on several real-world datasets using state-of-the-art\narchitectures including GRU and LSTM. The result shows that our approach\nsignificantly improves existing approaches in terms of accuracy or scalability.\nLastly, we demonstrate the usefulness of the extracted models through detecting\nadversarial texts.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 15:11:15 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 03:47:40 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Dong", "Guoliang", ""], ["Wang", "Jingyi", ""], ["Sun", "Jun", ""], ["Zhang", "Yang", ""], ["Wang", "Xinyu", ""], ["Dai", "Ting", ""], ["Dong", "Jin Song", ""], ["Wang", "Xingen", ""]]}, {"id": "1909.10072", "submitter": "Shih-Kang Chao", "authors": "Shih-Kang Chao and Guang Cheng", "title": "A generalization of regularized dual averaging and its dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excessive computational cost for learning large data and streaming data can\nbe alleviated by using stochastic algorithms, such as stochastic gradient\ndescent and its variants. Recent advances improve stochastic algorithms on\nconvergence speed, adaptivity and structural awareness. However, distributional\naspects of these new algorithms are poorly understood, especially for\nstructured parameters. To develop statistical inference in this case, we\npropose a class of generalized regularized dual averaging (gRDA) algorithms\nwith constant step size, which improves RDA (Xiao, 2010; Flammarion and Bach,\n2017). Weak convergence of gRDA trajectories are studied, and as a consequence,\nfor the first time in the literature, the asymptotic distributions for online\nl1 penalized problems become available. These general results apply to both\nconvex and non-convex differentiable loss functions, and in particular, recover\nthe existing regret bound for convex losses (Nemirovski et al., 2009). As\nimportant applications, statistical inferential theory on online sparse linear\nregression and online sparse principal component analysis are developed, and\nare supported by extensive numerical analysis. Interestingly, when gRDA is\nproperly tuned, support recovery and central limiting distribution (with mean\nzero) hold simultaneously in the online setting, which is in contrast with the\nbiased central limiting distribution of batch Lasso (Knight and Fu, 2000).\nTechnical devices, including weak convergence of stochastic mirror descent, are\ndeveloped as by-products with independent interest. Preliminary empirical\nanalysis of modern image data shows that learning very sparse deep neural\nnetworks by gRDA does not necessarily sacrifice testing accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 19:12:26 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Chao", "Shih-Kang", ""], ["Cheng", "Guang", ""]]}, {"id": "1909.10086", "submitter": "Saurabh Verma", "authors": "Saurabh Verma, Zhi-Li Zhang", "title": "Learning Universal Graph Neural Network Embeddings With Aid Of Transfer\n  Learning", "comments": "Previous Paper Title: Deep Universal Graph Embedding Neural Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning powerful data embeddings has become a center piece in machine\nlearning, especially in natural language processing and computer vision\ndomains. The crux of these embeddings is that they are pretrained on huge\ncorpus of data in a unsupervised fashion, sometimes aided with transfer\nlearning. However currently in the graph learning domain, embeddings learned\nthrough existing graph neural networks (GNNs) are task dependent and thus\ncannot be shared across different datasets. In this paper, we present a first\npowerful and theoretically guaranteed graph neural network that is designed to\nlearn task-independent graph embeddings, thereafter referred to as deep\nuniversal graph embedding (DUGNN). Our DUGNN model incorporates a novel graph\nneural network (as a universal graph encoder) and leverages rich Graph Kernels\n(as a multi-task graph decoder) for both unsupervised learning and\n(task-specific) adaptive supervised learning. By learning task-independent\ngraph embeddings across diverse datasets, DUGNN also reaps the benefits of\ntransfer learning. Through extensive experiments and ablation studies, we show\nthat the proposed DUGNN model consistently outperforms both the existing\nstate-of-art GNN models and Graph Kernels by an increased accuracy of 3% - 8%\non graph classification benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 20:21:15 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 02:11:12 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 05:06:26 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Verma", "Saurabh", ""], ["Zhang", "Zhi-Li", ""]]}, {"id": "1909.10136", "submitter": "Pravir Singh Gupta", "authors": "Pravir Singh Gupta, Xin Yuan, Gwan Seong Choi", "title": "DRCAS: Deep Restoration Network for Hardware Based Compressive\n  Acquisition Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the power and performance improvement in image acquisition\ndevices by the use of CAS (Compressed Acquisition Scheme) and DNN (Deep Neural\nNetworks). Towards this end, we propose a novel image acquisition scheme HCAS\n(Hardware based Compressed Acquisition Scheme) using hardware-based binning\n(downsampling), bit truncation and JPEG compression and develop a deep learning\nbased reconstruction network for images acquired using the same. HCAS is\nmotivated by the fact that in-situ compression of raw data using binning and\nbit truncation results in reduction in data traffic and power in the entire\ndownstream image processing pipeline and additional compression of processed\ndata using JPEG will help in storage/transmission of images. The combination of\nin-situ compression with JPEG leads to high compression ratios, significant\npower savings with further advantages of image acquisition simplification.\nBearing these concerns in mind, we propose DRCAS (Deep Restoration network for\nhardware based Compressed Acquisition Scheme), which to our best knowledge, is\nthe first work proposed in the literature for restoration of images acquired\nusing acquisition scheme like HCAS. When compared with the CAS methods (bicubic\ndownsampling) used in super resolution tasks in literature, HCAS proposed in\nthis paper performs superior in terms of both compression ratio and being\nhardware friendly. The restoration network DRCAS also perform superior than\nstate-of-the-art super resolution networks while being much smaller. Thus HCAS\nand DRCAS technique will enable us to design much simpler and power efficient\nimage acquisition pipelines.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 03:04:19 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 23:57:27 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Gupta", "Pravir Singh", ""], ["Yuan", "Xin", ""], ["Choi", "Gwan Seong", ""]]}, {"id": "1909.10145", "submitter": "Zhen Li", "authors": "Xuhui Meng, Zhen Li, Dongkun Zhang and George Em Karniadakis", "title": "PPINN: Parareal Physics-Informed Neural Network for time-dependent PDEs", "comments": "17 pages, 7 figures, 5 tables", "journal-ref": null, "doi": "10.1016/j.cma.2020.113250", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-informed neural networks (PINNs) encode physical conservation laws\nand prior physical knowledge into the neural networks, ensuring the correct\nphysics is represented accurately while alleviating the need for supervised\nlearning to a great degree. While effective for relatively short-term time\nintegration, when long time integration of the time-dependent PDEs is sought,\nthe time-space domain may become arbitrarily large and hence training of the\nneural network may become prohibitively expensive. To this end, we develop a\nparareal physics-informed neural network (PPINN), hence decomposing a long-time\nproblem into many independent short-time problems supervised by an\ninexpensive/fast coarse-grained (CG) solver. In particular, the serial CG\nsolver is designed to provide approximate predictions of the solution at\ndiscrete times, while initiate many fine PINNs simultaneously to correct the\nsolution iteratively. There is a two-fold benefit from training PINNs with\nsmall-data sets rather than working on a large-data set directly, i.e.,\ntraining of individual PINNs with small-data is much faster, while training the\nfine PINNs can be readily parallelized. Consequently, compared to the original\nPINN approach, the proposed PPINN approach may achieve a significant speedup\nfor long-time integration of PDEs, assuming that the CG solver is fast and can\nprovide reasonable predictions of the solution, hence aiding the PPINN solution\nto converge in just a few iterations. To investigate the PPINN performance on\nsolving time-dependent PDEs, we first apply the PPINN to solve the Burgers\nequation, and subsequently we apply the PPINN to solve a two-dimensional\nnonlinear diffusion-reaction equation. Our results demonstrate that PPINNs\nconverge in a couple of iterations with significant speed-ups proportional to\nthe number of time-subdomains employed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 03:53:53 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Meng", "Xuhui", ""], ["Li", "Zhen", ""], ["Zhang", "Dongkun", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1909.10155", "submitter": "Ananya Kumar", "authors": "Ananya Kumar, Percy Liang, Tengyu Ma", "title": "Verified Uncertainty Calibration", "comments": "Accepted as a spotlight to NeurIPS 2019, updated to include\n  experiments for ECE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications such as weather forecasting and personalized medicine demand\nmodels that output calibrated probability estimates---those representative of\nthe true likelihood of a prediction. Most models are not calibrated out of the\nbox but are recalibrated by post-processing model outputs. We find in this work\nthat popular recalibration methods like Platt scaling and temperature scaling\nare (i) less calibrated than reported, and (ii) current techniques cannot\nestimate how miscalibrated they are. An alternative method, histogram binning,\nhas measurable calibration error but is sample inefficient---it requires\n$O(B/\\epsilon^2)$ samples, compared to $O(1/\\epsilon^2)$ for scaling methods,\nwhere $B$ is the number of distinct probabilities the model can output. To get\nthe best of both worlds, we introduce the scaling-binning calibrator, which\nfirst fits a parametric function to reduce variance and then bins the function\nvalues to actually ensure calibration. This requires only $O(1/\\epsilon^2 + B)$\nsamples. Next, we show that we can estimate a model's calibration error more\naccurately using an estimator from the meteorological community---or\nequivalently measure its calibration error with fewer samples ($O(\\sqrt{B})$\ninstead of $O(B)$). We validate our approach with multiclass calibration\nexperiments on CIFAR-10 and ImageNet, where we obtain a 35% lower calibration\nerror than histogram binning and, unlike scaling methods, guarantees on true\ncalibration. In these experiments, we also estimate the calibration error and\nECE more accurately than the commonly used plugin estimators. We implement all\nthese methods in a Python library:\nhttps://pypi.org/project/uncertainty-calibration\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 04:41:42 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 18:59:12 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Kumar", "Ananya", ""], ["Liang", "Percy", ""], ["Ma", "Tengyu", ""]]}, {"id": "1909.10227", "submitter": "Evgeny Baraboshkin E.", "authors": "E.E. Baraboshkin, L.S. Ismailova, D.M. Orlov, E.A. Zhukovskaya, G.A.\n  Kalmykov, O.V. Khotylev, E.Yu. Baraboshkin, D.A. Koroteev", "title": "Deep Convolutions for In-Depth Automated Rock Typing", "comments": "25 pages, 9 figures, 3 tables, submitted to Computers and Geosciences\n  Journal. Keywords: Core Image; Description; Convolutional Neural Networks;\n  Representation; Geology; Lithotypes", "journal-ref": null, "doi": "10.1016/j.cageo.2019.104330", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The description of rocks is one of the most time-consuming tasks in the\neveryday work of a geologist, especially when very accurate description is\nrequired. We here present a method that reduces the time needed for accurate\ndescription of rocks, enabling the geologist to work more efficiently. We\ndescribe the application of methods based on color distribution analysis and\nfeature extraction. Then we focus on a new approach, used by us, which is based\non convolutional neural networks. We used several well-known neural network\narchitectures (AlexNet, VGG, GoogLeNet, ResNet) and made a comparison of their\nperformance. The precision of the algorithms is up to 95% on the validation set\nwith GoogLeNet architecture. The best of the proposed algorithms can describe\n50 m of full-size core in one minute.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 08:55:36 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 10:25:01 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 08:13:09 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Baraboshkin", "E. E.", ""], ["Ismailova", "L. S.", ""], ["Orlov", "D. M.", ""], ["Zhukovskaya", "E. A.", ""], ["Kalmykov", "G. A.", ""], ["Khotylev", "O. V.", ""], ["Baraboshkin", "E. Yu.", ""], ["Koroteev", "D. A.", ""]]}, {"id": "1909.10228", "submitter": "Zhigang Yao", "authors": "Zhigang Yao and Yuqing Xia", "title": "Manifold Fitting under Unbounded Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an emerging trend in non-Euclidean dimension reduction of\naiming to recover a low dimensional structure, namely a manifold, underlying\nthe high dimensional data. Recovering the manifold requires the noise to be of\ncertain concentration. Existing methods address this problem by constructing an\noutput manifold based on the tangent space estimation at each sample point.\nAlthough theoretical convergence for these methods is guaranteed, either the\nsamples are noiseless or the noise is bounded. However, if the noise is\nunbounded, which is a common scenario, the tangent space estimation of the\nnoisy samples will be blurred, thereby breaking the manifold fitting. In this\npaper, we introduce a new manifold-fitting method, by which the output manifold\nis constructed by directly estimating the tangent spaces at the projected\npoints on the underlying manifold, rather than at the sample points, to\ndecrease the error caused by the noise. Our new method provides theoretical\nconvergence, in terms of the upper bound on the Hausdorff distance between the\noutput and underlying manifold and the lower bound on the reach of the output\nmanifold, when the noise is unbounded. Numerical simulations are provided to\nvalidate our theoretical findings and demonstrate the advantages of our method\nover other relevant methods. Finally, our method is applied to real data\nexamples.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 08:55:41 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Yao", "Zhigang", ""], ["Xia", "Yuqing", ""]]}, {"id": "1909.10238", "submitter": "Tao Sun", "authors": "Tao Sun, Dongsheng Li", "title": "Decentralized Markov Chain Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized stochastic gradient method emerges as a promising solution for\nsolving large-scale machine learning problems. This paper studies the\ndecentralized Markov chain gradient descent (DMGD) algorithm - a variant of the\ndecentralized stochastic gradient methods where the random samples are taken\nalong the trajectory of a Markov chain. This setting is well-motivated when\nobtaining independent samples is costly or impossible, which excludes the use\nof the traditional stochastic gradient algorithms. Specifically, we consider\nthe first- and zeroth-order versions of decentralized Markov chain gradient\ndescent over a connected network, where each node only communicates with its\nneighbors about intermediate results. The nonergodic convergence and the\nergodic convergence rate of the proposed algorithms have been rigorously\nestablished, and their critical dependences on the network topology and the\nmixing time of Markov chain have been highlighted. The numerical tests further\nvalidate the sample efficiency of our algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 09:20:53 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 13:15:01 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Sun", "Tao", ""], ["Li", "Dongsheng", ""]]}, {"id": "1909.10247", "submitter": "Robert MacKay", "authors": "Robert S. MacKay", "title": "Inference of modes for linear stochastic processes", "comments": "Expanded in several places in response to reading by an electrical\n  engineer", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For dynamical systems that can be modelled as asymptotically stable linear\nsystems forced by Gaussian noise, this paper develops methods to infer or\nestimate their modes from observations in real time. The modes can be real or\ncomplex. For a real mode, we wish to infer its damping rate and mode shape. For\na complex mode, we wish to infer its frequency, damping rate and (complex) mode\nshape. Their amplitudes and correlations are encoded in a mode covariance\nmatrix. The work is motivated and illustrated by the problem of detection of\noscillations in power flow in AC electrical networks. Suggestions of other\napplications are given.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 09:43:05 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 16:46:47 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["MacKay", "Robert S.", ""]]}, {"id": "1909.10248", "submitter": "Yaping Zheng", "authors": "Yaping Zheng, Shiyi Chen, Xinni Zhang, Xiaofeng Zhang, Xiaofei Yang,\n  Di Wang", "title": "Heterogeneous-Temporal Graph Convolutional Networks: Make the Community\n  Detection Much Better", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection has long been an important yet challenging task to\nanalyze complex networks with a focus on detecting topological structures of\ngraph data. Essentially, real-world graph data contains various features, node\nand edge types which dynamically vary over time, and this invalidates most\nexisting community detection approaches. To cope with these issues, this paper\nproposes the heterogeneous-temporal graph convolutional networks (HTGCN) to\ndetect communities from hetergeneous and temporal graphs. Particularly, we\nfirst design a heterogeneous GCN component to acquire feature representations\nfor each heterogeneous graph at each time step. Then, a residual compressed\naggregation component is proposed to represent \"dynamic\" features for \"varying\"\ncommunities, which are then aggregated with \"static\" features extracted from\ncurrent graph. Extensive experiments are evaluated on two real-world datasets,\ni.e., DBLP and IMDB. The promising results demonstrate that the proposed HTGCN\nis superior to both benchmark and the state-of-the-art approaches, e.g., GCN,\nGAT, GNN, LGNN, HAN and STAR, with respect to a number of evaluation criteria.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 09:45:08 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 11:12:02 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Zheng", "Yaping", ""], ["Chen", "Shiyi", ""], ["Zhang", "Xinni", ""], ["Zhang", "Xiaofeng", ""], ["Yang", "Xiaofei", ""], ["Wang", "Di", ""]]}, {"id": "1909.10296", "submitter": "Christian Requena-Mesa", "authors": "Christian Requena-Mesa, Markus Reichstein, Miguel Mahecha, Basil\n  Kraft, Joachim Denzler", "title": "Predicting Landscapes from Environmental Conditions Using Generative\n  Networks", "comments": "Accepted conference paper at GCPR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Landscapes are meaningful ecological units that strongly depend on the\nenvironmental conditions. Such dependencies between landscapes and the\nenvironment have been noted since the beginning of Earth sciences and cast into\nconceptual models describing the interdependencies of climate, geology,\nvegetation and geomorphology. Here, we ask whether landscapes, as seen from\nspace, can be statistically predicted from pertinent environmental conditions.\nTo this end we adapted a deep learning generative model in order to establish\nthe relationship between the environmental conditions and the view of\nlandscapes from the Sentinel-2 satellite. We trained a conditional generative\nadversarial network to generate multispectral imagery given a set of climatic,\nterrain and anthropogenic predictors. The generated imagery of the landscapes\nshare many characteristics with the real one. Results based on landscape patch\nmetrics, indicative of landscape composition and structure, show that the\nproposed generative model creates landscapes that are more similar to the\ntargets than the baseline models while overall reflectance and vegetation cover\nare predicted better. We demonstrate that for many purposes the generated\nlandscapes behave as real with immediate application for global change studies.\nWe envision the application of machine learning as a tool to forecast the\neffects of climate change on the spatial features of landscapes, while we\nassess its limitations and breaking points.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 11:24:52 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Requena-Mesa", "Christian", ""], ["Reichstein", "Markus", ""], ["Mahecha", "Miguel", ""], ["Kraft", "Basil", ""], ["Denzler", "Joachim", ""]]}, {"id": "1909.10300", "submitter": "Edouard Pauwels", "authors": "J\\'er\\^ome Bolte and Edouard Pauwels", "title": "Conservative set valued fields, automatic differentiation, stochastic\n  gradient method and deep learning", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern problems in AI or in numerical analysis require nonsmooth approaches\nwith a flexible calculus. We introduce generalized derivatives called\nconservative fields for which we develop a calculus and provide representation\nformulas. Functions having a conservative field are called path differentiable:\nconvex, concave, Clarke regular and any semialgebraic Lipschitz continuous\nfunctions are path differentiable. Using Whitney stratification techniques for\nsemialgebraic and definable sets, our model provides variational formulas for\nnonsmooth automatic differentiation oracles, as for instance the famous\nbackpropagation algorithm in deep learning. Our differential model is applied\nto establish the convergence in values of nonsmooth stochastic gradient methods\nas they are implemented in practice.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 11:39:16 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 15:00:51 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 15:16:30 GMT"}, {"version": "v4", "created": "Thu, 9 Apr 2020 09:43:26 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Bolte", "J\u00e9r\u00f4me", ""], ["Pauwels", "Edouard", ""]]}, {"id": "1909.10304", "submitter": "Soroush Seifi", "authors": "Soroush Seifi, Tinne Tuytelaars", "title": "Where to Look Next: Unsupervised Active Visual Exploration on 360{\\deg}\n  Input", "comments": "Oral Presentation and best Paper Award at 360 Perception and\n  Interaction Workshop at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of active visual exploration of large 360{\\deg}\ninputs. In our setting an active agent with a limited camera bandwidth explores\nits 360{\\deg} environment by changing its viewing direction at limited discrete\ntime steps. As such, it observes the world as a sequence of narrow\nfield-of-view 'glimpses', deciding for itself where to look next. Our proposed\nmethod exceeds previous works' performance by a significant margin without the\nneed for deep reinforcement learning or training separate networks as\nsidekicks. A key component of our system are the spatial memory maps that make\nthe system aware of the glimpses' orientations (locations in the 360{\\deg}\nimage). Further, we stress the advantages of retina-like glimpses when the\nagent's sensor bandwidth and time-steps are limited. Finally, we use our\ntrained model to do classification of the whole scene using only the\ninformation observed in the glimpses.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 11:50:46 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 10:38:02 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Seifi", "Soroush", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "1909.10305", "submitter": "Alice Othmani", "authors": "Amine Djerghri, Ahmed Rachid Hazourli, Alice Othmani", "title": "Deep Multi-Facial patches Aggregation Network for Expression\n  Classification from Face Images", "comments": "we have a new version of the paper arXiv:2002.09298", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Emotional Intelligence in Human-Computer Interaction has attracted increasing\nattention from researchers in multidisciplinary research fields including\npsychology, computer vision, neuroscience, artificial intelligence, and related\ndisciplines. Human prone to naturally interact with computers face-to-face.\nHuman Expressions is an important key to better link human and computers. Thus,\ndesigning interfaces able to understand human expressions and emotions can\nimprove Human-Computer Interaction (HCI) for better communication. In this\npaper, we investigate HCI via a deep multi-facial patches aggregation network\nfor Face Expression Recognition (FER). Deep features are extracted from facial\nparts and aggregated for expression classification. Several problems may affect\nthe performance of the proposed framework like the small size of FER datasets\nand the high number of parameters to learn. For That, two data augmentation\ntechniques are proposed for facial expression generation to expand the labeled\ntraining. The proposed framework is evaluated on the extended Cohn-Konade\ndataset (CK+) and promising results are achieved.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 11:52:27 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 11:52:19 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Djerghri", "Amine", ""], ["Hazourli", "Ahmed Rachid", ""], ["Othmani", "Alice", ""]]}, {"id": "1909.10312", "submitter": "Soroush Seifi", "authors": "Soroush Seifi, Tinne Tuytelaars", "title": "How to improve CNN-based 6-DoF camera pose estimation", "comments": "Accepted at Deep Learning for Visual SLAM workshop at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) and transfer learning have recently been\nused for 6 degrees of freedom (6-DoF) camera pose estimation. While they do not\nreach the same accuracy as visual SLAM-based approaches and are restricted to a\nspecific environment, they excel in robustness and can be applied even to a\nsingle image. In this paper, we study PoseNet [1] and investigate modifications\nbased on datasets' characteristics to improve the accuracy of the pose\nestimates. In particular, we emphasize the importance of field-of-view over\nimage resolution; we present a data augmentation scheme to reduce overfitting;\nwe study the effect of Long-Short-Term-Memory (LSTM) cells. Lastly, we combine\nthese modifications and improve PoseNet's performance for monocular CNN based\ncamera pose regression.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 12:12:17 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 10:38:42 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Seifi", "Soroush", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "1909.10333", "submitter": "Debleena Sengupta", "authors": "Debleena Sengupta", "title": "Deep learning architectures for automated image segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image segmentation is widely used in a variety of computer vision tasks, such\nas object localization and recognition, boundary detection, and medical\nimaging. This thesis proposes deep learning architectures to improve automatic\nobject localization and boundary delineation for salient object segmentation in\nnatural images and for 2D medical image segmentation. First, we propose and\nevaluate a novel dilated dense encoder-decoder architecture with a custom\ndilated spatial pyramid pooling block to accurately localize and delineate\nboundaries for salient object segmentation. The dilation offers better spatial\nunderstanding and the dense connectivity preserves features learned at\nshallower levels of the network for better localization. Tested on three\npublicly available datasets, our architecture outperforms the state-of-the-art\nfor one and is very competitive on the other two. Second, we propose and\nevaluate a custom 2D dilated dense UNet architecture for accurate lesion\nlocalization and segmentation in medical images. This architecture can be\nutilized as a stand-alone segmentation framework or used as a rich feature\nextracting backbone to aid other models in medical image segmentation. Our\narchitecture outperforms all baseline models for accurate lesion localization\nand segmentation on a new dataset. We furthermore explore the main\nconsiderations that should be taken into account for 3D medical image\nsegmentation, among them preprocessing techniques and specialized loss\nfunctions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 19:46:30 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Sengupta", "Debleena", ""]]}, {"id": "1909.10340", "submitter": "Gideon Kowadlo", "authors": "Gideon Kowadlo, Abdelrahman Ahmed, and David Rawlinson", "title": "AHA! an 'Artificial Hippocampal Algorithm' for Episodic Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of ML research concerns slow, statistical learning of i.i.d.\nsamples from large, labelled datasets. Animals do not learn this way. An\nenviable characteristic of animal learning is `episodic' learning - the ability\nto memorise a specific experience as a composition of existing concepts, after\njust one experience, without provided labels. The new knowledge can then be\nused to distinguish between similar experiences, to generalise between classes,\nand to selectively consolidate to long-term memory. The Hippocampus is known to\nbe vital to these abilities. AHA is a biologically-plausible computational\nmodel of the Hippocampus. Unlike most machine learning models, AHA is trained\nwithout external labels and uses only local credit assignment. We demonstrate\nAHA in a superset of the Omniglot one-shot classification benchmark. The\nextended benchmark covers a wider range of known hippocampal functions by\ntesting pattern separation, completion, and recall of original input. These\nfunctions are all performed within a single configuration of the computational\nmodel. Despite these constraints, image classification results are comparable\nto conventional deep convolutional ANNs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 12:49:47 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 15:47:27 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 06:00:38 GMT"}, {"version": "v4", "created": "Fri, 8 Nov 2019 01:56:18 GMT"}, {"version": "v5", "created": "Wed, 25 Mar 2020 04:08:34 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Kowadlo", "Gideon", ""], ["Ahmed", "Abdelrahman", ""], ["Rawlinson", "David", ""]]}, {"id": "1909.10351", "submitter": "Yichun Yin", "authors": "Xiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Linlin\n  Li, Fang Wang and Qun Liu", "title": "TinyBERT: Distilling BERT for Natural Language Understanding", "comments": "Findings of EMNLP 2020; results have been updated; code and model:\n  https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language model pre-training, such as BERT, has significantly improved the\nperformances of many natural language processing tasks. However, pre-trained\nlanguage models are usually computationally expensive, so it is difficult to\nefficiently execute them on resource-restricted devices. To accelerate\ninference and reduce model size while maintaining accuracy, we first propose a\nnovel Transformer distillation method that is specially designed for knowledge\ndistillation (KD) of the Transformer-based models. By leveraging this new KD\nmethod, the plenty of knowledge encoded in a large teacher BERT can be\neffectively transferred to a small student Tiny-BERT. Then, we introduce a new\ntwo-stage learning framework for TinyBERT, which performs Transformer\ndistillation at both the pretraining and task-specific learning stages. This\nframework ensures that TinyBERT can capture he general-domain as well as the\ntask-specific knowledge in BERT.\n  TinyBERT with 4 layers is empirically effective and achieves more than 96.8%\nthe performance of its teacher BERTBASE on GLUE benchmark, while being 7.5x\nsmaller and 9.4x faster on inference. TinyBERT with 4 layers is also\nsignificantly better than 4-layer state-of-the-art baselines on BERT\ndistillation, with only about 28% parameters and about 31% inference time of\nthem. Moreover, TinyBERT with 6 layers performs on-par with its teacher\nBERTBASE.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 13:05:35 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 12:39:36 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 01:29:39 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 01:50:34 GMT"}, {"version": "v5", "created": "Fri, 16 Oct 2020 02:12:46 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Jiao", "Xiaoqi", ""], ["Yin", "Yichun", ""], ["Shang", "Lifeng", ""], ["Jiang", "Xin", ""], ["Chen", "Xiao", ""], ["Li", "Linlin", ""], ["Wang", "Fang", ""], ["Liu", "Qun", ""]]}, {"id": "1909.10364", "submitter": "Rahim Entezari", "authors": "Rahim Entezari, Olga Saukh", "title": "Class-dependent Compression of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's deep neural networks require substantial computation resources for\ntheir training, storage, and inference, which limits their effective use on\nresource-constrained devices. Many recent research activities explore different\noptions for compressing and optimizing deep models. On the one hand, in many\nreal-world applications, we face the data imbalance challenge, i.e. when the\nnumber of labeled instances of one class considerably outweighs the number of\nlabeled instances of the other class. On the other hand, applications may pose\na class imbalance problem, i.e. higher number of false positives produced when\ntraining a model and optimizing its performance may be tolerable, yet the\nnumber of false negatives must stay low. The problem originates from the fact\nthat some classes are more important for the application than others, e.g.\ndetection problems in medical and surveillance domains. Motivated by the\nsuccess of the lottery ticket hypothesis, in this paper we propose an iterative\ndeep model compression technique, which keeps the number of false negatives of\nthe compressed model close to the one of the original model at the price of\nincreasing the number of false positives if necessary. Our experimental\nevaluation using two benchmark data sets shows that the resulting compressed\nsub-networks 1) achieve up to 35% lower number of false negatives than the\ncompressed model without class optimization, 2) provide an overall higher\nAUC_ROC measure, and 3) use up to 99% fewer parameters compared to the original\nnetwork.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 13:47:51 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 14:24:12 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 15:47:42 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Entezari", "Rahim", ""], ["Saukh", "Olga", ""]]}, {"id": "1909.10367", "submitter": "Boris Knyazev", "authors": "Boris Knyazev, Carolyn Augusta, Graham W. Taylor", "title": "Learning Temporal Attention in Dynamic Graphs with Bilinear Interactions", "comments": "15 pages, source code is available at\n  https://github.com/uoguelph-mlrg/LDG", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about graphs evolving over time is a challenging concept in many\ndomains, such as bioinformatics, physics, and social networks. We consider a\ncommon case in which edges can be short term interactions (e.g., messaging) or\nlong term structural connections (e.g., friendship). In practice, long term\nedges are often specified by humans. Human-specified edges can be both\nexpensive to produce and suboptimal for the downstream task. To alleviate these\nissues, we propose a model based on temporal point processes and variational\nautoencoders that learns to infer temporal attention between nodes by observing\nnode communication. As temporal attention drives between-node feature\npropagation, using the dynamics of node interactions to learn this key\ncomponent provides more flexibility while simultaneously avoiding issues\nassociated with human-specified edges. We also propose a bilinear\ntransformation layer for pairs of node features instead of concatenation,\ntypically used in prior work, and demonstrate its superior performance in all\ncases. In experiments on two datasets in the dynamic link prediction task, our\nmodel often outperforms the baseline model that requires a human-specified\ngraph. Moreover, our learned attention is semantically interpretable and infers\nconnections similar to actual graphs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 13:54:10 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 01:08:38 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Knyazev", "Boris", ""], ["Augusta", "Carolyn", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1909.10387", "submitter": "Jacopo Panerati", "authors": "Hehui Zheng (1), Jacopo Panerati (2), Giovanni Beltrame (2), Amanda\n  Prorok (1) ((1) University of Cambridge, (2) Polytechnique Montreal)", "title": "An Adversarial Approach to Private Flocking in Mobile Robot Teams", "comments": "10 pages, 13 figures", "journal-ref": "IEEE Robotics and Automation Letters (2020)", "doi": "10.1109/LRA.2020.2967331", "report-no": null, "categories": "cs.RO cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy is an important facet of defence against adversaries. In this letter,\nwe introduce the problem of private flocking. We consider a team of mobile\nrobots flocking in the presence of an adversary, who is able to observe all\nrobots' trajectories, and who is interested in identifying the leader. We\npresent a method that generates private flocking controllers that hide the\nidentity of the leader robot. Our approach towards privacy leverages a\ndata-driven adversarial co-optimization scheme. We design a mechanism that\noptimizes flocking control parameters, such that leader inference is hindered.\nAs the flocking performance improves, we successively train an adversarial\ndiscriminator that tries to infer the identity of the leader robot. To evaluate\nthe performance of our co-optimization scheme, we investigate different classes\nof reference trajectories. Although it is reasonable to assume that there is an\ninherent trade-off between flocking performance and privacy, our results\ndemonstrate that we are able to achieve high flocking performance and\nsimultaneously reduce the risk of revealing the leader.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 14:28:56 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 12:58:07 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 17:23:47 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zheng", "Hehui", "", "University of Cambridge"], ["Panerati", "Jacopo", "", "Polytechnique Montreal"], ["Beltrame", "Giovanni", "", "Polytechnique Montreal"], ["Prorok", "Amanda", "", "University of Cambridge"]]}, {"id": "1909.10389", "submitter": "Luca Canali", "authors": "Matteo Migliorini, Riccardo Castellotti, Luca Canali, Marco Zanetti", "title": "Machine Learning Pipelines with Modern Big Data Tools for High Energy\n  Physics", "comments": "This is a pre-print of an article published in Computing and Software\n  for Big Science. The final authenticated version is available online at\n  https://rdcu.be/b4Wk9", "journal-ref": "Comput Softw Big Sci 4, 8 (2020)", "doi": "10.1007/s41781-020-00040-0", "report-no": null, "categories": "cs.DC cs.LG hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The effective utilization at scale of complex machine learning (ML)\ntechniques for HEP use cases poses several technological challenges, most\nimportantly on the actual implementation of dedicated end-to-end data\npipelines. A solution to these challenges is presented, which allows training\nneural network classifiers using solutions from the Big Data and data science\necosystems, integrated with tools, software, and platforms common in the HEP\nenvironment. In particular, Apache Spark is exploited for data preparation and\nfeature engineering, running the corresponding (Python) code interactively on\nJupyter notebooks. Key integrations and libraries that make Spark capable of\ningesting data stored using ROOT format and accessed via the XRootD protocol,\nare described and discussed. Training of the neural network models, defined\nusing the Keras API, is performed in a distributed fashion on Spark clusters by\nusing BigDL with Analytics Zoo and also by using TensorFlow, notably for\ndistributed training on CPU and GPU resourcess. The implementation and the\nresults of the distributed training are described in detail in this work.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 14:31:44 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 15:03:35 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 13:21:43 GMT"}, {"version": "v4", "created": "Tue, 17 Mar 2020 12:19:08 GMT"}, {"version": "v5", "created": "Tue, 16 Jun 2020 13:46:57 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Migliorini", "Matteo", ""], ["Castellotti", "Riccardo", ""], ["Canali", "Luca", ""], ["Zanetti", "Marco", ""]]}, {"id": "1909.10407", "submitter": "Mandar Gogate", "authors": "Mandar Gogate, Kia Dashtipour, Ahsan Adeel, Amir Hussain", "title": "CochleaNet: A Robust Language-independent Audio-Visual Model for Speech\n  Enhancement", "comments": "34 pages, 11 figures, Submitted to Information Fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy situations cause huge problems for suffers of hearing loss as hearing\naids often make the signal more audible but do not always restore the\nintelligibility. In noisy settings, humans routinely exploit the audio-visual\n(AV) nature of the speech to selectively suppress the background noise and to\nfocus on the target speaker. In this paper, we present a causal, language,\nnoise and speaker independent AV deep neural network (DNN) architecture for\nspeech enhancement (SE). The model exploits the noisy acoustic cues and noise\nrobust visual cues to focus on the desired speaker and improve the speech\nintelligibility. To evaluate the proposed SE framework a first of its kind AV\nbinaural speech corpus, called ASPIRE, is recorded in real noisy environments\nincluding cafeteria and restaurant. We demonstrate superior performance of our\napproach in terms of objective measures and subjective listening tests over the\nstate-of-the-art SE approaches as well as recent DNN based SE models. In\naddition, our work challenges a popular belief that a scarcity of\nmulti-language large vocabulary AV corpus and wide variety of noises is a major\nbottleneck to build a robust language, speaker and noise independent SE\nsystems. We show that a model trained on synthetic mixture of Grid corpus (with\n33 speakers and a small English vocabulary) and ChiME 3 Noises (consisting of\nonly bus, pedestrian, cafeteria, and street noises) generalise well not only on\nlarge vocabulary corpora but also on completely unrelated languages (such as\nMandarin), wide variety of speakers and noises.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 14:59:47 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Gogate", "Mandar", ""], ["Dashtipour", "Kia", ""], ["Adeel", "Ahsan", ""], ["Hussain", "Amir", ""]]}, {"id": "1909.10432", "submitter": "Mert Al", "authors": "Mert Al, Zejiang Hou, Sun-Yuan Kung", "title": "Scalable Kernel Learning via the Discriminant Information", "comments": "Published in IEEE 2020 International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel approximation methods create explicit, low-dimensional kernel feature\nmaps to deal with the high computational and memory complexity of standard\ntechniques. This work studies a supervised kernel learning methodology to\noptimize such mappings. We utilize the Discriminant Information criterion, a\nmeasure of class separability with a strong connection to Discriminant\nAnalysis. By generalizing this measure to cover a wider range of kernel maps\nand learning settings, we develop scalable methods to learn kernel features\nwith high discriminant power. Experimental results on several datasets showcase\nthat our techniques can improve optimization and generalization performances\nover state of the art kernel learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 15:43:12 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 15:41:24 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Al", "Mert", ""], ["Hou", "Zejiang", ""], ["Kung", "Sun-Yuan", ""]]}, {"id": "1909.10447", "submitter": "Pranava Madhyastha", "authors": "Pranava Madhyastha, Rishabh Jain", "title": "On Model Stability as a Function of Random Seed", "comments": "v1; Accepted for publication at CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we focus on quantifying model stability as a function of\nrandom seed by investigating the effects of the induced randomness on model\nperformance and the robustness of the model in general. We specifically perform\na controlled study on the effect of random seeds on the behaviour of attention,\ngradient-based and surrogate model based (LIME) interpretations. Our analysis\nsuggests that random seeds can adversely affect the consistency of models\nresulting in counterfactual interpretations. We propose a technique called\nAggressive Stochastic Weight Averaging (ASWA)and an extension called\nNorm-filtered Aggressive Stochastic Weight Averaging (NASWA) which improves the\nstability of models over random seeds. With our ASWA and NASWA based\noptimization, we are able to improve the robustness of the original model, on\naverage reducing the standard deviation of the model's performance by 72%.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:00:06 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Madhyastha", "Pranava", ""], ["Jain", "Rishabh", ""]]}, {"id": "1909.10449", "submitter": "Yuren Zhong", "authors": "Yuren Zhong, Aniket Anand Deshmukh and Clayton Scott", "title": "PAC Reinforcement Learning without Real-World Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies reinforcement learning in the Sim-to-Real setting, in which\nan agent is first trained on a number of simulators before being deployed in\nthe real world, with the aim of decreasing the real-world sample complexity\nrequirement. Using a dynamic model known as a rich observation Markov decision\nprocess (ROMDP), we formulate a theoretical framework for Sim-to-Real in the\nsituation where feedback in the real world is not available. We establish\nreal-world sample complexity guarantees that are smaller than what is currently\nknown for directly (i.e., without access to simulators) learning a ROMDP with\nfeedback.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:07:37 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 14:51:35 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 17:33:50 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Zhong", "Yuren", ""], ["Deshmukh", "Aniket Anand", ""], ["Scott", "Clayton", ""]]}, {"id": "1909.10455", "submitter": "Daniel L\\'evy", "authors": "Daniel Levy and John C. Duchi", "title": "Necessary and Sufficient Geometries for Gradient Methods", "comments": "23 pages. To appear at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the impact of the constraint set and gradient geometry on the\nconvergence of online and stochastic methods for convex optimization, providing\na characterization of the geometries for which stochastic gradient and adaptive\ngradient methods are (minimax) optimal. In particular, we show that when the\nconstraint set is quadratically convex, diagonally pre-conditioned stochastic\ngradient methods are minimax optimal. We further provide a converse that shows\nthat when the constraints are not quadratically convex---for example, any\n$\\ell_p$-ball for $p < 2$---the methods are far from optimal. Based on this, we\ncan provide concrete recommendations for when one should use adaptive, mirror\nor stochastic gradient methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:14:26 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 05:49:48 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Levy", "Daniel", ""], ["Duchi", "John C.", ""]]}, {"id": "1909.10461", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Terrence W.K. Mak, Pascal Van Hentenryck", "title": "Predicting AC Optimal Power Flows: Combining Deep Learning and\n  Lagrangian Dual Methods", "comments": "A version of this paper appears in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Optimal Power Flow (OPF) problem is a fundamental building block for the\noptimization of electrical power systems. It is nonlinear and nonconvex and\ncomputes the generator setpoints for power and voltage, given a set of load\ndemands. It is often needed to be solved repeatedly under various conditions,\neither in real-time or in large-scale studies. This need is further exacerbated\nby the increasing stochasticity of power systems due to renewable energy\nsources in front and behind the meter. To address these challenges, this paper\npresents a deep learning approach to the OPF. The learning model exploits the\ninformation available in the prior states of the system (which is commonly\navailable in practical applications), as well as a dual Lagrangian method to\nsatisfy the physical and engineering constraints present in the OPF. The\nproposed model is evaluated on a large collection of realistic power systems.\nThe experimental results show that its predictions are highly accurate with\naverage errors as low as 0.2%. Additionally, the proposed approach is shown to\nimprove the accuracy of widely adopted OPF linear DC approximation by at least\ntwo orders of magnitude.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 00:39:17 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 15:25:44 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Mak", "Terrence W. K.", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1909.10467", "submitter": "Hassan Rafique", "authors": "Hassan Rafique, Tong Wang, Qihang Lin", "title": "Model-Agnostic Linear Competitors -- When Interpretable Models Compete\n  and Collaborate with Black-Box Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by an increasing need for model interpretability, interpretable models\nhave become strong competitors for black-box models in many real applications.\nIn this paper, we propose a novel type of model where interpretable models\ncompete and collaborate with black-box models. We present the Model-Agnostic\nLinear Competitors (MALC) for partially interpretable classification. MALC is a\nhybrid model that uses linear models to locally substitute any black-box model,\ncapturing subspaces that are most likely to be in a class while leaving the\nrest of the data to the black-box. MALC brings together the interpretable power\nof linear models and good predictive performance of a black-box model. We\nformulate the training of a MALC model as a convex optimization. The predictive\naccuracy and transparency (defined as the percentage of data captured by the\nlinear models) balance through a carefully designed objective function and the\noptimization problem is solved with the accelerated proximal gradient method.\nExperiments show that MALC can effectively trade prediction accuracy for\ntransparency and provide an efficient frontier that spans the entire spectrum\nof transparency.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:41:57 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Rafique", "Hassan", ""], ["Wang", "Tong", ""], ["Lin", "Qihang", ""]]}, {"id": "1909.10470", "submitter": "Vishvak Murahari", "authors": "Vishvak Murahari, Prithvijit Chattopadhyay, Dhruv Batra, Devi Parikh,\n  Abhishek Das", "title": "Improving Generative Visual Dialog by Answering Diverse Questions", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on training generative Visual Dialog models with reinforcement\nlearning(Das et al.) has explored a Qbot-Abot image-guessing game and shown\nthat this 'self-talk' approach can lead to improved performance at the\ndownstream dialog-conditioned image-guessing task. However, this improvement\nsaturates and starts degrading after a few rounds of interaction, and does not\nlead to a better Visual Dialog model. We find that this is due in part to\nrepeated interactions between Qbot and Abot during self-talk, which are not\ninformative with respect to the image. To improve this, we devise a simple\nauxiliary objective that incentivizes Qbot to ask diverse questions, thus\nreducing repetitions and in turn enabling Abot to explore a larger state space\nduring RL ie. be exposed to more visual concepts to talk about, and varied\nquestions to answer. We evaluate our approach via a host of automatic metrics\nand human studies, and demonstrate that it leads to better dialog, ie. dialog\nthat is more diverse (ie. less repetitive), consistent (ie. has fewer\nconflicting exchanges), fluent (ie. more human-like),and detailed, while still\nbeing comparably image-relevant as prior work and ablations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:47:15 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 03:01:48 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Murahari", "Vishvak", ""], ["Chattopadhyay", "Prithvijit", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Das", "Abhishek", ""]]}, {"id": "1909.10476", "submitter": "Binil Starly", "authors": "Binil Starly, Atin Angrish, Paul Cohen", "title": "Research Directions in Democratizing Innovation through Design\n  Automation, One-Click Manufacturing Services and Intelligent Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digitalization of manufacturing has created opportunities for consumers\nto customize products that fit their individualized needs which in turn would\ndrive demand for manufacturing services. However, this pull-based manufacturing\nsystem production of extremely low quantity and limitless variety for products\nis expensive to implement. New emerging technology in design automation driven\nby data-driven computational design, manufacturing-as-a-service marketplaces\nand digitally enabled micro-factories holds promise towards democratization of\ninnovation. In this paper, scientific, technology and infrastructure challenges\nare identified and if solved, the impact of these emerging technologies on\nproduct innovation and future factory organization is discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:56:08 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Starly", "Binil", ""], ["Angrish", "Atin", ""], ["Cohen", "Paul", ""]]}, {"id": "1909.10477", "submitter": "Yuming Huang", "authors": "Yuming Huang, Ashkan Panahi, Hamid Krim, Liyi Dai", "title": "Community Detection and Improved Detectability in Multiplex Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TNSE.2019.2949036", "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the widely encountered problem of detecting communities in\nmultiplex networks, such as social networks, with an unknown arbitrary\nheterogeneous structure. To improve detectability, we propose a generative\nmodel that leverages the multiplicity of a single community in multiple layers,\nwith no prior assumption on the relation of communities among different layers.\nOur model relies on a novel idea of incorporating a large set of generic\nlocalized community label constraints across the layers, in conjunction with\nthe celebrated Stochastic Block Model (SBM) in each layer. Accordingly, we\nbuild a probabilistic graphical model over the entire multiplex network by\ntreating the constraints as Bayesian priors. We mathematically prove that these\nconstraints/priors promote existence of identical communities across layers\nwithout introducing further correlation between individual communities. The\nconstraints are further tailored to render a sparse graphical model and the\nnumerically efficient Belief Propagation algorithm is subsequently employed. We\nfurther demonstrate by numerical experiments that in the presence of consistent\ncommunities between different layers, consistent communities are matched, and\nthe detectability is improved over a single layer. We compare our model with a\n\"correlated model\" which exploits the prior knowledge of community correlation\nbetween layers. Similar detectability improvement is obtained under such a\ncorrelation, even though our model relies on much milder assumptions than the\ncorrelated model. Our model even shows a better detection performance over a\ncertain correlation and signal to noise ratio (SNR) range. In the absence of\ncommunity correlation, the correlation model naturally fails, while ours\nmaintains its performance.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:57:17 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 19:20:36 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Huang", "Yuming", ""], ["Panahi", "Ashkan", ""], ["Krim", "Hamid", ""], ["Dai", "Liyi", ""]]}, {"id": "1909.10480", "submitter": "Alesia Chernikova", "authors": "Alesia Chernikova and Alina Oprea", "title": "FENCE: Feasible Evasion Attacks on Neural Networks in Constrained\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As advances in Deep Neural Networks (DNNs) demonstrate unprecedented levels\nof performance in many critical applications, their vulnerability to attacks is\nstill an open question. We consider evasion attacks at the testing time against\nDeep Learning in constrained environments, in which dependencies between\nfeatures need to be satisfied. These situations may arise naturally in tabular\ndata or may be the result of feature engineering in specific application\ndomains, such as threat detection. We propose a general iterative\ngradient-based framework called FENCE for crafting evasion attacks that take\ninto consideration the specifics of constrained domains. We apply it against\nFeed-Forward Neural Networks in two threat detection applications: network\ntraffic botnet classification and malicious domain classification, to generate\nfeasible adversarial examples. We extensively evaluate the success rate and\nperformance of our attacks, compare their significant improvement over several\nbaselines, and analyze several factors that impact the attack success rate,\nincluding the optimization objective and the data imbalance. We show that with\nminimal effort (e.g., generating 12 additional network connections), an\nattacker can change the model's prediction to the target one. We found that\nmodels trained on datasets with higher imbalance are more vulnerable to our\nFENCE attacks. Finally, we show the potential of adversarial training in\nconstrained domains to increase the DNN resilience against these attacks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 16:59:15 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 20:00:26 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 03:19:13 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Chernikova", "Alesia", ""], ["Oprea", "Alina", ""]]}, {"id": "1909.10491", "submitter": "Pramesh Singh", "authors": "Jiahao Guo, Pramesh Singh, Kevin E. Bassler", "title": "Reduced network extremal ensemble learning (RenEEL) scheme for community\n  detection in complex networks", "comments": null, "journal-ref": "Scientific Reports 9, 14234 (2019)", "doi": "10.1038/s41598-019-50739-3", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an ensemble learning scheme for community detection in complex\nnetworks. The scheme uses a Machine Learning algorithmic paradigm we call\nExtremal Ensemble Learning. It uses iterative extremal updating of an ensemble\nof network partitions, which can be found by a conventional base algorithm, to\nfind a node partition that maximizes modularity. At each iteration, core groups\nof nodes that are in the same community in every ensemble partition are\nidentified and used to form a reduced network. Partitions of the reduced\nnetwork are then found and used to update the ensemble. The smaller size of the\nreduced network makes the scheme efficient. We use the scheme to analyze the\ncommunity structure in a set of commonly studied benchmark networks and find\nthat it outperforms all other known methods for finding the partition with\nmaximum modularity.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 17:19:50 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Guo", "Jiahao", ""], ["Singh", "Pramesh", ""], ["Bassler", "Kevin E.", ""]]}, {"id": "1909.10500", "submitter": "Xue-She Wang", "authors": "Xue-She Wang, James D. Turner, Brian P. Mann", "title": "Constrained Attractor Selection Using Deep Reinforcement Learning", "comments": "14 pages, 6 figures. Update: more application examples of attractor\n  selection; detailed algorithms for CEM and DDPG", "journal-ref": null, "doi": "10.1177/1077546320930144", "report-no": null, "categories": "eess.SY cs.LG cs.SY nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an approach for attractor selection (or multi-stability\ncontrol) in nonlinear dynamical systems with constrained actuation. Attractor\nselection is obtained using two different deep reinforcement learning methods:\n1) the cross-entropy method (CEM) and 2) the deep deterministic policy gradient\n(DDPG) method. The framework and algorithms for applying these control methods\nare presented. Experiments were performed on a Duffing oscillator, as it is a\nclassic nonlinear dynamical system with multiple attractors. Both methods\nachieve attractor selection under various control constraints. While these\nmethods have nearly identical success rates, the DDPG method has the advantages\nof a high learning rate, low performance variance, and a smooth control\napproach. This study demonstrates the ability of two reinforcement learning\napproaches to achieve constrained attractor selection.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 17:39:43 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 17:42:26 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 14:54:09 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Wang", "Xue-She", ""], ["Turner", "James D.", ""], ["Mann", "Brian P.", ""]]}, {"id": "1909.10506", "submitter": "Daniel Gillick", "authors": "Daniel Gillick, Sayali Kulkarni, Larry Lansing, Alessandro Presta,\n  Jason Baldridge, Eugene Ie, Diego Garcia-Olano", "title": "Learning Dense Representations for Entity Retrieval", "comments": "CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that it is feasible to perform entity linking by training a dual\nencoder (two-tower) model that encodes mentions and entities in the same dense\nvector space, where candidate entities are retrieved by approximate nearest\nneighbor search. Unlike prior work, this setup does not rely on an alias table\nfollowed by a re-ranker, and is thus the first fully learned entity retrieval\nmodel. We show that our dual encoder, trained using only anchor-text links in\nWikipedia, outperforms discrete alias table and BM25 baselines, and is\ncompetitive with the best comparable results on the standard TACKBP-2010\ndataset. In addition, it can retrieve candidates extremely fast, and\ngeneralizes well to a new dataset derived from Wikinews. On the modeling side,\nwe demonstrate the dramatic value of an unsupervised negative mining algorithm\nfor this task.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 17:52:34 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Gillick", "Daniel", ""], ["Kulkarni", "Sayali", ""], ["Lansing", "Larry", ""], ["Presta", "Alessandro", ""], ["Baldridge", "Jason", ""], ["Ie", "Eugene", ""], ["Garcia-Olano", "Diego", ""]]}, {"id": "1909.10519", "submitter": "Elie Wolfe", "authors": "Elie Wolfe, Alejandro Pozas-Kerstjens, Matan Grinberg, Denis Rosset,\n  Antonio Ac\\'in, Miguel Navascues", "title": "Quantum Inflation: A General Approach to Quantum Causal Compatibility", "comments": "V3 updated to match published version", "journal-ref": "Phys. Rev. X 11, 021043 (2021)", "doi": "10.1103/PhysRevX.11.021043", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causality is a seminal concept in science: Any research discipline, from\nsociology and medicine to physics and chemistry, aims at understanding the\ncauses that could explain the correlations observed among some measured\nvariables. While several methods exist to characterize classical causal models,\nno general construction is known for the quantum case. In this work, we present\nquantum inflation, a systematic technique to falsify if a given quantum causal\nmodel is compatible with some observed correlations. We demonstrate the power\nof the technique by reproducing known results and solving open problems for\nsome paradigmatic examples of causal networks. Our results may find\napplications in many fields: from the characterization of correlations in\nquantum networks to the study of quantum effects in thermodynamic and\nbiological processes.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 18:00:00 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 18:15:40 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 19:00:00 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 19:48:05 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Wolfe", "Elie", ""], ["Pozas-Kerstjens", "Alejandro", ""], ["Grinberg", "Matan", ""], ["Rosset", "Denis", ""], ["Ac\u00edn", "Antonio", ""], ["Navascues", "Miguel", ""]]}, {"id": "1909.10547", "submitter": "Stefano Carrazza", "authors": "Stefano Carrazza, Juan Cruz-Martinez, Jes\\'us Urtasun-Elizari, Emilio\n  Villa", "title": "Towards hardware acceleration for parton densities estimation", "comments": "6 pages, 2 figures, 3 tables, in proceedings of PHOTON 2019", "journal-ref": null, "doi": null, "report-no": "TIF-UNIMI-2019-16", "categories": "hep-ph cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this proceedings we describe the computational challenges associated to\nthe determination of parton distribution functions (PDFs). We compare the\nperformance of the convolution of the parton distributions with matrix elements\nusing different hardware instructions. We quantify and identify the most\npromising data-model configurations to increase PDF fitting performance in\nadapting the current code frameworks to hardware accelerators such as graphics\nprocessing units.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 18:09:39 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Carrazza", "Stefano", ""], ["Cruz-Martinez", "Juan", ""], ["Urtasun-Elizari", "Jes\u00fas", ""], ["Villa", "Emilio", ""]]}, {"id": "1909.10549", "submitter": "Gregory Farquhar", "authors": "Gregory Farquhar, Shimon Whiteson, Jakob Foerster", "title": "Loaded DiCE: Trading off Bias and Variance in Any-Order Score Function\n  Estimators for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based methods for optimisation of objectives in stochastic settings\nwith unknown or intractable dynamics require estimators of derivatives. We\nderive an objective that, under automatic differentiation, produces\nlow-variance unbiased estimators of derivatives at any order. Our objective is\ncompatible with arbitrary advantage estimators, which allows the control of the\nbias and variance of any-order derivatives when using function approximation.\nFurthermore, we propose a method to trade off bias and variance of higher order\nderivatives by discounting the impact of more distant causal dependencies. We\ndemonstrate the correctness and utility of our objective in analytically\ntractable MDPs and in meta-reinforcement-learning for continuous control.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 18:13:50 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Farquhar", "Gregory", ""], ["Whiteson", "Shimon", ""], ["Foerster", "Jakob", ""]]}, {"id": "1909.10562", "submitter": "Wei Wei", "authors": "Wei Zhang, Wei Wei, Lingjie Xu, Lingling Jin, Cheng Li", "title": "AI Matrix: A Deep Learning Benchmark for Alibaba Data Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alibaba has China's largest e-commerce platform. To support its diverse\nbusinesses, Alibaba has its own large-scale data centers providing the\ncomputing foundation for a wide variety of software applications. Among these\napplications, deep learning (DL) has been playing an important role in\ndelivering services like image recognition, objection detection, text\nrecognition, recommendation, and language processing. To build more efficient\ndata centers that deliver higher performance for these DL applications, it is\nimportant to understand their computational needs and use that information to\nguide the design of future computing infrastructure. An effective way to\nachieve this is through benchmarks that can fully represent Alibaba's DL\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 18:29:25 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Zhang", "Wei", ""], ["Wei", "Wei", ""], ["Xu", "Lingjie", ""], ["Jin", "Lingling", ""], ["Li", "Cheng", ""]]}, {"id": "1909.10572", "submitter": "Sarthak Dash", "authors": "Sarthak Dash, Md Faisal Mahbub Chowdhury, Alfio Gliozzo, Nandana\n  Mihindukulasooriya, Nicolas Rodolfo Fauceglia", "title": "Hypernym Detection Using Strict Partial Order Networks", "comments": "8 pages", "journal-ref": "AAAI 2020", "doi": "10.1609/aaai.v34i05.6263", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Strict Partial Order Networks (SPON), a novel neural\nnetwork architecture designed to enforce asymmetry and transitive properties as\nsoft constraints. We apply it to induce hypernymy relations by training with\nis-a pairs. We also present an augmented variant of SPON that can generalize\ntype information learned for in-vocabulary terms to previously unseen ones. An\nextensive evaluation over eleven benchmarks across different tasks shows that\nSPON consistently either outperforms or attains the state of the art on all but\none of these benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 18:54:52 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 22:40:23 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Dash", "Sarthak", ""], ["Chowdhury", "Md Faisal Mahbub", ""], ["Gliozzo", "Alfio", ""], ["Mihindukulasooriya", "Nandana", ""], ["Fauceglia", "Nicolas Rodolfo", ""]]}, {"id": "1909.10582", "submitter": "Vincent Kurtz", "authors": "Vince Kurtz, Hai Lin", "title": "Kalman Filtering with Gaussian Processes Measurement Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world measurement noise in applications like robotics is often\ncorrelated in time, but we typically assume i.i.d. Gaussian noise for\nfiltering. We propose general Gaussian Processes as a non-parametric model for\ncorrelated measurement noise that is flexible enough to accurately reflect\ncorrelation in time, yet simple enough to enable efficient computation. We show\nthat this model accurately reflects the measurement noise resulting from\nvision-based Simultaneous Localization and Mapping (SLAM), and argue that it\nprovides a flexible means of modeling measurement noise for a wide variety of\nsensor systems and perception algorithms. We then extend existing results for\nKalman filtering with autoregressive processes to more general Gaussian\nProcesses, and demonstrate the improved performance of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 19:19:11 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Kurtz", "Vince", ""], ["Lin", "Hai", ""]]}, {"id": "1909.10594", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia, Ahmed Salem, Michael Backes, Yang Zhang, Neil Zhenqiang\n  Gong", "title": "MemGuard: Defending against Black-Box Membership Inference Attacks via\n  Adversarial Examples", "comments": "ACM CCS 2019, code is available at this:\n  https://github.com/jjy1994/MemGuard", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a membership inference attack, an attacker aims to infer whether a data\nsample is in a target classifier's training dataset or not. Specifically, given\na black-box access to the target classifier, the attacker trains a binary\nclassifier, which takes a data sample's confidence score vector predicted by\nthe target classifier as an input and predicts the data sample to be a member\nor non-member of the target classifier's training dataset. Membership inference\nattacks pose severe privacy and security threats to the training dataset. Most\nexisting defenses leverage differential privacy when training the target\nclassifier or regularize the training process of the target classifier. These\ndefenses suffer from two key limitations: 1) they do not have formal\nutility-loss guarantees of the confidence score vectors, and 2) they achieve\nsuboptimal privacy-utility tradeoffs.\n  In this work, we propose MemGuard, the first defense with formal utility-loss\nguarantees against black-box membership inference attacks. Instead of tampering\nthe training process of the target classifier, MemGuard adds noise to each\nconfidence score vector predicted by the target classifier. Our key observation\nis that attacker uses a classifier to predict member or non-member and\nclassifier is vulnerable to adversarial examples. Based on the observation, we\npropose to add a carefully crafted noise vector to a confidence score vector to\nturn it into an adversarial example that misleads the attacker's classifier.\nOur experimental results on three datasets show that MemGuard can effectively\ndefend against membership inference attacks and achieve better privacy-utility\ntradeoffs than existing defenses. Our work is the first one to show that\nadversarial examples can be used as defensive mechanisms to defend against\nmembership inference attacks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 19:46:51 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 01:54:50 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 21:38:34 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Jia", "Jinyuan", ""], ["Salem", "Ahmed", ""], ["Backes", "Michael", ""], ["Zhang", "Yang", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1909.10614", "submitter": "Shiwali Mohan", "authors": "Shiwali Mohan, Hesham Rakha, Matthew Klenk", "title": "Acceptable Planning: Influencing Individual Behavior to Reduce\n  Transportation Energy Expenditure of a City", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research 66 (2019) 555-587", "doi": "10.1613/jair.1.11352", "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research aims at developing intelligent systems to reduce the\ntransportation-related energy expenditure of a large city by influencing\nindividual behavior. We introduce COPTER - an intelligent travel assistant that\nevaluates multi-modal travel alternatives to find a plan that is acceptable to\na person given their context and preferences. We propose a formulation for\nacceptable planning that brings together ideas from AI, machine learning, and\neconomics. This formulation has been incorporated in COPTER that produces\nacceptable plans in real-time. We adopt a novel empirical evaluation framework\nthat combines human decision data with a high fidelity multi-modal\ntransportation simulation to demonstrate a 4\\% energy reduction and 20\\% delay\nreduction in a realistic deployment scenario in Los Angeles, California, USA.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 20:55:18 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Mohan", "Shiwali", ""], ["Rakha", "Hesham", ""], ["Klenk", "Matthew", ""]]}, {"id": "1909.10616", "submitter": "Huaqing Zhang", "authors": "Huaqing Zhang, Xiaolin Cheng, Hui Zang and Dae Hoon Park", "title": "Compiler-Level Matrix Multiplication Optimization for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important linear algebra routine, GEneral Matrix Multiplication (GEMM), is\na fundamental operator in deep learning. Compilers need to translate these\nroutines into low-level code optimized for specific hardware. Compiler-level\noptimization of GEMM has significant performance impact on training and\nexecuting deep learning models. However, most deep learning frameworks rely on\nhardware-specific operator libraries in which GEMM optimization has been mostly\nachieved by manual tuning, which restricts the performance on different target\nhardware. In this paper, we propose two novel algorithms for GEMM optimization\nbased on the TVM framework, a lightweight Greedy Best First Search (G-BFS)\nmethod based on heuristic search, and a Neighborhood Actor Advantage Critic\n(N-A2C) method based on reinforcement learning. Experimental results show\nsignificant performance improvement of the proposed methods, in both the\noptimality of the solution and the cost of search in terms of time and fraction\nof the search space explored. Specifically, the proposed methods achieve 24%\nand 40% savings in GEMM computation time over state-of-the-art XGBoost and RNN\nmethods, respectively, while exploring only 0.1% of the search space. The\nproposed approaches have potential to be applied to other operator-level\noptimizations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 21:03:19 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Zhang", "Huaqing", ""], ["Cheng", "Xiaolin", ""], ["Zang", "Hui", ""], ["Park", "Dae Hoon", ""]]}, {"id": "1909.10618", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Haoran Tang, Xingyu Lu, Shixiang Gu, Honglak Lee, Sergey\n  Levine", "title": "Why Does Hierarchy (Sometimes) Work So Well in Reinforcement Learning?", "comments": "Presented as an oral at the NeurIPS 2019 DeepRL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning has demonstrated significant success at\nsolving difficult reinforcement learning (RL) tasks. Previous works have\nmotivated the use of hierarchy by appealing to a number of intuitive benefits,\nincluding learning over temporally extended transitions, exploring over\ntemporally extended periods, and training and exploring in a more semantically\nmeaningful action space, among others. However, in fully observed, Markovian\nsettings, it is not immediately clear why hierarchical RL should provide\nbenefits over standard \"shallow\" RL architectures. In this work, we isolate and\nevaluate the claimed benefits of hierarchical RL on a suite of tasks\nencompassing locomotion, navigation, and manipulation. Surprisingly, we find\nthat most of the observed benefits of hierarchy can be attributed to improved\nexploration, as opposed to easier policy learning or imposed hierarchical\nstructures. Given this insight, we present exploration techniques inspired by\nhierarchy that achieve performance competitive with hierarchical RL while at\nthe same time being much simpler to use and implement.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 21:11:30 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 17:21:22 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Nachum", "Ofir", ""], ["Tang", "Haoran", ""], ["Lu", "Xingyu", ""], ["Gu", "Shixiang", ""], ["Lee", "Honglak", ""], ["Levine", "Sergey", ""]]}, {"id": "1909.10642", "submitter": "Siddhant Garg", "authors": "Siddhant Garg", "title": "Data Ordering Patterns for Neural Machine Translation: An Empirical\n  Study", "comments": "Submitted to 3rd Workshop on Neural Generation and Translation, EMNLP\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works show that ordering of the training data affects the model\nperformance for Neural Machine Translation. Several approaches involving\ndynamic data ordering and data sharding based on curriculum learning have been\nanalysed for the their performance gains and faster convergence. In this work\nwe propose to empirically study several ordering approaches for the training\ndata based on different metrics and evaluate their impact on the model\nperformance. Results from our study show that pre-fixing the ordering of the\ntraining data based on perplexity scores from a pre-trained model performs the\nbest and outperforms the default approach of randomly shuffling the training\ndata every epoch.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 22:20:03 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Garg", "Siddhant", ""]]}, {"id": "1909.10649", "submitter": "F\\'abio Souza", "authors": "F\\'abio Souza, Rodrigo Nogueira, Roberto Lotufo", "title": "Portuguese Named Entity Recognition using BERT-CRF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in language representation using neural networks have made it\nviable to transfer the learned internal states of a trained model to downstream\nnatural language processing tasks, such as named entity recognition (NER) and\nquestion answering. It has been shown that the leverage of pre-trained language\nmodels improves the overall performance on many tasks and is highly beneficial\nwhen labeled data is scarce. In this work, we train Portuguese BERT models and\nemploy a BERT-CRF architecture to the NER task on the Portuguese language,\ncombining the transfer capabilities of BERT with the structured predictions of\nCRF. We explore feature-based and fine-tuning training strategies for the BERT\nmodel. Our fine-tuning approach obtains new state-of-the-art results on the\nHAREM I dataset, improving the F1-score by 1 point on the selective scenario (5\nNE classes) and by 4 points on the total scenario (10 NE classes).\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 23:21:42 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 15:06:49 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Souza", "F\u00e1bio", ""], ["Nogueira", "Rodrigo", ""], ["Lotufo", "Roberto", ""]]}, {"id": "1909.10651", "submitter": "Zhi Zhang", "authors": "Zhi Zhang, Jiachen Yang, Hongyuan Zha", "title": "Integrating independent and centralized multi-agent reinforcement\n  learning for traffic signal network optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic congestion in metropolitan areas is a world-wide problem that can be\nameliorated by traffic lights that respond dynamically to real-time conditions.\nRecent studies applying deep reinforcement learning (RL) to optimize single\ntraffic lights have shown significant improvement over conventional control.\nHowever, optimization of global traffic condition over a large road network\nfundamentally is a cooperative multi-agent control problem, for which\nsingle-agent RL is not suitable due to environment non-stationarity and\ninfeasibility of optimizing over an exponential joint-action space. Motivated\nby these challenges, we propose QCOMBO, a simple yet effective multi-agent\nreinforcement learning (MARL) algorithm that combines the advantages of\nindependent and centralized learning. We ensure scalability by selecting\nactions from individually optimized utility functions, which are shaped to\nmaximize global performance via a novel consistency regularization loss between\nindividual utility and a global action-value function. Experiments on diverse\nroad topologies and traffic flow conditions in the SUMO traffic simulator show\ncompetitive performance of QCOMBO versus recent state-of-the-art MARL\nalgorithms. We further show that policies trained on small sub-networks can\neffectively generalize to larger networks under different traffic flow\nconditions, providing empirical evidence for the suitability of MARL for\nintelligent traffic control.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 23:39:00 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhang", "Zhi", ""], ["Yang", "Jiachen", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1909.10652", "submitter": "Lingchen Zhu", "authors": "Lingchen Zhu, Tuanfeng Zhang", "title": "Generating Geological Facies Models with Fidelity to Diversity and\n  Statistics of Training Images using Improved Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology and workflow that overcome the limitations\nof the conventional Generative Adversarial Networks (GANs) for geological\nfacies modeling. It attempts to improve the training stability and guarantee\nthe diversity of the generated geology through interpretable latent vectors.\nThe resulting samples are ensured to have the equal probability (or an unbiased\ndistribution) as from the training dataset. This is critical when applying GANs\nto generate unbiased and representative geological models that can be further\nused to facilitate objective uncertainty evaluation and optimal decision-making\nin oil field exploration and development.\n  We proposed and implemented a new variant of GANs called Info-WGAN for the\ngeological facies modeling that combines Information Maximizing Generative\nAdversarial Network (InfoGAN) with Wasserstein distance and Gradient Penalty\n(GP) for learning interpretable latent codes as well as generating stable and\nunbiased distribution from the training data. Different from the original GAN\ndesign, InfoGAN can use the training images with full, partial, or no labels to\nperform disentanglement of the complex sedimentary types exhibited in the\ntraining dataset to achieve the variety and diversity of the generated samples.\nThis is accomplished by adding additional categorical variables that provide\ndisentangled semantic representations besides the mere randomized latent vector\nused in the original GANs. By such means, a regularization term is used to\nmaximize the mutual information between such latent categorical codes and the\ngenerated geological facies in the loss function.\n  Furthermore, the resulting unbiased sampling by Info-WGAN makes the data\nconditioning much easier than the conventional GANs in geological modeling\nbecause of the variety and diversity as well as the equal probability of the\nunconditional sampling by the generator.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 23:40:59 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Zhu", "Lingchen", ""], ["Zhang", "Tuanfeng", ""]]}, {"id": "1909.10660", "submitter": "Daiki Matsunaga", "authors": "Daiki Matsunaga, Toyotaro Suzumura, Toshihiro Takahashi", "title": "Exploring Graph Neural Networks for Stock Market Predictions with\n  Rolling Window Analysis", "comments": "NeurIPS 2019 Workshop on Robust AI in Financial Services: Data,\n  Fairness, Explainability, Trustworthiness, and Privacy (Robust AI in FS),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a surge of interest in the use of machine learning\nto help aid in the accurate predictions of financial markets. Despite the\nexciting advances in this cross-section of finance and AI, many of the current\napproaches are limited to using technical analysis to capture historical trends\nof each stock price and thus limited to certain experimental setups to obtain\ngood prediction results. On the other hand, professional investors additionally\nuse their rich knowledge of inter-market and inter-company relations to map the\nconnectivity of companies and events, and use this map to make better market\npredictions. For instance, they would predict the movement of a certain\ncompany's stock price based not only on its former stock price trends but also\non the performance of its suppliers or customers, the overall industry,\nmacroeconomic factors and trade policies. This paper investigates the\neffectiveness of work at the intersection of market predictions and graph\nneural networks, which hold the potential to mimic the ways in which investors\nmake decisions by incorporating company knowledge graphs directly into the\npredictive model. The main goal of this work is to test the validity of this\napproach across different markets and longer time horizons for backtesting\nusing rolling window analysis. In this work, we concentrate on the prediction\nof individual stock prices in the Japanese Nikkei 225 market over a period of\nroughly 20 years. For the knowledge graph, we use the Nikkei Value Search data,\nwhich is a rich dataset showing mainly supplier relations among Japanese and\nforeign companies. Our preliminary results show a 29.5% increase and a 2.2-fold\nincrease in the return ratio and Sharpe ratio, respectively, when compared to\nthe market benchmark, as well as a 6.32% increase and 1.3-fold increase,\nrespectively, compared to the baseline LSTM model.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 00:19:32 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 23:47:20 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 23:49:02 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Matsunaga", "Daiki", ""], ["Suzumura", "Toyotaro", ""], ["Takahashi", "Toshihiro", ""]]}, {"id": "1909.10662", "submitter": "Akhil Gupta", "authors": "Akhil Gupta, Naman Shukla, Lavanya Marla, Arinbj\\\"orn Kolbeinsson,\n  Kartik Yellepeddi", "title": "How to Incorporate Monotonicity in Deep Networks While Preserving\n  Flexibility?", "comments": "8 pages, 5 figures. NeurIPS 2019 Workshop on Machine Learning with\n  Guarantees", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of domain knowledge in enhancing model performance and making\nreliable predictions in the real-world is critical. This has led to an\nincreased focus on specific model properties for interpretability. We focus on\nincorporating monotonic trends, and propose a novel gradient-based point-wise\nloss function for enforcing partial monotonicity with deep neural networks.\nWhile recent developments have relied on structural changes to the model, our\napproach aims at enhancing the learning process. Our model-agnostic point-wise\nloss function acts as a plug-in to the standard loss and penalizes\nnon-monotonic gradients. We demonstrate that the point-wise loss produces\ncomparable (and sometimes better) results on both AUC and monotonicity measure,\nas opposed to state-of-the-art deep lattice networks that guarantee\nmonotonicity. Moreover, it is able to learn differentiated individual trends\nand produces smoother conditional curves which are important for personalized\ndecisions, while preserving the flexibility of deep networks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 00:24:23 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 01:29:53 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 00:08:17 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Gupta", "Akhil", ""], ["Shukla", "Naman", ""], ["Marla", "Lavanya", ""], ["Kolbeinsson", "Arinbj\u00f6rn", ""], ["Yellepeddi", "Kartik", ""]]}, {"id": "1909.10670", "submitter": "Xin Ding", "authors": "Xin Ding, Z. Jane Wang, William J. Welch", "title": "Subsampling Generative Adversarial Networks: Density Ratio Estimation in\n  Feature Space with Softplus Loss", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.2979601", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filtering out unrealistic images from trained generative adversarial networks\n(GANs) has attracted considerable attention recently. Two density ratio based\nsubsampling methods---Discriminator Rejection Sampling (DRS) and\nMetropolis-Hastings GAN (MH-GAN)---were recently proposed, and their\neffectiveness in improving GANs was demonstrated on multiple datasets. However,\nDRS and MH-GAN are based on discriminator based density ratio estimation (DRE)\nmethods, so they may not work well if the discriminator in the trained GAN is\nfar from optimal. Moreover, they do not apply to some GANs (e.g., MMD-GAN). In\nthis paper, we propose a novel Softplus (SP) loss for DRE. Based on it, we\ndevelop a sample-based DRE method in a feature space learned by a specially\ndesigned and pre-trained ResNet-34 (DRE-F-SP). We derive the rate of\nconvergence of a density ratio model trained under the SP loss. Then, we\npropose three different density ratio subsampling methods (DRE-F-SP+RS,\nDRE-F-SP+MH, and DRE-F-SP+SIR) for GANs based on DRE-F-SP. Our subsampling\nmethods do not rely on the optimality of the discriminator and are suitable for\nall types of GANs. We empirically show our subsampling approach can\nsubstantially outperform DRS and MH-GAN on a synthetic dataset and the CIFAR-10\ndataset, using multiple GANs.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 01:12:06 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 08:42:25 GMT"}, {"version": "v3", "created": "Sun, 27 Oct 2019 08:53:17 GMT"}, {"version": "v4", "created": "Fri, 1 Nov 2019 00:32:26 GMT"}, {"version": "v5", "created": "Thu, 20 Feb 2020 05:28:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Ding", "Xin", ""], ["Wang", "Z. Jane", ""], ["Welch", "William J.", ""]]}, {"id": "1909.10673", "submitter": "Rajat Talak", "authors": "Rajat Talak, Sertac Karaman, and Eytan Modiano", "title": "A Theory of Uncertainty Variables for State Estimation and Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new framework of uncertainty variables to model uncertainty. An\nuncertainty variable is characterized by an uncertainty set, in which its\nrealization is bound to lie, while the conditional uncertainty is characterized\nby a set map, from a given realization of a variable to a set of possible\nrealizations of another variable. We prove Bayes' law and the law of total\nprobability equivalents for uncertainty variables. We define a notion of\nindependence, conditional independence, and pairwise independence for a\ncollection of uncertainty variables, and show that this new notion of\nindependence preserves the properties of independence defined over random\nvariables. We then develop a graphical model, namely Bayesian uncertainty\nnetwork, a Bayesian network equivalent defined over a collection of uncertainty\nvariables, and show that all the natural conditional independence properties,\nexpected out of a Bayesian network, hold for the Bayesian uncertainty network.\nWe also define the notion of point estimate, and show its relation with the\nmaximum a posteriori estimate. Probability theory starts with a distribution\nfunction (equivalently a probability measure) as a primitive and builds all\nother useful concepts, such as law of total probability, Bayes' law,\nindependence, graphical models, point estimate, on it. Our work shows that it\nis perfectly possible to start with a set, instead of a distribution function,\nand retain all the useful ideas needed for state estimation and inference.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 01:31:32 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 18:46:08 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Talak", "Rajat", ""], ["Karaman", "Sertac", ""], ["Modiano", "Eytan", ""]]}, {"id": "1909.10681", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Di Wang, Chunyan Miao", "title": "Knowledge-Enriched Transformer for Emotion Detection in Textual\n  Conversations", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Messages in human conversations inherently convey emotions. The task of\ndetecting emotions in textual conversations leads to a wide range of\napplications such as opinion mining in social networks. However, enabling\nmachines to analyze emotions in conversations is challenging, partly because\nhumans often rely on the context and commonsense knowledge to express emotions.\nIn this paper, we address these challenges by proposing a Knowledge-Enriched\nTransformer (KET), where contextual utterances are interpreted using\nhierarchical self-attention and external commonsense knowledge is dynamically\nleveraged using a context-aware affective graph attention mechanism.\nExperiments on multiple textual conversation datasets demonstrate that both\ncontext and commonsense knowledge are consistently beneficial to the emotion\ndetection performance. In addition, the experimental results show that our KET\nmodel outperforms the state-of-the-art models on most of the tested datasets in\nF1 score.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 02:08:29 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 14:00:22 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Zhong", "Peixiang", ""], ["Wang", "Di", ""], ["Miao", "Chunyan", ""]]}, {"id": "1909.10695", "submitter": "Philipp V. Rouast", "authors": "Philipp V. Rouast, Marc T. P. Adam", "title": "Learning deep representations for video-based intake gesture detection", "comments": "To be published in IEEE Journal of Biomedical and Health Informatics", "journal-ref": null, "doi": "10.1109/JBHI.2019.2942845", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic detection of individual intake gestures during eating occasions has\nthe potential to improve dietary monitoring and support dietary\nrecommendations. Existing studies typically make use of on-body solutions such\nas inertial and audio sensors, while video is used as ground truth. Intake\ngesture detection directly based on video has rarely been attempted. In this\nstudy, we address this gap and show that deep learning architectures can\nsuccessfully be applied to the problem of video-based detection of intake\ngestures. For this purpose, we collect and label video data of eating occasions\nusing 360-degree video of 102 participants. Applying state-of-the-art\napproaches from video action recognition, our results show that (1) the best\nmodel achieves an $F_1$ score of 0.858, (2) appearance features contribute more\nthan motion features, and (3) temporal context in form of multiple video frames\nis essential for top model performance.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 03:29:53 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Rouast", "Philipp V.", ""], ["Adam", "Marc T. P.", ""]]}, {"id": "1909.10699", "submitter": "Allen Nie", "authors": "Allen Nie, Arturo L. Pineda, Matt W. Wright Hannah Wand, Bryan Wulf,\n  Helio A. Costa, Ronak Y. Patel, Carlos D. Bustamante, James Zou", "title": "LitGen: Genetic Literature Recommendation Guided by Human Explanations", "comments": "12 pages; 5 figures. Accepted by PSB 2020 (Pacific Symposium on\n  Biocomputing) track: Artificial Intelligence for Enhancing Clinical Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As genetic sequencing costs decrease, the lack of clinical interpretation of\nvariants has become the bottleneck in using genetics data. A major rate\nlimiting step in clinical interpretation is the manual curation of evidence in\nthe genetic literature by highly trained biocurators. What makes curation\nparticularly time-consuming is that the curator needs to identify papers that\nstudy variant pathogenicity using different types of approaches and\nevidences---e.g. biochemical assays or case control analysis. In collaboration\nwith the Clinical Genomic Resource (ClinGen)---the flagship NIH program for\nclinical curation---we propose the first machine learning system, LitGen, that\ncan retrieve papers for a particular variant and filter them by specific\nevidence types used by curators to assess for pathogenicity. LitGen uses\nsemi-supervised deep learning to predict the type of evidence provided by each\npaper. It is trained on papers annotated by ClinGen curators and systematically\nevaluated on new test data collected by ClinGen. LitGen further leverages rich\nhuman explanations and unlabeled data to gain 7.9%-12.6% relative performance\nimprovement over models learned only on the annotated papers. It is a useful\nframework to improve clinical variant curation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 03:56:48 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Nie", "Allen", ""], ["Pineda", "Arturo L.", ""], ["Wand", "Matt W. Wright Hannah", ""], ["Wulf", "Bryan", ""], ["Costa", "Helio A.", ""], ["Patel", "Ronak Y.", ""], ["Bustamante", "Carlos D.", ""], ["Zou", "James", ""]]}, {"id": "1909.10702", "submitter": "Nitish Bahadur", "authors": "Nitish Bahadur and Randy Paffenroth", "title": "Dimension Estimation Using Autoencoders", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dimension Estimation (DE) and Dimension Reduction (DR) are two closely\nrelated topics, but with quite different goals. In DE, one attempts to estimate\nthe intrinsic dimensionality or number of latent variables in a set of\nmeasurements of a random vector. However, in DR, one attempts to project a\nrandom vector, either linearly or non-linearly, to a lower dimensional space\nthat preserves the information contained in the original higher dimensional\nspace. Of course, these two ideas are quite closely linked since, for example,\ndoing DR to a dimension smaller than suggested by DE will likely lead to\ninformation loss. Accordingly, in this paper we will focus on a particular\nclass of deep neural networks called autoencoders which are used extensively\nfor DR but are less well studied for DE. We show that several important\nquestions arise when using autoencoders for DE, above and beyond those that\narise for more classic DR/DE techniques such as Principal Component Analysis.\nWe address autoencoder architectural choices and regularization techniques that\nallow one to transform autoencoder latent layer representations into estimates\nof intrinsic dimension.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 04:09:48 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Bahadur", "Nitish", ""], ["Paffenroth", "Randy", ""]]}, {"id": "1909.10705", "submitter": "Abigail See", "authors": "Abigail See, Aneesh Pappu, Rohun Saxena, Akhila Yerukola, Christopher\n  D. Manning", "title": "Do Massively Pretrained Language Models Make Better Storytellers?", "comments": "Accepted to CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large neural language models trained on massive amounts of text have emerged\nas a formidable strategy for Natural Language Understanding tasks. However, the\nstrength of these models as Natural Language Generators is less clear. Though\nanecdotal evidence suggests that these models generate better quality text,\nthere has been no detailed study characterizing their generation abilities. In\nthis work, we compare the performance of an extensively pretrained model,\nOpenAI GPT2-117 (Radford et al., 2019), to a state-of-the-art neural story\ngeneration model (Fan et al., 2018). By evaluating the generated text across a\nwide variety of automatic metrics, we characterize the ways in which pretrained\nmodels do, and do not, make better storytellers. We find that although GPT2-117\nconditions more strongly on context, is more sensitive to ordering of events,\nand uses more unusual words, it is just as likely to produce repetitive and\nunder-diverse text when using likelihood-maximizing decoding algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 04:26:27 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["See", "Abigail", ""], ["Pappu", "Aneesh", ""], ["Saxena", "Rohun", ""], ["Yerukola", "Akhila", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1909.10707", "submitter": "Yijiong Lin", "authors": "Yijiong Lin, Jiancong Huang, Matthieu Zimmer, Yisheng Guan, Juan\n  Rojas, Paul Weng", "title": "Invariant Transform Experience Replay: Data Augmentation for Deep\n  Reinforcement Learning", "comments": "8 pages, 11 figures, additional 3 pages for appendix. IEEE Robotics\n  and Automation Letters (RAL), 2020. Also in: Intelligent Robots and Systems\n  (IROS)", "journal-ref": "IEEE Robotics and Automation Letters, Volume: 5, Issue: 4, p.\n  6615-6622, Oct. 2020", "doi": "10.1109/LRA.2020.3013937", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (RL) is a promising approach for adaptive robot\ncontrol, but its current application to robotics is currently hindered by high\nsample requirements. To alleviate this issue, we propose to exploit the\nsymmetries present in robotic tasks. Intuitively, symmetries from observed\ntrajectories define transformations that leave the space of feasible RL\ntrajectories invariant and can be used to generate new feasible trajectories,\nwhich could be used for training. Based on this data augmentation idea, we\nformulate a general framework, called Invariant Transform Experience Replay\nthat we present with two techniques: (i) Kaleidoscope Experience Replay\nexploits reflectional symmetries and (ii) Goal-augmented Experience Replay\nwhich takes advantage of lax goal definitions. In the Fetch tasks from OpenAI\nGym, our experimental results show significant increases in learning rates and\nsuccess rates. Particularly, we attain a 13, 3, and 5 times speedup in the\npushing, sliding, and pick-and-place tasks respectively in the multi-goal\nsetting. Performance gains are also observed in similar tasks with obstacles\nand we successfully deployed a trained policy on a real Baxter robot. Our work\ndemonstrates that invariant transformations on RL trajectories are a promising\nmethodology to speed up learning in deep RL.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 04:34:58 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 07:31:08 GMT"}, {"version": "v3", "created": "Sat, 14 Dec 2019 02:42:27 GMT"}, {"version": "v4", "created": "Thu, 12 Mar 2020 09:27:44 GMT"}, {"version": "v5", "created": "Tue, 9 Jun 2020 03:51:26 GMT"}, {"version": "v6", "created": "Sun, 5 Jul 2020 03:19:06 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Lin", "Yijiong", ""], ["Huang", "Jiancong", ""], ["Zimmer", "Matthieu", ""], ["Guan", "Yisheng", ""], ["Rojas", "Juan", ""], ["Weng", "Paul", ""]]}, {"id": "1909.10708", "submitter": "Chiranjibi Sitaula", "authors": "Chiranjibi Sitaula, Yong Xiang, Sunil Aryal, Xuequan Lu", "title": "Unsupervised Deep Features for Privacy Image Classification", "comments": "Accepted in PSIVT2019 Conference", "journal-ref": "PSIVT 2019. Lecture Notes in Computer Science, vol 11854", "doi": "10.1007/978-3-030-34879-3_31", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharing images online poses security threats to a wide range of users due to\nthe unawareness of privacy information. Deep features have been demonstrated to\nbe a powerful representation for images. However, deep features usually suffer\nfrom the issues of a large size and requiring a huge amount of data for\nfine-tuning. In contrast to normal images (e.g., scene images), privacy images\nare often limited because of sensitive information. In this paper, we propose a\nnovel approach that can work on limited data and generate deep features of\nsmaller size. For training images, we first extract the initial deep features\nfrom the pre-trained model and then employ the K-means clustering algorithm to\nlearn the centroids of these initial deep features. We use the learned\ncentroids from training features to extract the final features for each testing\nimage and encode our final features with the triangle encoding. To improve the\ndiscriminability of the features, we further perform the fusion of two proposed\nunsupervised deep features obtained from different layers. Experimental results\nshow that the proposed features outperform state-of-the-art deep features, in\nterms of both classification accuracy and testing time.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 04:38:15 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Sitaula", "Chiranjibi", ""], ["Xiang", "Yong", ""], ["Aryal", "Sunil", ""], ["Lu", "Xuequan", ""]]}, {"id": "1909.10726", "submitter": "R\\\"udiger Schmitz", "authors": "R\\\"udiger Schmitz, Frederic Madesta, Maximilian Nielsen, Jenny Krause,\n  Ren\\'e Werner, and Thomas R\\\"osch", "title": "Multi-scale fully convolutional neural networks for histopathology image\n  segmentation: from nuclear aberrations to the global tissue architecture", "comments": "Accepted for Medical Image Analysis", "journal-ref": null, "doi": "10.1016/j.media.2021.101996", "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.TO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Histopathologic diagnosis relies on simultaneous integration of information\nfrom a broad range of scales, ranging from nuclear aberrations ($\\approx\n\\mathcal{O}(0.1{\\mu m})$) through cellular structures ($\\approx\n\\mathcal{O}(10{\\mu m})$) to the global tissue architecture ($\\gtrapprox\n\\mathcal{O}(1{mm})$). To explicitly mimic how human pathologists combine\nmulti-scale information, we introduce a family of multi-encoder FCNs with deep\nfusion. We present a simple block for merging model paths with differing\nspatial scales in a spatial relationship-preserving fashion, which can readily\nbe included in standard encoder-decoder networks. Additionally, a context\nclassification gate block is proposed as an alternative for the incorporation\nof global context.\n  Our experiments were performed on three publicly available whole-slide images\nof recent challenges (PAIP 2019, BACH 2020, CAMELYON 2016). The multi-scale\narchitectures consistently outperformed the baseline single-scale U-Nets by a\nlarge margin. They benefit from local as well as global context and\nparticularly a combination of both. If feature maps from different scales are\nfused, doing so in a manner preserving spatial relationships was found to be\nbeneficial. Deep guidance by a context classification loss appeared to improve\nmodel training at low computational costs. All multi-scale models had a reduced\nGPU memory footprint compared to ensembles of individual U-Nets trained on\ndifferent image scales. Additional path fusions were shown to be possible at\nlow computational cost, opening up possibilities for further, systematic and\ntask-specific architecture optimization.\n  The findings demonstrate the potential of the presented family of\nhuman-inspired, end-to-end trainable, multi-scale multi-encoder FCNs to improve\ndeep histopathologic diagnosis by extensive integration of largely different\nspatial scales.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 06:25:29 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 13:09:26 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 21:07:46 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Schmitz", "R\u00fcdiger", ""], ["Madesta", "Frederic", ""], ["Nielsen", "Maximilian", ""], ["Krause", "Jenny", ""], ["Werner", "Ren\u00e9", ""], ["R\u00f6sch", "Thomas", ""]]}, {"id": "1909.10737", "submitter": "Weihao Xuan", "authors": "Weihao Xuan, Ruijie Ren", "title": "Multi-agent Interactive Prediction under Challenging Driving Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to drive safely on the road, autonomous vehicle is expected to\npredict future outcomes of its surrounding environment and react properly. In\nfact, many researchers have been focused on solving behavioral prediction\nproblems for autonomous vehicles. However, very few of them consider\nmulti-agent prediction under challenging driving scenarios such as urban\nenvironment. In this paper, we proposed a prediction method that is able to\npredict various complicated driving scenarios where heterogeneous road\nentities, signal lights, and static map information are taken into account.\nMoreover, the proposed multi-agent interactive prediction (MAIP) system is\ncapable of simultaneously predicting any number of road entities while\nconsidering their mutual interactions. A case study of a simulated challenging\nurban intersection scenario is provided to demonstrate the performance and\ncapability of the proposed prediction system.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 07:16:32 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 05:47:39 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 16:09:21 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2020 19:09:37 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Xuan", "Weihao", ""], ["Ren", "Ruijie", ""]]}, {"id": "1909.10754", "submitter": "Seonguk Park", "authors": "SeongUk Park, Nojun Kwak", "title": "FEED: Feature-level Ensemble for Knowledge Distillation", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) aims to transfer knowledge in a teacher-student\nframework, by providing the predictions of the teacher network to the student\nnetwork in the training stage to help the student network generalize better. It\ncan use either a teacher with high capacity or {an} ensemble of multiple\nteachers. However, the latter is not convenient when one wants to use\nfeature-map-based distillation methods. For a solution, this paper proposes a\nversatile and powerful training algorithm named FEature-level Ensemble for\nknowledge Distillation (FEED), which aims to transfer the ensemble knowledge\nusing multiple teacher networks. We introduce a couple of training algorithms\nthat transfer ensemble knowledge to the student at the feature map level. Among\nthe feature-map-based distillation methods, using several non-linear\ntransformations in parallel for transferring the knowledge of the multiple\nteacher{s} helps the student find more generalized solutions. We name this\nmethod as parallel FEED, andexperimental results on CIFAR-100 and ImageNet show\nthat our method has clear performance enhancements, without introducing any\nadditional parameters or computations at test time. We also show the\nexperimental results of sequentially feeding teacher's information to the\nstudent, hence the name sequential FEED, and discuss the lessons obtained.\nAdditionally, the empirical results on measuring the reconstruction errors at\nthe feature map give hints for the enhancements.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 08:14:40 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Park", "SeongUk", ""], ["Kwak", "Nojun", ""]]}, {"id": "1909.10773", "submitter": "Minhao Cheng", "authors": "Minhao Cheng, Simranjit Singh, Patrick Chen, Pin-Yu Chen, Sijia Liu,\n  Cho-Jui Hsieh", "title": "Sign-OPT: A Query-Efficient Hard-label Adversarial Attack", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the most practical problem setup for evaluating adversarial\nrobustness of a machine learning system with limited access: the hard-label\nblack-box attack setting for generating adversarial examples, where limited\nmodel queries are allowed and only the decision is provided to a queried data\ninput. Several algorithms have been proposed for this problem but they\ntypically require huge amount (>20,000) of queries for attacking one example.\nAmong them, one of the state-of-the-art approaches (Cheng et al., 2019) showed\nthat hard-label attack can be modeled as an optimization problem where the\nobjective function can be evaluated by binary search with additional model\nqueries, thereby a zeroth order optimization algorithm can be applied. In this\npaper, we adopt the same optimization formulation but propose to directly\nestimate the sign of gradient at any direction instead of the gradient itself,\nwhich enjoys the benefit of single query. Using this single query oracle for\nretrieving sign of directional derivative, we develop a novel query-efficient\nSign-OPT approach for hard-label black-box attack. We provide a convergence\nanalysis of the new algorithm and conduct experiments on several models on\nMNIST, CIFAR-10 and ImageNet. We find that Sign-OPT attack consistently\nrequires 5X to 10X fewer queries when compared to the current state-of-the-art\napproaches, and usually converges to an adversarial example with smaller\nperturbation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 09:27:08 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 08:52:24 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 01:44:07 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Cheng", "Minhao", ""], ["Singh", "Simranjit", ""], ["Chen", "Patrick", ""], ["Chen", "Pin-Yu", ""], ["Liu", "Sijia", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1909.10779", "submitter": "Lisa Graziani", "authors": "Lisa Graziani, Stefano Melacci, Marco Gori", "title": "Jointly Learning to Detect Emotions and Predict Facebook Reactions", "comments": "International Conference on Artificial Neural Networks. Springer,\n  Cham, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing ubiquity of Social Media data offers an attractive perspective\nfor improving the quality of machine learning-based models in several fields,\nranging from Computer Vision to Natural Language Processing. In this paper we\nfocus on Facebook posts paired with reactions of multiple users, and we\ninvestigate their relationships with classes of emotions that are typically\nconsidered in the task of emotion detection. We are inspired by the idea of\nintroducing a connection between reactions and emotions by means of First-Order\nLogic formulas, and we propose an end-to-end neural model that is able to\njointly learn to detect emotions and predict Facebook reactions in a multi-task\nenvironment, where the logic formulas are converted into polynomial\nconstraints. Our model is trained using a large collection of unsupervised\ntexts together with data labeled with emotion classes and Facebook posts that\ninclude reactions. An extended experimental analysis that leverages a large\ncollection of Facebook posts shows that the tasks of emotion classification and\nreaction prediction can both benefit from their interaction.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 09:45:48 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Graziani", "Lisa", ""], ["Melacci", "Stefano", ""], ["Gori", "Marco", ""]]}, {"id": "1909.10790", "submitter": "Arnaud Huaulm\\'e", "authors": "Arnaud Huaulm\\'e, Pierre Jannin, Fabian Reche, Jean-Luc Faucheron,\n  Alexandre Moreau-Gaudry, Sandrine Voros", "title": "Offline identification of surgical deviations in laparoscopic rectopexy", "comments": null, "journal-ref": null, "doi": "10.1016/j.artmed.2020.101837", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: A median of 14.4% of patient undergone at least one adverse event\nduring surgery and a third of them are preventable. The occurrence of adverse\nevents forces surgeons to implement corrective strategies and, thus, deviate\nfrom the standard surgical process. Therefore, it is clear that the automatic\nidentification of adverse events is a major challenge for patient safety. In\nthis paper, we have proposed a method enabling us to identify such deviations.\nWe have focused on identifying surgeons' deviations from standard surgical\nprocesses due to surgical events rather than anatomic specificities. This is\nparticularly challenging, given the high variability in typical surgical\nprocedure workflows. Methods: We have introduced a new approach designed to\nautomatically detect and distinguish surgical process deviations based on\nmulti-dimensional non-linear temporal scaling with a hidden semi-Markov model\nusing manual annotation of surgical processes. The approach was then evaluated\nusing cross-validation. Results: The best results have over 90% accuracy.\nRecall and precision were superior at 70%. We have provided a detailed analysis\nof the incorrectly-detected observations. Conclusion: Multi-dimensional\nnon-linear temporal scaling with a hidden semi-Markov model provides promising\nresults for detecting deviations. Our error analysis of the\nincorrectly-detected observations offers different leads in order to further\nimprove our method. Significance: Our method demonstrated the feasibility of\nautomatically detecting surgical deviations that could be implemented for both\nskill analysis and developing situation awareness-based computer-assisted\nsurgical systems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 10:17:44 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 10:30:25 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Huaulm\u00e9", "Arnaud", ""], ["Jannin", "Pierre", ""], ["Reche", "Fabian", ""], ["Faucheron", "Jean-Luc", ""], ["Moreau-Gaudry", "Alexandre", ""], ["Voros", "Sandrine", ""]]}, {"id": "1909.10801", "submitter": "Michael Poli", "authors": "Michael Poli, Jinkyoo Park, Ilija Ilievski", "title": "WATTNet: Learning to Trade FX via Hierarchical Spatio-Temporal\n  Representation of Highly Multivariate Time Series", "comments": "Submitted to the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI 20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finance is a particularly challenging application area for deep learning\nmodels due to low noise-to-signal ratio, non-stationarity, and partial\nobservability. Non-deliverable-forwards (NDF), a derivatives contract used in\nforeign exchange (FX) trading, presents additional difficulty in the form of\nlong-term planning required for an effective selection of start and end date of\nthe contract. In this work, we focus on tackling the problem of NDF tenor\nselection by leveraging high-dimensional sequential data consisting of spot\nrates, technical indicators and expert tenor patterns. To this end, we\nconstruct a dataset from the Depository Trust & Clearing Corporation (DTCC) NDF\ndata that includes a comprehensive list of NDF volumes and daily spot rates for\n64 FX pairs. We introduce WaveATTentionNet (WATTNet), a novel temporal\nconvolution (TCN) model for spatio-temporal modeling of highly multivariate\ntime series, and validate it across NDF markets with varying degrees of\ndissimilarity between the training and test periods in terms of volatility and\ngeneral market regimes. The proposed method achieves a significant positive\nreturn on investment (ROI) in all NDF markets under analysis, outperforming\nrecurrent and classical baselines by a wide margin. Finally, we propose two\northogonal interpretability approaches to verify noise stability and detect the\ndriving factors of the learned tenor selection strategy.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 10:42:23 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Poli", "Michael", ""], ["Park", "Jinkyoo", ""], ["Ilievski", "Ilija", ""]]}, {"id": "1909.10802", "submitter": "Saar Barkai", "authors": "Saar Barkai, Ido Hakimi and Assaf Schuster", "title": "Gap Aware Mitigation of Gradient Staleness", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is becoming increasingly popular as a platform for\ndistributed training of deep neural networks. Synchronous stochastic gradient\ndescent (SSGD) suffers from substantial slowdowns due to stragglers if the\nenvironment is non-dedicated, as is common in cloud computing. Asynchronous SGD\n(ASGD) methods are immune to these slowdowns but are scarcely used due to\ngradient staleness, which encumbers the convergence process. Recent techniques\nhave had limited success mitigating the gradient staleness when scaling up to\nmany workers (computing nodes). In this paper we define the Gap as a measure of\ngradient staleness and propose Gap-Aware (GA), a novel asynchronous-distributed\nmethod that penalizes stale gradients linearly to the Gap and performs well\neven when scaling to large numbers of workers. Our evaluation on the CIFAR,\nImageNet, and WikiText-103 datasets shows that GA outperforms the currently\nacceptable gradient penalization method, in final test accuracy. We also\nprovide convergence rate proof for GA. Despite prior beliefs, we show that if\nGA is applied, momentum becomes beneficial in asynchronous environments, even\nwhen the number of workers scales up.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 10:46:21 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 13:10:30 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 17:28:14 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Barkai", "Saar", ""], ["Hakimi", "Ido", ""], ["Schuster", "Assaf", ""]]}, {"id": "1909.10812", "submitter": "Kim Hammar", "authors": "Kim Hammar, Shatha Jaradat, Nima Dokoohaki and Mihhail Matskin", "title": "Deep Text Mining of Instagram Data Without Strong Supervision", "comments": "8 pages, 5 figures. Pre-print for paper to appear in conference\n  proceedings for the Web Intelligence Conference", "journal-ref": null, "doi": "10.1109/WI.2018.00-94", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of social media, our online feeds increasingly consist of\nshort, informal, and unstructured text. This textual data can be analyzed for\nthe purpose of improving user recommendations and detecting trends. Instagram\nis one of the largest social media platforms, containing both text and images.\nHowever, most of the prior research on text processing in social media is\nfocused on analyzing Twitter data, and little attention has been paid to text\nmining of Instagram data. Moreover, many text mining methods rely on annotated\ntraining data, which in practice is both difficult and expensive to obtain. In\nthis paper, we present methods for unsupervised mining of fashion attributes\nfrom Instagram text, which can enable a new kind of user recommendation in the\nfashion domain. In this context, we analyze a corpora of Instagram posts from\nthe fashion domain, introduce a system for extracting fashion attributes from\nInstagram, and train a deep clothing classifier with weak supervision to\nclassify Instagram posts based on the associated text.\n  With our experiments, we confirm that word embeddings are a useful asset for\ninformation extraction. Experimental results show that information extraction\nusing word embeddings outperforms a baseline that uses Levenshtein distance.\nThe results also show the benefit of combining weak supervision signals using\ngenerative models instead of majority voting. Using weak supervision and\ngenerative modeling, an F1 score of 0.61 is achieved on the task of classifying\nthe image contents of Instagram posts based solely on the associated text,\nwhich is on level with human performance. Finally, our empirical study provides\none of the few available studies on Instagram text and shows that the text is\nnoisy, that the text distribution exhibits the long-tail phenomenon, and that\ncomment sections on Instagram are multi-lingual.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 11:04:02 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Hammar", "Kim", ""], ["Jaradat", "Shatha", ""], ["Dokoohaki", "Nima", ""], ["Matskin", "Mihhail", ""]]}, {"id": "1909.10815", "submitter": "Renqian Luo", "authors": "Renqian Luo, Tao Qin, Enhong Chen", "title": "Balanced One-shot Neural Architecture Optimization", "comments": "Code and model checkpoints are publicly available at\n  https://github.com/renqianluo/NAO_pytorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to rank candidate architectures is the key to the performance of\nneural architecture search~(NAS). One-shot NAS is proposed to reduce the\nexpense but shows inferior performance against conventional NAS and is not\nadequately stable. We investigate into this and find that the ranking\ncorrelation between architectures under one-shot training and the ones under\nstand-alone full training is poor, which misleads the algorithm to discover\nbetter architectures. Further, we show that the training of architectures of\ndifferent sizes under the current one-shot method is imbalanced, which causes\nthe evaluated performances of the architectures to be less predictable of their\nground-truth performances and affects the ranking correlation heavily.\nConsequently, we propose Balanced NAO where we introduce balanced training of\nthe supernet during the search procedure to encourage more updates for large\narchitectures than small architectures by sampling architectures in proportion\nto their model sizes. Comprehensive experiments verify that our proposed method\nis effective and robust which leads to a more stable search. The final\ndiscovered architecture shows significant improvements against baselines with a\ntest error rate of 2.60\\% on CIFAR-10 and top-1 accuracy of 74.4% on ImageNet\nunder the mobile setting. Code and model checkpoints will be publicly\navailable. The code is available at github.com/renqianluo/NAO_pytorch.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 11:18:52 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 04:20:18 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Luo", "Renqian", ""], ["Qin", "Tao", ""], ["Chen", "Enhong", ""]]}, {"id": "1909.10818", "submitter": "Florian Scheidegger", "authors": "Florian Scheidegger, Luca Benini, Costas Bekas, Cristiano Malossi", "title": "Constrained deep neural network architecture search for IoT devices\n  accounting hardware calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks achieve outstanding results in challenging image\nclassification tasks. However, the design of network topologies is a complex\ntask and the research community makes a constant effort in discovering\ntop-accuracy topologies, either manually or employing expensive architecture\nsearches. In this work, we propose a unique narrow-space architecture search\nthat focuses on delivering low-cost and fast executing networks that respect\nstrict memory and time requirements typical of Internet-of-Things (IoT)\nnear-sensor computing platforms. Our approach provides solutions with\nclassification latencies below 10ms running on a $35 device with 1GB RAM and\n5.6GFLOPS peak performance. The narrow-space search of floating-point models\nimproves the accuracy on CIFAR10 of an established IoT model from 70.64% to\n74.87% respecting the same memory constraints. We further improve the accuracy\nto 82.07% by including 16-bit half types and we obtain the best accuracy of\n83.45% by extending the search with model optimized IEEE 754 reduced types. To\nthe best of our knowledge, we are the first that empirically demonstrate on\nover 3000 trained models that running with reduced precision pushes the Pareto\noptimal front by a wide margin. Under a given memory constraint, accuracy is\nimproved by over 7% points for half and over 1% points further for running with\nthe best model individual format.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 11:27:33 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Scheidegger", "Florian", ""], ["Benini", "Luca", ""], ["Bekas", "Costas", ""], ["Malossi", "Cristiano", ""]]}, {"id": "1909.10820", "submitter": "Szabolcs Pavel", "authors": "Szabolcs P\\'avel, Csan\\'ad S\\'andor, Lehel Csat\\'o", "title": "Distortion Estimation Through Explicit Modeling of the Refractive\n  Surface", "comments": "Accepted to ICANN 2019", "journal-ref": "LNCS 11729, pp. 17-28, 2019", "doi": "10.1007/978-3-030-30508-6_2", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise calibration is a must for high reliance 3D computer vision\nalgorithms. A challenging case is when the camera is behind a protective glass\nor transparent object: due to refraction, the image is heavily distorted; the\npinhole camera model alone can not be used and a distortion correction step is\nrequired. By directly modeling the geometry of the refractive media, we build\nthe image generation process by tracing individual light rays from the camera\nto a target. Comparing the generated images to their distorted - observed -\ncounterparts, we estimate the geometry parameters of the refractive surface via\nmodel inversion by employing an RBF neural network. We present an image\ncollection methodology that produces data suited for finding the distortion\nparameters and test our algorithm on synthetic and real-world data. We analyze\nthe results of the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 11:31:09 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["P\u00e1vel", "Szabolcs", ""], ["S\u00e1ndor", "Csan\u00e1d", ""], ["Csat\u00f3", "Lehel", ""]]}, {"id": "1909.10831", "submitter": "Romuald A. Janik", "authors": "Romuald A. Janik", "title": "Entropy from Machine Learning", "comments": "10 pages, 2 figures; v2: reference added, minor notational\n  improvement; v3: reference added, general comments in section 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG hep-lat q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We translate the problem of calculating the entropy of a set of binary\nconfigurations/signals into a sequence of supervised classification tasks.\nSubsequently, one can use virtually any machine learning classification\nalgorithm for computing entropy. This procedure can be used to compute entropy,\nand consequently the free energy directly from a set of Monte Carlo\nconfigurations at a given temperature. As a test of the proposed method, using\nan off-the-shelf machine learning classifier we reproduce the entropy and free\nenergy of the 2D Ising model from Monte Carlo configurations at various\ntemperatures throughout its phase diagram. Other potential applications include\ncomputing the entropy of spiking neurons or any other multidimensional binary\nsignals.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 12:12:42 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 13:13:32 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 08:44:48 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Janik", "Romuald A.", ""]]}, {"id": "1909.10856", "submitter": "Qiegen Liu", "authors": "Yiling Liu, Qiegen Liu, Minghui Zhang, Qingxin Yang, Shanshan Wang and\n  Dong Liang", "title": "IFR-Net: Iterative Feature Refinement Network for Compressed Sensing MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the compressive sensing MRI (CS-MRI) approaches in terms of fine\nstructure loss under high acceleration factors, we have proposed an iterative\nfeature refinement model (IFR-CS), equipped with fixed transforms, to restore\nthe meaningful structures and details. Nevertheless, the proposed IFR-CS still\nhas some limitations, such as the selection of hyper-parameters, a lengthy\nreconstruction time, and the fixed sparsifying transform. To alleviate these\nissues, we unroll the iterative feature refinement procedures in IFR-CS to a\nsupervised model-driven network, dubbed IFR-Net. Equipped with training data\npairs, both regularization parameter and the utmost feature refinement operator\nin IFR-CS become trainable. Additionally, inspired by the powerful\nrepresentation capability of convolutional neural network (CNN), CNN-based\ninversion blocks are explored in the sparsity-promoting denoising module to\ngeneralize the sparsity-enforcing operator. Extensive experiments on both\nsimulated and in vivo MR datasets have shown that the proposed network\npossesses a strong capability to capture image details and preserve well the\nstructural information with fast reconstruction speed.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 12:57:18 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 02:18:02 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Liu", "Yiling", ""], ["Liu", "Qiegen", ""], ["Zhang", "Minghui", ""], ["Yang", "Qingxin", ""], ["Wang", "Shanshan", ""], ["Liang", "Dong", ""]]}, {"id": "1909.10861", "submitter": "Chao-Wei Huang", "authors": "Chao-Wei Huang and Yun-Nung Chen", "title": "Learning ASR-Robust Contextualized Embeddings for Spoken Language\n  Understanding", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Employing pre-trained language models (LM) to extract contextualized word\nrepresentations has achieved state-of-the-art performance on various NLP tasks.\nHowever, applying this technique to noisy transcripts generated by automatic\nspeech recognizer (ASR) is concerned. Therefore, this paper focuses on making\ncontextualized representations more ASR-robust. We propose a novel\nconfusion-aware fine-tuning method to mitigate the impact of ASR errors to\npre-trained LMs. Specifically, we fine-tune LMs to produce similar\nrepresentations for acoustically confusable words that are obtained from word\nconfusion networks (WCNs) produced by ASR. Experiments on the benchmark ATIS\ndataset show that the proposed method significantly improves the performance of\nspoken language understanding when performing on ASR transcripts. Our source\ncode is available at https://github.com/MiuLab/SpokenVec\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:06:43 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 06:59:49 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Huang", "Chao-Wei", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1909.10868", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Lina Yao, Manqing Dong, Zhe Liu, Yu Zhang, Yong Li", "title": "Adversarial Representation Learning for Robust Patient-Independent\n  Epileptic Seizure Detection", "comments": "Accepted by the IEEE Journal of Biomedical and Health Informatics\n  (J-BHI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Epilepsy is a chronic neurological disorder characterized by the\noccurrence of spontaneous seizures, which affects about one percent of the\nworld's population. Most of the current seizure detection approaches strongly\nrely on patient history records and thus fail in the patient-independent\nsituation of detecting the new patients. To overcome such limitation, we\npropose a robust and explainable epileptic seizure detection model that\neffectively learns from seizure states while eliminates the inter-patient\nnoises. Methods: A complex deep neural network model is proposed to learn the\npure seizure-specific representation from the raw non-invasive\nelectroencephalography (EEG) signals through adversarial training. Furthermore,\nto enhance the explainability, we develop an attention mechanism to\nautomatically learn the importance of each EEG channels in the seizure\ndiagnosis procedure. Results: The proposed approach is evaluated over the\nTemple University Hospital EEG (TUH EEG) database. The experimental results\nillustrate that our model outperforms the competitive state-of-the-art\nbaselines with low latency. Moreover, the designed attention mechanism is\ndemonstrated ables to provide fine-grained information for pathological\nanalysis. Conclusion and significance: We propose an effective and efficient\npatient-independent diagnosis approach of epileptic seizure based on raw EEG\nsignals without manually feature engineering, which is a step toward the\ndevelopment of large-scale deployment for real-life use.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 04:45:53 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 02:19:29 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Zhang", "Xiang", ""], ["Yao", "Lina", ""], ["Dong", "Manqing", ""], ["Liu", "Zhe", ""], ["Zhang", "Yu", ""], ["Li", "Yong", ""]]}, {"id": "1909.10881", "submitter": "Amir Karami", "authors": "Amir Karami", "title": "Application of Fuzzy Clustering for Text Data Dimensionality Reduction", "comments": "arXiv admin note: text overlap with arXiv:1712.05997", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large textual corpora are often represented by the document-term frequency\nmatrix whose elements are the frequency of terms; however, this matrix has two\nproblems: sparsity and high dimensionality. Four dimension reduction strategies\nare used to address these problems. Of the four strategies, unsupervised\nfeature transformation (UFT) is a popular and efficient strategy to map the\nterms to a new basis in the document-term frequency matrix. Although several\nUFT-based methods have been developed, fuzzy clustering has not been considered\nfor dimensionality reduction. This research explores fuzzy clustering as a new\nUFT-based approach to create a lower-dimensional representation of documents.\nPerformance of fuzzy clustering with and without using global term weighting\nmethods is shown to exceed principal component analysis and singular value\ndecomposition. This study also explores the effect of applying different\nfuzzifier values on fuzzy clustering for dimensionality reduction purpose.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 03:15:04 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Karami", "Amir", ""]]}, {"id": "1909.10893", "submitter": "Anirudh Goyal", "authors": "Anirudh Goyal, Alex Lamb, Jordan Hoffmann, Shagun Sodhani, Sergey\n  Levine, Yoshua Bengio, Bernhard Sch\\\"olkopf", "title": "Recurrent Independent Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning modular structures which reflect the dynamics of the environment can\nlead to better generalization and robustness to changes which only affect a few\nof the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a\nnew recurrent architecture in which multiple groups of recurrent cells operate\nwith nearly independent transition dynamics, communicate only sparingly through\nthe bottleneck of attention, and are only updated at time steps where they are\nmost relevant. We show that this leads to specialization amongst the RIMs,\nwhich in turn allows for dramatically improved generalization on tasks where\nsome factors of variation differ systematically between training and\nevaluation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:28:00 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 18:56:25 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 19:32:36 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2020 16:47:11 GMT"}, {"version": "v5", "created": "Thu, 12 Nov 2020 00:48:33 GMT"}, {"version": "v6", "created": "Tue, 17 Nov 2020 05:23:43 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Goyal", "Anirudh", ""], ["Lamb", "Alex", ""], ["Hoffmann", "Jordan", ""], ["Sodhani", "Shagun", ""], ["Levine", "Sergey", ""], ["Bengio", "Yoshua", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1909.10904", "submitter": "Joan Bas Serrano", "authors": "Joan Bas-Serrano, Gergely Neu", "title": "Faster saddle-point optimization for solving large-scale Markov decision\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing optimal policies in average-reward\nMarkov decision processes. This classical problem can be formulated as a linear\nprogram directly amenable to saddle-point optimization methods, albeit with a\nnumber of variables that is linear in the number of states. To address this\nissue, recent work has considered a linearly relaxed version of the resulting\nsaddle-point problem. Our work aims at achieving a better understanding of this\nrelaxed optimization problem by characterizing the conditions necessary for\nconvergence to the optimal policy, and designing an optimization algorithm\nenjoying fast convergence rates that are independent of the size of the state\nspace. Notably, our characterization points out some potential issues with\nprevious work.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 21:58:26 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 16:22:14 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Bas-Serrano", "Joan", ""], ["Neu", "Gergely", ""]]}, {"id": "1909.10911", "submitter": "Robert Schwarzenberg", "authors": "Robert Schwarzenberg, Marc H\\\"ubner, David Harbecke, Christoph Alt,\n  Leonhard Hennig", "title": "Layerwise Relevance Visualization in Convolutional Text Graph\n  Classifiers", "comments": "Accepted at EMNLP 2019 Workshop on Graph-Based Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations in the hidden layers of Deep Neural Networks (DNN) are often\nhard to interpret since it is difficult to project them into an interpretable\ndomain. Graph Convolutional Networks (GCN) allow this projection, but existing\nexplainability methods do not exploit this fact, i.e. do not focus their\nexplanations on intermediate states. In this work, we present a novel method\nthat traces and visualizes features that contribute to a classification\ndecision in the visible and hidden layers of a GCN. Our method exposes hidden\ncross-layer dynamics in the input graph structure. We experimentally\ndemonstrate that it yields meaningful layerwise explanations for a GCN sentence\nclassifier.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:37:02 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Schwarzenberg", "Robert", ""], ["H\u00fcbner", "Marc", ""], ["Harbecke", "David", ""], ["Alt", "Christoph", ""], ["Hennig", "Leonhard", ""]]}, {"id": "1909.10912", "submitter": "Viet Anh Tran", "authors": "Viet-Anh Tran, Romain Hennequin, Jimena Royo-Letelier, Manuel\n  Moussallam", "title": "Improving Collaborative Metric Learning with Efficient Negative Sampling", "comments": "SIGIR 2019", "journal-ref": null, "doi": "10.1145/3331184.3331337", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning based on triplet loss has been applied with success\nin a wide range of applications such as face recognition, image retrieval,\nspeaker change detection and recently recommendation with the CML model.\nHowever, as we show in this article, CML requires large batches to work\nreasonably well because of a too simplistic uniform negative sampling strategy\nfor selecting triplets. Due to memory limitations, this makes it difficult to\nscale in high-dimensional scenarios. To alleviate this problem, we propose here\na 2-stage negative sampling strategy which finds triplets that are highly\ninformative for learning. Our strategy allows CML to work effectively in terms\nof accuracy and popularity bias, even when the batch size is an order of\nmagnitude smaller than what would be needed with the default uniform sampling.\nWe demonstrate the suitability of the proposed strategy for recommendation and\nexhibit consistent positive results across various datasets.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:37:49 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Tran", "Viet-Anh", ""], ["Hennequin", "Romain", ""], ["Royo-Letelier", "Jimena", ""], ["Moussallam", "Manuel", ""]]}, {"id": "1909.10914", "submitter": "Wei Wang Dr.", "authors": "Xuedou Xiao, Wei Wang, Taobin Chen, Yang Cao, Tao Jiang, Qian Zhang", "title": "Sensor-Augmented Neural Adaptive Bitrate Video Streaming on UAVs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in unmanned aerial vehicle (UAV) technology have\nrevolutionized a broad class of civil and military applications. However, the\ndesigns of wireless technologies that enable real-time streaming of\nhigh-definition video between UAVs and ground clients present a conundrum. Most\nexisting adaptive bitrate (ABR) algorithms are not optimized for the\nair-to-ground links, which usually fluctuate dramatically due to the dynamic\nflight states of the UAV. In this paper, we present SA-ABR, a new\nsensor-augmented system that generates ABR video streaming algorithms with the\nassistance of various kinds of inherent sensor data that are used to pilot\nUAVs. By incorporating the inherent sensor data with network observations,\nSA-ABR trains a deep reinforcement learning (DRL) model to extract salient\nfeatures from the flight state information and automatically learn an ABR\nalgorithm to adapt to the varying UAV channel capacity through the training\nprocess. SA-ABR does not rely on any assumptions or models about UAV's flight\nstates or the environment, but instead, it makes decisions by exploiting\ntemporal properties of past throughput through the long short-term memory\n(LSTM) to adapt itself to a wide range of highly dynamic environments. We have\nimplemented SA-ABR in a commercial UAV and evaluated it in the wild. We compare\nSA-ABR with a variety of existing state-of-the-art ABR algorithms, and the\nresults show that our system outperforms the best known existing ABR algorithm\nby 21.4% in terms of the average quality of experience (QoE) reward.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 09:20:44 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Xiao", "Xuedou", ""], ["Wang", "Wei", ""], ["Chen", "Taobin", ""], ["Cao", "Yang", ""], ["Jiang", "Tao", ""], ["Zhang", "Qian", ""]]}, {"id": "1909.10924", "submitter": "Pengwei Wang", "authors": "Pengwei Wang, Liangchen Wei, Yong Cao, Jinghui Xie, Yuji Cao, Zaiqing\n  Nie", "title": "Understanding Semantics from Speech Through Pre-training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end Spoken Language Understanding (SLU) is proposed to infer the\nsemantic meaning directly from audio features without intermediate text\nrepresentation. Although the acoustic model component of an end-to-end SLU\nsystem can be pre-trained with Automatic Speech Recognition (ASR) targets, the\nSLU component can only learn semantic features from limited task-specific\ntraining data. In this paper, for the first time we propose to do large-scale\nunsupervised pre-training for the SLU component of an end-to-end SLU system, so\nthat the SLU component may preserve semantic features from massive unlabeled\naudio data. As the output of the acoustic model component, i.e. phoneme\nposterior sequences, has much different characteristic from text sequences, we\npropose a novel pre-training model called BERT-PLM, which stands for\nBidirectional Encoder Representations from Transformers through Permutation\nLanguage Modeling. BERT-PLM trains the SLU component on unlabeled data through\na regression objective equivalent to the partial permutation language modeling\nobjective, while leverages full bi-directional context information with BERT\nnetworks. The experiment results show that our approach out-perform the\nstate-of-the-art end-to-end systems with over 12.5% error reduction.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 13:49:14 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Wang", "Pengwei", ""], ["Wei", "Liangchen", ""], ["Cao", "Yong", ""], ["Xie", "Jinghui", ""], ["Cao", "Yuji", ""], ["Nie", "Zaiqing", ""]]}, {"id": "1909.10972", "submitter": "Krishan Rana Mr", "authors": "Krishan Rana, Ben Talbot, Vibhavari Dasagi, Michael Milford and Niko\n  S\\\"underhauf", "title": "Residual Reactive Navigation: Combining Classical and Learned Navigation\n  Strategies For Deployment in Unknown Environments", "comments": "Accepted as a conference paper at ICRA2020. Project site available at\n  https://sites.google.com/view/srrn/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we focus on improving the efficiency and generalisation of\nlearned navigation strategies when transferred from its training environment to\npreviously unseen ones. We present an extension of the residual reinforcement\nlearning framework from the robotic manipulation literature and adapt it to the\nvast and unstructured environments that mobile robots can operate in. The\nconcept is based on learning a residual control effect to add to a typical\nsub-optimal classical controller in order to close the performance gap, whilst\nguiding the exploration process during training for improved data efficiency.\nWe exploit this tight coupling and propose a novel deployment strategy,\nswitching Residual Reactive Navigation (sRRN), which yields efficient\ntrajectories whilst probabilistically switching to a classical controller in\ncases of high policy uncertainty. Our approach achieves improved performance\nover end-to-end alternatives and can be incorporated as part of a complete\nnavigation stack for cluttered indoor navigation tasks in the real world. The\ncode and training environment for this project is made publicly available at\nhttps://sites.google.com/view/srrn/home.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 14:55:00 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 05:46:37 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Rana", "Krishan", ""], ["Talbot", "Ben", ""], ["Dasagi", "Vibhavari", ""], ["Milford", "Michael", ""], ["S\u00fcnderhauf", "Niko", ""]]}, {"id": "1909.10976", "submitter": "Matthew Z Wong", "authors": "Matthew Z. Wong, Kiyohito Kunii, Max Baylis, Wai Hong Ong, Pavel\n  Kroupa, Swen Koller", "title": "Synthetic dataset generation for object-to-model deep learning in\n  industrial applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of large image data sets has been a crucial factor in the\nsuccess of deep learning-based classification and detection methods. While data\nsets for everyday objects are widely available, data for specific industrial\nuse-cases (e.g. identifying packaged products in a warehouse) remains scarce.\nIn such cases, the data sets have to be created from scratch, placing a crucial\nbottleneck on the deployment of deep learning techniques in industrial\napplications.\n  We present work carried out in collaboration with a leading UK online\nsupermarket, with the aim of creating a computer vision system capable of\ndetecting and identifying unique supermarket products in a warehouse setting.\nTo this end, we demonstrate a framework for using synthetic data to create an\nend-to-end deep learning pipeline, beginning with real-world objects and\nculminating in a trained model.\n  Our method is based on the generation of a synthetic dataset from 3D models\nobtained by applying photogrammetry techniques to real-world objects. Using\n100k synthetic images generated from 60 real images per class, an InceptionV3\nconvolutional neural network (CNN) was trained, which achieved classification\naccuracy of 95.8% on a separately acquired test set of real supermarket product\nimages. The image generation process supports automatic pixel annotation. This\neliminates the prohibitively expensive manual annotation typically required for\ndetection tasks. Based on this readily available data, a one-stage RetinaNet\ndetector was trained on the synthetic, annotated images to produce a detector\nthat can accurately localize and classify the specimen products in real-time.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 14:58:07 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Wong", "Matthew Z.", ""], ["Kunii", "Kiyohito", ""], ["Baylis", "Max", ""], ["Ong", "Wai Hong", ""], ["Kroupa", "Pavel", ""], ["Koller", "Swen", ""]]}, {"id": "1909.10994", "submitter": "Martin Ritzert", "authors": "Emilie Grienenberger and Martin Ritzert", "title": "Learning definable hypotheses on trees", "comments": "Full version of ICDT 2019 paper", "journal-ref": null, "doi": "10.4230/LIPIcs.ICDT.2019.24", "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning properties of nodes in tree structures.\nThose properties are specified by logical formulas, such as formulas from\nfirst-order or monadic second-order logic. We think of the tree as a database\nencoding a large dataset and therefore aim for learning algorithms which depend\nat most sublinearly on the size of the tree. We present a learning algorithm\nfor quantifier-free formulas where the running time only depends polynomially\non the number of training examples, but not on the size of the background\nstructure. By a previous result on strings we know that for general first-order\nor monadic second-order (MSO) formulas a sublinear running time cannot be\nachieved. However, we show that by building an index on the tree in a linear\ntime preprocessing phase, we can achieve a learning algorithm for MSO formulas\nwith a logarithmic learning phase.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 15:22:39 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Grienenberger", "Emilie", ""], ["Ritzert", "Martin", ""]]}, {"id": "1909.10995", "submitter": "Jo Schlemper", "authors": "Jo Schlemper, Ilkay Oksuz, James R. Clough, Jinming Duan, Andrew P.\n  King, Julia A. Schnabel, Joseph V. Hajnal, Daniel Rueckert", "title": "dAUTOMAP: decomposing AUTOMAP to achieve scalability and enhance\n  performance", "comments": "Presented at ISMRM 27th Annual Meeting & Exhibition (Abstract #658)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AUTOMAP is a promising generalized reconstruction approach, however, it is\nnot scalable and hence the practicality is limited. We present dAUTOMAP, a\nnovel way for decomposing the domain transformation of AUTOMAP, making the\nmodel scale linearly. We show dAUTOMAP outperforms AUTOMAP with significantly\nfewer parameters.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 15:22:43 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 20:21:44 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Schlemper", "Jo", ""], ["Oksuz", "Ilkay", ""], ["Clough", "James R.", ""], ["Duan", "Jinming", ""], ["King", "Andrew P.", ""], ["Schnabel", "Julia A.", ""], ["Hajnal", "Joseph V.", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1909.11015", "submitter": "Shiv Ram Dubey", "authors": "Shiv Ram Dubey, Soumendu Chakraborty, Swalpa Kumar Roy, Snehasis\n  Mukherjee, Satish Kumar Singh, Bidyut Baran Chaudhuri", "title": "diffGrad: An Optimization Method for Convolutional Neural Networks", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Decent (SGD) is one of the core techniques behind the\nsuccess of deep neural networks. The gradient provides information on the\ndirection in which a function has the steepest rate of change. The main problem\nwith basic SGD is to change by equal sized steps for all parameters,\nirrespective of gradient behavior. Hence, an efficient way of deep network\noptimization is to make adaptive step sizes for each parameter. Recently,\nseveral attempts have been made to improve gradient descent methods such as\nAdaGrad, AdaDelta, RMSProp and Adam. These methods rely on the square roots of\nexponential moving averages of squared past gradients. Thus, these methods do\nnot take advantage of local change in gradients. In this paper, a novel\noptimizer is proposed based on the difference between the present and the\nimmediate past gradient (i.e., diffGrad). In the proposed diffGrad optimization\ntechnique, the step size is adjusted for each parameter in such a way that it\nshould have a larger step size for faster gradient changing parameters and a\nlower step size for lower gradient changing parameters. The convergence\nanalysis is done using the regret bound approach of online learning framework.\nRigorous analysis is made in this paper over three synthetic complex non-convex\nfunctions. The image categorization experiments are also conducted over the\nCIFAR10 and CIFAR100 datasets to observe the performance of diffGrad with\nrespect to the state-of-the-art optimizers such as SGDM, AdaGrad, AdaDelta,\nRMSProp, AMSGrad, and Adam. The residual unit (ResNet) based Convolutional\nNeural Networks (CNN) architecture is used in the experiments. The experiments\nshow that diffGrad outperforms other optimizers. Also, we show that diffGrad\nperforms uniformly well for training CNN using different activation functions.\nThe source code is made publicly available at\nhttps://github.com/shivram1987/diffGrad.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 06:20:05 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 06:11:50 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 06:51:39 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Dubey", "Shiv Ram", ""], ["Chakraborty", "Soumendu", ""], ["Roy", "Swalpa Kumar", ""], ["Mukherjee", "Snehasis", ""], ["Singh", "Satish Kumar", ""], ["Chaudhuri", "Bidyut Baran", ""]]}, {"id": "1909.11022", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio, Alessio Micheli", "title": "Reservoir Topology in Deep Echo State Networks", "comments": "Preprint of the paper published in the proceedings of ICANN 2019", "journal-ref": null, "doi": "10.1007/978-3-030-30493-5_6", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Echo State Networks (DeepESNs) recently extended the applicability of\nReservoir Computing (RC) methods towards the field of deep learning. In this\npaper we study the impact of constrained reservoir topologies in the\narchitectural design of deep reservoirs, through numerical experiments on\nseveral RC benchmarks. The major outcome of our investigation is to show the\nremarkable effect, in terms of predictive performance gain, achieved by the\nsynergy between a deep reservoir construction and a structured organization of\nthe recurrent units in each layer. Our results also indicate that a\nparticularly advantageous architectural setting is obtained in correspondence\nof DeepESNs where reservoir units are structured according to a permutation\nrecurrent matrix.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 16:15:16 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "1909.11023", "submitter": "Tanwi Mallick", "authors": "Tanwi Mallick, Partha Pratim Das, and Arun Kumar Majumdar", "title": "Posture and sequence recognition for Bharatanatyam dance performances\n  using machine learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the underlying semantics of performing arts like dance is a\nchallenging task. Dance is multimedia in nature and spans over time as well as\nspace. Capturing and analyzing the multimedia content of the dance is useful\nfor the preservation of cultural heritage, to build video recommendation\nsystems, to assist learners to use tutoring systems. To develop an application\nfor dance, three aspects of dance analysis need to be addressed: 1)\nSegmentation of the dance video to find the representative action elements, 2)\nMatching or recognition of the detected action elements, and 3) Recognition of\nthe dance sequences formed by combining a number of action elements under\ncertain rules. This paper attempts to solve three fundamental problems of dance\nanalysis for understanding the underlying semantics of dance forms. Our focus\nis on an Indian Classical Dance (ICD) form known as Bharatanatyam. As dance is\ndriven by music, we use the music as well as motion information for key posture\nextraction. Next, we recognize the key postures using machine learning as well\nas deep learning techniques. Finally, the dance sequence is recognized using\nthe Hidden Markov Model (HMM). We capture the multi-modal data of Bharatanatyam\ndance using Kinect and build an annotated data set for research in ICD.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 16:18:01 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Mallick", "Tanwi", ""], ["Das", "Partha Pratim", ""], ["Majumdar", "Arun Kumar", ""]]}, {"id": "1909.11029", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker, A.S.M. Kayes, Md Hasan Furhad, Mohammad Mainul Islam\n  and Md Shohidul Islam", "title": "E-MIIM: An Ensemble Learning based Context-Aware Mobile Telephony Model\n  for Intelligent Interruption Management", "comments": "10 pages", "journal-ref": "Journal: AI and Society, Springer Nature, 2019", "doi": "10.1007/s00146-019-00898-8", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, mobile telephony interruptions in our daily life activities are\ncommon because of the inappropriate ringing notifications of incoming phone\ncalls in different contexts. Such interruptions may impact on the work\nattention not only for the mobile phone owners but also the surrounding people.\nDecision tree is the most popular machine learning classification technique\nthat is used in existing context-aware mobile intelligent interruption\nmanagement (MIIM) model to overcome such issues. However, a single decision\ntree based context-aware model may cause overfitting problem and thus decrease\nthe prediction accuracy of the inferred model. Therefore, in this paper, we\npropose an ensemble machine learning based context-aware mobile telephony model\nfor the purpose of intelligent interruption management by taking into account\nmulti-dimensional contexts and name it \"E-MIIM\". The experimental results on\nindividuals' real life mobile telephony datasets show that our E-MIIM model is\nmore effective and outperforms existing MIIM model for predicting and managing\nindividual's mobile telephony interruptions based on their relevant contextual\ninformation.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 21:36:33 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Kayes", "A. S. M.", ""], ["Furhad", "Md Hasan", ""], ["Islam", "Mohammad Mainul", ""], ["Islam", "Md Shohidul", ""]]}, {"id": "1909.11060", "submitter": "Shane Steinert-Threlkeld", "authors": "Shane Steinert-Threlkeld", "title": "Paying Attention to Function Words", "comments": "Emergent Communication Workshop @ NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All natural languages exhibit a distinction between content words (like nouns\nand adjectives) and function words (like determiners, auxiliaries,\nprepositions). Yet surprisingly little has been said about the emergence of\nthis universal architectural feature of natural languages. Why have human\nlanguages evolved to exhibit this division of labor between content and\nfunction words? How could such a distinction have emerged in the first place?\nThis paper takes steps towards answering these questions by showing how the\ndistinction can emerge through reinforcement learning in agents playing a\nsignaling game across contexts which contain multiple objects that possess\nmultiple perceptually salient gradable properties.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 17:18:48 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Steinert-Threlkeld", "Shane", ""]]}, {"id": "1909.11074", "submitter": "Mojtaba Vaezi", "authors": "Khai Nguyen Doan, Mojtaba Vaezi, Wonjae Shin, H. Vincent Poor,\n  Hyundong Shin, and Tony Q. S. Quek", "title": "Power Allocation in Cache-Aided NOMA Systems: Optimization and Deep\n  Reinforcement Learning Approaches", "comments": "To appear in the IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work exploits the advantages of two prominent techniques in future\ncommunication networks, namely caching and non-orthogonal multiple access\n(NOMA). Particularly, a system with Rayleigh fading channels and cache-enabled\nusers is analyzed. It is shown that the caching-NOMA combination provides a new\nopportunity of cache hit which enhances the cache utility as well as the\neffectiveness of NOMA. Importantly, this comes without requiring users'\ncollaboration, and thus, avoids many complicated issues such as users' privacy\nand security, selfishness, etc. In order to optimize users' quality of service\nand, concurrently, ensure the fairness among users, the probability that all\nusers can decode the desired signals is maximized. In NOMA, a combination of\nmultiple messages are sent to users, and the defined objective is approached by\nfinding an appropriate power allocation for message signals. To address the\npower allocation problem, two novel methods are proposed. The first one is a\ndivide-and-conquer-based method for which closed-form expressions for the\noptimal resource allocation policy are derived, making this method simple and\nflexible to the system context. The second one is based on the deep\nreinforcement learning method that allows all users to share the full\nbandwidth. Finally, simulation results are provided to demonstrate the\neffectiveness of the proposed methods and to compare their performance.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 17:53:10 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Doan", "Khai Nguyen", ""], ["Vaezi", "Mojtaba", ""], ["Shin", "Wonjae", ""], ["Poor", "H. Vincent", ""], ["Shin", "Hyundong", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "1909.11081", "submitter": "Arnab Ghosh", "authors": "Arnab Ghosh and Richard Zhang and Puneet K. Dokania and Oliver Wang\n  and Alexei A. Efros and Philip H.S. Torr and Eli Shechtman", "title": "Interactive Sketch & Fill: Multiclass Sketch-to-Image Translation", "comments": "ICCV 2019, Video Avaiable at https://youtu.be/T9xtpAMUDps", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an interactive GAN-based sketch-to-image translation method that\nhelps novice users create images of simple objects. As the user starts to draw\na sketch of a desired object type, the network interactively recommends\nplausible completions, and shows a corresponding synthesized image to the user.\nThis enables a feedback loop, where the user can edit their sketch based on the\nnetwork's recommendations, visualizing both the completed shape and final\nrendered image while they draw. In order to use a single trained model across a\nwide array of object classes, we introduce a gating-based approach for class\nconditioning, which allows us to generate distinct classes without feature\nmixing, from a single generator network. Video available at our website:\nhttps://arnabgho.github.io/iSketchNFill/.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 17:56:37 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 18:16:30 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Ghosh", "Arnab", ""], ["Zhang", "Richard", ""], ["Dokania", "Puneet K.", ""], ["Wang", "Oliver", ""], ["Efros", "Alexei A.", ""], ["Torr", "Philip H. S.", ""], ["Shechtman", "Eli", ""]]}, {"id": "1909.11082", "submitter": "Sethu Hareesh Kolluru", "authors": "Sethu Hareesh Kolluru", "title": "A Neural Network Based Method to Solve Boundary Value Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Neural Network (NN) based numerical method is formulated and implemented\nfor solving Boundary Value Problems (BVPs) and numerical results are presented\nto validate this method by solving Laplace equation with Dirichlet boundary\ncondition and Poisson's equation with mixed boundary conditions. The principal\nadvantage of NN based numerical method is the discrete data points where the\nfield is computed, can be unstructured and do not suffer from issues of meshing\nlike traditional numerical methods such as Finite Difference Time Domain or\nFinite Element Method. Numerical investigations are carried out for both\nuniform and non-uniform training grid distributions to understand the efficacy\nand limitations of this method and to provide qualitative understanding of\nvarious parameters involved.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 17:58:39 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Kolluru", "Sethu Hareesh", ""]]}, {"id": "1909.11114", "submitter": "Christian Gary Mena Leco\\~na", "authors": "C. Gary Mena, Arno De Caigny, Kristof Coussement, Koen W. De Bock,\n  Stefan Lessmann", "title": "Churn Prediction with Sequential Data and Deep Neural Networks. A\n  Comparative Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-the-shelf machine learning algorithms for prediction such as regularized\nlogistic regression cannot exploit the information of time-varying features\nwithout previously using an aggregation procedure of such sequential data.\nHowever, recurrent neural networks provide an alternative approach by which\ntime-varying features can be readily used for modeling. This paper assesses the\nperformance of neural networks for churn modeling using recency, frequency, and\nmonetary value data from a financial services provider. Results show that RFM\nvariables in combination with LSTM neural networks have larger top-decile lift\nand expected maximum profit metrics than regularized logistic regression models\nwith commonly-used demographic variables. Moreover, we show that using the\nfitted probabilities from the LSTM as feature in the logistic regression\nincreases the out-of-sample performance of the latter by 25 percent compared to\na model with only static features.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 18:27:14 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Mena", "C. Gary", ""], ["De Caigny", "Arno", ""], ["Coussement", "Kristof", ""], ["De Bock", "Koen W.", ""], ["Lessmann", "Stefan", ""]]}, {"id": "1909.11117", "submitter": "Alexis Arnaudon Dr", "authors": "Robert L. Peach, Alexis Arnaudon, Mauricio Barahona", "title": "Semi-supervised classification on graphs using explicit diffusion\n  dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification tasks based on feature vectors can be significantly improved\nby including within deep learning a graph that summarises pairwise\nrelationships between the samples. Intuitively, the graph acts as a conduit to\nchannel and bias the inference of class labels. Here, we study classification\nmethods that consider the graph as the originator of an explicit graph\ndiffusion. We show that appending graph diffusion to feature-based learning as\nan \\textit{a posteriori} refinement achieves state-of-the-art classification\naccuracy. This method, which we call Graph Diffusion Reclassification (GDR),\nuses overshooting events of a diffusive graph dynamics to reclassify individual\nnodes. The method uses intrinsic measures of node influence, which are distinct\nfor each node, and allows the evaluation of the relationship and importance of\nfeatures and graph for classification. We also present diff-GCN, a simple\nextension of Graph Convolutional Neural Network (GCN) architectures that\nleverages explicit diffusion dynamics, and allows the natural use of directed\ngraphs. To showcase our methods, we use benchmark datasets of documents with\nassociated citation data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 18:38:52 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Peach", "Robert L.", ""], ["Arnaudon", "Alexis", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1909.11124", "submitter": "Yifan Xue", "authors": "Yifan Xue, Michael Ding and Xinghua Lu", "title": "Supervised Vector Quantized Variational Autoencoder for Learning\n  Interpretable Global Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning interpretable representations of data remains a central challenge in\ndeep learning. When training a deep generative model, the observed data are\noften associated with certain categorical labels, and, in parallel with\nlearning to regenerate data and simulate new data, learning an interpretable\nrepresentation of each class of data is also a process of acquiring knowledge.\nHere, we present a novel generative model, referred to as the Supervised Vector\nQuantized Variational AutoEncoder (S-VQ-VAE), which combines the power of\nsupervised and unsupervised learning to obtain a unique, interpretable global\nrepresentation for each class of data. Compared with conventional generative\nmodels, our model has three key advantages: first, it is an integrative model\nthat can simultaneously learn a feature representation for individual data\npoint and a global representation for each class of data; second, the learning\nof global representations with embedding codes is guided by supervised\ninformation, which clearly defines the interpretation of each code; and third,\nthe global representations capture crucial characteristics of different\nclasses, which reveal similarity and differences of statistical structures\nunderlying different groups of data. We evaluated the utility of S-VQ-VAE on a\nmachine learning benchmark dataset, the MNIST dataset, and on gene expression\ndata from the Library of Integrated Network-Based Cellular Signatures (LINCS).\nWe proved that S-VQ-VAE was able to learn the global genetic characteristics of\nsamples perturbed by the same class of perturbagen (PCL), and further revealed\nthe mechanism correlations between PCLs. Such knowledge is crucial for\npromoting new drug development for complex diseases like cancer.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 18:51:21 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 19:54:35 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Xue", "Yifan", ""], ["Ding", "Michael", ""], ["Lu", "Xinghua", ""]]}, {"id": "1909.11128", "submitter": "Pooya Abolghasemi", "authors": "Pooya Abolghasemi, Ladislau B\\\"ol\\\"oni", "title": "Accept Synthetic Objects as Real: End-to-End Training of Attentive Deep\n  Visuomotor Policies for Manipulation in Clutter", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research demonstrated that it is feasible to end-to-end train\nmulti-task deep visuomotor policies for robotic manipulation using variations\nof learning from demonstration (LfD) and reinforcement learning (RL). In this\npaper, we extend the capabilities of end-to-end LfD architectures to object\nmanipulation in clutter. We start by introducing a data augmentation procedure\ncalled Accept Synthetic Objects as Real (ASOR). Using ASOR we develop two\nnetwork architectures: implicit attention ASOR-IA and explicit attention\nASOR-EA. Both architectures use the same training data (demonstrations in\nuncluttered environments) as previous approaches. Experimental results show\nthat ASOR-IA and ASOR-EA succeed ina significant fraction of trials in\ncluttered environments where previous approaches never succeed. In addition, we\nfind that both ASOR-IA and ASOR-EA outperform previous approaches even in\nuncluttered environments, with ASOR-EA performing better even in clutter\ncompared to the previous best baseline in an uncluttered environment.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 19:01:40 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 22:45:55 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Abolghasemi", "Pooya", ""], ["B\u00f6l\u00f6ni", "Ladislau", ""]]}, {"id": "1909.11150", "submitter": "Nouamane Laanait", "authors": "Nouamane Laanait, Joshua Romero, Junqi Yin, M. Todd Young, Sean\n  Treichler, Vitalii Starchenko, Albina Borisevich, Alex Sergeev, Michael\n  Matheson", "title": "Exascale Deep Learning for Scientific Inverse Problems", "comments": "13 pages, 9 figures. Under review by the Systems and Machine Learning\n  (SysML) Conference (SysML '20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci cs.DC physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce novel communication strategies in synchronous distributed Deep\nLearning consisting of decentralized gradient reduction orchestration and\ncomputational graph-aware grouping of gradient tensors. These new techniques\nproduce an optimal overlap between computation and communication and result in\nnear-linear scaling (0.93) of distributed training up to 27,600 NVIDIA V100\nGPUs on the Summit Supercomputer. We demonstrate our gradient reduction\ntechniques in the context of training a Fully Convolutional Neural Network to\napproximate the solution of a longstanding scientific inverse problem in\nmaterials imaging. The efficient distributed training on a dataset size of 0.5\nPB, produces a model capable of an atomically-accurate reconstruction of\nmaterials, and in the process reaching a peak performance of 2.15(4)\nEFLOPS$_{16}$.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 19:40:59 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Laanait", "Nouamane", ""], ["Romero", "Joshua", ""], ["Yin", "Junqi", ""], ["Young", "M. Todd", ""], ["Treichler", "Sean", ""], ["Starchenko", "Vitalii", ""], ["Borisevich", "Albina", ""], ["Sergeev", "Alex", ""], ["Matheson", "Michael", ""]]}, {"id": "1909.11155", "submitter": "Serim Ryou", "authors": "Serim Ryou, Seong-Gyun Jeong, Pietro Perona", "title": "Anchor Loss: Modulating Loss Scale based on Prediction Difficulty", "comments": "To appear in Proceedings of IEEE International Conference on Computer\n  Vision (ICCV), 2019. (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel loss function that dynamically rescales the cross entropy\nbased on prediction difficulty regarding a sample. Deep neural network\narchitectures in image classification tasks struggle to disambiguate visually\nsimilar objects. Likewise, in human pose estimation symmetric body parts often\nconfuse the network with assigning indiscriminative scores to them. This is due\nto the output prediction, in which only the highest confidence label is\nselected without taking into consideration a measure of uncertainty. In this\nwork, we define the prediction difficulty as a relative property coming from\nthe confidence score gap between positive and negative labels. More precisely,\nthe proposed loss function penalizes the network to avoid the score of a false\nprediction being significant. To demonstrate the efficacy of our loss function,\nwe evaluate it on two different domains: image classification and human pose\nestimation. We find improvements in both applications by achieving higher\naccuracy compared to the baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 20:01:36 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Ryou", "Serim", ""], ["Jeong", "Seong-Gyun", ""], ["Perona", "Pietro", ""]]}, {"id": "1909.11193", "submitter": "Wei Zhu", "authors": "Wei Zhu, Qiang Qiu, Robert Calderbank, Guillermo Sapiro, Xiuyuan Cheng", "title": "Scaling-Translation-Equivariant Networks with Decomposed Convolutional\n  Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoding the scale information explicitly into the representation learned by\na convolutional neural network (CNN) is beneficial for many computer vision\ntasks especially when dealing with multiscale inputs. We study, in this paper,\na scaling-translation-equivariant (ST-equivariant) CNN with joint convolutions\nacross the space and the scaling group, which is shown to be both sufficient\nand necessary to achieve equivariance for the regular representation of the\nscaling-translation group ST . To reduce the model complexity and computational\nburden, we decompose the convolutional filters under two pre-fixed separable\nbases and truncate the expansion to low-frequency components. A further benefit\nof the truncated filter expansion is the improved deformation robustness of the\nequivariant representation, a property which is theoretically analyzed and\nempirically verified. Numerical experiments demonstrate that the proposed\nscaling-translation-equivariant network with decomposed convolutional filters\n(ScDCFNet) achieves significantly improved performance in multiscale image\nclassification and better interpretability than regular CNNs at a reduced model\nsize.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:23:19 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 18:41:42 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zhu", "Wei", ""], ["Qiu", "Qiang", ""], ["Calderbank", "Robert", ""], ["Sapiro", "Guillermo", ""], ["Cheng", "Xiuyuan", ""]]}, {"id": "1909.11197", "submitter": "Tanwi Mallick", "authors": "Tanwi Mallick, Prasanna Balaprakash, Eric Rask, and Jane Macfarlane", "title": "Graph-Partitioning-Based Diffusion Convolutional Recurrent Neural\n  Network for Large-Scale Traffic Forecasting", "comments": null, "journal-ref": "Transportation Research Record (2020)", "doi": "10.1177/0361198120930010", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting approaches are critical to developing adaptive strategies\nfor mobility. Traffic patterns have complex spatial and temporal dependencies\nthat make accurate forecasting on large highway networks a challenging task.\nRecently, diffusion convolutional recurrent neural networks (DCRNNs) have\nachieved state-of-the-art results in traffic forecasting by capturing the\nspatiotemporal dynamics of the traffic. Despite the promising results, however,\napplying DCRNNs for large highway networks still remains elusive because of\ncomputational and memory bottlenecks. We present an approach for implementing a\nDCRNN for a large highway network that overcomes these limitations. Our\napproach uses a graph-partitioning method to decompose a large highway network\ninto smaller networks and trains them independently. We demonstrate the\nefficacy of the graph-partitioning-based DCRNN approach to model the traffic on\na large California highway network with 11,160 sensor locations. We develop an\noverlapping nodes approach for the graph-partitioning-based DCRNN to include\nsensor locations from partitions that are geographically close to a given\npartition. Furthermore, we demonstrate that the DCRNN model can be used to\nforecast the speed and flow simultaneously and that the forecasted values\npreserve fundamental traffic flow dynamics. Our approach to developing DCRNN\nmodels that represent large highway networks can be a potential core capability\nin advanced highway traffic monitoring systems, where a trained DCRNN model\nforecasting traffic at all sensor locations can be used to adjust traffic\nmanagement strategies proactively based on anticipated future conditions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:38:29 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 14:51:19 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 14:55:15 GMT"}, {"version": "v4", "created": "Mon, 20 Apr 2020 13:15:34 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Mallick", "Tanwi", ""], ["Balaprakash", "Prasanna", ""], ["Rask", "Eric", ""], ["Macfarlane", "Jane", ""]]}, {"id": "1909.11201", "submitter": "Shusen Wang", "authors": "Mengjiao Zhang and Shusen Wang", "title": "Matrix Sketching for Secure Collaborative Machine Learning", "comments": "In International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative learning allows participants to jointly train a model without\ndata sharing. To update the model parameters, the central server broadcasts\nmodel parameters to the clients, and the clients send updating directions such\nas gradients to the server. While data do not leave a client device, the\ncommunicated gradients and parameters will leak a client's privacy. Attacks\nthat infer clients' privacy from gradients and parameters have been developed\nby prior work. Simple defenses such as dropout and differential privacy either\nfail to defend the attacks or seriously hurt test accuracy.\n  We propose a practical defense which we call Double-Blind Collaborative\nLearning (DBCL). The high-level idea is to apply random matrix sketching to the\nparameters (aka weights) and re-generate random sketching after each iteration.\nDBCL prevents clients from conducting gradient-based privacy inferences which\nare the most effective attacks. DBCL works because from the attacker's\nperspective, sketching is effectively random noise that outweighs the signal.\nNotably, DBCL does not much increase computation and communication costs and\ndoes not hurt test accuracy at all.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:55:26 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 21:05:22 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 14:07:12 GMT"}, {"version": "v4", "created": "Thu, 8 Jul 2021 13:27:37 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhang", "Mengjiao", ""], ["Wang", "Shusen", ""]]}, {"id": "1909.11207", "submitter": "Shusen Wang", "authors": "Shusen Wang", "title": "Simple and Almost Assumption-Free Out-of-Sample Bound for Random Feature\n  Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random feature mapping (RFM) is a popular method for speeding up kernel\nmethods at the cost of losing a little accuracy. We study kernel ridge\nregression with random feature mapping (RFM-KRR) and establish novel\nout-of-sample error upper and lower bounds. While out-of-sample bounds for\nRFM-KRR have been established by prior work, this paper's theories are highly\ninteresting for two reasons. On the one hand, our theories are based on weak\nand valid assumptions. In contrast, the existing theories are based on various\nuncheckable assumptions, which makes it unclear whether their bounds are the\nnature of RFM-KRR or simply the consequence of strong assumptions. On the other\nhand, our analysis is completely based on elementary linear algebra and thereby\neasy to read and verify. Finally, our experiments lend empirical supports to\nthe theories.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 22:07:33 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wang", "Shusen", ""]]}, {"id": "1909.11212", "submitter": "Rajath Soans", "authors": "Julianna D. Ianni, Rajath E. Soans, Sivaramakrishnan Sankarapandian,\n  Ramachandra Vikas Chamarthi, Devi Ayyagari, Thomas G. Olsen, Michael J.\n  Bonham, Coleman C. Stavish, Kiran Motaparthi, Clay J. Cockerell, Theresa A.\n  Feeser, Jason B. Lee", "title": "Augmenting the Pathology Lab: An Intelligent Whole Slide Image\n  Classification System for the Real World", "comments": "23 pages, 5 figures", "journal-ref": "Sci Rep 10, 3217 (2020)", "doi": "10.1038/s41598-020-59985-2", "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard of care diagnostic procedure for suspected skin cancer is\nmicroscopic examination of hematoxylin \\& eosin stained tissue by a\npathologist. Areas of high inter-pathologist discordance and rising biopsy\nrates necessitate higher efficiency and diagnostic reproducibility. We present\nand validate a deep learning system which classifies digitized dermatopathology\nslides into 4 categories. The system is developed using 5,070 images from a\nsingle lab, and tested on an uncurated set of 13,537 images from 3 test labs,\nusing whole slide scanners manufactured by 3 different vendors. The system's\nuse of deep-learning-based confidence scoring as a criterion to consider the\nresult as accurate yields an accuracy of up to 98\\%, and makes it adoptable in\na real-world setting. Without confidence scoring, the system achieved an\naccuracy of 78\\%. We anticipate that our deep learning system will serve as a\nfoundation enabling faster diagnosis of skin cancer, identification of cases\nfor specialist review, and targeted diagnostic classifications.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 22:26:44 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ianni", "Julianna D.", ""], ["Soans", "Rajath E.", ""], ["Sankarapandian", "Sivaramakrishnan", ""], ["Chamarthi", "Ramachandra Vikas", ""], ["Ayyagari", "Devi", ""], ["Olsen", "Thomas G.", ""], ["Bonham", "Michael J.", ""], ["Stavish", "Coleman C.", ""], ["Motaparthi", "Kiran", ""], ["Cockerell", "Clay J.", ""], ["Feeser", "Theresa A.", ""], ["Lee", "Jason B.", ""]]}, {"id": "1909.11218", "submitter": "Manaal Faruqui", "authors": "Shikhar Vashishth, Shyam Upadhyay, Gaurav Singh Tomar, Manaal Faruqui", "title": "Attention Interpretability Across NLP Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": "2019", "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The attention layer in a neural network model provides insights into the\nmodel's reasoning behind its prediction, which are usually criticized for being\nopaque. Recently, seemingly contradictory viewpoints have emerged about the\ninterpretability of attention weights (Jain & Wallace, 2019; Vig & Belinkov,\n2019). Amid such confusion arises the need to understand attention mechanism\nmore systematically. In this work, we attempt to fill this gap by giving a\ncomprehensive explanation which justifies both kinds of observations (i.e.,\nwhen is attention interpretable and when it is not). Through a series of\nexperiments on diverse NLP tasks, we validate our observations and reinforce\nour claim of interpretability of attention through manual evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 22:58:44 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Upadhyay", "Shyam", ""], ["Tomar", "Gaurav Singh", ""], ["Faruqui", "Manaal", ""]]}, {"id": "1909.11228", "submitter": "David Venuto", "authors": "David Venuto, Leonard Boussioux, Junhao Wang, Rola Dali, Jhelum\n  Chakravorty, Yoshua Bengio, Doina Precup", "title": "Avoidance Learning Using Observational Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imitation learning seeks to learn an expert policy from sampled\ndemonstrations. However, in the real world, it is often difficult to find a\nperfect expert and avoiding dangerous behaviors becomes relevant for safety\nreasons. We present the idea of \\textit{learning to avoid}, an objective\nopposite to imitation learning in some sense, where an agent learns to avoid a\ndemonstrator policy given an environment. We define avoidance learning as the\nprocess of optimizing the agent's reward while avoiding dangerous behaviors\ngiven by a demonstrator. In this work we develop a framework of avoidance\nlearning by defining a suitable objective function for these problems which\ninvolves the \\emph{distance} of state occupancy distributions of the expert and\ndemonstrator policies. We use density estimates for state occupancy measures\nand use the aforementioned distance as the reward bonus for avoiding the\ndemonstrator. We validate our theory with experiments using a wide range of\npartially observable environments. Experimental results show that we are able\nto improve sample efficiency during training compared to state of the art\npolicy optimization and safety methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 23:37:35 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Venuto", "David", ""], ["Boussioux", "Leonard", ""], ["Wang", "Junhao", ""], ["Dali", "Rola", ""], ["Chakravorty", "Jhelum", ""], ["Bengio", "Yoshua", ""], ["Precup", "Doina", ""]]}, {"id": "1909.11229", "submitter": "Alexander Mathis", "authors": "Alexander Mathis, Thomas Biasi, Steffen Schneider, Mert\n  Y\\\"uksekg\\\"on\\\"ul, Byron Rogers, Matthias Bethge, Mackenzie W. Mathis", "title": "Pretraining boosts out-of-domain robustness for pose estimation", "comments": "A.M. and T.B. co-first authors. Dataset available at http://horse10.\n  deeplabcut.org . WACV 2021 conference", "journal-ref": "https://openaccess.thecvf.com/content/WACV2021/html/Mathis_Pretraining_Boosts_Out-of-Domain_Robustness_for_Pose_Estimation_WACV_2021_paper.html", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are highly effective tools for pose estimation. However, as\nin other computer vision tasks, robustness to out-of-domain data remains a\nchallenge, especially for small training sets that are common for real-world\napplications. Here, we probe the generalization ability with three architecture\nclasses (MobileNetV2s, ResNets, and EfficientNets) for pose estimation. We\ndeveloped a dataset of 30 horses that allowed for both \"within-domain\" and\n\"out-of-domain\" (unseen horse) benchmarking - this is a crucial test for\nrobustness that current human pose estimation benchmarks do not directly\naddress. We show that better ImageNet-performing architectures perform better\non both within- and out-of-domain data if they are first pretrained on\nImageNet. We additionally show that better ImageNet models generalize better\nacross animal species. Furthermore, we introduce Horse-C, a new benchmark for\ncommon corruptions for pose estimation, and confirm that pretraining increases\nperformance in this domain shift context as well. Overall, our results\ndemonstrate that transfer learning is beneficial for out-of-domain robustness.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 23:40:39 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 18:46:51 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Mathis", "Alexander", ""], ["Biasi", "Thomas", ""], ["Schneider", "Steffen", ""], ["Y\u00fcksekg\u00f6n\u00fcl", "Mert", ""], ["Rogers", "Byron", ""], ["Bethge", "Matthias", ""], ["Mathis", "Mackenzie W.", ""]]}, {"id": "1909.11232", "submitter": "Al Amin Hosain", "authors": "Al Amin Hosain, Panneer Selvam Santhalingam, Parth Pathak, Jana\n  Kosecka and Huzefa Rangwala", "title": "Sign Language Recognition Analysis using Multimodal Data", "comments": "conference : IEEE DSAA, 2019, Washington DC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-controlled personal and home assistants (such as the Amazon Echo and\nApple Siri) are becoming increasingly popular for a variety of applications.\nHowever, the benefits of these technologies are not readily accessible to Deaf\nor Hard-ofHearing (DHH) users. The objective of this study is to develop and\nevaluate a sign recognition system using multiple modalities that can be used\nby DHH signers to interact with voice-controlled devices. With the advancement\nof depth sensors, skeletal data is used for applications like video analysis\nand activity recognition. Despite having similarity with the well-studied human\nactivity recognition, the use of 3D skeleton data in sign language recognition\nis rare. This is because unlike activity recognition, sign language is mostly\ndependent on hand shape pattern. In this work, we investigate the feasibility\nof using skeletal and RGB video data for sign language recognition using a\ncombination of different deep learning architectures. We validate our results\non a large-scale American Sign Language (ASL) dataset of 12 users and 13107\nsamples across 51 signs. It is named as GMUASL51. We collected the dataset over\n6 months and it will be publicly released in the hope of spurring further\nmachine learning research towards providing improved accessibility for digital\nassistants.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 23:44:49 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Hosain", "Al Amin", ""], ["Santhalingam", "Panneer Selvam", ""], ["Pathak", "Parth", ""], ["Kosecka", "Jana", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1909.11233", "submitter": "Jalal Mahmud", "authors": "Yash Bhalgat, Zhe Liu, Pritam Gundecha, Jalal Mahmud, Amita Misra", "title": "Teacher-Student Learning Paradigm for Tri-training: An Efficient Method\n  for Unlabeled Data Exploitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given that labeled data is expensive to obtain in real-world scenarios, many\nsemi-supervised algorithms have explored the task of exploitation of unlabeled\ndata. Traditional tri-training algorithm and tri-training with disagreement\nhave shown promise in tasks where labeled data is limited. In this work, we\nintroduce a new paradigm for tri-training, mimicking the real world\nteacher-student learning process. We show that the adaptive teacher-student\nthresholds used in the proposed method provide more control over the learning\nprocess with higher label quality. We perform evaluation on SemEval sentiment\nanalysis task and provide comprehensive comparisons over experimental settings\ncontaining varied labeled versus unlabeled data rates. Experimental results\nshow that our method outperforms other strong semi-supervised baselines, while\nrequiring less number of labeled training samples.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 00:09:56 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Bhalgat", "Yash", ""], ["Liu", "Zhe", ""], ["Gundecha", "Pritam", ""], ["Mahmud", "Jalal", ""], ["Misra", "Amita", ""]]}, {"id": "1909.11236", "submitter": "Bardienus Duisterhof", "authors": "Bardienus P. Duisterhof, Srivatsan Krishnan, Jonathan J. Cruz, Colby\n  R. Banbury, William Fu, Aleksandra Faust, Guido C. H. E. de Croon, Vijay\n  Janapa Reddi", "title": "Learning to Seek: Autonomous Source Seeking with Deep Reinforcement\n  Learning Onboard a Nano Drone Microcontroller", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present fully autonomous source seeking onboard a highly constrained nano\nquadcopter, by contributing application-specific system and observation feature\ndesign to enable inference of a deep-RL policy onboard a nano quadcopter. Our\ndeep-RL algorithm finds a high-performance solution to a challenging problem,\neven in presence of high noise levels and generalizes across real and\nsimulation environments with different obstacle configurations. We verify our\napproach with simulation and in-field testing on a Bitcraze CrazyFlie using\nonly the cheap and ubiquitous Cortex-M4 microcontroller unit. The results show\nthat by end-to-end application-specific system design, our contribution\nconsumes almost three times less additional power, as compared to competing\nlearning-based navigation approach onboard a nano quadcopter. Thanks to our\nobservation space, which we carefully design within the resource constraints,\nour solution achieves a 94% success rate in cluttered and randomized test\nenvironments, as compared to the previously achieved 80%. We also compare our\nstrategy to a simple finite state machine (FSM), geared towards efficient\nexploration, and demonstrate that our policy is more robust and resilient at\nobstacle avoidance as well as up to 70% more efficient in source seeking. To\nthis end, we contribute a cheap and lightweight end-to-end tiny robot learning\n(tinyRL) solution, running onboard a nano quadcopter, that proves to be robust\nand efficient in a challenging task using limited sensory input.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 00:10:33 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 14:24:07 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 15:24:27 GMT"}, {"version": "v4", "created": "Wed, 5 Feb 2020 12:50:00 GMT"}, {"version": "v5", "created": "Fri, 11 Dec 2020 07:40:07 GMT"}, {"version": "v6", "created": "Fri, 15 Jan 2021 09:30:34 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Duisterhof", "Bardienus P.", ""], ["Krishnan", "Srivatsan", ""], ["Cruz", "Jonathan J.", ""], ["Banbury", "Colby R.", ""], ["Fu", "William", ""], ["Faust", "Aleksandra", ""], ["de Croon", "Guido C. H. E.", ""], ["Reddi", "Vijay Janapa", ""]]}, {"id": "1909.11241", "submitter": "Franco M. Luque", "authors": "Franco M. Luque", "title": "Atalaya at TASS 2019: Data Augmentation and Robust Embeddings for\n  Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article we describe our participation in TASS 2019, a shared task\naimed at the detection of sentiment polarity of Spanish tweets. We combined\ndifferent representations such as bag-of-words, bag-of-characters, and tweet\nembeddings. In particular, we trained robust subword-aware word embeddings and\ncomputed tweet representations using a weighted-averaging strategy. We also\nused two data augmentation techniques to deal with data scarcity: two-way\ntranslation augmentation, and instance crossover augmentation, a novel\ntechnique that generates new instances by combining halves of tweets. In\nexperiments, we trained linear classifiers and ensemble models, obtaining\nhighly competitive results despite the simplicity of our approaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 00:28:50 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Luque", "Franco M.", ""]]}, {"id": "1909.11248", "submitter": "John Gideon", "authors": "John Gideon, Katie Matton, Steve Anderau, Melvin G McInnis, Emily\n  Mower Provost", "title": "When to Intervene: Detecting Abnormal Mood using Everyday Smartphone\n  Conversations", "comments": "Submitted to IEEE Transactions on Affective Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipolar disorder (BPD) is a chronic mental illness characterized by extreme\nmood and energy changes from mania to depression. These changes drive behaviors\nthat often lead to devastating personal or social consequences. BPD is managed\nclinically with regular interactions with care providers, who assess mood,\nenergy levels, and the form and content of speech. Recent work has proposed\nsmartphones for monitoring mood using speech. However, these works do not\npredict when to intervene. Predicting when to intervene is challenging because\nthere is not a single measure that is relevant for every person: different\nindividuals may have different levels of symptom severity considered typical.\nAdditionally, this typical mood, or baseline, may change over time, making a\nsingle symptom threshold insufficient. This work presents an innovative\napproach that expands clinical mood monitoring to predict when interventions\nare necessary using an anomaly detection framework, which we call Temporal\nNormalization. We first validate the model using a dataset annotated for\nclinical interventions and then incorporate this method in a deep learning\nframework to predict mood anomalies from natural, unstructured, telephone\nspeech data. The combination of these approaches provides a framework to enable\nreal-world speech-focused mood monitoring.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 01:14:05 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 01:11:49 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Gideon", "John", ""], ["Matton", "Katie", ""], ["Anderau", "Steve", ""], ["McInnis", "Melvin G", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1909.11251", "submitter": "Chang How Tan Chang H Tan", "authors": "Chang How Tan, Vincent CS Lee, Mahsa Salehi", "title": "Online Semi-Supervised Concept Drift Detection with Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept drift is formally defined as the change in joint distribution of a\nset of input variables X and a target variable y. The two types of drift that\nare extensively studied are real drift and virtual drift where the former is\nthe change in posterior probabilities p(y|X) while the latter is the change in\ndistribution of X without affecting the posterior probabilities. Many\napproaches on concept drift detection either assume full availability of data\nlabels, y or handle only the virtual drift. In a streaming environment, the\nassumption of full availability of data labels, y is questioned. On the other\nhand, approaches that deal with virtual drift failed to address real drift.\nRather than improving the state-of-the-art methods, this paper presents a\nsemi-supervised framework to deal with the challenges above. The objective of\nthe proposed framework is to learn from streaming environment with limited data\nlabels, y and detect real drift concurrently. This paper proposes a novel\nconcept drift detection method utilizing the densities of posterior\nprobabilities in partially labeled streaming environments. Experimental results\non both synthetic and realworld datasets show that our proposed semi-supervised\nframework enables the detection of concept drift in such environment while\nachieving comparable prediction performance to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 01:47:28 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 02:10:38 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Tan", "Chang How", ""], ["Lee", "Vincent CS", ""], ["Salehi", "Mahsa", ""]]}, {"id": "1909.11252", "submitter": "Yang Lv", "authors": "Yang Lv, Liangsheng Zhuang, Pengyu Luo", "title": "Neighborhood-Enhanced and Time-Aware Model for Session-based\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session based recommendation has become one of the research hotpots in the\nfield of recommendation systems due to its highly practical value.Previous deep\nlearning methods mostly focus on the sequential characteristics within the\ncurrent session,and neglect the context similarity and temporal similarity\nbetween sessions which contain abundant collaborative information.In this\npaper,we propose a novel neural networks framework,namely Neighborhood Enhanced\nand Time Aware Recommendation Machine(NETA) for session based recommendation.\nFirstly,we introduce an efficient neighborhood retrieve mechanism to find out\nsimilar sessions which includes collaborative information.Then we design a\nguided attention with time-aware mechanism to extract collaborative\nrepresentation from neighborhood sessions.Especially,temporal recency between\nsessions is considered separately.Finally, we design a simple co-attention\nmechanism to determine the importance of complementary collaborative\nrepresentation when predicting the next item.Extensive experiments conducted on\ntwo real-world datasets demonstrate the effectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 01:50:32 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 14:33:07 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Lv", "Yang", ""], ["Zhuang", "Liangsheng", ""], ["Luo", "Pengyu", ""]]}, {"id": "1909.11258", "submitter": "Omer Anjum", "authors": "Omer Anjum, Hongyu Gong, Suma Bhat, Wen-Mei Hwu, Jinjun Xiong", "title": "PaRe: A Paper-Reviewer Matching Approach Using a Common Topic Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the right reviewers to assess the quality of conference submissions\nis a time consuming process for conference organizers. Given the importance of\nthis step, various automated reviewer-paper matching solutions have been\nproposed to alleviate the burden. Prior approaches, including bag-of-words\nmodels and probabilistic topic models have been inadequate to deal with the\nvocabulary mismatch and partial topic overlap between a paper submission and\nthe reviewer's expertise. Our approach, the common topic model, jointly models\nthe topics common to the submission and the reviewer's profile while relying on\nabstract topic vectors. Experiments and insightful evaluations on two datasets\ndemonstrate that the proposed method achieves consistent improvements compared\nto available state-of-the-art implementations of paper-reviewer matching.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 02:25:23 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Anjum", "Omer", ""], ["Gong", "Hongyu", ""], ["Bhat", "Suma", ""], ["Hwu", "Wen-Mei", ""], ["Xiong", "Jinjun", ""]]}, {"id": "1909.11269", "submitter": "Sibaek Seong", "authors": "Si-Baek Seong and Hae-Jeong Park", "title": "Automated identification of neural cells in the multi-photon images\n  using deep-neural networks", "comments": "8 pages, 4 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.SY eess.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of the neuroscientific imaging techniques has produced an\nunprecedented size of neural cell imaging data, which calls for automated\nprocessing. In particular, identification of cells from two photon images\ndemands segmentation of neural cells out of various materials and\nclassification of the segmented cells according to their cell types. To\nautomatically segment neural cells, we used U-Net model, followed by\nclassification of excitatory and inhibitory neurons and glia cells using a\ntransfer learning technique. For transfer learning, we tested three public\nmodels of resnet18, resnet50 and inceptionv3, after replacing the fully\nconnected layer with that for three classes. The best classification\nperformance was found for the model with inceptionv3. The proposed application\nof deep learning technique is expected to provide a critical way to cell\nidentification in the era of big neuroscience data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 03:30:50 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Seong", "Si-Baek", ""], ["Park", "Hae-Jeong", ""]]}, {"id": "1909.11274", "submitter": "Taiji Suzuki", "authors": "Taiji Suzuki, Hiroshi Abe, Tomoaki Nishimura", "title": "Compression based bound for non-compressed network: unified\n  generalization error analysis of large compressible deep neural network", "comments": "published in ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest issues in deep learning theory is the generalization\nability of networks with huge model size. The classical learning theory\nsuggests that overparameterized models cause overfitting. However, practically\nused large deep models avoid overfitting, which is not well explained by the\nclassical approaches. To resolve this issue, several attempts have been made.\nAmong them, the compression based bound is one of the promising approaches.\nHowever, the compression based bound can be applied only to a compressed\nnetwork, and it is not applicable to the non-compressed original network. In\nthis paper, we give a unified frame-work that can convert compression based\nbounds to those for non-compressed original networks. The bound gives even\nbetter rate than the one for the compressed network by improving the bias term.\nBy establishing the unified frame-work, we can obtain a data dependent\ngeneralization error bound which gives a tighter evaluation than the data\nindependent ones.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 03:43:14 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 05:40:09 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2020 16:39:16 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Suzuki", "Taiji", ""], ["Abe", "Hiroshi", ""], ["Nishimura", "Tomoaki", ""]]}, {"id": "1909.11275", "submitter": "Lech Szymanski", "authors": "Lech Szymanski, Brendan McCane, Craig Atkinson", "title": "Switched linear projections for neural network interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce switched linear projections for expressing the activity of a\nneuron in a deep neural network in terms of a single linear projection in the\ninput space. The method works by isolating the active subnetwork, a series of\nlinear transformations, that determine the entire computation of the network\nfor a given input instance. With these projections we can decompose activity in\nany hidden layer into patterns detected in a given input instance. We also\npropose that in ReLU networks it is instructive and meaningful to examine\npatterns that deactivate the neurons in a hidden layer, something that is\nimplicitly ignored by the existing interpretability methods tracking solely the\nactive aspect of the network's computation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 03:43:37 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 22:19:43 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 22:05:51 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Szymanski", "Lech", ""], ["McCane", "Brendan", ""], ["Atkinson", "Craig", ""]]}, {"id": "1909.11285", "submitter": "Ze Wang", "authors": "Ze Wang, Xiuyuan Cheng, Guillermo Sapiro, and Qiang Qiu", "title": "A Dictionary Approach to Domain-Invariant Learning in Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider domain-invariant deep learning by explicitly\nmodeling domain shifts with only a small amount of domain-specific parameters\nin a Convolutional Neural Network (CNN). By exploiting the observation that a\nconvolutional filter can be well approximated as a linear combination of a\nsmall set of dictionary atoms, we show for the first time, both empirically and\ntheoretically, that domain shifts can be effectively handled by decomposing a\nconvolutional layer into a domain-specific atom layer and a domain-shared\ncoefficient layer, while both remain convolutional. An input channel will now\nfirst convolve spatially only with each respective domain-specific dictionary\natom to \"absorb\" domain variations, and then output channels are linearly\ncombined using common decomposition coefficients trained to promote shared\nsemantics across domains. We use toy examples, rigorous analysis, and\nreal-world examples with diverse datasets and architectures, to show the\nproposed plug-in framework's effectiveness in cross and joint domain\nperformance and domain adaptation. With the proposed architecture, we need only\na small set of dictionary atoms to model each additional domain, which brings a\nnegligible amount of additional parameters, typically a few hundred.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 04:35:04 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 23:31:44 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wang", "Ze", ""], ["Cheng", "Xiuyuan", ""], ["Sapiro", "Guillermo", ""], ["Qiu", "Qiang", ""]]}, {"id": "1909.11286", "submitter": "Ze Wang", "authors": "Ze Wang, Xiuyuan Cheng, Guillermo Sapiro, and Qiang Qiu", "title": "Stochastic Conditional Generative Networks with Basis Decomposition", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While generative adversarial networks (GANs) have revolutionized machine\nlearning, a number of open questions remain to fully understand them and\nexploit their power. One of these questions is how to efficiently achieve\nproper diversity and sampling of the multi-mode data space. To address this, we\nintroduce BasisGAN, a stochastic conditional multi-mode image generator. By\nexploiting the observation that a convolutional filter can be well approximated\nas a linear combination of a small set of basis elements, we learn a\nplug-and-played basis generator to stochastically generate basis elements, with\njust a few hundred of parameters, to fully embed stochasticity into\nconvolutional filters. By sampling basis elements instead of filters, we\ndramatically reduce the cost of modeling the parameter space with no sacrifice\non either image diversity or fidelity. To illustrate this proposed\nplug-and-play framework, we construct variants of BasisGAN based on\nstate-of-the-art conditional image generation networks, and train the networks\nby simply plugging in a basis generator, without additional auxiliary\ncomponents, hyperparameters, or training objectives. The experimental success\nis complemented with theoretical results indicating how the perturbations\nintroduced by the proposed sampling of basis elements can propagate to the\nappearance of generated images.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 04:37:38 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 19:35:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Wang", "Ze", ""], ["Cheng", "Xiuyuan", ""], ["Sapiro", "Guillermo", ""], ["Qiu", "Qiang", ""]]}, {"id": "1909.11289", "submitter": "Morgan Heisler", "authors": "Morgan Heisler, Forson Chan, Zaid Mammo, Chandrakumar Balaratnasingam,\n  Pavle Prentasic, Gavin Docherty, MyeongJin Ju, Sanjeeva Rajapakse, Sieun Lee,\n  Andrew Merkur, Andrew Kirker, David Albiani, David Maberley, K. Bailey\n  Freund, Mirza Faisal Beg, Sven Loncaric, Marinko V. Sarunic and Eduardo V.\n  Navajas", "title": "Deep learning vessel segmentation and quantification of the foveal\n  avascular zone using commercial and prototype OCT-A platforms", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic quantification of perifoveal vessel densities in optical coherence\ntomography angiography (OCT-A) images face challenges such as variable intra-\nand inter-image signal to noise ratios, projection artefacts from outer\nvasculature layers, and motion artefacts. This study demonstrates the utility\nof deep neural networks for automatic quantification of foveal avascular zone\n(FAZ) parameters and perifoveal vessel density of OCT-A images in healthy and\ndiabetic eyes. OCT-A images of the foveal region were acquired using three\nOCT-A systems: a 1060nm Swept Source (SS)-OCT prototype, RTVue XR Avanti\n(Optovue Inc., Fremont, CA), and the ZEISS Angioplex (Carl Zeiss Meditec,\nDublin, CA). Automated segmentation was then performed using a deep neural\nnetwork. Four FAZ morphometric parameters (area, min/max diameter, and\neccentricity) and perifoveal vessel density were used as outcome measures. The\naccuracy, sensitivity and specificity of the DNN vessel segmentations were\ncomparable across all three device platforms. No significant difference between\nthe means of the measurements from automated and manual segmentations were\nfound for any of the outcome measures on any system. The intraclass correlation\ncoefficient (ICC) was also good (> 0.51) for all measurements. Automated deep\nlearning vessel segmentation of OCT-A may be suitable for both commercial and\nresearch purposes for better quantification of the retinal circulation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 05:04:20 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Heisler", "Morgan", ""], ["Chan", "Forson", ""], ["Mammo", "Zaid", ""], ["Balaratnasingam", "Chandrakumar", ""], ["Prentasic", "Pavle", ""], ["Docherty", "Gavin", ""], ["Ju", "MyeongJin", ""], ["Rajapakse", "Sanjeeva", ""], ["Lee", "Sieun", ""], ["Merkur", "Andrew", ""], ["Kirker", "Andrew", ""], ["Albiani", "David", ""], ["Maberley", "David", ""], ["Freund", "K. Bailey", ""], ["Beg", "Mirza Faisal", ""], ["Loncaric", "Sven", ""], ["Sarunic", "Marinko V.", ""], ["Navajas", "Eduardo V.", ""]]}, {"id": "1909.11294", "submitter": "Simon Luo", "authors": "Simon Luo, Lamiae Azizi and Mahito Sugiyama", "title": "Hierarchical Probabilistic Model for Blind Source Separation via\n  Legendre Transformation", "comments": "13 pages, 7 figures, UAI2021", "journal-ref": "37th Confeence on Uncertainty in Artificial Intelligence, July\n  27-30, 2021, Online", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel blind source separation (BSS) method, called information\ngeometric blind source separation (IGBSS). Our formulation is based on the\nlog-linear model equipped with a hierarchically structured sample space, which\nhas theoretical guarantees to uniquely recover a set of source signals by\nminimizing the KL divergence from a set of mixed signals. Source signals,\nreceived signals, and mixing matrices are realized as different layers in our\nhierarchical sample space. Our empirical results have demonstrated on images\nand time series data that our approach is superior to well established\ntechniques and is able to separate signals with complex interactions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 05:22:45 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 07:28:51 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 01:46:56 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Luo", "Simon", ""], ["Azizi", "Lamiae", ""], ["Sugiyama", "Mahito", ""]]}, {"id": "1909.11298", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Alexander Cloninger", "title": "Classification Logit Two-sample Testing by Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of generative adversarial networks and variational\nlearning suggests training a classifier network may work well in addressing the\nclassical two-sample problem. Network-based tests have the computational\nadvantage that the algorithm scales to large samples. This paper proposes a\ntwo-sample statistic which is the difference of the logit function, provided by\na trained classification neural network, evaluated on the testing set split of\nthe two datasets. Theoretically, we prove the testing power to differentiate\ntwo sub-exponential densities given that the network is sufficiently\nparametrized. When the two densities lie on or near to low-dimensional\nmanifolds embedded in possibly high-dimensional space, the needed network\ncomplexity is reduced to only scale with the intrinsic dimensionality. Both the\napproximation and estimation error analysis are based on a new result of\nnear-manifold integral approximation. In experiments, the proposed method\ndemonstrates better performance than previous network-based tests using\nclassification accuracy as the two-sample statistic, and compares favorably to\ncertain kernel maximum mean discrepancy tests on synthetic datasets and\nhand-written digit datasets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 05:55:28 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 20:16:04 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Cloninger", "Alexander", ""]]}, {"id": "1909.11299", "submitter": "Cheolhyoung Lee", "authors": "Cheolhyoung Lee, Kyunghyun Cho, Wanmo Kang", "title": "Mixout: Effective Regularization to Finetune Large-scale Pretrained\n  Language Models", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing, it has been observed recently that\ngeneralization could be greatly improved by finetuning a large-scale language\nmodel pretrained on a large unlabeled corpus. Despite its recent success and\nwide adoption, finetuning a large pretrained language model on a downstream\ntask is prone to degenerate performance when there are only a small number of\ntraining instances available. In this paper, we introduce a new regularization\ntechnique, to which we refer as \"mixout\", motivated by dropout. Mixout\nstochastically mixes the parameters of two models. We show that our mixout\ntechnique regularizes learning to minimize the deviation from one of the two\nmodels and that the strength of regularization adapts along the optimization\ntrajectory. We empirically evaluate the proposed mixout and its variants on\nfinetuning a pretrained language model on downstream tasks. More specifically,\nwe demonstrate that the stability of finetuning and the average accuracy\ngreatly increase when we use the proposed approach to regularize finetuning of\nBERT on downstream tasks in GLUE.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 06:04:37 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 02:18:43 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Lee", "Cheolhyoung", ""], ["Cho", "Kyunghyun", ""], ["Kang", "Wanmo", ""]]}, {"id": "1909.11303", "submitter": "Taewoo Kim", "authors": "Taewoo Kim and Joo-Haeng Lee", "title": "C-3PO: Cyclic-Three-Phase Optimization for Human-Robot Motion\n  Retargeting based on Reinforcement Learning", "comments": "Accepted in ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion retargeting between heterogeneous polymorphs with different sizes and\nkinematic configurations requires a comprehensive knowledge of (inverse)\nkinematics. Moreover, it is non-trivial to provide a kinematic independent\ngeneral solution. In this study, we developed a cyclic three-phase optimization\nmethod based on deep reinforcement learning for human-robot motion retargeting.\nThe motion retargeting learning is performed using refined data in a latent\nspace by the cyclic and filtering paths of our method. In addition, the\nhuman-in-the-loop based three-phase approach provides a framework for the\nimprovement of the motion retargeting policy by both quantitative and\nqualitative manners. Using the proposed C-3PO method, we were successfully able\nto learn the motion retargeting skill between the human skeleton and motion of\nthe multiple robots such as NAO, Pepper, Baxter and C-3PO.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 06:26:53 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 05:17:57 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 14:31:27 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Kim", "Taewoo", ""], ["Lee", "Joo-Haeng", ""]]}, {"id": "1909.11304", "submitter": "Ethan Dyer", "authors": "Ethan Dyer, Guy Gur-Ari", "title": "Asymptotics of Wide Networks from Feynman Diagrams", "comments": "10 pages, 3 figures, 1 Table + Appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the asymptotic behavior of wide networks is of considerable\ninterest. In this work, we present a general method for analyzing this large\nwidth behavior. The method is an adaptation of Feynman diagrams, a standard\ntool for computing multivariate Gaussian integrals. We apply our method to\nstudy training dynamics, improving existing bounds and deriving new results on\nwide network evolution during stochastic gradient descent. Going beyond the\nstrict large width limit, we present closed-form expressions for higher-order\nterms governing wide network training, and test these predictions empirically.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 06:29:20 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Dyer", "Ethan", ""], ["Gur-Ari", "Guy", ""]]}, {"id": "1909.11313", "submitter": "Bo Tranberg", "authors": "Bo Tranberg, Kasper Koops Kratmann, Jason Stege", "title": "Determining offshore wind installation times using machine learning and\n  open data", "comments": "Offshore WindEurope conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The installation process of offshore wind turbines requires the use of\nexpensive jack-up vessels. These vessels regularly report their position via\nthe Automatic Identification System (AIS). This paper introduces a novel\napproach of applying machine learning to AIS data from jack-up vessels. We\napply the new method to 13 offshore wind farms in Danish, German and British\nwaters. For each of the wind farms we identify individual turbine locations,\nindividual installation times, time in transit and time in harbor for the\nrespective vessel. This is done in an automated way exclusively using AIS data\nwith no prior knowledge of turbine locations, thus enabling a detailed\ndescription of the entire installation process.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 07:18:29 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 11:02:01 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Tranberg", "Bo", ""], ["Kratmann", "Kasper Koops", ""], ["Stege", "Jason", ""]]}, {"id": "1909.11334", "submitter": "Xiaoran Xu", "authors": "Xiaoran Xu, Wei Feng, Yunsheng Jiang, Xiaohui Xie, Zhiqing Sun,\n  Zhi-Hong Deng", "title": "Dynamically Pruned Message Passing Networks for Large-Scale Knowledge\n  Graph Reasoning", "comments": "ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Dynamically Pruned Message Passing Networks (DPMPN) for\nlarge-scale knowledge graph reasoning. In contrast to existing models,\nembedding-based or path-based, we learn an input-dependent subgraph to\nexplicitly model reasoning process. Subgraphs are dynamically constructed and\nexpanded by applying graphical attention mechanism conditioned on input\nqueries. In this way, we not only construct graph-structured explanations but\nalso enable message passing designed in Graph Neural Networks (GNNs) to scale\nwith graph sizes. We take the inspiration from the consciousness prior proposed\nby and develop a two-GNN framework to simultaneously encode input-agnostic full\ngraph representation and learn input-dependent local one coordinated by an\nattention module. Experiments demonstrate the reasoning capability of our model\nthat is to provide clear graphical explanations as well as deliver accurate\npredictions, outperforming most state-of-the-art methods in knowledge base\ncompletion tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 08:15:41 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 07:57:11 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 21:39:59 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Xu", "Xiaoran", ""], ["Feng", "Wei", ""], ["Jiang", "Yunsheng", ""], ["Xie", "Xiaohui", ""], ["Sun", "Zhiqing", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "1909.11337", "submitter": "Weiming Zhi", "authors": "Weiming Zhi and Tin Lai and Lionel Ott and Gilad Francis and Fabio\n  Ramos", "title": "OCTNet: Trajectory Generation in New Environments from Past Experiences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to safely operate for extended periods of time in dynamic\nenvironments is a critical capability for autonomous systems. This generally\ninvolves the prediction and understanding of motion patterns of dynamic\nentities, such as vehicles and people, in the surroundings. Many motion\nprediction methods in the literature can learn a function, mapping position and\ntime to potential trajectories taken by people or other dynamic entities.\nHowever, these predictions depend only on previously observed trajectories, and\ndo not explicitly take into consideration the environment. Trends of motion\nobtained in one environment are typically specific to that environment, and are\nnot used to better predict motion in other environments. In this paper, we\naddress the problem of generating likely motion dynamics conditioned on the\nenvironment, represented as an occupancy map. We introduce the Occupancy\nConditional Trajectory Network (OCTNet) framework, capable of generalising the\npreviously observed motion in known environments, to generate trajectories in\nnew environments where no observations of motion has not been observed. OCTNet\nencodes trajectories as a fixed-sized vector of parameters and utilises neural\nnetworks to learn conditional distributions over parameters. We empirically\ndemonstrate our method's ability to generate complex multi-modal trajectory\npatterns in different environments.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 08:27:25 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Zhi", "Weiming", ""], ["Lai", "Tin", ""], ["Ott", "Lionel", ""], ["Francis", "Gilad", ""], ["Ramos", "Fabio", ""]]}, {"id": "1909.11348", "submitter": "Koby Bibas", "authors": "Dotan Kaufman, Koby Bibas, Eran Borenstein, Michael Chertok and Tal\n  Hassner", "title": "Balancing Specialization, Generalization, and Compression for Detection\n  and Tracking", "comments": "Accepted to BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for specializing deep detectors and trackers to\nrestricted settings. Our approach is designed with the following goals in mind:\n(a) Improving accuracy in restricted domains; (b) preventing overfitting to new\ndomains and forgetting of generalized capabilities; (c) aggressive model\ncompression and acceleration. To this end, we propose a novel loss that\nbalances compression and acceleration of a deep learning model vs. loss of\ngeneralization capabilities. We apply our method to the existing tracker and\ndetector models. We report detection results on the VIRAT and CAVIAR data sets.\nThese results show our method to offer unprecedented compression rates along\nwith improved detection. We apply our loss for tracker compression at test\ntime, as it processes each video. Our tests on the OTB2015 benchmark show that\napplying compression during test time actually improves tracking performance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 08:59:06 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Kaufman", "Dotan", ""], ["Bibas", "Koby", ""], ["Borenstein", "Eran", ""], ["Chertok", "Michael", ""], ["Hassner", "Tal", ""]]}, {"id": "1909.11366", "submitter": "Zhe Xu", "authors": "Zhe Xu, Ray C. C. Cheung", "title": "Accurate and Compact Convolutional Neural Networks with Trained\n  Binarization", "comments": "Accepted as an Oral presentation in British Machine Vision Conference\n  (BMVC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although convolutional neural networks (CNNs) are now widely used in various\ncomputer vision applications, its huge resource demanding on parameter storage\nand computation makes the deployment on mobile and embedded devices difficult.\nRecently, binary convolutional neural networks are explored to help alleviate\nthis issue by quantizing both weights and activations with only 1 single bit.\nHowever, there may exist a noticeable accuracy degradation when compared with\nfull-precision models. In this paper, we propose an improved training approach\ntowards compact binary CNNs with higher accuracy. Trainable scaling factors for\nboth weights and activations are introduced to increase the value range. These\nscaling factors will be trained jointly with other parameters via\nbackpropagation. Besides, a specific training algorithm is developed including\ntight approximation for derivative of discontinuous binarization function and\n$L_2$ regularization acting on weight scaling factors. With these improvements,\nthe binary CNN achieves 92.3% accuracy on CIFAR-10 with VGG-Small network. On\nImageNet, our method also obtains 46.1% top-1 accuracy with AlexNet and 54.2%\nwith Resnet-18 surpassing previous works.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 09:29:50 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Xu", "Zhe", ""], ["Cheung", "Ray C. C.", ""]]}, {"id": "1909.11373", "submitter": "Jiachen Li", "authors": "Jiachen Li, Quan Vuong, Shuang Liu, Minghua Liu, Kamil Ciosek, Keith\n  Ross, Henrik Iskov Christensen, Hao Su", "title": "Multi-task Batch Reinforcement Learning with Metric Learning", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the Multi-task Batch Reinforcement Learning problem. Given multiple\ndatasets collected from different tasks, we train a multi-task policy to\nperform well in unseen tasks sampled from the same distribution. The task\nidentities of the unseen tasks are not provided. To perform well, the policy\nmust infer the task identity from collected transitions by modelling its\ndependency on states, actions and rewards. Because the different datasets may\nhave state-action distributions with large divergence, the task inference\nmodule can learn to ignore the rewards and spuriously correlate $\\textit{only}$\nstate-action pairs to the task identity, leading to poor test time performance.\nTo robustify task inference, we propose a novel application of the triplet\nloss. To mine hard negative examples, we relabel the transitions from the\ntraining tasks by approximating their reward functions. When we allow further\ntraining on the unseen tasks, using the trained policy as an initialization\nleads to significantly faster convergence compared to randomly initialized\npolicies (up to $80\\%$ improvement and across 5 different Mujoco task\ndistributions). We name our method $\\textbf{MBML}$\n($\\textbf{M}\\text{ulti-task}$ $\\textbf{B}\\text{atch}$ RL with\n$\\textbf{M}\\text{etric}$ $\\textbf{L}\\text{earning}$).\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 09:49:01 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 20:57:44 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 08:31:42 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 03:58:33 GMT"}, {"version": "v5", "created": "Thu, 1 Oct 2020 20:12:10 GMT"}, {"version": "v6", "created": "Fri, 23 Oct 2020 20:01:46 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Li", "Jiachen", ""], ["Vuong", "Quan", ""], ["Liu", "Shuang", ""], ["Liu", "Minghua", ""], ["Ciosek", "Kamil", ""], ["Ross", "Keith", ""], ["Christensen", "Henrik Iskov", ""], ["Su", "Hao", ""]]}, {"id": "1909.11380", "submitter": "Ketil Malde", "authors": "Ketil Malde and Hyeongji Kim", "title": "Beyond image classification: zooplankton identification with deep vector\n  space embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zooplankton images, like many other real world data types, have intrinsic\nproperties that make the design of effective classification systems difficult.\nFor instance, the number of classes encountered in practical settings is\npotentially very large, and classes can be ambiguous or overlap. In addition,\nthe choice of taxonomy often differs between researchers and between\ninstitutions. Although high accuracy has been achieved in benchmarks using\nstandard classifier architectures, biases caused by an inflexible\nclassification scheme can have profound effects when the output is used in\necosystem assessments and monitoring.\n  Here, we propose using a deep convolutional network to construct a vector\nembedding of zooplankton images. The system maps (embeds) each image into a\nhigh-dimensional Euclidean space so that distances between vectors reflect\nsemantic relationships between images. We show that the embedding can be used\nto derive classifications with comparable accuracy to a specific classifier,\nbut that it simultaneously reveals important structures in the data.\nFurthermore, we apply the embedding to new classes previously unseen by the\nsystem, and evaluate its classification performance in such cases.\n  Traditional neural network classifiers perform well when the classes are\nclearly defined a priori and have sufficiently large labeled data sets\navailable. For practical cases in ecology as well as in many other fields this\nis not the case, and we argue that the vector embedding method presented here\nis a more appropriate approach.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 10:12:05 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Malde", "Ketil", ""], ["Kim", "Hyeongji", ""]]}, {"id": "1909.11386", "submitter": "Diego Antognini", "authors": "Diego Antognini, Claudiu Musat, Boi Faltings", "title": "Multi-Dimensional Explanation of Target Variables from Documents", "comments": "Accepted in AAAI 2021. 18 pages, 14 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated predictions require explanations to be interpretable by humans.\nPast work used attention and rationale mechanisms to find words that predict\nthe target variable of a document. Often though, they result in a tradeoff\nbetween noisy explanations or a drop in accuracy. Furthermore, rationale\nmethods cannot capture the multi-faceted nature of justifications for multiple\ntargets, because of the non-probabilistic nature of the mask. In this paper, we\npropose the Multi-Target Masker (MTM) to address these shortcomings. The\nnovelty lies in the soft multi-dimensional mask that models a relevance\nprobability distribution over the set of target variables to handle\nambiguities. Additionally, two regularizers guide MTM to induce long,\nmeaningful explanations. We evaluate MTM on two datasets and show, using\nstandard metrics and human annotations, that the resulting masks are more\naccurate and coherent than those generated by the state-of-the-art methods.\nMoreover, MTM is the first to also achieve the highest F1 scores for all the\ntarget variables simultaneously.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 10:26:36 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 14:49:03 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 13:52:27 GMT"}, {"version": "v4", "created": "Mon, 21 Dec 2020 08:18:43 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Antognini", "Diego", ""], ["Musat", "Claudiu", ""], ["Faltings", "Boi", ""]]}, {"id": "1909.11396", "submitter": "Kristoffer Wickstr{\\o}m", "authors": "Kristoffer Wickstr{\\o}m, Sigurd L{\\o}kse, Michael Kampffmeyer, Shujian\n  Yu, Jose Principe, Robert Jenssen", "title": "Information Plane Analysis of Deep Neural Networks via Matrix-Based\n  Renyi's Entropy and Tensor Kernels", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing deep neural networks (DNNs) via information plane (IP) theory has\ngained tremendous attention recently as a tool to gain insight into, among\nothers, their generalization ability. However, it is by no means obvious how to\nestimate mutual information (MI) between each hidden layer and the\ninput/desired output, to construct the IP. For instance, hidden layers with\nmany neurons require MI estimators with robustness towards the high\ndimensionality associated with such layers. MI estimators should also be able\nto naturally handle convolutional layers, while at the same time being\ncomputationally tractable to scale to large networks. None of the existing IP\nmethods to date have been able to study truly deep Convolutional Neural\nNetworks (CNNs), such as the e.g.\\ VGG-16. In this paper, we propose an IP\nanalysis using the new matrix--based R\\'enyi's entropy coupled with tensor\nkernels over convolutional layers, leveraging the power of kernel methods to\nrepresent properties of the probability distribution independently of the\ndimensionality of the data. The obtained results shed new light on the previous\nliterature concerning small-scale DNNs, however using a completely new\napproach. Importantly, the new framework enables us to provide the first\ncomprehensive IP analysis of contemporary large-scale DNNs and CNNs,\ninvestigating the different training phases and providing new insights into the\ntraining dynamics of large-scale neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 10:42:39 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wickstr\u00f8m", "Kristoffer", ""], ["L\u00f8kse", "Sigurd", ""], ["Kampffmeyer", "Michael", ""], ["Yu", "Shujian", ""], ["Principe", "Jose", ""], ["Jenssen", "Robert", ""]]}, {"id": "1909.11406", "submitter": "Thiago Andrade", "authors": "Thiago Andrade, Brais Cancela and Jo\\~ao Gama", "title": "Mining Human Mobility Data to Discover Locations and Habits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many aspects of life are associated with places of human mobility patterns\nand nowadays we are facing an increase in the pervasiveness of mobile devices\nthese individuals carry. Positioning technologies that serve these devices such\nas the cellular antenna (GSM networks), global navigation satellite systems\n(GPS), and more recently the WiFi positioning system (WPS) provide large\namounts of spatio-temporal data in a continuous way. Therefore, detecting\nsignificant places and the frequency of movements between them is fundamental\nto understand human behavior. In this paper, we propose a method for\ndiscovering user habits without any a priori or external knowledge by\nintroducing a density-based clustering for spatio-temporal data to identify\nmeaningful places and by applying a Gaussian Mixture Model (GMM) over the set\nof meaningful places to identify the representations of individual habits. To\nevaluate the proposed method we use two real-world datasets. One dataset\ncontains high-density GPS data and the other one contains GSM mobile phone data\nin a coarse representation. The results show that the proposed method is\nsuitable for this task as many unique habits were identified. This can be used\nfor understanding users' behavior and to draw their characterizing profiles\nhaving a panorama of the mobility patterns from the data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 11:03:32 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Andrade", "Thiago", ""], ["Cancela", "Brais", ""], ["Gama", "Jo\u00e3o", ""]]}, {"id": "1909.11426", "submitter": "Abhinav Srivastav", "authors": "Nguyen Kim Thang and Abhinav Srivastav", "title": "Online Non-Monotone DR-submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study fundamental problems of maximizing DR-submodular\ncontinuous functions that have real-world applications in the domain of machine\nlearning, economics, operations research and communication systems. It captures\na subclass of non-convex optimization that provides both theoretical and\npractical guarantees. Here, we focus on minimizing regret for online arriving\nnon-monotone DR-submodular functions over different types of convex sets:\nhypercube, down-closed and general convex sets.\n  First, we present an online algorithm that achieves a $1/e$-approximation\nratio with the regret of $O(T^{2/3})$ for maximizing DR-submodular functions\nover any down-closed convex set. Note that, the approximation ratio of $1/e$\nmatches the best-known guarantee for the offline version of the problem.\nMoreover, when the convex set is the hypercube, we propose a tight\n1/2-approximation algorithm with regret bound of $O(\\sqrt{T})$. Next, we give\nan online algorithm that achieves an approximation guarantee (depending on the\nsearch space) for the problem of maximizing non-monotone continuous\nDR-submodular functions over a \\emph{general} convex set (not necessarily\ndown-closed). To best of our knowledge, no prior algorithm with approximation\nguarantee was known for non-monotone DR-submodular maximization in the online\nsetting. Finally we run experiments to verify the performance of our algorithms\non problems arising in machine learning domain with the real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:06:39 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 18:22:16 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Thang", "Nguyen Kim", ""], ["Srivastav", "Abhinav", ""]]}, {"id": "1909.11436", "submitter": "Marco Tulio Valente", "authors": "Fabio Ferreira, Luciana Lourdes Silva, Marco Tulio Valente", "title": "Software Engineering Meets Deep Learning: A Mapping Study", "comments": "8 pages, 5 figures, 4 tables. Accepted for publication at ACM SAC\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) is being used nowadays in many traditional Software\nEngineering (SE) problems and tasks. However, since the renaissance of DL\ntechniques is still very recent, we lack works that summarize and condense the\nmost recent and relevant research conducted at the intersection of DL and SE.\nTherefore, in this paper, we describe the first results of a mapping study\ncovering 81 papers about DL & SE. Our results confirm that DL is gaining\nmomentum among SE researchers over the years and that the top-3 research\nproblems tackled by the analyzed papers are documentation, defect prediction,\nand testing.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:27:59 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 15:07:41 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 20:57:46 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ferreira", "Fabio", ""], ["Silva", "Luciana Lourdes", ""], ["Valente", "Marco Tulio", ""]]}, {"id": "1909.11446", "submitter": "Jialin Liu", "authors": "Jialin Liu and Fei Chao and Longzhi Yang and Chih-Min Lin and Qiang\n  Shen", "title": "Decoder Choice Network for Meta-Learning", "comments": "13papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning has been widely used for implementing few-shot learning and\nfast model adaptation. One kind of meta-learning methods attempt to learn how\nto control the gradient descent process in order to make the gradient-based\nlearning have high speed and generalization. This work proposes a method that\ncontrols the gradient descent process of the model parameters of a neural\nnetwork by limiting the model parameters in a low-dimensional latent space. The\nmain challenge of this idea is that a decoder with too many parameters is\nrequired. This work designs a decoder with typical structure and shares a part\nof weights in the decoder to reduce the number of the required parameters.\nBesides, this work has introduced ensemble learning to work with the proposed\napproach for improving performance. The results show that the proposed approach\nis witnessed by the superior performance over the Omniglot classification and\nthe miniImageNet classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:43:53 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 14:55:35 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Jialin", ""], ["Chao", "Fei", ""], ["Yang", "Longzhi", ""], ["Lin", "Chih-Min", ""], ["Shen", "Qiang", ""]]}, {"id": "1909.11448", "submitter": "Mireille El Gheche", "authors": "Guillermo Ortiz-Jimenez, Mireille El Gheche, Effrosyni Simou, Hermina\n  Petric Maretic, Pascal Frossard", "title": "Forward-Backward Splitting for Optimal Transport based Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport aims to estimate a transportation plan that minimizes a\ndisplacement cost. This is realized by optimizing the scalar product between\nthe sought plan and the given cost, over the space of doubly stochastic\nmatrices. When the entropy regularization is added to the problem, the\ntransportation plan can be efficiently computed with the Sinkhorn algorithm.\nThanks to this breakthrough, optimal transport has been progressively extended\nto machine learning and statistical inference by introducing additional\napplication-specific terms in the problem formulation. It is however\nchallenging to design efficient optimization algorithms for optimal transport\nbased extensions. To overcome this limitation, we devise a general\nforward-backward splitting algorithm based on Bregman distances for solving a\nwide range of optimization problems involving a differentiable function with\nLipschitz-continuous gradient and a doubly stochastic constraint. We illustrate\nthe efficiency of our approach in the context of continuous domain adaptation.\nExperiments show that the proposed method leads to a significant improvement in\nterms of speed and performance with respect to the state of the art for domain\nadaptation on a continually rotating distribution coming from the standard two\nmoon dataset.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 03:43:35 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 13:07:09 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 16:39:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ortiz-Jimenez", "Guillermo", ""], ["Gheche", "Mireille El", ""], ["Simou", "Effrosyni", ""], ["Maretic", "Hermina Petric", ""], ["Frossard", "Pascal", ""]]}, {"id": "1909.11456", "submitter": "Dongrui Wu", "authors": "Yuqi Cuui and Yifan Xu and Dongrui Wu", "title": "EEG-Based Driver Drowsiness Estimation Using Feature Weighted Episodic\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drowsy driving is pervasive, and also a major cause of traffic accidents.\nEstimating a driver's drowsiness level by monitoring the electroencephalogram\n(EEG) signal and taking preventative actions accordingly may improve driving\nsafety. However, individual differences among different drivers make this task\nvery challenging. A calibration session is usually required to collect some\nsubject-specific data and tune the model parameters before applying it to a new\nsubject, which is very inconvenient and not user-friendly. Many approaches have\nbeen proposed to reduce the calibration effort, but few can completely\neliminate it. This paper proposes a novel approach, feature weighted episodic\ntraining (FWET), to completely eliminate the calibration requirement. It\nintegrates two techniques: feature weighting to learn the importance of\ndifferent features, and episodic training for domain generalization.\nExperiments on EEG-based driver drowsiness estimation demonstrated that both\nfeature weighting and episodic training are effective, and their integration\ncan further improve the generalization performance. FWET does not need any\nlabelled or unlabelled calibration data from the new subject, and hence could\nbe very useful in plug-and-play brain-computer interfaces.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:52:02 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Cuui", "Yuqi", ""], ["Xu", "Yifan", ""], ["Wu", "Dongrui", ""]]}, {"id": "1909.11459", "submitter": "Gregor Simm", "authors": "Gregor N. C. Simm and Jos\\'e Miguel Hern\\'andez-Lobato", "title": "A Generative Model for Molecular Distance Geometry", "comments": null, "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Great computational effort is invested in generating equilibrium states for\nmolecular systems using, for example, Markov chain Monte Carlo. We present a\nprobabilistic model that generates statistically independent samples for\nmolecules from their graph representations. Our model learns a low-dimensional\nmanifold that preserves the geometry of local atomic neighborhoods through a\nprincipled learning representation that is based on Euclidean distance\ngeometry. In a new benchmark for molecular conformation generation, we show\nexperimentally that our generative model achieves state-of-the-art accuracy.\nFinally, we show how to use our model as a proposal distribution in an\nimportance sampling scheme to compute molecular properties.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:56:50 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 09:49:40 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 18:07:06 GMT"}, {"version": "v4", "created": "Thu, 13 Aug 2020 17:06:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Simm", "Gregor N. C.", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1909.11469", "submitter": "Vinu Joseph", "authors": "Mark Van der Merwe, Vinu Joseph, Ganesh Gopalakrishnan", "title": "Message Scheduling for Performant, Many-Core Belief Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CV cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Belief Propagation (BP) is a message-passing algorithm for approximate\ninference over Probabilistic Graphical Models (PGMs), finding many applications\nsuch as computer vision, error-correcting codes, and protein-folding. While\ngeneral, the convergence and speed of the algorithm has limited its practical\nuse on difficult inference problems. As an algorithm that is highly amenable to\nparallelization, many-core Graphical Processing Units (GPUs) could\nsignificantly improve BP performance. Improving BP through many-core systems is\nnon-trivial: the scheduling of messages in the algorithm strongly affects\nperformance. We present a study of message scheduling for BP on GPUs. We\ndemonstrate that BP exhibits a tradeoff between speed and convergence based on\nparallelism and show that existing message schedulings are not able to utilize\nthis tradeoff. To this end, we present a novel randomized message scheduling\napproach, Randomized BP (RnBP), which outperforms existing methods on the GPU.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 05:19:33 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Van der Merwe", "Mark", ""], ["Joseph", "Vinu", ""], ["Gopalakrishnan", "Ganesh", ""]]}, {"id": "1909.11472", "submitter": "Guillaume Godin", "authors": "Ruud van Deursen and Guillaume Godin", "title": "Deep Generative Model for Sparse Graphs using Text-Based Learning with\n  Augmentation in Generative Examination Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graphs and networks are a key research tool for a variety of science fields,\nmost notably chemistry, biology, engineering and social sciences. Modeling and\ngeneration of graphs with efficient sampling is a key challenge for graphs. In\nparticular, the non-uniqueness, high dimensionality of the vertices and local\ndependencies of the edges may render the task challenging. We apply our\nrecently introduced method, Generative Examination Networks (GENs) to create\nthe first text-based generative graph models using one-line text formats as\ngraph representation. In our GEN, a RNN-generative model for a one-line text\nformat learns autonomously to predict the next available character. The\ntraining is stopped by an examination mechanism checking validating the\npercentage of valid graphs generated. We achieved moderate to high validity\nusing dense g6 strings (random 67.8 +/- 0.6, canonical 99.1 +/- 0.2). Based on\nthese results we have adapted the widely used SMILES representation for\nmolecules to a new input format, which we call linear graph input (LGI). Apart\nfrom the benefits of a short compressible text-format, a major advantage\ninclude the possibility to randomize and augment the format. The generative\nmodels are evaluated for overall performance and for reconstruction of the\nproperty space. The results show that LGI strings are very well suited for\nmachine-learning and that augmentation is essential for the performance of the\nmodel in terms of validity, uniqueness and novelty. Lastly, the format can\naddress smaller and larger dataset of graphs and the format can be easily\nadapted to define another meaning of the characters used in the LGI-string and\ncan address sparse graph problems in used in other fields of science.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 14:50:37 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["van Deursen", "Ruud", ""], ["Godin", "Guillaume", ""]]}, {"id": "1909.11480", "submitter": "Joan Serr\\`a", "authors": "Joan Serr\\`a, David \\'Alvarez, Vicen\\c{c} G\\'omez, Olga Slizovskaia,\n  Jos\\'e F. N\\'u\\~nez, Jordi Luque", "title": "Input complexity and out-of-distribution detection with likelihood-based\n  generative models", "comments": "Accepted for ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood-based generative models are a promising resource to detect\nout-of-distribution (OOD) inputs which could compromise the robustness or\nreliability of a machine learning system. However, likelihoods derived from\nsuch models have been shown to be problematic for detecting certain types of\ninputs that significantly differ from training data. In this paper, we pose\nthat this problem is due to the excessive influence that input complexity has\nin generative models' likelihoods. We report a set of experiments supporting\nthis hypothesis, and use an estimate of input complexity to derive an efficient\nand parameter-free OOD score, which can be seen as a likelihood-ratio, akin to\nBayesian model comparison. We find such score to perform comparably to, or even\nbetter than, existing OOD detection approaches under a wide range of data sets,\nmodels, model sizes, and complexity estimates.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 13:27:53 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 10:46:41 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 10:38:05 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Serr\u00e0", "Joan", ""], ["\u00c1lvarez", "David", ""], ["G\u00f3mez", "Vicen\u00e7", ""], ["Slizovskaia", "Olga", ""], ["N\u00fa\u00f1ez", "Jos\u00e9 F.", ""], ["Luque", "Jordi", ""]]}, {"id": "1909.11481", "submitter": "Evgenii Zheltonozhskii", "authors": "Chaim Baskin, Brian Chmiel, Evgenii Zheltonozhskii, Ron Banner, Alex\n  M. Bronstein, Avi Mendelson", "title": "CAT: Compression-Aware Training for bandwidth reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional neural networks (CNNs) have become the dominant neural network\narchitecture for solving visual processing tasks. One of the major obstacles\nhindering the ubiquitous use of CNNs for inference is their relatively high\nmemory bandwidth requirements, which can be a main energy consumer and\nthroughput bottleneck in hardware accelerators. Accordingly, an efficient\nfeature map compression method can result in substantial performance gains.\nInspired by quantization-aware training approaches, we propose a\ncompression-aware training (CAT) method that involves training the model in a\nway that allows better compression of feature maps during inference. Our method\ntrains the model to achieve low-entropy feature maps, which enables efficient\ncompression at inference time using classical transform coding methods. CAT\nsignificantly improves the state-of-the-art results reported for quantization.\nFor example, on ResNet-34 we achieve 73.1% accuracy (0.2% degradation from the\nbaseline) with an average representation of only 1.79 bits per value. Reference\nimplementation accompanies the paper at https://github.com/CAT-teams/CAT\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 13:29:58 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Baskin", "Chaim", ""], ["Chmiel", "Brian", ""], ["Zheltonozhskii", "Evgenii", ""], ["Banner", "Ron", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "1909.11483", "submitter": "Jordan Ott", "authors": "Jordan Ott, Erik Linstead, Nicholas LaHaye, Pierre Baldi", "title": "Learning in the Machine: To Share or Not to Share?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight-sharing is one of the pillars behind Convolutional Neural Networks and\ntheir successes. However, in physical neural systems such as the brain,\nweight-sharing is implausible. This discrepancy raises the fundamental question\nof whether weight-sharing is necessary. If so, to which degree of precision? If\nnot, what are the alternatives? The goal of this study is to investigate these\nquestions, primarily through simulations where the weight-sharing assumption is\nrelaxed. Taking inspiration from neural circuitry, we explore the use of Free\nConvolutional Networks and neurons with variable connection patterns. Using\nFree Convolutional Networks, we show that while weight-sharing is a pragmatic\noptimization approach, it is not a necessity in computer vision applications.\nFurthermore, Free Convolutional Networks match the performance observed in\nstandard architectures when trained using properly translated data (akin to\nvideo). Under the assumption of translationally augmented data, Free\nConvolutional Networks learn translationally invariant representations that\nyield an approximate form of weight sharing.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 20:10:50 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 19:58:04 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ott", "Jordan", ""], ["Linstead", "Erik", ""], ["LaHaye", "Nicholas", ""], ["Baldi", "Pierre", ""]]}, {"id": "1909.11500", "submitter": "Sebastian Goldt", "authors": "Sebastian Goldt, Marc M\\'ezard, Florent Krzakala, Lenka Zdeborov\\'a", "title": "Modelling the influence of data structure on learning in neural\n  networks: the hidden manifold model", "comments": null, "journal-ref": "Physical Review X, Vol. 10, No. 4 (2020)", "doi": "10.1103/PhysRevX.10.041044", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the reasons for the success of deep neural networks trained\nusing stochastic gradient-based methods is a key open problem for the nascent\ntheory of deep learning. The types of data where these networks are most\nsuccessful, such as images or sequences of speech, are characterised by\nintricate correlations. Yet, most theoretical work on neural networks does not\nexplicitly model training data, or assumes that elements of each data sample\nare drawn independently from some factorised probability distribution. These\napproaches are thus by construction blind to the correlation structure of\nreal-world data sets and their impact on learning in neural networks. Here, we\nintroduce a generative model for structured data sets that we call the hidden\nmanifold model (HMM). The idea is to construct high-dimensional inputs that lie\non a lower-dimensional manifold, with labels that depend only on their position\nwithin this manifold, akin to a single layer decoder or generator in a\ngenerative adversarial network. We demonstrate that learning of the hidden\nmanifold model is amenable to an analytical treatment by proving a \"Gaussian\nEquivalence Property\" (GEP), and we use the GEP to show how the dynamics of\ntwo-layer neural networks trained using one-pass stochastic gradient descent is\ncaptured by a set of integro-differential equations that track the performance\nof the network at all times. This permits us to analyse in detail how a neural\nnetwork learns functions of increasing complexity during training, how its\nperformance depends on its size and how it is impacted by parameters such as\nthe learning rate or the dimension of the hidden manifold.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 13:56:56 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 15:57:34 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 14:15:45 GMT"}, {"version": "v4", "created": "Thu, 3 Dec 2020 16:48:43 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Goldt", "Sebastian", ""], ["M\u00e9zard", "Marc", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1909.11501", "submitter": "Matthew Willetts", "authors": "Matthew Willetts, Stephen Roberts, Chris Holmes", "title": "Disentangling to Cluster: Gaussian Mixture Variational Ladder\n  Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In clustering we normally output one cluster variable for each datapoint.\nHowever it is not necessarily the case that there is only one way to partition\na given dataset into cluster components. For example, one could cluster objects\nby their colour, or by their type. Different attributes form a hierarchy, and\nwe could wish to cluster in any of them. By disentangling the learnt latent\nrepresentations of some dataset into different layers for different attributes\nwe can then cluster in those latent spaces. We call this \"disentangled\nclustering\". Extending Variational Ladder Autoencoders (Zhao et al., 2017), we\npropose a clustering algorithm, VLAC, that outperforms a Gaussian Mixture DGM\nin cluster accuracy over digit identity on the test set of SVHN. We also\ndemonstrate learning clusters jointly over numerous layers of the hierarchy of\nlatent variables for the data, and show component-wise generation from this\nhierarchical model.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:05:02 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 17:37:25 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Willetts", "Matthew", ""], ["Roberts", "Stephen", ""], ["Holmes", "Chris", ""]]}, {"id": "1909.11507", "submitter": "Matthew Willetts", "authors": "Matthew Willetts, Alexander Camuto, Stephen Roberts, Chris Holmes", "title": "Regularising Deep Networks with Deep Generative Models", "comments": "8 pages plus appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new method for regularising neural networks. We learn a\nprobability distribution over the activations of all layers of the model and\nthen insert imputed values into the network during training. We obtain a\nposterior for an arbitrary subset of activations conditioned on the remainder.\nThis is a generalisation of data augmentation to the hidden layers of a\nnetwork, and a form of data-aware dropout. We demonstrate that our training\nmethod leads to higher test accuracy and lower test-set cross-entropy for\nneural networks trained on CIFAR-10 and SVHN compared to standard\nregularisation baselines: our approach leads to networks with better calibrated\nuncertainty over the class posteriors all the while delivering greater test-set\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:14:04 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 17:05:10 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Willetts", "Matthew", ""], ["Camuto", "Alexander", ""], ["Roberts", "Stephen", ""], ["Holmes", "Chris", ""]]}, {"id": "1909.11508", "submitter": "Neelanjan Bhowmik", "authors": "Neelanjan Bhowmik, Qian Wang, Yona Falinie A. Gaus, Marcin Szarek,\n  Toby P. Breckon", "title": "The Good, the Bad and the Ugly: Evaluating Convolutional Neural Networks\n  for Prohibited Item Detection Using Real and Synthetically Composited X-ray\n  Imagery", "comments": null, "journal-ref": "In Proc. British Machine Vision Conference Workshops, BMVA, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting prohibited items in X-ray security imagery is pivotal in\nmaintaining border and transport security against a wide range of threat\nprofiles. Convolutional Neural Networks (CNN) with the support of a significant\nvolume of data have brought advancement in such automated prohibited object\ndetection and classification. However, collating such large volumes of X-ray\nsecurity imagery remains a significant challenge. This work opens up the\npossibility of using synthetically composed imagery, avoiding the need to\ncollate such large volumes of hand-annotated real-world imagery. Here we\ninvestigate the difference in detection performance achieved using real and\nsynthetic X-ray training imagery for CNN architecture detecting three exemplar\nprohibited items, {Firearm, Firearm Parts, Knives}, within cluttered and\ncomplex X-ray security baggage imagery. We achieve 0.88 of mean average\nprecision (mAP) with a Faster R-CNN and ResNet-101 CNN architecture for this\n3-class object detection using real X-ray imagery. While the performance is\ncomparable with synthetically composited X-ray imagery (0.78 mAP), our extended\nevaluation demonstrates both challenge and promise of using synthetically\ncomposed images to diversify the X-ray security training imagery for automated\ndetection algorithm training.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:16:16 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Bhowmik", "Neelanjan", ""], ["Wang", "Qian", ""], ["Gaus", "Yona Falinie A.", ""], ["Szarek", "Marcin", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1909.11512", "submitter": "Sergey Nikolenko", "authors": "Sergey I. Nikolenko", "title": "Synthetic Data for Deep Learning", "comments": "156 pages, 24 figures, 719 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic data is an increasingly popular tool for training deep learning\nmodels, especially in computer vision but also in other areas. In this work, we\nattempt to provide a comprehensive survey of the various directions in the\ndevelopment and application of synthetic data. First, we discuss synthetic\ndatasets for basic computer vision problems, both low-level (e.g., optical flow\nestimation) and high-level (e.g., semantic segmentation), synthetic\nenvironments and datasets for outdoor and urban scenes (autonomous driving),\nindoor scenes (indoor navigation), aerial navigation, simulation environments\nfor robotics, applications of synthetic data outside computer vision (in neural\nprogramming, bioinformatics, NLP, and more); we also survey the work on\nimproving synthetic data development and alternative ways to produce it such as\nGANs. Second, we discuss in detail the synthetic-to-real domain adaptation\nproblem that inevitably arises in applications of synthetic data, including\nsynthetic-to-real refinement with GAN-based models and domain adaptation at the\nfeature/model level without explicit data transformations. Third, we turn to\nprivacy-related applications of synthetic data and review the work on\ngenerating synthetic datasets with differential privacy guarantees. We conclude\nby highlighting the most promising directions for further work in synthetic\ndata studies.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:20:57 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Nikolenko", "Sergey I.", ""]]}, {"id": "1909.11515", "submitter": "Tianyu Pang", "authors": "Tianyu Pang, Kun Xu, Jun Zhu", "title": "Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been widely recognized that adversarial examples can be easily crafted\nto fool deep networks, which mainly root from the locally non-linear behavior\nnearby input examples. Applying mixup in training provides an effective\nmechanism to improve generalization performance and model robustness against\nadversarial perturbations, which introduces the globally linear behavior\nin-between training examples. However, in previous work, the mixup-trained\nmodels only passively defend adversarial attacks in inference by directly\nclassifying the inputs, where the induced global linearity is not well\nexploited. Namely, since the locality of the adversarial perturbations, it\nwould be more efficient to actively break the locality via the globality of the\nmodel predictions. Inspired by simple geometric intuition, we develop an\ninference principle, named mixup inference (MI), for mixup-trained models. MI\nmixups the input with other random clean samples, which can shrink and transfer\nthe equivalent perturbation if the input is adversarial. Our experiments on\nCIFAR-10 and CIFAR-100 demonstrate that MI can further improve the adversarial\nrobustness for the models trained by mixup and its variants.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:21:55 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 08:54:57 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Pang", "Tianyu", ""], ["Xu", "Kun", ""], ["Zhu", "Jun", ""]]}, {"id": "1909.11522", "submitter": "Guillermo Valle-P\\'erez", "authors": "Chris Mingard, Joar Skalse, Guillermo Valle-P\\'erez, David\n  Mart\\'inez-Rubio, Vladimir Mikulik, Ard A. Louis", "title": "Neural networks are a priori biased towards Boolean functions with low\n  entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the inductive bias of neural networks is critical to explaining\ntheir ability to generalise. Here, for one of the simplest neural networks -- a\nsingle-layer perceptron with n input neurons, one output neuron, and no\nthreshold bias term -- we prove that upon random initialisation of weights, the\na priori probability P(t) that it represents a Boolean function that classifies\nt points in {0,1}^n as 1 has a remarkably simple form: P(t) = 2^{-n} for 0\\leq\nt < 2^n.\n  Since a perceptron can express far fewer Boolean functions with small or\nlarge values of t (low entropy) than with intermediate values of t (high\nentropy) there is, on average, a strong intrinsic a-priori bias towards\nindividual functions with low entropy. Furthermore, within a class of functions\nwith fixed t, we often observe a further intrinsic bias towards functions of\nlower complexity. Finally, we prove that, regardless of the distribution of\ninputs, the bias towards low entropy becomes monotonically stronger upon adding\nReLU layers, and empirically show that increasing the variance of the bias term\nhas a similar effect.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:29:45 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 15:57:00 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 21:47:42 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Mingard", "Chris", ""], ["Skalse", "Joar", ""], ["Valle-P\u00e9rez", "Guillermo", ""], ["Mart\u00ednez-Rubio", "David", ""], ["Mikulik", "Vladimir", ""], ["Louis", "Ard A.", ""]]}, {"id": "1909.11527", "submitter": "Li Wang", "authors": "Leihong Zhang, Li Wang, Zhaojun Bai and Ren-cang Li", "title": "A Self-consistent-field Iteration for Orthogonal Canonical Correlation\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient algorithm for solving orthogonal canonical\ncorrelation analysis (OCCA) in the form of trace-fractional structure and\northogonal linear projections. Even though orthogonality has been widely used\nand proved to be a useful criterion for pattern recognition and feature\nextraction, existing methods for solving OCCA problem are either numerical\nunstable by relying on a deflation scheme, or less efficient by directly using\ngeneric optimization methods. In this paper, we propose an alternating\nnumerical scheme whose core is the sub-maximization problem in the\ntrace-fractional form with an orthogonal constraint. A customized\nself-consistent-field (SCF) iteration for this sub-maximization problem is\ndevised. It is proved that the SCF iteration is globally convergent to a KKT\npoint and that the alternating numerical scheme always converges. We further\nformulate a new trace-fractional maximization problem for orthogonal multiset\nCCA (OMCCA) and then propose an efficient algorithm with an either Jacobi-style\nor Gauss-Seidel-style updating scheme based on the same SCF iteration.\nExtensive experiments are conducted to evaluate the proposed algorithms against\nexisting methods including two real world applications: multi-label\nclassification and multi-view feature extraction. Experimental results show\nthat our methods not only perform competitively to or better than baselines but\nalso are more efficient.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:34:31 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Zhang", "Leihong", ""], ["Wang", "Li", ""], ["Bai", "Zhaojun", ""], ["Li", "Ren-cang", ""]]}, {"id": "1909.11532", "submitter": "Yangang Chen", "authors": "Yangang Chen, Justin W. L. Wan", "title": "Deep Neural Network Framework Based on Backward Stochastic Differential\n  Equations for Pricing and Hedging American Options in High Dimensions", "comments": "35 pages, 11 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep neural network framework for computing prices and deltas of\nAmerican options in high dimensions. The architecture of the framework is a\nsequence of neural networks, where each network learns the difference of the\nprice functions between adjacent timesteps. We introduce the least squares\nresidual of the associated backward stochastic differential equation as the\nloss function. Our proposed framework yields prices and deltas on the entire\nspacetime, not only at a given point. The computational cost of the proposed\napproach is quadratic in dimension, which addresses the curse of dimensionality\nissue that state-of-the-art approaches suffer. Our numerical simulations\ndemonstrate these contributions, and show that the proposed neural network\nframework outperforms state-of-the-art approaches in high dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:50:24 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Chen", "Yangang", ""], ["Wan", "Justin W. L.", ""]]}, {"id": "1909.11538", "submitter": "Majid Moghadam", "authors": "Ali Alizadeh, Majid Moghadam, Yunus Bicer, Nazim Kemal Ure, Ugur\n  Yavas, Can Kurtulus", "title": "Automated Lane Change Decision Making using Deep Reinforcement Learning\n  in Dynamic and Uncertain Highway Environment", "comments": "Accepted to IEEE Intelligent Transportation Systems Conference - ITSC\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous lane changing is a critical feature for advanced autonomous\ndriving systems, that involves several challenges such as uncertainty in other\ndriver's behaviors and the trade-off between safety and agility. In this work,\nwe develop a novel simulation environment that emulates these challenges and\ntrain a deep reinforcement learning agent that yields consistent performance in\na variety of dynamic and uncertain traffic scenarios. Results show that the\nproposed data-driven approach performs significantly better in noisy\nenvironments compared to methods that rely solely on heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 02:27:07 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Alizadeh", "Ali", ""], ["Moghadam", "Majid", ""], ["Bicer", "Yunus", ""], ["Ure", "Nazim Kemal", ""], ["Yavas", "Ugur", ""], ["Kurtulus", "Can", ""]]}, {"id": "1909.11542", "submitter": "Gabriel Ryan", "authors": "Gabriel Ryan, Justin Wong, Jianan Yao, Ronghui Gu, Suman Jana", "title": "CLN2INV: Learning Loop Invariants with Continuous Logic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program verification offers a framework for ensuring program correctness and\ntherefore systematically eliminating different classes of bugs. Inferring loop\ninvariants is one of the main challenges behind automated verification of\nreal-world programs which often contain many loops. In this paper, we present\nContinuous Logic Network (CLN), a novel neural architecture for automatically\nlearning loop invariants directly from program execution traces. Unlike\nexisting neural networks, CLNs can learn precise and explicit representations\nof formulas in Satisfiability Modulo Theories (SMT) for loop invariants from\nprogram execution traces. We develop a new sound and complete semantic mapping\nfor assigning SMT formulas to continuous truth values that allows CLNs to be\ntrained efficiently. We use CLNs to implement a new inference system for loop\ninvariants, CLN2INV, that significantly outperforms existing approaches on the\npopular Code2Inv dataset. CLN2INV is the first tool to solve all 124\ntheoretically solvable problems in the Code2Inv dataset. Moreover, CLN2INV\ntakes only 1.1 seconds on average for each problem, which is 40 times faster\nthan existing approaches. We further demonstrate that CLN2INV can even learn 12\nsignificantly more complex loop invariants than the ones required for the\nCode2Inv dataset.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:05:02 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 15:54:09 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 16:07:49 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Ryan", "Gabriel", ""], ["Wong", "Justin", ""], ["Yao", "Jianan", ""], ["Gu", "Ronghui", ""], ["Jana", "Suman", ""]]}, {"id": "1909.11544", "submitter": "Aleksandr Koriagin", "authors": "Alexander Koryagin, Roman Khudorozkov, Sergey Tsimfer", "title": "PyDEns: a Python Framework for Solving Differential Equations with\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a lot of papers proposed to use neural networks to approximately\nsolve partial differential equations (PDEs). Yet, there has been a lack of\nflexible framework for convenient experimentation. In an attempt to fill the\ngap, we introduce a PyDEns-module open-sourced on GitHub. Coupled with\ncapabilities of BatchFlow, open-source framework for convenient and\nreproducible deep learning, PyDEns-module allows to 1) solve partial\ndifferential equations from a large family, including heat equation and wave\nequation 2) easily search for the best neural-network architecture among the\nzoo, that includes ResNet and DenseNet 3) fully control the process of\nmodel-training by testing different point-sampling schemes. With that in mind,\nour main contribution goes as follows: implementation of a ready-to-use and\nopen-source numerical solver of PDEs of a novel format, based on neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:06:26 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Koryagin", "Alexander", ""], ["Khudorozkov", "Roman", ""], ["Tsimfer", "Sergey", ""]]}, {"id": "1909.11553", "submitter": "Alix Lh\\'eritier", "authors": "Alix Lh\\'eritier", "title": "PCMC-Net: Feature-based Pairwise Choice Markov Chains", "comments": "Final version to be published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise Choice Markov Chains (PCMC) have been recently introduced to\novercome limitations of choice models based on traditional axioms unable to\nexpress empirical observations from modern behavior economics like context\neffects occurring when a choice between two options is altered by adding a\nthird alternative. The inference approach that estimates the transition rates\nbetween each possible pair of alternatives via maximum likelihood suffers when\nthe examples of each alternative are scarce and is inappropriate when new\nalternatives can be observed at test time. In this work, we propose an\namortized inference approach for PCMC by embedding its definition into a neural\nnetwork that represents transition rates as a function of the alternatives' and\nindividual's features. We apply our construction to the complex case of airline\nitinerary booking where singletons are common (due to varying prices and\nindividual-specific itineraries), and context effects and behaviors strongly\ndependent on market segments are observed. Experiments show our network\nsignificantly outperforming, in terms of prediction accuracy and logarithmic\nloss, feature engineered standard and latent class Multinomial Logit models as\nwell as recent machine learning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:30:38 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 14:48:18 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lh\u00e9ritier", "Alix", ""]]}, {"id": "1909.11555", "submitter": "Amrit Singh Bedi", "authors": "Alec Koppel, Amrit Singh Bedi, Ketan Rajawat, and Brian M. Sadler", "title": "Optimally Compressed Nonparametric Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch training of machine learning models based on neural networks is now\nwell established, whereas to date streaming methods are largely based on linear\nmodels. To go beyond linear in the online setting, nonparametric methods are of\ninterest due to their universality and ability to stably incorporate new\ninformation via convexity or Bayes' Rule. Unfortunately, when used online,\nnonparametric methods suffer a \"curse of dimensionality\" which precludes their\nuse: their complexity scales at least with the time index. We survey online\ncompression tools which bring their memory under control and attain approximate\nconvergence. The asymptotic bias depends on a compression parameter that trades\noff memory and accuracy. Further, the applications to robotics, communications,\neconomics, and power are discussed, as well as extensions to multi-agent\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:34:34 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 04:30:45 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Koppel", "Alec", ""], ["Bedi", "Amrit Singh", ""], ["Rajawat", "Ketan", ""], ["Sadler", "Brian M.", ""]]}, {"id": "1909.11556", "submitter": "Angela Fan", "authors": "Angela Fan, Edouard Grave, Armand Joulin", "title": "Reducing Transformer Depth on Demand with Structured Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterized transformer networks have obtained state of the art results\nin various natural language processing tasks, such as machine translation,\nlanguage modeling, and question answering. These models contain hundreds of\nmillions of parameters, necessitating a large amount of computation and making\nthem prone to overfitting. In this work, we explore LayerDrop, a form of\nstructured dropout, which has a regularization effect during training and\nallows for efficient pruning at inference time. In particular, we show that it\nis possible to select sub-networks of any depth from one large network without\nhaving to finetune them and with limited impact on performance. We demonstrate\nthe effectiveness of our approach by improving the state of the art on machine\ntranslation, language modeling, summarization, question answering, and language\nunderstanding benchmarks. Moreover, we show that our approach leads to small\nBERT-like models of higher quality compared to training from scratch or using\ndistillation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:35:03 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Fan", "Angela", ""], ["Grave", "Edouard", ""], ["Joulin", "Armand", ""]]}, {"id": "1909.11564", "submitter": "Giacomo Aletti", "authors": "Giacomo Aletti", "title": "Analytical confidence intervals for the number of different objects in\n  data streams", "comments": "accepted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.CO stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper develops a new mathematical-statistical approach to analyze a\nclass of Flajolet-Martin algorithms (FMa), and provides analytical confidence\nintervals for the number F0 of distinct elements in a stream, based on Chernoff\nbounds. The class of FMa has reached a significant popularity in bigdata stream\nlearning, and the attention of the literature has mainly been based on\nalgorithmic aspects, basically complexity optimality, while the statistical\nanalysis of these class of algorithms has been often faced heuristically. The\nanalysis provided here shows deep connections with mathematical special\nfunctions and with extreme value theory. The latter connection may help in\nexplaining heuristic considerations, while the first opens many numerical\nissues, faced at the end of the present paper. Finally, the algorithms are\ntested on an anonymized real data stream and MonteCarlo simulations are\nprovided to support our analytical choice in this context.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 15:46:11 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 10:37:18 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 16:50:17 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Aletti", "Giacomo", ""]]}, {"id": "1909.11572", "submitter": "Dar Gilboa", "authors": "Dar Gilboa and Guy Gur-Ari", "title": "Wider Networks Learn Better Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferability of learned features between tasks can massively reduce the\ncost of training a neural network on a novel task. We investigate the effect of\nnetwork width on learned features using activation atlases --- a visualization\ntechnique that captures features the entire hidden state responds to, as\nopposed to individual neurons alone. We find that, while individual neurons do\nnot learn interpretable features in wide networks, groups of neurons do. In\naddition, the hidden state of a wide network contains more information about\nthe inputs than that of a narrow network trained to the same test accuracy.\nInspired by this observation, we show that when fine-tuning the last layer of a\nnetwork on a new task, performance improves significantly as the width of the\nnetwork is increased, even though test accuracy on the original task is\nindependent of width.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:00:27 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Gilboa", "Dar", ""], ["Gur-Ari", "Guy", ""]]}, {"id": "1909.11573", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Quoc Viet Hung Nguyen, Cuong M. Nguyen, Dung Nguyen,\n  Duc Thanh Nguyen and Saeid Nahavandi", "title": "Deep Learning for Deepfakes Creation and Detection: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning has been successfully applied to solve various complex problems\nranging from big data analytics to computer vision and human-level control.\nDeep learning advances however have also been employed to create software that\ncan cause threats to privacy, democracy and national security. One of those\ndeep learning-powered applications recently emerged is deepfake. Deepfake\nalgorithms can create fake images and videos that humans cannot distinguish\nthem from authentic ones. The proposal of technologies that can automatically\ndetect and assess the integrity of digital visual media is therefore\nindispensable. This paper presents a survey of algorithms used to create\ndeepfakes and, more importantly, methods proposed to detect deepfakes in the\nliterature to date. We present extensive discussions on challenges, research\ntrends and directions related to deepfake technologies. By reviewing the\nbackground of deepfakes and state-of-the-art deepfake detection methods, this\nstudy provides a comprehensive overview of deepfake techniques and facilitates\nthe development of new and more robust methods to deal with the increasingly\nchallenging deepfakes.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:03:45 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 17:54:11 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 05:23:48 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Nguyen", "Quoc Viet Hung", ""], ["Nguyen", "Cuong M.", ""], ["Nguyen", "Dung", ""], ["Nguyen", "Duc Thanh", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "1909.11580", "submitter": "Yuguang Wang", "authors": "Yu Guang Wang, Ming Li, Zheng Ma, Guido Montufar, Xiaosheng Zhuang,\n  Yanan Fan", "title": "Haar Graph Pooling", "comments": "14 pages, 4 figures, 7 tables; Published in ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Graph Neural Networks (GNNs) are useful models for graph classification\nand graph-based regression tasks. In these tasks, graph pooling is a critical\ningredient by which GNNs adapt to input graphs of varying size and structure.\nWe propose a new graph pooling operation based on compressive Haar transforms\n-- HaarPooling. HaarPooling implements a cascade of pooling operations; it is\ncomputed by following a sequence of clusterings of the input graph. A\nHaarPooling layer transforms a given input graph to an output graph with a\nsmaller node number and the same feature dimension; the compressive Haar\ntransform filters out fine detail information in the Haar wavelet domain. In\nthis way, all the HaarPooling layers together synthesize the features of any\ngiven input graph into a feature vector of uniform size. Such transforms\nprovide a sparse characterization of the data and preserve the structure\ninformation of the input graph. GNNs implemented with standard graph\nconvolution layers and HaarPooling layers achieve state of the art performance\non diverse graph classification and regression problems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:13:54 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 10:49:45 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 15:10:45 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Wang", "Yu Guang", ""], ["Li", "Ming", ""], ["Ma", "Zheng", ""], ["Montufar", "Guido", ""], ["Zhuang", "Xiaosheng", ""], ["Fan", "Yanan", ""]]}, {"id": "1909.11583", "submitter": "Simon Schmitt", "authors": "Simon Schmitt, Matteo Hessel, Karen Simonyan", "title": "Off-Policy Actor-Critic with Shared Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the combination of actor-critic reinforcement learning\nalgorithms with uniform large-scale experience replay and propose solutions for\ntwo challenges: (a) efficient actor-critic learning with experience replay (b)\nstability of off-policy learning where agents learn from other agents\nbehaviour. We employ those insights to accelerate hyper-parameter sweeps in\nwhich all participating agents run concurrently and share their experience via\na common replay module. To this end we analyze the bias-variance tradeoffs in\nV-trace, a form of importance sampling for actor-critic methods. Based on our\nanalysis, we then argue for mixing experience sampled from replay with\non-policy experience, and propose a new trust region scheme that scales\neffectively to data distributions where V-trace becomes unstable. We provide\nextensive empirical validation of the proposed solution. We further show the\nbenefits of this setup by demonstrating state-of-the-art data efficiency on\nAtari among agents trained up until 200M environment frames.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:20:46 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 12:51:59 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Schmitt", "Simon", ""], ["Hessel", "Matteo", ""], ["Simonyan", "Karen", ""]]}, {"id": "1909.11588", "submitter": "Zhanfu Yang", "authors": "Ziliang Chen, Zhanfu Yang", "title": "Graph Neural Reasoning May Fail in Certifying Boolean Unsatisfiability", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is feasible and practically-valuable to bridge the characteristics between\ngraph neural networks (GNNs) and logical reasoning. Despite considerable\nefforts and successes witnessed to solve Boolean satisfiability (SAT), it\nremains a mystery of GNN-based solvers for more complex predicate logic\nformulae. In this work, we conjectures with some evidences, that\ngenerally-defined GNNs present several limitations to certify the\nunsatisfiability (UNSAT) in Boolean formulae. It implies that GNNs may probably\nfail in learning the logical reasoning tasks if they contain proving UNSAT as\nthe sub-problem included by most predicate logic formulae.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:24:50 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 16:57:26 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Chen", "Ziliang", ""], ["Yang", "Zhanfu", ""]]}, {"id": "1909.11591", "submitter": "Mohammadhosein Hasanbeig", "authors": "Lim Zun Yuan, Mohammadhosein Hasanbeig, Alessandro Abate, Daniel\n  Kroening", "title": "Modular Deep Reinforcement Learning with Temporal Logic Specifications", "comments": "arXiv admin note: text overlap with arXiv:1902.00778", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an actor-critic, model-free, and online Reinforcement Learning\n(RL) framework for continuous-state continuous-action Markov Decision Processes\n(MDPs) when the reward is highly sparse but encompasses a high-level temporal\nstructure. We represent this temporal structure by a finite-state machine and\nconstruct an on-the-fly synchronised product with the MDP and the finite\nmachine. The temporal structure acts as a guide for the RL agent within the\nproduct, where a modular Deep Deterministic Policy Gradient (DDPG) architecture\nis proposed to generate a low-level control policy. We evaluate our framework\nin a Mars rover experiment and we present the success rate of the synthesised\npolicy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 18:10:00 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 12:57:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yuan", "Lim Zun", ""], ["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""]]}, {"id": "1909.11594", "submitter": "Sandeep Kumar", "authors": "Sandeep Kumar, Jiaxi Ying, Jos'e Vin'icius de M. Cardoso, and Daniel\n  P.Palomar", "title": "Structured Graph Learning Via Laplacian Spectral Constraints", "comments": "12 Pages, Accepted for NIPS 2019. arXiv admin note: substantial text\n  overlap with arXiv:1904.09792", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a graph with a specific structure is essential for interpretability\nand identification of the relationships among data. It is well known that\nstructured graph learning from observed samples is an NP-hard combinatorial\nproblem. In this paper, we first show that for a set of important graph\nfamilies it is possible to convert the structural constraints of structure into\neigenvalue constraints of the graph Laplacian matrix. Then we introduce a\nunified graph learning framework, lying at the integration of the spectral\nproperties of the Laplacian matrix with Gaussian graphical modeling that is\ncapable of learning structures of a large class of graph families. The proposed\nalgorithms are provably convergent and practically amenable for large-scale\nsemi-supervised and unsupervised graph-based learning tasks. Extensive\nnumerical experiments with both synthetic and real data sets demonstrate the\neffectiveness of the proposed methods. An R package containing code for all the\nexperimental results is available at\nhttps://cran.r-project.org/package=spectralGraphTopology.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 11:25:10 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Kumar", "Sandeep", ""], ["Ying", "Jiaxi", ""], ["Cardoso", "Jos'e Vin'icius de M.", ""], ["Palomar", "Daniel P.", ""]]}, {"id": "1909.11598", "submitter": "Chuan-Chi Lai", "authors": "Haoran Peng, Chao Chen, Chuan-Chi Lai, Li-Chun Wang, Zhu Han", "title": "A Predictive On-Demand Placement of UAV Base Stations Using Echo State\n  Network", "comments": "6 pages, 8 figures, accepted by 2019 IEEE/CIC International\n  Conference on Communications in China (ICCC)", "journal-ref": null, "doi": "10.1109/ICCChina.2019.8855868", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unmanned aerial vehicles base stations (UAV-BSs) have great potential in\nbeing widely used in many dynamic application scenarios. In those scenarios,\nthe movements of served user equipments (UEs) are inevitable, so the UAV-BSs\nneeds to be re-positioned dynamically for providing seamless services. In this\npaper, we propose a system framework consisting of UEs clustering, UAV-BS\nplacement, UEs trajectories prediction, and UAV-BS reposition matching scheme,\nto serve the UEs seamlessly as well as minimize the energy cost of UAV-BSs'\nreposition trajectories. An Echo State Network (ESN) based algorithm for\npredicting the future trajectories of UEs and a Kuhn-Munkres-based algorithm\nfor finding the energy-efficient reposition trajectories of UAV-BSs is\ndesigned, respectively. We conduct a simulation using a real open dataset for\nperformance validation. The simulation results indicate that the proposed\nframework achieves high prediction accuracy and provides the energy-efficient\nmatching scheme.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:35:32 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 06:56:20 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Peng", "Haoran", ""], ["Chen", "Chao", ""], ["Lai", "Chuan-Chi", ""], ["Wang", "Li-Chun", ""], ["Han", "Zhu", ""]]}, {"id": "1909.11611", "submitter": "Ivana Bala\\v{z}evi\\'c", "authors": "Carl Allen, Ivana Bala\\v{z}evi\\'c, Timothy Hospedales", "title": "Interpreting Knowledge Graph Relation Representation from Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many models learn representations of knowledge graph data by exploiting its\nlow-rank latent structure, encoding known relations between entities and\nenabling unknown facts to be inferred. To predict whether a relation holds\nbetween entities, embeddings are typically compared in the latent space\nfollowing a relation-specific mapping. Whilst their predictive performance has\nsteadily improved, how such models capture the underlying latent structure of\nsemantic information remains unexplained. Building on recent theoretical\nunderstanding of word embeddings, we categorise knowledge graph relations into\nthree types and for each derive explicit requirements of their representations.\nWe show that empirical properties of relation representations and the relative\nperformance of leading knowledge graph representation methods are justified by\nour analysis.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:49:44 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 10:02:19 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Allen", "Carl", ""], ["Bala\u017eevi\u0107", "Ivana", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1909.11616", "submitter": "Ching-Yuan Bai", "authors": "Ching-Yuan Bai, Buo-Fu Chen, and Hsuan-Tien Lin", "title": "Benchmarking Tropical Cyclone Rapid Intensification with Satellite\n  Images and Attention-based Deep Models", "comments": "In Proceedings of the The European Conference on Machine Learning and\n  Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD),\n  September 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid intensification (RI) of tropical cyclones often causes major\ndestruction to human civilization due to short response time. It is an\nimportant yet challenging task to accurately predict this kind of extreme\nweather event in advance. Traditionally, meteorologists tackle the task with\nhuman-driven feature extraction and predictor correction procedures.\nNevertheless, these procedures do not leverage the power of modern machine\nlearning models and abundant sensor data, such as satellite images. In\naddition, the human-driven nature of such an approach makes it difficult to\nreproduce and benchmark prediction models. In this study, we build a benchmark\nfor RI prediction using only satellite images, which are underutilized in\ntraditional techniques. The benchmark follows conventional data science\npractices, making it easier for data scientists to contribute to RI prediction.\nWe demonstrate the usefulness of the benchmark by designing a domain-inspired\nspatiotemporal deep learning model. The results showcase the promising\nperformance of deep learning in solving complex meteorological problems such as\nRI prediction.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:59:41 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 17:18:25 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Bai", "Ching-Yuan", ""], ["Chen", "Buo-Fu", ""], ["Lin", "Hsuan-Tien", ""]]}, {"id": "1909.11622", "submitter": "K\\'aroly Zsolnai-Feh\\'er", "authors": "K\\'aroly Zsolnai-Feh\\'er, Peter Wonka, Michael Wimmer", "title": "Photorealistic Material Editing Through Direct Image Manipulation", "comments": "The high-resolution paper, supplementary materials, video and source\n  code are available here:\n  https://users.cg.tuwien.ac.at/zsolnai/gfx/photorealistic-material-editing/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Creating photorealistic materials for light transport algorithms requires\ncarefully fine-tuning a set of material properties to achieve a desired\nartistic effect. This is typically a lengthy process that involves a trained\nartist with specialized knowledge. In this work, we present a technique that\naims to empower novice and intermediate-level users to synthesize high-quality\nphotorealistic materials by only requiring basic image processing knowledge. In\nthe proposed workflow, the user starts with an input image and applies a few\nintuitive transforms (e.g., colorization, image inpainting) within a 2D image\neditor of their choice, and in the next step, our technique produces a\nphotorealistic result that approximates this target image. Our method combines\nthe advantages of a neural network-augmented optimizer and an encoder neural\nnetwork to produce high-quality output results within 30 seconds. We also\ndemonstrate that it is resilient against poorly-edited target images and\npropose a simple extension to predict image sequences with a strict time budget\nof 1-2 seconds per image.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 15:17:49 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Zsolnai-Feh\u00e9r", "K\u00e1roly", ""], ["Wonka", "Peter", ""], ["Wimmer", "Michael", ""]]}, {"id": "1909.11625", "submitter": "Ayush Singh", "authors": "Ayush Singh, Seyed Sadegh Mohseni Salehi, Ali Gholipour", "title": "Deep Predictive Motion Tracking in Magnetic Resonance Imaging:\n  Application to Fetal Imaging", "comments": "The article has been published in IEEE TMI: 14 pages, 11 figures, 2\n  tables and 1 supplementary\n  https://github.com/bchimagine/DeepPredictiveMotionTracking", "journal-ref": null, "doi": "10.1109/TMI.2020.2998600", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fetal magnetic resonance imaging (MRI) is challenged by uncontrollable,\nlarge, and irregular fetal movements. It is, therefore, performed through\nvisual monitoring of fetal motion and repeated acquisitions to ensure\ndiagnostic-quality images are acquired. Nevertheless, visual monitoring of\nfetal motion based on displayed slices, and navigation at the level of\nstacks-of-slices is inefficient. The current process is highly\noperator-dependent, increases scanner usage and cost, and significantly\nincreases the length of fetal MRI scans which makes them hard to tolerate for\npregnant women. To help build automatic MRI motion tracking and navigation\nsystems to overcome the limitations of the current process and improve fetal\nimaging, we have developed a new real time image-based motion tracking method\nbased on deep learning that learns to predict fetal motion directly from\nacquired images. Our method is based on a recurrent neural network, composed of\nspatial and temporal encoder-decoders, that infers motion parameters from\nanatomical features extracted from sequences of acquired slices. We compared\nour trained network on held out test sets (including data with different\ncharacteristics, e.g. different fetuses scanned at different ages, and motion\ntrajectories recorded from volunteer subjects) with networks designed for\nestimation as well as methods adopted to make predictions. The results show\nthat our method outperformed alternative techniques, and achieved real-time\nperformance with average errors of 3.5 and 8 degrees for the estimation and\nprediction tasks, respectively. Our real-time deep predictive motion tracking\ntechnique can be used to assess fetal movements, to guide slice acquisitions,\nand to build navigation systems for fetal MRI.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:12:40 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 14:03:27 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 23:15:28 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Singh", "Ayush", ""], ["Salehi", "Seyed Sadegh Mohseni", ""], ["Gholipour", "Ali", ""]]}, {"id": "1909.11628", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Rasul Tutunov, Phu Sakulwongtana, Haitham Bou Ammar", "title": "$\\alpha^{\\alpha}$-Rank: Practically Scaling $\\alpha$-Rank through\n  Stochastic Optimisation", "comments": "AAMAS 2020 Full Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, $\\alpha$-Rank, a graph-based algorithm, has been proposed as a\nsolution to ranking joint policy profiles in large scale multi-agent systems.\n$\\alpha$-Rank claimed tractability through a polynomial time implementation\nwith respect to the total number of pure strategy profiles. Here, we note that\ninputs to the algorithm were not clearly specified in the original\npresentation; as such, we deem complexity claims as not grounded, and\nconjecture solving $\\alpha$-Rank is NP-hard. The authors of $\\alpha$-Rank\nsuggested that the input to $\\alpha$-Rank can be an exponentially-sized payoff\nmatrix; a claim promised to be clarified in subsequent manuscripts. Even though\n$\\alpha$-Rank exhibits a polynomial-time solution with respect to such an\ninput, we further reflect additional critical problems. We demonstrate that due\nto the need of constructing an exponentially large Markov chain, $\\alpha$-Rank\nis infeasible beyond a small finite number of agents. We ground these claims by\nadopting amount of dollars spent as a non-refutable evaluation metric.\nRealising such scalability issue, we present a stochastic implementation of\n$\\alpha$-Rank with a double oracle mechanism allowing for reductions in joint\nstrategy spaces. Our method, $\\alpha^\\alpha$-Rank, does not need to save\nexponentially-large transition matrix, and can terminate early under required\nprecision. Although theoretically our method exhibits similar worst-case\ncomplexity guarantees compared to $\\alpha$-Rank, it allows us, for the first\ntime, to practically conduct large-scale multi-agent evaluations. On $10^4\n\\times 10^4$ random matrices, we achieve $1000x$ speed reduction. Furthermore,\nwe also show successful results on large joint strategy profiles with a maximum\nsize in the order of $\\mathcal{O}(2^{25})$ ($\\approx 33$ million joint\nstrategies) -- a setting not evaluable using $\\alpha$-Rank with reasonable\ncomputational budget.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:21:45 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 15:38:30 GMT"}, {"version": "v3", "created": "Sat, 28 Sep 2019 22:50:53 GMT"}, {"version": "v4", "created": "Sun, 17 Nov 2019 16:41:39 GMT"}, {"version": "v5", "created": "Thu, 21 Nov 2019 15:41:17 GMT"}, {"version": "v6", "created": "Tue, 3 Mar 2020 00:00:34 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Yang", "Yaodong", ""], ["Tutunov", "Rasul", ""], ["Sakulwongtana", "Phu", ""], ["Ammar", "Haitham Bou", ""]]}, {"id": "1909.11630", "submitter": "Thanh Le", "authors": "Thanh Le, Vasant Honavar", "title": "The Dynamical Gaussian Process Latent Variable Model in the Longitudinal\n  Scenario", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dynamical Gaussian Process Latent Variable Models provide an elegant\nnon-parametric framework for learning the low dimensional representations of\nthe high-dimensional time-series. Real world observational studies, however,\nare often ill-conditioned: the observations can be noisy, not assuming the\nluxury of relatively complete and equally spaced like those in time series.\nSuch conditions make it difficult to learn reasonable representations in the\nhigh dimensional longitudinal data set by way of Gaussian Process Latent\nVariable Model as well as other dimensionality reduction procedures. In this\nstudy, we approach the inference of Gaussian Process Dynamical Systems in\nLongitudinal scenario by augmenting the bound in the variational approximation\nto include systematic samples of the unseen observations. We demonstrate the\nusefulness of this approach on synthetic as well as the human motion capture\ndata set.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:24:51 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Le", "Thanh", ""], ["Honavar", "Vasant", ""]]}, {"id": "1909.11637", "submitter": "Haytham Elmousalami", "authors": "Haytham H. Elmousalami", "title": "Comparison of Artificial Intelligence Techniques for Project Conceptual\n  Cost Prediction", "comments": "arXiv admin note: text overlap with arXiv:1905.11804", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing a reliable parametric cost model at the conceptual stage of the\nproject is crucial for projects managers and decision-makers. Existing methods,\nsuch as probabilistic and statistical algorithms have been developed for\nproject cost prediction. However, these methods are unable to produce accurate\nresults for conceptual cost prediction due to small and unstable data samples.\nArtificial intelligence (AI) and machine learning (ML) algorithms include\nnumerous models and algorithms for supervised regression applications.\nTherefore, a comparison analysis for AI models is required to guide\npractitioners to the appropriate model. The study focuses on investigating\ntwenty artificial intelligence (AI) techniques which are conducted for cost\nmodeling such as fuzzy logic (FL) model, artificial neural networks (ANNs),\nmultiple regression analysis (MRA), case-based reasoning (CBR), hybrid models,\nand ensemble methods such as scalable boosting trees (XGBoost). Field canals\nimprovement projects (FCIPs) are used as an actual case study to analyze the\nperformance of the applied ML models. Out of 20 AI techniques, the results\nshowed that the most accurate and suitable method is XGBoost with 9.091% and\n0.929 based on Mean Absolute Percentage Error (MAPE) and adjusted R2. Nonlinear\nadaptability, handling missing values and outliers, model interpretation and\nuncertainty have been discussed for the twenty developed AI models. Keywords:\nArtificial intelligence, Machine learning, ensemble methods, XGBoost,\nevolutionary fuzzy rules generation, Conceptual cost, and parametric cost\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 20:16:30 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Elmousalami", "Haytham H.", ""]]}, {"id": "1909.11639", "submitter": "Vikash Kumar", "authors": "Michael Ahn, Henry Zhu, Kristian Hartikainen, Hugo Ponte, Abhishek\n  Gupta, Sergey Levine, Vikash Kumar", "title": "ROBEL: Robotics Benchmarks for Learning with Low-Cost Robots", "comments": "Published @ CoRL2019. For details visit -\n  http://www.roboticsbenchmarks.org", "journal-ref": "Conference on Robot Learning, 2019", "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ROBEL is an open-source platform of cost-effective robots designed for\nreinforcement learning in the real world. ROBEL introduces two robots, each\naimed to accelerate reinforcement learning research in different task domains:\nD'Claw is a three-fingered hand robot that facilitates learning dexterous\nmanipulation tasks, and D'Kitty is a four-legged robot that facilitates\nlearning agile legged locomotion tasks. These low-cost, modular robots are easy\nto maintain and are robust enough to sustain on-hardware reinforcement learning\nfrom scratch with over 14000 training hours registered on them to date. To\nleverage this platform, we propose an extensible set of continuous control\nbenchmark tasks for each robot. These tasks feature dense and sparse task\nobjectives, and additionally introduce score metrics as hardware-safety. We\nprovide benchmark scores on an initial set of tasks using a variety of\nlearning-based methods. Furthermore, we show that these results can be\nreplicated across copies of the robots located in different institutions. Code,\ndocumentation, design files, detailed assembly instructions, final policies,\nbaseline details, task videos, and all supplementary materials required to\nreproduce the results are available at www.roboticsbenchmarks.org.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:38:52 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 07:16:23 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 01:47:52 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Ahn", "Michael", ""], ["Zhu", "Henry", ""], ["Hartikainen", "Kristian", ""], ["Ponte", "Hugo", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""], ["Kumar", "Vikash", ""]]}, {"id": "1909.11646", "submitter": "Miko{\\l}aj Bi\\'nkowski", "authors": "Miko{\\l}aj Bi\\'nkowski, Jeff Donahue, Sander Dieleman, Aidan Clark,\n  Erich Elsen, Norman Casagrande, Luis C. Cobo, Karen Simonyan", "title": "High Fidelity Speech Synthesis with Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks have seen rapid development in recent years\nand have led to remarkable improvements in generative modelling of images.\nHowever, their application in the audio domain has received limited attention,\nand autoregressive models, such as WaveNet, remain the state of the art in\ngenerative modelling of audio signals such as human speech. To address this\npaucity, we introduce GAN-TTS, a Generative Adversarial Network for\nText-to-Speech. Our architecture is composed of a conditional feed-forward\ngenerator producing raw speech audio, and an ensemble of discriminators which\noperate on random windows of different sizes. The discriminators analyse the\naudio both in terms of general realism, as well as how well the audio\ncorresponds to the utterance that should be pronounced. To measure the\nperformance of GAN-TTS, we employ both subjective human evaluation (MOS - Mean\nOpinion Score), as well as novel quantitative metrics (Fr\\'echet DeepSpeech\nDistance and Kernel DeepSpeech Distance), which we find to be well correlated\nwith MOS. We show that GAN-TTS is capable of generating high-fidelity speech\nwith naturalness comparable to the state-of-the-art models, and unlike\nautoregressive models, it is highly parallelisable thanks to an efficient\nfeed-forward generator. Listen to GAN-TTS reading this abstract at\nhttps://storage.googleapis.com/deepmind-media/research/abstract.wav.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:47:49 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 21:12:19 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Bi\u0144kowski", "Miko\u0142aj", ""], ["Donahue", "Jeff", ""], ["Dieleman", "Sander", ""], ["Clark", "Aidan", ""], ["Elsen", "Erich", ""], ["Casagrande", "Norman", ""], ["Cobo", "Luis C.", ""], ["Simonyan", "Karen", ""]]}, {"id": "1909.11651", "submitter": "Manuel P\\'erez-Carrasco", "authors": "Manuel P\\'erez-Carrasco, Guillermo Cabrera-Vives, Pavlos Protopapas,\n  Nicol\\'as Astorga, Marouan Belhaj", "title": "Matching Embeddings for Domain Adaptation", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this work we address the problem of transferring knowledge obtained from a\nvast annotated source domain to a low labeled target domain. We propose\nAdversarial Variational Domain Adaptation (AVDA), a semi-supervised domain\nadaptation method based on deep variational embedded representations. We use\napproximate inference and domain adversarial methods to map samples from source\nand target domains into an aligned class-dependent embedding defined as a\nGaussian Mixture Model. AVDA works as a classifier and considers a generative\nmodel that helps this classification. We used digits dataset for\nexperimentation. Our results show that on a semi-supervised few-shot scenario\nour model outperforms previous methods in most of the adaptation tasks, even\nusing a fewer number of labeled samples per class on target domain.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:54:47 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 02:00:18 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 13:39:14 GMT"}, {"version": "v4", "created": "Sun, 24 Jan 2021 06:36:35 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["P\u00e9rez-Carrasco", "Manuel", ""], ["Cabrera-Vives", "Guillermo", ""], ["Protopapas", "Pavlos", ""], ["Astorga", "Nicol\u00e1s", ""], ["Belhaj", "Marouan", ""]]}, {"id": "1909.11652", "submitter": "Anusha Nagabandi", "authors": "Anusha Nagabandi, Kurt Konoglie, Sergey Levine, Vikash Kumar", "title": "Deep Dynamics Models for Learning Dexterous Manipulation", "comments": "project website https://sites.google.com/view/pddm/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dexterous multi-fingered hands can provide robots with the ability to\nflexibly perform a wide range of manipulation skills. However, many of the more\ncomplex behaviors are also notoriously difficult to control: Performing in-hand\nobject manipulation, executing finger gaits to move objects, and exhibiting\nprecise fine motor skills such as writing, all require finely balancing contact\nforces, breaking and reestablishing contacts repeatedly, and maintaining\ncontrol of unactuated objects. Learning-based techniques provide the appealing\npossibility of acquiring these skills directly from data, but current learning\napproaches either require large amounts of data and produce task-specific\npolicies, or they have not yet been shown to scale up to more complex and\nrealistic tasks requiring fine motor skills. In this work, we demonstrate that\nour method of online planning with deep dynamics models (PDDM) addresses both\nof these limitations; we show that improvements in learned dynamics models,\ntogether with improvements in online model-predictive control, can indeed\nenable efficient and effective learning of flexible contact-rich dexterous\nmanipulation skills -- and that too, on a 24-DoF anthropomorphic hand in the\nreal world, using just 4 hours of purely real-world data to learn to\nsimultaneously coordinate multiple free-floating objects. Videos can be found\nat https://sites.google.com/view/pddm/\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:55:37 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Nagabandi", "Anusha", ""], ["Konoglie", "Kurt", ""], ["Levine", "Sergey", ""], ["Kumar", "Vikash", ""]]}, {"id": "1909.11655", "submitter": "AkshatKumar Nigam Mr", "authors": "AkshatKumar Nigam, Pascal Friederich, Mario Krenn, Al\\'an Aspuru-Guzik", "title": "Augmenting Genetic Algorithms with Deep Neural Networks for Exploring\n  the Chemical Space", "comments": "9+3 Pages, 7+4 figures, 2 tables. Comments are welcome! (code is\n  available at: https://github.com/aspuru-guzik-group/GA)", "journal-ref": "International Conference on Learning Representations (ICLR-2020)", "doi": null, "report-no": null, "categories": "cs.NE cs.LG physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenges in natural sciences can often be phrased as optimization problems.\nMachine learning techniques have recently been applied to solve such problems.\nOne example in chemistry is the design of tailor-made organic materials and\nmolecules, which requires efficient methods to explore the chemical space. We\npresent a genetic algorithm (GA) that is enhanced with a neural network (DNN)\nbased discriminator model to improve the diversity of generated molecules and\nat the same time steer the GA. We show that our algorithm outperforms other\ngenerative models in optimization tasks. We furthermore present a way to\nincrease interpretability of genetic algorithms, which helped us to derive\ndesign principles.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:59:17 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 23:41:14 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 22:13:45 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 23:23:23 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Nigam", "AkshatKumar", ""], ["Friederich", "Pascal", ""], ["Krenn", "Mario", ""], ["Aspuru-Guzik", "Al\u00e1n", ""]]}, {"id": "1909.11663", "submitter": "Tristan Bepler", "authors": "Tristan Bepler, Ellen D. Zhong, Kotaro Kelley, Edward Brignole, and\n  Bonnie Berger", "title": "Explicitly disentangling image content from translation and rotation\n  with spatial-VAE", "comments": "11 pages, 6 figures, to appear in the 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an image dataset, we are often interested in finding data generative\nfactors that encode semantic content independently from pose variables such as\nrotation and translation. However, current disentanglement approaches do not\nimpose any specific structure on the learned latent representations. We propose\na method for explicitly disentangling image rotation and translation from other\nunstructured latent factors in a variational autoencoder (VAE) framework. By\nformulating the generative model as a function of the spatial coordinate, we\nmake the reconstruction error differentiable with respect to latent translation\nand rotation parameters. This formulation allows us to train a neural network\nto perform approximate inference on these latent variables while explicitly\nconstraining them to only represent rotation and translation. We demonstrate\nthat this framework, termed spatial-VAE, effectively learns latent\nrepresentations that disentangle image rotation and translation from content\nand improves reconstruction over standard VAEs on several benchmark datasets,\nincluding applications to modeling continuous 2-D views of proteins from single\nparticle electron microscopy and galaxies in astronomical images.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 17:17:30 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Bepler", "Tristan", ""], ["Zhong", "Ellen D.", ""], ["Kelley", "Kotaro", ""], ["Brignole", "Edward", ""], ["Berger", "Bonnie", ""]]}, {"id": "1909.11671", "submitter": "Jinsung Yoon", "authors": "Jinsung Yoon, Sercan O. Arik, Tomas Pfister", "title": "Data Valuation using Reinforcement Learning", "comments": "17 pages, 12 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the value of data is a fundamental problem in machine learning.\nData valuation has multiple important use cases: (1) building insights about\nthe learning task, (2) domain adaptation, (3) corrupted sample discovery, and\n(4) robust learning. To adaptively learn data values jointly with the target\ntask predictor model, we propose a meta learning framework which we name Data\nValuation using Reinforcement Learning (DVRL). We employ a data value estimator\n(modeled by a deep neural network) to learn how likely each datum is used in\ntraining of the predictor model. We train the data value estimator using a\nreinforcement signal of the reward obtained on a small validation set that\nreflects performance on the target task. We demonstrate that DVRL yields\nsuperior data value estimates compared to alternative methods across different\ntypes of datasets and in a diverse set of application scenarios. The corrupted\nsample discovery performance of DVRL is close to optimal in many regimes (i.e.\nas if the noisy samples were known apriori), and for domain adaptation and\nrobust learning DVRL significantly outperforms state-of-the-art by 14.6% and\n10.8%, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:00:02 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Yoon", "Jinsung", ""], ["Arik", "Sercan O.", ""], ["Pfister", "Tomas", ""]]}, {"id": "1909.11702", "submitter": "Tyler Scott", "authors": "Tyler R. Scott, Karl Ridgeway, Michael C. Mozer", "title": "Stochastic Prototype Embeddings", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised deep-embedding methods project inputs of a domain to a\nrepresentational space in which same-class instances lie near one another and\ndifferent-class instances lie far apart. We propose a probabilistic method that\ntreats embeddings as random variables. Extending a state-of-the-art\ndeterministic method, Prototypical Networks (Snell et al., 2017), our approach\nsupposes the existence of a class prototype around which class instances are\nGaussian distributed. The prototype posterior is a product distribution over\nlabeled instances, and query instances are classified by marginalizing relative\nprototype proximity over embedding uncertainty. We describe an efficient\nsampler for approximate inference that allows us to train the model at roughly\nthe same space and time cost as its deterministic sibling. Incorporating\nuncertainty improves performance on few-shot learning and gracefully handles\nlabel noise and out-of-distribution inputs. Compared to the state-of-the-art\nstochastic method, Hedged Instance Embeddings (Oh et al., 2019), we achieve\nsuperior large- and open-set classification accuracy. Our method also aligns\nclass-discriminating features with the axes of the embedding space, yielding an\ninterpretable, disentangled representation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:38:36 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Scott", "Tyler R.", ""], ["Ridgeway", "Karl", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1909.11715", "submitter": "Alex Lamb", "authors": "Vikas Verma, Meng Qu, Kenji Kawaguchi, Alex Lamb, Yoshua Bengio, Juho\n  Kannala, Jian Tang", "title": "GraphMix: Improved Training of GNNs for Semi-Supervised Learning", "comments": "https://github.com/vikasverma1077/GraphMix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GraphMix, a regularization method for Graph Neural Network based\nsemi-supervised object classification, whereby we propose to train a\nfully-connected network jointly with the graph neural network via parameter\nsharing and interpolation-based regularization. Further, we provide a\ntheoretical analysis of how GraphMix improves the generalization bounds of the\nunderlying graph neural network, without making any assumptions about the\n\"aggregation\" layer or the depth of the graph neural networks. We\nexperimentally validate this analysis by applying GraphMix to various\narchitectures such as Graph Convolutional Networks, Graph Attention Networks\nand Graph-U-Net. Despite its simplicity, we demonstrate that GraphMix can\nconsistently improve or closely match state-of-the-art performance using even\nsimpler architectures such as Graph Convolutional Networks, across three\nestablished graph benchmarks: Cora, Citeseer and Pubmed citation network\ndatasets, as well as three newly proposed datasets: Cora-Full, Co-author-CS and\nCo-author-Physics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:57:39 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 20:49:23 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 22:08:36 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Verma", "Vikas", ""], ["Qu", "Meng", ""], ["Kawaguchi", "Kenji", ""], ["Lamb", "Alex", ""], ["Bengio", "Yoshua", ""], ["Kannala", "Juho", ""], ["Tang", "Jian", ""]]}, {"id": "1909.11720", "submitter": "Guang Cheng", "authors": "Yue Xing, Qifan Song, and Guang Cheng", "title": "Benefit of Interpolation in Nearest Neighbor Algorithms", "comments": "Under review as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The over-parameterized models attract much attention in the era of data\nscience and deep learning. It is empirically observed that although these\nmodels, e.g. deep neural networks, over-fit the training data, they can still\nachieve small testing error, and sometimes even {\\em outperform} traditional\nalgorithms which are designed to avoid over-fitting. The major goal of this\nwork is to sharply quantify the benefit of data interpolation in the context of\nnearest neighbors (NN) algorithm. Specifically, we consider a class of\ninterpolated weighting schemes and then carefully characterize their asymptotic\nperformances. Our analysis reveals a U-shaped performance curve with respect to\nthe level of data interpolation, and proves that a mild degree of data\ninterpolation {\\em strictly} improves the prediction accuracy and statistical\nstability over those of the (un-interpolated) optimal $k$NN algorithm. This\ntheoretically justifies (predicts) the existence of the second U-shaped curve\nin the recently discovered double descent phenomenon. Note that our goal in\nthis study is not to promote the use of interpolated-NN method, but to obtain\ntheoretical insights on data interpolation inspired by the aforementioned\nphenomenon.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 19:24:24 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Xing", "Yue", ""], ["Song", "Qifan", ""], ["Cheng", "Guang", ""]]}, {"id": "1909.11722", "submitter": "Tianshi Cao", "authors": "Tianshi Cao, Marc Law, Sanja Fidler", "title": "A Theoretical Analysis of the Number of Shots in Few-Shot Learning", "comments": "15 pages incl. appendix, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot classification is the task of predicting the category of an example\nfrom a set of few labeled examples. The number of labeled examples per category\nis called the number of shots (or shot number). Recent works tackle this task\nthrough meta-learning, where a meta-learner extracts information from observed\ntasks during meta-training to quickly adapt to new tasks during meta-testing.\nIn this formulation, the number of shots exploited during meta-training has an\nimpact on the recognition performance at meta-test time. Generally, the shot\nnumber used in meta-training should match the one used in meta-testing to\nobtain the best performance. We introduce a theoretical analysis of the impact\nof the shot number on Prototypical Networks, a state-of-the-art few-shot\nclassification method. From our analysis, we propose a simple method that is\nrobust to the choice of shot number used during meta-training, which is a\ncrucial hyperparameter. The performance of our model trained for an arbitrary\nmeta-training shot number shows great performance for different values of\nmeta-testing shot numbers. We experimentally demonstrate our approach on\ndifferent few-shot classification benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 19:33:05 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 23:24:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Cao", "Tianshi", ""], ["Law", "Marc", ""], ["Fidler", "Sanja", ""]]}, {"id": "1909.11723", "submitter": "Li Yuan", "authors": "Li Yuan, Francis E.H.Tay, Guilin Li, Tao Wang, Jiashi Feng", "title": "Revisiting Knowledge Distillation via Label Smoothing Regularization", "comments": "CVPR2020 Oral, codes:\n  https://github.com/yuanli2333/Teacher-free-Knowledge-Distillation", "journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) aims to distill the knowledge of a cumbersome\nteacher model into a lightweight student model. Its success is generally\nattributed to the privileged information on similarities among categories\nprovided by the teacher model, and in this sense, only strong teacher models\nare deployed to teach weaker students in practice. In this work, we challenge\nthis common belief by following experimental observations: 1) beyond the\nacknowledgment that the teacher can improve the student, the student can also\nenhance the teacher significantly by reversing the KD procedure; 2) a\npoorly-trained teacher with much lower accuracy than the student can still\nimprove the latter significantly. To explain these observations, we provide a\ntheoretical analysis of the relationships between KD and label smoothing\nregularization. We prove that 1) KD is a type of learned label smoothing\nregularization and 2) label smoothing regularization provides a virtual teacher\nmodel for KD. From these results, we argue that the success of KD is not fully\ndue to the similarity information between categories from teachers, but also to\nthe regularization of soft targets, which is equally or even more important.\n  Based on these analyses, we further propose a novel Teacher-free Knowledge\nDistillation (Tf-KD) framework, where a student model learns from itself or\nmanuallydesigned regularization distribution. The Tf-KD achieves comparable\nperformance with normal KD from a superior teacher, which is well applied when\na stronger teacher model is unavailable. Meanwhile, Tf-KD is generic and can be\ndirectly deployed for training deep neural networks. Without any extra\ncomputation cost, Tf-KD achieves up to 0.65\\% improvement on ImageNet over\nwell-established baseline models, which is superior to label smoothing\nregularization.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 19:33:43 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 03:53:49 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 08:02:53 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Yuan", "Li", ""], ["Tay", "Francis E. H.", ""], ["Li", "Guilin", ""], ["Wang", "Tao", ""], ["Feng", "Jiashi", ""]]}, {"id": "1909.11727", "submitter": "Nishant Gurunath", "authors": "Nishant Gurunath, Sai Krishna Rallabandi, Alan Black", "title": "Disentangling Speech and Non-Speech Components for Building Robust\n  Acoustic Models from Found Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to build language technologies for majority of the languages, it is\nimportant to leverage the resources available in public domain on the internet\n- commonly referred to as `Found Data'. However, such data is characterized by\nthe presence of non-standard, non-trivial variations. For instance, speech\nresources found on the internet have non-speech content, such as music.\nTherefore, speech recognition and speech synthesis models need to be robust to\nsuch variations. In this work, we present an analysis to show that it is\nimportant to disentangle the latent causal factors of variation in the original\ndata to accomplish these tasks. Based on this, we present approaches to\ndisentangle such variations from the data using Latent Stochastic Models.\nSpecifically, we present a method to split the latent prior space into\ncontinuous representations of dominant speech modes present in the magnitude\nspectra of audio signals. We propose a completely unsupervised approach using\nmultinode latent space variational autoencoders (VAE). We show that the\nconstraints on the latent space of a VAE can be in-fact used to separate speech\nand music, independent of the language of the speech. This paper also\nanalytically presents the requirement on the number of latent variables for the\ntask based on distribution of the speech data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 19:37:47 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Gurunath", "Nishant", ""], ["Rallabandi", "Sai Krishna", ""], ["Black", "Alan", ""]]}, {"id": "1909.11730", "submitter": "Andrew Hundt", "authors": "Andrew Hundt and Benjamin Killeen and Nicholas Greene and Hongtao Wu\n  and Heeyeon Kwon and Chris Paxton and Gregory D. Hager", "title": "\"Good Robot!\": Efficient Reinforcement Learning for Multi-Step Visual\n  Tasks with Sim to Real Transfer", "comments": "Accepted to the journal IEEE Robotics and Automation Letters (RA-L)\n  and to be presented at IROS 2020. This is a minor update to v3. 8 pages, 6\n  figures, 3 tables, 1 algorithm. Code is available at\n  https://github.com/jhu-lcsr/good_robot and a video overview is at\n  https://youtu.be/MbCuEZadkIw", "journal-ref": null, "doi": "10.1109/LRA.2020.3015448", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current Reinforcement Learning (RL) algorithms struggle with long-horizon\ntasks where time can be wasted exploring dead ends and task progress may be\neasily reversed. We develop the SPOT framework, which explores within action\nsafety zones, learns about unsafe regions without exploring them, and\nprioritizes experiences that reverse earlier progress to learn with remarkable\nefficiency.\n  The SPOT framework successfully completes simulated trials of a variety of\ntasks, improving a baseline trial success rate from 13% to 100% when stacking 4\ncubes, from 13% to 99% when creating rows of 4 cubes, and from 84% to 95% when\nclearing toys arranged in adversarial patterns. Efficiency with respect to\nactions per trial typically improves by 30% or more, while training takes just\n1-20k actions, depending on the task.\n  Furthermore, we demonstrate direct sim to real transfer. We are able to\ncreate real stacks in 100% of trials with 61% efficiency and real rows in 100%\nof trials with 59% efficiency by directly loading the simulation-trained model\non the real robot with no additional real-world fine-tuning. To our knowledge,\nthis is the first instance of reinforcement learning with successful sim to\nreal transfer applied to long term multi-step tasks such as block-stacking and\nrow-making with consideration of progress reversal. Code is available at\nhttps://github.com/jhu-lcsr/good_robot .\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 19:50:36 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 21:05:14 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 21:42:30 GMT"}, {"version": "v4", "created": "Sat, 15 Aug 2020 18:10:40 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Hundt", "Andrew", ""], ["Killeen", "Benjamin", ""], ["Greene", "Nicholas", ""], ["Wu", "Hongtao", ""], ["Kwon", "Heeyeon", ""], ["Paxton", "Chris", ""], ["Hager", "Gregory D.", ""]]}, {"id": "1909.11740", "submitter": "Yen-Chun Chen", "authors": "Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed El Kholy, Faisal Ahmed,\n  Zhe Gan, Yu Cheng, Jingjing Liu", "title": "UNITER: UNiversal Image-TExt Representation Learning", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint image-text embedding is the bedrock for most Vision-and-Language (V+L)\ntasks, where multimodality inputs are simultaneously processed for joint visual\nand textual understanding. In this paper, we introduce UNITER, a UNiversal\nImage-TExt Representation, learned through large-scale pre-training over four\nimage-text datasets (COCO, Visual Genome, Conceptual Captions, and SBU\nCaptions), which can power heterogeneous downstream V+L tasks with joint\nmultimodal embeddings. We design four pre-training tasks: Masked Language\nModeling (MLM), Masked Region Modeling (MRM, with three variants), Image-Text\nMatching (ITM), and Word-Region Alignment (WRA). Different from previous work\nthat applies joint random masking to both modalities, we use conditional\nmasking on pre-training tasks (i.e., masked language/region modeling is\nconditioned on full observation of image/text). In addition to ITM for global\nimage-text alignment, we also propose WRA via the use of Optimal Transport (OT)\nto explicitly encourage fine-grained alignment between words and image regions\nduring pre-training. Comprehensive analysis shows that both conditional masking\nand OT-based WRA contribute to better pre-training. We also conduct a thorough\nablation study to find an optimal combination of pre-training tasks. Extensive\nexperiments show that UNITER achieves new state of the art across six V+L tasks\n(over nine datasets), including Visual Question Answering, Image-Text\nRetrieval, Referring Expression Comprehension, Visual Commonsense Reasoning,\nVisual Entailment, and NLVR$^2$. Code is available at\nhttps://github.com/ChenRocks/UNITER.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 20:02:54 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 05:03:12 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 22:19:59 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chen", "Yen-Chun", ""], ["Li", "Linjie", ""], ["Yu", "Licheng", ""], ["Kholy", "Ahmed El", ""], ["Ahmed", "Faisal", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Liu", "Jingjing", ""]]}, {"id": "1909.11759", "submitter": "Wei Cai", "authors": "Wei Cai, Xiaoguang Li, Lizuo Liu", "title": "A Phase Shift Deep Neural Network for High Frequency Approximation and\n  Wave Problems", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.01389", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a phase shift deep neural network (PhaseDNN), which\nprovides a uniform wideband convergence in approximating high frequency\nfunctions and solutions of wave equations. The PhaseDNN makes use of the fact\nthat common DNNs often achieve convergence in the low frequency range first,\nand a series of moderately-sized DNNs are constructed and trained for selected\nhigh frequency ranges. With the help of phase shifts in the frequency domain,\neach of the DNNs will be trained to approximate the function's higher frequency\ncontent over a specific range at the the speed of convergence as in the low\nfrequency range. As a result, the proposed PhaseDNN is able to convert high\nfrequency learning to low frequency one, allowing a uniform learning to\nwideband functions. The PhaseDNN will then be applied to find the solution of\nhigh frequency wave equations in inhomogeneous media through both differential\nand integral equation formulations with least square residual loss functions.\nNumerical results have demonstrated the capability of the PhaseDNN in learning\nhigh frequency functions and oscillatory solutions of interior and exterior\nHelmholtz equations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 20:45:08 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 23:49:49 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Cai", "Wei", ""], ["Li", "Xiaoguang", ""], ["Liu", "Lizuo", ""]]}, {"id": "1909.11760", "submitter": "Chang Liu", "authors": "Chang Liu, Yanan Xu, Yanmin Zhu", "title": "ALCNN: Attention-based Model for Fine-grained Demand Inference of\n  Dock-less Shared Bike in New Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, dock-less shared bikes have been widely spread across many\ncities in China and facilitate people's lives. However, at the same time, it\nalso raises many problems about dock-less shared bike management due to the\nmismatching between demands and real distribution of bikes. Before deploying\ndock-less shared bikes in a city, companies need to make a plan for dispatching\nbikes from places having excessive bikes to locations with high demands for\nproviding better services. In this paper, we study the problem of inferring\nfine-grained bike demands anywhere in a new city before the deployment of\nbikes. This problem is challenging because new city lacks training data and\nbike demands vary by both places and time. To solve the problem, we provide\nvarious methods to extract discriminative features from multi-source geographic\ndata, such as POI, road networks and nighttime light, for each place. We\nutilize correlation Principle Component Analysis (coPCA) to deal with extracted\nfeatures of both old city and new city to realize distribution adaption. Then,\nwe adopt a discrete wavelet transform (DWT) based model to mine daily patterns\nfor each place from fine-grained bike demand. We propose an attention based\nlocal CNN model, \\textbf{ALCNN}, to infer the daily patterns with latent\nfeatures from coPCA with multiple CNNs for modeling the influence of neighbor\nplaces. In addition, ALCNN merges latent features from multiple CNNs and can\nselect a suitable size of influenced regions. The extensive experiments on\nreal-life datasets show that the proposed approach outperforms competitive\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 21:05:13 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Liu", "Chang", ""], ["Xu", "Yanan", ""], ["Zhu", "Yanmin", ""]]}, {"id": "1909.11763", "submitter": "Yunhui Guo", "authors": "Yunhui Guo, Mingrui Liu, Tianbao Yang, Tajana Rosing", "title": "Improved Schemes for Episodic Memory-based Lifelong Learning", "comments": "NeurIPS 2020, Spotlight. 17 pages. Code:\n  https://github.com/yunhuiguo/MEGA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep neural networks can achieve remarkable performance on a single\ntask. However, when the deep neural network is continually trained on a\nsequence of tasks, it seems to gradually forget the previous learned knowledge.\nThis phenomenon is referred to as \\textit{catastrophic forgetting} and\nmotivates the field called lifelong learning. Recently, episodic memory based\napproaches such as GEM \\cite{lopez2017gradient} and A-GEM\n\\cite{chaudhry2018efficient} have shown remarkable performance. In this paper,\nwe provide the first unified view of episodic memory based approaches from an\noptimization's perspective. This view leads to two improved schemes for\nepisodic memory based lifelong learning, called MEGA-I and MEGA-II. MEGA-I and\nMEGA-II modulate the balance between old tasks and the new task by integrating\nthe current gradient with the gradient computed on the episodic memory.\nNotably, we show that GEM and A-GEM are degenerate cases of MEGA-I and MEGA-II\nwhich consistently put the same emphasis on the current task, regardless of how\nthe loss changes over time. Our proposed schemes address this issue by using\nnovel loss-balancing updating rules, which drastically improve the performance\nover GEM and A-GEM. Extensive experimental results show that the proposed\nschemes significantly advance the state-of-the-art on four commonly used\nlifelong learning benchmarks, reducing the error by up to 18\\%.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 20:49:15 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 00:34:42 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 20:08:09 GMT"}, {"version": "v4", "created": "Wed, 6 Nov 2019 19:46:43 GMT"}, {"version": "v5", "created": "Fri, 22 Nov 2019 06:08:31 GMT"}, {"version": "v6", "created": "Tue, 13 Oct 2020 22:09:32 GMT"}, {"version": "v7", "created": "Tue, 15 Dec 2020 04:06:12 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Guo", "Yunhui", ""], ["Liu", "Mingrui", ""], ["Yang", "Tianbao", ""], ["Rosing", "Tajana", ""]]}, {"id": "1909.11764", "submitter": "Chen Zhu", "authors": "Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, Jingjing Liu", "title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding", "comments": "Adding results with ALBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training, which minimizes the maximal risk for label-preserving\ninput perturbations, has proved to be effective for improving the\ngeneralization of language models. In this work, we propose a novel adversarial\ntraining algorithm, FreeLB, that promotes higher invariance in the embedding\nspace, by adding adversarial perturbations to word embeddings and minimizing\nthe resultant adversarial risk inside different regions around input samples.\nTo validate the effectiveness of the proposed approach, we apply it to\nTransformer-based models for natural language understanding and commonsense\nreasoning tasks. Experiments on the GLUE benchmark show that when applied only\nto the finetuning stage, it is able to improve the overall test scores of\nBERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8.\nIn addition, the proposed approach achieves state-of-the-art single-model test\naccuracies of 85.44\\% and 67.75\\% on ARC-Easy and ARC-Challenge. Experiments on\nCommonsenseQA benchmark further demonstrate that FreeLB can be generalized and\nboost the performance of RoBERTa-large model on other tasks as well. Code is\navailable at \\url{https://github.com/zhuchen03/FreeLB .\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 20:50:32 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 18:53:21 GMT"}, {"version": "v3", "created": "Sat, 5 Oct 2019 04:05:46 GMT"}, {"version": "v4", "created": "Wed, 19 Feb 2020 01:57:24 GMT"}, {"version": "v5", "created": "Thu, 23 Apr 2020 07:19:00 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Zhu", "Chen", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Sun", "Siqi", ""], ["Goldstein", "Tom", ""], ["Liu", "Jingjing", ""]]}, {"id": "1909.11784", "submitter": "Achim Zeileis", "authors": "Nikolaus Umlauf, Nadja Klein, Thorsten Simon, Achim Zeileis", "title": "bamlss: A Lego Toolbox for Flexible Bayesian Regression (and Beyond)", "comments": "48 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last decades, the challenges in applied regression and in predictive\nmodeling have been changing considerably: (1) More flexible model\nspecifications are needed as big(ger) data become available, facilitated by\nmore powerful computing infrastructure. (2) Full probabilistic modeling rather\nthan predicting just means or expectations is crucial in many applications. (3)\nInterest in Bayesian inference has been increasing both as an appealing\nframework for regularizing or penalizing model estimation as well as a natural\nalternative to classical frequentist inference. However, while there has been a\nlot of research in all three areas, also leading to associated software\npackages, a modular software implementation that allows to easily combine all\nthree aspects has not yet been available. For filling this gap, the R package\nbamlss is introduced for Bayesian additive models for location, scale, and\nshape (and beyond). At the core of the package are algorithms for\nhighly-efficient Bayesian estimation and inference that can be applied to\ngeneralized additive models (GAMs) or generalized additive models for location,\nscale, and shape (GAMLSS), also known as distributional regression. However,\nits building blocks are designed as \"Lego bricks\" encompassing various\ndistributions (exponential family, Cox, joint models, ...), regression terms\n(linear, splines, random effects, tensor products, spatial fields, ...), and\nestimators (MCMC, backfitting, gradient boosting, lasso, ...). It is\ndemonstrated how these can be easily recombined to make classical models more\nflexible or create new custom models for specific modeling challenges.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 21:31:02 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Umlauf", "Nikolaus", ""], ["Klein", "Nadja", ""], ["Simon", "Thorsten", ""], ["Zeileis", "Achim", ""]]}, {"id": "1909.11786", "submitter": "Nilesh Ahuja", "authors": "Nilesh A. Ahuja, Ibrahima Ndiour, Trushant Kalyanpur, Omesh Tickoo", "title": "Probabilistic Modeling of Deep Features for Out-of-Distribution and\n  Adversarial Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a principled approach for detecting out-of-distribution (OOD) and\nadversarial samples in deep neural networks. Our approach consists in modeling\nthe outputs of the various layers (deep features) with parametric probability\ndistributions once training is completed. At inference, the likelihoods of the\ndeep features w.r.t the previously learnt distributions are calculated and used\nto derive uncertainty estimates that can discriminate in-distribution samples\nfrom OOD samples. We explore the use of two classes of multivariate\ndistributions for modeling the deep features - Gaussian and Gaussian mixture -\nand study the trade-off between accuracy and computational complexity. We\ndemonstrate benefits of our approach on image features by detecting OOD images\nand adversarially-generated images, using popular DNN architectures on MNIST\nand CIFAR10 datasets. We show that more precise modeling of the feature\ndistributions result in significantly improved detection of OOD and adversarial\nsamples; up to 12 percentage points in AUPR and AUROC metrics. We further show\nthat our approach remains extremely effective when applied to video data and\nassociated spatio-temporal features by detecting adversarial samples on\nactivity classification tasks using UCF101 dataset, and the C3D network. To our\nknowledge, our methodology is the first one reported for reliably detecting\nwhite-box adversarial framing, a state-of-the-art adversarial attack for video\nclassifiers.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 21:41:56 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Ahuja", "Nilesh A.", ""], ["Ndiour", "Ibrahima", ""], ["Kalyanpur", "Trushant", ""], ["Tickoo", "Omesh", ""]]}, {"id": "1909.11790", "submitter": "Chapman Siu", "authors": "Chapman Siu", "title": "Residual Networks Behave Like Boosting Algorithms", "comments": "This work was supported by and completed whilst author was at Suncorp\n  Group Limited. to appear 2019 IEEE International Conference on Data Science\n  and Advance Analytics (DSAA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Residual Networks (ResNet) is equivalent to boosting feature\nrepresentation, without any modification to the underlying ResNet training\nalgorithm. A regret bound based on Online Gradient Boosting theory is proved\nand suggests that ResNet could achieve Online Gradient Boosting regret bounds\nthrough neural network architectural changes with the addition of a shrinkage\nparameter in the identity skip-connections and using residual modules with\nmax-norm bounds. Through this relation between ResNet and Online Boosting,\nnovel feature representation boosting algorithms can be constructed based on\naltering residual modules. We demonstrate this through proposing decision tree\nresidual modules to construct a new boosted decision tree algorithm and\ndemonstrating generalization error bounds for both approaches; relaxing\nconstraints within BoostResNet algorithm to allow it to be trained in an\nout-of-core manner. We evaluate convolution ResNet with and without shrinkage\nmodifications to demonstrate its efficacy, and demonstrate that our online\nboosted decision tree algorithm is comparable to state-of-the-art offline\nboosted decision tree algorithms without the drawback of offline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:00:08 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Siu", "Chapman", ""]]}, {"id": "1909.11791", "submitter": "Sajad Mousavi", "authors": "Sajad Mousavi, Atiyeh Fotoohinasab and Fatemeh Afghah", "title": "Single-modal and Multi-modal False Arrhythmia Alarm Reduction using\n  Attention-based Convolutional and Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0226990", "report-no": null, "categories": "q-bio.QM cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a deep learning model that effectively suppresses the\nfalse alarms in the intensive care units (ICUs) without ignoring the true\nalarms using single- and multimodal biosignals. Most of the current work in the\nliterature are either rule-based methods, requiring prior knowledge of\narrhythmia analysis to build rules, or classical machine learning approaches,\ndepending on hand-engineered features. In this work, we apply convolutional\nneural networks to automatically extract time-invariant features, an attention\nmechanism to put more emphasis on the important regions of the input segmented\nsignal(s) that are more likely to contribute to an alarm, and long short-term\nmemory units to capture the temporal information presented in the signal\nsegments. We trained our method efficiently using a two-step training algorithm\n(i.e., pre-training and fine-tuning the proposed network) on the dataset\nprovided by the PhysioNet computing in cardiology challenge 2015. The\nevaluation results demonstrate that the proposed method obtains better results\ncompared to other existing algorithms for the false alarm reduction task in\nICUs. The proposed method achieves a sensitivity of 93.88% and a specificity of\n92.05% for the alarm classification, considering three different signals. In\naddition, our experiments for 5 separate alarm types leads significant results,\nwhere we just consider a single-lead ECG (e.g., a sensitivity of 90.71%, a\nspecificity of 88.30%, an AUC of 89.51 for alarm type of Ventricular\nTachycardia arrhythmia)\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:00:26 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Mousavi", "Sajad", ""], ["Fotoohinasab", "Atiyeh", ""], ["Afghah", "Fatemeh", ""]]}, {"id": "1909.11793", "submitter": "John Palowitch", "authors": "John Palowitch, Bryan Perozzi", "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training\n  Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Are Graph Neural Networks (GNNs) fair? In many real world graphs, the\nformation of edges is related to certain node attributes (e.g. gender,\ncommunity, reputation). In this case, standard GNNs using these edges will be\nbiased by this information, as it is encoded in the structure of the adjacency\nmatrix itself. In this paper, we show that when metadata is correlated with the\nformation of node neighborhoods, unsupervised node embedding dimensions learn\nthis metadata. This bias implies an inability to control for important\ncovariates in real-world applications, such as recommendation systems. To solve\nthese issues, we introduce the Metadata-Orthogonal Node Embedding Training\n(MONET) unit, a general model for debiasing embeddings of nodes in a graph.\nMONET achieves this by ensuring that the node embeddings are trained on a\nhyperplane orthogonal to that of the node metadata. This effectively organizes\nunstructured embedding dimensions into an interpretable topology-only,\nmetadata-only division with no linear interactions. We illustrate the\neffectiveness of MONET though our experiments on a variety of real world\ngraphs, which shows that our method can learn and remove the effect of\narbitrary covariates in tasks such as preventing the leakage of political party\naffiliation in a blog network, and thwarting the gaming of embedding-based\nrecommendation systems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:12:08 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 07:25:32 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Palowitch", "John", ""], ["Perozzi", "Bryan", ""]]}, {"id": "1909.11795", "submitter": "Jo Schlemper", "authors": "Jo Schlemper, Jinming Duan, Cheng Ouyang, Chen Qin, Jose Caballero,\n  Joseph V. Hajnal, Daniel Rueckert", "title": "Data consistency networks for (calibration-less) accelerated parallel MR\n  image reconstruction", "comments": "Presented at ISMRM 27th Annual Meeting & Exhibition (Abstract #4663)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present simple reconstruction networks for multi-coil data by extending\ndeep cascade of CNN's and exploiting the data consistency layer. In particular,\nwe propose two variants, where one is inspired by POCSENSE and the other is\ncalibration-less. We show that the proposed approaches are competitive relative\nto the state of the art both quantitatively and qualitatively.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:15:56 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Schlemper", "Jo", ""], ["Duan", "Jinming", ""], ["Ouyang", "Cheng", ""], ["Qin", "Chen", ""], ["Caballero", "Jose", ""], ["Hajnal", "Joseph V.", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1909.11799", "submitter": "Ronan Perry", "authors": "Ronan Perry, Tyler M. Tomita, Ronak Mehta, Jesus Arroyo, Jesse\n  Patsolic, Benjamin Falk, Joshua T. Vogelstein", "title": "Manifold Forests: Closing the Gap on Neural Networks", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decision forests (DFs), in particular random forests and gradient boosting\ntrees, have demonstrated state-of-the-art accuracy compared to other methods in\nmany supervised learning scenarios. In particular, DFs dominate other methods\nin tabular data, that is, when the feature space is unstructured, so that the\nsignal is invariant to permuting feature indices. However, in structured data\nlying on a manifold---such as images, text, and speech---deep networks (DNs),\nspecifically convolutional deep networks (ConvNets), tend to outperform DFs. We\nconjecture that at least part of the reason for this is that the input to DNs\nis not simply the feature magnitudes, but also their indices (for example, the\nconvolution operation uses feature locality). In contrast, naive DF\nimplementations fail to explicitly consider feature indices. A recently\nproposed DF approach demonstrates that DFs, for each node, implicitly sample a\nrandom matrix from some specific distribution. These DFs, like some classes of\nDNs, learn by partitioning the feature space into convex polytopes\ncorresponding to linear functions. We build on that approach and show that one\ncan choose distributions in a manifold-aware fashion to incorporate feature\nlocality. We demonstrate the empirical performance on data whose features live\non three different manifolds: a torus, images, and time-series. In all\nsimulations, our Manifold Oblique Random Forest (MORF) algorithm empirically\ndominates other state-of-the-art approaches that ignore feature space structure\nand challenges the performance of ConvNets. Moreover, MORF runs significantly\nfaster than ConvNets and maintains interpretability and theoretical\njustification. This approach, therefore, has promise to enable DFs and other\nmachine learning methods to close the gap to deep networks on manifold-valued\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:28:47 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 19:24:32 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 21:05:16 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Perry", "Ronan", ""], ["Tomita", "Tyler M.", ""], ["Mehta", "Ronak", ""], ["Arroyo", "Jesus", ""], ["Patsolic", "Jesse", ""], ["Falk", "Benjamin", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1909.11800", "submitter": "Kemal Davaslioglu", "authors": "Yi Shi, Kemal Davaslioglu, Yalin E. Sagduyu, William C. Headley,\n  Michael Fowler, and Gilbert Green", "title": "Deep Learning for RF Signal Classification in Unknown and Dynamic\n  Spectrum Environments", "comments": "Accepted to IEEE International Symposium on Dynamic Spectrum Access\n  Networks (DYSPAN) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic spectrum access (DSA) benefits from detection and classification of\ninterference sources including in-network users, out-network users, and jammers\nthat may all coexist in a wireless network. We present a deep learning based\nsignal (modulation) classification solution in a realistic wireless network\nsetting, where 1) signal types may change over time; 2) some signal types may\nbe unknown for which there is no training data; 3) signals may be spoofed such\nas the smart jammers replaying other signal types; and 4) different signal\ntypes may be superimposed due to the interference from concurrent\ntransmissions. For case 1, we apply continual learning and train a\nConvolutional Neural Network (CNN) using an Elastic Weight Consolidation (EWC)\nbased loss. For case 2, we detect unknown signals via outlier detection applied\nto the outputs of convolutional layers using Minimum Covariance Determinant\n(MCD) and k-means clustering methods. For case 3, we extend the CNN structure\nto capture phase shifts due to radio hardware effects to identify the spoofing\nsignal sources. For case 4, we apply blind source separation using Independent\nComponent Analysis (ICA) to separate interfering signals. We utilize the signal\nclassification results in a distributed scheduling protocol, where in-network\n(secondary) users employ signal classification scores to make channel access\ndecisions and share the spectrum with each other while avoiding interference\nwith out-network (primary) users and jammers. Compared with benchmark\nTDMA-based schemes, we show that distributed scheduling constructed upon signal\nclassification results provides major improvements to in-network user\nthroughput and out-network user success ratio.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:32:26 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Shi", "Yi", ""], ["Davaslioglu", "Kemal", ""], ["Sagduyu", "Yalin E.", ""], ["Headley", "William C.", ""], ["Fowler", "Michael", ""], ["Green", "Gilbert", ""]]}, {"id": "1909.11804", "submitter": "Shusen Liu", "authors": "Shusen Liu, Rushil Anirudh, Jayaraman J. Thiagarajan and Peer-Timo\n  Bremer", "title": "Function Preserving Projection for Scalable Exploration of\n  High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present function preserving projections (FPP), a scalable linear\nprojection technique for discovering interpretable relationships in\nhigh-dimensional data. Conventional dimension reduction methods aim to\nmaximally preserve the global and/or local geometric structure of a dataset.\nHowever, in practice one is often more interested in determining how one or\nmultiple user-selected response function(s) can be explained by the data. To\nintuitively connect the responses to the data, FPP constructs 2D linear\nembeddings optimized to reveal interpretable yet potentially non-linear\npatterns of the response functions. More specifically, FPP is designed to (i)\nproduce human-interpretable embeddings; (ii) capture non-linear relationships;\n(iii) allow the simultaneous use of multiple response functions; and (iv) scale\nto millions of samples. Using FPP on real-world datasets, one can obtain\nfundamentally new insights about high-dimensional relationships in large-scale\ndata that could not be achieved using existing dimension reduction methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 22:40:47 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Liu", "Shusen", ""], ["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1909.11810", "submitter": "Antonio Ginart", "authors": "Antonio Ginart, Maxim Naumov, Dheevatsa Mudigere, Jiyan Yang, James\n  Zou", "title": "Mixed Dimension Embeddings with Application to Memory-Efficient\n  Recommendation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Embedding representations power machine intelligence in many applications,\nincluding recommendation systems, but they are space intensive -- potentially\noccupying hundreds of gigabytes in large-scale settings. To help manage this\noutsized memory consumption, we explore mixed dimension embeddings, an\nembedding layer architecture in which a particular embedding vector's dimension\nscales with its query frequency. Through theoretical analysis and systematic\nexperiments, we demonstrate that using mixed dimensions can drastically reduce\nthe memory usage, while maintaining and even improving the ML performance.\nEmpirically, we show that the proposed mixed dimension layers improve accuracy\nby 0.1% using half as many parameters or maintain it using 16X fewer parameters\nfor click-through rate prediction task on the Criteo Kaggle dataset.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 23:19:55 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 20:04:29 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 09:37:45 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ginart", "Antonio", ""], ["Naumov", "Maxim", ""], ["Mudigere", "Dheevatsa", ""], ["Yang", "Jiyan", ""], ["Zou", "James", ""]]}, {"id": "1909.11813", "submitter": "Andrea Dittadi", "authors": "Andrea Dittadi, Ole Winther", "title": "LAVAE: Disentangling Location and Appearance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic generative model for unsupervised learning of\nstructured, interpretable, object-based representations of visual scenes. We\nuse amortized variational inference to train the generative model end-to-end.\nThe learned representations of object location and appearance are fully\ndisentangled, and objects are represented independently of each other in the\nlatent space. Unlike previous approaches that disentangle location and\nappearance, ours generalizes seamlessly to scenes with many more objects than\nencountered in the training regime. We evaluate the proposed model on\nmulti-MNIST and multi-dSprites data sets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 23:33:14 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 00:10:09 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Dittadi", "Andrea", ""], ["Winther", "Ole", ""]]}, {"id": "1909.11820", "submitter": "Masoud Badiei Khuzani", "authors": "Masoud Badiei Khuzani, Liyue Shen, Shahin Shahrampour, Lei Xing", "title": "A Mean-Field Theory for Kernel Alignment with Random Features in\n  Generative and Discriminative Models", "comments": "51 pages, 4 figures. In this edition, new simulations for the kernel\n  SVMs are included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel supervised learning method to optimize the kernel in the\nmaximum mean discrepancy generative adversarial networks (MMD GANs), and the\nkernel support vector machines (SVMs). Specifically, we characterize a\ndistributionally robust optimization problem to compute a good distribution for\nthe random feature model of Rahimi and Recht. Due to the fact that the\ndistributional optimization is infinite dimensional, we consider a Monte-Carlo\nsample average approximation (SAA) to obtain a more tractable finite\ndimensional optimization problem. We subsequently leverage a particle\nstochastic gradient descent (SGD) method to solve the derived finite\ndimensional optimization problem. Based on a mean-field analysis, we then prove\nthat the empirical distribution of the interactive particles system at each\niteration of the SGD follows the path of the gradient descent flow on the\nWasserstein manifold. We also establish the non-asymptotic consistency of the\nfinite sample estimator. We evaluate our kernel learning method for the\nhypothesis testing problem by evaluating the kernel MMD statistics, and show\nthat our learning method indeed attains better power of the test for larger\nthreshold values compared to an untrained kernel. Moreover, our empirical\nevaluation on benchmark data-sets shows the advantage of our kernel learning\napproach compared to alternative kernel learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 23:45:55 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 02:40:56 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 02:53:48 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Khuzani", "Masoud Badiei", ""], ["Shen", "Liyue", ""], ["Shahrampour", "Shahin", ""], ["Xing", "Lei", ""]]}, {"id": "1909.11821", "submitter": "Yueh-Hua Wu", "authors": "Yueh-Hua Wu, Ting-Han Fan, Peter J. Ramadge, and Hao Su", "title": "Model Imitation for Model-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (MBRL) aims to learn a dynamic model to\nreduce the number of interactions with real-world environments. However, due to\nestimation error, rollouts in the learned model, especially those of long\nhorizons, fail to match the ones in real-world environments. This mismatching\nhas seriously impacted the sample complexity of MBRL. The phenomenon can be\nattributed to the fact that previous works employ supervised learning to learn\nthe one-step transition models, which has inherent difficulty ensuring the\nmatching of distributions from multi-step rollouts. Based on the claim, we\npropose to learn the transition model by matching the distributions of\nmulti-step rollouts sampled from the transition model and the real ones via\nWGAN. We theoretically show that matching the two can minimize the difference\nof cumulative rewards between the real transition and the learned one. Our\nexperiments also show that the proposed Model Imitation method can compete or\noutperform the state-of-the-art in terms of sample complexity and average\nreturn.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 23:52:30 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 06:19:21 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 05:47:10 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Wu", "Yueh-Hua", ""], ["Fan", "Ting-Han", ""], ["Ramadge", "Peter J.", ""], ["Su", "Hao", ""]]}, {"id": "1909.11822", "submitter": "Adam Rupe", "authors": "Adam Rupe, Nalini Kumar, Vladislav Epifanov, Karthik Kashinath,\n  Oleksandr Pavlyk, Frank Schlimbach, Mostofa Patwary, Sergey Maidanov, Victor\n  Lee, Prabhat, James P. Crutchfield", "title": "DisCo: Physics-Based Unsupervised Discovery of Coherent Structures in\n  Spatiotemporal Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extracting actionable insight from complex unlabeled scientific data is an\nopen challenge and key to unlocking data-driven discovery in science.\nComplementary and alternative to supervised machine learning approaches,\nunsupervised physics-based methods based on behavior-driven theories hold great\npromise. Due to computational limitations, practical application on real-world\ndomain science problems has lagged far behind theoretical development. We\npresent our first step towards bridging this divide - DisCo - a\nhigh-performance distributed workflow for the behavior-driven local causal\nstate theory. DisCo provides a scalable unsupervised physics-based\nrepresentation learning method that decomposes spatiotemporal systems into\ntheir structurally relevant components, which are captured by the latent local\ncausal state variables. Complex spatiotemporal systems are generally highly\nstructured and organize around a lower-dimensional skeleton of coherent\nstructures, and in several firsts we demonstrate the efficacy of DisCo in\ncapturing such structures from observational and simulated scientific data. To\nthe best of our knowledge, DisCo is also the first application software\ndeveloped entirely in Python to scale to over 1000 machine nodes, providing\ngood performance along with ensuring domain scientists' productivity. We\ndeveloped scalable, performant methods optimized for Intel many-core processors\nthat will be upstreamed to open-source Python library packages. Our capstone\nexperiment, using newly developed DisCo workflow and libraries, performs\nunsupervised spacetime segmentation analysis of CAM5.1 climate simulation data,\nprocessing an unprecedented 89.5 TB in 6.6 minutes end-to-end using 1024 Intel\nHaswell nodes on the Cori supercomputer obtaining 91% weak-scaling and 64%\nstrong-scaling efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 23:52:57 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Rupe", "Adam", ""], ["Kumar", "Nalini", ""], ["Epifanov", "Vladislav", ""], ["Kashinath", "Karthik", ""], ["Pavlyk", "Oleksandr", ""], ["Schlimbach", "Frank", ""], ["Patwary", "Mostofa", ""], ["Maidanov", "Sergey", ""], ["Lee", "Victor", ""], ["Prabhat", "", ""], ["Crutchfield", "James P.", ""]]}, {"id": "1909.11825", "submitter": "Yu Sun", "authors": "Yu Sun, Eric Tzeng, Trevor Darrell, Alexei A. Efros", "title": "Unsupervised Domain Adaptation through Self-Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper addresses unsupervised domain adaptation, the setting where\nlabeled training data is available on a source domain, but the goal is to have\ngood performance on a target domain with only unlabeled data. Like much of\nprevious work, we seek to align the learned representations of the source and\ntarget domains while preserving discriminability. The way we accomplish\nalignment is by learning to perform auxiliary self-supervised task(s) on both\ndomains simultaneously. Each self-supervised task brings the two domains closer\ntogether along the direction relevant to that task. Training this jointly with\nthe main task classifier on the source domain is shown to successfully\ngeneralize to the unlabeled target domain. The presented objective is\nstraightforward to implement and easy to optimize. We achieve state-of-the-art\nresults on four out of seven standard benchmarks, and competitive results on\nsegmentation adaptation. We also demonstrate that our method composes well with\nanother popular pixel-level adaptation method.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 00:21:16 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 08:09:29 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sun", "Yu", ""], ["Tzeng", "Eric", ""], ["Darrell", "Trevor", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1909.11830", "submitter": "Vitaly Kurin", "authors": "Vitaly Kurin, Saad Godil, Shimon Whiteson, Bryan Catanzaro", "title": "Can $Q$-Learning with Graph Networks Learn a Generalizable Branching\n  Heuristic for a SAT Solver?", "comments": "Camera-ready for NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Graph-$Q$-SAT, a branching heuristic for a Boolean SAT solver\ntrained with value-based reinforcement learning (RL) using Graph Neural\nNetworks for function approximation. Solvers using Graph-$Q$-SAT are complete\nSAT solvers that either provide a satisfying assignment or proof of\nunsatisfiability, which is required for many SAT applications. The branching\nheuristics commonly used in SAT solvers make poor decisions during their\nwarm-up period, whereas Graph-$Q$-SAT is trained to examine the structure of\nthe particular problem instance to make better decisions early in the search.\nTraining Graph-$Q$-SAT is data efficient and does not require elaborate dataset\npreparation or feature engineering. We train Graph-$Q$-SAT using RL interfacing\nwith MiniSat solver and show that Graph-$Q$-SAT can reduce the number of\niterations required to solve SAT problems by 2-3X. Furthermore, it generalizes\nto unsatisfiable SAT instances, as well as to problems with 5X more variables\nthan it was trained on. We show that for larger problems, reductions in the\nnumber of iterations lead to wall clock time reductions, the ultimate goal when\ndesigning heuristics. We also show positive zero-shot transfer behavior when\ntesting Graph-$Q$-SAT on a task family different from that used for training.\nWhile more work is needed to apply Graph-$Q$-SAT to reduce wall clock time in\nmodern SAT solving settings, it is a compelling proof-of-concept showing that\nRL equipped with Graph Neural Networks can learn a generalizable branching\nheuristic for SAT search.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 00:44:40 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 10:28:55 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Kurin", "Vitaly", ""], ["Godil", "Saad", ""], ["Whiteson", "Shimon", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "1909.11832", "submitter": "Nairouz Mrabah", "authors": "Nairouz Mrabah, Mohamed Bouguessa, Riadh Ksantini", "title": "Adversarial Deep Embedded Clustering: on a better trade-off between\n  Feature Randomness and Feature Drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering using deep autoencoders has been thoroughly investigated in recent\nyears. Current approaches rely on simultaneously learning embedded features and\nclustering the data points in the latent space. Although numerous deep\nclustering approaches outperform the shallow models in achieving favorable\nresults on several high-semantic datasets, a critical weakness of such models\nhas been overlooked. In the absence of concrete supervisory signals, the\nembedded clustering objective function may distort the latent space by learning\nfrom unreliable pseudo-labels. Thus, the network can learn non-representative\nfeatures, which in turn undermines the discriminative ability, yielding worse\npseudo-labels. In order to alleviate the effect of random discriminative\nfeatures, modern autoencoder-based clustering papers propose to use the\nreconstruction loss for pretraining and as a regularizer during the clustering\nphase. Nevertheless, a clustering-reconstruction trade-off can cause the\n\\textit{Feature Drift} phenomena. In this paper, we propose ADEC (Adversarial\nDeep Embedded Clustering) a novel autoencoder-based clustering model, which\naddresses a dual problem, namely, \\textit{Feature Randomness} and\n\\textit{Feature Drift}, using adversarial training. We empirically demonstrate\nthe suitability of our model on handling these problems using benchmark real\ndatasets. Experimental results validate that our model outperforms\nstate-of-the-art autoencoder-based clustering methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 00:51:09 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Mrabah", "Nairouz", ""], ["Bouguessa", "Mohamed", ""], ["Ksantini", "Riadh", ""]]}, {"id": "1909.11835", "submitter": "Ulrich A\\\"ivodji", "authors": "Ulrich A\\\"ivodji, S\\'ebastien Gambs, Timon Ther", "title": "GAMIN: An Adversarial Approach to Black-Box Model Inversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have demonstrated that machine learning models are vulnerable to\nmodel inversion attacks, which lead to the exposure of sensitive information\ncontained in their training dataset. While some model inversion attacks have\nbeen developed in the past in the black-box attack setting, in which the\nadversary does not have direct access to the structure of the model, few of\nthese have been conducted so far against complex models such as deep neural\nnetworks. In this paper, we introduce GAMIN (for Generative Adversarial Model\nINversion), a new black-box model inversion attack framework achieving\nsignificant results even against deep models such as convolutional neural\nnetworks at a reasonable computing cost. GAMIN is based on the continuous\ntraining of a surrogate model for the target model under attack and a generator\nwhose objective is to generate inputs resembling those used to train the target\nmodel. The attack was validated against various neural networks used as image\nclassifiers. In particular, when attacking models trained on the MNIST dataset,\nGAMIN is able to extract recognizable digits for up to 60% of labels produced\nby the target. Attacks against skin classification models trained on the pilot\nparliament dataset also demonstrated the capacity to extract recognizable\nfeatures from the targets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 01:01:32 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["A\u00efvodji", "Ulrich", ""], ["Gambs", "S\u00e9bastien", ""], ["Ther", "Timon", ""]]}, {"id": "1909.11837", "submitter": "Haoyu Zhao", "authors": "Rong Ge, Runzhe Wang, Haoyu Zhao", "title": "Mildly Overparametrized Neural Nets can Memorize Training Data\n  Efficiently", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been observed \\citep{zhang2016understanding} that deep neural networks\ncan memorize: they achieve 100\\% accuracy on training data. Recent theoretical\nresults explained such behavior in highly overparametrized regimes, where the\nnumber of neurons in each layer is larger than the number of training samples.\nIn this paper, we show that neural networks can be trained to memorize training\ndata perfectly in a mildly overparametrized regime, where the number of\nparameters is just a constant factor more than the number of training samples,\nand the number of neurons is much smaller.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 01:19:21 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Ge", "Rong", ""], ["Wang", "Runzhe", ""], ["Zhao", "Haoyu", ""]]}, {"id": "1909.11839", "submitter": "Sara Hosseinzadeh Kassani", "authors": "Sara Hosseinzadeh Kassani, Peyman Hosseinzadeh Kassani, Michal J.\n  Wesolowski, Kevin A. Schneider, Ralph Deters", "title": "Breast Cancer Diagnosis with Transfer Learning and Global Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is one of the most common causes of cancer-related death in\nwomen worldwide. Early and accurate diagnosis of breast cancer may\nsignificantly increase the survival rate of patients. In this study, we aim to\ndevelop a fully automatic, deep learning-based, method using descriptor\nfeatures extracted by Deep Convolutional Neural Network (DCNN) models and\npooling operation for the classification of hematoxylin and eosin stain (H&E)\nhistological breast cancer images provided as a part of the International\nConference on Image Analysis and Recognition (ICIAR) 2018 Grand Challenge on\nBreAst Cancer Histology (BACH) Images. Different data augmentation methods are\napplied to optimize the DCNN performance. We also investigated the efficacy of\ndifferent stain normalization methods as a pre-processing step. The proposed\nnetwork architecture using a pre-trained Xception model yields 92.50% average\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 01:29:59 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Kassani", "Sara Hosseinzadeh", ""], ["Kassani", "Peyman Hosseinzadeh", ""], ["Wesolowski", "Michal J.", ""], ["Schneider", "Kevin A.", ""], ["Deters", "Ralph", ""]]}, {"id": "1909.11851", "submitter": "Christian Szegedy", "authors": "Dennis Lee, Christian Szegedy, Markus N. Rabe, Sarah M. Loos and\n  Kshitij Bansal", "title": "Mathematical Reasoning in Latent Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and conduct a simple experiment to study whether neural networks\ncan perform several steps of approximate reasoning in a fixed dimensional\nlatent space. The set of rewrites (i.e. transformations) that can be\nsuccessfully performed on a statement represents essential semantic features of\nthe statement. We can compress this information by embedding the formula in a\nvector space, such that the vector associated with a statement can be used to\npredict whether a statement can be rewritten by other theorems. Predicting the\nembedding of a formula generated by some rewrite rule is naturally viewed as\napproximate reasoning in the latent space. In order to measure the\neffectiveness of this reasoning, we perform approximate deduction sequences in\nthe latent space and use the resulting embedding to inform the semantic\nfeatures of the corresponding formal statement (which is obtained by performing\nthe corresponding rewrite sequence using real formulas). Our experiments show\nthat graph neural networks can make non-trivial predictions about the\nrewrite-success of statements, even when they propagate predicted latent\nrepresentations for several steps. Since our corpus of mathematical formulas\nincludes a wide variety of mathematical disciplines, this experiment is a\nstrong indicator for the feasibility of deduction in latent space in general.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 02:33:07 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Lee", "Dennis", ""], ["Szegedy", "Christian", ""], ["Rabe", "Markus N.", ""], ["Loos", "Sarah M.", ""], ["Bansal", "Kshitij", ""]]}, {"id": "1909.11854", "submitter": "Irem Cetin", "authors": "Irem Cetin, Gerard Sanroma, Steffen E. Petersen, Sandy Napel, Oscar\n  Camara, Miguel-Angel Gonzalez Ballester, Karim Lekadir", "title": "A Radiomics Approach to Computer-Aided Diagnosis with Cardiac Cine-MRI", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-75541-0_9", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Use expert visualization or conventional clinical indices can lack accuracy\nfor borderline classications. Advanced statistical approaches based on\neigen-decomposition have been mostly concerned with shape and motion indices.\nIn this paper, we present a new approach to identify CVDs from cine-MRI by\nestimating large pools of radiomic features (statistical, shape and textural\nfeatures) encoding relevant changes in anatomical and image characteristics due\nto CVDs. The calculated cine-MRI radiomic features are assessed using\nsequential forward feature selection to identify the most relevant ones for\ngiven CVD classes (e.g. myocardial infarction, cardiomyopathy, abnormal right\nventricle). Finally, advanced machine learning is applied to suitably integrate\nthe selected radiomics for final multi-feature classification based on Support\nVector Machines (SVMs). The proposed technique was trained and cross-validated\nusing 100 cine-MRI cases corresponding to five different cardiac classes from\nthe ACDC MICCAI 2017 challenge\n\\footnote{https://www.creatis.insa-lyon.fr/Challenge/acdc/index.html}. All\ncases were correctly classified in this preliminary study, indicating potential\nof using large-scale radiomics for MRI-based diagnosis of CVDs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 10:43:51 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Cetin", "Irem", ""], ["Sanroma", "Gerard", ""], ["Petersen", "Steffen E.", ""], ["Napel", "Sandy", ""], ["Camara", "Oscar", ""], ["Ballester", "Miguel-Angel Gonzalez", ""], ["Lekadir", "Karim", ""]]}, {"id": "1909.11855", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Tu Dinh Nguyen and Dinh Phung", "title": "Universal Graph Transformer Self-Attention Networks", "comments": "We have updated the Pytorch and Tensorflow implementation at:\n  https://github.com/daiquocnguyen/Graph-Transformer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transformer self-attention network has been extensively used in research\ndomains such as computer vision, image processing, and natural language\nprocessing. But it has not been actively used in graph neural networks (GNNs)\nwhere constructing an advanced aggregation function is essential. To this end,\nwe present U2GNN, an effective GNN model leveraging a transformer\nself-attention mechanism followed by a recurrent transition, to induce a\npowerful aggregation function to learn graph representations. Experimental\nresults show that the proposed U2GNN achieves state-of-the-art accuracies on\nwell-known benchmark datasets for graph classification. Our code is available\nat: https://github.com/daiquocnguyen/Graph-Transformer\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 02:39:59 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 13:27:35 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 16:47:35 GMT"}, {"version": "v4", "created": "Sat, 29 Feb 2020 02:05:59 GMT"}, {"version": "v5", "created": "Wed, 8 Apr 2020 15:15:35 GMT"}, {"version": "v6", "created": "Thu, 16 Apr 2020 14:46:21 GMT"}, {"version": "v7", "created": "Mon, 29 Jun 2020 10:15:50 GMT"}, {"version": "v8", "created": "Mon, 3 Aug 2020 15:13:44 GMT"}, {"version": "v9", "created": "Fri, 23 Oct 2020 17:39:40 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "1909.11864", "submitter": "Yao Zhu", "authors": "Yao Zhu, Hongzhi Liu, Zhonghai Wu, Yang Song and Tao Zhang", "title": "Representation Learning with Ordered Relation Paths for Knowledge Graph\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incompleteness is a common problem for existing knowledge graphs (KGs), and\nthe completion of KG which aims to predict links between entities is\nchallenging. Most existing KG completion methods only consider the direct\nrelation between nodes and ignore the relation paths which contain useful\ninformation for link prediction. Recently, a few methods take relation paths\ninto consideration but pay less attention to the order of relations in paths\nwhich is important for reasoning. In addition, these path-based models always\nignore nonlinear contributions of path features for link prediction. To solve\nthese problems, we propose a novel KG completion method named OPTransE. Instead\nof embedding both entities of a relation into the same latent space as in\nprevious methods, we project the head entity and the tail entity of each\nrelation into different spaces to guarantee the order of relations in the path.\nMeanwhile, we adopt a pooling strategy to extract nonlinear and complex\nfeatures of different paths to further improve the performance of link\nprediction. Experimental results on two benchmark datasets show that the\nproposed model OPTransE performs better than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 03:07:53 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zhu", "Yao", ""], ["Liu", "Hongzhi", ""], ["Wu", "Zhonghai", ""], ["Song", "Yang", ""], ["Zhang", "Tao", ""]]}, {"id": "1909.11865", "submitter": "Alessandro Fanfarillo", "authors": "Alessandro Fanfarillo, Behrooz Roozitalab, Weiming Hu, Guido Cervone", "title": "Probabilistic Forecasting using Deep Generative Models", "comments": "23 pages, 9 figures, submitted to Computers and Geosciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Analog Ensemble (AnEn) method tries to estimate the probability\ndistribution of the future state of the atmosphere with a set of past\nobservations that correspond to the best analogs of a deterministic Numerical\nWeather Prediction (NWP). This model post-processing method has been\nsuccessfully used to improve the forecast accuracy for several weather-related\napplications including air quality, and short-term wind and solar power\nforecasting, to name a few. In order to provide a meaningful probabilistic\nforecast, the AnEn method requires storing a historical set of past predictions\nand observations in memory for a period of at least several months and spanning\nthe seasons relevant for the prediction of interest. Although the memory and\ncomputing costs of the AnEn method are less expensive than using a brute-force\ndynamical ensemble approach, for a large number of stations and large datasets,\nthe amount of memory required for AnEn can easily become prohibitive.\nFurthermore, in order to find the best analogs associated with a certain\nprediction produced by a NWP model, the current approach requires searching\nover the entire dataset by applying a certain metric. This approach requires\napplying the metric over the entire historical dataset, which may take a\nsubstantial amount of time. In this work, we investigate an alternative way to\nimplement the AnEn method using deep generative models. By doing so, a\ngenerative model can entirely or partially replace the dataset of pairs of\npredictions and observations, reducing the amount of memory required to produce\nthe probabilistic forecast by several orders of magnitude. Furthermore, the\ngenerative model can generate a meaningful set of analogs associated with a\ncertain forecast in constant time without performing any search, saving a\nconsiderable amount of time even in the presence of huge historical datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 03:12:48 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Fanfarillo", "Alessandro", ""], ["Roozitalab", "Behrooz", ""], ["Hu", "Weiming", ""], ["Cervone", "Guido", ""]]}, {"id": "1909.11866", "submitter": "Sara Hosseinzadeh Kassani", "authors": "Sara Hosseinzadeh Kassani, Peyman Hosseinzadeh kassani, Michal J.\n  Wesolowski, Kevin A. Schneider, Ralph Deters", "title": "A Hybrid Deep Learning Architecture for Leukemic B-lymphoblast\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic detection of leukemic B-lymphoblast cancer in microscopic images is\nvery challenging due to the complicated nature of histopathological structures.\nTo tackle this issue, an automatic and robust diagnostic system is required for\nearly detection and treatment. In this paper, an automated deep learning-based\nmethod is proposed to distinguish between immature leukemic blasts and normal\ncells. The proposed deep learning based hybrid method, which is enriched by\ndifferent data augmentation techniques, is able to extract high-level features\nfrom input images. Results demonstrate that the proposed model yields better\nprediction than individual models for Leukemic B-lymphoblast classification\nwith 96.17% overall accuracy, 95.17% sensitivity and 98.58% specificity. Fusing\nthe features extracted from intermediate layers, our approach has the potential\nto improve the overall classification performance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 03:34:24 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Kassani", "Sara Hosseinzadeh", ""], ["kassani", "Peyman Hosseinzadeh", ""], ["Wesolowski", "Michal J.", ""], ["Schneider", "Kevin A.", ""], ["Deters", "Ralph", ""]]}, {"id": "1909.11870", "submitter": "Sara Hosseinzadeh Kassani", "authors": "Sara Hosseinzadeh Kassani, Peyman Hosseinzadeh Kassani, Michal J.\n  Wesolowski, Kevin A. Schneider, Ralph Deters", "title": "Classification of Histopathological Biopsy Images Using Ensemble of Deep\n  Learning Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is one of the leading causes of death across the world in\nwomen. Early diagnosis of this type of cancer is critical for treatment and\npatient care. Computer-aided detection (CAD) systems using convolutional neural\nnetworks (CNN) could assist in the classification of abnormalities. In this\nstudy, we proposed an ensemble deep learning-based approach for automatic\nbinary classification of breast histology images. The proposed ensemble model\nadapts three pre-trained CNNs, namely VGG19, MobileNet, and DenseNet. The\nensemble model is used for the feature representation and extraction steps. The\nextracted features are then fed into a multi-layer perceptron classifier to\ncarry out the classification task. Various pre-processing and CNN tuning\ntechniques such as stain-normalization, data augmentation, hyperparameter\ntuning, and fine-tuning are used to train the model. The proposed method is\nvalidated on four publicly available benchmark datasets, i.e., ICIAR, BreakHis,\nPatchCamelyon, and Bioimaging. The proposed multi-model ensemble method obtains\nbetter predictions than single classifiers and machine learning algorithms with\naccuracies of 98.13%, 95.00%, 94.64% and 83.10% for BreakHis, ICIAR,\nPatchCamelyon and Bioimaging datasets, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 03:57:32 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Kassani", "Sara Hosseinzadeh", ""], ["Kassani", "Peyman Hosseinzadeh", ""], ["Wesolowski", "Michal J.", ""], ["Schneider", "Kevin A.", ""], ["Deters", "Ralph", ""]]}, {"id": "1909.11877", "submitter": "Yaniv Ben-Itzhak", "authors": "Shay Vargaftik, Isaac Keslassy, Ariel Orda, Yaniv Ben-Itzhak", "title": "RADE: Resource-Efficient Supervised Anomaly Detection Using Decision\n  Tree-Based Ensemble Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-tree-based ensemble classification methods (DTEMs) are a prevalent\ntool for supervised anomaly detection. However, due to the continued growth of\ndatasets, DTEMs result in increasing drawbacks such as growing memory\nfootprints, longer training times, and slower classification latencies at lower\nthroughput. In this paper, we present, design, and evaluate RADE - a DTEM-based\nanomaly detection framework that augments standard DTEM classifiers and\nalleviates these drawbacks by relying on two observations: (1) we find that a\nsmall (coarse-grained) DTEM model is sufficient to classify the majority of the\nclassification queries correctly, such that a classification is valid only if\nits corresponding confidence level is greater than or equal to a predetermined\nclassification confidence threshold; (2) we find that in these fewer harder\ncases where our coarse-grained DTEM model results in insufficient confidence in\nits classification, we can improve it by forwarding the classification query to\none of expert DTEM (fine-grained) models, which is explicitly trained for that\nparticular case. We implement RADE in Python based on scikit-learn and evaluate\nit over different DTEM methods: RF, XGBoost, AdaBoost, GBDT and LightGBM, and\nover three publicly available datasets. Our evaluation over both a strong AWS\nEC2 instance and a Raspberry Pi 3 device indicates that RADE offers competitive\nand often superior anomaly detection capabilities as compared to standard DTEM\nmethods, while significantly improving memory footprint (by up to 5.46x),\ntraining-time (by up to 17.2x), and classification latency (by up to 31.2x).\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 04:07:43 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 12:40:58 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Vargaftik", "Shay", ""], ["Keslassy", "Isaac", ""], ["Orda", "Ariel", ""], ["Ben-Itzhak", "Yaniv", ""]]}, {"id": "1909.11886", "submitter": "Youngmoon Jung", "authors": "Youngmoon Jung, Yeunju Choi, Hoirin Kim", "title": "Self-Adaptive Soft Voice Activity Detection using Deep Neural Networks\n  for Robust Speaker Verification", "comments": "Accepted at 2019 IEEE Automatic Speech Recognition and Understanding\n  Workshop (ASRU 2019)", "journal-ref": "Proc. of ASRU 2019, pp. 365-372", "doi": "10.1109/ASRU46091.2019.9003935", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice activity detection (VAD), which classifies frames as speech or\nnon-speech, is an important module in many speech applications including\nspeaker verification. In this paper, we propose a novel method, called\nself-adaptive soft VAD, to incorporate a deep neural network (DNN)-based VAD\ninto a deep speaker embedding system. The proposed method is a combination of\nthe following two approaches. The first approach is soft VAD, which performs a\nsoft selection of frame-level features extracted from a speaker feature\nextractor. The frame-level features are weighted by their corresponding speech\nposteriors estimated from the DNN-based VAD, and then aggregated to generate a\nspeaker embedding. The second approach is self-adaptive VAD, which fine-tunes\nthe pre-trained VAD on the speaker verification data to reduce the domain\nmismatch. Here, we introduce two unsupervised domain adaptation (DA) schemes,\nnamely speech posterior-based DA (SP-DA) and joint learning-based DA (JL-DA).\nExperiments on a Korean speech database demonstrate that the verification\nperformance is improved significantly in real-world environments by using\nself-adaptive soft VAD.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 04:38:01 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Jung", "Youngmoon", ""], ["Choi", "Yeunju", ""], ["Kim", "Hoirin", ""]]}, {"id": "1909.11887", "submitter": "Huitao Shen", "authors": "Huitao Shen, Pengfei Zhang, Yi-Zhuang You, Hui Zhai", "title": "Information Scrambling in Quantum Neural Networks", "comments": "6 pages, 4 figures + 9 pages of supplemental material", "journal-ref": "Phys. Rev. Lett. 124, 200504 (2020)", "doi": "10.1103/PhysRevLett.124.200504", "report-no": null, "categories": "cond-mat.dis-nn cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantum neural network is one of the promising applications for near-term\nnoisy intermediate-scale quantum computers. A quantum neural network distills\nthe information from the input wavefunction into the output qubits. In this\nLetter, we show that this process can also be viewed from the opposite\ndirection: the quantum information in the output qubits is scrambled into the\ninput. This observation motivates us to use the tripartite information, a\nquantity recently developed to characterize information scrambling, to diagnose\nthe training dynamics of quantum neural networks. We empirically find strong\ncorrelation between the dynamical behavior of the tripartite information and\nthe loss function in the training process, from which we identify that the\ntraining process has two stages for randomly initialized networks. In the early\nstage, the network performance improves rapidly and the tripartite information\nincreases linearly with a universal slope, meaning that the neural network\nbecomes less scrambled than the random unitary. In the latter stage, the\nnetwork performance improves slowly while the tripartite information decreases.\nWe present evidences that the network constructs local correlations in the\nearly stage and learns large-scale structures in the latter stage. We believe\nthis two-stage training dynamics is universal and is applicable to a wide range\nof problems. Our work builds bridges between two research subjects of quantum\nneural networks and information scrambling, which opens up a new perspective to\nunderstand quantum neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 04:39:33 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 19:53:25 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 08:50:57 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Shen", "Huitao", ""], ["Zhang", "Pengfei", ""], ["You", "Yi-Zhuang", ""], ["Zhai", "Hui", ""]]}, {"id": "1909.11907", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Shaofeng Zou, Yingbin Liang", "title": "Two Time-scale Off-Policy TD Learning: Non-asymptotic Analysis over\n  Markovian Samples", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based temporal difference (GTD) algorithms are widely used in\noff-policy learning scenarios. Among them, the two time-scale TD with gradient\ncorrection (TDC) algorithm has been shown to have superior performance. In\ncontrast to previous studies that characterized the non-asymptotic convergence\nrate of TDC only under identical and independently distributed (i.i.d.) data\nsamples, we provide the first non-asymptotic convergence analysis for two\ntime-scale TDC under a non-i.i.d.\\ Markovian sample path and linear function\napproximation. We show that the two time-scale TDC can converge as fast as\nO(log t/(t^(2/3))) under diminishing stepsize, and can converge exponentially\nfast under constant stepsize, but at the cost of a non-vanishing error. We\nfurther propose a TDC algorithm with blockwisely diminishing stepsize, and show\nthat it asymptotically converges with an arbitrarily small error at a\nblockwisely linear convergence rate. Our experiments demonstrate that such an\nalgorithm converges as fast as TDC under constant stepsize, and still enjoys\ncomparable accuracy as TDC under diminishing stepsize.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 05:48:16 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Xu", "Tengyu", ""], ["Zou", "Shaofeng", ""], ["Liang", "Yingbin", ""]]}, {"id": "1909.11909", "submitter": "Chang-Le Liu", "authors": "Chang-Le Liu, Sze-Wei Fu, You-Jin Li, Jen-Wei Huang, Hsin-Min Wang, Yu\n  Tsao", "title": "Multichannel Speech Enhancement by Raw Waveform-mapping using Fully\n  Convolutional Networks", "comments": "Accepted to IEEE/ACM Transactions on Audio, Speech and Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, waveform-mapping-based speech enhancement (SE) methods have\ngarnered significant attention. These methods generally use a deep learning\nmodel to directly process and reconstruct speech waveforms. Because both the\ninput and output are in waveform format, the waveform-mapping-based SE methods\ncan overcome the distortion caused by imperfect phase estimation, which may be\nencountered in spectral-mapping-based SE systems. So far, most\nwaveform-mapping-based SE methods have focused on single-channel tasks. In this\npaper, we propose a novel fully convolutional network (FCN) with Sinc and\ndilated convolutional layers (termed SDFCN) for multichannel SE that operates\nin the time domain. We also propose an extended version of SDFCN, called the\nresidual SDFCN (termed rSDFCN). The proposed methods are evaluated on two\nmultichannel SE tasks, namely the dual-channel inner-ear microphones SE task\nand the distributed microphones SE task. The experimental results confirm the\noutstanding denoising capability of the proposed SE systems on both tasks and\nthe benefits of using the residual architecture on the overall SE performance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 05:51:05 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 15:31:27 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 08:47:23 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Liu", "Chang-Le", ""], ["Fu", "Sze-Wei", ""], ["Li", "You-Jin", ""], ["Huang", "Jen-Wei", ""], ["Wang", "Hsin-Min", ""], ["Tsao", "Yu", ""]]}, {"id": "1909.11913", "submitter": "Tong Wu", "authors": "Yue Wang, Tong Wu, Yunlong Wang, Gao Wang", "title": "Enhancing Model Interpretability and Accuracy for Disease Progression\n  Prediction via Phenotype-Based Patient Similarity Learning", "comments": "12 pages, accepted by Pacific Symposium on Biocomputing (PSB) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models have been proposed to extract temporal patterns from longitudinal\nelectronic health records (EHR) for clinical predictive models. However, the\ncommon relations among patients (e.g., receiving the same medical treatments)\nwere rarely considered. In this paper, we propose to learn patient similarity\nfeatures as phenotypes from the aggregated patient-medical service matrix using\nnon-negative matrix factorization. On real-world medical claim data, we show\nthat the learned phenotypes are coherent within each group, and also\nexplanatory and indicative of targeted diseases. We conducted experiments to\npredict the diagnoses for Chronic Lymphocytic Leukemia (CLL) patients. Results\nshow that the phenotype-based similarity features can improve prediction over\nmultiple baselines, including logistic regression, random forest, convolutional\nneural network, and more.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 05:56:33 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Wang", "Yue", ""], ["Wu", "Tong", ""], ["Wang", "Yunlong", ""], ["Wang", "Gao", ""]]}, {"id": "1909.11915", "submitter": "Haseeb Nazki", "authors": "Haseeb Nazki, Sook Yoon, Alvaro Fuentes, Dong Sun Park", "title": "Unsupervised Image Translation using Adversarial Networks for Improved\n  Plant Disease Recognition", "comments": "20 pages, 11 figures, 3 tables, article under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquisition of data in task-specific applications of machine learning like\nplant disease recognition is a costly endeavor owing to the requirements of\nprofessional human diligence and time constraints. In this paper, we present a\nsimple pipeline that uses GANs in an unsupervised image translation environment\nto improve learning with respect to the data distribution in a plant disease\ndataset, reducing the partiality introduced by acute class imbalance and hence\nshifting the classification decision boundary towards better performance. The\nempirical analysis of our method is demonstrated on a limited dataset of 2789\ntomato plant disease images, highly corrupted with an imbalance in the 9\ndisease categories. First, we extend the state of the art for the GAN-based\nimage-to-image translation method by enhancing the perceptual quality of the\ngenerated images and preserving the semantics. We introduce AR-GAN, where in\naddition to the adversarial loss, our synthetic image generator optimizes on\nActivation Reconstruction loss (ARL) function that optimizes feature\nactivations against the natural image. We present visually more compelling\nsynthetic images in comparison to most prominent existing models and evaluate\nthe performance of our GAN framework in terms of various datasets and metrics.\nSecond, we evaluate the performance of a baseline convolutional neural network\nclassifier for improved recognition using the resulting synthetic samples to\naugment our training set and compare it with the classical data augmentation\nscheme. We observe a significant improvement in classification accuracy (+5.2%)\nusing generated synthetic samples as compared to (+0.8%) increase using classic\naugmentation in an equal class distribution environment.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 06:01:42 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Nazki", "Haseeb", ""], ["Yoon", "Sook", ""], ["Fuentes", "Alvaro", ""], ["Park", "Dong Sun", ""]]}, {"id": "1909.11926", "submitter": "Guilin Li", "authors": "Guilin Li, Xing Zhang, Zitong Wang, Matthias Tan, Jiashi Feng, Zhenguo\n  Li, Tong Zhang", "title": "Hierarchical Neural Architecture Search via Operator Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, the efficiency of automatic neural architecture design has been\nsignificantly improved by gradient-based search methods such as DARTS. However,\nrecent literature has brought doubt to the generalization ability of DARTS,\narguing that DARTS performs poorly when the search space is changed, i.e, when\ndifferent set of candidate operators are used. Regularization techniques such\nas early stopping have been proposed to partially solve this problem. In this\npaper, we tackle this problem from a different perspective by identifying two\ncontributing factors to the collapse of DARTS when the search space changes:\n(1) the correlation of similar operators incurs unfavorable competition among\nthem and makes their relative importance score unreliable and (2) the\noptimization complexity gap between the proxy search stage and the final\ntraining. Based on these findings, we propose a new hierarchical search\nalgorithm. With its operator clustering and optimization complexity match, the\nalgorithm can consistently find high-performance architecture across various\nsearch spaces. For all the five variants of the popular cell-based search\nspaces, the proposed algorithm always obtains state-of-the-art architecture\nwith best accuracy on the CIFAR-10, CIFAR-100 and ImageNet over other\nwell-established DARTS-alike algorithms. Code is available at\nhttps://github.com/susan0199/StacNAS.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 06:26:58 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 15:29:40 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 03:20:17 GMT"}, {"version": "v4", "created": "Wed, 11 Dec 2019 03:53:31 GMT"}, {"version": "v5", "created": "Mon, 25 Jan 2021 10:03:07 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Li", "Guilin", ""], ["Zhang", "Xing", ""], ["Wang", "Zitong", ""], ["Tan", "Matthias", ""], ["Feng", "Jiashi", ""], ["Li", "Zhenguo", ""], ["Zhang", "Tong", ""]]}, {"id": "1909.11939", "submitter": "Yannis Flet-Berliac", "authors": "Yannis Flet-Berliac, Philippe Preux", "title": "MERL: Multi-Head Reinforcement Learning", "comments": "Deep Reinforcement Learning Workshop, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common challenge in reinforcement learning is how to convert the agent's\ninteractions with an environment into fast and robust learning. For instance,\nearlier work makes use of domain knowledge to improve existing reinforcement\nlearning algorithms in complex tasks. While promising, previously acquired\nknowledge is often costly and challenging to scale up. Instead, we decide to\nconsider problem knowledge with signals from quantities relevant to solve any\ntask, e.g., self-performance assessment and accurate expectations.\n$\\mathcal{V}^{ex}$ is such a quantity. It is the fraction of variance explained\nby the value function $V$ and measures the discrepancy between $V$ and the\nreturns. Taking advantage of $\\mathcal{V}^{ex}$, we propose MERL, a general\nframework for structuring reinforcement learning by injecting problem knowledge\ninto policy gradient updates. As a result, the agent is not only optimized for\na reward but learns using problem-focused quantities provided by MERL,\napplicable out-of-the-box to any task. In this paper: (a) We introduce and\ndefine MERL, the multi-head reinforcement learning framework we use throughout\nthis work. (b) We conduct experiments across a variety of standard benchmark\nenvironments, including 9 continuous control tasks, where results show improved\nperformance. (c) We demonstrate that MERL also improves transfer learning on a\nset of challenging pixel-based tasks. (d) We ponder how MERL tackles the\nproblem of reward sparsity and better conditions the feature space of\nreinforcement learning agents.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 06:57:51 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 15:31:28 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 12:17:17 GMT"}, {"version": "v4", "created": "Tue, 15 Oct 2019 09:15:11 GMT"}, {"version": "v5", "created": "Fri, 29 Nov 2019 14:24:35 GMT"}, {"version": "v6", "created": "Tue, 31 Mar 2020 07:57:20 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Flet-Berliac", "Yannis", ""], ["Preux", "Philippe", ""]]}, {"id": "1909.11943", "submitter": "Maksims Fiosins", "authors": "Jelena Fiosina, Maksims Fiosins, Stefan Bonn", "title": "Deep Learning and Random Forest-Based Augmentation of sRNA Expression\n  Profiles", "comments": null, "journal-ref": "Lecture Notes in Computer Science, 11490 (2019)", "doi": "10.1007/978-3-030-20242-2_14", "report-no": null, "categories": "q-bio.GN cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of well-structured annotations in a growing amount of RNA expression\ndata complicates data interoperability and reusability. Commonly - used text\nmining methods extract annotations from existing unstructured data descriptions\nand often provide inaccurate output that requires manual curation. Automatic\ndata-based augmentation (generation of annotations on the base of expression\ndata) can considerably improve the annotation quality and has not been\nwell-studied. We formulate an automatic augmentation of small RNA-seq\nexpression data as a classification problem and investigate deep learning (DL)\nand random forest (RF) approaches to solve it. We generate tissue and sex\nannotations from small RNA-seq expression data for tissues and cell lines of\nhomo sapiens. We validate our approach on 4243 annotated small RNA-seq samples\nfrom the Small RNA Expression Atlas (SEA) database. The average prediction\naccuracy for tissue groups is 98% (DL), for tissues - 96.5% (DL), and for sex -\n77% (DL). The \"one dataset out\" average accuracy for tissue group prediction is\n83% (DL) and 59% (RF). On average, DL provides better results as compared to\nRF, and considerably improves classification performance for 'unseen' datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 07:10:03 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Fiosina", "Jelena", ""], ["Fiosins", "Maksims", ""], ["Bonn", "Stefan", ""]]}, {"id": "1909.11946", "submitter": "Palakorn Achananuparp", "authors": "Doyen Sahoo, Wang Hao, Shu Ke, Wu Xiongwei, Hung Le, Palakorn\n  Achananuparp, Ee-Peng Lim, Steven C. H. Hoi", "title": "FoodAI: Food Image Recognition via Deep Learning for Smart Food Logging", "comments": "Published at KDD 2019 (Applied Data Science track). Demo is\n  accessible at https://foodai.org/", "journal-ref": null, "doi": "10.1145/3292500.3330734", "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important aspect of health monitoring is effective logging of food\nconsumption. This can help management of diet-related diseases like obesity,\ndiabetes, and even cardiovascular diseases. Moreover, food logging can help\nfitness enthusiasts, and people who wanting to achieve a target weight.\nHowever, food-logging is cumbersome, and requires not only taking additional\neffort to note down the food item consumed regularly, but also sufficient\nknowledge of the food item consumed (which is difficult due to the availability\nof a wide variety of cuisines). With increasing reliance on smart devices, we\nexploit the convenience offered through the use of smart phones and propose a\nsmart-food logging system: FoodAI, which offers state-of-the-art deep-learning\nbased image recognition capabilities. FoodAI has been developed in Singapore\nand is particularly focused on food items commonly consumed in Singapore.\nFoodAI models were trained on a corpus of 400,000 food images from 756\ndifferent classes. In this paper we present extensive analysis and insights\ninto the development of this system. FoodAI has been deployed as an API service\nand is one of the components powering Healthy 365, a mobile app developed by\nSingapore's Heath Promotion Board. We have over 100 registered organizations\n(universities, companies, start-ups) subscribing to this service and actively\nreceive several API requests a day. FoodAI has made food logging convenient,\naiding smart consumption and a healthy lifestyle.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 07:15:46 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Sahoo", "Doyen", ""], ["Hao", "Wang", ""], ["Ke", "Shu", ""], ["Xiongwei", "Wu", ""], ["Le", "Hung", ""], ["Achananuparp", "Palakorn", ""], ["Lim", "Ee-Peng", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "1909.11953", "submitter": "Sheng Wan", "authors": "Sheng Wan and Chen Gong and Ping Zhong and Shirui Pan and Guangyu Li\n  and Jian Yang", "title": "Hyperspectral Image Classification With Context-Aware Dynamic Graph\n  Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In hyperspectral image (HSI) classification, spatial context has demonstrated\nits significance in achieving promising performance. However, conventional\nspatial context-based methods simply assume that spatially neighboring pixels\nshould correspond to the same land-cover class, so they often fail to correctly\ndiscover the contextual relations among pixels in complex situations, and thus\nleading to imperfect classification results on some irregular or inhomogeneous\nregions such as class boundaries. To address this deficiency, we develop a new\nHSI classification method based on the recently proposed Graph Convolutional\nNetwork (GCN), as it can flexibly encode the relations among arbitrarily\nstructured non-Euclidean data. Different from traditional GCN, there are two\nnovel strategies adopted by our method to further exploit the contextual\nrelations for accurate HSI classification. First, since the receptive field of\ntraditional GCN is often limited to fairly small neighborhood, we proposed to\ncapture long range contextual relations in HSI by performing successive graph\nconvolutions on a learned region-induced graph which is transformed from the\noriginal 2D image grids. Second, we refine the graph edge weight and the\nconnective relationships among image regions by learning the improved adjacency\nmatrix and the 'edge filter', so that the graph can be gradually refined to\nadapt to the representations generated by each graph convolutional layer. Such\nupdated graph will in turn result in accurate region representations, and vice\nversa. The experiments carried out on three real-world benchmark datasets\ndemonstrate that the proposed method yields significant improvement in the\nclassification performance when compared with some state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 07:37:37 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Wan", "Sheng", ""], ["Gong", "Chen", ""], ["Zhong", "Ping", ""], ["Pan", "Shirui", ""], ["Li", "Guangyu", ""], ["Yang", "Jian", ""]]}, {"id": "1909.11956", "submitter": "Maksims Fiosins", "authors": "Jelena Fiosina, Maksims Fiosins, Stefan Bonn", "title": "Explainable Deep Learning for Augmentation of sRNA Expression Profiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of well-structured metadata annotations complicates there-usability\nand interpretation of the growing amount of publicly available RNA expression\ndata. The machine learning-based prediction of metadata(data augmentation) can\nconsiderably improve the quality of expression data annotation. In this\nstudy,we systematically benchmark deep learning (DL) and random forest\n(RF)-based metadata augmentation of tissue, age, and sex using small RNA (sRNA)\nexpression profiles. We use 4243 annotated sRNA-Seq samples from the small RNA\nexpression atlas (SEA) database to train and test the augmentation performance.\nIn general, the DL machine learner outperforms the RF method in almost all\ntested cases. The average cross-validated prediction accuracy of the DL\nalgorithm for tissues is 96.5%, for sex is 77%, and for age is 77.2%. The\naverage tissue prediction accuracy for a completely new dataset is 83.1% (DL)\nand 80.8% (RF). To understand which sRNAs influence DL predictions, we employ\nbackpropagation-based feature importance scores using the DeepLIFT method,\nwhich enable us to obtain information on biological relevance of sRNAs.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 07:42:10 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Fiosina", "Jelena", ""], ["Fiosins", "Maksims", ""], ["Bonn", "Stefan", ""]]}, {"id": "1909.11957", "submitter": "Haoran You", "authors": "Haoran You, Chaojian Li, Pengfei Xu, Yonggan Fu, Yue Wang, Xiaohan\n  Chen, Richard G. Baraniuk, Zhangyang Wang, and Yingyan Lin", "title": "Drawing early-bird tickets: Towards more efficient training of deep\n  networks", "comments": "Accepted as ICLR2020 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Frankle & Carbin, 2019) shows that there exist winning tickets (small but\ncritical subnetworks) for dense, randomly initialized networks, that can be\ntrained alone to achieve comparable accuracies to the latter in a similar\nnumber of iterations. However, the identification of these winning tickets\nstill requires the costly train-prune-retrain process, limiting their practical\nbenefits. In this paper, we discover for the first time that the winning\ntickets can be identified at the very early training stage, which we term as\nearly-bird (EB) tickets, via low-cost training schemes (e.g., early stopping\nand low-precision training) at large learning rates. Our finding of EB tickets\nis consistent with recently reported observations that the key connectivity\npatterns of neural networks emerge early. Furthermore, we propose a mask\ndistance metric that can be used to identify EB tickets with low computational\noverhead, without needing to know the true winning tickets that emerge after\nthe full training. Finally, we leverage the existence of EB tickets and the\nproposed mask distance to develop efficient training methods, which are\nachieved by first identifying EB tickets via low-cost schemes, and then\ncontinuing to train merely the EB tickets towards the target accuracy.\nExperiments based on various deep networks and datasets validate: 1) the\nexistence of EB tickets, and the effectiveness of mask distance in efficiently\nidentifying them; and 2) that the proposed efficient training via EB tickets\ncan achieve up to 4.7x energy savings while maintaining comparable or even\nbetter accuracy, demonstrating a promising and easily adopted method for\ntackling cost-prohibitive deep network training. Code available at\nhttps://github.com/RICE-EIC/Early-Bird-Tickets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 07:43:56 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 05:44:12 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 21:21:44 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 06:12:58 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["You", "Haoran", ""], ["Li", "Chaojian", ""], ["Xu", "Pengfei", ""], ["Fu", "Yonggan", ""], ["Wang", "Yue", ""], ["Chen", "Xiaohan", ""], ["Baraniuk", "Richard G.", ""], ["Wang", "Zhangyang", ""], ["Lin", "Yingyan", ""]]}, {"id": "1909.11968", "submitter": "Ze Yang", "authors": "Ze Yang, Wei Wu, Jian Yang, Can Xu, Zhoujun Li", "title": "Low-Resource Response Generation with Template Prior", "comments": "Accepted by EMNLP2019", "journal-ref": null, "doi": "10.18653/v1/D19-1197", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study open domain response generation with limited message-response pairs.\nThe problem exists in real-world applications but is less explored by the\nexisting work. Since the paired data now is no longer enough to train a neural\ngeneration model, we consider leveraging the large scale of unpaired data that\nare much easier to obtain, and propose response generation with both paired and\nunpaired data. The generation model is defined by an encoder-decoder\narchitecture with templates as prior, where the templates are estimated from\nthe unpaired data as a neural hidden semi-markov model. By this means, response\ngeneration learned from the small paired data can be aided by the semantic and\nsyntactic knowledge in the large unpaired data. To balance the effect of the\nprior and the input message to response generation, we propose learning the\nwhole generation model with an adversarial approach. Empirical studies on\nquestion response generation and sentiment response generation indicate that\nwhen only a few pairs are available, our model can significantly outperform\nseveral state-of-the-art response generation models in terms of both automatic\nand human evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 08:19:34 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 10:00:52 GMT"}, {"version": "v3", "created": "Mon, 30 Dec 2019 02:45:42 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Yang", "Ze", ""], ["Wu", "Wei", ""], ["Yang", "Jian", ""], ["Xu", "Can", ""], ["Li", "Zhoujun", ""]]}, {"id": "1909.11974", "submitter": "Ze Yang", "authors": "Ze Yang, Can Xu, Wei Wu, Zhoujun Li", "title": "Read, Attend and Comment: A Deep Architecture for Automatic News Comment\n  Generation", "comments": "Accepted by EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic news comment generation is a new testbed for techniques of natural\nlanguage generation. In this paper, we propose a \"read-attend-comment\"\nprocedure for news comment generation and formalize the procedure with a\nreading network and a generation network. The reading network comprehends a\nnews article and distills some important points from it, then the generation\nnetwork creates a comment by attending to the extracted discrete points and the\nnews title. We optimize the model in an end-to-end manner by maximizing a\nvariational lower bound of the true objective using the back-propagation\nalgorithm. Experimental results on two datasets indicate that our model can\nsignificantly outperform existing methods in terms of both automatic evaluation\nand human judgment.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 08:34:05 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 06:33:29 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 17:55:14 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Yang", "Ze", ""], ["Xu", "Can", ""], ["Wu", "Wei", ""], ["Li", "Zhoujun", ""]]}, {"id": "1909.11977", "submitter": "Patrik Reizinger", "authors": "Patrik Reizinger, B\\'alint Gyires-T\\'oth", "title": "Stochastic Weight Matrix-based Regularization Methods for Deep Neural\n  Networks", "comments": "Preprint of an LOD 2019 conference paper, 12 pages, 5 figures", "journal-ref": "Springer LNCS. 11943 (2020) 45-57", "doi": "10.1007/978-3-030-37599-7_5", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to introduce two widely applicable regularization\nmethods based on the direct modification of weight matrices. The first method,\nWeight Reinitialization, utilizes a simplified Bayesian assumption with\npartially resetting a sparse subset of the parameters. The second one, Weight\nShuffling, introduces an entropy- and weight distribution-invariant non-white\nnoise to the parameters. The latter can also be interpreted as an ensemble\napproach. The proposed methods are evaluated on benchmark datasets, such as\nMNIST, CIFAR-10 or the JSB Chorales database, and also on time series modeling\ntasks. We report gains both regarding performance and entropy of the analyzed\nnetworks. We also made our code available as a GitHub repository\n(https://github.com/rpatrik96/lod-wmm-2019).\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 08:38:55 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Reizinger", "Patrik", ""], ["Gyires-T\u00f3th", "B\u00e1lint", ""]]}, {"id": "1909.11988", "submitter": "Ahsan Javed Awan Dr", "authors": "Jiaying Yang, Ahsan Javed Awan and Gemma Vall-Llosera", "title": "Support Vector Machines on Noisy Intermediate Scale Quantum Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machine algorithms are considered essential for the\nimplementation of automation in a radio access network. Specifically, they are\ncritical in the prediction of the quality of user experience for video\nstreaming based on device and network-level metrics. Quantum SVM is the quantum\nanalogue of the classical SVM algorithm, which utilizes the properties of\nquantum computers to speed up the algorithm exponentially. In this work, we\nderive an optimized preprocessing unit for a quantum SVM that allows\nclassifying any two-dimensional datasets that are linearly separable. We\nfurther provide a result readout method of the kernel matrix generation circuit\nto avoid quantum tomography that, in turn, reduces the quantum circuit depth.\nWe also derive a quantum SVM system based on an optimized HHL quantum circuit\nwith reduced circuit depth.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 09:10:44 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Yang", "Jiaying", ""], ["Awan", "Ahsan Javed", ""], ["Vall-Llosera", "Gemma", ""]]}, {"id": "1909.12009", "submitter": "Swagata Duari", "authors": "Swagata Duari and Vasudha Bhatnagar", "title": "Complex Network based Supervised Keyword Extractor", "comments": null, "journal-ref": "Expert Systems with Applications, 140, 112876 (2020)", "doi": "10.1016/j.eswa.2019.112876", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a supervised framework for automatic keyword\nextraction from single document. We model the text as complex network, and\nconstruct the feature set by extracting select node properties from it. Several\nnode properties have been exploited by unsupervised, graph-based keyword\nextraction methods to discriminate keywords from non-keywords. We exploit the\ncomplex interplay of node properties to design a supervised keyword extraction\nmethod. The training set is created from the feature set by assigning a label\nto each candidate keyword depending on whether the candidate is listed as a\ngold-standard keyword or not. Since the number of keywords in a document is\nmuch less than non-keywords, the curated training set is naturally imbalanced.\nWe train a binary classifier to predict keywords after balancing the training\nset. The model is trained using two public datasets from scientific domain and\ntested using three unseen scientific corpora and one news corpus. Comparative\nstudy of the results with several recent keyword and keyphrase extraction\nmethods establishes that the proposed method performs better in most cases.\nThis substantiates our claim that graph-theoretic properties of words are\neffective discriminators between keywords and non-keywords. We support our\nargument by showing that the improved performance of the proposed method is\nstatistically significant for all datasets. We also evaluate the effectiveness\nof the pre-trained model on Hindi and Assamese language documents. We observe\nthat the model performs equally well for the cross-language text even though it\nwas trained only on English language documents. This shows that the proposed\nmethod is independent of the domain, collection, and language of the training\ncorpora.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 10:02:07 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Duari", "Swagata", ""], ["Bhatnagar", "Vasudha", ""]]}, {"id": "1909.12028", "submitter": "Samuel Charreyron", "authors": "Ruoxi Yu, Samuel L. Charreyron, Quentin Boehler, Cameron Weibel,\n  Carmen C. Y. Poon and Bradley J. Nelson", "title": "Modeling Electromagnetic Navigation Systems for Medical Applications\n  using Random Forests and Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electromagnetic Navigation Systems (eMNS) can be used to control a variety of\nmultiscale devices within the human body for remote surgery. Accurate modeling\nof the magnetic fields generated by the electromagnets of an eMNS is crucial\nfor the precise control of these devices. Existing methods assume a linear\nbehavior of these systems, leading to significant modeling errors within\nnonlinear regions exhibited at higher magnetic fields. In this paper, we use a\nrandom forest (RF) and an artificial neural network (ANN) to model the\nnonlinear behavior of the magnetic fields generated by an eMNS. Both machine\nlearning methods outperformed the state-of-the-art linear multipole\nelectromagnet method (LMEM). The RF and the ANN model reduced the root mean\nsquared error of the LMEM when predicting the field magnitude by around 40% and\n80%, respectively, over the entire current range of the eMNS. At high current\nregions, especially between 30 and 35 A, the field-magnitude RMSE improvement\nof the ANN model over the LMEM was over 35 mT. This study demonstrates the\nfeasibility of using machine learning methods to model an eMNS for medical\napplications, and its ability to account for complex nonlinear behavior at high\ncurrents. The use of machine learning thus shows promise for improving surgical\nprocedures that use magnetic navigation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 11:05:35 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Yu", "Ruoxi", ""], ["Charreyron", "Samuel L.", ""], ["Boehler", "Quentin", ""], ["Weibel", "Cameron", ""], ["Poon", "Carmen C. Y.", ""], ["Nelson", "Bradley J.", ""]]}, {"id": "1909.12031", "submitter": "Hong Liu", "authors": "Hong Liu and Mingsheng Long and Jianmin Wang and Michael I. Jordan", "title": "Towards Understanding the Transferability of Deep Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks trained on a wide range of datasets demonstrate\nimpressive transferability. Deep features appear general in that they are\napplicable to many datasets and tasks. Such property is in prevalent use in\nreal-world applications. A neural network pretrained on large datasets, such as\nImageNet, can significantly boost generalization and accelerate training if\nfine-tuned to a smaller target dataset. Despite its pervasiveness, few effort\nhas been devoted to uncovering the reason of transferability in deep feature\nrepresentations. This paper tries to understand transferability from the\nperspectives of improved generalization, optimization and the feasibility of\ntransferability. We demonstrate that 1) Transferred models tend to find flatter\nminima, since their weight matrices stay close to the original flat region of\npretrained parameters when transferred to a similar target dataset; 2)\nTransferred representations make the loss landscape more favorable with\nimproved Lipschitzness, which accelerates and stabilizes training\nsubstantially. The improvement largely attributes to the fact that the\nprincipal component of gradient is suppressed in the pretrained parameters,\nthus stabilizing the magnitude of gradient in back-propagation. 3) The\nfeasibility of transferability is related to the similarity of both input and\nlabel. And a surprising discovery is that the feasibility is also impacted by\nthe training stages in that the transferability first increases during\ntraining, and then declines. We further provide a theoretical analysis to\nverify our observations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 11:23:34 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Liu", "Hong", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1909.12035", "submitter": "Moustafa Ebada", "authors": "Moustafa Ebada, Sebastian Cammerer, Ahmed Elkelesh and Stephan ten\n  Brink", "title": "Deep Learning-based Polar Code Design", "comments": "Allerton2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a deep learning-based polar code construction\nalgorithm. The core idea is to represent the information/frozen bit indices of\na polar code as a binary vector which can be interpreted as trainable weights\nof a neural network (NN). For this, we demonstrate how this binary vector can\nbe relaxed to a soft-valued vector, facilitating the learning process through\ngradient descent and enabling an efficient code construction. We further show\nhow different polar code design constraints (e.g., code rate) can be taken into\naccount by means of careful binary-to-soft and soft-to-binary conversions,\nalong with rate-adjustment after each learning iteration. Besides its\nconceptual simplicity, this approach benefits from having the\n\"decoder-in-the-loop\", i.e., the nature of the decoder is inherently taken into\nconsideration while learning (designing) the polar code. We show results for\nbelief propagation (BP) decoding over both AWGN and Rayleigh fading channels\nwith considerable performance gains over state-of-the-art construction schemes.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 11:36:51 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 16:17:37 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ebada", "Moustafa", ""], ["Cammerer", "Sebastian", ""], ["Elkelesh", "Ahmed", ""], ["Brink", "Stephan ten", ""]]}, {"id": "1909.12038", "submitter": "Qimai Li", "authors": "Qimai Li, Xiaotong Zhang, Han Liu, Quanyu Dai, Xiao-Ming Wu", "title": "Dimensionwise Separable 2-D Graph Convolution for Unsupervised and\n  Semi-Supervised Learning on Graphs", "comments": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining (KDD '21)", "journal-ref": null, "doi": "10.1145/3447548.3467413", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCN) have been the model of choice for\ngraph representation learning, which is mainly due to the effective design of\ngraph convolution that computes the representation of a node by aggregating\nthose of its neighbors. However, existing GCN variants commonly use 1-D graph\nconvolution that solely operates on the object link graph without exploring\ninformative relational information among object attributes. This significantly\nlimits their modeling capability and may lead to inferior performance on noisy\nand sparse real-world networks. In this paper, we explore 2-D graph convolution\nto jointly model object links and attribute relations for graph representation\nlearning. Specifically, we propose a computationally efficient dimensionwise\nseparable 2-D graph convolution (DSGC) for filtering node features.\nTheoretically, we show that DSGC can reduce intra-class variance of node\nfeatures on both the object dimension and the attribute dimension to learn more\neffective representations. Empirically, we demonstrate that by modeling\nattribute relations, DSGC achieves significant performance gain over\nstate-of-the-art methods for node classification and clustering on a variety of\nreal-world networks. The source code for reproducing the experimental results\nis available at https://github.com/liqimai/DSGC.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 11:47:54 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 18:19:39 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 16:22:25 GMT"}, {"version": "v4", "created": "Sun, 21 Jun 2020 17:44:03 GMT"}, {"version": "v5", "created": "Wed, 9 Jun 2021 10:33:41 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Li", "Qimai", ""], ["Zhang", "Xiaotong", ""], ["Liu", "Han", ""], ["Dai", "Quanyu", ""], ["Wu", "Xiao-Ming", ""]]}, {"id": "1909.12047", "submitter": "Max Argus", "authors": "Max Argus, Cornelia Schaefer-Prokop, David A. Lynch, Bram van Ginneken", "title": "Function Follows Form: Regression from Complete Thoracic Computed\n  Tomography Scans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chronic Obstructive Pulmonary Disease (COPD) is a leading cause of morbidity\nand mortality. While COPD diagnosis is based on lung function tests, early\nstages and progression of different aspects of the disease can be visible and\nquantitatively assessed on computed tomography (CT) scans. Many studies have\nbeen published that quantify imaging biomarkers related to COPD. In this paper\nwe present a convolutional neural network that directly computes visual\nemphysema scores and predicts the outcome of lung function tests for 195 CT\nscans from the COPDGene study. Contrary to previous work, the proposed method\ndoes not encode any specific prior knowledge about what to quantify, but it is\ntrained end-to-end with a set of 1424 CT scans for which the output parameters\nwere available. The network provided state-of-the-art results for these tasks:\nVisual emphysema scores are comparable to those assessed by trained human\nobservers; COPD diagnosis from estimated lung function reaches an area under\nthe ROC curve of 0.94, outperforming prior art. The method is easily\ngeneralizable to other situations where information from whole scans needs to\nbe summarized in single quantities.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 12:27:52 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 07:13:36 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Argus", "Max", ""], ["Schaefer-Prokop", "Cornelia", ""], ["Lynch", "David A.", ""], ["van Ginneken", "Bram", ""]]}, {"id": "1909.12051", "submitter": "Daniel Gissin", "authors": "Daniel Gissin, Shai Shalev-Shwartz, Amit Daniely", "title": "The Implicit Bias of Depth: How Incremental Learning Drives\n  Generalization", "comments": "25 pages, 7 figures, published at the International Conference on\n  Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A leading hypothesis for the surprising generalization of neural networks is\nthat the dynamics of gradient descent bias the model towards simple solutions,\nby searching through the solution space in an incremental order of complexity.\nWe formally define the notion of incremental learning dynamics and derive the\nconditions on depth and initialization for which this phenomenon arises in deep\nlinear models. Our main theoretical contribution is a dynamical depth\nseparation result, proving that while shallow models can exhibit incremental\nlearning dynamics, they require the initialization to be exponentially small\nfor these dynamics to present themselves. However, once the model becomes\ndeeper, the dependence becomes polynomial and incremental learning can arise in\nmore natural settings. We complement our theoretical findings by experimenting\nwith deep matrix sensing, quadratic neural networks and with binary\nclassification using diagonal and convolutional linear networks, showing all of\nthese models exhibit incremental learning.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 12:38:41 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 10:44:16 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gissin", "Daniel", ""], ["Shalev-Shwartz", "Shai", ""], ["Daniely", "Amit", ""]]}, {"id": "1909.12057", "submitter": "Erik J Bekkers", "authors": "Erik J Bekkers", "title": "B-Spline CNNs on Lie Groups", "comments": "Accepted for publication at ICLR 2020, code available at\n  https://github.com/ebekkers/gsplinets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group convolutional neural networks (G-CNNs) can be used to improve classical\nCNNs by equipping them with the geometric structure of groups. Central in the\nsuccess of G-CNNs is the lifting of feature maps to higher dimensional\ndisentangled representations, in which data characteristics are effectively\nlearned, geometric data-augmentations are made obsolete, and predictable\nbehavior under geometric transformations (equivariance) is guaranteed via group\ntheory. Currently, however, the practical implementations of G-CNNs are limited\nto either discrete groups (that leave the grid intact) or continuous compact\ngroups such as rotations (that enable the use of Fourier theory). In this paper\nwe lift these limitations and propose a modular framework for the design and\nimplementation of G-CNNs for arbitrary Lie groups. In our approach the\ndifferential structure of Lie groups is used to expand convolution kernels in a\ngeneric basis of B-splines that is defined on the Lie algebra. This leads to a\nflexible framework that enables localized, atrous, and deformable convolutions\nin G-CNNs by means of respectively localized, sparse and non-uniform B-spline\nexpansions. The impact and potential of our approach is studied on two\nbenchmark datasets: cancer detection in histopathology slides in which rotation\nequivariance plays a key role and facial landmark localization in which scale\nequivariance is important. In both cases, G-CNN architectures outperform their\nclassical 2D counterparts and the added value of atrous and localized group\nconvolutions is studied in detail.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 12:42:42 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 08:33:36 GMT"}, {"version": "v3", "created": "Tue, 21 Jan 2020 12:53:19 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 08:46:23 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Bekkers", "Erik J", ""]]}, {"id": "1909.12063", "submitter": "Qi Deng", "authors": "Qi Deng", "title": "Artificial Intelligence BlockCloud (AIBC) Technical Whitepaper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AIBC is an Artificial Intelligence and blockchain technology based\nlarge-scale decentralized ecosystem that allows system-wide low-cost sharing of\ncomputing and storage resources. The AIBC consists of four layers: a\nfundamental layer, a resource layer, an application layer, and an ecosystem\nlayer. The AIBC implements a two-consensus scheme to enforce upper-layer\neconomic policies and achieve fundamental layer performance and robustness: the\nDPoEV incentive consensus on the application and resource layers, and the DABFT\ndistributed consensus on the fundamental layer. The DABFT uses deep learning\ntechniques to predict and select the most suitable BFT algorithm in order to\nachieve the best balance of performance, robustness, and security. The DPoEV\nuses the knowledge map algorithm to accurately assess the economic value of\ndigital assets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 12:49:50 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Deng", "Qi", ""]]}, {"id": "1909.12064", "submitter": "Max Horn", "authors": "Max Horn, Michael Moor, Christian Bock, Bastian Rieck, Karsten\n  Borgwardt", "title": "Set Functions for Time Series", "comments": "Accepted at the International Conference on Machine Learning (ICML)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the eminent successes of deep neural networks, many architectures are\noften hard to transfer to irregularly-sampled and asynchronous time series that\ncommonly occur in real-world datasets, especially in healthcare applications.\nThis paper proposes a novel approach for classifying irregularly-sampled time\nseries with unaligned measurements, focusing on high scalability and data\nefficiency. Our method SeFT (Set Functions for Time Series) is based on recent\nadvances in differentiable set function learning, extremely parallelizable with\na beneficial memory footprint, thus scaling well to large datasets of long time\nseries and online monitoring scenarios. Furthermore, our approach permits\nquantifying per-observation contributions to the classification outcome. We\nextensively compare our method with existing algorithms on multiple healthcare\ntime series datasets and demonstrate that it performs competitively whilst\nsignificantly reducing runtime.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 12:52:43 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 15:37:23 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 19:59:49 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Horn", "Max", ""], ["Moor", "Michael", ""], ["Bock", "Christian", ""], ["Rieck", "Bastian", ""], ["Borgwardt", "Karsten", ""]]}, {"id": "1909.12066", "submitter": "Jan Deriu", "authors": "Jan Deriu, Mark Cieliebak", "title": "Towards a Metric for Automated Conversational Dialogue System Evaluation\n  and Improvement", "comments": "8 Pages, To be published at the INLG 2019 converence", "journal-ref": "Proceedings of the 12th International Conference on Natural\n  Language Generation. 2019", "doi": "10.18653/v1/W19-8654", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present \"AutoJudge\", an automated evaluation method for conversational\ndialogue systems. The method works by first generating dialogues based on\nself-talk, i.e. dialogue systems talking to itself. Then, it uses human ratings\non these dialogues to train an automated judgement model. Our experiments show\nthat AutoJudge correlates well with the human ratings and can be used to\nautomatically evaluate dialogue systems, even in deployed systems. In a second\npart, we attempt to apply AutoJudge to improve existing systems. This works\nwell for re-ranking a set of candidate utterances. However, our experiments\nshow that AutoJudge cannot be applied as reward for reinforcement learning,\nalthough the metric can distinguish good from bad dialogues. We discuss\npotential reasons, but state here already that this is still an open question\nfor further research.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 12:55:14 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 08:00:47 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Deriu", "Jan", ""], ["Cieliebak", "Mark", ""]]}, {"id": "1909.12072", "submitter": "Wojciech Samek", "authors": "Wojciech Samek and Klaus-Robert M\\\"uller", "title": "Towards Explainable Artificial Intelligence", "comments": "19 pages", "journal-ref": null, "doi": "10.1007/978-3-030-28954-6_1", "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning (ML) has become a key enabling technology\nfor the sciences and industry. Especially through improvements in methodology,\nthe availability of large databases and increased computational power, today's\nML algorithms are able to achieve excellent performance (at times even\nexceeding the human level) on an increasing number of complex tasks. Deep\nlearning models are at the forefront of this development. However, due to their\nnested non-linear structure, these powerful models have been generally\nconsidered \"black boxes\", not providing any information about what exactly\nmakes them arrive at their predictions. Since in many applications, e.g., in\nthe medical domain, such lack of transparency may be not acceptable, the\ndevelopment of methods for visualizing, explaining and interpreting deep\nlearning models has recently attracted increasing attention. This introductory\npaper presents recent developments and applications in this field and makes a\nplea for a wider use of explainable learning algorithms in practice.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:05:58 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1909.12077", "submitter": "Biswadip Dey", "authors": "Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty", "title": "Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control", "comments": "Published as a Conference Paper at ICLR 2020", "journal-ref": "International Conference on Learning Representations (ICLR 2020);\n  https://openreview.net/forum?id=ryxmb1rKDS", "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Symplectic ODE-Net (SymODEN), a deep learning\nframework which can infer the dynamics of a physical system, given by an\nordinary differential equation (ODE), from observed state trajectories. To\nachieve better generalization with fewer training samples, SymODEN incorporates\nappropriate inductive bias by designing the associated computation graph in a\nphysics-informed manner. In particular, we enforce Hamiltonian dynamics with\ncontrol to learn the underlying dynamics in a transparent way, which can then\nbe leveraged to draw insight about relevant physical aspects of the system,\nsuch as mass and potential energy. In addition, we propose a parametrization\nwhich can enforce this Hamiltonian formalism even when the generalized\ncoordinate data is embedded in a high-dimensional space or we can only access\nvelocity data instead of generalized momentum. This framework, by offering\ninterpretable, physically-consistent models for physical systems, opens up new\npossibilities for synthesizing model-based control strategies.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:13:16 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 16:22:51 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 04:10:53 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 03:02:07 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Zhong", "Yaofeng Desmond", ""], ["Dey", "Biswadip", ""], ["Chakraborty", "Amit", ""]]}, {"id": "1909.12078", "submitter": "Kolyan Ray", "authors": "Kolyan Ray and Botond Szabo", "title": "Debiased Bayesian inference for average treatment effects", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian approaches have become increasingly popular in causal inference\nproblems due to their conceptual simplicity, excellent performance and in-built\nuncertainty quantification ('posterior credible sets'). We investigate Bayesian\ninference for average treatment effects from observational data, which is a\nchallenging problem due to the missing counterfactuals and selection bias.\nWorking in the standard potential outcomes framework, we propose a data-driven\nmodification to an arbitrary (nonparametric) prior based on the propensity\nscore that corrects for the first-order posterior bias, thereby improving\nperformance. We illustrate our method for Gaussian process (GP) priors using\n(semi-)synthetic data. Our experiments demonstrate significant improvement in\nboth estimation accuracy and uncertainty quantification compared to the\nunmodified GP, rendering our approach highly competitive with the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:19:51 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Ray", "Kolyan", ""], ["Szabo", "Botond", ""]]}, {"id": "1909.12083", "submitter": "Marco Cristoforetti", "authors": "L. Coviello, M. Cristoforetti, G. Jurman and C. Furlanello", "title": "In-field grape berries counting for yield estimation using dilated CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital technologies ignited a revolution in the agrifood domain known as\nprecision agriculture: a main question for enabling precision agriculture at\nscale is if accurate product quality control can be made available at minimal\ncost, leveraging existing technologies and agronomists' skills. As a\ncontribution along this direction we demonstrate a tool for accurate fruit\nyield estimation from smartphone cameras, by adapting Deep Learning algorithms\noriginally developed for crowd counting.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:28:53 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Coviello", "L.", ""], ["Cristoforetti", "M.", ""], ["Jurman", "G.", ""], ["Furlanello", "C.", ""]]}, {"id": "1909.12086", "submitter": "Jun Quan", "authors": "Jun Quan, Deyi Xiong, Bonnie Webber and Changjian Hu", "title": "GECOR: An End-to-End Generative Ellipsis and Co-reference Resolution\n  Model for Task-Oriented Dialogue", "comments": "accepted to appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ellipsis and co-reference are common and ubiquitous especially in multi-turn\ndialogues. In this paper, we treat the resolution of ellipsis and co-reference\nin dialogue as a problem of generating omitted or referred expressions from the\ndialogue context. We therefore propose a unified end-to-end Generative Ellipsis\nand CO-reference Resolution model (GECOR) in the context of dialogue. The model\ncan generate a new pragmatically complete user utterance by alternating the\ngeneration and copy mode for each user utterance. A multi-task learning\nframework is further proposed to integrate the GECOR into an end-to-end\ntask-oriented dialogue. In order to train both the GECOR and the multi-task\nlearning framework, we manually construct a new dataset on the basis of the\npublic dataset CamRest676 with both ellipsis and co-reference annotation. On\nthis dataset, intrinsic evaluations on the resolution of ellipsis and\nco-reference show that the GECOR model significantly outperforms the\nsequence-to-sequence (seq2seq) baseline model in terms of EM, BLEU and F1 while\nextrinsic evaluations on the downstream dialogue task demonstrate that our\nmulti-task learning framework with GECOR achieves a higher success rate of task\ncompletion than TSCP, a state-of-the-art end-to-end task-oriented dialogue\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:34:26 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Quan", "Jun", ""], ["Xiong", "Deyi", ""], ["Webber", "Bonnie", ""], ["Hu", "Changjian", ""]]}, {"id": "1909.12098", "submitter": "Gonzalo Mart\\'inez-Mu\\~noz", "authors": "Seyedsaman Emami, Gonzalo Mart\\'inez-Mu\\~noz", "title": "Sequential Training of Neural Networks with Gradient Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel technique based on gradient boosting to train a\nshallow neural network (NN). Gradient boosting is an additive expansion\nalgorithm in which a series of models are trained sequentially to approximate a\ngiven function. A neural network can also be seen as an additive model where\nthe scalar product of the responses of the last hidden layer and its weights\nprovide the final output of the network. Instead of training the network as a\nwhole, the proposed algorithm trains the network sequentially in $T$ steps.\nFirst, the bias term of the network is initialized with a constant\napproximation that minimizes the average loss of the data. Then, at each step,\na portion of the network, composed of $J$ neurons, is trained to approximate\nthe pseudo-residuals on the training data computed from the previous\niterations. Finally, the $T$ partial models and bias are integrated as a single\nNN with $T \\times J$ neurons in the hidden layer. Extensive experiments in\nclassification and regression tasks are carried out showing a competitive\ngeneralization performance with respect to neural networks trained with\ndifferent standard solvers, such as Adam, L-BFGS and SGD. Furthermore, we show\nthat the proposed method design permits to switch off a number of hidden units\nduring test (the units that were last trained) without a significant reduction\nof its generalization ability. This permits the adaptation of the model to\ndifferent classification speed requirements on the fly.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:45:39 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 14:42:37 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Emami", "Seyedsaman", ""], ["Mart\u00ednez-Mu\u00f1oz", "Gonzalo", ""]]}, {"id": "1909.12108", "submitter": "Avraam Chatzimichailidis", "authors": "Avraam Chatzimichailidis, Franz-Josef Pfreundt, Nicolas R. Gauger,\n  Janis Keuper", "title": "GradVis: Visualization and Second Order Analysis of Optimization\n  Surfaces during the Training of Deep Neural Networks", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current training methods for deep neural networks boil down to very high\ndimensional and non-convex optimization problems which are usually solved by a\nwide range of stochastic gradient descent methods. While these approaches tend\nto work in practice, there are still many gaps in the theoretical understanding\nof key aspects like convergence and generalization guarantees, which are\ninduced by the properties of the optimization surface (loss landscape). In\norder to gain deeper insights, a number of recent publications proposed methods\nto visualize and analyze the optimization surfaces. However, the computational\ncost of these methods are very high, making it hardly possible to use them on\nlarger networks.\n  In this paper, we present the GradVis Toolbox, an open source library for\nefficient and scalable visualization and analysis of deep neural network loss\nlandscapes in Tensorflow and PyTorch. Introducing more efficient mathematical\nformulations and a novel parallelization scheme, GradVis allows to plot 2d and\n3d projections of optimization surfaces and trajectories, as well as high\nresolution second order gradient information for large networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:55:12 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 09:45:59 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Chatzimichailidis", "Avraam", ""], ["Pfreundt", "Franz-Josef", ""], ["Gauger", "Nicolas R.", ""], ["Keuper", "Janis", ""]]}, {"id": "1909.12111", "submitter": "Jianhang Zhou", "authors": "Jianhang Zhou, Shaoning Zeng, Bob Zhang", "title": "Two-stage Image Classification Supervised by a Single Teacher Single\n  Student Model", "comments": "Accepted by 30th British Machine Vision Conference (BMVC2019)", "journal-ref": null, "doi": null, "report-no": "#155", "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two-stage strategy has been widely used in image classification. However,\nthese methods barely take the classification criteria of the first stage into\nconsideration in the second prediction stage. In this paper, we propose a novel\ntwo-stage representation method (TSR), and convert it to a Single-Teacher\nSingle-Student (STSS) problem in our two-stage image classification framework.\nWe seek the nearest neighbours of the test sample to choose candidate target\nclasses. Meanwhile, the first stage classifier is formulated as the teacher,\nwhich holds the classification scores. The samples of the candidate classes are\nutilized to learn a student classifier based on L2-minimization in the second\nstage. The student will be supervised by the teacher classifier, which approves\nthe student only if it obtains a higher score. In actuality, the proposed\nframework generates a stronger classifier by staging two weaker classifiers in\na novel way. The experiments conducted on several face and object databases\nshow that our proposed framework is effective and outperforms multiple popular\nclassification methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 13:59:34 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zhou", "Jianhang", ""], ["Zeng", "Shaoning", ""], ["Zhang", "Bob", ""]]}, {"id": "1909.12114", "submitter": "Leila Arras", "authors": "Leila Arras, Jose A. Arjona-Medina, Michael Widrich, Gr\\'egoire\n  Montavon, Michael Gillhofer, Klaus-Robert M\\\"uller, Sepp Hochreiter and\n  Wojciech Samek", "title": "Explaining and Interpreting LSTMs", "comments": "28 pages, 7 figures, book chapter, In: Explainable AI: Interpreting,\n  Explaining and Visualizing Deep Learning, LNCS volume 11700, Springer 2019.\n  arXiv admin note: text overlap with arXiv:1806.07857", "journal-ref": null, "doi": "10.1007/978-3-030-28954-6_11", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks have acted as a strong unifying force in the design of\nmodern AI systems, the neural network architectures themselves remain highly\nheterogeneous due to the variety of tasks to be solved. In this chapter, we\nexplore how to adapt the Layer-wise Relevance Propagation (LRP) technique used\nfor explaining the predictions of feed-forward networks to the LSTM\narchitecture used for sequential data modeling and forecasting. The special\naccumulators and gated interactions present in the LSTM require both a new\npropagation scheme and an extension of the underlying theoretical framework to\ndeliver faithful explanations.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 11:45:43 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Arras", "Leila", ""], ["Arjona-Medina", "Jose A.", ""], ["Widrich", "Michael", ""], ["Montavon", "Gr\u00e9goire", ""], ["Gillhofer", "Michael", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Hochreiter", "Sepp", ""], ["Samek", "Wojciech", ""]]}, {"id": "1909.12116", "submitter": "Jong Chul Ye", "authors": "Byeongsu Sim, Gyutaek Oh, Jeongsol Kim, Chanyong Jung, Jong Chul Ye", "title": "Optimal Transport driven CycleGAN for Unsupervised Learning in Inverse\n  Problems", "comments": "accepted for publication in the SIAM Journal on Imaging Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the performance of classical generative adversarial network (GAN),\nWasserstein generative adversarial networks (W-GAN) was developed as a\nKantorovich dual formulation of the optimal transport (OT) problem using\nWasserstein-1 distance. However, it was not clear how cycleGAN-type generative\nmodels can be derived from the optimal transport theory. Here we show that a\nnovel cycleGAN architecture can be derived as a Kantorovich dual OT formulation\nif a penalized least square (PLS) cost with deep learning-based inverse path\npenalty is used as a transportation cost. One of the most important advantages\nof this formulation is that depending on the knowledge of the forward problem,\ndistinct variations of cycleGAN architecture can be derived: for example, one\nwith two pairs of generators and discriminators, and the other with only a\nsingle pair of generator and discriminator. Even for the two generator cases,\nwe show that the structural knowledge of the forward operator can lead to a\nsimpler generator architecture which significantly simplifies the neural\nnetwork training. The new cycleGAN formulation, what we call the OT-cycleGAN,\nhave been applied for various biomedical imaging problems, such as accelerated\nmagnetic resonance imaging (MRI), super-resolution microscopy, and low-dose\nx-ray computed tomography (CT). Experimental results confirm the efficacy and\nflexibility of the theory.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 11:28:49 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 13:59:39 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 16:28:14 GMT"}, {"version": "v4", "created": "Sun, 30 Aug 2020 12:14:48 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Sim", "Byeongsu", ""], ["Oh", "Gyutaek", ""], ["Kim", "Jeongsol", ""], ["Jung", "Chanyong", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1909.12120", "submitter": "Eren Balevi", "authors": "Eren Balevi and Jeffrey G. Andrews", "title": "Autoencoder-Based Error Correction Coding for One-Bit Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel deep learning-based error correction coding\nscheme for AWGN channels under the constraint of one-bit quantization in the\nreceivers. Specifically, it is first shown that the optimum error correction\ncode that minimizes the probability of bit error can be obtained by perfectly\ntraining a special autoencoder, in which \"perfectly\" refers to converging the\nglobal minima. However, perfect training is not possible in most cases. To\napproach the performance of a perfectly trained autoencoder with a suboptimum\ntraining, we propose utilizing turbo codes as an implicit regularization, i.e.,\nusing a concatenation of a turbo code and an autoencoder. It is empirically\nshown that this design gives nearly the same performance as to the\nhypothetically perfectly trained autoencoder, and we also provide a theoretical\nproof of why that is so. The proposed coding method is as bandwidth efficient\nas the integrated (outer) turbo code, since the autoencoder exploits the excess\nbandwidth from pulse shaping and packs signals more intelligently thanks to\nsparsity in neural networks. Our results show that the proposed coding scheme\nat finite block lengths outperforms conventional turbo codes even for QPSK\nmodulation. Furthermore, the proposed coding method can make one-bit\nquantization operational even for 16-QAM.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:57:13 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Balevi", "Eren", ""], ["Andrews", "Jeffrey G.", ""]]}, {"id": "1909.12122", "submitter": "Kostas Hatalis", "authors": "Kostas Hatalis, Alberto J. Lamadrid, Katya Scheinberg, Shalinee\n  Kishore", "title": "A Novel Smoothed Loss and Penalty Function for Noncrossing Composite\n  Quantile Estimation via Deep Neural Networks", "comments": "12 pages, IEEE Transactions Journal format. arXiv admin note:\n  substantial text overlap with arXiv:1710.01720", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty analysis in the form of probabilistic forecasting can\nsignificantly improve decision making processes in the smart power grid when\nintegrating renewable energy sources such as wind. Whereas point forecasting\nprovides a single expected value, probabilistic forecasts provide more\ninformation in the form of quantiles, prediction intervals, or full predictive\ndensities. Traditionally quantile regression is applied for such forecasting\nand recently quantile regression neural networks have become popular for\nweather and renewable energy forecasting. However, one major shortcoming of\ncomposite quantile estimation in neural networks is the quantile crossover\nproblem. This paper analyzes the effectiveness of a novel smoothed loss and\npenalty function for neural network architectures to prevent the quantile\ncrossover problem. Its efficacy is examined on the wind power forecasting\nproblem. A numerical case study is conducted using publicly available wind data\nfrom the Global Energy Forecasting Competition 2014. Multiple quantiles are\nestimated to form 10\\%, to 90\\% prediction intervals which are evaluated using\na quantile score and reliability measures. Benchmark models such as the\npersistence and climatology distributions, multiple quantile regression, and\nsupport vector quantile regression are used for comparison where results\ndemonstrate the proposed approach leads to improved performance while\npreventing the problem of overlapping quantile estimates.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 21:22:09 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Hatalis", "Kostas", ""], ["Lamadrid", "Alberto J.", ""], ["Scheinberg", "Katya", ""], ["Kishore", "Shalinee", ""]]}, {"id": "1909.12127", "submitter": "Oleksandr Shchur", "authors": "Oleksandr Shchur, Marin Bilo\\v{s}, Stephan G\\\"unnemann", "title": "Intensity-Free Learning of Temporal Point Processes", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal point processes are the dominant paradigm for modeling sequences of\nevents happening at irregular intervals. The standard way of learning in such\nmodels is by estimating the conditional intensity function. However,\nparameterizing the intensity function usually incurs several trade-offs. We\nshow how to overcome the limitations of intensity-based approaches by directly\nmodeling the conditional distribution of inter-event times. We draw on the\nliterature on normalizing flows to design models that are flexible and\nefficient. We additionally propose a simple mixture model that matches the\nflexibility of flow-based models, but also permits sampling and computing\nmoments in closed form. The proposed models achieve state-of-the-art\nperformance in standard prediction tasks and are suitable for novel\napplications, such as learning sequence embeddings and imputing missing data.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 14:11:55 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 10:06:02 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Shchur", "Oleksandr", ""], ["Bilo\u0161", "Marin", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1909.12153", "submitter": "Andreas Folkers", "authors": "Andreas Folkers, Matthias Rick, Christof B\\\"uskens", "title": "Controlling an Autonomous Vehicle with Deep Reinforcement Learning", "comments": "Award as Best Student Paper at IEEE Intelligent Vehicles Symposium\n  (IV), 2019", "journal-ref": null, "doi": "10.1109/IVS.2019.8814124", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a control approach for autonomous vehicles based on deep\nreinforcement learning. A neural network agent is trained to map its estimated\nstate to acceleration and steering commands given the objective of reaching a\nspecific target state while considering detected obstacles. Learning is\nperformed using state-of-the-art proximal policy optimization in combination\nwith a simulated environment. Training from scratch takes five to nine hours.\nThe resulting agent is evaluated within simulation and subsequently applied to\ncontrol a full-size research vehicle. For this, the autonomous exploration of a\nparking lot is considered, including turning maneuvers and obstacle avoidance.\nAltogether, this work is among the first examples to successfully apply deep\nreinforcement learning to a real vehicle.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 06:24:23 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 08:55:20 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Folkers", "Andreas", ""], ["Rick", "Matthias", ""], ["B\u00fcskens", "Christof", ""]]}, {"id": "1909.12160", "submitter": "Mohamad Dia", "authors": "Mohamad Dia, Elodie Savary, Martin Melchior, Frederic Courbin", "title": "Galaxy Image Simulation Using Progressive GANs", "comments": "Submitted to the Astronomical Data Analysis Software & Systems\n  Conference (ADASS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.GA eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide an efficient and realistic data-driven approach to\nsimulate astronomical images using deep generative models from machine\nlearning. Our solution is based on a variant of the generative adversarial\nnetwork (GAN) with progressive training methodology and Wasserstein cost\nfunction. The proposed solution generates naturalistic images of galaxies that\nshow complex structures and high diversity, which suggests that data-driven\nsimulations using machine learning can replace many of the expensive\nmodel-driven methods used in astronomical data processing.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 14:44:27 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Dia", "Mohamad", ""], ["Savary", "Elodie", ""], ["Melchior", "Martin", ""], ["Courbin", "Frederic", ""]]}, {"id": "1909.12176", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou", "title": "Randomized Iterative Methods for Linear Systems: Momentum, Inexactness\n  and Gossip", "comments": "PhD Thesis, University of Edinburgh, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, one of the key challenges is the development of novel\noptimization algorithms that can accommodate vast amounts of data while at the\nsame time satisfying constraints and limitations of the problem under study.\nThe need to solve optimization problems is ubiquitous in essentially all\nquantitative areas of human endeavor, including industry and science. In the\nlast decade there has been a surge in the demand from practitioners, in fields\nsuch as machine learning, computer vision, artificial intelligence, signal\nprocessing and data science, for new methods able to cope with these new large\nscale problems.\n  In this thesis we are focusing on the design, complexity analysis and\nefficient implementations of such algorithms. In particular, we are interested\nin the development of randomized iterative methods for solving large scale\nlinear systems, stochastic quadratic optimization problems, the best\napproximation problem and quadratic optimization problems. A large part of the\nthesis is also devoted to the development of efficient methods for obtaining\naverage consensus on large scale networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:15:22 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Loizou", "Nicolas", ""]]}, {"id": "1909.12180", "submitter": "Alexander Meinke", "authors": "Alexander Meinke, Matthias Hein", "title": "Towards neural networks that provably know when they don't know", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been shown that ReLU networks produce arbitrarily\nover-confident predictions far away from the training data. Thus, ReLU networks\ndo not know when they don't know. However, this is a highly important property\nin safety critical applications. In the context of out-of-distribution\ndetection (OOD) there have been a number of proposals to mitigate this problem\nbut none of them are able to make any mathematical guarantees. In this paper we\npropose a new approach to OOD which overcomes both problems. Our approach can\nbe used with ReLU networks and provides provably low confidence predictions far\naway from the training data as well as the first certificates for low\nconfidence predictions in a neighborhood of an out-distribution point. In the\nexperiments we show that state-of-the-art methods fail in this worst-case\nsetting whereas our model can guarantee its performance while retaining\nstate-of-the-art OOD performance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:20:08 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 09:27:11 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Meinke", "Alexander", ""], ["Hein", "Matthias", ""]]}, {"id": "1909.12185", "submitter": "Regis Albuquerque", "authors": "Regis Antonio Saraiva Albuquerque, Albert Franca Josua Costa, Eulanda\n  Miranda dos Santos, Robert Sabourin and Rafael Giusti", "title": "A Decision-Based Dynamic Ensemble Selection Method for Concept Drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online method for concept driftdetection based on dynamic\nclassifier ensemble selection. Theproposed method generates a pool of ensembles\nby promotingdiversity among classifier members and chooses expert\nensemblesaccording to global prequential accuracy values. Unlike currentdynamic\nensemble selection approaches that use only local knowl-edge to select the most\ncompetent ensemble for each instance,our method focuses on selection taking\ninto account the decisionspace. Consequently, it is well adapted to the context\nof driftdetection in data stream problems. The results of the experimentsshow\nthat the proposed method attained the highest detection pre-cision and the\nlowest number of false alarms, besides competitiveclassification accuracy\nrates, in artificial datasets representingdifferent types of drifts. Moreover,\nit outperformed baselines indifferent real-problem datasets in terms of\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:22:18 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Albuquerque", "Regis Antonio Saraiva", ""], ["Costa", "Albert Franca Josua", ""], ["Santos", "Eulanda Miranda dos", ""], ["Sabourin", "Robert", ""], ["Giusti", "Rafael", ""]]}, {"id": "1909.12196", "submitter": "Jochen Gast", "authors": "Jochen Gast and Stefan Roth", "title": "Deep Video Deblurring: The Devil is in the Details", "comments": "To appear at ICCVW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video deblurring for hand-held cameras is a challenging task, since the\nunderlying blur is caused by both camera shake and object motion.\nState-of-the-art deep networks exploit temporal information from neighboring\nframes, either by means of spatio-temporal transformers or by recurrent\narchitectures. In contrast to these involved models, we found that a simple\nbaseline CNN can perform astonishingly well when particular care is taken\nw.r.t. the details of model and training procedure. To that end, we conduct a\ncomprehensive study regarding these crucial details, uncovering extreme\ndifferences in quantitative and qualitative performance. Exploiting these\ndetails allows us to boost the architecture and training procedure of a simple\nbaseline CNN by a staggering 3.15dB, such that it becomes highly competitive\nw.r.t. cutting-edge networks. This raises the question whether the reported\naccuracy difference between models is always due to technical contributions or\nalso subject to such orthogonal, but crucial details.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:35:29 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Gast", "Jochen", ""], ["Roth", "Stefan", ""]]}, {"id": "1909.12200", "submitter": "Serkan Cabi", "authors": "Serkan Cabi, Sergio G\\'omez Colmenarejo, Alexander Novikov, Ksenia\n  Konyushkova, Scott Reed, Rae Jeong, Konrad Zolna, Yusuf Aytar, David Budden,\n  Mel Vecerik, Oleg Sushkov, David Barker, Jonathan Scholz, Misha Denil, Nando\n  de Freitas, Ziyu Wang", "title": "Scaling data-driven robotics with reward sketching and batch\n  reinforcement learning", "comments": "Project website: https://sites.google.com/view/data-driven-robotics/", "journal-ref": "Robotics: Science and Systems Conference 2020", "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for data-driven robotics that makes use of a large\ndataset of recorded robot experience and scales to several tasks using learned\nreward functions. We show how to apply this framework to accomplish three\ndifferent object manipulation tasks on a real robot platform. Given\ndemonstrations of a task together with task-agnostic recorded experience, we\nuse a special form of human annotation as supervision to learn a reward\nfunction, which enables us to deal with real-world tasks where the reward\nsignal cannot be acquired directly. Learned rewards are used in combination\nwith a large dataset of experience from different tasks to learn a robot policy\noffline using batch RL. We show that using our approach it is possible to train\nagents to perform a variety of challenging manipulation tasks including\nstacking rigid objects and handling cloth.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:45:23 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 15:17:05 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 11:00:06 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Cabi", "Serkan", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Novikov", "Alexander", ""], ["Konyushkova", "Ksenia", ""], ["Reed", "Scott", ""], ["Jeong", "Rae", ""], ["Zolna", "Konrad", ""], ["Aytar", "Yusuf", ""], ["Budden", "David", ""], ["Vecerik", "Mel", ""], ["Sushkov", "Oleg", ""], ["Barker", "David", ""], ["Scholz", "Jonathan", ""], ["Denil", "Misha", ""], ["de Freitas", "Nando", ""], ["Wang", "Ziyu", ""]]}, {"id": "1909.12201", "submitter": "Oleksandr Shchur", "authors": "Oleksandr Shchur, Stephan G\\\"unnemann", "title": "Overlapping Community Detection with Graph Neural Networks", "comments": "The First International Workshop on Deep Learning on Graphs (In\n  Conjunction with the 25th ACM SIGKDD Conference on Knowledge Discovery and\n  Data Mining) https://dlg2019.bitbucket.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is a fundamental problem in machine learning. While deep\nlearning has shown great promise in many graphrelated tasks, developing neural\nmodels for community detection has received surprisingly little attention. The\nfew existing approaches focus on detecting disjoint communities, even though\ncommunities in real graphs are well known to be overlapping. We address this\nshortcoming and propose a graph neural network (GNN) based model for\noverlapping community detection. Despite its simplicity, our model outperforms\nthe existing baselines by a large margin in the task of community recovery. We\nestablish through an extensive experimental evaluation that the proposed model\nis effective, scalable and robust to hyperparameter settings. We also perform\nan ablation study that confirms that GNN is the key ingredient to the power of\nthe proposed model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:45:39 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Shchur", "Oleksandr", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1909.12205", "submitter": "Vahid Partovi Nia", "authors": "Gr\\'egoire Morin, Ryan Razani, Vahid Partovi Nia, and Eyy\\\"ub Sari", "title": "Smart Ternary Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models are resource hungry. Low bit quantization such as\nbinary and ternary quantization is a common approach to alleviate this resource\nrequirements. Ternary quantization provides a more flexible model and often\nbeats binary quantization in terms of accuracy, but doubles memory and\nincreases computation cost. Mixed quantization depth models, on another hand,\nallows a trade-off between accuracy and memory footprint. In such models,\nquantization depth is often chosen manually (which is a tiring task), or is\ntuned using a separate optimization routine (which requires training a\nquantized network multiple times). Here, we propose Smart Ternary Quantization\n(STQ) in which we modify the quantization depth directly through an adaptive\nregularization function, so that we train a model only once. This method jumps\nbetween binary and ternary quantization while training. We show its application\non image classification.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 15:49:08 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Morin", "Gr\u00e9goire", ""], ["Razani", "Ryan", ""], ["Nia", "Vahid Partovi", ""], ["Sari", "Eyy\u00fcb", ""]]}, {"id": "1909.12217", "submitter": "Amir Ehsan Niaraki Asli", "authors": "Amir Niaraki, Jeremy Roghair, Ali Jannesari", "title": "Visual Exploration and Energy-aware Path Planning via Reinforcement\n  Learning", "comments": "20 Pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual exploration and smart data collection via autonomous vehicles is an\nattractive topic in various disciplines. Disturbances like wind significantly\ninfluence both the power consumption of the flying robots and the performance\nof the camera. We propose a reinforcement learning approach which combines the\neffects of the power consumption and the object detection modules to develop a\npolicy for object detection in large areas with limited battery life. The\nlearning model enables dynamic learning of the negative rewards of each action\nbased on the drag forces that is resulted by the motion of the flying robot\nwith respect to the wind field. The algorithm is implemented in a near-real\nworld simulation environment both for the planar motion and flight in different\naltitudes. The trained agent often performed a trade-off between detecting the\nobjects with high accuracy and increasing the area coverage within its battery\nlife. The developed exploration policy outperformed the complete coverage\nalgorithm by minimizing the traveled path while finding the target objects. The\nperformance of the algorithms under various wind fields was evaluated in planar\nand 3D motion. During an exploration task with sparsely distributed goals and\nwithin a UAV's battery life, the proposed architecture could detect more than\ntwice the amount of goal objects compared to the coverage path planning\nalgorithm in moderate wind field. In high wind intensities, the energy-aware\nalgorithm could detect 4 times the amount of goal objects when compared to its\ncomplete coverage counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:15:37 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 17:40:34 GMT"}, {"version": "v3", "created": "Sat, 9 Jan 2021 00:42:43 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 21:19:51 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Niaraki", "Amir", ""], ["Roghair", "Jeremy", ""], ["Jannesari", "Ali", ""]]}, {"id": "1909.12220", "submitter": "Yulin Wang", "authors": "Yulin Wang, Xuran Pan, Shiji Song, Hong Zhang, Cheng Wu, Gao Huang", "title": "Implicit Semantic Data Augmentation for Deep Networks", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel implicit semantic data augmentation (ISDA)\napproach to complement traditional augmentation techniques like flipping,\ntranslation or rotation. Our work is motivated by the intriguing property that\ndeep networks are surprisingly good at linearizing features, such that certain\ndirections in the deep feature space correspond to meaningful semantic\ntransformations, e.g., adding sunglasses or changing backgrounds. As a\nconsequence, translating training samples along many semantic directions in the\nfeature space can effectively augment the dataset to improve generalization. To\nimplement this idea effectively and efficiently, we first perform an online\nestimate of the covariance matrix of deep features for each class, which\ncaptures the intra-class semantic variations. Then random vectors are drawn\nfrom a zero-mean normal distribution with the estimated covariance to augment\nthe training data in that class. Importantly, instead of augmenting the samples\nexplicitly, we can directly minimize an upper bound of the expected\ncross-entropy (CE) loss on the augmented training set, leading to a highly\nefficient algorithm. In fact, we show that the proposed ISDA amounts to\nminimizing a novel robust CE loss, which adds negligible extra computational\ncost to a normal training procedure. Although being simple, ISDA consistently\nimproves the generalization performance of popular deep models (ResNets and\nDenseNets) on a variety of datasets, e.g., CIFAR-10, CIFAR-100 and ImageNet.\nCode for reproducing our results is available at\nhttps://github.com/blackfeather-wang/ISDA-for-Deep-Networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:17:45 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 04:57:35 GMT"}, {"version": "v3", "created": "Sun, 24 Nov 2019 13:56:17 GMT"}, {"version": "v4", "created": "Fri, 20 Dec 2019 10:11:01 GMT"}, {"version": "v5", "created": "Sat, 25 Apr 2020 03:13:03 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Yulin", ""], ["Pan", "Xuran", ""], ["Song", "Shiji", ""], ["Zhang", "Hong", ""], ["Wu", "Cheng", ""], ["Huang", "Gao", ""]]}, {"id": "1909.12223", "submitter": "Lingxiao Zhao", "authors": "Lingxiao Zhao, Leman Akoglu", "title": "PairNorm: Tackling Oversmoothing in GNNs", "comments": "ICLR 2020 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of graph neural nets (GNNs) is known to gradually decrease\nwith increasing number of layers. This decay is partly attributed to\noversmoothing, where repeated graph convolutions eventually make node\nembeddings indistinguishable. We take a closer look at two different\ninterpretations, aiming to quantify oversmoothing. Our main contribution is\nPairNorm, a novel normalization layer that is based on a careful analysis of\nthe graph convolution operator, which prevents all node embeddings from\nbecoming too similar. What is more, PairNorm is fast, easy to implement without\nany change to network architecture nor any additional parameters, and is\nbroadly applicable to any GNN. Experiments on real-world graphs demonstrate\nthat PairNorm makes deeper GCN, GAT, and SGC models more robust against\noversmoothing, and significantly boosts performance for a new problem setting\nthat benefits from deeper GNNs. Code is available at\nhttps://github.com/LingxiaoShawn/PairNorm.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:20:37 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 02:27:25 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Zhao", "Lingxiao", ""], ["Akoglu", "Leman", ""]]}, {"id": "1909.12224", "submitter": "Zhixin Piao", "authors": "Wen Liu, Zhixin Piao, Jie Min, Wenhan Luo, Lin Ma, Shenghua Gao", "title": "Liquid Warping GAN: A Unified Framework for Human Motion Imitation,\n  Appearance Transfer and Novel View Synthesis", "comments": "accepted by ICCV2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the human motion imitation, appearance transfer, and novel view\nsynthesis within a unified framework, which means that the model once being\ntrained can be used to handle all these tasks. The existing task-specific\nmethods mainly use 2D keypoints (pose) to estimate the human body structure.\nHowever, they only expresses the position information with no abilities to\ncharacterize the personalized shape of the individual person and model the\nlimbs rotations. In this paper, we propose to use a 3D body mesh recovery\nmodule to disentangle the pose and shape, which can not only model the joint\nlocation and rotation but also characterize the personalized body shape. To\npreserve the source information, such as texture, style, color, and face\nidentity, we propose a Liquid Warping GAN with Liquid Warping Block (LWB) that\npropagates the source information in both image and feature spaces, and\nsynthesizes an image with respect to the reference. Specifically, the source\nfeatures are extracted by a denoising convolutional auto-encoder for\ncharacterizing the source identity well. Furthermore, our proposed method is\nable to support a more flexible warping from multiple sources. In addition, we\nbuild a new dataset, namely Impersonator (iPER) dataset, for the evaluation of\nhuman motion imitation, appearance transfer, and novel view synthesis.\nExtensive experiments demonstrate the effectiveness of our method in several\naspects, such as robustness in occlusion case and preserving face identity,\nshape consistency and clothes details. All codes and datasets are available on\nhttps://svip-lab.github.io/project/impersonator.html\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:23:59 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 14:52:32 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 16:42:27 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Liu", "Wen", ""], ["Piao", "Zhixin", ""], ["Min", "Jie", ""], ["Luo", "Wenhan", ""], ["Ma", "Lin", ""], ["Gao", "Shenghua", ""]]}, {"id": "1909.12226", "submitter": "Wei Hao Khoong", "authors": "Wei Hao Khoong", "title": "A Heuristic for Efficient Reduction in Hidden Layer Combinations For\n  Feedforward Neural Networks", "comments": "To appear in the proceedings of the 2020 Computing Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the hyper-parameter search problem in the field of\nmachine learning and present a heuristic approach in an attempt to tackle it.\nIn most learning algorithms, a set of hyper-parameters must be determined\nbefore training commences. The choice of hyper-parameters can affect the final\nmodel's performance significantly, but yet determining a good choice of\nhyper-parameters is in most cases complex and consumes large amount of\ncomputing resources. In this paper, we show the differences between an\nexhaustive search of hyper-parameters and a heuristic search, and show that\nthere is a significant reduction in time taken to obtain the resulting model\nwith marginal differences in evaluation metrics when compared to the benchmark\ncase.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 14:36:37 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 16:36:44 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 16:20:09 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Khoong", "Wei Hao", ""]]}, {"id": "1909.12227", "submitter": "Jialin Liu", "authors": "Jialin Liu and Fei Chao and Yu-Chen Lin and Chih-Min Lin", "title": "Stock Prices Prediction using Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial markets have a vital role in the development of modern society.\nThey allow the deployment of economic resources. Changes in stock prices\nreflect changes in the market. In this study, we focus on predicting stock\nprices by deep learning model. This is a challenge task, because there is much\nnoise and uncertainty in information that is related to stock prices. So this\nwork uses sparse autoencoders with one-dimension (1-D) residual convolutional\nnetworks which is a deep learning model, to de-noise the data. Long-short term\nmemory (LSTM) is then used to predict the stock price. The prices, indices and\nmacroeconomic variables in past are the features used to predict the next day's\nprice. Experiment results show that 1-D residual convolutional networks can\nde-noise data and extract deep features better than a model that combines\nwavelet transforms (WT) and stacked autoencoders (SAEs). In addition, we\ncompare the performances of model with two different forecast targets of stock\nprice: absolute stock price and price rate of change. The results show that\npredicting stock price through price rate of change is better than predicting\nabsolute prices directly.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 11:38:25 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Liu", "Jialin", ""], ["Chao", "Fei", ""], ["Lin", "Yu-Chen", ""], ["Lin", "Chih-Min", ""]]}, {"id": "1909.12228", "submitter": "Ameya Jagtap Dr", "authors": "Ameya D. Jagtap, Kenji Kawaguchi and George Em Karniadakis", "title": "Locally adaptive activation functions with slope recovery term for deep\n  and physics-informed neural networks", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": "10.1098/rspa.2020.0334", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two approaches of locally adaptive activation functions namely,\nlayer-wise and neuron-wise locally adaptive activation functions, which improve\nthe performance of deep and physics-informed neural networks. The local\nadaptation of activation function is achieved by introducing a scalable\nparameter in each layer (layer-wise) and for every neuron (neuron-wise)\nseparately, and then optimizing it using a variant of stochastic gradient\ndescent algorithm. In order to further increase the training speed, an\nactivation slope based slope recovery term is added in the loss function, which\nfurther accelerates convergence, thereby reducing the training cost. On the\ntheoretical side, we prove that in the proposed method, the gradient descent\nalgorithms are not attracted to sub-optimal critical points or local minima\nunder practical conditions on the initialization and learning rate, and that\nthe gradient dynamics of the proposed method is not achievable by base methods\nwith any (adaptive) learning rates. We further show that the adaptive\nactivation methods accelerate the convergence by implicitly multiplying\nconditioning matrices to the gradient of the base method without any explicit\ncomputation of the conditioning matrix and the matrix-vector product. The\ndifferent adaptive activation functions are shown to induce different implicit\nconditioning matrices. Furthermore, the proposed methods with the slope\nrecovery are shown to accelerate the training process.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 16:36:21 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 23:00:15 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 01:21:22 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 04:39:24 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Jagtap", "Ameya D.", ""], ["Kawaguchi", "Kenji", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1909.12229", "submitter": "Avinash Swaminathan", "authors": "Avinash Swaminathan, Raj Kuwar Gupta, Haimin Zhang, Debanjan Mahata,\n  Rakesh Gosangi, Rajiv Ratn Shah", "title": "Keyphrase Generation for Scientific Articles using GANs", "comments": "2 pages, 1 fig, 8 references, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a keyphrase generation approach using conditional\nGenerative Adversarial Networks (GAN). In our GAN model, the generator outputs\na sequence of keyphrases based on the title and abstract of a scientific\narticle. The discriminator learns to distinguish between machine-generated and\nhuman-curated keyphrases. We evaluate this approach on standard benchmark\ndatasets. Our model achieves state-of-the-art performance in generation of\nabstractive keyphrases and is also comparable to the best performing extractive\ntechniques. We also demonstrate that our method generates more diverse\nkeyphrases and make our implementation publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 02:46:58 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Swaminathan", "Avinash", ""], ["Gupta", "Raj Kuwar", ""], ["Zhang", "Haimin", ""], ["Mahata", "Debanjan", ""], ["Gosangi", "Rakesh", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "1909.12231", "submitter": "Diego Antognini", "authors": "Diego Antognini and Boi Faltings", "title": "Learning to Create Sentence Semantic Relation Graphs for Multi-Document\n  Summarization", "comments": "10 pages, 4 tables, 1 figure, Accepted at 2019 Empirical Methods in\n  Natural Language Processing - Workshop on New Frontiers in Summarization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linking facts across documents is a challenging task, as the language used to\nexpress the same information in a sentence can vary significantly, which\ncomplicates the task of multi-document summarization. Consequently, existing\napproaches heavily rely on hand-crafted features, which are domain-dependent\nand hard to craft, or additional annotated data, which is costly to gather. To\novercome these limitations, we present a novel method, which makes use of two\ntypes of sentence embeddings: universal embeddings, which are trained on a\nlarge unrelated corpus, and domain-specific embeddings, which are learned\nduring training.\n  To this end, we develop SemSentSum, a fully data-driven model able to\nleverage both types of sentence embeddings by building a sentence semantic\nrelation graph. SemSentSum achieves competitive results on two types of\nsummary, consisting of 665 bytes and 100 words. Unlike other state-of-the-art\nmodels, neither hand-crafted features nor additional annotated data are\nnecessary, and the method is easily adaptable for other tasks. To our\nknowledge, we are the first to use multiple sentence embeddings for the task of\nmulti-document summarization.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 10:21:55 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Antognini", "Diego", ""], ["Faltings", "Boi", ""]]}, {"id": "1909.12232", "submitter": "Sebastian Bayerl", "authors": "Sebastian P. Bayerl and Korbinian Riedhammer", "title": "A Comparison of Hybrid and End-to-End Models for Syllable Recognition", "comments": "22th International Conference of Text, Speech and Dialogue TSD2019", "journal-ref": null, "doi": "10.1007/978-3-030-27947-9_30", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a comparison of a traditional hybrid speech recognition\nsystem (kaldi using WFST and TDNN with lattice-free MMI) and a lexicon-free\nend-to-end (TensorFlow implementation of multi-layer LSTM with CTC training)\nmodels for German syllable recognition on the Verbmobil corpus. The results\nshow that explicitly modeling prior knowledge is still valuable in building\nrecognition systems. With a strong language model (LM) based on syllables, the\nstructured approach significantly outperforms the end-to-end model. The best\nword error rate (WER) regarding syllables was achieved using kaldi with a\n4-gram LM, modeling all syllables observed in the training set. It achieved\n10.0% WER w.r.t. the syllables, compared to the end-to-end approach where the\nbest WER was 27.53%. The work presented here has implications for building\nfuture recognition systems that operate independent of a large vocabulary, as\ntypically used in a tasks such as recognition of syllabic or agglutinative\nlanguages, out-of-vocabulary techniques, keyword search indexing and medical\nspeech processing.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 09:51:35 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Bayerl", "Sebastian P.", ""], ["Riedhammer", "Korbinian", ""]]}, {"id": "1909.12235", "submitter": "Matteo Tiezzi", "authors": "Matteo Tiezzi, Stefano Melacci, Marco Maggini, Angelo Frosini", "title": "Video Surveillance of Highway Traffic Events by Deep Learning\n  Architectures", "comments": null, "journal-ref": "Lecture Notes in Computer Science, vol 11141, (2018) pp 584-593", "doi": "10.1007/978-3-030-01424-7_57", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a video surveillance system able to detect traffic\nevents in videos acquired by fixed videocameras on highways. The events of\ninterest consist in a specific sequence of situations that occur in the video,\nas for instance a vehicle stopping on the emergency lane. Hence, the detection\nof these events requires to analyze a temporal sequence in the video stream. We\ncompare different approaches that exploit architectures based on Recurrent\nNeural Networks (RNNs) and Convolutional Neural Networks (CNNs). A first\napproach extracts vectors of features, mostly related to motion, from each\nvideo frame and exploits a RNN fed with the resulting sequence of vectors. The\nother approaches are based directly on the sequence of frames, that are\neventually enriched with pixel-wise motion information. The obtained stream is\nprocessed by an architecture that stacks a CNN and a RNN, and we also\ninvestigate a transfer-learning-based model. The results are very promising and\nthe best architecture will be tested online in real operative conditions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 15:36:02 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Tiezzi", "Matteo", ""], ["Melacci", "Stefano", ""], ["Maggini", "Marco", ""], ["Frosini", "Angelo", ""]]}, {"id": "1909.12236", "submitter": "Ke Li", "authors": "Ke Li, Kejun Tang, Tianfan Wu, Qifeng Liao", "title": "D3M: A deep domain decomposition method for partial differential\n  equations", "comments": null, "journal-ref": "IEEE Access. 8 (2019) 5283 - 5294", "doi": "10.1109/ACCESS.2019.2957200", "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A state-of-the-art deep domain decomposition method (D3M) based on the\nvariational principle is proposed for partial differential equations (PDEs).\nThe solution of PDEs can be formulated as the solution of a constrained\noptimization problem, and we design a multi-fidelity neural network framework\nto solve this optimization problem. Our contribution is to develop a\nsystematical computational procedure for the underlying problem in parallel\nwith domain decomposition. Our analysis shows that the D3M approximation\nsolution converges to the exact solution of underlying PDEs. Our proposed\nframework establishes a foundation to use variational deep learning in\nlarge-scale engineering problems and designs. We present a general mathematical\nframework of D3M, validate its accuracy and demonstrate its efficiency with\nnumerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 08:40:12 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Li", "Ke", ""], ["Tang", "Kejun", ""], ["Wu", "Tianfan", ""], ["Liao", "Qifeng", ""]]}, {"id": "1909.12238", "submitter": "Francis Song", "authors": "H. Francis Song, Abbas Abdolmaleki, Jost Tobias Springenberg, Aidan\n  Clark, Hubert Soyer, Jack W. Rae, Seb Noury, Arun Ahuja, Siqi Liu, Dhruva\n  Tirumala, Nicolas Heess, Dan Belov, Martin Riedmiller, Matthew M. Botvinick", "title": "V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete\n  and Continuous Control", "comments": "* equal contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some of the most successful applications of deep reinforcement learning to\nchallenging domains in discrete and continuous control have used policy\ngradient methods in the on-policy setting. However, policy gradients can suffer\nfrom large variance that may limit performance, and in practice require\ncarefully tuned entropy regularization to prevent policy collapse. As an\nalternative to policy gradient algorithms, we introduce V-MPO, an on-policy\nadaptation of Maximum a Posteriori Policy Optimization (MPO) that performs\npolicy iteration based on a learned state-value function. We show that V-MPO\nsurpasses previously reported scores for both the Atari-57 and DMLab-30\nbenchmark suites in the multi-task setting, and does so reliably without\nimportance weighting, entropy regularization, or population-based tuning of\nhyperparameters. On individual DMLab and Atari levels, the proposed algorithm\ncan achieve scores that are substantially higher than has previously been\nreported. V-MPO is also applicable to problems with high-dimensional,\ncontinuous action spaces, which we demonstrate in the context of learning to\ncontrol simulated humanoids with 22 degrees of freedom from full state\nobservations and 56 degrees of freedom from pixel observations, as well as\nexample OpenAI Gym tasks where V-MPO achieves substantially higher asymptotic\nscores than previously reported.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:34:22 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Song", "H. Francis", ""], ["Abdolmaleki", "Abbas", ""], ["Springenberg", "Jost Tobias", ""], ["Clark", "Aidan", ""], ["Soyer", "Hubert", ""], ["Rae", "Jack W.", ""], ["Noury", "Seb", ""], ["Ahuja", "Arun", ""], ["Liu", "Siqi", ""], ["Tirumala", "Dhruva", ""], ["Heess", "Nicolas", ""], ["Belov", "Dan", ""], ["Riedmiller", "Martin", ""], ["Botvinick", "Matthew M.", ""]]}, {"id": "1909.12243", "submitter": "Yi Huang", "authors": "Yi Huang and Ishanu Chattopadhyay", "title": "Data Smashing 2.0: Sequence Likelihood (SL) Divergence For Fast Time\n  Series Comparison", "comments": "typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing subtle historical patterns is central to modeling and forecasting\nproblems in time series analysis. Here we introduce and develop a new approach\nto quantify deviations in the underlying hidden generators of observed data\nstreams, resulting in a new efficiently computable universal metric for time\nseries. The proposed metric is in the sense that we can compare and contrast\ndata streams regardless of where and how they are generated and without any\nfeature engineering step. The approach proposed in this paper is conceptually\ndistinct from our previous work on data smashing, and vastly improves\ndiscrimination performance and computing speed. The core idea here is the\ngeneralization of the notion of KL divergence often used to compare probability\ndistributions to a notion of divergence in time series. We call this the\nsequence likelihood (SL) divergence, which may be used to measure deviations\nwithin a well-defined class of discrete-valued stochastic processes. We devise\nefficient estimators of SL divergence from finite sample paths and subsequently\nformulate a universal metric useful for computing distance between time series\nproduced by hidden stochastic generators.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 16:42:13 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 02:08:53 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Huang", "Yi", ""], ["Chattopadhyay", "Ishanu", ""]]}, {"id": "1909.12255", "submitter": "Yuzhe Yang", "authors": "Yuzhe Yang, Guo Zhang, Zhi Xu, Dina Katabi", "title": "Harnessing Structures for Value-Based Planning and Reinforcement\n  Learning", "comments": "ICLR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-based methods constitute a fundamental methodology in planning and deep\nreinforcement learning (RL). In this paper, we propose to exploit the\nunderlying structures of the state-action value function, i.e., Q function, for\nboth planning and deep RL. In particular, if the underlying system dynamics\nlead to some global structures of the Q function, one should be capable of\ninferring the function better by leveraging such structures. Specifically, we\ninvestigate the low-rank structure, which widely exists for big data matrices.\nWe verify empirically the existence of low-rank Q functions in the context of\ncontrol and deep RL tasks. As our key contribution, by leveraging Matrix\nEstimation (ME) techniques, we propose a general framework to exploit the\nunderlying low-rank structure in Q functions. This leads to a more efficient\nplanning procedure for classical control, and additionally, a simple scheme\nthat can be applied to any value-based RL techniques to consistently achieve\nbetter performance on \"low-rank\" tasks. Extensive experiments on control tasks\nand Atari games confirm the efficacy of our approach. Code is available at\nhttps://github.com/YyzHarry/SV-RL.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:01:23 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 21:39:26 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 15:53:48 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Yang", "Yuzhe", ""], ["Zhang", "Guo", ""], ["Xu", "Zhi", ""], ["Katabi", "Dina", ""]]}, {"id": "1909.12264", "submitter": "Stefan Leichenauer", "authors": "Guillaume Verdon, Trevor McCourt, Enxhell Luzhnica, Vikash Singh,\n  Stefan Leichenauer, Jack Hidary", "title": "Quantum Graph Neural Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Quantum Graph Neural Networks (QGNN), a new class of quantum\nneural network ansatze which are tailored to represent quantum processes which\nhave a graph structure, and are particularly suitable to be executed on\ndistributed quantum systems over a quantum network. Along with this general\nclass of ansatze, we introduce further specialized architectures, namely,\nQuantum Graph Recurrent Neural Networks (QGRNN) and Quantum Graph Convolutional\nNeural Networks (QGCNN). We provide four example applications of QGNNs:\nlearning Hamiltonian dynamics of quantum systems, learning how to create\nmultipartite entanglement in a quantum network, unsupervised learning for\nspectral clustering, and supervised learning for graph isomorphism\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:19:16 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Verdon", "Guillaume", ""], ["McCourt", "Trevor", ""], ["Luzhnica", "Enxhell", ""], ["Singh", "Vikash", ""], ["Leichenauer", "Stefan", ""], ["Hidary", "Jack", ""]]}, {"id": "1909.12268", "submitter": "Yongcan Cao", "authors": "Huixin Zhan, Yongcan Cao", "title": "Relationship Explainable Multi-objective Reinforcement Learning with\n  Semantic Explainability Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving multi-objective optimization problems is important in various\napplications where users are interested in obtaining optimal policies subject\nto multiple, yet often conflicting objectives. A typical approach to obtain\noptimal policies is to first construct a loss function that is based on the\nscalarization of individual objectives, and then find the optimal policy that\nminimizes the loss. However, optimizing the scalarized (and weighted) loss does\nnot necessarily provide guarantee of high performance on each possibly\nconflicting objective because it is challenging to assign the right weights\nwithout knowing the relationship among these objectives. Moreover, the\neffectiveness of these gradient descent algorithms is limited by the agent's\nability to explain their decisions and actions to human users. The purpose of\nthis study is two-fold. First, we propose a vector value function based\nmulti-objective reinforcement learning (V2f-MORL) approach that seeks to\nquantify the inter-objective relationship via reinforcement learning (RL) when\nthe impact of one objective on others is unknown a prior. In particular, we\nconstruct one actor and multiple critics that can co-learn the policy and\ninter-objective relationship matrix (IORM), quantifying the impact of\nobjectives on each other, in an iterative way. Second, we provide a semantic\nrepresentation that can uncover the trade-off of decision policies made by\nusers to reconcile conflicting objectives based on the proposed V2f-MORL\napproach for the explainability of the generated behaviors subject to given\noptimization objectives. We demonstrate the effectiveness of the proposed\napproach via a MuJoCo based robotics case study.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:25:57 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zhan", "Huixin", ""], ["Cao", "Yongcan", ""]]}, {"id": "1909.12271", "submitter": "Stephen James", "authors": "Stephen James, Zicong Ma, David Rovick Arrojo, Andrew J. Davison", "title": "RLBench: The Robot Learning Benchmark & Learning Environment", "comments": "Videos and code: https://sites.google.com/view/rlbench", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a challenging new benchmark and learning-environment for robot\nlearning: RLBench. The benchmark features 100 completely unique, hand-designed\ntasks ranging in difficulty, from simple target reaching and door opening, to\nlonger multi-stage tasks, such as opening an oven and placing a tray in it. We\nprovide an array of both proprioceptive observations and visual observations,\nwhich include rgb, depth, and segmentation masks from an over-the-shoulder\nstereo camera and an eye-in-hand monocular camera. Uniquely, each task comes\nwith an infinite supply of demos through the use of motion planners operating\non a series of waypoints given during task creation time; enabling an exciting\nflurry of demonstration-based learning. RLBench has been designed with\nscalability in mind; new tasks, along with their motion-planned demos, can be\neasily created and then verified by a series of tools, allowing users to submit\ntheir own tasks to the RLBench task repository. This large-scale benchmark aims\nto accelerate progress in a number of vision-guided manipulation research\nareas, including: reinforcement learning, imitation learning, multi-task\nlearning, geometric computer vision, and in particular, few-shot learning. With\nthe benchmark's breadth of tasks and demonstrations, we propose the first\nlarge-scale few-shot challenge in robotics. We hope that the scale and\ndiversity of RLBench offers unparalleled research opportunities in the robot\nlearning community and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:26:18 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["James", "Stephen", ""], ["Ma", "Zicong", ""], ["Arrojo", "David Rovick", ""], ["Davison", "Andrew J.", ""]]}, {"id": "1909.12272", "submitter": "Arjun Nitin Bhagoji", "authors": "Arjun Nitin Bhagoji, Daniel Cullina, Prateek Mittal", "title": "Lower Bounds on Adversarial Robustness from Optimal Transport", "comments": "Accepted for the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019); 18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While progress has been made in understanding the robustness of machine\nlearning classifiers to test-time adversaries (evasion attacks), fundamental\nquestions remain unresolved. In this paper, we use optimal transport to\ncharacterize the minimum possible loss in an adversarial classification\nscenario. In this setting, an adversary receives a random labeled example from\none of two classes, perturbs the example subject to a neighborhood constraint,\nand presents the modified example to the classifier. We define an appropriate\ncost function such that the minimum transportation cost between the\ndistributions of the two classes determines the minimum $0-1$ loss for any\nclassifier. When the classifier comes from a restricted hypothesis class, the\noptimal transportation cost provides a lower bound. We apply our framework to\nthe case of Gaussian data with norm-bounded adversaries and explicitly show\nmatching bounds for the classification and transport problems as well as the\noptimality of linear classifiers. We also characterize the sample complexity of\nlearning in this setting, deriving and extending previously known results as a\nspecial case. Finally, we use our framework to study the gap between the\noptimal classification performance possible and that currently achieved by\nstate-of-the-art robustly trained neural networks for datasets of interest,\nnamely, MNIST, Fashion MNIST and CIFAR-10.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:30:16 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 22:09:50 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Bhagoji", "Arjun Nitin", ""], ["Cullina", "Daniel", ""], ["Mittal", "Prateek", ""]]}, {"id": "1909.12289", "submitter": "Qingyun Dou", "authors": "Qingyun Dou, Yiting Lu, Joshua Efiong and Mark J. F. Gales", "title": "Attention Forcing for Sequence-to-sequence Model Training", "comments": "11 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-regressive sequence-to-sequence models with attention mechanism have\nachieved state-of-the-art performance in many tasks such as machine translation\nand speech synthesis. These models can be difficult to train. The standard\napproach, teacher forcing, guides a model with reference output history during\ntraining. The problem is that the model is unlikely to recover from its\nmistakes during inference, where the reference output is replaced by generated\noutput. Several approaches deal with this problem, largely by guiding the model\nwith generated output history. To make training stable, these approaches often\nrequire a heuristic schedule or an auxiliary classifier. This paper introduces\nattention forcing, which guides the model with generated output history and\nreference attention. This approach can train the model to recover from its\nmistakes, in a stable fashion, without the need for a schedule or a classifier.\nIn addition, it allows the model to generate output sequences aligned with the\nreferences, which can be important for cascaded systems like many speech\nsynthesis systems. Experiments on speech synthesis show that attention forcing\nyields significant performance gain. Experiments on machine translation show\nthat for tasks where various re-orderings of the output are valid, guiding the\nmodel with generated output history is challenging, while guiding the model\nwith reference attention is beneficial.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:52:15 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 19:17:11 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Dou", "Qingyun", ""], ["Lu", "Yiting", ""], ["Efiong", "Joshua", ""], ["Gales", "Mark J. F.", ""]]}, {"id": "1909.12291", "submitter": "Steven Young", "authors": "Robert M. Patton, J. Travis Johnston, Steven R. Young, Catherine D.\n  Schuman, Thomas E. Potok, Derek C. Rose, Seung-Hwan Lim, Junghoon Chae, Le\n  Hou, Shahira Abousamra, Dimitris Samaras, Joel Saltz", "title": "Exascale Deep Learning to Accelerate Cancer Research", "comments": "Submitted to IEEE Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, through the use of neural networks, has demonstrated\nremarkable ability to automate many routine tasks when presented with\nsufficient data for training. The neural network architecture (e.g. number of\nlayers, types of layers, connections between layers, etc.) plays a critical\nrole in determining what, if anything, the neural network is able to learn from\nthe training data. The trend for neural network architectures, especially those\ntrained on ImageNet, has been to grow ever deeper and more complex. The result\nhas been ever increasing accuracy on benchmark datasets with the cost of\nincreased computational demands. In this paper we demonstrate that neural\nnetwork architectures can be automatically generated, tailored for a specific\napplication, with dual objectives: accuracy of prediction and speed of\nprediction. Using MENNDL--an HPC-enabled software stack for neural architecture\nsearch--we generate a neural network with comparable accuracy to\nstate-of-the-art networks on a cancer pathology dataset that is also $16\\times$\nfaster at inference. The speedup in inference is necessary because of the\nvolume and velocity of cancer pathology data; specifically, the previous\nstate-of-the-art networks are too slow for individual researchers without\naccess to HPC systems to keep pace with the rate of data generation. Our new\nmodel enables researchers with modest computational resources to analyze newly\ngenerated data faster than it is collected.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:53:26 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Patton", "Robert M.", ""], ["Johnston", "J. Travis", ""], ["Young", "Steven R.", ""], ["Schuman", "Catherine D.", ""], ["Potok", "Thomas E.", ""], ["Rose", "Derek C.", ""], ["Lim", "Seung-Hwan", ""], ["Chae", "Junghoon", ""], ["Hou", "Le", ""], ["Abousamra", "Shahira", ""], ["Samaras", "Dimitris", ""], ["Saltz", "Joel", ""]]}, {"id": "1909.12292", "submitter": "Ziwei Ji", "authors": "Ziwei Ji, Matus Telgarsky", "title": "Polylogarithmic width suffices for gradient descent to achieve\n  arbitrarily small test error with shallow ReLU networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical work has guaranteed that overparameterized networks\ntrained by gradient descent achieve arbitrarily low training error, and\nsometimes even low test error. The required width, however, is always\npolynomial in at least one of the sample size $n$, the (inverse) target error\n$1/\\epsilon$, and the (inverse) failure probability $1/\\delta$. This work shows\nthat $\\widetilde{\\Theta}(1/\\epsilon)$ iterations of gradient descent with\n$\\widetilde{\\Omega}(1/\\epsilon^2)$ training examples on two-layer ReLU networks\nof any width exceeding $\\mathrm{polylog}(n,1/\\epsilon,1/\\delta)$ suffice to\nachieve a test misclassification error of $\\epsilon$. We also prove that\nstochastic gradient descent can achieve $\\epsilon$ test error with\npolylogarithmic width and $\\widetilde{\\Theta}(1/\\epsilon)$ samples. The\nanalysis relies upon the separation margin of the limiting kernel, which is\nguaranteed positive, can distinguish between true labels and random labels, and\ncan give a tight sample-complexity analysis in the infinite-width setting\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:56:28 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 02:21:50 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 05:48:27 GMT"}, {"version": "v4", "created": "Sat, 15 Feb 2020 03:53:09 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ji", "Ziwei", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1909.12297", "submitter": "Fredrik K. Gustafsson", "authors": "Fredrik K. Gustafsson, Martin Danelljan, Goutam Bhat, Thomas B.\n  Sch\\\"on", "title": "Energy-Based Models for Deep Probabilistic Regression", "comments": "ECCV 2020. Code is available at\n  https://github.com/fregu856/ebms_regression", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning-based classification is generally tackled using\nstandardized approaches, a wide variety of techniques are employed for\nregression. In computer vision, one particularly popular such technique is that\nof confidence-based regression, which entails predicting a confidence value for\neach input-target pair (x,y). While this approach has demonstrated impressive\nresults, it requires important task-dependent design choices, and the predicted\nconfidences lack a natural probabilistic meaning. We address these issues by\nproposing a general and conceptually simple regression method with a clear\nprobabilistic interpretation. In our proposed approach, we create an\nenergy-based model of the conditional target density p(y|x), using a deep\nneural network to predict the un-normalized density from (x,y). This model of\np(y|x) is trained by directly minimizing the associated negative\nlog-likelihood, approximated using Monte Carlo sampling. We perform\ncomprehensive experiments on four computer vision regression tasks. Our\napproach outperforms direct regression, as well as other probabilistic and\nconfidence-based methods. Notably, our model achieves a 2.2% AP improvement\nover Faster-RCNN for object detection on the COCO dataset, and sets a new\nstate-of-the-art on visual tracking when applied for bounding box estimation.\nIn contrast to confidence-based methods, our approach is also shown to be\ndirectly applicable to more general tasks such as age and head-pose estimation.\nCode is available at https://github.com/fregu856/ebms_regression.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:58:43 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 15:35:36 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 11:19:02 GMT"}, {"version": "v4", "created": "Sun, 19 Jul 2020 12:47:37 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Gustafsson", "Fredrik K.", ""], ["Danelljan", "Martin", ""], ["Bhat", "Goutam", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1909.12299", "submitter": "Subba Reddy Oota", "authors": "Subba Reddy Oota and Naresh Manwani and Raju S. Bapi", "title": "Expert2Coder: Capturing Divergent Brain Regions Using Mixture of\n  Regression Experts", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  fMRI semantic category understanding using linguistic encoding models\nattempts to learn a forward mapping that relates stimuli to the corresponding\nbrain activation. State-of-the-art encoding models use a single global model\n(linear or non-linear) to predict brain activation given the stimulus. However,\nthe critical assumption in these methods is that a priori different brain\nregions respond the same way to all the stimuli, that is, there is no\nmodularity or specialization assumed for any region. This goes against the\nmodularity theory, supported by many cognitive neuroscience investigations\nsuggesting that there are functionally specialized regions in the brain. In\nthis paper, we achieve this by clustering similar regions together and for\nevery cluster we learn a different linear regression model using a mixture of\nlinear experts model. The key idea here is that each linear expert captures the\nbehaviour of similar brain regions. Given a new stimulus, the utility of the\nproposed model is twofold (i) predicts the brain activation as a weighted\nlinear combination of the activations of multiple linear experts and (ii) to\nlearn multiple experts corresponding to different brain regions. We argue that\neach expert captures activity patterns related to a particular region of\ninterest (ROI) in the human brain. This study helps in understanding the brain\nregions that are activated together given different kinds of stimuli.\nImportantly, we suggest that the mixture of regression experts (MoRE) framework\nsuccessfully combines the two principles of organization of function in the\nbrain, namely that of specialization and integration. Experiments on fMRI data\nfrom paradigm 1 [1]where participants view linguistic stimuli show that the\nproposed MoRE model has better prediction accuracy compared to that of\nconventional models.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:59:33 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 19:45:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Oota", "Subba Reddy", ""], ["Manwani", "Naresh", ""], ["Bapi", "Raju S.", ""]]}, {"id": "1909.12301", "submitter": "Jingwei Ma", "authors": "Jingwei Ma, Jiahui Wen, Mingyang Zhong, Liangchen Liu, Chaojie Li,\n  Weitong Chen, Yin Yang, Honghui Tu, Xue Li", "title": "DBRec: Dual-Bridging Recommendation via Discovering Latent Groups", "comments": "10 pages, 16 figures, The 28th ACM International Conference on\n  Information and Knowledge Management (CIKM '19)", "journal-ref": null, "doi": "10.1145/3357384.3357892", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recommender systems, the user-item interaction data is usually sparse and\nnot sufficient for learning comprehensive user/item representations for\nrecommendation. To address this problem, we propose a novel dual-bridging\nrecommendation model (DBRec). DBRec performs latent user/item group discovery\nsimultaneously with collaborative filtering, and interacts group information\nwith users/items for bridging similar users/items. Therefore, a user's\npreference over an unobserved item, in DBRec, can be bridged by the users\nwithin the same group who have rated the item, or the user-rated items that\nshare the same group with the unobserved item. In addition, we propose to\njointly learn user-user group (item-item group) hierarchies, so that we can\neffectively discover latent groups and learn compact user/item representations.\nWe jointly integrate collaborative filtering, latent group discovering and\nhierarchical modelling into a unified framework, so that all the model\nparameters can be learned toward the optimization of the objective function. We\nvalidate the effectiveness of the proposed model with two real datasets, and\ndemonstrate its advantage over the state-of-the-art recommendation models with\nextensive experiments.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 03:58:03 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 14:19:23 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Ma", "Jingwei", ""], ["Wen", "Jiahui", ""], ["Zhong", "Mingyang", ""], ["Liu", "Liangchen", ""], ["Li", "Chaojie", ""], ["Chen", "Weitong", ""], ["Yang", "Yin", ""], ["Tu", "Honghui", ""], ["Li", "Xue", ""]]}, {"id": "1909.12325", "submitter": "Shahana Ibrahim", "authors": "Shahana Ibrahim, Xiao Fu, Nikos Kargas, Kejun Huang", "title": "Crowdsourcing via Pairwise Co-occurrences: Identifiability and\n  Algorithms", "comments": "28 pages, 5 figures, to appear in 33rd NeurIPS conference, Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data deluge comes with high demands for data labeling. Crowdsourcing (or,\nmore generally, ensemble learning) techniques aim to produce accurate labels\nvia integrating noisy, non-expert labeling from annotators. The classic\nDawid-Skene estimator and its accompanying expectation maximization (EM)\nalgorithm have been widely used, but the theoretical properties are not fully\nunderstood. Tensor methods were proposed to guarantee identification of the\nDawid-Skene model, but the sample complexity is a hurdle for applying such\napproaches---since the tensor methods hinge on the availability of third-order\nstatistics that are hard to reliably estimate given limited data. In this\npaper, we propose a framework using pairwise co-occurrences of the annotator\nresponses, which naturally admits lower sample complexity. We show that the\napproach can identify the Dawid-Skene model under realistic conditions. We\npropose an algebraic algorithm reminiscent of convex geometry-based structured\nmatrix factorization to solve the model identification problem efficiently, and\nan identifiability-enhanced algorithm for handling more challenging and\ncritical scenarios. Experiments show that the proposed algorithms outperform\nthe state-of-art algorithms under a variety of scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 18:28:23 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ibrahim", "Shahana", ""], ["Fu", "Xiao", ""], ["Kargas", "Nikos", ""], ["Huang", "Kejun", ""]]}, {"id": "1909.12326", "submitter": "Yuang Jiang", "authors": "Yuang Jiang, Shiqiang Wang, Victor Valls, Bong Jun Ko, Wei-Han Lee,\n  Kin K. Leung, Leandros Tassiulas", "title": "Model Pruning Enables Efficient Federated Learning on Edge Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) allows model training from local data collected by\nedge/mobile devices, while preserving data privacy. A challenge is that client\ndevices in FL usually have much more limited computation and communication\nresources compared to servers in a datacenter. To overcome this challenge, we\npropose PruneFL -- a novel FL approach with adaptive and distributed parameter\npruning, which adapts the model size during FL to reduce both communication and\ncomputation overhead and minimize the overall training time, while maintaining\na similar accuracy as the original model. PruneFL includes initial pruning at a\nselected client and further pruning as part of the FL process. The model size\nis adapted during this process, which includes maximizing the approximate\nempirical risk reduction divided by the time of one FL round. Our experiments\nwith various datasets on edge devices (e.g., Raspberry Pi) show that: (i) we\nsignificantly reduce the training time compared to conventional FL and various\nother pruning-based methods; (ii) the pruned model converges to an accuracy\nthat is very similar to the original model but has a much smaller size, and it\nis also a lottery ticket of the original model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 18:32:33 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 21:16:43 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 03:01:22 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 03:35:42 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Jiang", "Yuang", ""], ["Wang", "Shiqiang", ""], ["Valls", "Victor", ""], ["Ko", "Bong Jun", ""], ["Lee", "Wei-Han", ""], ["Leung", "Kin K.", ""], ["Tassiulas", "Leandros", ""]]}, {"id": "1909.12335", "submitter": "Yao Fu", "authors": "Yao Fu, Hao Zhou, Jiaze Chen, and Lei Li", "title": "Rethinking Text Attribute Transfer: A Lexical Analysis", "comments": "INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text attribute transfer is modifying certain linguistic attributes (e.g.\nsentiment, style, authorship, etc.) of a sentence and transforming them from\none type to another. In this paper, we aim to analyze and interpret what is\nchanged during the transfer process. We start from the observation that in many\nexisting models and datasets, certain words within a sentence play important\nroles in determining the sentence attribute class. These words are referred to\nas \\textit{the Pivot Words}. Based on these pivot words, we propose a lexical\nanalysis framework, \\textit{the Pivot Analysis}, to quantitatively analyze the\neffects of these words in text attribute classification and transfer. We apply\nthis framework to existing datasets and models and show that: (1) the pivot\nwords are strong features for the classification of sentence attributes; (2) to\nchange the attribute of a sentence, many datasets only requires to change\ncertain pivot words; (3) consequently, many transfer models only perform the\nlexical-level modification, while leaving higher-level sentence structures\nunchanged. Our work provides an in-depth understanding of linguistic attribute\ntransfer and further identifies the future requirements and challenges of this\ntask\\footnote{Our code can be found at\nhttps://github.com/FranxYao/pivot_analysis}.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 18:59:53 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Fu", "Yao", ""], ["Zhou", "Hao", ""], ["Chen", "Jiaze", ""], ["Li", "Lei", ""]]}, {"id": "1909.12339", "submitter": "Neus Catal\\`a", "authors": "Neus Catal\\`a and Mario Martin", "title": "Coin_flipper at eHealth-KD Challenge 2019: Voting LSTMs for Key Phrases\n  and Semantic Relation Identification Applied to Spanish eHealth Texts", "comments": "9 pages, 2 figures, 1 table", "journal-ref": "Proceedings of the Iberian Languages Evaluation Forum (IberLEF\n  2019) co-located with 35th Conference of the Spanish Society for Natural\n  Language Processing (SEPLN 2019) http://ceur-ws.org/Vol-2421/", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper describes our approach presented for the eHealth-KD 2019\nchallenge. Our participation was aimed at testing how far we could go using\ngeneric tools for Text-Processing but, at the same time, using common\noptimization techniques in the field of Data Mining. The architecture proposed\nfor both tasks of the challenge is a standard stacked 2-layer bi-LSTM. The main\nparticularities of our approach are: (a) The use of a surrogate function of F1\nas loss function to close the gap between the minimization function and the\nevaluation metric, and (b) The generation of an ensemble of models for\ngenerating predictions by majority vote. Our system ranked second with an F1\nscore of 62.18% in the main task by a narrow margin with the winner that scored\n63.94%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 19:03:54 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Catal\u00e0", "Neus", ""], ["Martin", "Mario", ""]]}, {"id": "1909.12340", "submitter": "Mor Shpigel Nacson", "authors": "Niv Giladi, Mor Shpigel Nacson, Elad Hoffer, Daniel Soudry", "title": "At Stability's Edge: How to Adjust Hyperparameters to Preserve Minima\n  Selection in Asynchronous Training of Neural Networks?", "comments": "ICLR 2020 Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Recent developments have made it possible to accelerate neural\nnetworks training significantly using large batch sizes and data parallelism.\nTraining in an asynchronous fashion, where delay occurs, can make training even\nmore scalable. However, asynchronous training has its pitfalls, mainly a\ndegradation in generalization, even after convergence of the algorithm. This\ngap remains not well understood, as theoretical analysis so far mainly focused\non the convergence rate of asynchronous methods. Contributions: We examine\nasynchronous training from the perspective of dynamical stability. We find that\nthe degree of delay interacts with the learning rate, to change the set of\nminima accessible by an asynchronous stochastic gradient descent algorithm. We\nderive closed-form rules on how the learning rate could be changed, while\nkeeping the accessible set the same. Specifically, for high delay values, we\nfind that the learning rate should be kept inversely proportional to the delay.\nWe then extend this analysis to include momentum. We find momentum should be\neither turned off, or modified to improve training stability. We provide\nempirical experiments to validate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 19:05:58 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 13:06:02 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Giladi", "Niv", ""], ["Nacson", "Mor Shpigel", ""], ["Hoffer", "Elad", ""], ["Soudry", "Daniel", ""]]}, {"id": "1909.12356", "submitter": "Fatima Batool", "authors": "Fatima Batool", "title": "An agglomerative hierarchical clustering method by optimizing the\n  average silhouette width", "comments": "43 pages, several figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An agglomerative hierarchical clustering (AHC) framework and algorithm named\nHOSil based on a new linkage metric optimized by the average silhouette width\n(ASW) index is proposed. A conscientious investigation of various clustering\nmethods and estimation indices is conducted across a diverse verities of data\nstructures for three aims: a) clustering quality, b) clustering recovery, and\nc) estimation of number of clusters. HOSil has shown better clustering quality\nfor a range of artificial and real world data structures as compared to\nk-means, PAM, single, complete, average, Ward, McQuitty, spectral, model-based,\nand several estimation methods. It can identify clusters of various shapes\nincluding spherical, elongated, relatively small sized clusters, clusters\ncoming from different distributions including uniform, t, gamma and others.\nHOSil has shown good recovery for correct determination of the number of\nclusters. For some data structures only HOSil was able to identify the correct\nnumber of clusters.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 19:46:28 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Batool", "Fatima", ""]]}, {"id": "1909.12362", "submitter": "Adityanarayanan Radhakrishnan", "authors": "Adityanarayanan Radhakrishnan, Mikhail Belkin, Caroline Uhler", "title": "Overparameterized Neural Networks Implement Associative Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying computational mechanisms for memorization and retrieval of data\nis a long-standing problem at the intersection of machine learning and\nneuroscience. Our main finding is that standard overparameterized deep neural\nnetworks trained using standard optimization methods implement such a mechanism\nfor real-valued data. Empirically, we show that: (1) overparameterized\nautoencoders store training samples as attractors, and thus, iterating the\nlearned map leads to sample recovery; (2) the same mechanism allows for\nencoding sequences of examples, and serves as an even more efficient mechanism\nfor memory than autoencoding. Theoretically, we prove that when trained on a\nsingle example, autoencoders store the example as an attractor. Lastly, by\ntreating a sequence encoder as a composition of maps, we prove that sequence\nencoding provides a more efficient mechanism for memory than autoencoding.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 19:53:55 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 16:16:21 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Radhakrishnan", "Adityanarayanan", ""], ["Belkin", "Mikhail", ""], ["Uhler", "Caroline", ""]]}, {"id": "1909.12367", "submitter": "Jinsung Yoon", "authors": "Jinsung Yoon, Sercan O. Arik, Tomas Pfister", "title": "RL-LIM: Reinforcement Learning-based Locally Interpretable Modeling", "comments": "18 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding black-box machine learning models is important towards their\nwidespread adoption. However, developing globally interpretable models that\nexplain the behavior of the entire model is challenging. An alternative\napproach is to explain black-box models through explaining individual\nprediction using a locally interpretable model. In this paper, we propose a\nnovel method for locally interpretable modeling - Reinforcement Learning-based\nLocally Interpretable Modeling (RL-LIM). RL-LIM employs reinforcement learning\nto select a small number of samples and distill the black-box model prediction\ninto a low-capacity locally interpretable model. Training is guided with a\nreward that is obtained directly by measuring agreement of the predictions from\nthe locally interpretable model with the black-box model. RL-LIM near-matches\nthe overall prediction performance of black-box models while yielding\nhuman-like interpretability, and significantly outperforms state of the art\nlocally interpretable models in terms of overall prediction performance and\nfidelity.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:06:45 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Yoon", "Jinsung", ""], ["Arik", "Sercan O.", ""], ["Pfister", "Tomas", ""]]}, {"id": "1909.12373", "submitter": "Lizhong Chen", "authors": "Drew D. Penney and Lizhong Chen", "title": "A Survey of Machine Learning Applied to Computer Architecture Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has enabled significant benefits in diverse fields, but,\nwith a few exceptions, has had limited impact on computer architecture. Recent\nwork, however, has explored broader applicability for design, optimization, and\nsimulation. Notably, machine learning based strategies often surpass prior\nstate-of-the-art analytical, heuristic, and human-expert approaches. This paper\nreviews machine learning applied system-wide to simulation and run-time\noptimization, and in many individual components, including memory systems,\nbranch predictors, networks-on-chip, and GPUs. The paper further analyzes\ncurrent practice to highlight useful design strategies and identify areas for\nfuture work, based on optimized implementation strategies, opportune extensions\nto existing work, and ambitious long term possibilities. Taken together, these\nstrategies and techniques present a promising future for increasingly automated\narchitectural design.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:23:46 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Penney", "Drew D.", ""], ["Chen", "Lizhong", ""]]}, {"id": "1909.12383", "submitter": "Ziming Zhang", "authors": "Yecheng Lyu and Xinming Huang and Ziming Zhang", "title": "Graph-Preserving Grid Layout: A Simple Graph Drawing Method for Graph\n  Classification using CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) suffer from the irregularity of graphs,\nwhile more widely-used convolutional neural networks (CNNs) benefit from\nregular grids. To bridge the gap between GCN and CNN, in contrast to previous\nworks on generalizing the basic operations in CNNs to graph data, in this paper\nwe address the problem of how to project undirected graphs onto the grid in a\n{\\em principled} way where CNNs can be used as backbone for geometric deep\nlearning. To this end, inspired by the literature of graph drawing we propose a\nnovel graph-preserving grid layout (GPGL), an integer programming that\nminimizes the topological loss on the grid. Technically we propose solving GPGL\napproximately using a {\\em regularized} Kamada-Kawai algorithm, a well-known\nnonconvex optimization technique in graph drawing, with a vertex separation\npenalty that improves the rounding performance on top of the solutions from\nrelaxation. Using GPGL we can easily conduct data augmentation as every local\nminimum will lead to a grid layout for the same graph. Together with the help\nof multi-scale maxout CNNs, we demonstrate the empirical success of our method\nfor graph classification.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:53:12 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Lyu", "Yecheng", ""], ["Huang", "Xinming", ""], ["Zhang", "Ziming", ""]]}, {"id": "1909.12384", "submitter": "Xiangrui Zeng", "authors": "Xiangrui Zeng, Hongyu Zheng", "title": "CS Sparse K-means: An Algorithm for Cluster-Specific Feature Selection\n  in High-Dimensional Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feature selection is an important and challenging task in high dimensional\nclustering. For example, in genomics, there may only be a small number of genes\nthat are differentially expressed, which are informative to the overall\nclustering structure. Existing feature selection methods, such as Sparse\nK-means, rarely tackle the problem of accounting features that can only\nseparate a subset of clusters. In genomics, it is highly likely that a gene can\nonly define one subtype against all the other subtypes or distinguish a pair of\nsubtypes but not others. In this paper, we propose a K-means based clustering\nalgorithm that discovers informative features as well as which cluster pairs\nare separable by each selected features. The method is essentially an EM\nalgorithm, in which we introduce lasso-type constraints on each cluster pair in\nthe M step, and make the E step possible by maximizing the raw cross-cluster\ndistance instead of minimizing the intra-cluster distance. The results were\ndemonstrated on simulated data and a leukemia gene expression dataset.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:57:17 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 19:23:13 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zeng", "Xiangrui", ""], ["Zheng", "Hongyu", ""]]}, {"id": "1909.12385", "submitter": "Lingxiao Zhao", "authors": "Xuan Wu, Lingxiao Zhao, Leman Akoglu", "title": "A Quest for Structure: Jointly Learning the Graph Structure and\n  Semi-Supervised Classification", "comments": "11 pages, CIKM-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) is effectively used for numerous\nclassification problems, thanks to its ability to make use of abundant\nunlabeled data. The main assumption of various SSL algorithms is that the\nnearby points on the data manifold are likely to share a label. Graph-based SSL\nconstructs a graph from point-cloud data as an approximation to the underlying\nmanifold, followed by label inference. It is no surprise that the quality of\nthe constructed graph in capturing the essential structure of the data is\ncritical to the accuracy of the subsequent inference step [6]. How should one\nconstruct a graph from the input point-cloud data for graph-based SSL? In this\nwork we introduce a new, parallel graph learning framework (called PG-learn)\nfor the graph construction step of SSL. Our solution has two main ingredients:\n(1) a gradient-based optimization of the edge weights (more specifically,\ndifferent kernel bandwidths in each dimension) based on a validation loss\nfunction, and (2) a parallel hyperparameter search algorithm with an adaptive\nresource allocation scheme. In essence, (1) allows us to search around a\n(random) initial hyperparameter configuration for a better one with lower\nvalidation loss. Since the search space of hyperparameters is huge for\nhigh-dimensional problems, (2) empowers our gradient-based search to go through\nas many different initial configurations as possible, where runs for relatively\nunpromising starting configurations are terminated early to allocate the time\nfor others. As such, PG-learn is a carefully-designed hybrid of random and\nadaptive search. Through experiments on multi-class classification problems, we\nshow that PG-learn significantly outperforms a variety of existing graph\nconstruction schemes in accuracy (per fixed time budget for hyperparameter\ntuning), and scales more effectively to high dimensional problems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:59:29 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Wu", "Xuan", ""], ["Zhao", "Lingxiao", ""], ["Akoglu", "Leman", ""]]}, {"id": "1909.12387", "submitter": "Digvijay Boob", "authors": "Digvijay Boob, Saurabh Sawlani, Di Wang", "title": "Faster width-dependent algorithm for mixed packing and covering LPs", "comments": "Accepted for oral presentation at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we give a faster width-dependent algorithm for mixed\npacking-covering LPs. Mixed packing-covering LPs are fundamental to\ncombinatorial optimization in computer science and operations research. Our\nalgorithm finds a $1+\\eps$ approximate solution in time $O(Nw/ \\eps)$, where\n$N$ is number of nonzero entries in the constraint matrix and $w$ is the\nmaximum number of nonzeros in any constraint. This run-time is better than\nNesterov's smoothing algorithm which requires $O(N\\sqrt{n}w/ \\eps)$ where $n$\nis the dimension of the problem. Our work utilizes the framework of area\nconvexity introduced in [Sherman-FOCS'17] to obtain the best dependence on\n$\\eps$ while breaking the infamous $\\ell_{\\infty}$ barrier to eliminate the\nfactor of $\\sqrt{n}$. The current best width-independent algorithm for this\nproblem runs in time $O(N/\\eps^2)$ [Young-arXiv-14] and hence has worse running\ntime dependence on $\\eps$. Many real life instances of the mixed\npacking-covering problems exhibit small width and for such cases, our algorithm\ncan report higher precision results when compared to width-independent\nalgorithms. As a special case of our result, we report a $1+\\eps$ approximation\nalgorithm for the densest subgraph problem which runs in time $O(md/ \\eps)$,\nwhere $m$ is the number of edges in the graph and $d$ is the maximum graph\ndegree.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:02:51 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Boob", "Digvijay", ""], ["Sawlani", "Saurabh", ""], ["Wang", "Di", ""]]}, {"id": "1909.12397", "submitter": "Moonkyung Ryu", "authors": "Moonkyung Ryu, Yinlam Chow, Ross Anderson, Christian Tjandraatmadja,\n  Craig Boutilier", "title": "CAQL: Continuous Action Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-based reinforcement learning (RL) methods like Q-learning have shown\nsuccess in a variety of domains. One challenge in applying Q-learning to\ncontinuous-action RL problems, however, is the continuous action maximization\n(max-Q) required for optimal Bellman backup. In this work, we develop CAQL, a\n(class of) algorithm(s) for continuous-action Q-learning that can use several\nplug-and-play optimizers for the max-Q problem. Leveraging recent optimization\nresults for deep neural networks, we show that max-Q can be solved optimally\nusing mixed-integer programming (MIP). When the Q-function representation has\nsufficient power, MIP-based optimization gives rise to better policies and is\nmore robust than approximate methods (e.g., gradient ascent, cross-entropy\nsearch). We further develop several techniques to accelerate inference in CAQL,\nwhich despite their approximate nature, perform well. We compare CAQL with\nstate-of-the-art RL algorithms on benchmark continuous-control problems that\nhave different degrees of action constraints and show that CAQL outperforms\npolicy-based methods in heavily constrained environments, often dramatically.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:16:17 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 18:15:34 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 19:29:14 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ryu", "Moonkyung", ""], ["Chow", "Yinlam", ""], ["Anderson", "Ross", ""], ["Tjandraatmadja", "Christian", ""], ["Boutilier", "Craig", ""]]}, {"id": "1909.12398", "submitter": "Sathya N. Ravi", "authors": "Sathya N. Ravi, Abhay Venkatesh, Glenn Moo Fung, Vikas Singh", "title": "Optimizing Nondecomposable Data Dependent Regularizers via Lagrangian\n  Reparameterization offers Significant Performance and Efficiency Gains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data dependent regularization is known to benefit a wide variety of problems\nin machine learning. Often, these regularizers cannot be easily decomposed into\na sum over a finite number of terms, e.g., a sum over individual example-wise\nterms. The $F_\\beta$ measure, Area under the ROC curve (AUCROC) and Precision\nat a fixed recall (P@R) are some prominent examples that are used in many\napplications. We find that for most medium to large sized datasets, scalability\nissues severely limit our ability in leveraging the benefits of such\nregularizers. Importantly, the key technical impediment despite some recent\nprogress is that, such objectives remain difficult to optimize via\nbackpropapagation procedures. While an efficient general-purpose strategy for\nthis problem still remains elusive, in this paper, we show that for many\ndata-dependent nondecomposable regularizers that are relevant in applications,\nsizable gains in efficiency are possible with minimal code-level changes; in\nother words, no specialized tools or numerical schemes are needed. Our\nprocedure involves a reparameterization followed by a partial dualization --\nthis leads to a formulation that has provably cheap projection operators. We\npresent a detailed analysis of runtime and convergence properties of our\nalgorithm. On the experimental side, we show that a direct use of our scheme\nsignificantly improves the state of the art IOU measures reported for MSCOCO\nStuff segmentation dataset.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:19:30 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ravi", "Sathya N.", ""], ["Venkatesh", "Abhay", ""], ["Fung", "Glenn Moo", ""], ["Singh", "Vikas", ""]]}, {"id": "1909.12401", "submitter": "Brent Harrison", "authors": "Md Sultan Al Nahian, Tasmia Tasrin, Sagar Gandhi, Ryan Gaines, and\n  Brent Harrison", "title": "A Hierarchical Approach for Visual Storytelling Using Image Description", "comments": "Accepted at the 2019 International Conference on Interactive Digital\n  Storytelling (ICIDS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary challenges of visual storytelling is developing techniques\nthat can maintain the context of the story over long event sequences to\ngenerate human-like stories. In this paper, we propose a hierarchical deep\nlearning architecture based on encoder-decoder networks to address this\nproblem. To better help our network maintain this context while also generating\nlong and diverse sentences, we incorporate natural language image descriptions\nalong with the images themselves to generate each story sentence. We evaluate\nour system on the Visual Storytelling (VIST) dataset and show that our method\noutperforms state-of-the-art techniques on a suite of different automatic\nevaluation metrics. The empirical results from this evaluation demonstrate the\nnecessities of different components of our proposed architecture and shows the\neffectiveness of the architecture for visual storytelling.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:25:41 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Nahian", "Md Sultan Al", ""], ["Tasrin", "Tasmia", ""], ["Gandhi", "Sagar", ""], ["Gaines", "Ryan", ""], ["Harrison", "Brent", ""]]}, {"id": "1909.12408", "submitter": "Yuan Shangguan", "authors": "Yuan Shangguan, Jian Li, Qiao Liang, Raziel Alvarez, Ian McGraw", "title": "Optimizing Speech Recognition For The Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most deployed speech recognition systems today still run on servers, we\nare in the midst of a transition towards deployments on edge devices. This leap\nto the edge is powered by the progression from traditional speech recognition\npipelines to end-to-end (E2E) neural architectures, and the parallel\ndevelopment of more efficient neural network topologies and optimization\ntechniques. Thus, we are now able to create highly accurate speech recognizers\nthat are both small and fast enough to execute on typical mobile devices. In\nthis paper, we begin with a baseline RNN-Transducer architecture comprised of\nLong Short-Term Memory (LSTM) layers. We then experiment with a variety of more\ncomputationally efficient layer types, as well as apply optimization techniques\nlike neural connection pruning and parameter quantization to construct a small,\nhigh quality, on-device speech recognizer that is an order of magnitude smaller\nthan the baseline system without any optimizations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 21:43:53 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 21:57:39 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 00:15:41 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Shangguan", "Yuan", ""], ["Li", "Jian", ""], ["Liang", "Qiao", ""], ["Alvarez", "Raziel", ""], ["McGraw", "Ian", ""]]}, {"id": "1909.12432", "submitter": "Hamidreza Mahyar", "authors": "Soroush Aalibagi, Hamidreza Mahyar, Ali Movaghar, and H. Eugene\n  Stanley", "title": "A Matrix Factorization Model for Hellinger-based Trust Management in\n  Social Internet of Things", "comments": null, "journal-ref": null, "doi": "10.1109/TDSC.2021.3052953", "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Social Internet of Things (SIoT), integration of the Internet of Things\nand Social Networks paradigms, has been introduced to build a network of smart\nnodes that are capable of establishing social links. In order to deal with\nmisbehaving service provider nodes, service requestor nodes must evaluate their\ntrustworthiness levels. In this paper, we propose a novel trust management\nmechanism in the SIoT to predict the most reliable service providers for each\nservice requestor, which leads to reduce the risk of being exposed to malicious\nnodes. We model the SIoT with a flexible bipartite graph (containing two sets\nof nodes: service providers and service requestors), then build a social\nnetwork among the service requestor nodes, using the Hellinger distance.\nAfterward, we develop a social trust model using nodes' centrality and\nsimilarity measures to extract trust behaviors among the social network nodes.\nFinally, a matrix factorization technique is designed to extract latent\nfeatures of SIoT nodes, find trustworthy nodes, and mitigate the data sparsity\nand cold start problems. We analyze the effect of parameters in the proposed\ntrust prediction mechanism on prediction accuracy. The results indicate that\nfeedbacks from the neighboring nodes of a specific service requestor with high\nHellinger similarity in our mechanism outperforms the best existing methods. We\nalso show that utilizing the social trust model, which only considers a\nsimilarity measure, significantly improves the accuracy of the prediction\nmechanism. Furthermore, we evaluate the effectiveness of the proposed trust\nmanagement system through a real-world SIoT use case. Our results demonstrate\nthat the proposed mechanism is resilient to different types of network attacks,\nand it can accurately find the most proper and trustworthy service provider.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 23:18:40 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 21:06:52 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 20:59:08 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Aalibagi", "Soroush", ""], ["Mahyar", "Hamidreza", ""], ["Movaghar", "Ali", ""], ["Stanley", "H. Eugene", ""]]}, {"id": "1909.12434", "submitter": "Divyansh Kaushik", "authors": "Divyansh Kaushik, Eduard Hovy, Zachary C. Lipton", "title": "Learning the Difference that Makes a Difference with\n  Counterfactually-Augmented Data", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite alarm over the reliance of machine learning systems on so-called\nspurious patterns, the term lacks coherent meaning in standard statistical\nframeworks. However, the language of causality offers clarity: spurious\nassociations are due to confounding (e.g., a common cause), but not direct or\nindirect causal effects. In this paper, we focus on natural language\nprocessing, introducing methods and resources for training models less\nsensitive to spurious patterns. Given documents and their initial labels, we\ntask humans with revising each document so that it (i) accords with a\ncounterfactual target label; (ii) retains internal coherence; and (iii) avoids\nunnecessary changes. Interestingly, on sentiment analysis and natural language\ninference tasks, classifiers trained on original data fail on their\ncounterfactually-revised counterparts and vice versa. Classifiers trained on\ncombined datasets perform remarkably well, just shy of those specialized to\neither domain. While classifiers trained on either original or manipulated data\nalone are sensitive to spurious features (e.g., mentions of genre), models\ntrained on the combined data are less sensitive to this signal. Both datasets\nare publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 23:25:25 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 22:32:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kaushik", "Divyansh", ""], ["Hovy", "Eduard", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1909.12441", "submitter": "Xin Yang", "authors": "Huaian Diao, Zhao Song, David P. Woodruff, Xin Yang", "title": "Total Least Squares Regression in Input Sparsity Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the total least squares problem, one is given an $m \\times n$ matrix $A$,\nand an $m \\times d$ matrix $B$, and one seeks to \"correct\" both $A$ and $B$,\nobtaining matrices $\\hat{A}$ and $\\hat{B}$, so that there exists an $X$\nsatisfying the equation $\\hat{A}X = \\hat{B}$. Typically the problem is\noverconstrained, meaning that $m \\gg \\max(n,d)$. The cost of the solution\n$\\hat{A}, \\hat{B}$ is given by $\\|A-\\hat{A}\\|_F^2 + \\|B - \\hat{B}\\|_F^2$. We\ngive an algorithm for finding a solution $X$ to the linear system\n$\\hat{A}X=\\hat{B}$ for which the cost $\\|A-\\hat{A}\\|_F^2 + \\|B-\\hat{B}\\|_F^2$\nis at most a multiplicative $(1+\\epsilon)$ factor times the optimal cost, up to\nan additive error $\\eta$ that may be an arbitrarily small function of $n$.\nImportantly, our running time is $\\tilde{O}( \\mathrm{nnz}(A) + \\mathrm{nnz}(B)\n) + \\mathrm{poly}(n/\\epsilon) \\cdot d$, where for a matrix $C$,\n$\\mathrm{nnz}(C)$ denotes its number of non-zero entries. Importantly, our\nrunning time does not directly depend on the large parameter $m$. As total\nleast squares regression is known to be solvable via low rank approximation, a\nnatural approach is to invoke fast algorithms for approximate low rank\napproximation, obtaining matrices $\\hat{A}$ and $\\hat{B}$ from this low rank\napproximation, and then solving for $X$ so that $\\hat{A}X = \\hat{B}$. However,\nexisting algorithms do not apply since in total least squares the rank of the\nlow rank approximation needs to be $n$, and so the running time of known\nmethods would be at least $mn^2$. In contrast, we are able to achieve a much\nfaster running time for finding $X$ by never explicitly forming the equation\n$\\hat{A} X = \\hat{B}$, but instead solving for an $X$ which is a solution to an\nimplicit such equation. Finally, we generalize our algorithm to the total least\nsquares problem with regularization.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 00:02:57 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Diao", "Huaian", ""], ["Song", "Zhao", ""], ["Woodruff", "David P.", ""], ["Yang", "Xin", ""]]}, {"id": "1909.12460", "submitter": "Mohit Sharma", "authors": "Kevin Zhang, Mohit Sharma, Manuela Veloso, and Oliver Kroemer", "title": "Leveraging Multimodal Haptic Sensory Data for Robust Cutting", "comments": "Accepted as conference paper at Humanoids'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cutting is a common form of manipulation when working with divisible objects\nsuch as food, rope, or clay. Cooking in particular relies heavily on cutting to\ndivide food items into desired shapes. However, cutting food is a challenging\ntask due to the wide range of material properties exhibited by food items. Due\nto this variability, the same cutting motions cannot be used for all food\nitems. Sensations from contact events, e.g., when placing the knife on the food\nitem, will also vary depending on the material properties, and the robot will\nneed to adapt accordingly. In this paper, we propose using vibrations and\nforce-torque feedback from the interactions to adapt the slicing motions and\nmonitor for contact events. The robot learns neural networks for performing\neach of these tasks and generalizing across different material properties. By\nadapting and monitoring the skill executions, the robot is able to reliably cut\nthrough more than 20 different types of food items and even detect whether\ncertain food items are fresh or old.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 01:54:17 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Zhang", "Kevin", ""], ["Sharma", "Mohit", ""], ["Veloso", "Manuela", ""], ["Kroemer", "Oliver", ""]]}, {"id": "1909.12472", "submitter": "Ruisen Luo", "authors": "Ruisen Luo, Tao Hu, Zuodong Tang, Chen Wang, Xiaofeng Gong, and Haiyan\n  Tu", "title": "A Radio Signal Modulation Recognition Algorithm Based on Residual\n  Networks and Attention Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve the problem of inaccurate recognition of types of communication\nsignal modulation, a RNN neural network recognition algorithm combining\nresidual block network with attention mechanism is proposed. In this method, 10\nkinds of communication signals with Gaussian white noise are generated from\nstandard data sets, such as MASK, MPSK, MFSK, OFDM, 16QAM, AM and FM. Based on\nthe original RNN neural network, residual block network is added to solve the\nproblem of gradient disappearance caused by deep network layers. Attention\nmechanism is added to the network to accelerate the gradient descent. In the\nexperiment, 16QAM, 2FSK and 4FSK are used as actual samples, IQ data frames of\nsignals are used as input, and the RNN neural network combined with residual\nblock network and attention mechanism is trained. The final recognition results\nshow that the average recognition rate of real-time signals is over 93%. The\nnetwork has high robustness and good use value.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 02:26:19 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Luo", "Ruisen", ""], ["Hu", "Tao", ""], ["Tang", "Zuodong", ""], ["Wang", "Chen", ""], ["Gong", "Xiaofeng", ""], ["Tu", "Haiyan", ""]]}, {"id": "1909.12473", "submitter": "Gaurav Gupta", "authors": "Gaurav Gupta, Anit Kumar Sahu, Wan-Yi Lin", "title": "Noisy Batch Active Learning with Deterministic Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of training machine learning models incrementally with\nbatches of samples annotated with noisy oracles. We select each batch of\nsamples that are important and also diverse via clustering and importance\nsampling. More importantly, we incorporate model uncertainty into the sampling\nprobability to compensate for poor estimation of the importance scores when the\ntraining data is too small to build a meaningful model. Experiments on\nbenchmark image classification datasets (MNIST, SVHN, CIFAR10, and EMNIST) show\nimprovement over existing active learning strategies. We introduce an extra\ndenoising layer to deep networks to make active learning robust to label noises\nand show significant improvements.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 02:33:30 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 21:00:27 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Gupta", "Gaurav", ""], ["Sahu", "Anit Kumar", ""], ["Lin", "Wan-Yi", ""]]}, {"id": "1909.12475", "submitter": "Jared Dunnmon", "authors": "Luke Oakden-Rayner, Jared Dunnmon, Gustavo Carneiro, Christopher R\\'e", "title": "Hidden Stratification Causes Clinically Meaningful Failures in Machine\n  Learning for Medical Imaging", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models for medical image analysis often suffer from poor\nperformance on important subsets of a population that are not identified during\ntraining or testing. For example, overall performance of a cancer detection\nmodel may be high, but the model still consistently misses a rare but\naggressive cancer subtype. We refer to this problem as hidden stratification,\nand observe that it results from incompletely describing the meaningful\nvariation in a dataset. While hidden stratification can substantially reduce\nthe clinical efficacy of machine learning models, its effects remain difficult\nto measure. In this work, we assess the utility of several possible techniques\nfor measuring and describing hidden stratification effects, and characterize\nthese effects on multiple medical imaging datasets. We find evidence that\nhidden stratification can occur in unidentified imaging subsets with low\nprevalence, low label quality, subtle distinguishing features, or spurious\ncorrelates, and that it can result in relative performance differences of over\n20% on clinically important subsets. Finally, we explore the clinical\nimplications of our findings, and suggest that evaluation of hidden\nstratification should be a critical component of any machine learning\ndeployment in medical imaging.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 02:42:58 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 09:44:33 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Oakden-Rayner", "Luke", ""], ["Dunnmon", "Jared", ""], ["Carneiro", "Gustavo", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1909.12486", "submitter": "Fu-Ming Guo", "authors": "Fu-Ming Guo, Sijia Liu, Finlay S. Mungall, Xue Lin and Yanzhi Wang", "title": "Reweighted Proximal Pruning for Large-Scale Language Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, pre-trained language representation flourishes as the mainstay of\nthe natural language understanding community, e.g., BERT. These pre-trained\nlanguage representations can create state-of-the-art results on a wide range of\ndownstream tasks. Along with continuous significant performance improvement,\nthe size and complexity of these pre-trained neural models continue to increase\nrapidly. Is it possible to compress these large-scale language representation\nmodels? How will the pruned language representation affect the downstream\nmulti-task transfer learning objectives? In this paper, we propose Reweighted\nProximal Pruning (RPP), a new pruning method specifically designed for a\nlarge-scale language representation model. Through experiments on SQuAD and the\nGLUE benchmark suite, we show that proximal pruned BERT keeps high accuracy for\nboth the pre-training task and the downstream multiple fine-tuning tasks at\nhigh prune ratio. RPP provides a new perspective to help us analyze what\nlarge-scale language representation might learn. Additionally, RPP makes it\npossible to deploy a large state-of-the-art language representation model such\nas BERT on a series of distinct devices (e.g., online servers, mobile phones,\nand edge devices).\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 04:10:10 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 01:23:53 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Guo", "Fu-Ming", ""], ["Liu", "Sijia", ""], ["Mungall", "Finlay S.", ""], ["Lin", "Xue", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1909.12488", "submitter": "Jakub Kone\\v{c}n\\'y", "authors": "Yihan Jiang, Jakub Kone\\v{c}n\\'y, Keith Rush, Sreeram Kannan", "title": "Improving Federated Learning Personalization via Model Agnostic Meta\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) refers to learning a high quality global model based\non decentralized data storage, without ever copying the raw data. A natural\nscenario arises with data created on mobile phones by the activity of their\nusers. Given the typical data heterogeneity in such situations, it is natural\nto ask how can the global model be personalized for every such device,\nindividually. In this work, we point out that the setting of Model Agnostic\nMeta Learning (MAML), where one optimizes for a fast, gradient-based, few-shot\nadaptation to a heterogeneous distribution of tasks, has a number of\nsimilarities with the objective of personalization for FL. We present FL as a\nnatural source of practical applications for MAML algorithms, and make the\nfollowing observations. 1) The popular FL algorithm, Federated Averaging, can\nbe interpreted as a meta learning algorithm. 2) Careful fine-tuning can yield a\nglobal model with higher accuracy, which is at the same time easier to\npersonalize. However, solely optimizing for the global model accuracy yields a\nweaker personalization result. 3) A model trained using a standard datacenter\noptimization method is much harder to personalize, compared to one trained\nusing Federated Averaging, supporting the first claim. These results raise new\nquestions for FL, MAML, and broader ML research.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 04:26:37 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Jiang", "Yihan", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["Rush", "Keith", ""], ["Kannan", "Sreeram", ""]]}, {"id": "1909.12513", "submitter": "Lin Song", "authors": "Lin Song, Yanwei Li, Zeming Li, Gang Yu, Hongbin Sun, Jian Sun,\n  Nanning Zheng", "title": "Learnable Tree Filter for Structure-preserving Feature Transform", "comments": "Accepted by NeurIPS-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning discriminative global features plays a vital role in semantic\nsegmentation. And most of the existing methods adopt stacks of local\nconvolutions or non-local blocks to capture long-range context. However, due to\nthe absence of spatial structure preservation, these operators ignore the\nobject details when enlarging receptive fields. In this paper, we propose the\nlearnable tree filter to form a generic tree filtering module that leverages\nthe structural property of minimal spanning tree to model long-range\ndependencies while preserving the details. Furthermore, we propose a highly\nefficient linear-time algorithm to reduce resource consumption. Thus, the\ndesigned modules can be plugged into existing deep neural networks\nconveniently. To this end, tree filtering modules are embedded to formulate a\nunified framework for semantic segmentation. We conduct extensive ablation\nstudies to elaborate on the effectiveness and efficiency of the proposed\nmethod. Specifically, it attains better performance with much less overhead\ncompared with the classic PSP block and Non-local operation under the same\nbackbone. Our approach is proved to achieve consistent improvements on several\nbenchmarks without bells-and-whistles. Code and models are available at\nhttps://github.com/StevenGrove/TreeFilter-Torch.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 06:36:39 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Song", "Lin", ""], ["Li", "Yanwei", ""], ["Li", "Zeming", ""], ["Yu", "Gang", ""], ["Sun", "Hongbin", ""], ["Sun", "Jian", ""], ["Zheng", "Nanning", ""]]}, {"id": "1909.12514", "submitter": "Han Liu", "authors": "Han Liu, Xianchao Zhang, Xiaotong Zhang, Qimai Li, Xiao-Ming Wu", "title": "Clustering Uncertain Data via Representative Possible Worlds with\n  Consistency Learning", "comments": "Accepted by IJCAI 2019 Workshops (AI for Internet of Things)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering uncertain data is an essential task in data mining for the\ninternet of things. Possible world based algorithms seem promising for\nclustering uncertain data. However, there are two issues in existing possible\nworld based algorithms: (1) They rely on all the possible worlds and treat them\nequally, but some marginal possible worlds may cause negative effects. (2) They\ndo not well utilize the consistency among possible worlds, since they conduct\nclustering or construct the affinity matrix on each possible world\nindependently. In this paper, we propose a representative possible world based\nconsistent clustering (RPC) algorithm for uncertain data. First, by introducing\nrepresentative loss and using Jensen-Shannon divergence as the distribution\nmeasure, we design a heuristic strategy for the selection of representative\npossible worlds, thus avoiding the negative effects caused by marginal possible\nworlds. Second, we integrate a consistency learning procedure into spectral\nclustering to deal with the representative possible worlds synergistically,\nthus utilizing the consistency to achieve better performance. Experimental\nresults show that our proposed algorithm performs better than the\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 06:36:47 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Liu", "Han", ""], ["Zhang", "Xianchao", ""], ["Zhang", "Xiaotong", ""], ["Li", "Qimai", ""], ["Wu", "Xiao-Ming", ""]]}, {"id": "1909.12518", "submitter": "Lior Kamma", "authors": "Allan Gr{\\o}nlund, Lior Kamma, Kasper Green Larsen, Alexander\n  Mathiasen, Jelani Nelson", "title": "Margin-Based Generalization Lower Bounds for Boosted Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is one of the most successful ideas in machine learning. The most\nwell-accepted explanations for the low generalization error of boosting\nalgorithms such as AdaBoost stem from margin theory. The study of margins in\nthe context of boosting algorithms was initiated by Schapire, Freund, Bartlett\nand Lee (1998) and has inspired numerous boosting algorithms and generalization\nbounds. To date, the strongest known generalization (upper bound) is the $k$th\nmargin bound of Gao and Zhou (2013). Despite the numerous generalization upper\nbounds that have been proved over the last two decades, nothing is known about\nthe tightness of these bounds. In this paper, we give the first margin-based\nlower bounds on the generalization error of boosted classifiers. Our lower\nbounds nearly match the $k$th margin bound and thus almost settle the\ngeneralization performance of boosted classifiers in terms of margins.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 06:56:47 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 14:39:11 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 08:07:50 GMT"}, {"version": "v4", "created": "Thu, 7 May 2020 05:56:19 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Gr\u00f8nlund", "Allan", ""], ["Kamma", "Lior", ""], ["Larsen", "Kasper Green", ""], ["Mathiasen", "Alexander", ""], ["Nelson", "Jelani", ""]]}, {"id": "1909.12525", "submitter": "Ashish Sinha", "authors": "Ashish Sinha, Yohei Sugawara, Yuichiro Hirano", "title": "GA-GAN: CT reconstruction from Biplanar DRRs using GAN with Guided\n  Attention", "comments": "4 pages, 4 figures, NeurIPS workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work investigates the use of guided attention in the reconstruction of\nCTvolumes from biplanar DRRs. We try to improve the visual image quality of the\nCT reconstruction using Guided Attention based GANs (GA-GAN). We also consider\nthe use of Vector Quantization (VQ) for the CT reconstruction so that the\nmemory usage can be reduced, maintaining the same visual image quality. To the\nbest of our knowledge no work has been done before that explores the Vector\nQuantization for this purpose. Although our findings show that our approaches\noutperform the previous works, still there is a lot of room for improvement.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 07:25:03 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 12:19:55 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Sinha", "Ashish", ""], ["Sugawara", "Yohei", ""], ["Hirano", "Yuichiro", ""]]}, {"id": "1909.12535", "submitter": "Duc Bui", "authors": "Duc Bui, Kshitiz Malik, Jack Goetz, Honglei Liu, Seungwhan Moon, Anuj\n  Kumar, Kang G. Shin", "title": "Federated User Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative personalization, such as through learned user representations\n(embeddings), can improve the prediction accuracy of neural-network-based\nmodels significantly. We propose Federated User Representation Learning (FURL),\na simple, scalable, privacy-preserving and resource-efficient way to utilize\nexisting neural personalization techniques in the Federated Learning (FL)\nsetting. FURL divides model parameters into federated and private parameters.\nPrivate parameters, such as private user embeddings, are trained locally, but\nunlike federated parameters, they are not transferred to or averaged on the\nserver. We show theoretically that this parameter split does not affect\ntraining for most model personalization approaches. Storing user embeddings\nlocally not only preserves user privacy, but also improves memory locality of\npersonalization compared to on-server training. We evaluate FURL on two\ndatasets, demonstrating a significant improvement in model quality with 8% and\n51% performance increases, and approximately the same level of performance as\ncentralized training with only 0% and 4% reductions. Furthermore, we show that\nuser embeddings learned in FL and the centralized setting have a very similar\nstructure, indicating that FURL can learn collaboratively through the shared\nparameters while preserving user privacy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 07:40:08 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Bui", "Duc", ""], ["Malik", "Kshitiz", ""], ["Goetz", "Jack", ""], ["Liu", "Honglei", ""], ["Moon", "Seungwhan", ""], ["Kumar", "Anuj", ""], ["Shin", "Kang G.", ""]]}, {"id": "1909.12537", "submitter": "Hugo Richard", "authors": "Hugo Richard, Lucas Martin, Ana Lu{\\i}sa Pinho, Jonathan Pillow,\n  Bertrand Thirion", "title": "Fast shared response model for fMRI data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shared response model provides a simple but effective framework to\nanalyse fMRI data of subjects exposed to naturalistic stimuli. However when the\nnumber of subjects or runs is large, fitting the model requires a large amount\nof memory and computational power, which limits its use in practice. In this\nwork, we introduce the FastSRM algorithm that relies on an intermediate\natlas-based representation. It provides considerable speed-up in time and\nmemory usage, hence it allows easy and fast large-scale analysis of\nnaturalistic-stimulus fMRI data. Using four different datasets, we show that\nour method matches the performance of the original SRM algorithm while being\nabout 5x faster and 20x to 40x more memory efficient. Based on this\ncontribution, we use FastSRM to predict age from movie watching data on the\nCamCAN sample. Besides delivering accurate predictions (mean absolute error of\n7.5 years), FastSRM extracts topographic patterns that are predictive of age,\ndemonstrating that brain activity during free perception reflects age.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 07:46:28 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 16:20:24 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Richard", "Hugo", ""], ["Martin", "Lucas", ""], ["Pinho", "Ana Lu\u0131sa", ""], ["Pillow", "Jonathan", ""], ["Thirion", "Bertrand", ""]]}, {"id": "1909.12552", "submitter": "Valerio Perrone", "authors": "Valerio Perrone, Huibin Shen, Matthias Seeger, Cedric Archambeau,\n  Rodolphe Jenatton", "title": "Learning search spaces for Bayesian optimization: Another view of\n  hyperparameter transfer learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a successful methodology to optimize black-box\nfunctions that are expensive to evaluate. While traditional methods optimize\neach black-box function in isolation, there has been recent interest in\nspeeding up BO by transferring knowledge across multiple related black-box\nfunctions. In this work, we introduce a method to automatically design the BO\nsearch space by relying on evaluations of previous black-box functions. We\ndepart from the common practice of defining a set of arbitrary search ranges a\npriori by considering search space geometries that are learned from historical\ndata. This simple, yet effective strategy can be used to endow many existing BO\nmethods with transfer learning properties. Despite its simplicity, we show that\nour approach considerably boosts BO by reducing the size of the search space,\nthus accelerating the optimization of a variety of black-box optimization\nproblems. In particular, the proposed approach combined with random search\nresults in a parameter-free, easy-to-implement, robust hyperparameter\noptimization strategy. We hope it will constitute a natural baseline for\nfurther research attempting to warm-start BO.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:22:48 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Perrone", "Valerio", ""], ["Shen", "Huibin", ""], ["Seeger", "Matthias", ""], ["Archambeau", "Cedric", ""], ["Jenatton", "Rodolphe", ""]]}, {"id": "1909.12555", "submitter": "Shen Li", "authors": "Shen Li, Bryan Hooi, Gim Hee Lee", "title": "Identifying through Flows for Recovering Latent Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifiability, or recovery of the true latent representations from which\nthe observed data originates, is de facto a fundamental goal of representation\nlearning. Yet, most deep generative models do not address the question of\nidentifiability, and thus fail to deliver on the promise of the recovery of the\ntrue latent sources that generate the observations. Recent work proposed\nidentifiable generative modelling using variational autoencoders (iVAE) with a\ntheory of identifiability. Due to the intractablity of KL divergence between\nvariational approximate posterior and the true posterior, however, iVAE has to\nmaximize the evidence lower bound (ELBO) of the marginal likelihood, leading to\nsuboptimal solutions in both theory and practice. In contrast, we propose an\nidentifiable framework for estimating latent representations using a flow-based\nmodel (iFlow). Our approach directly maximizes the marginal likelihood,\nallowing for theoretical guarantees on identifiability, thereby dispensing with\nvariational approximations. We derive its optimization objective in analytical\nform, making it possible to train iFlow in an end-to-end manner. Simulations on\nsynthetic data validate the correctness and effectiveness of our proposed\nmethod and demonstrate its practical advantages over other existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:37:13 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 00:48:12 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 01:07:37 GMT"}, {"version": "v4", "created": "Sun, 26 Apr 2020 07:21:45 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Li", "Shen", ""], ["Hooi", "Bryan", ""], ["Lee", "Gim Hee", ""]]}, {"id": "1909.12557", "submitter": "Heechang Ryu", "authors": "Heechang Ryu, Hayong Shin, Jinkyoo Park", "title": "Multi-Agent Actor-Critic with Hierarchical Graph Attention Network", "comments": "Accepted as a conference paper at the Thirty-Fourth AAAI Conference\n  on Artificial Intelligence (AAAI-20), New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most previous studies on multi-agent reinforcement learning focus on deriving\ndecentralized and cooperative policies to maximize a common reward and rarely\nconsider the transferability of trained policies to new tasks. This prevents\nsuch policies from being applied to more complex multi-agent tasks. To resolve\nthese limitations, we propose a model that conducts both representation\nlearning for multiple agents using hierarchical graph attention network and\npolicy learning using multi-agent actor-critic. The hierarchical graph\nattention network is specially designed to model the hierarchical relationships\namong multiple agents that either cooperate or compete with each other to\nderive more advanced strategic policies. Two attention networks, the\ninter-agent and inter-group attention layers, are used to effectively model\nindividual and group level interactions, respectively. The two attention\nnetworks have been proven to facilitate the transfer of learned policies to new\ntasks with different agent compositions and allow one to interpret the learned\nstrategies. Empirically, we demonstrate that the proposed model outperforms\nexisting methods in several mixed cooperative and competitive tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:40:01 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 02:38:58 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ryu", "Heechang", ""], ["Shin", "Hayong", ""], ["Park", "Jinkyoo", ""]]}, {"id": "1909.12566", "submitter": "Hamid Zafar", "authors": "Hamid Zafar, Maryam Tavakol, Jens Lehmann", "title": "Distantly Supervised Question Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of structured databases for Question Answering (QA) systems has\nled to developing methods, in which the problem of learning the correct answer\nefficiently is based on a linking task between the constituents of the question\nand the corresponding entries in the database. As a result, parsing the\nquestions in order to determine their main elements, which are required for\nanswer retrieval, becomes crucial. However, most datasets for QA systems lack\ngold annotations for parsing, i.e., labels are only available in the form of\n(question, formal-query, answer). In this paper, we propose a distantly\nsupervised learning framework based on reinforcement learning to learn the\nmentions of entities and relations in questions. We leverage the provided\nformal queries to characterize delayed rewards for optimizing a policy gradient\nobjective for the parsing model. An empirical evaluation of our approach shows\na significant improvement in the performance of entity and relation linking\ncompared to the state of the art. We also demonstrate that a more accurate\nparsing component enhances the overall performance of QA systems.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:58:20 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 13:31:12 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Zafar", "Hamid", ""], ["Tavakol", "Maryam", ""], ["Lehmann", "Jens", ""]]}, {"id": "1909.12580", "submitter": "Malik Magdon-Ismail", "authors": "Malik Magdon-Ismail, Alex Gittens", "title": "Fast Fixed Dimension L2-Subspace Embeddings of Arbitrary Accuracy, With\n  Application to L1 and L2 Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a fast oblivious L2-embedding of $A\\in \\mathbb{R}^{n x d}$ to $B\\in\n\\mathbb{R}^{r x d}$ satisfying $(1-\\varepsilon)\\|A x\\|_2^2 \\le \\|B x\\|_2^2 <=\n(1+\\varepsilon) \\|Ax\\|_2^2.$ Our embedding dimension $r$ equals $d$, a constant\nindependent of the distortion $\\varepsilon$. We use as a black-box any\nL2-embedding $\\Pi^T A$ and inherit its runtime and accuracy, effectively\ndecoupling the dimension $r$ from runtime and accuracy, allowing downstream\nmachine learning applications to benefit from both a low dimension and high\naccuracy (in prior embeddings higher accuracy means higher dimension). We give\napplications of our L2-embedding to regression, PCA and statistical leverage\nscores. We also give applications to L1: 1.) An oblivious L1-embedding with\ndimension $d+O(d\\ln^{1+\\eta} d)$ and distortion $O((d\\ln d)/\\ln\\ln d)$, with\napplication to constructing well-conditioned bases; 2.) Fast approximation of\nL1-Lewis weights using our L2 embedding to quickly approximate L2-leverage\nscores.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 09:41:47 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Magdon-Ismail", "Malik", ""], ["Gittens", "Alex", ""]]}, {"id": "1909.12598", "submitter": "Apratim Bhattacharyya", "authors": "Apratim Bhattacharyya, Mario Fritz, Bernt Schiele", "title": "\"Best-of-Many-Samples\" Distribution Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) can achieve state-of-the-art sample\nquality in generative modelling tasks but suffer from the mode collapse\nproblem. Variational Autoencoders (VAE) on the other hand explicitly maximize a\nreconstruction-based data log-likelihood forcing it to cover all modes, but\nsuffer from poorer sample quality. Recent works have proposed hybrid VAE-GAN\nframeworks which integrate a GAN-based synthetic likelihood to the VAE\nobjective to address both the mode collapse and sample quality issues, with\nlimited success. This is because the VAE objective forces a trade-off between\nthe data log-likelihood and divergence to the latent prior. The synthetic\nlikelihood ratio term also shows instability during training. We propose a\nnovel objective with a \"Best-of-Many-Samples\" reconstruction cost and a stable\ndirect estimate of the synthetic likelihood. This enables our hybrid VAE-GAN\nframework to achieve high data log-likelihood and low divergence to the latent\nprior at the same time and shows significant improvement over both hybrid\nVAE-GANS and plain GANs in mode coverage and quality.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 10:23:42 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Bhattacharyya", "Apratim", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""]]}, {"id": "1909.12601", "submitter": "Kashif Ahmad Dr", "authors": "Naina Said, Kashif Ahmad, Nicola Conci, Ala Al-Fuqaha", "title": "Active Learning for Event Detection in Support of Disaster Analysis\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disaster analysis in social media content is one of the interesting research\ndomains having abundance of data. However, there is a lack of labeled data that\ncan be used to train machine learning models for disaster analysis\napplications. Active learning is one of the possible solutions to such problem.\nTo this aim, in this paper we propose and assess the efficacy of an active\nlearning based framework for disaster analysis using images shared on social\nmedia outlets. Specifically, we analyze the performance of different active\nlearning techniques employing several sampling and disagreement strategies.\nMoreover, we collect a large-scale dataset covering images from eight common\ntypes of natural disasters. The experimental results show that the use of\nactive learning techniques for disaster analysis using images results in a\nperformance comparable to that obtained using human annotated images, and could\nbe used in frameworks for disaster analysis in images without tedious job of\nmanual annotation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 10:28:10 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Said", "Naina", ""], ["Ahmad", "Kashif", ""], ["Conci", "Nicola", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "1909.12637", "submitter": "Vincent Fortuin", "authors": "Margherita Rosnati, Vincent Fortuin", "title": "MGP-AttTCN: An Interpretable Machine Learning Model for the Prediction\n  of Sepsis", "comments": "Published at PLOS ONE", "journal-ref": null, "doi": "10.1371/journal.pone.0251248", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a mortality rate of 5.4 million lives worldwide every year and a\nhealthcare cost of more than 16 billion dollars in the USA alone, sepsis is one\nof the leading causes of hospital mortality and an increasing concern in the\nageing western world. Recently, medical and technological advances have helped\nre-define the illness criteria of this disease, which is otherwise poorly\nunderstood by the medical society. Together with the rise of widely accessible\nElectronic Health Records, the advances in data mining and complex nonlinear\nalgorithms are a promising avenue for the early detection of sepsis. This work\ncontributes to the research effort in the field of automated sepsis detection\nwith an open-access labelling of the medical MIMIC-III data set. Moreover, we\npropose MGP-AttTCN: a joint multitask Gaussian Process and attention-based deep\nlearning model to early predict the occurrence of sepsis in an interpretable\nmanner. We show that our model outperforms the current state-of-the-art and\npresent evidence that different labelling heuristics lead to discrepancies in\ntask difficulty. For instance, when predicting sepsis five hours prior to onset\non our new realistic labels, our proposed model achieves an area under the ROC\ncurve of 0.660 and an area under the PR curve of 0.483, whereas the (less\ninterpretable) previous state-of-the-art model (MGP-TCN) achieves 0.635 AUROC\nand 0.460 AUPR and the popular commercial InSight model achieves 0.490 AUROC\nand 0.359 AUPR.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 11:55:24 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 16:36:40 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Rosnati", "Margherita", ""], ["Fortuin", "Vincent", ""]]}, {"id": "1909.12638", "submitter": "Jinchen Xuan", "authors": "Jinchen Xuan, Yunchang Yang, Ze Yang, Di He, Liwei Wang", "title": "On the Anomalous Generalization of GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models, especially Generative Adversarial Networks (GANs), have\nreceived significant attention recently. However, it has been observed that in\nterms of some attributes, e.g. the number of simple geometric primitives in an\nimage, GANs are not able to learn the target distribution in practice.\nMotivated by this observation, we discover two specific problems of GANs\nleading to anomalous generalization behaviour, which we refer to as the sample\ninsufficiency and the pixel-wise combination. For the first problem of sample\ninsufficiency, we show theoretically and empirically that the batchsize of the\ntraining samples in practice may be insufficient for the discriminator to learn\nan accurate discrimination function. It could result in unstable training\ndynamics for the generator, leading to anomalous generalization. For the second\nproblem of pixel-wise combination, we find that besides recognizing the\npositive training samples as real, under certain circumstances, the\ndiscriminator could be fooled to recognize the pixel-wise combinations (e.g.\npixel-wise average) of the positive training samples as real. However, those\ncombinations could be visually different from the real samples in the target\ndistribution. With the fooled discriminator as reference, the generator would\nobtain biased supervision further, leading to the anomalous generalization\nbehaviour. Additionally, in this paper, we propose methods to mitigate the\nanomalous generalization of GANs. Extensive experiments on benchmark show our\nproposed methods improve the FID score up to 30\\% on natural image dataset.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 12:00:41 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 06:27:06 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Xuan", "Jinchen", ""], ["Yang", "Yunchang", ""], ["Yang", "Ze", ""], ["He", "Di", ""], ["Wang", "Liwei", ""]]}, {"id": "1909.12641", "submitter": "Jack Goetz", "authors": "Jack Goetz, Kshitiz Malik, Duc Bui, Seungwhan Moon, Honglei Liu and\n  Anuj Kumar", "title": "Active Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning allows for population level models to be trained without\ncentralizing client data by transmitting the global model to clients,\ncalculating gradients locally, then averaging the gradients. Downloading models\nand uploading gradients uses the client's bandwidth, so minimizing these\ntransmission costs is important. The data on each client is highly variable, so\nthe benefit of training on different clients may differ dramatically. To\nexploit this we propose Active Federated Learning, where in each round clients\nare selected not uniformly at random, but with a probability conditioned on the\ncurrent model and the data on the client to maximize efficiency. We propose a\ncheap, simple and intuitive sampling scheme which reduces the number of\nrequired training iterations by 20-70% while maintaining the same model\naccuracy, and which mimics well known resampling techniques under certain\nconditions.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 12:15:42 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Goetz", "Jack", ""], ["Malik", "Kshitiz", ""], ["Bui", "Duc", ""], ["Moon", "Seungwhan", ""], ["Liu", "Honglei", ""], ["Kumar", "Anuj", ""]]}, {"id": "1909.12644", "submitter": "Shotaro Akaho", "authors": "Shotaro Akaho, Hideitsu Hino, Noboru Murata", "title": "On a convergence property of a geometrical algorithm for statistical\n  manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine a geometrical projection algorithm for statistical\ninference. The algorithm is based on Pythagorean relation and it is\nderivative-free as well as representation-free that is useful in nonparametric\ncases. We derive a bound of learning rate to guarantee local convergence. In\nspecial cases of m-mixture and e-mixture estimation problems, we calculate\nspecific forms of the bound that can be used easily in practice.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 12:23:52 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Akaho", "Shotaro", ""], ["Hino", "Hideitsu", ""], ["Murata", "Noboru", ""]]}, {"id": "1909.12655", "submitter": "Kosuke Arase", "authors": "Kosuke Arase, Yusuke Mukuta, and Tatsuya Harada", "title": "Rethinking Task and Metrics of Instance Segmentation on 3D Point Clouds", "comments": "The 4th Workshop on Geometry Meets Deep Learning (ICCV Workshop 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance segmentation on 3D point clouds is one of the most extensively\nresearched areas toward the realization of autonomous cars and robots. Certain\nexisting studies have split input point clouds into small regions such as 1m x\n1m; one reason for this is that models in the studies cannot consume a large\nnumber of points because of the large space complexity. However, because such\nsmall regions occasionally include a very small number of instances belonging\nto the same class, an evaluation using existing metrics such as mAP is largely\naffected by the category recognition performance. To address these problems, we\npropose a new method with space complexity O(Np) such that large regions can be\nconsumed, as well as novel metrics for tasks that are independent of the\ncategories or size of the inputs. Our method learns a mapping from input point\nclouds to an embedding space, where the embeddings form clusters for each\ninstance and distinguish instances using these clusters during testing. Our\nmethod achieves state-of-the-art performance using both existing and the\nproposed metrics. Moreover, we show that our new metric can evaluate the\nperformance of a task without being affected by any other condition.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 12:45:12 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Arase", "Kosuke", ""], ["Mukuta", "Yusuke", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1909.12673", "submitter": "Jonathan Rosenfeld", "authors": "Jonathan S. Rosenfeld, Amir Rosenfeld, Yonatan Belinkov, Nir Shavit", "title": "A Constructive Prediction of the Generalization Error Across Scales", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dependency of the generalization error of neural networks on model and\ndataset size is of critical importance both in practice and for understanding\nthe theory of neural networks. Nevertheless, the functional form of this\ndependency remains elusive. In this work, we present a functional form which\napproximates well the generalization error in practice. Capitalizing on the\nsuccessful concept of model scaling (e.g., width, depth), we are able to\nsimultaneously construct such a form and specify the exact models which can\nattain it across model/data scales. Our construction follows insights obtained\nfrom observations conducted over a range of model/data scales, in various model\ntypes and datasets, in vision and language tasks. We show that the form both\nfits the observations well across scales, and provides accurate predictions\nfrom small- to large-scale models and data.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 13:27:53 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 18:20:34 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Rosenfeld", "Jonathan S.", ""], ["Rosenfeld", "Amir", ""], ["Belinkov", "Yonatan", ""], ["Shavit", "Nir", ""]]}, {"id": "1909.12699", "submitter": "Sainath Adapa", "authors": "Sainath Adapa", "title": "Urban Sound Tagging using Convolutional Neural Networks", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a framework for environmental sound classification\nin a low-data context (less than 100 labeled examples per class). We show that\nusing pre-trained image classification models along with the usage of data\naugmentation techniques results in higher performance over alternative\napproaches. We applied this system to the task of Urban Sound Tagging, part of\nthe DCASE 2019. The objective was to label different sources of noise from raw\naudio data. A modified form of MobileNetV2, a convolutional neural network\n(CNN) model was trained to classify both coarse and fine tags jointly. The\nproposed model uses log-scaled Mel-spectrogram as the representation format for\nthe audio data. Mixup, Random erasing, scaling, and shifting are used as data\naugmentation techniques. A second model that uses scaled labels was built to\naccount for human errors in the annotations. The proposed model achieved the\nfirst rank on the leaderboard with Micro-AUPRC values of 0.751 and 0.860 on\nfine and coarse tags, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 14:14:58 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Adapa", "Sainath", ""]]}, {"id": "1909.12701", "submitter": "Ran Tian", "authors": "Ran Tian, Nan Li, Ilya Kolmanovsky, and Anouck Girard", "title": "Beating humans in a penny-matching game by leveraging cognitive\n  hierarchy theory and Bayesian learning", "comments": "IEEE 2020 American Control Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a long-standing goal of artificial intelligence (AI) to be superior to\nhuman beings in decision making. Games are suitable for testing AI capabilities\nof making good decisions in non-numerical tasks. In this paper, we develop a\nnew AI algorithm to play the penny-matching game considered in Shannon's\n\"mind-reading machine\" (1953) against human players. In particular, we exploit\ncognitive hierarchy theory and Bayesian learning techniques to continually\nevolve a model for predicting human player decisions, and let the AI player\nmake decisions according to the model predictions to pursue the best chance of\nwinning. Experimental results show that our AI algorithm beats 27 out of 30\nvolunteer human players.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 14:16:50 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 14:41:13 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 06:17:30 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Tian", "Ran", ""], ["Li", "Nan", ""], ["Kolmanovsky", "Ilya", ""], ["Girard", "Anouck", ""]]}, {"id": "1909.12702", "submitter": "Sunil Aryal", "authors": "Sunil Aryal, Arbind Agrahari Baniya and KC Santosh", "title": "Improved histogram-based anomaly detector with the extended principal\n  component features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this era of big data, databases are growing rapidly in terms of the number\nof records. Fast automatic detection of anomalous records in these massive\ndatabases is a challenging task. Traditional distance based anomaly detectors\nare not applicable in these massive datasets. Recently, a simple but extremely\nfast anomaly detector using one-dimensional histograms has been introduced. The\nanomaly score of a data instance is computed as the product of the probability\nmass of histograms in each dimensions where it falls into. It is shown to\nproduce competitive results compared to many state-of-the-art methods in many\ndatasets. Because it assumes data features are independent of each other, it\nresults in poor detection accuracy when there is correlation between features.\nTo address this issue, we propose to increase the feature size by adding more\nfeatures based on principal components. Our results show that using the\noriginal input features together with principal components improves the\ndetection accuracy of histogram-based anomaly detector significantly without\ncompromising much in terms of run-time.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 14:18:10 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Aryal", "Sunil", ""], ["Baniya", "Arbind Agrahari", ""], ["Santosh", "KC", ""]]}, {"id": "1909.12732", "submitter": "Shruti Tople", "authors": "Shruti Tople and Amit Sharma and Aditya Nori", "title": "Alleviating Privacy Attacks via Causal Learning", "comments": "Accepted at International Conference on Machine Learning, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models, especially deep neural networks have been shown to\nbe susceptible to privacy attacks such as membership inference where an\nadversary can detect whether a data point was used for training a black-box\nmodel. Such privacy risks are exacerbated when a model's predictions are used\non an unseen data distribution. To alleviate privacy attacks, we demonstrate\nthe benefit of predictive models that are based on the causal relationships\nbetween input features and the outcome. We first show that models learnt using\ncausal structure generalize better to unseen data, especially on data from\ndifferent distributions than the train distribution. Based on this\ngeneralization property, we establish a theoretical link between causality and\nprivacy: compared to associational models, causal models provide stronger\ndifferential privacy guarantees and are more robust to membership inference\nattacks. Experiments on simulated Bayesian networks and the colored-MNIST\ndataset show that associational models exhibit upto 80% attack accuracy under\ndifferent test distributions and sample sizes whereas causal models exhibit\nattack accuracy close to a random guess.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:06:42 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 18:15:45 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 16:20:02 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 14:02:13 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Tople", "Shruti", ""], ["Sharma", "Amit", ""], ["Nori", "Aditya", ""]]}, {"id": "1909.12734", "submitter": "Praneeth Vepakomma", "authors": "Indu Ilanchezian, Praneeth Vepakomma, Abhishek Singh, Otkrist Gupta,\n  G. N. Srinivasa Prasanna, Ramesh Raskar", "title": "Maximal adversarial perturbations for obfuscation: Hiding certain\n  attributes while preserving rest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the usage of adversarial perturbations for the\npurpose of privacy from human perception and model (machine) based detection.\nWe employ adversarial perturbations for obfuscating certain variables in raw\ndata while preserving the rest. Current adversarial perturbation methods are\nused for data poisoning with minimal perturbations of the raw data such that\nthe machine learning model's performance is adversely impacted while the human\nvision cannot perceive the difference in the poisoned dataset due to minimal\nnature of perturbations. We instead apply relatively maximal perturbations of\nraw data to conditionally damage model's classification of one attribute while\npreserving the model performance over another attribute. In addition, the\nmaximal nature of perturbation helps adversely impact human perception in\nclassifying hidden attribute apart from impacting model performance. We\nvalidate our result qualitatively by showing the obfuscated dataset and\nquantitatively by showing the inability of models trained on clean data to\npredict the hidden attribute from the perturbed dataset while being able to\npredict the rest of attributes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:08:46 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Ilanchezian", "Indu", ""], ["Vepakomma", "Praneeth", ""], ["Singh", "Abhishek", ""], ["Gupta", "Otkrist", ""], ["Prasanna", "G. N. Srinivasa", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1909.12737", "submitter": "Gon\\c{c}alo Faria", "authors": "Gon\\c{c}alo Faria", "title": "Learning to compute inner consensus: A novel approach to modeling\n  agreement between Capsules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This project considers Capsule Networks, a recently introduced machine\nlearning model that has shown promising results regarding generalization and\npreservation of spatial information with few parameters. The Capsule Network's\ninner routing procedures thus far proposed, a priori, establish how the routing\nrelations are modeled, which limits the expressiveness of the underlying model.\nIn this project, we propose two distinct ways in which the routing procedure\ncan be learned like any other network parameter.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:13:13 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 23:33:53 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 15:46:01 GMT"}, {"version": "v4", "created": "Wed, 11 Dec 2019 16:33:03 GMT"}, {"version": "v5", "created": "Thu, 9 Jan 2020 18:22:45 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Faria", "Gon\u00e7alo", ""]]}, {"id": "1909.12741", "submitter": "R\\'emi Bernhard", "authors": "R\\'emi Bernhard, Pierre-Alain Moellic and Jean-Max Dutertre", "title": "Impact of Low-bitwidth Quantization on the Adversarial Robustness for\n  Embedded Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the will to deploy neural networks models on embedded systems grows, and\nconsidering the related memory footprint and energy consumption issues, finding\nlighter solutions to store neural networks such as weight quantization and more\nefficient inference methods become major research topics. Parallel to that,\nadversarial machine learning has risen recently with an impressive and\nsignificant attention, unveiling some critical flaws of machine learning\nmodels, especially neural networks. In particular, perturbed inputs called\nadversarial examples have been shown to fool a model into making incorrect\npredictions. In this article, we investigate the adversarial robustness of\nquantized neural networks under different threat models for a classical\nsupervised image classification task. We show that quantization does not offer\nany robust protection, results in severe form of gradient masking and advance\nsome hypotheses to explain it. However, we experimentally observe poor\ntransferability capacities which we explain by quantization value shift\nphenomenon and gradient misalignment and explore how these results can be\nexploited with an ensemble-based defense.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:18:37 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:34:24 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Bernhard", "R\u00e9mi", ""], ["Moellic", "Pierre-Alain", ""], ["Dutertre", "Jean-Max", ""]]}, {"id": "1909.12743", "submitter": "Reza Bahmanyar", "authors": "Reza Bahmanyar, Elenora Vig, and Peter Reinartz", "title": "MRCNet: Crowd Counting and Density Map Estimation in Aerial and Ground\n  Imagery", "comments": null, "journal-ref": "BMVC Workshop on Object Detection and Recognition for Security\n  Screenin (BMVC-ODRSS) 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the many advantages of aerial imagery for crowd monitoring and\nmanagement at mass events, datasets of aerial images of crowds are still\nlacking in the field. As a remedy, in this work we introduce a novel crowd\ndataset, the DLR Aerial Crowd Dataset (DLR-ACD), which is composed of 33 large\naerial images acquired from 16 flight campaigns over mass events with 226,291\npersons annotated. To the best of our knowledge, DLR-ACD is the first aerial\ncrowd dataset and will be released publicly. To tackle the problem of accurate\ncrowd counting and density map estimation in aerial images of crowds, this work\nalso proposes a new encoder-decoder convolutional neural network, the so-called\nMulti-Resolution Crowd Network MRCNet. The encoder is based on the VGG-16\nnetwork and the decoder is composed of a set of bilinear upsampling and\nconvolutional layers. Using two losses, one at an earlier level and another at\nthe last level of the decoder, MRCNet estimates crowd counts and\nhigh-resolution crowd density maps as two different but interrelated tasks. In\naddition, MRCNet utilizes contextual and detailed local information by\ncombining high- and low-level features through a number of lateral connections\ninspired by the Feature Pyramid Network (FPN) technique. We evaluated MRCNet on\nthe proposed DLR-ACD dataset as well as on the ShanghaiTech dataset, a\nCCTV-based crowd counting benchmark. The results demonstrate that MRCNet\noutperforms the state-of-the-art crowd counting methods in estimating the crowd\ncounts and density maps for both aerial and CCTV-based images.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:22:23 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Bahmanyar", "Reza", ""], ["Vig", "Elenora", ""], ["Reinartz", "Peter", ""]]}, {"id": "1909.12744", "submitter": "St\\'ephane Clinchant", "authors": "St\\'ephane Clinchant, Kweon Woo Jung and Vassilina Nikoulina", "title": "On the use of BERT for Neural Machine Translation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting large pretrained models for various NMT tasks have gained a lot of\nvisibility recently. In this work we study how BERT pretrained models could be\nexploited for supervised Neural Machine Translation. We compare various ways to\nintegrate pretrained BERT model with NMT model and study the impact of the\nmonolingual data used for BERT training on the final translation quality. We\nuse WMT-14 English-German, IWSLT15 English-German and IWSLT14 English-Russian\ndatasets for these experiments. In addition to standard task test set\nevaluation, we perform evaluation on out-of-domain test sets and noise injected\ntest sets, in order to assess how BERT pretrained representations affect model\nrobustness.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:23:17 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Clinchant", "St\u00e9phane", ""], ["Jung", "Kweon Woo", ""], ["Nikoulina", "Vassilina", ""]]}, {"id": "1909.12778", "submitter": "Xiaohan Ding", "authors": "Xiaohan Ding, Guiguang Ding, Xiangxin Zhou, Yuchen Guo, Jungong Han,\n  Ji Liu", "title": "Global Sparse Momentum SGD for Pruning Very Deep Neural Networks", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) is powerful but computationally expensive and\nmemory intensive, thus impeding its practical usage on resource-constrained\nfront-end devices. DNN pruning is an approach for deep model compression, which\naims at eliminating some parameters with tolerable performance degradation. In\nthis paper, we propose a novel momentum-SGD-based optimization method to reduce\nthe network complexity by on-the-fly pruning. Concretely, given a global\ncompression ratio, we categorize all the parameters into two parts at each\ntraining iteration which are updated using different rules. In this way, we\ngradually zero out the redundant parameters, as we update them using only the\nordinary weight decay but no gradients derived from the objective function. As\na departure from prior methods that require heavy human works to tune the\nlayer-wise sparsity ratios, prune by solving complicated non-differentiable\nproblems or finetune the model after pruning, our method is characterized by 1)\nglobal compression that automatically finds the appropriate per-layer sparsity\nratios; 2) end-to-end training; 3) no need for a time-consuming re-training\nprocess after pruning; and 4) superior capability to find better winning\ntickets which have won the initialization lottery.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 16:24:19 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 17:21:53 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 15:39:02 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Ding", "Xiaohan", ""], ["Ding", "Guiguang", ""], ["Zhou", "Xiangxin", ""], ["Guo", "Yuchen", ""], ["Han", "Jungong", ""], ["Liu", "Ji", ""]]}, {"id": "1909.12789", "submitter": "Hongxun Jiang", "authors": "Yancong Xie, Hongxun Jiang", "title": "Stock Market Forecasting Based on Text Mining Technology: A Support\n  Vector Machine Method", "comments": "11 pages, 10 figures, 5 tables", "journal-ref": "J. Comp. 12 (2017) 500-510", "doi": "10.17706/jcp.12.6.500-510", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  News items have a significant impact on stock markets but the ways are\nobscure. Many previous works have aimed at finding accurate stock market\nforecasting models. In this paper, we use text mining and sentiment analysis on\nChinese online financial news, to predict Chinese stock tendency and stock\nprices based on support vector machine (SVM). Firstly, we collect 2,302,692\nnews items, which date from 1/1/2008 to 1/1/2015. Secondly, based on this\ndataset, a specific domain stop-word dictionary and a precise sentiment\ndictionary are formed. Thirdly, we propose a forecasting model using SVM. On\nthe algorithm of SVM implementation, we also propose two-parameter optimization\nalgorithms to search for the best initial parameter setting. The result shows\nthat parameter G has the main effect, while parameter C's effect is not\nobvious. Furthermore, support vector regression (SVR) models for different\nChinese stocks are similar whereas in support vector classification (SVC)\nmodels best parameters are quite differential. Series of contrast experiments\nshow that: a) News has significant influence on stock market; b) Expansion\ninput vector for additional situations when that day has no news data is better\nthan normal input in SVR, yet is worse in SVC; c) SVR shows a fantastic degree\nof fitting in predicting stock fluctuation while such result has some time lag;\nd) News effect time lag for stock market is less than two days; e) In SVC,\nhistoric stock data has a most efficient time lag which is about 10 days,\nwhereas in SVR this effect is not obvious. Besides, based on the special\nstructure of the input vector, we also design a method to calculate the\nfinancial source impact factor. Result suggests that the news quality and\naudience number both have a significant effect on the source impact factor.\nBesides, for Chinese investors, traditional media has more influence than\ndigital media.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 16:52:27 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Xie", "Yancong", ""], ["Jiang", "Hongxun", ""]]}, {"id": "1909.12790", "submitter": "Alvaro Sanchez-Gonzalez", "authors": "Alvaro Sanchez-Gonzalez, Victor Bapst, Kyle Cranmer, Peter Battaglia", "title": "Hamiltonian Graph Networks with ODE Integrators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach for imposing physically informed inductive biases in\nlearned simulation models. We combine graph networks with a differentiable\nordinary differential equation integrator as a mechanism for predicting future\nstates, and a Hamiltonian as an internal representation. We find that our\napproach outperforms baselines without these biases in terms of predictive\naccuracy, energy accuracy, and zero-shot generalization to time-step sizes and\nintegrator orders not experienced during training. This advances the\nstate-of-the-art of learned simulation, and in principle is applicable beyond\nphysical domains.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 16:54:04 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Sanchez-Gonzalez", "Alvaro", ""], ["Bapst", "Victor", ""], ["Cranmer", "Kyle", ""], ["Battaglia", "Peter", ""]]}, {"id": "1909.12792", "submitter": "Matteo Marsili", "authors": "O Duranthon, M Marsili and R Xie", "title": "Maximal Relevance and Optimal Learning Machines", "comments": "28 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cond-mat.stat-mech cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that the mutual information between the representation of a learning\nmachine and the hidden features that it extracts from data is bounded from\nbelow by the relevance, which is the entropy of the model's energy\ndistribution. Models with maximal relevance -- that we call Optimal Learning\nMachines (OLM) -- are hence expected to extract maximally informative\nrepresentations. We explore this principle in a range of models. For fully\nconnected Ising models and we show that {\\em i)} OLM are characterised by\ninhomogeneous distributions of couplings, and that {\\em ii)} their learning\nperformance is affected by sub-extensive features that are elusive to a\nthermodynamic treatment. On specific learning tasks, we find that likelihood\nmaximisation is achieved by models with maximal relevance. Training of\nRestricted Boltzmann Machines on the MNIST benchmark shows that learning is\nassociated with a broadening of the spectrum of energy levels and that the\ninternal representation of the hidden layer approaches the maximal relevance\nthat can be achieved in a finite dataset. Finally, we discuss a Gaussian\nlearning machine that clarifies that learning hidden features is conceptually\ndifferent from parameter estimation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 16:59:29 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 11:43:46 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 12:28:46 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Duranthon", "O", ""], ["Marsili", "M", ""], ["Xie", "R", ""]]}, {"id": "1909.12798", "submitter": "Hao Wang", "authors": "Hao Wang, Zonghu Wang, Weishi Zhang", "title": "Quantitative analysis of Matthew effect and sparsity problem of\n  recommender systems", "comments": null, "journal-ref": "2018 IEEE 3rd International Conference on Cloud Computing and Big\n  Data Analysis (ICCCBDA)", "doi": "10.1109/ICCCBDA.2018.8386490", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems have received great commercial success. Recommendation\nhas been used widely in areas such as e-commerce, online music FM, online news\nportal, etc. However, several problems related to input data structure pose\nserious challenge to recommender system performance. Two of these problems are\nMatthew effect and sparsity problem. Matthew effect heavily skews recommender\nsystem output towards popular items. Data sparsity problem directly affects the\ncoverage of recommendation result. Collaborative filtering is a simple\nbenchmark ubiquitously adopted in the industry as the baseline for recommender\nsystem design. Understanding the underlying mechanism of collaborative\nfiltering is crucial for further optimization. In this paper, we do a thorough\nquantitative analysis on Matthew effect and sparsity problem in the particular\ncontext setting of collaborative filtering. We compare the underlying mechanism\nof user-based and item-based collaborative filtering and give insight to\nindustrial recommender system builders.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 10:50:47 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wang", "Hao", ""], ["Wang", "Zonghu", ""], ["Zhang", "Weishi", ""]]}, {"id": "1909.12799", "submitter": "Anne-Marie Tousch", "authors": "Anne-Marie Tousch", "title": "How robust is MovieLens? A dataset analysis for recommender systems", "comments": "2 pages ; accepted at REVEAL workshop, RecSys 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research publication requires public datasets. In recommender systems, some\ndatasets are largely used to compare algorithms against a --supposedly-- common\nbenchmark. Problem: for various reasons, these datasets are heavily\npreprocessed, making the comparison of results across papers difficult. This\npaper makes explicit the variety of preprocessing and evaluation protocols to\ntest the robustness of a dataset (or lack of flexibility). While robustness is\ngood to compare results across papers, for flexible datasets we propose a\nmethod to select a preprocessing protocol and share results more transparently.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 09:36:31 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Tousch", "Anne-Marie", ""]]}, {"id": "1909.12823", "submitter": "Shayegan Omidshafiei", "authors": "Paul Muller, Shayegan Omidshafiei, Mark Rowland, Karl Tuyls, Julien\n  Perolat, Siqi Liu, Daniel Hennes, Luke Marris, Marc Lanctot, Edward Hughes,\n  Zhe Wang, Guy Lever, Nicolas Heess, Thore Graepel, Remi Munos", "title": "A Generalized Training Approach for Multiagent Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a population-based training regime based on\ngame-theoretic principles called Policy-Spaced Response Oracles (PSRO). PSRO is\ngeneral in the sense that it (1) encompasses well-known algorithms such as\nfictitious play and double oracle as special cases, and (2) in principle\napplies to general-sum, many-player games. Despite this, prior studies of PSRO\nhave been focused on two-player zero-sum games, a regime wherein Nash\nequilibria are tractably computable. In moving from two-player zero-sum games\nto more general settings, computation of Nash equilibria quickly becomes\ninfeasible. Here, we extend the theoretical underpinnings of PSRO by\nconsidering an alternative solution concept, $\\alpha$-Rank, which is unique\n(thus faces no equilibrium selection issues, unlike Nash) and applies readily\nto general-sum, many-player settings. We establish convergence guarantees in\nseveral games classes, and identify links between Nash equilibria and\n$\\alpha$-Rank. We demonstrate the competitive performance of\n$\\alpha$-Rank-based PSRO against an exact Nash solver-based PSRO in 2-player\nKuhn and Leduc Poker. We then go beyond the reach of prior PSRO applications by\nconsidering 3- to 5-player poker games, yielding instances where $\\alpha$-Rank\nachieves faster convergence than approximate Nash solvers, thus establishing it\nas a favorable general games solver. We also carry out an initial empirical\nvalidation in MuJoCo soccer, illustrating the feasibility of the proposed\napproach in another complex domain.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 17:49:53 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 15:04:45 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Muller", "Paul", ""], ["Omidshafiei", "Shayegan", ""], ["Rowland", "Mark", ""], ["Tuyls", "Karl", ""], ["Perolat", "Julien", ""], ["Liu", "Siqi", ""], ["Hennes", "Daniel", ""], ["Marris", "Luke", ""], ["Lanctot", "Marc", ""], ["Hughes", "Edward", ""], ["Wang", "Zhe", ""], ["Lever", "Guy", ""], ["Heess", "Nicolas", ""], ["Graepel", "Thore", ""], ["Munos", "Remi", ""]]}, {"id": "1909.12830", "submitter": "Brandon Amos", "authors": "Brandon Amos, Denis Yarats", "title": "The Differentiable Cross-Entropy Method", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the cross-entropy method (CEM) for the non-convex optimization of a\ncontinuous and parameterized objective function and introduce a differentiable\nvariant that enables us to differentiate the output of CEM with respect to the\nobjective function's parameters. In the machine learning setting this brings\nCEM inside of the end-to-end learning pipeline where this has otherwise been\nimpossible. We show applications in a synthetic energy-based structured\nprediction task and in non-convex continuous control. In the control setting we\nshow how to embed optimal action sequences into a lower-dimensional space. DCEM\nenables us to fine-tune CEM-based controllers with policy optimization.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 17:59:08 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 16:28:10 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 17:24:05 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 23:10:39 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Amos", "Brandon", ""], ["Yarats", "Denis", ""]]}, {"id": "1909.12868", "submitter": "Tong Niu", "authors": "Tong Niu, Mohit Bansal", "title": "Automatically Learning Data Augmentation Policies for Dialogue Tasks", "comments": "7 pages (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic data augmentation (AutoAugment) (Cubuk et al., 2019) searches for\noptimal perturbation policies via a controller trained using performance\nrewards of a sampled policy on the target task, hence reducing data-level model\nbias. While being a powerful algorithm, their work has focused on computer\nvision tasks, where it is comparatively easy to apply imperceptible\nperturbations without changing an image's semantic meaning. In our work, we\nadapt AutoAugment to automatically discover effective perturbation policies for\nnatural language processing (NLP) tasks such as dialogue generation. We start\nwith a pool of atomic operations that apply subtle semantic-preserving\nperturbations to the source inputs of a dialogue task (e.g., different POS-tag\ntypes of stopword dropout, grammatical errors, and paraphrasing). Next, we\nallow the controller to learn more complex augmentation policies by searching\nover the space of the various combinations of these atomic operations.\nMoreover, we also explore conditioning the controller on the source inputs of\nthe target task, since certain strategies may not apply to inputs that do not\ncontain that strategy's required linguistic features. Empirically, we\ndemonstrate that both our input-agnostic and input-aware controllers discover\nuseful data augmentation policies, and achieve significant improvements over\nthe previous state-of-the-art, including trained on manually-designed policies.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 18:40:23 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Niu", "Tong", ""], ["Bansal", "Mohit", ""]]}, {"id": "1909.12874", "submitter": "Zhiang Chen", "authors": "Zhiang Chen, Tyler R. Scott, Sarah Bearman, Harish Anand, Devin\n  Keating, Chelsea Scott, J Ramon Arrowsmith, Jnaneshwar Das", "title": "Geomorphological Analysis Using Unpiloted Aircraft Systems, Structure\n  from Motion, and Deep Learning", "comments": null, "journal-ref": "2020 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS)", "doi": "10.1109/IROS45743.2020.9341354", "report-no": null, "categories": "cs.RO astro-ph.EP cs.LG physics.geo-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a pipeline for geomorphological analysis that uses structure from\nmotion (SfM) and deep learning on close-range aerial imagery to estimate\nspatial distributions of rock traits (size, roundness, and orientation) along a\ntectonic fault scarp. The properties of the rocks on the fault scarp derive\nfrom the combination of initial volcanic fracturing and subsequent tectonic and\ngeomorphic fracturing, and our pipeline allows scientists to leverage UAS-based\nimagery to gain a better understanding of such surface processes. We start by\nusing SfM on aerial imagery to produce georeferenced orthomosaics and digital\nelevation models (DEM). A human expert then annotates rocks on a set of image\ntiles sampled from the orthomosaics, and these annotations are used to train a\ndeep neural network to detect and segment individual rocks in the entire site.\nThe extracted semantic information (rock masks) on large volumes of unlabeled,\nhigh-resolution SfM products allows subsequent structural analysis and shape\ndescriptors to estimate rock size, roundness, and orientation. We present\nresults of two experiments conducted along a fault scarp in the Volcanic\nTablelands near Bishop, California. We conducted the first, proof-of-concept\nexperiment with a DJI Phantom 4 Pro equipped with an RGB camera and inspected\nif elevation information assisted instance segmentation from RGB channels.\nRock-trait histograms along and across the fault scarp were obtained with the\nneural network inference. In the second experiment, we deployed a hexrotor and\na multispectral camera to produce a DEM and five spectral orthomosaics in red,\ngreen, blue, red edge, and near infrared. We focused on examining the\neffectiveness of different combinations of input channels in instance\nsegmentation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 18:57:28 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 03:09:03 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 04:47:11 GMT"}, {"version": "v4", "created": "Mon, 11 Jan 2021 06:55:06 GMT"}, {"version": "v5", "created": "Wed, 17 Feb 2021 18:16:18 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Chen", "Zhiang", ""], ["Scott", "Tyler R.", ""], ["Bearman", "Sarah", ""], ["Anand", "Harish", ""], ["Keating", "Devin", ""], ["Scott", "Chelsea", ""], ["Arrowsmith", "J Ramon", ""], ["Das", "Jnaneshwar", ""]]}, {"id": "1909.12892", "submitter": "Andrew Lampinen", "authors": "Sebastien Racaniere, Andrew K. Lampinen, Adam Santoro, David P.\n  Reichert, Vlad Firoiu, Timothy P. Lillicrap", "title": "Automated curricula through setter-solver interactions", "comments": null, "journal-ref": "International Conference on Learning Representations, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms use correlations between policies and\nrewards to improve agent performance. But in dynamic or sparsely rewarding\nenvironments these correlations are often too small, or rewarding events are\ntoo infrequent to make learning feasible. Human education instead relies on\ncurricula--the breakdown of tasks into simpler, static challenges with dense\nrewards--to build up to complex behaviors. While curricula are also useful for\nartificial agents, hand-crafting them is time consuming. This has lead\nresearchers to explore automatic curriculum generation. Here we explore\nautomatic curriculum generation in rich, dynamic environments. Using a\nsetter-solver paradigm we show the importance of considering goal validity,\ngoal feasibility, and goal coverage to construct useful curricula. We\ndemonstrate the success of our approach in rich but sparsely rewarding 2D and\n3D environments, where an agent is tasked to achieve a single goal selected\nfrom a set of possible goals that varies between episodes, and identify\nchallenges for future work. Finally, we demonstrate the value of a novel\ntechnique that guides agents towards a desired goal distribution. Altogether,\nthese results represent a substantial step towards applying automatic task\ncurricula to learn complex, otherwise unlearnable goals, and to our knowledge\nare the first to demonstrate automated curriculum generation for\ngoal-conditioned agents in environments where the possible goals vary between\nepisodes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 20:11:12 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 00:01:48 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Racaniere", "Sebastien", ""], ["Lampinen", "Andrew K.", ""], ["Santoro", "Adam", ""], ["Reichert", "David P.", ""], ["Firoiu", "Vlad", ""], ["Lillicrap", "Timothy P.", ""]]}, {"id": "1909.12894", "submitter": "Kostas Hatalis", "authors": "Kostas Hatalis, Parv Venkitasubramaniam, Shalinee Kishore", "title": "Modeling and Detection of Future Cyber-Enabled DSM Data Attacks using\n  Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand-Side Management (DSM) is a vital tool that can be used to ensure power\nsystem reliability and stability. In future smart grids, certain portions of a\ncustomers load usage could be under automatic control with a cyber-enabled DSM\nprogram which selectively schedules loads as a function of electricity prices\nto improve power balance and grid stability. In such a case, the security of\nDSM cyberinfrastructure will be critical as advanced metering infrastructure,\nand communication systems are susceptible to hacking, cyber-attacks. Such\nattacks, in the form of data injection, can manipulate customer load profiles\nand cause metering chaos and energy losses in the grid. These attacks are also\nexacerbated by the feedback mechanism between load management on the consumer\nside and dynamic price schemes by independent system operators. This work\nprovides a novel methodology for modeling and simulating the nonlinear\nrelationship between load management and real-time pricing. We then investigate\nthe behavior of such a feedback loop under intentional cyber-attacks using our\nfeedback model. We simulate and examine load-price data under different levels\nof DSM participation with three types of additive attacks: ramp, sudden, and\npoint attacks. We apply change point and supervised learning methods for\ndetection of DSM attacks. Results conclude that while higher levels of DSM\nparticipation can exacerbate attacks they also lead to better detection of such\nattacks. Further analysis of results shows that point attacks are the hardest\nto detect and supervised learning methods produce results on par or better than\nsequential detectors.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 20:14:47 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Hatalis", "Kostas", ""], ["Venkitasubramaniam", "Parv", ""], ["Kishore", "Shalinee", ""]]}, {"id": "1909.12898", "submitter": "Mahsa Ghasemi", "authors": "Mahsa Ghasemi, Abolfazl Hashemi, Haris Vikalo, Ufuk Topcu", "title": "Identifying Sparse Low-Dimensional Structures in Markov Chains: A\n  Nonnegative Matrix Factorization Approach", "comments": "Accepted for publication in American Control Conference (ACC)\n  Proceedings, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning low-dimensional representations for\nlarge-scale Markov chains. We formulate the task of representation learning as\nthat of mapping the state space of the model to a low-dimensional state space,\ncalled the kernel space. The kernel space contains a set of meta states which\nare desired to be representative of only a small subset of original states. To\npromote this structural property, we constrain the number of nonzero entries of\nthe mappings between the state space and the kernel space. By imposing the\ndesired characteristics of the representation, we cast the problem as a\nconstrained nonnegative matrix factorization. To compute the solution, we\npropose an efficient block coordinate gradient descent and theoretically\nanalyze its convergence properties.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 20:28:44 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 19:23:56 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ghasemi", "Mahsa", ""], ["Hashemi", "Abolfazl", ""], ["Vikalo", "Haris", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1909.12902", "submitter": "Denys Dutykh", "authors": "Beno\\^it Colange and Laurent Vuillon and Sylvain Lespinats and Denys\n  Dutykh", "title": "Interpreting Distortions in Dimensionality Reduction by Superimposing\n  Neighbourhood Graphs", "comments": "5 pages, 6 figures, 22 references. Paper presented at IEEE VIS 2019\n  Conference. Other author's papers can be downloaded at\n  http://www.denys-dutykh.com/", "journal-ref": "Paper presented at IEEE Vis 2019 conference at Vancouver, Canada", "doi": "10.1109/VISUAL.2019.8933568", "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To perform visual data exploration, many dimensionality reduction methods\nhave been developed. These tools allow data analysts to represent\nmultidimensional data in a 2D or 3D space, while preserving as much relevant\ninformation as possible. Yet, they cannot preserve all structures\nsimultaneously and they induce some unavoidable distortions. Hence, many\ncriteria have been introduced to evaluate a map's overall quality, mostly based\non the preservation of neighbourhoods. Such global indicators are currently\nused to compare several maps, which helps to choose the most appropriate\nmapping method and its hyperparameters. However, those aggregated indicators\ntend to hide the local repartition of distortions. Thereby, they need to be\nsupplemented by local evaluation to ensure correct interpretation of maps. In\nthis paper, we describe a new method, called MING, for `Map Interpretation\nusing Neighbourhood Graphs'. It offers a graphical interpretation of pairs of\nmap quality indicators, as well as local evaluation of the distortions. This is\ndone by displaying on the map the nearest neighbours graphs computed in the\ndata space and in the embedding. Shared and unshared edges exhibit reliable and\nunreliable neighbourhood information conveyed by the mapping. By this mean,\nanalysts may determine whether proximity (or remoteness) of points on the map\nfaithfully represents similarity (or dissimilarity) of original data, within\nthe meaning of a chosen map quality criteria. We apply this approach to two\npairs of widespread indicators: precision/recall and\ntrustworthiness/continuity, chosen for their wide use in the community, which\nwill allow an easy handling by users.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2019 07:48:26 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Colange", "Beno\u00eet", ""], ["Vuillon", "Laurent", ""], ["Lespinats", "Sylvain", ""], ["Dutykh", "Denys", ""]]}, {"id": "1909.12903", "submitter": "Shupeng Gui", "authors": "Shupeng Gui, Xiangliang Zhang, Pan Zhong, Shuang Qiu, Mingrui Wu,\n  Jieping Ye, Zhengdao Wang, and Ji Liu", "title": "PINE: Universal Deep Embedding for Graph Nodes via Partial Permutation\n  Invariant Set Functions", "comments": "24 pages, 4 figures, 3 tables. arXiv admin note: text overlap with\n  arXiv:1805.11182", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph node embedding aims at learning a vector representation for all nodes\ngiven a graph. It is a central problem in many machine learning tasks (e.g.,\nnode classification, recommendation, community detection). The key problem in\ngraph node embedding lies in how to define the dependence to neighbors.\nExisting approaches specify (either explicitly or implicitly) certain\ndependencies on neighbors, which may lead to loss of subtle but important\nstructural information within the graph and other dependencies among neighbors.\nThis intrigues us to ask the question: can we design a model to give the\nmaximal flexibility of dependencies to each node's neighborhood. In this paper,\nwe propose a novel graph node embedding (named PINE) via a novel notion of\npartial permutation invariant set function, to capture any possible dependence.\nOur method 1) can learn an arbitrary form of the representation function from\nthe neighborhood, withour losing any potential dependence structures, and 2) is\napplicable to both homogeneous and heterogeneous graph embedding, the latter of\nwhich is challenged by the diversity of node types. Furthermore, we provide\ntheoretical guarantee for the representation capability of our method for\ngeneral homogeneous and heterogeneous graphs. Empirical evaluation results on\nbenchmark data sets show that our proposed PINE method outperforms the\nstate-of-the-art approaches on producing node vectors for various learning\ntasks of both homogeneous and heterogeneous graphs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 18:35:03 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gui", "Shupeng", ""], ["Zhang", "Xiangliang", ""], ["Zhong", "Pan", ""], ["Qiu", "Shuang", ""], ["Wu", "Mingrui", ""], ["Ye", "Jieping", ""], ["Wang", "Zhengdao", ""], ["Liu", "Ji", ""]]}, {"id": "1909.12907", "submitter": "Xiaoyang Guo", "authors": "Xiaoyang Guo, Anuj Srivastava, Sudeep Sarkar", "title": "A Quotient Space Formulation for Generative Statistical Analysis of\n  Graphical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex analyses involving multiple, dependent random quantities often lead\nto graphical models - a set of nodes denoting variables of interest, and\ncorresponding edges denoting statistical interactions between nodes. To develop\nstatistical analyses for graphical data, especially towards generative\nmodeling, one needs mathematical representations and metrics for matching and\ncomparing graphs, and subsequent tools, such as geodesics, means, and\ncovariances. This paper utilizes a quotient structure to develop efficient\nalgorithms for computing these quantities, leading to useful statistical tools,\nincluding principal component analysis, statistical testing, and modeling. We\ndemonstrate the efficacy of this framework using datasets taken from several\nproblem areas, including letters, biochemical structures, and social networks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:29:04 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 01:33:17 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Guo", "Xiaoyang", ""], ["Srivastava", "Anuj", ""], ["Sarkar", "Sudeep", ""]]}, {"id": "1909.12912", "submitter": "Andre Pacheco", "authors": "Andre G. C. Pacheco and Renato A. Krohling", "title": "The impact of patient clinical information on automated skin cancer\n  detection", "comments": null, "journal-ref": null, "doi": "10.1016/j.compbiomed.2019.103545", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin cancer is one of the most common types of cancer around the world. For\nthis reason, over the past years, different approaches have been proposed to\nassist detect it. Nonetheless, most of them are based only on dermoscopy images\nand do not take into account the patient clinical information. In this work,\nfirst, we present a new dataset that contains clinical images, acquired from\nsmartphones, and patient clinical information of the skin lesions. Next, we\nintroduce a straightforward approach to combine the clinical data and the\nimages using different well-known deep learning models. These models are\napplied to the presented dataset using only the images and combining them with\nthe patient clinical information. We present a comprehensive study to show the\nimpact of the clinical data on the final predictions. The results obtained by\ncombining both sets of information show a general improvement of around 7% in\nthe balanced accuracy for all models. In addition, the statistical test\nindicates significant differences between the models with and without\nconsidering both data. The improvement achieved shows the potential of using\npatient clinical information in skin cancer detection and indicates that this\npiece of information is important to leverage skin cancer detection systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 14:27:12 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Pacheco", "Andre G. C.", ""], ["Krohling", "Renato A.", ""]]}, {"id": "1909.12913", "submitter": "Prabin Sharma", "authors": "Prabin Sharma, Shubham Joshi, Subash Gautam, Sneha Maharjan, Vitor\n  Filipe, Manuel J. C. S. Reis", "title": "Student Engagement Detection Using Emotion Analysis, Eye Tracking and\n  Head Movement with Machine Learning", "comments": "9 pages, 9 Figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increase of distance learning, in general, and e-learning, in\nparticular, having a system capable of determining the engagement of students\nis of primordial importance, and one of the biggest challenges, both for\nteachers, researchers and policy makers. Here, we present a system to detect\nthe engagement level of the students. It uses only information provided by the\ntypical built-in web-camera present in a laptop computer, and was designed to\nwork in real time. We combine information about the movements of the eyes and\nhead, and facial emotions to produce a concentration index with three classes\nof engagement: \"very engaged\", \"nominally engaged\" and \"not engaged at all\".\nThe system was tested in a typical e-learning scenario, and the results show\nthat it correctly identifies each period of time where students were \"very\nengaged\", \"nominally engaged\" and \"not engaged at all\". Additionally, the\nresults also show that the students with best scores also have higher\nconcentration indexes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 15:46:48 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 09:28:54 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 16:56:12 GMT"}, {"version": "v4", "created": "Sat, 26 Dec 2020 19:05:15 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Sharma", "Prabin", ""], ["Joshi", "Shubham", ""], ["Gautam", "Subash", ""], ["Maharjan", "Sneha", ""], ["Filipe", "Vitor", ""], ["Reis", "Manuel J. C. S.", ""]]}, {"id": "1909.12916", "submitter": "Lucas Pascal", "authors": "Lucas Pascal, Xavier Bost (LIA), Beno\\^it Huet", "title": "Semantic and Visual Similarities for Efficient Knowledge Transfer in CNN\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, representation learning approaches have disrupted many\nmultimedia computing tasks. Among those approaches, deep convolutional neural\nnetworks (CNNs) have notably reached human level expertise on some constrained\nimage classification tasks. Nonetheless, training CNNs from scratch for new\ntask or simply new data turns out to be complex and time-consuming. Recently,\ntransfer learning has emerged as an effective methodology for adapting\npre-trained CNNs to new data and classes, by only retraining the last\nclassification layer. This paper focuses on improving this process, in order to\nbetter transfer knowledge between CNN architectures for faster trainings in the\ncase of fine tuning for image classification. This is achieved by combining and\ntransfering supplementary weights, based on similarity considerations between\nsource and target classes. The study includes a comparison between semantic and\ncontent-based similarities, and highlights increased initial performances and\ntraining speed, along with superior long term performances when limited\ntraining samples are available.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 14:49:38 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Pascal", "Lucas", "", "LIA"], ["Bost", "Xavier", "", "LIA"], ["Huet", "Beno\u00eet", ""]]}, {"id": "1909.12925", "submitter": "David Isele", "authors": "Anahita Mohseni-Kabir, David Isele, and Kikuo Fujimura", "title": "Interaction-Aware Multi-Agent Reinforcement Learning for Mobile Agents\n  with Individual Goals", "comments": null, "journal-ref": "ICRA 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multi-agent setting, the optimal policy of a single agent is largely\ndependent on the behavior of other agents. We investigate the problem of\nmulti-agent reinforcement learning, focusing on decentralized learning in\nnon-stationary domains for mobile robot navigation. We identify a cause for the\ndifficulty in training non-stationary policies: mutual adaptation to\nsub-optimal behaviors, and we use this to motivate a curriculum-based strategy\nfor learning interactive policies. The curriculum has two stages. First, the\nagent leverages policy gradient algorithms to learn a policy that is capable of\nachieving multiple goals. Second, the agent learns a modifier policy to learn\nhow to interact with other agents in a multi-agent setting. We evaluated our\napproach on both an autonomous driving lane-change domain and a robot\nnavigation domain.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 20:49:05 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Mohseni-Kabir", "Anahita", ""], ["Isele", "David", ""], ["Fujimura", "Kikuo", ""]]}, {"id": "1909.12927", "submitter": "Basemah Alshemali", "authors": "Basemah Alshemali, Alta Graham, Jugal Kalita", "title": "Toward Robust Image Classification", "comments": "2019 Intelligent Systems Conference, pp 483-489", "journal-ref": "Intelligent Systems and Applications. IntelliSys 2019. Advances in\n  Intelligent Systems and Computing, vol 1038. Springer, Cham", "doi": "10.1007/978-3-030-29513-4", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are frequently used for image classification, but can be\nvulnerable to misclassification caused by adversarial images. Attempts to make\nneural network image classification more robust have included variations on\npreprocessing (cropping, applying noise, blurring), adversarial training, and\ndropout randomization. In this paper, we implemented a model for adversarial\ndetection based on a combination of two of these techniques: dropout\nrandomization with preprocessing applied to images within a given Bayesian\nuncertainty. We evaluated our model on the MNIST dataset, using adversarial\nimages generated using Fast Gradient Sign Method (FGSM), Jacobian-based\nSaliency Map Attack (JSMA) and Basic Iterative Method (BIM) attacks. Our model\nachieved an average adversarial image detection accuracy of 97%, with an\naverage image classification accuracy, after discarding images flagged as\nadversarial, of 99%. Our average detection accuracy exceeded that of recent\npapers using similar techniques.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 21:08:13 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Alshemali", "Basemah", ""], ["Graham", "Alta", ""], ["Kalita", "Jugal", ""]]}, {"id": "1909.12937", "submitter": "Manel Mart\\'inez-Ram\\'on", "authors": "Meenu Ajith and Manel Mart\\'inez-Ram\\'on", "title": "Unsupervised Segmentation of Fire and Smoke from Infra-Red Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a vision-based fire and smoke segmentation system which\nuse spatial, temporal and motion information to extract the desired regions\nfrom the video frames. The fusion of information is done using multiple\nfeatures such as optical flow, divergence and intensity values. These features\nextracted from the images are used to segment the pixels into different classes\nin an unsupervised way. A comparative analysis is done by using multiple\nclustering algorithms for segmentation. Here the Markov Random Field performs\nmore accurately than other segmentation algorithms since it characterizes the\nspatial interactions of pixels using a finite number of parameters. It builds a\nprobabilistic image model that selects the most likely labeling using the\nmaximum a posteriori (MAP) estimation. This unsupervised approach is tested on\nvarious images and achieves a frame-wise fire detection rate of 95.39%. Hence\nthis method can be used for early detection of fire in real-time and it can be\nincorporated into an indoor or outdoor surveillance system.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:19:17 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Ajith", "Meenu", ""], ["Mart\u00ednez-Ram\u00f3n", "Manel", ""]]}, {"id": "1909.12938", "submitter": "Akhil Gupta", "authors": "Akhil Gupta", "title": "Time Series Modeling for Dream Team in Fantasy Premier League", "comments": "International Conference on Sports Engineering (ICSE'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The performance of football players in English Premier League varies largely\nfrom season to season and for different teams. It is evident that a method\ncapable of forecasting and analyzing the future of these players on-field\nantics shall assist the management to a great extent. In a simulated\nenvironment like the Fantasy Premier League, enthusiasts from all over the\nworld participate and manage the players catalogue for the entire season. Due\nto the dynamic nature of points system, there is no known approach for the\nformulation of a dream team. This study aims to tackle this problem by using a\nhybrid of Autoregressive Integrated Moving Average (ARIMA) and Recurrent Neural\nNetworks (RNNs) for time series prediction of player points and subsequent\nmaximization of total points using Linear Programming (LPP). Given the player\npoints for the past three seasons, the predictions have been made for the\ncurrent season by modeling differently for ARIMA and RNN, and then creating an\nensemble of the same. Prior to that, proper data preprocessing techniques were\ndeployed to enhance the efficacy of the prepared model. Constraints on the type\nof players like goalkeepers, defenders, midfielders and forwards along with the\ntotal budget were effectively optimized using LPP approach. The validation of\nthe proposed team was done with the performance in upcoming season, where the\nplayers outperform as expected, and helped in strengthening the feasibility of\nthe solution. Likewise, the proposed approach can be extended to English\nPremier League by official managers on-field.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 20:20:04 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gupta", "Akhil", ""]]}, {"id": "1909.12940", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Shriphani Palakodety, Ashiqur R. KhudaBukhsh, Jaime G. Carbonell", "title": "Hope Speech Detection: A Computational Analysis of the Voice of Peace", "comments": "Minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent Pulwama terror attack (February 14, 2019, Pulwama, Kashmir)\ntriggered a chain of escalating events between India and Pakistan adding\nanother episode to their 70-year-old dispute over Kashmir. The present era of\nubiquitious social media has never seen nuclear powers closer to war. In this\npaper, we analyze this evolving international crisis via a substantial corpus\nconstructed using comments on YouTube videos (921,235 English comments posted\nby 392,460 users out of 2.04 million overall comments by 791,289 users on 2,890\nvideos). Our main contributions in the paper are three-fold. First, we present\nan observation that polyglot word-embeddings reveal precise and accurate\nlanguage clusters, and subsequently construct a document\nlanguage-identification technique with negligible annotation requirements. We\ndemonstrate the viability and utility across a variety of data sets involving\nseveral low-resource languages. Second, we present an analysis on temporal\ntrends of pro-peace and pro-war intent observing that when tensions between the\ntwo nations were at their peak, pro-peace intent in the corpus was at its\nhighest point. Finally, in the context of heated discussions in a politically\ntense situation where two nations are at the brink of a full-fledged war, we\nargue the importance of automatic identification of user-generated web content\nthat can diffuse hostility and address this prediction task, dubbed\n\\emph{hope-speech detection}.\n", "versions": [{"version": "v1", "created": "Wed, 11 Sep 2019 04:22:20 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 20:21:37 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 22:37:43 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 05:11:46 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Palakodety", "Shriphani", ""], ["KhudaBukhsh", "Ashiqur R.", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "1909.12942", "submitter": "Zheyu Yang", "authors": "Zheyu Yang, Yujie Wu, Guanrui Wang, Yukuan Yang, Guoqi Li, Lei Deng,\n  Jun Zhu, Luping Shi", "title": "DashNet: A Hybrid Artificial and Spiking Neural Network for High-speed\n  Object Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-science-oriented artificial neural networks (ANNs) have achieved\ntremendous success in a variety of scenarios via powerful feature extraction\nand high-precision data operations. It is well known, however, that ANNs\nusually suffer from expensive processing resources and costs. In contrast,\nneuroscience-oriented spiking neural networks (SNNs) are promising for\nenergy-efficient information processing benefit from the event-driven spike\nactivities, whereas, they are yet be evidenced to achieve impressive\neffectiveness on real complicated tasks. How to combine the advantage of these\ntwo model families is an open question of great interest. Two significant\nchallenges need to be addressed: (1) lack of benchmark datasets including both\nANN-oriented (frames) and SNN-oriented (spikes) signal resources; (2) the\ndifficulty in jointly processing the synchronous activation from ANNs and\nevent-driven spikes from SNNs. In this work, we proposed a hybrid paradigm,\nnamed as DashNet, to demonstrate the advantages of combining ANNs and SNNs in a\nsingle model. A simulator and benchmark dataset NFS-DAVIS is built, and a\ntemporal complementary filter (TCF) and attention module are designed to\naddress the two mentioned challenges, respectively. In this way, it is shown\nthat DashNet achieves the record-breaking speed of 2083FPS on neuromorphic\nchips and the best tracking performance on NFS-DAVIS and PRED18 datasets. To\nthe best of our knowledge, DashNet is the first framework that can integrate\nand process ANNs and SNNs in a hybrid paradigm, which provides a novel solution\nto achieve both effectiveness and efficiency for high-speed object tracking.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 14:59:53 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Yang", "Zheyu", ""], ["Wu", "Yujie", ""], ["Wang", "Guanrui", ""], ["Yang", "Yukuan", ""], ["Li", "Guoqi", ""], ["Deng", "Lei", ""], ["Zhu", "Jun", ""], ["Shi", "Luping", ""]]}, {"id": "1909.12943", "submitter": "Mesay Samuel", "authors": "Mesay Samuel Gondere, Lars Schmidt-Thieme, Abiot Sinamo Boltena, Hadi\n  Samer Jomaa", "title": "Handwritten Amharic Character Recognition Using a Convolutional Neural\n  Network", "comments": "ECDA2019 Conference Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amharic is the official language of the Federal Democratic Republic of\nEthiopia. There are lots of historic Amharic and Ethiopic handwritten documents\naddressing various relevant issues including governance, science, religious,\nsocial rules, cultures and art works which are very reach indigenous knowledge.\nThe Amharic language has its own alphabet derived from Ge'ez which is currently\nthe liturgical language in Ethiopia. Handwritten character recognition for non\nLatin scripts like Amharic is not addressed especially using the advantages of\nthe state of the art techniques. This research work designs for the first time\na model for Amharic handwritten character recognition using a convolutional\nneural network. The dataset was organized from collected sample handwritten\ndocuments and data augmentation was applied for machine learning. The model was\nfurther enhanced using multi-task learning from the relationships of the\ncharacters. Promising results are observed from the later model which can\nfurther be applied to word prediction.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 21:12:22 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gondere", "Mesay Samuel", ""], ["Schmidt-Thieme", "Lars", ""], ["Boltena", "Abiot Sinamo", ""], ["Jomaa", "Hadi Samer", ""]]}, {"id": "1909.12946", "submitter": "Toyotaro Suzumura Prof", "authors": "Toyotaro Suzumura, Yi Zhou, Natahalie Baracaldo, Guangnan Ye, Keith\n  Houck, Ryo Kawahara, Ali Anwar, Lucia Larise Stavarache, Yuji Watanabe, Pablo\n  Loyola, Daniel Klyashtorny, Heiko Ludwig, Kumar Bhaskaran", "title": "Towards Federated Graph Learning for Collaborative Financial Crimes\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG cs.SI q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial crime is a large and growing problem, in some way touching almost\nevery financial institution. Financial institutions are the front line in the\nwar against financial crime and accordingly, must devote substantial human and\ntechnology resources to this effort. Current processes to detect financial\nmisconduct have limitations in their ability to effectively differentiate\nbetween malicious behavior and ordinary financial activity. These limitations\ntend to result in gross over-reporting of suspicious activity that necessitate\ntime-intensive and costly manual review. Advances in technology used in this\ndomain, including machine learning based approaches, can improve upon the\neffectiveness of financial institutions' existing processes, however, a key\nchallenge that most financial institutions continue to face is that they\naddress financial crimes in isolation without any insight from other firms.\nWhere financial institutions address financial crimes through the lens of their\nown firm, perpetrators may devise sophisticated strategies that may span across\ninstitutions and geographies. Financial institutions continue to work\nrelentlessly to advance their capabilities, forming partnerships across\ninstitutions to share insights, patterns and capabilities. These public-private\npartnerships are subject to stringent regulatory and data privacy requirements,\nthereby making it difficult to rely on traditional technology solutions. In\nthis paper, we propose a methodology to share key information across\ninstitutions by using a federated graph learning platform that enables us to\nbuild more accurate machine learning models by leveraging federated learning\nand also graph learning approaches. We demonstrated that our federated model\noutperforms local model by 20% with the UK FCA TechSprint data set. This new\nplatform opens up a door to efficiently detecting global money laundering\nactivity.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 21:31:14 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 22:32:23 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Suzumura", "Toyotaro", ""], ["Zhou", "Yi", ""], ["Baracaldo", "Natahalie", ""], ["Ye", "Guangnan", ""], ["Houck", "Keith", ""], ["Kawahara", "Ryo", ""], ["Anwar", "Ali", ""], ["Stavarache", "Lucia Larise", ""], ["Watanabe", "Yuji", ""], ["Loyola", "Pablo", ""], ["Klyashtorny", "Daniel", ""], ["Ludwig", "Heiko", ""], ["Bhaskaran", "Kumar", ""]]}, {"id": "1909.12949", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker and Khaled Salah", "title": "AppsPred: Predicting Context-Aware Smartphone Apps using Random Forest\n  Learning", "comments": "28 pages", "journal-ref": "Journal: Internet of Things (IoT): Engineering Cyber-Physical\n  Human Systems, Elsevier, 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the popularity of context-awareness in the Internet of Things (IoT)\nand the recent advanced features in the most popular IoT device, i.e.,\nsmartphone, modeling and predicting personalized usage behavior based on\nrelevant contexts can be highly useful in assisting them to carry out daily\nroutines and activities. Usage patterns of different categories smartphone apps\nsuch as social networking, communication, entertainment, or daily life services\nrelated apps usually vary greatly between individuals. People use these apps\ndifferently in different contexts, such as temporal context, spatial context,\nindividual mood and preference, work status, Internet connectivity like Wifi?\nstatus, or device related status like phone profile, battery level etc. Thus,\nwe consider individuals' apps usage as a multi-class context-aware problem for\npersonalized modeling and prediction. Random Forest learning is one of the most\npopular machine learning techniques to build a multi-class prediction model.\nTherefore, in this paper, we present an effective context-aware smartphone apps\nprediction model, and name it \"AppsPred\" using random forest machine learning\ntechnique that takes into account optimal number of trees based on such\nmulti-dimensional contexts to build the resultant forest. The effectiveness of\nthis model is examined by conducting experiments on smartphone apps usage\ndatasets collected from individual users. The experimental results show that\nour AppsPred significantly outperforms other popular machine learning\nclassification approaches like ZeroR, Naive Bayes, Decision Tree, Support\nVector Machines, Logistic Regression while predicting smartphone apps in\nvarious context-aware test cases.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 11:43:37 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Salah", "Khaled", ""]]}, {"id": "1909.12950", "submitter": "Rico Jonschkowski", "authors": "Rico Jonschkowski and Austin Stone", "title": "Towards Object Detection from Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel approach to weakly supervised object detection. Instead of\nannotated images, our method only requires two short videos to learn to detect\na new object: 1) a video of a moving object and 2) one or more \"negative\"\nvideos of the scene without the object. The key idea of our algorithm is to\ntrain the object detector to produce physically plausible object motion when\napplied to the first video and to not detect anything in the second video. With\nthis approach, our method learns to locate objects without any object location\nannotations. Once the model is trained, it performs object detection on single\nimages. We evaluate our method in three robotics settings that afford learning\nobjects from motion: observing moving objects, watching demonstrations of\nobject manipulation, and physically interacting with objects (see a video\nsummary at https://youtu.be/BH0Hv3zZG_4).\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 18:00:14 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Jonschkowski", "Rico", ""], ["Stone", "Austin", ""]]}, {"id": "1909.12969", "submitter": "Matthew Olson", "authors": "Matthew L. Olson, Lawrence Neal, Fuxin Li, Weng-Keen Wong", "title": "Counterfactual States for Atari Agents via Generative Deep Learning", "comments": "IJCAI XAI Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep reinforcement learning agents have produced impressive results\nin many domains, their decision making is difficult to explain to humans. To\naddress this problem, past work has mainly focused on explaining why an action\nwas chosen in a given state. A different type of explanation that is useful is\na counterfactual, which deals with \"what if?\" scenarios. In this work, we\nintroduce the concept of a counterfactual state to help humans gain a better\nunderstanding of what would need to change (minimally) in an Atari game image\nfor the agent to choose a different action. We introduce a novel method to\ncreate counterfactual states from a generative deep learning architecture. In\naddition, we evaluate the effectiveness of counterfactual states on human\nparticipants who are not machine learning experts. Our user study results\nsuggest that our generated counterfactual states are useful in helping\nnon-expert participants gain a better understanding of an agent's decision\nmaking process.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 21:55:01 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Olson", "Matthew L.", ""], ["Neal", "Lawrence", ""], ["Li", "Fuxin", ""], ["Wong", "Weng-Keen", ""]]}, {"id": "1909.12982", "submitter": "Congzheng Song", "authors": "Congzheng Song, Reza Shokri", "title": "Robust Membership Encoding: Inference Attacks and Copyright Protection\n  for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning as a service (MLaaS), and algorithm marketplaces are on a\nrise. Data holders can easily train complex models on their data using third\nparty provided learning codes. Training accurate ML models requires massive\nlabeled data and advanced learning algorithms. The resulting models are\nconsidered as intellectual property of the model owners and their copyright\nshould be protected. Also, MLaaS needs to be trusted not to embed secret\ninformation about the training data into the model, such that it could be later\nretrieved when the model is deployed.\n  In this paper, we present \\emph{membership encoding} for training deep neural\nnetworks and encoding the membership information, i.e. whether a data point is\nused for training, for a subset of training data. Membership encoding has\nseveral applications in different scenarios, including robust watermarking for\nmodel copyright protection, and also the risk analysis of stealthy data\nembedding privacy attacks. Our encoding algorithm can determine the membership\nof significantly redacted data points, and is also robust to model compression\nand fine-tuning. It also enables encoding a significant fraction of the\ntraining set, with negligible drop in the model's prediction accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 23:17:13 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 01:28:12 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Song", "Congzheng", ""], ["Shokri", "Reza", ""]]}, {"id": "1909.12983", "submitter": "Pablo Navarrete Michelini", "authors": "Pablo Navarrete Michelini, Wenbin Chen, Hanwen Liu, Dan Zhu", "title": "MGBPv2: Scaling Up Multi-Grid Back-Projection Networks", "comments": "In ICCV 2019 Workshops. Winner of Perceptual track in AIM Extreme\n  Super-Resolution Challenge 2019. Code available at\n  https://github.com/pnavarre/mgbpv2", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Here, we describe our solution for the AIM-2019 Extreme Super-Resolution\nChallenge, where we won the 1st place in terms of perceptual quality (MOS)\nsimilar to the ground truth and achieved the 5th place in terms of\nhigh-fidelity (PSNR). To tackle this challenge, we introduce the second\ngeneration of MultiGrid BackProjection networks (MGBPv2) whose major\nmodifications make the system scalable and more general than its predecessor.\nIt combines the scalability of the multigrid algorithm and the performance of\niterative backprojections. In its original form, MGBP is limited to a small\nnumber of parameters due to a strongly recursive structure. In MGBPv2, we make\nfull use of the multigrid recursion from the beginning of the network; we allow\ndifferent parameters in every module of the network; we simplify the main\nmodules; and finally, we allow adjustments of the number of network features\nbased on the scale of operation. For inference tasks, we introduce an\noverlapping patch approach to further allow processing of very large images\n(e.g. 8K). Our training strategies make use of a multiscale loss, combining\ndistortion and/or perception losses on the output as well as downscaled output\nimages. The final system can balance between high quality and high performance.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 23:27:10 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Michelini", "Pablo Navarrete", ""], ["Chen", "Wenbin", ""], ["Liu", "Hanwen", ""], ["Zhu", "Dan", ""]]}, {"id": "1909.12989", "submitter": "Yuke Zhu", "authors": "Linxi Fan, Yuke Zhu, Jiren Zhu, Zihua Liu, Orien Zeng, Anchit Gupta,\n  Joan Creus-Costa, Silvio Savarese, Li Fei-Fei", "title": "SURREAL-System: Fully-Integrated Stack for Distributed Deep\n  Reinforcement Learning", "comments": "Technical report of the SURREAL system. See more details at\n  https://surreal.stanford.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an overview of SURREAL-System, a reproducible, flexible, and\nscalable framework for distributed reinforcement learning (RL). The framework\nconsists of a stack of four layers: Provisioner, Orchestrator, Protocol, and\nAlgorithms. The Provisioner abstracts away the machine hardware and node pools\nacross different cloud providers. The Orchestrator provides a unified interface\nfor scheduling and deploying distributed algorithms by high-level description,\nwhich is capable of deploying to a wide range of hardware from a personal\nlaptop to full-fledged cloud clusters. The Protocol provides network\ncommunication primitives optimized for RL. Finally, the SURREAL algorithms,\nsuch as Proximal Policy Optimization (PPO) and Evolution Strategies (ES), can\neasily scale to 1000s of CPU cores and 100s of GPUs. The learning performances\nof our distributed algorithms establish new state-of-the-art on OpenAI Gym and\nRobotics Suites tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 23:54:42 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 06:19:15 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Fan", "Linxi", ""], ["Zhu", "Yuke", ""], ["Zhu", "Jiren", ""], ["Liu", "Zihua", ""], ["Zeng", "Orien", ""], ["Gupta", "Anchit", ""], ["Creus-Costa", "Joan", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1909.12995", "submitter": "Wenhao Yu", "authors": "Wenhao Yu, Jie Tan, Yunfei Bai, Erwin Coumans, Sehoon Ha", "title": "Learning Fast Adaptation with Meta Strategy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to walk in new scenarios is a key milestone on the path toward\nreal-world applications of legged robots. In this work, we introduce Meta\nStrategy Optimization, a meta-learning algorithm for training policies with\nlatent variable inputs that can quickly adapt to new scenarios with a handful\nof trials in the target environment. The key idea behind MSO is to expose the\nsame adaptation process, Strategy Optimization (SO), to both the training and\ntesting phases. This allows MSO to effectively learn locomotion skills as well\nas a latent space that is suitable for fast adaptation. We evaluate our method\non a real quadruped robot and demonstrate successful adaptation in various\nscenarios, including sim-to-real transfer, walking with a weakened motor, or\nclimbing up a slope. Furthermore, we quantitatively analyze the generalization\ncapability of the trained policy in simulated environments. Both real and\nsimulated experiments show that our method outperforms previous methods in\nadaptation to novel tasks.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 00:57:58 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 03:26:57 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Yu", "Wenhao", ""], ["Tan", "Jie", ""], ["Bai", "Yunfei", ""], ["Coumans", "Erwin", ""], ["Ha", "Sehoon", ""]]}, {"id": "1909.13003", "submitter": "Yunbo Wang", "authors": "Yunbo Wang, Bo Liu, Jiajun Wu, Yuke Zhu, Simon S. Du, Li Fei-Fei,\n  Joshua B. Tenenbaum", "title": "DualSMC: Tunneling Differentiable Filtering and Planning under\n  Continuous POMDPs", "comments": "IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major difficulty of solving continuous POMDPs is to infer the multi-modal\ndistribution of the unobserved true states and to make the planning algorithm\ndependent on the perceived uncertainty. We cast POMDP filtering and planning\nproblems as two closely related Sequential Monte Carlo (SMC) processes, one\nover the real states and the other over the future optimal trajectories, and\ncombine the merits of these two parts in a new model named the DualSMC network.\nIn particular, we first introduce an adversarial particle filter that leverages\nthe adversarial relationship between its internal components. Based on the\nfiltering results, we then propose a planning algorithm that extends the\nprevious SMC planning approach [Piche et al., 2018] to continuous POMDPs with\nan uncertainty-dependent policy. Crucially, not only can DualSMC handle complex\nobservations such as image input but also it remains highly interpretable. It\nis shown to be effective in three continuous POMDP domains: the floor\npositioning domain, the 3D light-dark navigation domain, and a modified Reacher\ndomain.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 01:52:27 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 07:35:53 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 04:23:39 GMT"}, {"version": "v4", "created": "Thu, 7 May 2020 06:27:36 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Wang", "Yunbo", ""], ["Liu", "Bo", ""], ["Wu", "Jiajun", ""], ["Zhu", "Yuke", ""], ["Du", "Simon S.", ""], ["Fei-Fei", "Li", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1909.13004", "submitter": "Tianyi Luo", "authors": "Tianyi Luo and Yang Liu", "title": "Machine Truth Serum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wisdom of the crowd revealed a striking fact that the majority answer from a\ncrowd is often more accurate than any individual expert. We observed the same\nstory in machine learning--ensemble methods leverage this idea to combine\nmultiple learning algorithms to obtain better classification performance. Among\nmany popular examples is the celebrated Random Forest, which applies the\nmajority voting rule in aggregating different decision trees to make the final\nprediction. Nonetheless, these aggregation rules would fail when the majority\nis more likely to be wrong. In this paper, we extend the idea proposed in\nBayesian Truth Serum that \"a surprisingly more popular answer is more likely\nthe true answer\" to classification problems. The challenge for us is to define\nor detect when an answer should be considered as being \"surprising\". We present\ntwo machine learning aided methods which aim to reveal the truth when it is\nminority instead of majority who has the true answer. Our experiments over\nreal-world datasets show that better classification performance can be obtained\ncompared to always trusting the majority voting. Our proposed methods also\noutperform popular ensemble algorithms. Our approach can be generically applied\nas a subroutine in ensemble methods to replace majority voting rule.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 01:59:14 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Luo", "Tianyi", ""], ["Liu", "Yang", ""]]}, {"id": "1909.13014", "submitter": "Amirhossein Reisizadeh", "authors": "Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie,\n  Ramtin Pedarsani", "title": "FedPAQ: A Communication-Efficient Federated Learning Method with\n  Periodic Averaging and Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed framework according to which a model is\ntrained over a set of devices, while keeping data localized. This framework\nfaces several systems-oriented challenges which include (i) communication\nbottleneck since a large number of devices upload their local updates to a\nparameter server, and (ii) scalability as the federated network consists of\nmillions of devices. Due to these systems challenges as well as issues related\nto statistical heterogeneity of data and privacy concerns, designing a provably\nefficient federated learning method is of significant importance yet it remains\nchallenging. In this paper, we present FedPAQ, a communication-efficient\nFederated Learning method with Periodic Averaging and Quantization. FedPAQ\nrelies on three key features: (1) periodic averaging where models are updated\nlocally at devices and only periodically averaged at the server; (2) partial\ndevice participation where only a fraction of devices participate in each round\nof the training; and (3) quantized message-passing where the edge nodes\nquantize their updates before uploading to the parameter server. These features\naddress the communications and scalability challenges in federated learning. We\nalso show that FedPAQ achieves near-optimal theoretical guarantees for strongly\nconvex and non-convex loss functions and empirically demonstrate the\ncommunication-computation tradeoff provided by our method.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 03:10:53 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 02:38:39 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 21:37:38 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 19:09:29 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Reisizadeh", "Amirhossein", ""], ["Mokhtari", "Aryan", ""], ["Hassani", "Hamed", ""], ["Jadbabaie", "Ali", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "1909.13021", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki, Carl Allen, Rik Sarkar", "title": "Multi-scale Attributed Node Embedding", "comments": "Published in the Journal of Complex Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present network embedding algorithms that capture information about a node\nfrom the local distribution over node attributes around it, as observed over\nrandom walks following an approach similar to Skip-gram. Observations from\nneighborhoods of different sizes are either pooled (AE) or encoded distinctly\nin a multi-scale approach (MUSAE). Capturing attribute-neighborhood\nrelationships over multiple scales is useful for a diverse range of\napplications, including latent feature identification across disconnected\nnetworks with similar attributes. We prove theoretically that matrices of\nnode-feature pointwise mutual information are implicitly factorized by the\nembeddings. Experiments show that our algorithms are robust, computationally\nefficient and outperform comparable models on social networks and web graphs.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 04:13:33 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:57:34 GMT"}, {"version": "v3", "created": "Sun, 21 Mar 2021 22:05:08 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Allen", "Carl", ""], ["Sarkar", "Rik", ""]]}, {"id": "1909.13025", "submitter": "Negin Heravi", "authors": "Negin Heravi, Wenzhen Yuan, Allison M. Okamura, Jeannette Bohg", "title": "Learning an Action-Conditional Model for Haptic Texture Generation", "comments": "ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rich haptic sensory feedback in response to user interactions is desirable\nfor an effective, immersive virtual reality or teleoperation system. However,\nthis feedback depends on material properties and user interactions in a\ncomplex, non-linear manner. Therefore, it is challenging to model the mapping\nfrom material and user interactions to haptic feedback in a way that\ngeneralizes over many variations of the user's input. Current methodologies are\ntypically conditioned on user interactions, but require a separate model for\neach material. In this paper, we present a learned action-conditional model\nthat uses data from a vision-based tactile sensor (GelSight) and user's action\nas input. This model predicts an induced acceleration that could be used to\nprovide haptic vibration feedback to a user. We trained our proposed model on a\npublicly available dataset (Penn Haptic Texture Toolkit) that we augmented with\nGelSight measurements of the different materials. We show that a unified model\nover all materials outperforms previous methods and generalizes to new actions\nand new instances of the material categories in the dataset.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 04:45:42 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 01:11:01 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Heravi", "Negin", ""], ["Yuan", "Wenzhen", ""], ["Okamura", "Allison M.", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1909.13031", "submitter": "Sarath Yasodharan", "authors": "Sarath Yasodharan, Patrick Loiseau", "title": "Nonzero-sum Adversarial Hypothesis Testing Games", "comments": "23 pages, 14 figures. Accepted for publication in the 33rd Conference\n  on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.ST stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonzero-sum hypothesis testing games that arise in the context of\nadversarial classification, in both the Bayesian as well as the Neyman-Pearson\nframeworks. We first show that these games admit mixed strategy Nash\nequilibria, and then we examine some interesting concentration phenomena of\nthese equilibria. Our main results are on the exponential rates of convergence\nof classification errors at equilibrium, which are analogous to the well-known\nChernoff-Stein lemma and Chernoff information that describe the error exponents\nin the classical binary hypothesis testing problem, but with parameters derived\nfrom the adversarial model. The results are validated through numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 05:46:48 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Yasodharan", "Sarath", ""], ["Loiseau", "Patrick", ""]]}, {"id": "1909.13032", "submitter": "Xiao Peng Yan", "authors": "Xiaopeng Yan, Ziliang Chen, Anni Xu, Xiaoxi Wang, Xiaodan Liang, Liang\n  Lin", "title": "Meta R-CNN : Towards General Solver for Instance-level Few-shot Learning", "comments": "Published in ICCV-2019. Project:\n  https://yanxp.github.io/metarcnn.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resembling the rapid learning capability of human, few-shot learning empowers\nvision systems to understand new concepts by training with few samples. Leading\napproaches derived from meta-learning on images with a single visual object.\nObfuscated by a complex background and multiple objects in one image, they are\nhard to promote the research of few-shot object detection/segmentation. In this\nwork, we present a flexible and general methodology to achieve these tasks. Our\nwork extends Faster /Mask R-CNN by proposing meta-learning over RoI\n(Region-of-Interest) features instead of a full image feature. This simple\nspirit disentangles multi-object information merged with the background,\nwithout bells and whistles, enabling Faster /Mask R-CNN turn into a\nmeta-learner to achieve the tasks. Specifically, we introduce a Predictor-head\nRemodeling Network (PRN) that shares its main backbone with Faster /Mask R-CNN.\nPRN receives images containing few-shot objects with their bounding boxes or\nmasks to infer their class attentive vectors. The vectors take channel-wise\nsoft-attention on RoI features, remodeling those R-CNN predictor heads to\ndetect or segment the objects that are consistent with the classes these\nvectors represent. In our experiments, Meta R-CNN yields the state of the art\nin few-shot object detection and improves few-shot object segmentation by Mask\nR-CNN.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 05:46:49 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 03:10:42 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Yan", "Xiaopeng", ""], ["Chen", "Ziliang", ""], ["Xu", "Anni", ""], ["Wang", "Xiaoxi", ""], ["Liang", "Xiaodan", ""], ["Lin", "Liang", ""]]}, {"id": "1909.13035", "submitter": "Qitian Wu", "authors": "Qitian Wu, Rui Gao, Hongyuan Zha", "title": "Stein Bridging: Enabling Mutual Reinforcement between Explicit and\n  Implicit Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are generally categorized into explicit models and\nimplicit models. The former defines an explicit density form, whose normalizing\nconstant is often unknown; while the latter, including generative adversarial\nnetworks (GANs), generates samples without explicitly defining a density\nfunction. In spite of substantial recent advances demonstrating the power of\nthe two classes of generative models in many applications, both of them, when\nused alone, suffer from respective limitations and drawbacks. To mitigate these\nissues, we propose Stein Bridging, a novel joint training framework that\nconnects an explicit density estimator and an implicit sample generator with\nStein discrepancy. We show that the Stein Bridge induces new regularization\nschemes for both explicit and implicit models. Convergence analysis and\nextensive experiments demonstrate that the Stein Bridging i) improves the\nstability and sample quality of the GAN training, and ii) facilitates the\ndensity estimator to seek more modes in data and alleviate the mode-collapse\nissue. Additionally, we discuss several applications of Stein Bridging and\nuseful tricks in practical implementation used in our experiments.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 06:39:33 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 10:33:42 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Wu", "Qitian", ""], ["Gao", "Rui", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1909.13047", "submitter": "Wei Zhou", "authors": "Wei Zhou, Yiying Li", "title": "Feature Fusion Detector for Semantic Cognition of Remote Sensing", "comments": "12 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The value of remote sensing images is of vital importance in many areas and\nneeds to be refined by some cognitive approaches. The remote sensing detection\nis an appropriate way to achieve the semantic cognition. However, such\ndetection is a challenging issue for scale diversity, diversity of views, small\nobjects, sophisticated light and shadow backgrounds. In this article, inspired\nby the state-of-the-art detection framework FPN, we propose a novel approach\nfor constructing a feature fusion module that optimizes feature context\nutilization in detection, calling our system LFFN for Layer-weakening Feature\nFusion Network. We explore the inherent relevance of different layers to the\nfinal decision, and the incentives of higher-level features to lower-level\nfeatures. More importantly, we explore the characteristics of different\nbackbone networks in the mining of basic features and the correlation\nutilization of convolutional channels, and call our upgraded version as\nadvanced LFFN. Based on experiments on the remote sensing dataset from Google\nEarth, our LFFN has proved effective and practical for the semantic cognition\nof remote sensing, achieving 89% mAP which is 4.1% higher than that of FPN.\nMoreover, in terms of the generalization performance, LFFN achieves 79.9% mAP\non VOC 2007 and achieves 73.0% mAP on VOC 2012 test, and advacned LFFN obtains\nthe mAP values of 80.7% and 74.4% on VOC 2007 and 2012 respectively,\noutperforming the comparable state-of-the-art SSD and Faster R-CNN models.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 08:30:03 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zhou", "Wei", ""], ["Li", "Yiying", ""]]}, {"id": "1909.13049", "submitter": "Alberto Bemporad Prof.", "authors": "Alberto Bemporad and Dario Piga", "title": "Active preference learning based on radial basis functions", "comments": "33 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for solving optimization problems in which the\ndecision-maker cannot evaluate the objective function, but rather can only\nexpress a preference such as \"this is better than that\" between two candidate\ndecision vectors. The algorithm described in this paper aims at reaching the\nglobal optimizer by iteratively proposing the decision maker a new comparison\nto make, based on actively learning a surrogate of the latent (unknown and\nperhaps unquantifiable) objective function from past sampled decision vectors\nand pairwise preferences. The surrogate is fit by means of radial basis\nfunctions, under the constraint of satisfying, if possible, the preferences\nexpressed by the decision maker on existing samples. The surrogate is used to\npropose a new sample of the decision vector for comparison with the current\nbest candidate based on two possible criteria: minimize a combination of the\nsurrogate and an inverse weighting distance function to balance between\nexploitation of the surrogate and exploration of the decision space, or\nmaximize a function related to the probability that the new candidate will be\npreferred. Compared to active preference learning based on Bayesian\noptimization, we show that our approach is superior in that, within the same\nnumber of comparisons, it approaches the global optimum more closely and is\ncomputationally lighter. MATLAB and a Python implementations of the algorithms\ndescribed in the paper are available at\nhttp://cse.lab.imtlucca.it/~bemporad/idwgopt.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 08:37:51 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Bemporad", "Alberto", ""], ["Piga", "Dario", ""]]}, {"id": "1909.13055", "submitter": "Duc Tam Nguyen", "authors": "Duc Tam Nguyen, Maximilian Dax, Chaithanya Kumar Mummadi, Thi Phuong\n  Nhung Ngo, Thi Hoai Phuong Nguyen, Zhongyu Lou, Thomas Brox", "title": "DeepUSPS: Deep Robust Unsupervised Saliency Prediction With\n  Self-Supervision", "comments": "NeuRIPS-2019 (Vancouver, Canada): camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) based salient object detection in images based on\nhigh-quality labels is expensive. Alternative unsupervised approaches rely on\ncareful selection of multiple handcrafted saliency methods to generate noisy\npseudo-ground-truth labels. In this work, we propose a two-stage mechanism for\nrobust unsupervised object saliency prediction, where the first stage involves\nrefinement of the noisy pseudo labels generated from different handcrafted\nmethods. Each handcrafted method is substituted by a deep network that learns\nto generate the pseudo labels. These labels are refined incrementally in\nmultiple iterations via our proposed self-supervision technique. In the second\nstage, the refined labels produced from multiple networks representing multiple\nsaliency methods are used to train the actual saliency detection network. We\nshow that this self-learning procedure outperforms all the existing\nunsupervised methods over different datasets. Results are even comparable to\nthose of fully-supervised state-of-the-art approaches. The code is available at\nhttps://tinyurl.com/wtlhgo3 .\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 09:23:14 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 14:11:58 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 14:32:36 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 13:28:46 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Nguyen", "Duc Tam", ""], ["Dax", "Maximilian", ""], ["Mummadi", "Chaithanya Kumar", ""], ["Ngo", "Thi Phuong Nhung", ""], ["Nguyen", "Thi Hoai Phuong", ""], ["Lou", "Zhongyu", ""], ["Brox", "Thomas", ""]]}, {"id": "1909.13062", "submitter": "Prateek Munjal", "authors": "Prateek Munjal, Akanksha Paul, Narayanan C. Krishnan", "title": "Implicit Discriminator in Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently generative models have focused on combining the advantages of\nvariational autoencoders (VAE) and generative adversarial networks (GAN) for\ngood reconstruction and generative abilities. In this work we introduce a novel\nhybrid architecture, Implicit Discriminator in Variational Autoencoder (IDVAE),\nthat combines a VAE and a GAN, which does not need an explicit discriminator\nnetwork. The fundamental premise of the IDVAE architecture is that the encoder\nof a VAE and the discriminator of a GAN utilize common features and therefore\ncan be trained as a shared network, while the decoder of the VAE and the\ngenerator of the GAN can be combined to learn a single network. This results in\na simple two-tier architecture that has the properties of both a VAE and a GAN.\nThe qualitative and quantitative experiments on real-world benchmark datasets\ndemonstrates that IDVAE perform better than the state of the art hybrid\napproaches. We experimentally validate that IDVAE can be easily extended to\nwork in a conditional setting and demonstrate its performance on complex\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 10:12:28 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Munjal", "Prateek", ""], ["Paul", "Akanksha", ""], ["Krishnan", "Narayanan C.", ""]]}, {"id": "1909.13072", "submitter": "Danfei Xu", "authors": "Danfei Xu, Roberto Mart\\'in-Mart\\'in, De-An Huang, Yuke Zhu, Silvio\n  Savarese, Li Fei-Fei", "title": "Regression Planning Networks", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent learning-to-plan methods have shown promising results on planning\ndirectly from observation space. Yet, their ability to plan for long-horizon\ntasks is limited by the accuracy of the prediction model. On the other hand,\nclassical symbolic planners show remarkable capabilities in solving\nlong-horizon tasks, but they require predefined symbolic rules and symbolic\nstates, restricting their real-world applicability. In this work, we combine\nthe benefits of these two paradigms and propose a learning-to-plan method that\ncan directly generate a long-term symbolic plan conditioned on high-dimensional\nobservations. We borrow the idea of regression (backward) planning from\nclassical planning literature and introduce Regression Planning Networks (RPN),\na neural network architecture that plans backward starting at a task goal and\ngenerates a sequence of intermediate goals that reaches the current\nobservation. We show that our model not only inherits many favorable traits\nfrom symbolic planning, e.g., the ability to solve previously unseen tasks but\nalso can learn from visual inputs in an end-to-end manner. We evaluate the\ncapabilities of RPN in a grid world environment and a simulated 3D kitchen\nenvironment featuring complex visual scenes and long task horizons, and show\nthat it achieves near-optimal performance in completely new task instances.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 11:30:24 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Xu", "Danfei", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Huang", "De-An", ""], ["Zhu", "Yuke", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1909.13077", "submitter": "Dan Wang", "authors": "Dan Wang and Jibing Gong and Yaxi Song", "title": "W-RNN: News text classification based on a Weighted RNN", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the information is stored as text, so text mining is regarded as\nhaving high commercial potential. Aiming at the semantic constraint problem of\nclassification methods based on sparse representation, we propose a weighted\nrecurrent neural network (W-RNN), which can fully extract text serialization\nsemantic information. For the problem that the feature high dimensionality and\nunclear semantic relationship in text data representation, we first utilize the\nword vector to represent the vocabulary in the text and use Recurrent Neural\nNetwork (RNN) to extract features of the serialized text data. The word vector\nis then automatically weighted and summed using the intermediate output of the\nword vector to form the text representation vector. Finally, the neural network\nis used for classification. W-RNN is verified on the news dataset and proves\nthat W-RNN is superior to other four baseline methods in Precision, Recall, F1\nand loss values, which is suitable for text classification.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 11:54:15 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wang", "Dan", ""], ["Gong", "Jibing", ""], ["Song", "Yaxi", ""]]}, {"id": "1909.13079", "submitter": "Alexandre Proutiere", "authors": "Alexandre Proutiere and Po-An Wang", "title": "An Optimal Algorithm for Multiplayer Multi-Armed Bandits", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses the Multiplayer Multi-Armed Bandit (MMAB) problem, where\n$M$ decision makers or players collaborate to maximize their cumulative reward.\nWhen several players select the same arm, a collision occurs and no reward is\ncollected on this arm. Players involved in a collision are informed about this\ncollision. We present DPE (Decentralized Parsimonious Exploration), a\ndecentralized algorithm that achieves the same regret as that obtained by an\noptimal centralized algorithm. Our algorithm has better regret guarantees than\nthe state-of-the-art algorithm SIC-MMAB \\cite{boursier2019}. As in SIC-MMAB,\nplayers communicate through collisions only. An additional important advantage\nof DPE is that it requires very little communication. Specifically, the\nexpected number of rounds where players use collisions to communicate is\nfinite.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 12:35:12 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 07:57:57 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Proutiere", "Alexandre", ""], ["Wang", "Po-An", ""]]}, {"id": "1909.13082", "submitter": "Alexander Korotin", "authors": "Alexander Korotin and Vage Egiazarian and Arip Asadulaev and Alexander\n  Safin and Evgeny Burnaev", "title": "Wasserstein-2 Generative Networks", "comments": "30 pages, 21 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel end-to-end non-minimax algorithm for training optimal\ntransport mappings for the quadratic cost (Wasserstein-2 distance). The\nalgorithm uses input convex neural networks and a cycle-consistency\nregularization to approximate Wasserstein-2 distance. In contrast to popular\nentropic and quadratic regularizers, cycle-consistency does not introduce bias\nand scales well to high dimensions. From the theoretical side, we estimate the\nproperties of the generative mapping fitted by our algorithm. From the\npractical side, we evaluate our algorithm on a wide range of tasks:\nimage-to-image color transfer, latent space optimal transport, image-to-image\nstyle transfer, and domain adaptation.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 12:42:12 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 09:42:03 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 18:04:14 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 10:53:46 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Korotin", "Alexander", ""], ["Egiazarian", "Vage", ""], ["Asadulaev", "Arip", ""], ["Safin", "Alexander", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1909.13104", "submitter": "Christos Karatsalos", "authors": "Christos Karatsalos, Yannis Panagiotakis", "title": "Attention-based method for categorizing different types of online\n  harassment language", "comments": "Accepted in \"SIMAH (SocIaL Media And Harassment): First workshop on\n  categorizing different types of online harassment languages in social media\"\n  @ ECML-PKDD 2019", "journal-ref": null, "doi": "10.1007/978-3-030-43887-6_26", "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the era of social media and networking platforms, Twitter has been doomed\nfor abuse and harassment toward users specifically women. Monitoring the\ncontents including sexism and sexual harassment in traditional media is easier\nthan monitoring on the online social media platforms like Twitter, because of\nthe large amount of user generated content in these media. So, the research\nabout the automated detection of content containing sexual or racist harassment\nis an important issue and could be the basis for removing that content or\nflagging it for human evaluation. Previous studies have been focused on\ncollecting data about sexism and racism in very broad terms. However, there is\nno much study focusing on different types of online harassment attracting\nnatural language processing techniques. In this work, we present an\nmulti-attention based approach for the detection of different types of\nharassment in tweets. Our approach is based on the Recurrent Neural Networks\nand particularly we are using a deep, classification specific multi-attention\nmechanism. Moreover, we tackle the problem of imbalanced data, using a\nback-translation method. Finally, we present a comparison between different\napproaches based on the Recurrent Neural Networks.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 14:32:46 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 00:36:10 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Karatsalos", "Christos", ""], ["Panagiotakis", "Yannis", ""]]}, {"id": "1909.13111", "submitter": "Ryo Yonetani", "authors": "Mohammadamin Barekatain, Ryo Yonetani, Masashi Hamaya", "title": "MULTIPOLAR: Multi-Source Policy Aggregation for Transfer Reinforcement\n  Learning between Diverse Environmental Dynamics", "comments": "This work was presented at IJCAI 2020. Copyright (c) 2020\n  International Joint Conferences on Artificial Intelligence, All rights\n  reserved", "journal-ref": "Proceedings of the Twenty-Ninth International Joint Conference on\n  Artificial Intelligence 2020. Pages 3108-3116", "doi": "10.24963/ijcai.2020/430", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer reinforcement learning (RL) aims at improving the learning\nefficiency of an agent by exploiting knowledge from other source agents trained\non relevant tasks. However, it remains challenging to transfer knowledge\nbetween different environmental dynamics without having access to the source\nenvironments. In this work, we explore a new challenge in transfer RL, where\nonly a set of source policies collected under diverse unknown dynamics is\navailable for learning a target task efficiently. To address this problem, the\nproposed approach, MULTI-source POLicy AggRegation (MULTIPOLAR), comprises two\nkey techniques. We learn to aggregate the actions provided by the source\npolicies adaptively to maximize the target task performance. Meanwhile, we\nlearn an auxiliary network that predicts residuals around the aggregated\nactions, which ensures the target policy's expressiveness even when some of the\nsource policies perform poorly. We demonstrated the effectiveness of MULTIPOLAR\nthrough an extensive experimental evaluation across six simulated environments\nranging from classic control problems to challenging robotics simulations,\nunder both continuous and discrete action spaces. The demo videos and code are\navailable on the project webpage: https://omron-sinicx.github.io/multipolar/.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 15:13:46 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 00:21:32 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Barekatain", "Mohammadamin", ""], ["Yonetani", "Ryo", ""], ["Hamaya", "Masashi", ""]]}, {"id": "1909.13121", "submitter": "Quentin Cappart", "authors": "Antoine Fran\\c{c}ois, Quentin Cappart, Louis-Martin Rousseau", "title": "How to Evaluate Machine Learning Approaches for Combinatorial\n  Optimization: Application to the Travelling Salesman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial optimization is the field devoted to the study and practice of\nalgorithms that solve NP-hard problems. As Machine Learning (ML) and deep\nlearning have popularized, several research groups have started to use ML to\nsolve combinatorial optimization problems, such as the well-known Travelling\nSalesman Problem (TSP). Based on deep (reinforcement) learning, new models and\narchitecture for the TSP have been successively developed and have gained\nincreasing performances. At the time of writing, state-of-the-art models\nprovide solutions to TSP instances of 100 cities that are roughly 1.33% away\nfrom optimal solutions. However, despite these apparently positive results, the\nperformances remain far from those that can be achieved using a specialized\nsearch procedure. In this paper, we address the limitations of ML approaches\nfor solving the TSP and investigate two fundamental questions: (1) how can we\nmeasure the level of accuracy of the pure ML component of such methods; and (2)\nwhat is the impact of a search procedure plugged inside a ML model on the\nperformances? To answer these questions, we propose a new metric, ratio of\noptimal decisions (ROD), based on a fair comparison with a parametrized oracle,\nmimicking a ML model with a controlled accuracy. All the experiments are\ncarried out on four state-of-the-art ML approaches dedicated to solve the TSP.\nFinally, we made ROD open-source in order to ease future research in the field.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 16:35:38 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Fran\u00e7ois", "Antoine", ""], ["Cappart", "Quentin", ""], ["Rousseau", "Louis-Martin", ""]]}, {"id": "1909.13123", "submitter": "Zhengming Ding", "authors": "Zhengming Ding and Ming Shao and Handong Zhao and Sheng Li", "title": "Learning Robust Data Representation: A Knowledge Flow Perspective", "comments": "7 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  It is always demanding to learn robust visual representation for various\nlearning problems; however, this learning and maintenance process usually\nsuffers from noise, incompleteness or knowledge domain mismatch. Thus, robust\nrepresentation learning by removing noisy features or samples, complementing\nincomplete data, and mitigating the distribution difference becomes the key.\nAlong this line of research, low-rank modeling has been widely-applied to\nsolving representation learning challenges. This survey covers the topic from a\nknowledge flow perspective in terms of: (1) robust knowledge recovery, (2)\nrobust knowledge transfer, and (3) robust knowledge fusion, centered around\nseveral major applications. First of all, we deliver a unified formulation for\nrobust knowledge discovery given single dataset. Second, we discuss robust\nknowledge transfer and fusion given multiple datasets with different knowledge\nflows, followed by practical challenges, model variations, and remarks.\nFinally, we highlight future research of robust knowledge discovery for\nincomplete, unbalance, large-scale data analysis. This would benefit AI\ncommunity from literature review to future direction.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 17:15:38 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 18:35:43 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Ding", "Zhengming", ""], ["Shao", "Ming", ""], ["Zhao", "Handong", ""], ["Li", "Sheng", ""]]}, {"id": "1909.13144", "submitter": "Xin Dong", "authors": "Yuhang Li, Xin Dong, Wei Wang", "title": "Additive Powers-of-Two Quantization: An Efficient Non-uniform\n  Discretization for Neural Networks", "comments": "quantization, efficient neural network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Additive Powers-of-Two~(APoT) quantization, an efficient\nnon-uniform quantization scheme for the bell-shaped and long-tailed\ndistribution of weights and activations in neural networks. By constraining all\nquantization levels as the sum of Powers-of-Two terms, APoT quantization enjoys\nhigh computational efficiency and a good match with the distribution of\nweights. A simple reparameterization of the clipping function is applied to\ngenerate a better-defined gradient for learning the clipping threshold.\nMoreover, weight normalization is presented to refine the distribution of\nweights to make the training more stable and consistent. Experimental results\nshow that our proposed method outperforms state-of-the-art methods, and is even\ncompetitive with the full-precision models, demonstrating the effectiveness of\nour proposed APoT quantization. For example, our 4-bit quantized ResNet-50 on\nImageNet achieves 76.6% top-1 accuracy without bells and whistles; meanwhile,\nour model reduces 22% computational cost compared with the uniformly quantized\ncounterpart. The code is available at\nhttps://github.com/yhhhli/APoT_Quantization.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 20:14:11 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 14:15:07 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Yuhang", ""], ["Dong", "Xin", ""], ["Wang", "Wei", ""]]}, {"id": "1909.13146", "submitter": "Andreas Georgiou", "authors": "Andreas Georgiou, Vincent Fortuin, Harun Mustafa, Gunnar R\\\"atsch", "title": "META$^\\mathbf{2}$: Memory-efficient taxonomic classification and\n  abundance estimation for metagenomics with deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metagenomic studies have increasingly utilized sequencing technologies in\norder to analyze DNA fragments found in environmental samples.One important\nstep in this analysis is the taxonomic classification of the DNA fragments.\nConventional read classification methods require large databases and vast\namounts of memory to run, with recent deep learning methods suffering from very\nlarge model sizes. We therefore aim to develop a more memory-efficient\ntechnique for taxonomic classification. A task of particular interest is\nabundance estimation in metagenomic samples. Current attempts rely on\nclassifying single DNA reads independently from each other and are therefore\nagnostic to co-occurence patterns between taxa. In this work, we also attempt\nto take these patterns into account. We develop a novel memory-efficient read\nclassification technique, combining deep learning and locality-sensitive\nhashing. We show that this approach outperforms conventional mapping-based and\nother deep learning methods for single-read taxonomic classification when\nrestricting all methods to a fixed memory footprint. Moreover, we formulate the\ntask of abundance estimation as a Multiple Instance Learning (MIL) problem and\nwe extend current deep learning architectures with two different types of\npermutation-invariant MIL pooling layers: a) deepsets and b) attention-based\npooling. We illustrate that our architectures can exploit the co-occurrence of\nspecies in metagenomic read sets and outperform the single-read architectures\nin predicting the distribution over taxa at higher taxonomic ranks.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 20:30:40 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 16:05:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Georgiou", "Andreas", ""], ["Fortuin", "Vincent", ""], ["Mustafa", "Harun", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "1909.13154", "submitter": "Congzheng Song", "authors": "Congzheng Song, Shanghang Zhang, Najmeh Sadoughi, Pengtao Xie, Eric\n  Xing", "title": "Generalized Zero-shot ICD Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The International Classification of Diseases (ICD) is a list of\nclassification codes for the diagnoses. Automatic ICD coding is in high demand\nas the manual coding can be labor-intensive and error-prone. It is a\nmulti-label text classification task with extremely long-tailed label\ndistribution, making it difficult to perform fine-grained classification on\nboth frequent and zero-shot codes at the same time. In this paper, we propose a\nlatent feature generation framework for generalized zero-shot ICD coding, where\nwe aim to improve the prediction on codes that have no labeled data without\ncompromising the performance on seen codes. Our framework generates pseudo\nfeatures conditioned on the ICD code descriptions and exploits the ICD code\nhierarchical structure. To guarantee the semantic consistency between the\ngenerated features and real features, we reconstruct the keywords in the input\ndocuments that are related to the conditioned ICD codes. To the best of our\nknowledge, this works represents the first one that proposes an adversarial\ngenerative model for the generalized zero-shot learning on multi-label text\nclassification. Extensive experiments demonstrate the effectiveness of our\napproach. On the public MIMIC-III dataset, our methods improve the F1 score\nfrom nearly 0 to 20.91% for the zero-shot codes, and increase the AUC score by\n3% (absolute improvement) from previous state of the art. We also show that the\nframework improves the performance on few-shot codes.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 21:32:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Song", "Congzheng", ""], ["Zhang", "Shanghang", ""], ["Sadoughi", "Najmeh", ""], ["Xie", "Pengtao", ""], ["Xing", "Eric", ""]]}, {"id": "1909.13158", "submitter": "Daniel Pirutinsky", "authors": "Wesley Cowan, Michael N. Katehakis, and Daniel Pirutinsky", "title": "Accelerating the Computation of UCB and Related Indices for\n  Reinforcement Learning", "comments": "A version of some of the algorithms and comparisons has appeared in a\n  previous technical note by Cowan, Katehakis, and Pirutinsky (2019)\n  arXiv:1909.06019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we derive an efficient method for computing the indices\nassociated with an asymptotically optimal upper confidence bound algorithm\n(MDP-UCB) of Burnetas and Katehakis (1997) that only requires solving a system\nof two non-linear equations with two unknowns, irrespective of the cardinality\nof the state space of the Markovian decision process (MDP). In addition, we\ndevelop a similar acceleration for computing the indices for the\nMDP-Deterministic Minimum Empirical Divergence (MDP-DMED) algorithm developed\nin Cowan et al. (2019), based on ideas from Honda and Takemura (2011), that\ninvolves solving a single equation of one variable. We provide experimental\nresults demonstrating the computational time savings and regret performance of\nthese algorithms. In these comparison we also consider the Optimistic Linear\nProgramming (OLP) algorithm (Tewari and Bartlett, 2008) and a method based on\nPosterior sampling (MDP-PS).\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 21:56:11 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Cowan", "Wesley", ""], ["Katehakis", "Michael N.", ""], ["Pirutinsky", "Daniel", ""]]}, {"id": "1909.13162", "submitter": "Aneek Barman Roy", "authors": "Aneek Barman Roy", "title": "Translation, Sentiment and Voices: A Computational Model to Translate\n  and Analyse Voices from Real-Time Video Calling", "comments": "79 Pages, 19 Tables, 24 Figures, A M.Sc Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With internet quickly becoming an easy access to many, voice calling over\ninternet is slowly gaining momentum. Individuals has been engaging in video\ncommunication across the world in different languages. The decade saw the\nemergence of language translation using neural networks as well. With more data\nbeing generated in audio and visual forms, there has become a need and a\nchallenge to analyse such information for many researchers from academia and\nindustry. The availability of video chat corpora is limited as organizations\nprotect user privacy and ensure data security. For this reason, an audio-visual\ncommunication system (VidALL) has been developed and audio-speeches were\nextracted. To understand human nature while answering a video call, an analysis\nwas conducted where polarity and vocal intensity were considered as parameters.\nSimultaneously, a translation model using a neural approach was developed to\ntranslate English sentences to French. Simple RNN-based and Embedded-RNN based\nmodels were used for the translation model. BLEU score and target sentence\ncomparators were used to check sentence correctness. Embedded-RNN showed an\naccuracy of 88.71 percentage and predicted correct sentences. A key finding\nsuggest that polarity is a good estimator to understand human emotion.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 22:11:03 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Roy", "Aneek Barman", ""]]}, {"id": "1909.13164", "submitter": "Meyer Scetbon", "authors": "Meyer Scetbon, Michael Elad, Peyman Milanfar", "title": "Deep K-SVD Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers noise removal from images, focusing on the well known\nK-SVD denoising algorithm. This sparsity-based method was proposed in 2006, and\nfor a short while it was considered as state-of-the-art. However, over the\nyears it has been surpassed by other methods, including the recent\ndeep-learning-based newcomers. The question we address in this paper is whether\nK-SVD was brought to its peak in its original conception, or whether it can be\nmade competitive again. The approach we take in answering this question is to\nredesign the algorithm to operate in a supervised manner. More specifically, we\npropose an end-to-end deep architecture with the exact K-SVD computational\npath, and train it for optimized denoising. Our work shows how to overcome\ndifficulties arising in turning the K-SVD scheme into a differentiable, and\nthus learnable, machine. With a small number of parameters to learn and while\npreserving the original K-SVD essence, the proposed architecture is shown to\noutperform the classical K-SVD algorithm substantially, and getting closer to\nrecent state-of-the-art learning-based denoising methods. Adopting a broader\ncontext, this work touches on themes around the design of deep-learning\nsolutions for image processing tasks, while paving a bridge between classic\nmethods and novel deep-learning-based ones.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 22:30:21 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 17:54:48 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Scetbon", "Meyer", ""], ["Elad", "Michael", ""], ["Milanfar", "Peyman", ""]]}, {"id": "1909.13165", "submitter": "Changan Chen", "authors": "Changan Chen, Sha Hu, Payam Nikdel, Greg Mori, Manolis Savva", "title": "Relational Graph Learning for Crowd Navigation", "comments": "Accepted to IROS 2020. Added links to codes and video demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a relational graph learning approach for robotic crowd navigation\nusing model-based deep reinforcement learning that plans actions by looking\ninto the future. Our approach reasons about the relations between all agents\nbased on their latent features and uses a Graph Convolutional Network to encode\nhigher-order interactions in each agent's state representation, which is\nsubsequently leveraged for state prediction and value estimation. The ability\nto predict human motion allows us to perform multi-step lookahead planning,\ntaking into account the temporal evolution of human crowds. We evaluate our\napproach against a state-of-the-art baseline for crowd navigation and ablations\nof our model to demonstrate that navigation with our approach is more\nefficient, results in fewer collisions, and avoids failure cases involving\noscillatory and freezing behaviors.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 22:31:46 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 04:22:25 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 19:07:08 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Chen", "Changan", ""], ["Hu", "Sha", ""], ["Nikdel", "Payam", ""], ["Mori", "Greg", ""], ["Savva", "Manolis", ""]]}, {"id": "1909.13168", "submitter": "Sandeep Srinivasan", "authors": "William Hughes, Sandeep Srinivasan, Rohit Suvarna, Maithilee Kulkarni", "title": "Optimizing Design Verification using Machine Learning: Doing better than\n  Random", "comments": "9 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As integrated circuits have become progressively more complex, constrained\nrandom stimulus has become ubiquitous as a means of stimulating a designs\nfunctionality and ensuring it fully meets expectations. In theory, random\nstimulus allows all possible combinations to be exercised given enough time,\nbut in practice with highly complex designs a purely random approach will have\ndifficulty in exercising all possible combinations in a timely fashion. As a\nresult it is often necessary to steer the Design Verification (DV) environment\nto generate hard to hit combinations. The resulting constrained-random approach\nis powerful but often relies on extensive human expertise to guide the DV\nenvironment in order to fully exercise the design. As designs become more\ncomplex, the guidance aspect becomes progressively more challenging and time\nconsuming often resulting in design schedules in which the verification time to\nhit all possible design coverage points is the dominant schedule limitation.\nThis paper describes an approach which leverages existing constrained-random DV\nenvironment tools but which further enhances them using supervised learning and\nreinforcement learning techniques. This approach provides better than random\nresults in a highly automated fashion thereby ensuring DV objectives of full\ndesign coverage can be achieved on an accelerated timescale and with fewer\nresources.\n  Two hardware verification examples are presented, one of a Cache Controller\ndesign and one using the open-source RISCV-Ariane design and Google's RISCV\nRandom Instruction Generator. We demonstrate that a machine-learning based\napproach can perform significantly better on functional coverage and reaching\ncomplex hard-to-hit states than a random or constrained-random approach.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 23:23:57 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Hughes", "William", ""], ["Srinivasan", "Sandeep", ""], ["Suvarna", "Rohit", ""], ["Kulkarni", "Maithilee", ""]]}, {"id": "1909.13183", "submitter": "Carl Yang", "authors": "Carl Yang, Lingrui Gan, Zongyi Wang, Jiaming Shen, Jinfeng Xiao,\n  Jiawei Han", "title": "Query-Specific Knowledge Summarization with Entity Evolutionary Networks", "comments": "published in CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a query, unlike traditional IR that finds relevant documents or\nentities, in this work, we focus on retrieving both entities and their\nconnections for insightful knowledge summarization. For example, given a query\n\"computer vision\" on a CS literature corpus, rather than returning a list of\nrelevant entities like \"cnn\", \"imagenet\" and \"svm\", we are interested in the\nconnections among them, and furthermore, the evolution patterns of such\nconnections along particular ordinal dimensions such as time. Particularly, we\nhope to provide structural knowledge relevant to the query, such as \"svm\" is\nrelated to \"imagenet\" but not \"cnn\". Moreover, we aim to model the changing\ntrends of the connections, such as \"cnn\" becomes highly related to \"imagenet\"\nafter 2010, which enables the tracking of knowledge evolutions. In this work,\nto facilitate such a novel insightful search system, we propose\n\\textsc{SetEvolve}, which is a unified framework based on nonparanomal\ngraphical models for evolutionary network construction from large text corpora.\nSystematic experiments on synthetic data and insightful case studies on\nreal-world corpora demonstrate the utility of \\textsc{SetEvolve}.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 01:48:32 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Yang", "Carl", ""], ["Gan", "Lingrui", ""], ["Wang", "Zongyi", ""], ["Shen", "Jiaming", ""], ["Xiao", "Jinfeng", ""], ["Han", "Jiawei", ""]]}, {"id": "1909.13188", "submitter": "Kun Xu", "authors": "Kun Xu, Chongxuan Li, Jun Zhu, Bo Zhang", "title": "Understanding and Stabilizing GANs' Training Dynamics with Control\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are effective in generating realistic\nimages but the training is often unstable. There are existing efforts that\nmodel the training dynamics of GANs in the parameter space but the analysis\ncannot directly motivate practically effective stabilizing methods. To this\nend, we present a conceptually novel perspective from control theory to\ndirectly model the dynamics of GANs in the function space and provide simple\nyet effective methods to stabilize GANs' training. We first analyze the\ntraining dynamic of a prototypical Dirac GAN and adopt the widely-used\nclosed-loop control (CLC) to improve its stability. We then extend CLC to\nstabilize the training dynamic of normal GANs, where CLC is implemented as a\nsquared $L2$ regularizer on the output of the discriminator. Empirical results\nshow that our method can effectively stabilize the training and obtain\nstate-of-the-art performance on data generation tasks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 02:19:40 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 03:42:34 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 08:41:51 GMT"}, {"version": "v4", "created": "Wed, 8 Jul 2020 03:25:00 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Xu", "Kun", ""], ["Li", "Chongxuan", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1909.13189", "submitter": "Bryon Aragam", "authors": "Xun Zheng, Chen Dan, Bryon Aragam, Pradeep Ravikumar, and Eric P. Xing", "title": "Learning Sparse Nonparametric DAGs", "comments": "To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for learning sparse nonparametric directed acyclic\ngraphs (DAGs) from data. Our approach is based on a recent algebraic\ncharacterization of DAGs that led to a fully continuous program for score-based\nlearning of DAG models parametrized by a linear structural equation model\n(SEM). We extend this algebraic characterization to nonparametric SEM by\nleveraging nonparametric sparsity based on partial derivatives, resulting in a\ncontinuous optimization problem that can be applied to a variety of\nnonparametric and semiparametric models including GLMs, additive noise models,\nand index models as special cases. Unlike existing approaches that require\nspecific modeling choices, loss functions, or algorithms, we present a\ncompletely general framework that can be applied to general nonlinear models\n(e.g. without additive noise), general differentiable loss functions, and\ngeneric black-box optimization routines. The code is available at\nhttps://github.com/xunzheng/notears.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 02:20:56 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 23:21:15 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Zheng", "Xun", ""], ["Dan", "Chen", ""], ["Aragam", "Bryon", ""], ["Ravikumar", "Pradeep", ""], ["Xing", "Eric P.", ""]]}, {"id": "1909.13193", "submitter": "Isaac Ampomah", "authors": "Isaac K. E. Ampomah, Sally McClean, Zhiwei Lin and Glenn Hawe", "title": "Gated Task Interaction Framework for Multi-task Sequence Tagging", "comments": "8 pages", "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN)", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent studies have shown that neural models can achieve high performance on\nseveral sequence labelling/tagging problems without the explicit use of\nlinguistic features such as part-of-speech (POS) tags. These models are trained\nonly using the character-level and the word embedding vectors as inputs. Others\nhave shown that linguistic features can improve the performance of neural\nmodels on tasks such as chunking and named entity recognition (NER). However,\nthe change in performance depends on the degree of semantic relatedness between\nthe linguistic features and the target task; in some instances, linguistic\nfeatures can have a negative impact on performance. This paper presents an\napproach to jointly learn these linguistic features along with the target\nsequence labelling tasks with a new multi-task learning (MTL) framework called\nGated Tasks Interaction (GTI) network for solving multiple sequence tagging\ntasks. The GTI network exploits the relations between the multiple tasks via\nneural gate modules. These gate modules control the flow of information between\nthe different tasks. Experiments on benchmark datasets for chunking and NER\nshow that our framework outperforms other competitive baselines trained with\nand without external training resources.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 02:56:24 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Ampomah", "Isaac K. E.", ""], ["McClean", "Sally", ""], ["Lin", "Zhiwei", ""], ["Hawe", "Glenn", ""]]}, {"id": "1909.13196", "submitter": "Zhiwei Deng", "authors": "Zhiwei Deng, Greg Mori", "title": "Policy Message Passing: A New Algorithm for Probabilistic Graph\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general graph-structured neural network architecture operates on graphs\nthrough two core components: (1) complex enough message functions; (2) a fixed\ninformation aggregation process. In this paper, we present the Policy Message\nPassing algorithm, which takes a probabilistic perspective and reformulates the\nwhole information aggregation as stochastic sequential processes. The algorithm\nworks on a much larger search space, utilizes reasoning history to perform\ninference, and is robust to noisy edges. We apply our algorithm to multiple\ncomplex graph reasoning and prediction tasks and show that our algorithm\nconsistently outperforms state-of-the-art graph-structured models by a\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 03:23:17 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Deng", "Zhiwei", ""], ["Mori", "Greg", ""]]}, {"id": "1909.13203", "submitter": "Ruishan Liu", "authors": "Ruishan Liu, Akshay Balsubramani, James Zou", "title": "Learning transport cost from subset correspondence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to align multiple datasets is an important problem with many\napplications, and it is especially useful when we need to integrate multiple\nexperiments or correct for confounding. Optimal transport (OT) is a principled\napproach to align datasets, but a key challenge in applying OT is that we need\nto specify a transport cost function that accurately captures how the two\ndatasets are related. Reliable cost functions are typically not available and\npractitioners often resort to using hand-crafted or Euclidean cost even if it\nmay not be appropriate. In this work, we investigate how to learn the cost\nfunction using a small amount of side information which is often available. The\nside information we consider captures subset correspondence---i.e. certain\nsubsets of points in the two data sets are known to be related. For example, we\nmay have some images labeled as cars in both datasets; or we may have a common\nannotated cell type in single-cell data from two batches. We develop an\nend-to-end optimizer (OT-SI) that differentiates through the Sinkhorn algorithm\nand effectively learns the suitable cost function from side information. On\nsystematic experiments in images, marriage-matching and single-cell RNA-seq,\nour method substantially outperform state-of-the-art benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 05:28:28 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Liu", "Ruishan", ""], ["Balsubramani", "Akshay", ""], ["Zou", "James", ""]]}, {"id": "1909.13221", "submitter": "Chao Wei", "authors": "Chao Wei, Weiru Zhang, Shengjie Sun, Fei Li, Xiaonan Meng, Yi Hu and\n  Hao Wang", "title": "Optimal Delivery with Budget Constraint in E-Commerce Advertising", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online advertising in E-commerce platforms provides sellers an opportunity to\nachieve potential audiences with different target goals. Ad serving systems\n(like display and search advertising systems) that assign ads to pages should\nsatisfy objectives such as plenty of audience for branding advertisers, clicks\nor conversions for performance-based advertisers, at the same time try to\nmaximize overall revenue of the platform. In this paper, we propose an approach\nbased on linear programming subjects to constraints in order to optimize the\nrevenue and improve different performance goals simultaneously. We have\nvalidated our algorithm by implementing an offline simulation system in Alibaba\nE-commerce platform and running the auctions from online requests which takes\nsystem performance, ranking and pricing schemas into account. We have also\ncompared our algorithm with related work, and the results show that our\nalgorithm can effectively improve campaign performance and revenue of the\nplatform.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 07:11:10 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 12:52:24 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Wei", "Chao", ""], ["Zhang", "Weiru", ""], ["Sun", "Shengjie", ""], ["Li", "Fei", ""], ["Meng", "Xiaonan", ""], ["Hu", "Yi", ""], ["Wang", "Hao", ""]]}, {"id": "1909.13231", "submitter": "Yu Sun", "authors": "Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A. Efros,\n  Moritz Hardt", "title": "Test-Time Training with Self-Supervision for Generalization under\n  Distribution Shifts", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we propose Test-Time Training, a general approach for\nimproving the performance of predictive models when training and test data come\nfrom different distributions. We turn a single unlabeled test sample into a\nself-supervised learning problem, on which we update the model parameters\nbefore making a prediction. This also extends naturally to data in an online\nstream. Our simple approach leads to improvements on diverse image\nclassification benchmarks aimed at evaluating robustness to distribution\nshifts.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 08:09:15 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 06:34:47 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 18:09:39 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Sun", "Yu", ""], ["Wang", "Xiaolong", ""], ["Liu", "Zhuang", ""], ["Miller", "John", ""], ["Efros", "Alexei A.", ""], ["Hardt", "Moritz", ""]]}, {"id": "1909.13241", "submitter": "Evangelos Psomakelis Mr", "authors": "Evangelos Psomakelis, Konstantinos Tserpes, Dimitris Zissisc,\n  Dimosthenis Anagnostopoulos and Theodora Varvarigou", "title": "Context agnostic trajectory prediction based on $\\lambda$-architecture", "comments": null, "journal-ref": "Future Generation Computer Systems 2019,ISSN 0167-739X", "doi": "10.1016/j.future.2019.09.046", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the next position of movable objects has been a problem for at\nleast the last three decades, referred to as trajectory prediction. In our\ndays, the vast amounts of data being continuously produced add the big data\ndimension to the trajectory prediction problem, which we are trying to tackle\nby creating a {\\lambda}-Architecture based analytics platform. This platform\nperforms both batch and stream analytics tasks and then combines them to\nperform analytical tasks that cannot be performed by analyzing any of these\nlayers by itself. The biggest benefit of this platform is its context agnostic\ntrait, which allows us to use it for any use case, as long as a time-stamped\ngeolocation stream is provided. The experimental results presented prove that\neach part of the {\\lambda}-Architecture performs well at certain targets,\nmaking a combination of these parts a necessity in order to improve the overall\naccuracy and performance of the platform.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 09:22:21 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Psomakelis", "Evangelos", ""], ["Tserpes", "Konstantinos", ""], ["Zissisc", "Dimitris", ""], ["Anagnostopoulos", "Dimosthenis", ""], ["Varvarigou", "Theodora", ""]]}, {"id": "1909.13260", "submitter": "Emille E. O. Ishida", "authors": "Emille E. O. Ishida, Matwey V. Kornilov, Konstantin L. Malanchev,\n  Maria V. Pruzhinskaya, Alina A. Volnova, Vladimir S. Korolev, Florian Mondon,\n  Sreevarsha Sreejith, Anastasia Malancheva and Shubhomoy Das", "title": "Active Anomaly Detection for time-domain discoveries", "comments": "10 pages, 5 figures, updated to include PLAsTiCC results", "journal-ref": "A&A 650, A195 (2021)", "doi": "10.1051/0004-6361/202037709", "report-no": null, "categories": "astro-ph.IM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first evidence that adaptive learning techniques can boost the\ndiscovery of unusual objects within astronomical light curve data sets. Our\nmethod follows an active learning strategy where the learning algorithm chooses\nobjects which can potentially improve the learner if additional information\nabout them is provided. This new information is subsequently used to update the\nmachine learning model, allowing its accuracy to evolve with each new\ninformation. For the case of anomaly detection, the algorithm aims to maximize\nthe number of scientifically interesting anomalies presented to the expert by\nslightly modifying the weights of a traditional Isolation Forest (IF) at each\niteration. In order to demonstrate the potential of such techniques, we apply\nthe Active Anomaly Discovery (AAD) algorithm to 2 data sets: simulated light\ncurves from the PLAsTiCC challenge and real light curves from the Open\nSupernova Catalog. We compare the AAD results to those of a static IF. For both\nmethods, we performed a detailed analysis for all objects with the ~2% highest\nanomaly scores. We show that, in the real data scenario, AAD was able to\nidentify ~80\\% more true anomalies than the IF. This result is the first\nevidence that AAD algorithms can play a central role in the search for new\nphysics in the era of large scale sky surveys.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 11:25:15 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 15:52:21 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ishida", "Emille E. O.", ""], ["Kornilov", "Matwey V.", ""], ["Malanchev", "Konstantin L.", ""], ["Pruzhinskaya", "Maria V.", ""], ["Volnova", "Alina A.", ""], ["Korolev", "Vladimir S.", ""], ["Mondon", "Florian", ""], ["Sreejith", "Sreevarsha", ""], ["Malancheva", "Anastasia", ""], ["Das", "Shubhomoy", ""]]}, {"id": "1909.13271", "submitter": "Thierry Tambe", "authors": "Thierry Tambe, En-Yu Yang, Zishen Wan, Yuntian Deng, Vijay Janapa\n  Reddi, Alexander Rush, David Brooks, Gu-Yeon Wei", "title": "AdaptivFloat: A Floating-point based Data Type for Resilient Deep\n  Learning Inference", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional hardware-friendly quantization methods, such as fixed-point or\ninteger, tend to perform poorly at very low word sizes as their shrinking\ndynamic ranges cannot adequately capture the wide data distributions commonly\nseen in sequence transduction models. We present AdaptivFloat, a floating-point\ninspired number representation format for deep learning that dynamically\nmaximizes and optimally clips its available dynamic range, at a layer\ngranularity, in order to create faithful encoding of neural network parameters.\nAdaptivFloat consistently produces higher inference accuracies compared to\nblock floating-point, uniform, IEEE-like float or posit encodings at very low\nprecision ($\\leq$ 8-bit) across a diverse set of state-of-the-art neural\nnetwork topologies. And notably, AdaptivFloat is seen surpassing baseline FP32\nperformance by up to +0.3 in BLEU score and -0.75 in word error rate at weight\nbit widths that are $\\leq$ 8-bit. Experimental results on a deep neural network\n(DNN) hardware accelerator, exploiting AdaptivFloat logic in its computational\ndatapath, demonstrate per-operation energy and area that is 0.9$\\times$ and\n1.14$\\times$, respectively, that of equivalent bit width integer-based\naccelerator variants.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 12:41:46 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 16:00:21 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 09:30:21 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Tambe", "Thierry", ""], ["Yang", "En-Yu", ""], ["Wan", "Zishen", ""], ["Deng", "Yuntian", ""], ["Reddi", "Vijay Janapa", ""], ["Rush", "Alexander", ""], ["Brooks", "David", ""], ["Wei", "Gu-Yeon", ""]]}, {"id": "1909.13273", "submitter": "Yuwen Yang", "authors": "Yuwen Yang, Feifei Gao, Cheng Qian, Guisheng Liao", "title": "Model-aided Deep Neural Network for Source Number Detection", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2019.2957673", "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source number detection is a critical problem in array signal processing.\nConventional model-driven methods e.g., Akaikes information criterion (AIC) and\nminimum description length (MDL), suffer from severe performance degradation\nwhen the number of snapshots is small or the signal-to-noise ratio (SNR) is\nlow. In this paper, we exploit the model-aided based deep neural network (DNN)\nto estimate the source number. Specifically, we first propose the eigenvalue\nbased regression network (ERNet) and classification network (ECNet) to estimate\nthe number of non-coherent sources, where the eigenvalues of the received\nsignal covariance matrix and the source number are used as the input and the\nsupervise label of the networks, respectively. Then, we extend the ERNet and\nECNet for estimating the number of coherent sources, where the forward-backward\nspatial smoothing (FBSS) scheme is adopted to improve the performance of ERNet\nand ECNet. Numerical results demonstrate the outstanding performance of ERNet\nand ECNet over the conventional AIC and MDL methods as well as their excellent\ngeneralization capability, which also shows their great potentials for\npractical applications.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 13:03:37 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 13:51:24 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Yang", "Yuwen", ""], ["Gao", "Feifei", ""], ["Qian", "Cheng", ""], ["Liao", "Guisheng", ""]]}, {"id": "1909.13315", "submitter": "Yatin Chaudhary", "authors": "Yatin Chaudhary, Pankaj Gupta, Thomas Runkler", "title": "Lifelong Neural Topic Learning in Contextualized Autoregressive Topic\n  Models of Language via Informative Transfers", "comments": "94 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models such as LDA, DocNADE, iDocNADEe have been popular in document\nanalysis. However, the traditional topic models have several limitations\nincluding: (1) Bag-of-words (BoW) assumption, where they ignore word ordering,\n(2) Data sparsity, where the application of topic models is challenging due to\nlimited word co-occurrences, leading to incoherent topics and (3) No Continuous\nLearning framework for topic learning in lifelong fashion, exploiting\nhistorical knowledge (or latent topics) and minimizing catastrophic forgetting.\nThis thesis focuses on addressing the above challenges within neural topic\nmodeling framework. We propose: (1) Contextualized topic model that combines a\ntopic and a language model and introduces linguistic structures (such as word\nordering, syntactic and semantic features, etc.) in topic modeling, (2) A novel\nlifelong learning mechanism into neural topic modeling framework to demonstrate\ncontinuous learning in sequential document collections and minimizing\ncatastrophic forgetting. Additionally, we perform a selective data augmentation\nto alleviate the need for complete historical corpora during data hallucination\nor replay.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 16:43:30 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Chaudhary", "Yatin", ""], ["Gupta", "Pankaj", ""], ["Runkler", "Thomas", ""]]}, {"id": "1909.13316", "submitter": "Vitor Cerqueira", "authors": "Vitor Cerqueira, Luis Torgo, Carlos Soares", "title": "Machine Learning vs Statistical Methods for Time Series Forecasting:\n  Size Matters", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time series forecasting is one of the most active research topics. Machine\nlearning methods have been increasingly adopted to solve these predictive\ntasks. However, in a recent work, these were shown to systematically present a\nlower predictive performance relative to simple statistical methods. In this\nwork, we counter these results. We show that these are only valid under an\nextremely low sample size. Using a learning curve method, our results suggest\nthat machine learning methods improve their relative predictive performance as\nthe sample size grows. The code to reproduce the experiments is available at\nhttps://github.com/vcerqueira/MLforForecasting.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 16:44:12 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Cerqueira", "Vitor", ""], ["Torgo", "Luis", ""], ["Soares", "Carlos", ""]]}, {"id": "1909.13322", "submitter": "Rongrong Wang", "authors": "Rongrong Wang, Xiaopeng Zhang", "title": "Capacity Preserving Mapping for High-dimensional Data Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a rigorous mathematical treatment to the crowding issue in data\nvisualization when high dimensional data sets are projected down to low\ndimensions for visualization. By properly adjusting the capacity of high\ndimensional balls, our method makes right enough room to prepare for the\nembedding. A key component of the proposed method is an estimation of the\ncorrelation dimension at various scales which reflects the data density\nvariation. The proposed adjustment to the capacity applies to any distance\n(Euclidean, geodesic, diffusion) and can potentially be used in many existing\nmethods to mitigate the crowding during the dimension reduction. We demonstrate\nthe effectiveness of the new method using synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 17:06:13 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 13:59:39 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wang", "Rongrong", ""], ["Zhang", "Xiaopeng", ""]]}, {"id": "1909.13327", "submitter": "Christoph Feinauer", "authors": "Matteo Negri, Davide Bergamini, Carlo Baldassi, Riccardo Zecchina,\n  Christoph Feinauer", "title": "Natural representation of composite data with replicated autoencoders", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative processes in biology and other fields often produce data that can\nbe regarded as resulting from a composition of basic features. Here we present\nan unsupervised method based on autoencoders for inferring these basic features\nof data. The main novelty in our approach is that the training is based on the\noptimization of the `local entropy' rather than the standard loss, resulting in\na more robust inference, and enhancing the performance on this type of data\nconsiderably. Algorithmically, this is realized by training an interacting\nsystem of replicated autoencoders. We apply this method to synthetic and\nprotein sequence data, and show that it is able to infer a hidden\nrepresentation that correlates well with the underlying generative process,\nwithout requiring any prior knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 17:41:44 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Negri", "Matteo", ""], ["Bergamini", "Davide", ""], ["Baldassi", "Carlo", ""], ["Zecchina", "Riccardo", ""], ["Feinauer", "Christoph", ""]]}, {"id": "1909.13330", "submitter": "Ezgi Yildirim", "authors": "Ezgi Y{\\i}ld{\\i}r{\\i}m, Payam Azad, \\c{S}ule G\\\"und\\\"uz\n  \\\"O\\u{g}\\\"ud\\\"uc\\\"u", "title": "Neural Hybrid Recommender: Recommendation needs collaboration", "comments": "Accepted for ECML PKDD 2019 International Workshop on New Frontiers\n  in Mining Complex Patterns", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning has gained an indisputable success in computer\nvision, speech recognition, and natural language processing. After its rising\nsuccess on these challenging areas, it has been studied on recommender systems\nas well, but mostly to include content features into traditional methods. In\nthis paper, we introduce a generalized neural network-based recommender\nframework that is easily extendable by additional networks. This framework\nnamed NHR, short for Neural Hybrid Recommender allows us to include more\nelaborate information from the same and different data sources. We have worked\non item prediction problems, but the framework can be used for rating\nprediction problems as well with a single change on the loss function. To\nevaluate the effect of such a framework, we have tested our approach on\nbenchmark and not yet experimented datasets. The results in these real-world\ndatasets show the superior performance of our approach in comparison with the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 17:51:52 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Y\u0131ld\u0131r\u0131m", "Ezgi", ""], ["Azad", "Payam", ""], ["\u00d6\u011f\u00fcd\u00fcc\u00fc", "\u015eule G\u00fcnd\u00fcz", ""]]}, {"id": "1909.13334", "submitter": "Zhengdao Chen", "authors": "Zhengdao Chen, Jianyu Zhang, Martin Arjovsky and L\\'eon Bottou", "title": "Symplectic Recurrent Neural Networks", "comments": "Added link to GitHub repository", "journal-ref": "8th International Conference on Learning Representations (ICLR\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Symplectic Recurrent Neural Networks (SRNNs) as learning\nalgorithms that capture the dynamics of physical systems from observed\ntrajectories. An SRNN models the Hamiltonian function of the system by a neural\nnetwork and furthermore leverages symplectic integration, multiple-step\ntraining and initial state optimization to address the challenging numerical\nissues associated with Hamiltonian systems. We show that SRNNs succeed reliably\non complex and noisy Hamiltonian systems. We also show how to augment the SRNN\nintegration scheme in order to handle stiff dynamical systems such as bouncing\nbilliards.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 18:04:07 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 16:32:53 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Chen", "Zhengdao", ""], ["Zhang", "Jianyu", ""], ["Arjovsky", "Martin", ""], ["Bottou", "L\u00e9on", ""]]}, {"id": "1909.13339", "submitter": "Badr-Eddine Ch\\'erief-Abdellatif", "authors": "Badr-Eddine Ch\\'erief-Abdellatif, Pierre Alquier", "title": "MMD-Bayes: Robust Bayesian Estimation via Maximum Mean Discrepancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some misspecified settings, the posterior distribution in Bayesian\nstatistics may lead to inconsistent estimates. To fix this issue, it has been\nsuggested to replace the likelihood by a pseudo-likelihood, that is the\nexponential of a loss function enjoying suitable robustness properties. In this\npaper, we build a pseudo-likelihood based on the Maximum Mean Discrepancy,\ndefined via an embedding of probability distributions into a reproducing kernel\nHilbert space. We show that this MMD-Bayes posterior is consistent and robust\nto model misspecification. As the posterior obtained in this way might be\nintractable, we also prove that reasonable variational approximations of this\nposterior enjoy the same properties. We provide details on a stochastic\ngradient algorithm to compute these variational approximations. Numerical\nsimulations indeed suggest that our estimator is more robust to\nmisspecification than the ones based on the likelihood.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 18:49:05 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 17:51:01 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Ch\u00e9rief-Abdellatif", "Badr-Eddine", ""], ["Alquier", "Pierre", ""]]}, {"id": "1909.13340", "submitter": "Geoffrey Fox", "authors": "Geoffrey Fox, Shantenu Jha", "title": "Learning Everywhere: A Taxonomy for the Integration of Machine Learning\n  and Simulations", "comments": "15th International Conference eScience 2019, September 24-27, 2019,\n  San Diego, California,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a taxonomy of research on Machine Learning (ML) applied to enhance\nsimulations together with a catalog of some activities. We cover eight patterns\nfor the link of ML to the simulations or systems plus three algorithmic areas:\nparticle dynamics, agent-based models and partial differential equations. The\npatterns are further divided into three action areas: Improving simulation with\nConfigurations and Integration of Data, Learn Structure, Theory and Model for\nSimulation, and Learn to make Surrogates.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 18:52:30 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 11:20:36 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Fox", "Geoffrey", ""], ["Jha", "Shantenu", ""]]}, {"id": "1909.13343", "submitter": "Xiao Wang", "authors": "Akshay Arora, Arun Nethi, Priyanka Kharat, Vency Verghese, Grant\n  Jenkins, Steve Miff, Vikas Chowdhry, Xiao Wang", "title": "ISTHMUS: Secure, Scalable, Real-time and Robust Machine Learning\n  Platform for Healthcare", "comments": "11 pages, 7 figures. Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, machine learning (ML) and artificial intelligence (AI) based\nsystems have evolved and scaled across different industries such as finance,\nretail, insurance, energy utilities, etc. Among other things, they have been\nused to predict patterns of customer behavior, to generate pricing models, and\nto predict the return on investments. But the successes in deploying machine\nlearning models at scale in those industries have not translated into the\nhealthcare setting. There are multiple reasons why integrating ML models into\nhealthcare has not been widely successful, but from a technical perspective,\ngeneral-purpose commercial machine learning platforms are not a good fit for\nhealthcare due to complexities in handling data quality issues, mandates to\ndemonstrate clinical relevance, and a lack of ability to monitor performance in\na highly regulated environment with stringent security and privacy needs. In\nthis paper, we describe Isthmus, a turnkey, cloud-based platform which\naddresses the challenges above and reduces time to market for operationalizing\nML/AI in healthcare. Towards the end, we describe three case studies which shed\nlight on Isthmus capabilities. These include (1) supporting an end-to-end\nlifecycle of a model which predicts trauma survivability at hospital trauma\ncenters, (2) bringing in and harmonizing data from disparate sources to create\na community data platform for inferring population as well as patient level\ninsights for Social Determinants of Health (SDoH), and (3) ingesting\nlive-streaming data from various IoT sensors to build models, which can\nleverage real-time and longitudinal information to make advanced time-sensitive\npredictions.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 19:15:08 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 16:06:39 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Arora", "Akshay", ""], ["Nethi", "Arun", ""], ["Kharat", "Priyanka", ""], ["Verghese", "Vency", ""], ["Jenkins", "Grant", ""], ["Miff", "Steve", ""], ["Chowdhry", "Vikas", ""], ["Wang", "Xiao", ""]]}, {"id": "1909.13355", "submitter": "Christoph Studer", "authors": "Eric Lei, Oscar Casta\\~neda, Olav Tirkkonen, Tom Goldstein, Christoph\n  Studer", "title": "Siamese Neural Networks for Wireless Positioning and Channel Charting", "comments": "Presented at Allerton 2019; 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been proposed recently for positioning and channel\ncharting of user equipments (UEs) in wireless systems. Both of these approaches\nprocess channel state information (CSI) that is acquired at a multi-antenna\nbase-station in order to learn a function that maps CSI to location\ninformation. CSI-based positioning using deep neural networks requires a\ndataset that contains both CSI and associated location information. Channel\ncharting (CC) only requires CSI information to extract relative position\ninformation. Since CC builds on dimensionality reduction, it can be implemented\nusing autoencoders. In this paper, we propose a unified architecture based on\nSiamese networks that can be used for supervised UE positioning and\nunsupervised channel charting. In addition, our framework enables\nsemisupervised positioning, where only a small set of location information is\navailable during training. We use simulations to demonstrate that Siamese\nnetworks achieve similar or better performance than existing positioning and CC\napproaches with a single, unified neural network architecture.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 20:04:15 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Lei", "Eric", ""], ["Casta\u00f1eda", "Oscar", ""], ["Tirkkonen", "Olav", ""], ["Goldstein", "Tom", ""], ["Studer", "Christoph", ""]]}, {"id": "1909.13360", "submitter": "Jung Lee", "authors": "Jung Hoon Lee", "title": "Library network, a possible path to explainable neural networks", "comments": "15 page, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) may outperform human brains in complex tasks, but\nthe lack of transparency in their decision-making processes makes us question\nwhether we could fully trust DNNs with high stakes problems. As DNNs'\noperations rely on a massive number of both parallel and sequential\nlinear/nonlinear computations, predicting their mistakes is nearly impossible.\nAlso, a line of studies suggests that DNNs can be easily deceived by\nadversarial attacks, indicating that their decisions can easily be corrupted by\nunexpected factors. Such vulnerability must be overcome if we intend to take\nadvantage of DNNs' efficiency in high stakes problems. Here, we propose an\nalgorithm that can help us better understand DNNs' decision-making processes.\nOur empirical evaluations suggest that this algorithm can effectively trace\nDNNs' decision processes from one layer to another and detect adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 20:25:08 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 16:12:46 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 23:59:46 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Lee", "Jung Hoon", ""]]}, {"id": "1909.13361", "submitter": "Christoph Kern", "authors": "Christoph Kern, Bernd Weiss, Jan-Philipp Kolb", "title": "A Longitudinal Framework for Predicting Nonresponse in Panel Surveys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonresponse in panel studies can lead to a substantial loss in data quality\ndue to its potential to introduce bias and distort survey estimates. Recent\nwork investigates the usage of machine learning to predict nonresponse in\nadvance, such that predicted nonresponse propensities can be used to inform the\ndata collection process. However, predicting nonresponse in panel studies\nrequires accounting for the longitudinal data structure in terms of model\nbuilding, tuning, and evaluation. This study proposes a longitudinal framework\nfor predicting nonresponse with machine learning and multiple panel waves and\nillustrates its application. With respect to model building, this approach\nutilizes information from multiple waves by introducing features that aggregate\nprevious (non)response patterns. Concerning model tuning and evaluation,\ntemporal cross-validation is employed by iterating through pairs of panel waves\nsuch that the training and test sets move in time. Implementing this approach\nwith data from a German probability-based mixed-mode panel shows that\naggregating information over multiple panel waves can be used to build\nprediction models with competitive and robust performance over all test waves.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 20:28:45 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 02:41:27 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Kern", "Christoph", ""], ["Weiss", "Bernd", ""], ["Kolb", "Jan-Philipp", ""]]}, {"id": "1909.13371", "submitter": "Erik Meijer", "authors": "Kartik Chandra, Erik Meijer, Samantha Andow, Emilio Arroyo-Fang, Irene\n  Dea, Johann George, Melissa Grueter, Basil Hosmer, Steffi Stumpos, Alanna\n  Tempest, Shannon Yang", "title": "Gradient Descent: The Ultimate Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working with any gradient-based machine learning algorithm involves the\ntedious task of tuning the optimizer's hyperparameters, such as the learning\nrate. There exist many techniques for automated hyperparameter optimization,\nbut they typically introduce even more hyperparameters to control the\nhyperparameter optimization process. We propose to instead learn the\nhyperparameters themselves by gradient descent, and furthermore to learn the\nhyper-hyperparameters by gradient descent as well, and so on ad infinitum. As\nthese towers of gradient-based optimizers grow, they become significantly less\nsensitive to the choice of top-level hyperparameters, hence decreasing the\nburden on the user to search for optimal values.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:41:49 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Chandra", "Kartik", ""], ["Meijer", "Erik", ""], ["Andow", "Samantha", ""], ["Arroyo-Fang", "Emilio", ""], ["Dea", "Irene", ""], ["George", "Johann", ""], ["Grueter", "Melissa", ""], ["Hosmer", "Basil", ""], ["Stumpos", "Steffi", ""], ["Tempest", "Alanna", ""], ["Yang", "Shannon", ""]]}, {"id": "1909.13374", "submitter": "Neehar Peri", "authors": "Neehar Peri, Neal Gupta, W. Ronny Huang, Liam Fowl, Chen Zhu, Soheil\n  Feizi, Tom Goldstein, John P. Dickerson", "title": "Deep k-NN Defense against Clean-label Data Poisoning Attacks", "comments": "Accepted to ECCV 2020 Workshop - Adversarial Robustness in the Real\n  World (AROW). First three authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Targeted clean-label data poisoning is a type of adversarial attack on\nmachine learning systems in which an adversary injects a few correctly-labeled,\nminimally-perturbed samples into the training data, causing a model to\nmisclassify a particular test sample during inference. Although defenses have\nbeen proposed for general poisoning attacks, no reliable defense for\nclean-label attacks has been demonstrated, despite the attacks' effectiveness\nand realistic applications. In this work, we propose a simple, yet\nhighly-effective Deep k-NN defense against both feature collision and convex\npolytope clean-label attacks on the CIFAR-10 dataset. We demonstrate that our\nproposed strategy is able to detect over 99% of poisoned examples in both\nattacks and remove them without compromising model performance. Additionally,\nthrough ablation studies, we discover simple guidelines for selecting the value\nof k as well as for implementing the Deep k-NN defense on real-world datasets\nwith class imbalance. Our proposed defense shows that current clean-label\npoisoning attack strategies can be annulled, and serves as a strong yet\nsimple-to-implement baseline defense to test future clean-label poisoning\nattacks. Our code is available at https://github.com/neeharperi/DeepKNNDefense\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:47:14 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 02:38:02 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 05:47:23 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Peri", "Neehar", ""], ["Gupta", "Neal", ""], ["Huang", "W. Ronny", ""], ["Fowl", "Liam", ""], ["Zhu", "Chen", ""], ["Feizi", "Soheil", ""], ["Goldstein", "Tom", ""], ["Dickerson", "John P.", ""]]}, {"id": "1909.13377", "submitter": "Jiacheng Pan", "authors": "Jiacheng Pan, Hongyi Sun, Kecheng Xu, Yifei Jiang, Xiangquan Xiao,\n  Jiangtao Hu, Jinghao Miao", "title": "Lane Attention: Predicting Vehicles' Moving Trajectories by Learning\n  Their Attention over Lanes", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately forecasting the future movements of surrounding vehicles is\nessential for safe and efficient operations of autonomous driving cars. This\ntask is difficult because a vehicle's moving trajectory is greatly determined\nby its driver's intention, which is often hard to estimate. By leveraging\nattention mechanisms along with long short-term memory (LSTM) networks, this\nwork learns the relation between a driver's intention and the vehicle's\nchanging positions relative to road infrastructures, and uses it to guide the\nprediction. Different from other state-of-the-art solutions, our work treats\nthe on-road lanes as non-Euclidean structures, unfolds the vehicle's moving\nhistory to form a spatio-temporal graph, and uses methods from Graph Neural\nNetworks to solve the problem. Not only is our approach a pioneering attempt in\nusing non-Euclidean methods to process static environmental features around a\npredicted object, our model also outperforms other state-of-the-art models in\nseveral metrics. The practicability and interpretability analysis of the model\nshows great potential for large-scale deployment in various autonomous driving\nsystems in addition to our own.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:50:39 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 05:44:24 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Pan", "Jiacheng", ""], ["Sun", "Hongyi", ""], ["Xu", "Kecheng", ""], ["Jiang", "Yifei", ""], ["Xiao", "Xiangquan", ""], ["Hu", "Jiangtao", ""], ["Miao", "Jinghao", ""]]}, {"id": "1909.13384", "submitter": "Rajesh Jayaram", "authors": "Huaian Diao, Rajesh Jayaram, Zhao Song, Wen Sun, David P. Woodruff", "title": "Optimal Sketching for Kronecker Product Regression and Low Rank\n  Approximation", "comments": "A preliminary version of this paper appeared in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Kronecker product regression problem, in which the design matrix\nis a Kronecker product of two or more matrices. Given $A_i \\in \\mathbb{R}^{n_i\n\\times d_i}$ for $i=1,2,\\dots,q$ where $n_i \\gg d_i$ for each $i$, and $b \\in\n\\mathbb{R}^{n_1 n_2 \\cdots n_q}$, let $\\mathcal{A} = A_1 \\otimes A_2 \\otimes\n\\cdots \\otimes A_q$. Then for $p \\in [1,2]$, the goal is to find $x \\in\n\\mathbb{R}^{d_1 \\cdots d_q}$ that approximately minimizes $\\|\\mathcal{A}x -\nb\\|_p$. Recently, Diao, Song, Sun, and Woodruff (AISTATS, 2018) gave an\nalgorithm which is faster than forming the Kronecker product $\\mathcal{A}$\nSpecifically, for $p=2$ their running time is $O(\\sum_{i=1}^q \\text{nnz}(A_i) +\n\\text{nnz}(b))$, where nnz$(A_i)$ is the number of non-zero entries in $A_i$.\nNote that nnz$(b)$ can be as large as $n_1 \\cdots n_q$. For $p=1,$ $q=2$ and\n$n_1 = n_2$, they achieve a worse bound of $O(n_1^{3/2} \\text{poly}(d_1d_2) +\n\\text{nnz}(b))$. In this work, we provide significantly faster algorithms. For\n$p=2$, our running time is $O(\\sum_{i=1}^q \\text{nnz}(A_i) )$, which has no\ndependence on nnz$(b)$. For $p<2$, our running time is $O(\\sum_{i=1}^q\n\\text{nnz}(A_i) + \\text{nnz}(b))$, which matches the prior best running time\nfor $p=2$. We also consider the related all-pairs regression problem, where\ngiven $A \\in \\mathbb{R}^{n \\times d}, b \\in \\mathbb{R}^n$, we want to solve\n$\\min_{x} \\|\\bar{A}x - \\bar{b}\\|_p$, where $\\bar{A} \\in \\mathbb{R}^{n^2 \\times\nd}, \\bar{b} \\in \\mathbb{R}^{n^2}$ consist of all pairwise differences of the\nrows of $A,b$. We give an $O(\\text{nnz}(A))$ time algorithm for $p \\in[1,2]$,\nimproving the $\\Omega(n^2)$ time needed to form $\\bar{A}$. Finally, we initiate\nthe study of Kronecker product low rank and low $t$-rank approximation. For\ninput $\\mathcal{A}$ as above, we give $O(\\sum_{i=1}^q \\text{nnz}(A_i))$ time\nalgorithms, which is much faster than computing $\\mathcal{A}$.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 22:24:28 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Diao", "Huaian", ""], ["Jayaram", "Rajesh", ""], ["Song", "Zhao", ""], ["Sun", "Wen", ""], ["Woodruff", "David P.", ""]]}, {"id": "1909.13387", "submitter": "Yi Luo", "authors": "Yi Luo, Enea Ceolini, Cong Han, Shih-Chii Liu, Nima Mesgarani", "title": "FaSNet: Low-latency Adaptive Beamforming for Multi-microphone Audio\n  Processing", "comments": "Accepted to ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Beamforming has been extensively investigated for multi-channel audio\nprocessing tasks. Recently, learning-based beamforming methods, sometimes\ncalled \\textit{neural beamformers}, have achieved significant improvements in\nboth signal quality (e.g. signal-to-noise ratio (SNR)) and speech recognition\n(e.g. word error rate (WER)). Such systems are generally non-causal and require\na large context for robust estimation of inter-channel features, which is\nimpractical in applications requiring low-latency responses. In this paper, we\npropose filter-and-sum network (FaSNet), a time-domain, filter-based\nbeamforming approach suitable for low-latency scenarios. FaSNet has a two-stage\nsystem design that first learns frame-level time-domain adaptive beamforming\nfilters for a selected reference channel, and then calculate the filters for\nall remaining channels. The filtered outputs at all channels are summed to\ngenerate the final output. Experiments show that despite its small model size,\nFaSNet is able to outperform several traditional oracle beamformers with\nrespect to scale-invariant signal-to-noise ratio (SI-SNR) in reverberant speech\nenhancement and separation tasks. Moreover, when trained with a\nfrequency-domain objective function on the CHiME-3 dataset, FaSNet achieves\n14.3\\% relative word error rate reduction (RWERR) compared with the baseline\nmodel. These results show the efficacy of FaSNet particularly in reverberant\nand noisy signal conditions.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 22:26:06 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 02:07:14 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Luo", "Yi", ""], ["Ceolini", "Enea", ""], ["Han", "Cong", ""], ["Liu", "Shih-Chii", ""], ["Mesgarani", "Nima", ""]]}, {"id": "1909.13391", "submitter": "Jayanth Regatti", "authors": "Jayanth Regatti, Gaurav Tendolkar, Yi Zhou, Abhishek Gupta, Yingbin\n  Liang", "title": "Distributed SGD Generalizes Well Under Asynchrony", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of fully synchronized distributed systems has faced a\nbottleneck due to the big data trend, under which asynchronous distributed\nsystems are becoming a major popularity due to their powerful scalability. In\nthis paper, we study the generalization performance of stochastic gradient\ndescent (SGD) on a distributed asynchronous system. The system consists of\nmultiple worker machines that compute stochastic gradients which are further\nsent to and aggregated on a common parameter server to update the variables,\nand the communication in the system suffers from possible delays. Under the\nalgorithm stability framework, we prove that distributed asynchronous SGD\ngeneralizes well given enough data samples in the training optimization. In\nparticular, our results suggest to reduce the learning rate as we allow more\nasynchrony in the distributed system. Such adaptive learning rate strategy\nimproves the stability of the distributed algorithm and reduces the\ncorresponding generalization error. Then, we confirm our theoretical findings\nvia numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 22:35:42 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Regatti", "Jayanth", ""], ["Tendolkar", "Gaurav", ""], ["Zhou", "Yi", ""], ["Gupta", "Abhishek", ""], ["Liang", "Yingbin", ""]]}, {"id": "1909.13392", "submitter": "Sunil Gandhi", "authors": "Sunil Gandhi, Tim Oates, Tinoosh Mohsenin, Nicholas Waytowich", "title": "Learning from Observations Using a Single Video Demonstration and Human\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method for learning from video demonstrations by\nusing human feedback to construct a mapping between the standard representation\nof the agent and the visual representation of the demonstration. In this way,\nwe leverage the advantages of both these representations, i.e., we learn the\npolicy using standard state representations, but are able to specify the\nexpected behavior using video demonstration. We train an autonomous agent using\na single video demonstration and use human feedback (using numerical similarity\nrating) to map the standard representation to the visual representation with a\nneural network. We show the effectiveness of our method by teaching a hopper\nagent in the MuJoCo to perform a backflip using a single video demonstration\ngenerated in MuJoCo as well as from a real-world YouTube video of a person\nperforming a backflip. Additionally, we show that our method can transfer to\nnew tasks, such as hopping, with very little human feedback.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 22:44:59 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gandhi", "Sunil", ""], ["Oates", "Tim", ""], ["Mohsenin", "Tinoosh", ""], ["Waytowich", "Nicholas", ""]]}, {"id": "1909.13396", "submitter": "Caiwen Ding", "authors": "Caiwen Ding, Shuo Wang, Ning Liu, Kaidi Xu, Yanzhi Wang and Yun Liang", "title": "REQ-YOLO: A Resource-Aware, Efficient Quantization Framework for Object\n  Detection on FPGAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs), as the basis of object detection, will play a\nkey role in the development of future autonomous systems with full autonomy.\nThe autonomous systems have special requirements of real-time, energy-efficient\nimplementations of DNNs on a power-constrained system. Two research thrusts are\ndedicated to performance and energy efficiency enhancement of the inference\nphase of DNNs. The first one is model compression techniques while the second\nis efficient hardware implementation. Recent works on extremely-low-bit CNNs\nsuch as the binary neural network (BNN) and XNOR-Net replace the traditional\nfloating-point operations with binary bit operations which significantly\nreduces the memory bandwidth and storage requirement. However, it suffers from\nnon-negligible accuracy loss and underutilized digital signal processing (DSP)\nblocks of FPGAs. To overcome these limitations, this paper proposes REQ-YOLO, a\nresource-aware, systematic weight quantization framework for object detection,\nconsidering both algorithm and hardware resource aspects in object detection.\nWe adopt the block-circulant matrix method and propose a heterogeneous weight\nquantization using the Alternating Direction Method of Multipliers (ADMM), an\neffective optimization technique for general, non-convex optimization problems.\nTo achieve real-time, highly-efficient implementations on FPGA, we present the\ndetailed hardware implementation of block circulant matrices on CONV layers and\ndevelop an efficient processing element (PE) structure supporting the\nheterogeneous weight quantization, CONV dataflow and pipelining techniques,\ndesign optimization, and a template-based automatic synthesis framework to\noptimally exploit hardware resource. Experimental results show that our\nproposed REQ-YOLO framework can significantly compress the YOLO model while\nintroducing very small accuracy degradation.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 23:21:05 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Ding", "Caiwen", ""], ["Wang", "Shuo", ""], ["Liu", "Ning", ""], ["Xu", "Kaidi", ""], ["Wang", "Yanzhi", ""], ["Liang", "Yun", ""]]}, {"id": "1909.13403", "submitter": "Zinan Lin", "authors": "Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, Vyas Sekar", "title": "Using GANs for Sharing Networked Time Series Data: Challenges, Initial\n  Promise, and Open Questions", "comments": "Published in IMC 2020. 20 pages, 26 figures", "journal-ref": null, "doi": "10.1145/3419394.3423643", "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited data access is a longstanding barrier to data-driven research and\ndevelopment in the networked systems community. In this work, we explore if and\nhow generative adversarial networks (GANs) can be used to incentivize data\nsharing by enabling a generic framework for sharing synthetic datasets with\nminimal expert knowledge. As a specific target, our focus in this paper is on\ntime series datasets with metadata (e.g., packet loss rate measurements with\ncorresponding ISPs). We identify key challenges of existing GAN approaches for\nsuch workloads with respect to fidelity (e.g., long-term dependencies, complex\nmultidimensional relationships, mode collapse) and privacy (i.e., existing\nguarantees are poorly understood and can sacrifice fidelity). To improve\nfidelity, we design a custom workflow called DoppelGANger (DG) and demonstrate\nthat across diverse real-world datasets (e.g., bandwidth measurements, cluster\nrequests, web sessions) and use cases (e.g., structural characterization,\npredictive modeling, algorithm comparison), DG achieves up to 43% better\nfidelity than baseline models. Although we do not resolve the privacy problem\nin this work, we identify fundamental challenges with both classical notions of\nprivacy and recent advances to improve the privacy properties of GANs, and\nsuggest a potential roadmap for addressing these challenges. By shedding light\non the promise and challenges, we hope our work can rekindle the conversation\non workflows for data sharing.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 00:13:19 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 06:39:40 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 15:45:27 GMT"}, {"version": "v4", "created": "Sun, 15 Nov 2020 01:20:02 GMT"}, {"version": "v5", "created": "Sun, 17 Jan 2021 04:54:51 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Lin", "Zinan", ""], ["Jain", "Alankar", ""], ["Wang", "Chen", ""], ["Fanti", "Giulia", ""], ["Sekar", "Vyas", ""]]}, {"id": "1909.13404", "submitter": "Renato Negrinho", "authors": "Renato Negrinho, Darshan Patil, Nghia Le, Daniel Ferreira, Matthew\n  Gormley, Geoffrey Gordon", "title": "Towards modular and programmable architecture search", "comments": "Published at NeurIPS 2019. Code and documentation for the language\n  implementation can be found at https://github.com/negrinho/deep_architect", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search methods are able to find high performance deep\nlearning architectures with minimal effort from an expert. However, current\nsystems focus on specific use-cases (e.g. convolutional image classifiers and\nrecurrent language models), making them unsuitable for general use-cases that\nan expert might wish to write. Hyperparameter optimization systems are\ngeneral-purpose but lack the constructs needed for easy application to\narchitecture search. In this work, we propose a formal language for encoding\nsearch spaces over general computational graphs. The language constructs allow\nus to write modular, composable, and reusable search space encodings and to\nreason about search space design. We use our language to encode search spaces\nfrom the architecture search literature. The language allows us to decouple the\nimplementations of the search space and the search algorithm, allowing us to\nexpose search spaces to search algorithms through a consistent interface. Our\nexperiments show the ease with which we can experiment with different\ncombinations of search spaces and search algorithms without having to implement\neach combination from scratch. We release an implementation of our language\nwith this paper.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 00:18:56 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Negrinho", "Renato", ""], ["Patil", "Darshan", ""], ["Le", "Nghia", ""], ["Ferreira", "Daniel", ""], ["Gormley", "Matthew", ""], ["Gordon", "Geoffrey", ""]]}, {"id": "1909.13408", "submitter": "Pawe{\\l} Widera", "authors": "Pawe{\\l} Widera, Paco M.J. Welsing, Christoph Ladel, John Loughlin,\n  Floris P.J.G. Lafeber, Florence Petit Dop, Jonathan Larkin, Harrie Weinans,\n  Ali Mobasheri and Jaume Bacardit", "title": "Multi-classifier prediction of knee osteoarthritis progression from\n  incomplete imbalanced longitudinal data", "comments": "22 pages, 12 figures, 10 tables", "journal-ref": "Scientific Reports, 10(1), 2020", "doi": "10.1038/s41598-020-64643-8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conventional inclusion criteria used in osteoarthritis clinical trials are\nnot very effective in selecting patients who would benefit from a therapy being\ntested. Typically majority of selected patients show no or limited disease\nprogression during a trial period. As a consequence, the effect of the tested\ntreatment cannot be observed, and the efforts and resources invested in running\nthe trial are not rewarded. This could be avoided, if selection criteria were\nmore predictive of the future disease progression.\n  In this article, we formulated the patient selection problem as a multi-class\nclassification task, with classes based on clinically relevant measures of\nprogression (over a time scale typical for clinical trials). Using data from\ntwo long-term knee osteoarthritis studies OAI and CHECK, we tested multiple\nalgorithms and learning process configurations (including multi-classifier\napproaches, cost-sensitive learning, and feature selection), to identify the\nbest performing machine learning models. We examined the behaviour of the best\nmodels, with respect to prediction errors and the impact of used features, to\nconfirm their clinical relevance. We found that the model-based selection\noutperforms the conventional inclusion criteria, reducing by 20-25% the number\nof patients who show no progression. This result might lead to more efficient\nclinical trials.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 00:42:14 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 17:58:00 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Widera", "Pawe\u0142", ""], ["Welsing", "Paco M. J.", ""], ["Ladel", "Christoph", ""], ["Loughlin", "John", ""], ["Lafeber", "Floris P. J. G.", ""], ["Dop", "Florence Petit", ""], ["Larkin", "Jonathan", ""], ["Weinans", "Harrie", ""], ["Mobasheri", "Ali", ""], ["Bacardit", "Jaume", ""]]}, {"id": "1909.13423", "submitter": "Gines Hidalgo Martinez", "authors": "Gines Hidalgo and Yaadhav Raaj and Haroon Idrees and Donglai Xiang and\n  Hanbyul Joo and Tomas Simon and Yaser Sheikh", "title": "Single-Network Whole-Body Pose Estimation", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first single-network approach for 2D~whole-body pose\nestimation, which entails simultaneous localization of body, face, hands, and\nfeet keypoints. Due to the bottom-up formulation, our method maintains constant\nreal-time performance regardless of the number of people in the image. The\nnetwork is trained in a single stage using multi-task learning, through an\nimproved architecture which can handle scale differences between body/foot and\nface/hand keypoints. Our approach considerably improves upon\nOpenPose~\\cite{cao2018openpose}, the only work so far capable of whole-body\npose estimation, both in terms of speed and global accuracy. Unlike OpenPose,\nour method does not need to run an additional network for each hand and face\ncandidate, making it substantially faster for multi-person scenarios. This work\ndirectly results in a reduction of computational complexity for applications\nthat require 2D whole-body information (e.g., VR/AR, re-targeting). In\naddition, it yields higher accuracy, especially for occluded, blurry, and low\nresolution faces and hands. For code, trained models, and validation\nbenchmarks, visit our project page:\nhttps://github.com/CMU-Perceptual-Computing-Lab/openpose_train.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 02:00:53 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Hidalgo", "Gines", ""], ["Raaj", "Yaadhav", ""], ["Idrees", "Haroon", ""], ["Xiang", "Donglai", ""], ["Joo", "Hanbyul", ""], ["Simon", "Tomas", ""], ["Sheikh", "Yaser", ""]]}, {"id": "1909.13428", "submitter": "Qinghua Tao", "authors": "Yusen Huo, Qinghua Tao, and Jianming Hu", "title": "Tensor-based Cooperative Control for Large Scale Multi-intersection\n  Traffic Signal Using Deep Reinforcement Learning and Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic signal control has long been considered as a critical topic in\nintelligent transportation systems. Most existing learning methods mainly focus\non isolated intersections and suffer from inefficient training. This paper aims\nat the cooperative control for large scale multi-intersection traffic signal,\nin which a novel end-to-end learning based model is established and the\nefficient training method is proposed correspondingly. In the proposed model,\nthe input traffic status in multi-intersections is represented by a tensor,\nwhich not only significantly reduces dimensionality than using a single matrix\nbut also avoids information loss. For the output, a multidimensional boolean\nvector is employed for the control policy to indicate whether the signal state\nchanges or not, which simplifies the representation and abides the practical\nphase changing rules. In the proposed model, a multi-task learning structure is\nused to get the cooperative policy by learning. Instead of only using the\nreinforcement learning to train the model, we employ imitation learning to\nintegrate a rule based model with neural networks to do the pre-training, which\nprovides a reliable and satisfactory stage solution and greatly accelerates the\nconvergence. Afterwards, the reinforcement learning method is adopted to\ncontinue the fine training, where proximal policy optimization algorithm is\nincorporated to solve the policy collapse problem in multi-dimensional output\nsituation. In numerical experiments, the advantages of the proposed model are\ndemonstrated with comparison to the related state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 02:20:47 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Huo", "Yusen", ""], ["Tao", "Qinghua", ""], ["Hu", "Jianming", ""]]}, {"id": "1909.13433", "submitter": "Juho Lee", "authors": "Juho Lee, Yoonho Lee, Yee Whye Teh", "title": "Deep Amortized Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep amortized clustering (DAC), a neural architecture which\nlearns to cluster datasets efficiently using a few forward passes. DAC\nimplicitly learns what makes a cluster, how to group data points into clusters,\nand how to count the number of clusters in datasets. DAC is meta-learned using\nlabelled datasets for training, a process distinct from traditional clustering\nalgorithms which usually require hand-specified prior knowledge about cluster\nshapes/structures. We empirically show, on both synthetic and image data, that\nDAC can efficiently and accurately cluster new datasets coming from the same\ndistribution used to generate training datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 02:35:49 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Lee", "Juho", ""], ["Lee", "Yoonho", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1909.13446", "submitter": "Xinlin Li", "authors": "Xinlin Li, Vahid Partovi Nia", "title": "Random Bias Initialization Improves Quantized Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary neural networks improve computationally efficiency of deep models with\na large margin. However, there is still a performance gap between a successful\nfull-precision training and binary training. We bring some insights about why\nthis accuracy drop exists and call for a better understanding of binary network\ngeometry. We start with analyzing full-precision neural networks with ReLU\nactivation and compare it with its binarized version. This comparison suggests\nto initialize networks with random bias, a counter-intuitive remedy.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 04:01:13 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 19:50:23 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Li", "Xinlin", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "1909.13455", "submitter": "Zhiyuan Liu", "authors": "Zhiyuan Liu, Guohui Ding, Lijun Chen and Enoch Yeung", "title": "Towards Scalable Koopman Operator Learning: Convergence Rates and A\n  Distributed Learning Algorithm", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an alternating optimization algorithm to the nonconvex Koopman\noperator learning problem for nonlinear dynamic systems. We show that the\nproposed algorithm will converge to a critical point with rate $O(1/T)$ and\n$O(\\frac{1}{\\log T})$ for the constant and diminishing learning rates,\nrespectively, under some mild conditions. To cope with the high dimensional\nnonlinear dynamical systems, we present the first-ever distributed Koopman\noperator learning algorithm. We show that the distributed Koopman operator\nlearning has the same convergence properties as the centralized Koopman\noperator learning, in the absence of optimal tracker, so long as the basis\nfunctions satisfy a set of state-based decomposition conditions. Numerical\nexperiments are provided to complement our theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 04:57:05 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 17:24:50 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Liu", "Zhiyuan", ""], ["Ding", "Guohui", ""], ["Chen", "Lijun", ""], ["Yeung", "Enoch", ""]]}, {"id": "1909.13456", "submitter": "Zhe Gan", "authors": "Wenlin Wang, Chenyang Tao, Zhe Gan, Guoyin Wang, Liqun Chen, Xinyuan\n  Zhang, Ruiyi Zhang, Qian Yang, Ricardo Henao, Lawrence Carin", "title": "Improving Textual Network Learning with Variational Homophilic\n  Embeddings", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of many network learning applications crucially hinges on the\nsuccess of network embedding algorithms, which aim to encode rich network\ninformation into low-dimensional vertex-based vector representations. This\npaper considers a novel variational formulation of network embeddings, with\nspecial focus on textual networks. Different from most existing methods that\noptimize a discriminative objective, we introduce Variational Homophilic\nEmbedding (VHE), a fully generative model that learns network embeddings by\nmodeling the semantic (textual) information with a variational autoencoder,\nwhile accounting for the structural (topology) information through a novel\nhomophilic prior design. Homophilic vertex embeddings encourage similar\nembedding vectors for related (connected) vertices. The proposed VHE promises\nbetter generalization for downstream tasks, robustness to incomplete\nobservations, and the ability to generalize to unseen vertices. Extensive\nexperiments on real-world networks, for multiple tasks, demonstrate that the\nproposed method consistently achieves superior performance relative to\ncompeting state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 05:03:25 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Wang", "Wenlin", ""], ["Tao", "Chenyang", ""], ["Gan", "Zhe", ""], ["Wang", "Guoyin", ""], ["Chen", "Liqun", ""], ["Zhang", "Xinyuan", ""], ["Zhang", "Ruiyi", ""], ["Yang", "Qian", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1909.13458", "submitter": "Yuandong Tian", "authors": "Yuandong Tian", "title": "Student Specialization in Deep ReLU Networks With Finite Width and Input\n  Dimension", "comments": "Accepted in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a deep ReLU / Leaky ReLU student network trained from the output\nof a fixed teacher network of the same depth, with Stochastic Gradient Descent\n(SGD). The student network is \\emph{over-realized}: at each layer $l$, the\nnumber $n_l$ of student nodes is more than that ($m_l$) of teacher. Under mild\nconditions on dataset and teacher network, we prove that when the gradient is\nsmall at every data sample, each teacher node is \\emph{specialized} by at least\none student node \\emph{at the lowest layer}. For two-layer network, such\nspecialization can be achieved by training on any dataset of \\emph{polynomial}\nsize $\\mathcal{O}( K^{5/2} d^3 \\epsilon^{-1})$. until the gradient magnitude\ndrops to $\\mathcal{O}(\\epsilon/K^{3/2}\\sqrt{d})$. Here $d$ is the input\ndimension, $K = m_1 + n_1$ is the total number of neurons in the lowest layer\nof teacher and student. Note that we require a specific form of data\naugmentation and the sample complexity includes the additional data generated\nfrom augmentation. To our best knowledge, we are the first to give polynomial\nsample complexity for student specialization of training two-layer (Leaky) ReLU\nnetworks with finite depth and width in teacher-student setting, and finite\ncomplexity for the lowest layer specialization in multi-layer case, without\nparametric assumption of the input (like Gaussian). Our theory suggests that\nteacher nodes with large fan-out weights get specialized first when the\ngradient is still large, while others are specialized with small gradient,\nwhich suggests inductive bias in training. This shapes the stage of training as\nempirically observed in multiple previous works. Experiments on synthetic and\nCIFAR10 verify our findings. The code is released in\nhttps://github.com/facebookresearch/luckmatters.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 05:06:58 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:22:39 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 19:23:16 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 04:12:10 GMT"}, {"version": "v5", "created": "Mon, 8 Jun 2020 16:41:18 GMT"}, {"version": "v6", "created": "Sun, 28 Jun 2020 18:12:14 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tian", "Yuandong", ""]]}, {"id": "1909.13459", "submitter": "Jie Liu", "authors": "Jie Liu, Xiao Yan, Xinyan Dai, Zhirong Li, James Cheng, Ming-Chang\n  Yang", "title": "Understanding and Improving Proximity Graph based Maximum Inner Product\n  Search", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inner-product navigable small world graph (ip-NSW) represents the\nstate-of-the-art method for approximate maximum inner product search (MIPS) and\nit can achieve an order of magnitude speedup over the fastest baseline.\nHowever, to date it is still unclear where its exceptional performance comes\nfrom. In this paper, we show that there is a strong norm bias in the MIPS\nproblem, which means that the large norm items are very likely to become the\nresult of MIPS. Then we explain the good performance of ip-NSW as matching the\nnorm bias of the MIPS problem - large norm items have big in-degrees in the\nip-NSW proximity graph and a walk on the graph spends the majority of\ncomputation on these items, thus effectively avoids unnecessary computation on\nsmall norm items. Furthermore, we propose the ip-NSW+ algorithm, which improves\nip-NSW by introducing an additional angular proximity graph. Search is first\nconducted on the angular graph to find the angular neighbors of a query and\nthen the MIPS neighbors of these angular neighbors are used to initialize the\ncandidate pool for search on the inner-product proximity graph. Experiment\nresults show that ip-NSW+ consistently and significantly outperforms ip-NSW and\nprovides more robust performance under different data distributions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 05:12:49 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 14:19:53 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Liu", "Jie", ""], ["Yan", "Xiao", ""], ["Dai", "Xinyan", ""], ["Li", "Zhirong", ""], ["Cheng", "James", ""], ["Yang", "Ming-Chang", ""]]}, {"id": "1909.13471", "submitter": "Damien Teney", "authors": "Damien Teney, Ehsan Abbasnejad, Anton van den Hengel", "title": "On Incorporating Semantic Prior Knowledge in Deep Learning Through\n  Embedding-Space Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The knowledge that humans hold about a problem often extends far beyond a set\nof training data and output labels. While the success of deep learning mostly\nrelies on supervised training, important properties cannot be inferred\nefficiently from end-to-end annotations alone, for example causal relations or\ndomain-specific invariances. We present a general technique to supplement\nsupervised training with prior knowledge expressed as relations between\ntraining instances. We illustrate the method on the task of visual question\nanswering to exploit various auxiliary annotations, including relations of\nequivalence and of logical entailment between questions. Existing methods to\nuse these annotations, including auxiliary losses and data augmentation, cannot\nguarantee the strict inclusion of these relations into the model since they\nrequire a careful balancing against the end-to-end objective. Our method uses\nthese relations to shape the embedding space of the model, and treats them as\nstrict constraints on its learned representations. In the context of VQA, this\napproach brings significant improvements in accuracy and robustness, in\nparticular over the common practice of incorporating the constraints as a soft\nregularizer. We also show that incorporating this type of prior knowledge with\nour method brings consistent improvements, independently from the amount of\nsupervised data used. It demonstrates the value of an additional training\nsignal that is otherwise difficult to extract from end-to-end annotations\nalone.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 06:26:09 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 04:07:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Teney", "Damien", ""], ["Abbasnejad", "Ehsan", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1909.13488", "submitter": "Guang-He Lee", "authors": "Guang-He Lee and Tommi S. Jaakkola", "title": "Oblique Decision Trees from Derivatives of ReLU Networks", "comments": "Published in International Conference on Learning Representations\n  (ICLR), 2020. Code available: https://github.com/guanghelee/iclr20-lcn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how neural models can be used to realize piece-wise constant\nfunctions such as decision trees. The proposed architecture, which we call\nlocally constant networks, builds on ReLU networks that are piece-wise linear\nand hence their associated gradients with respect to the inputs are locally\nconstant. We formally establish the equivalence between the classes of locally\nconstant networks and decision trees. Moreover, we highlight several\nadvantageous properties of locally constant networks, including how they\nrealize decision trees with parameter sharing across branching / leaves.\nIndeed, only $M$ neurons suffice to implicitly model an oblique decision tree\nwith $2^M$ leaf nodes. The neural representation also enables us to adopt many\ntools developed for deep networks (e.g., DropConnect (Wan et al., 2013)) while\nimplicitly training decision trees. We demonstrate that our method outperforms\nalternative techniques for training oblique decision trees in the context of\nmolecular property classification and regression tasks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 07:23:16 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 18:55:49 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lee", "Guang-He", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1909.13492", "submitter": "Zhigang Yao", "authors": "Zhigang Yao and Wee Chin Tan", "title": "Manifold Fitting in Ambient Space", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data sets in many applications no longer comprise samples of real\nvectors in a real vector space but samples of much more complex structures\nwhich may be represented as points in a space with certain underlying geometric\nstructure, namely a manifold. Manifold learning is an emerging field for\nlearning the underlying structure. The study of manifold learning can be split\ninto two main branches, namely dimension reduction and manifold fitting. With\nthe aim of interacting statistics and geometry, we tackle the problem of\nmanifold fitting in the ambient space. Inspired by the relation between the\neigenvalues of the Laplace-Beltrami operator and the geometry of a manifold, we\naim to find a small set of points that preserve the geometry of the underlying\nmanifold. Based on this relationship, we extend the idea of subsampling to\nnoisy datasets in high dimensional space and utilize the Moving Least Squares\n(MLS) approach to approximate the underlying manifold. We analyze the two core\nsteps in our proposed method theoretically and also provide the bounds for the\nMLS approach. Our simulation results and real data analysis demonstrate the\nsuperiority of our method in estimating the underlying manifold from noisy\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 07:36:41 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Yao", "Zhigang", ""], ["Tan", "Wee Chin", ""]]}, {"id": "1909.13501", "submitter": "Guang-Yuan Hao", "authors": "Guang-Yuan Hao, Hong-Xing Yu, Wei-Shi Zheng", "title": "DSRGAN: Explicitly Learning Disentangled Representation of Underlying\n  Structure and Rendering for Image Generation without Tuple Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on explicitly learning disentangled representation for natural image\ngeneration, where the underlying spatial structure and the rendering on the\nstructure can be independently controlled respectively, yet using no tuple\nsupervision. The setting is significant since tuple supervision is costly and\nsometimes even unavailable. However, the task is highly unconstrained and thus\nill-posed. To address this problem, we propose to introduce an auxiliary domain\nwhich shares a common underlying-structure space with the target domain, and we\nmake a partially shared latent space assumption. The key idea is to encourage\nthe partially shared latent variable to represent the similar underlying\nspatial structures in both domains, while the two domain-specific latent\nvariables will be unavoidably arranged to present renderings of two domains\nrespectively. This is achieved by designing two parallel generative networks\nwith a common Progressive Rendering Architecture (PRA), which constrains both\ngenerative networks' behaviors to model shared underlying structure and to\nmodel spatially dependent relation between rendering and underlying structure.\nThus, we propose DSRGAN (GANs for Disentangling Underlying Structure and\nRendering) to instantiate our method. We also propose a quantitative criterion\n(the Normalized Disentanglability) to quantify disentanglability. Comparison to\nthe state-of-the-art methods shows that DSRGAN can significantly outperform\nthem in disentanglability.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 08:07:11 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Hao", "Guang-Yuan", ""], ["Yu", "Hong-Xing", ""], ["Zheng", "Wei-Shi", ""]]}, {"id": "1909.13518", "submitter": "Gabriel Kalweit", "authors": "Gabriel Kalweit, Maria Huegle, Joschka Boedecker", "title": "Composite Q-learning: Multi-scale Q-function Decomposition and Separable\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, off-policy reinforcement learning methods have shown\npromising results in their application for robot control. Deep Q-learning,\nhowever, still suffers from poor data-efficiency and is susceptible to\nstochasticity in the environment or reward functions which is limiting with\nregard to real-world applications. We alleviate these problems by proposing two\nnovel off-policy Temporal-Difference formulations: (1) Truncated Q-functions\nwhich represent the return for the first n steps of a target-policy rollout\nw.r.t. the full action-value and (2) Shifted Q-functions, acting as the\nfarsighted return after this truncated rollout. This decomposition allows us to\noptimize both parts with their individual learning rates, achieving significant\nlearning speedup. We prove that the combination of these short- and long-term\npredictions is a representation of the full return, leading to the Composite\nQ-learning algorithm. We show the efficacy of Composite Q-learning in the\ntabular case and compare Deep Composite Q-learning with TD3 and TD3(Delta),\nwhich we introduce as an off-policy variant of TD(Delta). Moreover, we show\nthat Composite TD3 outperforms TD3 as well as state-of-the-art compositional\nQ-learning approaches significantly in terms of data-efficiency in multiple\nsimulated robot tasks and that Composite Q-learning is robust to stochastic\nenvironments and reward functions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 08:40:09 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 08:32:55 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kalweit", "Gabriel", ""], ["Huegle", "Maria", ""], ["Boedecker", "Joschka", ""]]}, {"id": "1909.13521", "submitter": "Katsuhiko Ishiguro", "authors": "Shion Honda, Hirotaka Akita, Katsuhiko Ishiguro, Toshiki Nakanishi,\n  Kenta Oono", "title": "Graph Residual Flow for Molecular Graph Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical generative models for molecular graphs attract attention from\nmany researchers from the fields of bio- and chemo-informatics. Among these\nmodels, invertible flow-based approaches are not fully explored yet. In this\npaper, we propose a powerful invertible flow for molecular graphs, called graph\nresidual flow (GRF). The GRF is based on residual flows, which are known for\nmore flexible and complex non-linear mappings than traditional coupling flows.\nWe theoretically derive non-trivial conditions such that GRF is invertible, and\npresent a way of keeping the entire flows invertible throughout the training\nand sampling. Experimental results show that a generative model based on the\nproposed GRF achieves comparable generation performance, with much smaller\nnumber of trainable parameters compared to the existing flow-based model.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 08:43:10 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Honda", "Shion", ""], ["Akita", "Hirotaka", ""], ["Ishiguro", "Katsuhiko", ""], ["Nakanishi", "Toshiki", ""], ["Oono", "Kenta", ""]]}, {"id": "1909.13550", "submitter": "Max-Heinrich Laves M. Sc.", "authors": "Max-Heinrich Laves, Sontje Ihler, Karl-Philipp Kortmann, Tobias\n  Ortmaier", "title": "Well-calibrated Model Uncertainty with Temperature Scaling for Dropout\n  Variational Inference", "comments": "Accepted at 4th workshop on Bayesian Deep Learning (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model uncertainty obtained by variational Bayesian inference with Monte Carlo\ndropout is prone to miscalibration. The uncertainty does not represent the\nmodel error well. In this paper, temperature scaling is extended to dropout\nvariational inference to calibrate model uncertainty. Expected uncertainty\ncalibration error (UCE) is presented as a metric to measure miscalibration of\nuncertainty. The effectiveness of this approach is evaluated on CIFAR-10/100\nfor recent CNN architectures. Experimental results show, that temperature\nscaling considerably reduces miscalibration by means of UCE and enables robust\nrejection of uncertain predictions. The proposed approach can easily be derived\nfrom frequentist temperature scaling and yields well-calibrated model\nuncertainty. It is simple to implement and does not affect the model accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 09:29:44 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 14:46:21 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 16:49:58 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Laves", "Max-Heinrich", ""], ["Ihler", "Sontje", ""], ["Kortmann", "Karl-Philipp", ""], ["Ortmaier", "Tobias", ""]]}, {"id": "1909.13561", "submitter": "Yizhe Wu", "authors": "Yizhe Wu, Sudhanshu Kasewa, Oliver Groth, Sasha Salter, Li Sun, Oiwi\n  Parker Jones, Ingmar Posner", "title": "Imagine That! Leveraging Emergent Affordances for 3D Tool Synthesis", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the richness of information captured by the latent\nspace of a vision-based generative model. The model combines unsupervised\ngenerative learning with a task-based performance predictor to learn and to\nexploit task-relevant object affordances given visual observations from a\nreaching task, involving a scenario and a stick-like tool. While the learned\nembedding of the generative model captures factors of variation in 3D tool\ngeometry (e.g. length, width, and shape), the performance predictor identifies\nsub-manifolds of the embedding that correlate with task success. Within a\nvariety of scenarios, we demonstrate that traversing the latent space via\nbackpropagation from the performance predictor allows us to imagine tools\nappropriate for the task at hand. Our results indicate that affordances-like\nthe utility for reaching-are encoded along smooth trajectories in latent space.\nAccessing these emergent affordances by considering only high-level performance\ncriteria (such as task success) enables an agent to manipulate tool geometries\nin a targeted and deliberate way.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 09:55:33 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 11:37:36 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 06:51:23 GMT"}, {"version": "v4", "created": "Wed, 7 Oct 2020 04:05:19 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Wu", "Yizhe", ""], ["Kasewa", "Sudhanshu", ""], ["Groth", "Oliver", ""], ["Salter", "Sasha", ""], ["Sun", "Li", ""], ["Jones", "Oiwi Parker", ""], ["Posner", "Ingmar", ""]]}, {"id": "1909.13563", "submitter": "Nikolaos Bakas", "authors": "Nikolaos P. Bakas, Andreas Langousis, Mihalis Nicolaou, Savvas A.\n  Chatzichristofis", "title": "A Gradient Free Neural Network Framework Based on Universal\n  Approximation Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a numerical scheme for computation of Artificial Neural Networks\n(ANN) weights, which stems from the Universal Approximation Theorem, avoiding\nlaborious iterations. The proposed algorithm adheres to the underlying theory,\nis highly fast, and results in remarkably low errors when applied for\nregression and classification of complex data-sets, such as the Griewank\nfunction of multiple variables $\\mathbf{x} \\in \\mathbb{R}^{100}$ with random\nnoise addition, and MNIST database for handwritten digits recognition, with\n$7\\times10^4$ images. The same mathematical formulation is found capable of\napproximating highly nonlinear functions in multiple dimensions, with low\nerrors (e.g. $10^{-10}$) for the test-set of the unknown functions, their\nhigher-order partial derivatives, as well as numerically solving Partial\nDifferential Equations. The method is based on the calculation of the weights\nof each neuron in small neighborhoods of the data, such that the corresponding\nlocal approximation matrix is invertible. Accordingly, optimization of\nhyperparameters is not necessary, as the number of neurons stems directly from\nthe dimensionality of the data, further improving the algorithmic speed. Under\nthis setting, overfitting is inherently avoided, and the results are\ninterpretable and reproducible. The complexity of the proposed algorithm is of\nclass P with\n$\\mathcal{O}(mn^2)+\\mathcal{O}(\\frac{m^3}{n^2})-\\mathcal{O}(\\log(n+1))$\ncomputing time, with respect to the observations $m$ and features $n$, in\ncontrast with the NP-Complete class of standard algorithms for ANN training.\nThe performance of the method is high, irrespective of the size of the dataset,\nand the test-set errors are similar or smaller than the training errors,\nindicating the generalization efficiency of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:04:15 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 09:54:05 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 11:29:07 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Bakas", "Nikolaos P.", ""], ["Langousis", "Andreas", ""], ["Nicolaou", "Mihalis", ""], ["Chatzichristofis", "Savvas A.", ""]]}, {"id": "1909.13568", "submitter": "Mandar Gogate", "authors": "Kia Dashtipour, Mandar Gogate, Jingpeng Li, Fengling Jiang, Bin Kong,\n  Amir Hussain", "title": "A Hybrid Persian Sentiment Analysis Framework: Integrating Dependency\n  Grammar Based Rules and Deep Neural Networks", "comments": "Accepted in Neurocomputing, Demo available at:\n  https://cogbid.napier.ac.uk/demo/persian-sentiment-analysis/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media hold valuable, vast and unstructured information on public\nopinion that can be utilized to improve products and services. The automatic\nanalysis of such data, however, requires a deep understanding of natural\nlanguage. Current sentiment analysis approaches are mainly based on word\nco-occurrence frequencies, which are inadequate in most practical cases. In\nthis work, we propose a novel hybrid framework for concept-level sentiment\nanalysis in Persian language, that integrates linguistic rules and deep\nlearning to optimize polarity detection. When a pattern is triggered, the\nframework allows sentiments to flow from words to concepts based on symbolic\ndependency relations. When no pattern is triggered, the framework switches to\nits subsymbolic counterpart and leverages deep neural networks (DNN) to perform\nthe classification. The proposed framework outperforms state-of-the-art\napproaches (including support vector machine, and logistic regression) and DNN\nclassifiers (long short-term memory, and Convolutional Neural Networks) with a\nmargin of 10-15% and 3-4% respectively, using benchmark Persian product and\nhotel reviews corpora.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:29:45 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Dashtipour", "Kia", ""], ["Gogate", "Mandar", ""], ["Li", "Jingpeng", ""], ["Jiang", "Fengling", ""], ["Kong", "Bin", ""], ["Hussain", "Amir", ""]]}, {"id": "1909.13576", "submitter": "Lukas Brinkmeyer", "authors": "Lukas Brinkmeyer, Rafael Rego Drumond, Randolf Scholz, Josif Grabocka,\n  Lars Schmidt-Thieme", "title": "Chameleon: Learning Model Initializations Across Tasks With Different\n  Schemas", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric models, and particularly neural networks, require weight\ninitialization as a starting point for gradient-based optimization. Recent work\nshows that a specific initial parameter set can be learned from a population of\nsupervised learning tasks. Using this initial parameter set enables a fast\nconvergence for unseen classes even when only a handful of instances is\navailable (model-agnostic meta-learning). Currently, methods for learning model\ninitializations are limited to a population of tasks sharing the same schema,\ni.e., the same number, order, type, and semantics of predictor and target\nvariables. In this paper, we address the problem of meta-learning parameter\ninitialization across tasks with different schemas, i.e., if the number of\npredictors varies across tasks, while they still share some variables. We\npropose Chameleon, a model that learns to align different predictor schemas to\na common representation. In experiments on 23 datasets of the OpenML-CC18\nbenchmark, we show that Chameleon can successfully learn parameter\ninitializations across tasks with different schemas, presenting, to the best of\nour knowledge, the first cross-dataset few-shot classification approach for\nunstructured data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:42:44 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 12:36:22 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 17:13:37 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 16:34:37 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Brinkmeyer", "Lukas", ""], ["Drumond", "Rafael Rego", ""], ["Scholz", "Randolf", ""], ["Grabocka", "Josif", ""], ["Schmidt-Thieme", "Lars", ""]]}, {"id": "1909.13579", "submitter": "Etienne Bennequin", "authors": "Etienne Bennequin", "title": "Meta-learning algorithms for Few-Shot Computer Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-Shot Learning is the challenge of training a model with only a small\namount of data. Many solutions to this problem use meta-learning algorithms,\ni.e. algorithms that learn to learn. By sampling few-shot tasks from a larger\ndataset, we can teach these algorithms to solve new, unseen tasks. This\ndocument reports my work on meta-learning algorithms for Few-Shot Computer\nVision. This work was done during my internship at Sicara, a French company\nbuilding image recognition solutions for businesses. It contains: 1. an\nextensive review of the state-of-the-art in few-shot computer vision; 2. a\nbenchmark of meta-learning algorithms for few-shot image classification; 3. the\nintroduction to a novel meta-learning algorithm for few-shot object detection,\nwhich is still in development.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:51:16 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Bennequin", "Etienne", ""]]}, {"id": "1909.13581", "submitter": "Jie Bai", "authors": "Jie Bai, Linjing Li, Daniel Zeng", "title": "Spread-gram: A spreading-activation schema of network structural\n  learning", "comments": "21 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning has exploded recently. However, existing\nstudies usually reconstruct networks as sequences or matrices, which may cause\ninformation bias or sparsity problem during model training. Inspired by a\ncognitive model of human memory, we propose a network representation learning\nscheme. In this scheme, we learn node embeddings by adjusting the proximity of\nnodes traversing the spreading structure of the network. Our proposed method\nshows a significant improvement in multiple analysis tasks based on various\nreal-world networks, ranging from semantic networks to protein interaction\nnetworks, international trade networks, human behavior networks, etc. In\nparticular, our model can effectively discover the hierarchical structures in\nnetworks. The well-organized model training speeds up the convergence to only a\nsmall number of iterations, and the training time is linear with respect to the\nedge numbers.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:55:00 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Bai", "Jie", ""], ["Li", "Linjing", ""], ["Zeng", "Daniel", ""]]}, {"id": "1909.13582", "submitter": "Maria H\\\"ugle", "authors": "Maria Huegle, Gabriel Kalweit, Moritz Werling, Joschka Boedecker", "title": "Dynamic Interaction-Aware Scene Understanding for Reinforcement Learning\n  in Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The common pipeline in autonomous driving systems is highly modular and\nincludes a perception component which extracts lists of surrounding objects and\npasses these lists to a high-level decision component. In this case, leveraging\nthe benefits of deep reinforcement learning for high-level decision making\nrequires special architectures to deal with multiple variable-length sequences\nof different object types, such as vehicles, lanes or traffic signs. At the\nsame time, the architecture has to be able to cover interactions between\ntraffic participants in order to find the optimal action to be taken. In this\nwork, we propose the novel Deep Scenes architecture, that can learn complex\ninteraction-aware scene representations based on extensions of either 1) Deep\nSets or 2) Graph Convolutional Networks. We present the Graph-Q and DeepScene-Q\noff-policy reinforcement learning algorithms, both outperforming\nstate-of-the-art methods in evaluations with the publicly available traffic\nsimulator SUMO.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 10:59:11 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Huegle", "Maria", ""], ["Kalweit", "Gabriel", ""], ["Werling", "Moritz", ""], ["Boedecker", "Joschka", ""]]}, {"id": "1909.13584", "submitter": "Laura Rieger", "authors": "Laura Rieger, Chandan Singh, W. James Murdoch, Bin Yu", "title": "Interpretations are useful: penalizing explanations to align neural\n  networks with prior knowledge", "comments": "18 pages; published in ICML2020; Erratum: numbers in table 1 were too\n  high (now corrected) with the trend remaining the same", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an explanation of a deep learning model to be effective, it must provide\nboth insight into a model and suggest a corresponding action in order to\nachieve some objective. Too often, the litany of proposed explainable deep\nlearning methods stop at the first step, providing practitioners with insight\ninto a model, but no way to act on it. In this paper, we propose contextual\ndecomposition explanation penalization (CDEP), a method which enables\npractitioners to leverage existing explanation methods in order to increase the\npredictive accuracy of deep learning models. In particular, when shown that a\nmodel has incorrectly assigned importance to some features, CDEP enables\npractitioners to correct these errors by directly regularizing the provided\nexplanations. Using explanations provided by contextual decomposition (CD)\n(Murdoch et al., 2018), we demonstrate the ability of our method to increase\nperformance on an array of toy and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 11:02:01 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 12:05:59 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 19:24:50 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 12:43:21 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Rieger", "Laura", ""], ["Singh", "Chandan", ""], ["Murdoch", "W. James", ""], ["Yu", "Bin", ""]]}, {"id": "1909.13595", "submitter": "David Salinas", "authors": "David Salinas, Huibin Shen, Valerio Perrone", "title": "A Quantile-based Approach for Hyperparameter Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a popular methodology to tune the\nhyperparameters of expensive black-box functions. Traditionally, BO focuses on\na single task at a time and is not designed to leverage information from\nrelated functions, such as tuning performance objectives of the same algorithm\nacross multiple datasets. In this work, we introduce a novel approach to\nachieve transfer learning across different \\emph{datasets} as well as different\n\\emph{objectives}. The main idea is to regress the mapping from hyperparameter\nto objective quantiles with a semi-parametric Gaussian Copula distribution,\nwhich provides robustness against different scales or outliers that can occur\nin different tasks. We introduce two methods to leverage this mapping: a\nThompson sampling strategy as well as a Gaussian Copula process using such\nquantile estimate as a prior. We show that these strategies can combine the\nestimation of multiple objectives such as latency and accuracy, steering the\nhyperparameters optimization toward faster predictions for the same level of\naccuracy. Extensive experiments demonstrate significant improvements over\nstate-of-the-art methods for both hyperparameter optimization and neural\narchitecture search.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 11:28:09 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 11:43:02 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Salinas", "David", ""], ["Shen", "Huibin", ""], ["Perrone", "Valerio", ""]]}, {"id": "1909.13600", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng", "title": "Towards Robust Direct Perception Networks for Automated Driving", "comments": "Preprint. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of engineering robust direct perception neural\nnetworks with output being regression. Such networks take high dimensional\ninput image data, and they produce affordances such as the curvature of the\nupcoming road segment or the distance to the front vehicle. Our proposal starts\nby allowing a neural network prediction to deviate from the label with\ntolerance $\\Delta$. The source of tolerance can be either contractual or from\nlimiting factors where two entities may label the same data with slightly\ndifferent numerical values. The tolerance motivates the use of a non-standard\nloss function where the loss is set to $0$ so long as the prediction-to-label\ndistance is less than $\\Delta$. We further extend the loss function and define\na new provably robust criterion that is parametric to the allowed output\ntolerance $\\Delta$, the layer index $\\tilde{l}$ where perturbation is\nconsidered, and the maximum perturbation amount $\\kappa$. During training, the\nrobust loss is computed by first propagating symbolic errors from the\n$\\tilde{l}$-th layer (with quantity bounded by $\\kappa$) to the output layer,\nfollowed by computing the overflow between the error bounds and the allowed\ntolerance. The overall concept is experimented in engineering a direct\nperception neural network for understanding the central position of the\nego-lane in pixel coordinates.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 11:32:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Cheng", "Chih-Hong", ""]]}, {"id": "1909.13607", "submitter": "Haotian Fu", "authors": "Haotian Fu, Hongyao Tang, Jianye Hao, Wulong Liu, Chen Chen", "title": "MGHRL: Meta Goal-generation for Hierarchical Reinforcement Learning", "comments": "Accepted to the ICLR 2020 workshop: Beyond tabula rasa in RL\n  (BeTR-RL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most meta reinforcement learning (meta-RL) methods learn to adapt to new\ntasks by directly optimizing the parameters of policies over primitive action\nspace. Such algorithms work well in tasks with relatively slight difference.\nHowever, when the task distribution becomes wider, it would be quite\ninefficient to directly learn such a meta-policy. In this paper, we propose a\nnew meta-RL algorithm called Meta Goal-generation for Hierarchical RL (MGHRL).\nInstead of directly generating policies over primitive action space for new\ntasks, MGHRL learns to generate high-level meta strategies over subgoals given\npast experience and leaves the rest of how to achieve subgoals as independent\nRL subtasks. Our empirical results on several challenging simulated robotics\nenvironments show that our method enables more efficient and generalized\nmeta-learning from past experience.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 11:55:17 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 03:39:47 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 05:26:55 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 08:36:01 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Fu", "Haotian", ""], ["Tang", "Hongyao", ""], ["Hao", "Jianye", ""], ["Liu", "Wulong", ""], ["Chen", "Chen", ""]]}, {"id": "1909.13611", "submitter": "An-Phi Nguyen", "authors": "An-phi Nguyen, Mar\\'ia Rodr\\'iguez Mart\\'inez", "title": "MonoNet: Towards Interpretable Models by Learning Monotonic Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to interpret, or explain, the predictions made by a machine\nlearning model is of fundamental importance. This is especially true when there\nis interest in deploying data-driven models to make high-stakes decisions, e.g.\nin healthcare. While recent years have seen an increasing interest in\ninterpretable machine learning research, this field is currently lacking an\nagreed-upon definition of interpretability, and some researchers have called\nfor a more active conversation towards a rigorous approach to interpretability.\nJoining this conversation, we claim in this paper that the difficulty of\ninterpreting a complex model stems from the existing interactions among\nfeatures. We argue that by enforcing monotonicity between features and outputs,\nwe are able to reason about the effect of a single feature on an output\nindependently from other features, and consequently better understand the\nmodel. We show how to structurally introduce this constraint in deep learning\nmodels by adding new simple layers. We validate our model on benchmark\ndatasets, and compare our results with previously proposed interpretable\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 12:02:16 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Nguyen", "An-phi", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""]]}, {"id": "1909.13640", "submitter": "Mohammad Hamghalam", "authors": "Mohammad Hamghalam, Baiying Lei, and Tianfu Wang", "title": "Brain Tumor Synthetic Segmentation in 3D Multimodal MRI Scans", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-46640-4_15", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The magnetic resonance (MR) analysis of brain tumors is widely used for\ndiagnosis and examination of tumor subregions. The overlapping area among the\nintensity distribution of healthy, enhancing, non-enhancing, and edema regions\nmakes the automatic segmentation a challenging task. Here, we show that a\nconvolutional neural network trained on high-contrast images can transform the\nintensity distribution of brain lesions in its internal subregions.\nSpecifically, a generative adversarial network (GAN) is extended to synthesize\nhigh-contrast images. A comparison of these synthetic images and real images of\nbrain tumor tissue in MR scans showed significant segmentation improvement and\ndecreased the number of real channels for segmentation. The synthetic images\nare used as a substitute for real channels and can bypass real modalities in\nthe multimodal brain tumor segmentation framework. Segmentation results on\nBraTS 2019 dataset demonstrate that our proposed approach can efficiently\nsegment the tumor areas. In the end, we predict patient survival time based on\nvolumetric features of the tumor subregions as well as the age of each case\nthrough several regression models.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 02:11:24 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 06:50:19 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Hamghalam", "Mohammad", ""], ["Lei", "Baiying", ""], ["Wang", "Tianfu", ""]]}, {"id": "1909.13654", "submitter": "Tian Zhao", "authors": "Tian Zhao, Yaqi Zhang, Kunle Olukotun", "title": "Serving Recurrent Neural Networks Efficiently with a Spatial Accelerator", "comments": null, "journal-ref": "Proceedings of the 2 nd SysML Conference, Palo Alto, CA, USA,\n  2019. Copyright 2019 by the author(s)", "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network (RNN) applications form a major class of AI-powered,\nlow-latency data center workloads. Most execution models for RNN acceleration\nbreak computation graphs into BLAS kernels, which lead to significant\ninter-kernel data movement and resource underutilization. We show that by\nsupporting more general loop constructs that capture design parameters in\naccelerators, it is possible to improve resource utilization using cross-kernel\noptimization without sacrificing programmability. Such abstraction level\nenables a design space search that can lead to efficient usage of on-chip\nresources on a spatial architecture across a range of problem sizes. We\nevaluate our optimization strategy on such abstraction with DeepBench using a\nconfigurable spatial accelerator. We demonstrate that this implementation\nprovides a geometric speedup of 30x in performance, 1.6x in area, and 2x in\npower efficiency compared to a Tesla V100 GPU, and a geometric speedup of 2x\ncompared to Microsoft Brainwave implementation on a Stratix 10 FPGA.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 00:55:17 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zhao", "Tian", ""], ["Zhang", "Yaqi", ""], ["Olukotun", "Kunle", ""]]}, {"id": "1909.13668", "submitter": "Victor Prokhorov", "authors": "Victor Prokhorov, Ehsan Shareghi, Yingzhen Li, Mohammad Taher\n  Pilehvar, Nigel Collier", "title": "On the Importance of the Kullback-Leibler Divergence Term in Variational\n  Autoencoders for Text Generation", "comments": "10 pages; Accepted in 3rd Workshop on Neural Generation and\n  Translation (WNGT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAEs) are known to suffer from learning\nuninformative latent representation of the input due to issues such as\napproximated posterior collapse, or entanglement of the latent space. We impose\nan explicit constraint on the Kullback-Leibler (KL) divergence term inside the\nVAE objective function. While the explicit constraint naturally avoids\nposterior collapse, we use it to further understand the significance of the KL\nterm in controlling the information transmitted through the VAE channel. Within\nthis framework, we explore different properties of the estimated posterior\ndistribution, and highlight the trade-off between the amount of information\nencoded in a latent code during training, and the generative capacity of the\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:05:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Prokhorov", "Victor", ""], ["Shareghi", "Ehsan", ""], ["Li", "Yingzhen", ""], ["Pilehvar", "Mohammad Taher", ""], ["Collier", "Nigel", ""]]}, {"id": "1909.13671", "submitter": "Lei Li", "authors": "Lei Li", "title": "On the convergence of gradient descent for two layer neural networks", "comments": "There was some issue in the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that gradient descent can yield the zero training loss in\nthe over-parametrized regime (the width of the neural networks is much larger\nthan the number of data points). In this work, combining the ideas of some\nexisting works, we investigate the gradient descent method for training\ntwo-layer neural networks for approximating some target continuous functions.\nBy making use the generic chaining technique from probability theory, we show\nthat gradient descent can yield an exponential convergence rate, while the\nwidth of the neural networks needed is independent of the size of the training\ndata. The result also implies some strong approximation ability of the\ntwo-layer neural networks without curse of dimensionality.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:14:44 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 01:53:57 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 09:09:25 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Li", "Lei", ""]]}, {"id": "1909.13676", "submitter": "Alexander Robey", "authors": "Alexander Robey, Arman Adibi, Brent Schlotfeldt, George J. Pappas,\n  Hamed Hassani", "title": "Optimal Algorithms for Submodular Maximization with Distributed\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of discrete optimization problems that aim to maximize a\nsubmodular objective function subject to a distributed partition matroid\nconstraint. More precisely, we consider a networked scenario in which multiple\nagents choose actions from local strategy sets with the goal of maximizing a\nsubmodular objective function defined over the set of all possible actions.\nGiven this distributed setting, we develop Constraint-Distributed Continuous\nGreedy (CDCG), a message passing algorithm that converges to the tight\n$(1-1/e)$ approximation factor of the optimum global solution using only local\ncomputation and communication. It is known that a sequential greedy algorithm\ncan only achieve a $1/2$ multiplicative approximation of the optimal solution\nfor this class of problems in the distributed setting. Our framework relies on\nlifting the discrete problem to a continuous domain and developing a consensus\nalgorithm that achieves the tight $(1-1/e)$ approximation guarantee of the\nglobal discrete solution once a proper rounding scheme is applied. We also\noffer empirical results from a multi-agent area coverage problem to show that\nthe proposed method significantly outperforms the state-of-the-art sequential\ngreedy method.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:26:05 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 00:21:21 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 01:40:48 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Robey", "Alexander", ""], ["Adibi", "Arman", ""], ["Schlotfeldt", "Brent", ""], ["Pappas", "George J.", ""], ["Hassani", "Hamed", ""]]}, {"id": "1909.13690", "submitter": "Suryabhan Singh Hada", "authors": "Suryabhan Singh Hada and Miguel \\'A. Carreira-Perpi\\~n\\'an", "title": "Style Transfer by Rigid Alignment in Neural Net Feature Space", "comments": "Accepted to WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arbitrary style transfer is an important problem in computer vision that aims\nto transfer style patterns from an arbitrary style image to a given content\nimage. However, current methods either rely on slow iterative optimization or\nfast pre-determined feature transformation, but at the cost of compromised\nvisual quality of the styled image; especially, distorted content structure. In\nthis work, we present an effective and efficient approach for arbitrary style\ntransfer that seamlessly transfers style patterns as well as keep content\nstructure intact in the styled image. We achieve this by aligning style\nfeatures to content features using rigid alignment; thus modifying style\nfeatures, unlike the existing methods that do the opposite. We demonstrate the\neffectiveness of the proposed approach by generating high-quality stylized\nimages and compare the results with the current state-of-the-art techniques for\narbitrary style transfer.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 02:54:00 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 08:03:17 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Hada", "Suryabhan Singh", ""], ["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""]]}, {"id": "1909.13692", "submitter": "Berkin Bilgic", "authors": "Daniel Polak, Itthi Chatnuntawech, Jaeyeon Yoon, Siddharth Srinivasan\n  Iyer, Jongho Lee, Peter Bachert, Elfar Adalsteinsson, Kawin Setsompop, Berkin\n  Bilgic", "title": "Nonlinear Dipole Inversion (NDI) enables Quantitative Susceptibility\n  Mapping (QSM) without parameter tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Nonlinear Dipole Inversion (NDI) for high-quality Quantitative\nSusceptibility Mapping (QSM) without regularization tuning, while matching the\nimage quality of state-of-the-art reconstruction techniques. In addition to\navoiding over-smoothing that these techniques often suffer from, we also\nobviate the need for parameter selection. NDI is flexible enough to allow for\nreconstruction from an arbitrary number of head orientations, and outperforms\nCOSMOS even when using as few as 1-direction data. This is made possible by a\nnonlinear forward-model that uses the magnitude as an effective prior, for\nwhich we derived a simple gradient descent update rule. We synergistically\ncombine this physics-model with a Variational Network (VN) to leverage the\npower of deep learning in the VaNDI algorithm. This technique adopts the simple\ngradient descent rule from NDI and learns the network parameters during\ntraining, hence requires no additional parameter tuning. Further, we evaluate\nNDI at 7T using highly accelerated Wave-CAIPI acquisitions at 0.5 mm isotropic\nresolution and demonstrate high-quality QSM from as few as 2-direction data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 13:37:24 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Polak", "Daniel", ""], ["Chatnuntawech", "Itthi", ""], ["Yoon", "Jaeyeon", ""], ["Iyer", "Siddharth Srinivasan", ""], ["Lee", "Jongho", ""], ["Bachert", "Peter", ""], ["Adalsteinsson", "Elfar", ""], ["Setsompop", "Kawin", ""], ["Bilgic", "Berkin", ""]]}, {"id": "1909.13698", "submitter": "Yuyang Gao", "authors": "Yuyang Gao, Giorgio A. Ascoli, Liang Zhao", "title": "BEAN: Interpretable Representation Learning with Biologically-Enhanced\n  Artificial Neuronal Assembly Regularization", "comments": "Accepted as an original research paper at Frontiers in Neurorobotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known for extracting useful information from\nlarge amounts of data. However, the representations learned in DNNs are\ntypically hard to interpret, especially in dense layers. One crucial issue of\nthe classical DNN model such as multilayer perceptron (MLP) is that neurons in\nthe same layer of DNNs are conditionally independent of each other, which makes\nco-training and emergence of higher modularity difficult. In contrast to DNNs,\nbiological neurons in mammalian brains display substantial dependency patterns.\nSpecifically, biological neural networks encode representations by so-called\nneuronal assemblies: groups of neurons interconnected by strong synaptic\ninteractions and sharing joint semantic content. The resulting population\ncoding is essential for human cognitive and mnemonic processes. Here, we\npropose a novel Biologically Enhanced Artificial Neuronal assembly (BEAN)\nregularization to model neuronal correlations and dependencies, inspired by\ncell assembly theory from neuroscience. Experimental results show that BEAN\nenables the formation of interpretable neuronal functional clusters and\nconsequently promotes a sparse, memory/computation-efficient network without\nloss of model performance. Moreover, our few-shot learning experiments\ndemonstrate that BEAN could also enhance the generalizability of the model when\ntraining samples are extremely limited.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 14:54:30 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 14:18:45 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Gao", "Yuyang", ""], ["Ascoli", "Giorgio A.", ""], ["Zhao", "Liang", ""]]}, {"id": "1909.13717", "submitter": "Ana Valeria Gonzalez-Gardu\\~no", "authors": "Ana Valeria Gonzalez, Isabelle Augenstein and Anders S{\\o}gaard", "title": "Retrieval-based Goal-Oriented Dialogue Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research on dialogue has focused either on dialogue generation for\nopenended chit chat or on state tracking for goal-directed dialogue. In this\nwork, we explore a hybrid approach to goal-oriented dialogue generation that\ncombines retrieval from past history with a hierarchical, neural\nencoder-decoder architecture. We evaluate this approach in the customer support\ndomain using the Multiwoz dataset (Budzianowski et al., 2018). We show that\nadding this retrieval step to a hierarchical, neural encoder-decoder\narchitecture leads to significant improvements, including responses that are\nrated more appropriate and fluent by human evaluators. Finally, we compare our\nretrieval-based model to various semantically conditioned models explicitly\nusing past dialog act information, and find that our proposed model is\ncompetitive with the current state of the art (Chen et al., 2019), while not\nrequiring explicit labels about past machine acts.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:02:53 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Gonzalez", "Ana Valeria", ""], ["Augenstein", "Isabelle", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1909.13718", "submitter": "Navid Zobeiry", "authors": "Navid Zobeiry, Keith D. Humfeld", "title": "An Iterative Scientific Machine Learning Approach for Discovery of\n  Theories Underlying Physical Phenomena", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Form a pure mathematical point of view, common functional forms representing\ndifferent physical phenomena can be defined. For example, rates of chemical\nreactions, diffusion and heat transfer are all governed by exponential-type\nexpressions. If machine learning is used for physical problems, inferred from\ndomain knowledge, original features can be transformed in such a way that the\nend expressions are highly aligned and correlated with the underlying physics.\nThis should significantly reduce the training effort in terms of iterations,\narchitecture and the number of required data points. We extend this by\napproaching a problem from an agnostic position and propose a systematic and\niterative methodology to discover theories underlying physical phenomena. At\nfirst, commonly observed functional forms of theoretical expressions are used\nto transform original features before conducting correlation analysis to\noutput. Using random combinations of highly correlated expressions, training of\nNeural Networks (NN) are performed. By comparing the rates of convergence or\nmean error in training, expressions describing the underlying physical problems\ncan be discovered, leading to extracting explicit analytic equations. This\napproach was used in three blind demonstrations for different physical\nphenomena.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 05:06:34 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zobeiry", "Navid", ""], ["Humfeld", "Keith D.", ""]]}, {"id": "1909.13721", "submitter": "Andrey Sapegin", "authors": "Andrey Sapegin and Christoph Meinel", "title": "K-Metamodes: frequency- and ensemble-based distributed k-modes\n  clustering for security analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays processing of Big Security Data, such as log messages, is commonly\nused for intrusion detection purposed. Its heterogeneous nature, as well as\ncombination of numerical and categorical attributes does not allow to apply the\nexisting data mining methods directly on the data without feature\npreprocessing. Therefore, a rather computationally expensive conversion of\ncategorical attributes into vector space should be utilised for analysis of\nsuch data. However, a well-known k-modes algorithm allows to cluster the\ncategorical data directly and avoid conversion into the vector space. The\nexisting implementations of k-modes for Big Data processing are ensemble-based\nand utilise two-step clustering, where data subsets are first clustered\nindependently, whereas the resulting cluster modes are clustered again in order\nto calculate metamodes valid for all data subsets. In this paper, the novel\nfrequency-based distance function is proposed for the second step of\nensemble-based k-modes clustering. Besides this, the existing feature\ndiscretisation method from the previous work is utilised in order to adapt\nk-modes for processing of mixed data sets. The resulting k-metamodes algorithm\nwas tested on two public security data sets and reached higher effectiveness in\ncomparison with the previous work.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:05:50 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sapegin", "Andrey", ""], ["Meinel", "Christoph", ""]]}, {"id": "1909.13726", "submitter": "Timothy Verstraeten", "authors": "Felipe Gomez Marulanda, Pieter Libin, Timothy Verstraeten, Ann Now\\'e", "title": "IPC-Net: 3D point-cloud segmentation using deep inter-point\n  convolutional layers", "comments": null, "journal-ref": "2018 IEEE 30th International Conference on Tools with Artificial\n  Intelligence (ICTAI),", "doi": "10.1109/ICTAI.2018.00054", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, the demand for better segmentation and classification\nalgorithms in 3D spaces has significantly grown due to the popularity of new 3D\nsensor technologies and advancements in the field of robotics. Point-clouds are\none of the most popular representations to store a digital description of 3D\nshapes. However, point-clouds are stored in irregular and unordered structures,\nwhich limits the direct use of segmentation algorithms such as Convolutional\nNeural Networks. The objective of our work is twofold: First, we aim to provide\na full analysis of the PointNet architecture to illustrate which features are\nbeing extracted from the point-clouds. Second, to propose a new network\narchitecture called IPC-Net to improve the state-of-the-art point cloud\narchitectures. We show that IPC-Net extracts a larger set of unique features\nallowing the model to produce more accurate segmentations compared to the\nPointNet architecture. In general, our approach outperforms PointNet on every\nfamily of 3D geometries on which the models were tested. A high generalisation\nimprovement was observed on every 3D shape, especially on the rockets dataset.\nOur experiments demonstrate that our main contribution, inter-point activation\non the network's layers, is essential to accurately segment 3D point-clouds.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:14:30 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Marulanda", "Felipe Gomez", ""], ["Libin", "Pieter", ""], ["Verstraeten", "Timothy", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1909.13733", "submitter": "David Semedo", "authors": "David Semedo and Jo\\~ao Magalh\\~aes", "title": "Cross-Modal Subspace Learning with Scheduled Adaptive Margin Constraints", "comments": "To appear in ACM MM 2019", "journal-ref": null, "doi": "10.1145/3343031.3351030", "report-no": null, "categories": "cs.MM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-modal embeddings, between textual and visual modalities, aim to\norganise multimodal instances by their semantic correlations. State-of-the-art\napproaches use maximum-margin methods, based on the hinge-loss, to enforce a\nconstant margin m, to separate projections of multimodal instances from\ndifferent categories. In this paper, we propose a novel scheduled adaptive\nmaximum-margin (SAM) formulation that infers triplet-specific constraints\nduring training, therefore organising instances by adaptively enforcing\ninter-category and inter-modality correlations. This is supported by a\nscheduled adaptive margin function, that is smoothly activated, replacing a\nstatic margin by an adaptively inferred one reflecting triplet-specific\nsemantic correlations while accounting for the incremental learning behaviour\nof neural networks to enforce category cluster formation and enforcement.\nExperiments on widely used datasets show that our model improved upon\nstate-of-the-art approaches, by achieving a relative improvement of up to\n~12.5% over the second best method, thus confirming the effectiveness of our\nscheduled adaptive margin formulation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:20:06 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Semedo", "David", ""], ["Magalh\u00e3es", "Jo\u00e3o", ""]]}, {"id": "1909.13739", "submitter": "Danilo Jimenez Rezende", "authors": "Danilo Jimenez Rezende and S\\'ebastien Racani\\`ere and Irina Higgins\n  and Peter Toth", "title": "Equivariant Hamiltonian Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces equivariant hamiltonian flows, a method for learning\nexpressive densities that are invariant with respect to a known Lie-algebra of\nlocal symmetry transformations while providing an equivariant representation of\nthe data. We provide proof of principle demonstrations of how such flows can be\nlearnt, as well as how the addition of symmetry invariance constraints can\nimprove data efficiency and generalisation. Finally, we make connections to\ndisentangled representation learning and show how this work relates to a\nrecently proposed definition.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:30:15 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Rezende", "Danilo Jimenez", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Higgins", "Irina", ""], ["Toth", "Peter", ""]]}, {"id": "1909.13743", "submitter": "Roman F\\\"oll", "authors": "Roman F\\\"oll, Bernard Haasdonk, Markus Hanselmann, Holger Ulmer", "title": "Deep recurrent Gaussian process with variational Sparse Spectrum\n  approximation", "comments": "22 pages, 4 figures, 3 tables. arXiv admin note: substantial text\n  overlap with arXiv:1711.00799", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling sequential data has become more and more important in practice. Some\napplications are autonomous driving, virtual sensors and weather forecasting.\nTo model such systems, so called recurrent models are frequently used. In this\npaper we introduce several new Deep recurrent Gaussian process (DRGP) models\nbased on the Sparse Spectrum Gaussian process (SSGP) and the improved version,\ncalled variational Sparse Spectrum Gaussian process (VSSGP). We follow the\nrecurrent structure given by an existing DRGP based on a specific variational\nsparse Nystr\\\"om approximation, the recurrent Gaussian process (RGP). Similar\nto previous work, we also variationally integrate out the input-space and hence\ncan propagate uncertainty through the Gaussian process (GP) layers. Our\napproach can deal with a larger class of covariance functions than the RGP,\nbecause its spectral nature allows variational integration in all stationary\ncases. Furthermore, we combine the (variational) Sparse Spectrum ((V)SS)\napproximations with a well known inducing-input regularization framework. We\nimprove over current state of the art methods in prediction accuracy for\nexperimental data-sets used for their evaluation and introduce a new data-set\nfor engine control, named Emission.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 09:44:10 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["F\u00f6ll", "Roman", ""], ["Haasdonk", "Bernard", ""], ["Hanselmann", "Markus", ""], ["Ulmer", "Holger", ""]]}, {"id": "1909.13765", "submitter": "Mostafa Khalaji", "authors": "Mostafa Khalaji and Chitra Dadkhah", "title": "FNHSM_HRS: Hybrid recommender system using fuzzy clustering and\n  heuristic similarity measure", "comments": "6 pages, Conference: 7th Iranian Joint Congress on Fuzzy and\n  Intelligent Systems, 18th Conference on Fuzzy Systems and 17th Conference on\n  Intelligent Systems At: Bojnord, Iran, University of Bojnord, p.p 562-568,\n  January 2019. Persian format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Recommender Systems have become a comprehensive system for helping\nand guiding users in a huge amount of data on the Internet. Collaborative\nFiltering offers to active users based on the rating of a set of users. One of\nthe simplest and most comprehensible and successful models is to find users\nwith a taste in recommender systems. In this model, with increasing number of\nusers and items, the system is faced to scalability problem. On the other hand,\nimproving system performance when there is little information available from\nratings, that is important. In this paper, a hybrid recommender system called\nFNHSM_HRS which is based on the new heuristic similarity measure (NHSM) along\nwith a fuzzy clustering is presented. Using the fuzzy clustering method in the\nproposed system improves the scalability problem and increases the accuracy of\nsystem recommendations. The proposed system is based on the collaborative\nfiltering model and is partnered with the heuristic similarity measure to\nimprove the system's performance and accuracy. The evaluation of the proposed\nsystem based results on the MovieLens dataset carried out the results using\nMAE, Recall, Precision and Accuracy measures Indicating improvement in system\nperformance and increasing the accuracy of recommendation to collaborative\nfiltering methods which use other measures to find similarities.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 20:27:29 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Khalaji", "Mostafa", ""], ["Dadkhah", "Chitra", ""]]}, {"id": "1909.13768", "submitter": "Damiano Mazza", "authors": "Alois Brunel, Damiano Mazza, Michele Pagani", "title": "Backpropagation in the Simply Typed Lambda-calculus with Linear Negation", "comments": "27 pages", "journal-ref": "Proc. ACM Program. Lang. 4, POPL, Article 64 (January 2020)", "doi": "10.1145/3371132", "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation is a classic automatic differentiation algorithm computing\nthe gradient of functions specified by a certain class of simple, first-order\nprograms, called computational graphs. It is a fundamental tool in several\nfields, most notably machine learning, where it is the key for efficiently\ntraining (deep) neural networks. Recent years have witnessed the quick growth\nof a research field called differentiable programming, the aim of which is to\nexpress computational graphs more synthetically and modularly by resorting to\nactual programming languages endowed with control flow operators and\nhigher-order combinators, such as map and fold. In this paper, we extend the\nbackpropagation algorithm to a paradigmatic example of such a programming\nlanguage: we define a compositional program transformation from the\nsimply-typed lambda-calculus to itself augmented with a notion of linear\nnegation, and prove that this computes the gradient of the source program with\nthe same efficiency as first-order backpropagation. The transformation is\ncompletely effect-free and thus provides a purely logical understanding of the\ndynamics of backpropagation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 15:18:49 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 13:04:53 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Brunel", "Alois", ""], ["Mazza", "Damiano", ""], ["Pagani", "Michele", ""]]}, {"id": "1909.13784", "submitter": "Reuben Tan", "authors": "Reuben Tan, Huijuan Xu, Kate Saenko, Bryan A. Plummer", "title": "LoGAN: Latent Graph Co-Attention Network for Weakly-Supervised Video\n  Moment Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of weakly-supervised video moment retrieval is to localize the video\nsegment most relevant to the given natural language query without access to\ntemporal annotations during training. Prior strongly- and weakly-supervised\napproaches often leverage co-attention mechanisms to learn visual-semantic\nrepresentations for localization. However, while such approaches tend to focus\non identifying relationships between elements of the video and language\nmodalities, there is less emphasis on modeling relational context between video\nframes given the semantic context of the query. Consequently, the\nabove-mentioned visual-semantic representations, built upon local frame\nfeatures, do not contain much contextual information. To address this\nlimitation, we propose a Latent Graph Co-Attention Network (LoGAN) that\nexploits fine-grained frame-by-word interactions to reason about\ncorrespondences between all possible pairs of frames, given the semantic\ncontext of the query. Comprehensive experiments across two datasets, DiDeMo and\nCharades-Sta, demonstrate the effectiveness of our proposed latent co-attention\nmodel where it outperforms current state-of-the-art (SOTA) weakly-supervised\napproaches by a significant margin. Notably, it even achieves a 11% improvement\nto Recall@1 accuracy over strongly-supervised SOTA methods on DiDeMo.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 16:26:30 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 18:11:37 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Tan", "Reuben", ""], ["Xu", "Huijuan", ""], ["Saenko", "Kate", ""], ["Plummer", "Bryan A.", ""]]}, {"id": "1909.13788", "submitter": "Junxian He", "authors": "Junxian He, Jiatao Gu, Jiajun Shen, Marc'Aurelio Ranzato", "title": "Revisiting Self-Training for Neural Sequence Generation", "comments": "ICLR 2020. The first two authors contributed equally. Updated to fix\n  typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-training is one of the earliest and simplest semi-supervised methods.\nThe key idea is to augment the original labeled dataset with unlabeled data\npaired with the model's prediction (i.e. the pseudo-parallel data). While\nself-training has been extensively studied on classification problems, in\ncomplex sequence generation tasks (e.g. machine translation) it is still\nunclear how self-training works due to the compositionality of the target\nspace. In this work, we first empirically show that self-training is able to\ndecently improve the supervised baseline on neural sequence generation tasks.\nThrough careful examination of the performance gains, we find that the\nperturbation on the hidden states (i.e. dropout) is critical for self-training\nto benefit from the pseudo-parallel data, which acts as a regularizer and\nforces the model to yield close predictions for similar unlabeled inputs. Such\neffect helps the model correct some incorrect predictions on unlabeled data. To\nfurther encourage this mechanism, we propose to inject noise to the input\nspace, resulting in a \"noisy\" version of self-training. Empirical study on\nstandard machine translation and text summarization benchmarks shows that noisy\nself-training is able to effectively utilize unlabeled data and improve the\nperformance of the supervised baseline by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 15:30:00 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 08:35:41 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 22:49:31 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["He", "Junxian", ""], ["Gu", "Jiatao", ""], ["Shen", "Jiajun", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1909.13789", "submitter": "Irina Higgins", "authors": "Peter Toth and Danilo Jimenez Rezende and Andrew Jaegle and\n  S\\'ebastien Racani\\`ere and Aleksandar Botev and Irina Higgins", "title": "Hamiltonian Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hamiltonian formalism plays a central role in classical and quantum\nphysics. Hamiltonians are the main tool for modelling the continuous time\nevolution of systems with conserved quantities, and they come equipped with\nmany useful properties, like time reversibility and smooth interpolation in\ntime. These properties are important for many machine learning problems - from\nsequence prediction to reinforcement learning and density modelling - but are\nnot typically provided out of the box by standard tools such as recurrent\nneural networks. In this paper, we introduce the Hamiltonian Generative Network\n(HGN), the first approach capable of consistently learning Hamiltonian dynamics\nfrom high-dimensional observations (such as images) without restrictive domain\nassumptions. Once trained, we can use HGN to sample new trajectories, perform\nrollouts both forward and backward in time and even speed up or slow down the\nlearned dynamics. We demonstrate how a simple modification of the network\narchitecture turns HGN into a powerful normalising flow model, called Neural\nHamiltonian Flow (NHF), that uses Hamiltonian dynamics to model expressive\ndensities. We hope that our work serves as a first practical demonstration of\nthe value that the Hamiltonian formalism can bring to deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 15:32:52 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 12:00:47 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Toth", "Peter", ""], ["Rezende", "Danilo Jimenez", ""], ["Jaegle", "Andrew", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Botev", "Aleksandar", ""], ["Higgins", "Irina", ""]]}, {"id": "1909.13806", "submitter": "Sijia Liu", "authors": "Sijia Liu, Songtao Lu, Xiangyi Chen, Yao Feng, Kaidi Xu, Abdullah\n  Al-Dujaili, Minyi Hong, Una-May O'Reilly", "title": "Min-Max Optimization without Gradients: Convergence and Applications to\n  Adversarial ML", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of constrained robust (min-max)\noptimization ina black-box setting, where the desired optimizer cannot access\nthe gradients of the objective function but may query its values. We present a\nprincipled optimization framework, integrating a zeroth-order (ZO) gradient\nestimator with an alternating projected stochastic gradient descent-ascent\nmethod, where the former only requires a small number of function queries and\nthe later needs just one-step descent/ascent update. We show that the proposed\nframework, referred to as ZO-Min-Max, has a sub-linear convergence rate under\nmild conditions and scales gracefully with problem size. From an application\nside, we explore a promising connection between black-box min-max optimization\nand black-box evasion and poisoning attacks in adversarial machine learning\n(ML). Our empirical evaluations on these use cases demonstrate the\neffectiveness of our approach and its scalability to dimensions that prohibit\nusing recent black-box solvers.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 16:02:49 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 01:49:54 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 01:41:35 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Liu", "Sijia", ""], ["Lu", "Songtao", ""], ["Chen", "Xiangyi", ""], ["Feng", "Yao", ""], ["Xu", "Kaidi", ""], ["Al-Dujaili", "Abdullah", ""], ["Hong", "Minyi", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1909.13827", "submitter": "Zhecheng An", "authors": "Zhecheng An, Sicong Liu", "title": "Towards Diverse Paraphrase Generation Using Multi-Class Wasserstein GAN", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrase generation is an important and challenging natural language\nprocessing (NLP) task. In this work, we propose a deep generative model to\ngenerate paraphrase with diversity. Our model is based on an encoder-decoder\narchitecture. An additional transcoder is used to convert a sentence into its\nparaphrasing latent code. The transcoder takes an explicit pattern embedding\nvariable as condition, so diverse paraphrase can be generated by sampling on\nthe pattern embedding variable. We use a Wasserstein GAN to align the\ndistributions of the real and generated paraphrase samples. We propose a\nmulti-class extension to the Wasserstein GAN, which allows our generative model\nto learn from both positive and negative samples. The generated paraphrase\ndistribution is forced to get closer to the positive real distribution, and be\npushed away from the negative distribution in Wasserstein distance. We test our\nmodel in two datasets with both automatic metrics and human evaluation. Results\nshow that our model can generate fluent and reliable paraphrase samples that\noutperform the state-of-art results, while also provides reasonable variability\nand diversity.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 16:40:15 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["An", "Zhecheng", ""], ["Liu", "Sicong", ""]]}, {"id": "1909.13833", "submitter": "Rob Cornish", "authors": "Rob Cornish, Anthony L. Caterini, George Deligiannidis, Arnaud Doucet", "title": "Relaxing Bijectivity Constraints with Continuously Indexed Normalising\n  Flows", "comments": "Minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that normalising flows become pathological when used to model targets\nwhose supports have complicated topologies. In this scenario, we prove that a\nflow must become arbitrarily numerically noninvertible in order to approximate\nthe target closely. This result has implications for all flow-based models, and\nespecially Residual Flows (ResFlows), which explicitly control the Lipschitz\nconstant of the bijection used. To address this, we propose Continuously\nIndexed Flows (CIFs), which replace the single bijection used by normalising\nflows with a continuously indexed family of bijections, and which can\nintuitively \"clean up\" mass that would otherwise be misplaced by a single\nbijection. We show theoretically that CIFs are not subject to the same\ntopological limitations as normalising flows, and obtain better empirical\nperformance on a variety of models and benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 16:51:48 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 18:25:10 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 15:20:23 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 16:54:30 GMT"}, {"version": "v5", "created": "Fri, 23 Apr 2021 17:48:10 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Cornish", "Rob", ""], ["Caterini", "Anthony L.", ""], ["Deligiannidis", "George", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1909.13834", "submitter": "Wen Zhang", "authors": "Wen Zhang and Yalin Wang", "title": "Geometric Brain Surface Network For Brain Cortical Parcellation", "comments": "8 pages", "journal-ref": "GLMI in Conjunction with MICCAI 2019", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A large number of surface-based analyses on brain imaging data adopt some\nspecific brain atlases to better assess structural and functional changes in\none or more brain regions. In these analyses, it is necessary to obtain an\nanatomically correct surface parcellation scheme in an individual brain by\nreferring to the given atlas. Traditional ways to accomplish this goal are\nthrough a designed surface-based registration or hand-crafted surface features,\nalthough both of them are time-consuming. A recent deep learning approach\ndepends on a regular spherical parameterization of the mesh, which is\ncomputationally prohibitive in some cases and may also demand further\npost-processing to refine the network output. Therefore, an accurate and\nfully-automatic cortical surface parcellation scheme directly working on the\noriginal brain surfaces would be highly advantageous. In this study, we propose\nan end-to-end deep brain cortical parcellation network, called \\textbf{DBPN}.\nThrough intrinsic and extrinsic graph convolution kernels, DBPN dynamically\ndeciphers neighborhood graph topology around each vertex and encodes the\ndeciphered knowledge into node features. Eventually, a non-linear mapping\nbetween the node features and parcellation labels is constructed. Our model is\na two-stage deep network which contains a coarse parcellation network with a\nU-shape structure and a refinement network to fine-tune the coarse results. We\nevaluate our model in a large public dataset and our work achieves superior\nperformance than state-of-the-art baseline methods in both accuracy and\nefficiency\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 03:36:05 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Zhang", "Wen", ""], ["Wang", "Yalin", ""]]}, {"id": "1909.13839", "submitter": "Sami Alabed", "authors": "Sami Alabed", "title": "RLCache: Automated Cache Management Using Reinforcement Learning", "comments": "MPhil Thesis, 76 pages, Reinforcement Learning, Multi-agent,\n  multi-task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the use of reinforcement learning to guide a general\npurpose cache manager decisions. Cache managers directly impact the overall\nperformance of computer systems. They govern decisions about which objects\nshould be cached, the duration they should be cached for, and decides on which\nobjects to evict from the cache if it is full. These three decisions impact\nboth the cache hit rate and size of the storage that is needed to achieve that\ncache hit rate. An optimal cache manager will avoid unnecessary operations,\nmaximise the cache hit rate which results in fewer round trips to a slower\nbackend storage system, and minimise the size of storage needed to achieve a\nhigh hit-rate.\n  This project investigates using reinforcement learning in cache management by\ndesigning three separate agents for each of the cache manager tasks.\nFurthermore, the project investigates two advanced reinforcement learning\narchitectures for multi-decision problems: a single multi-task agent and a\nmulti-agent. We also introduce a framework to simplify the modelling of\ncomputer systems problems as a reinforcement learning task. The framework\nabstracts delayed experiences observations and reward assignment in computer\nsystems while providing a flexible way to scale to multiple agents.\n  Simulation results based on an established database benchmark system show\nthat reinforcement learning agents can achieve a higher cache hit rate over\nheuristic driven algorithms while minimising the needed space. They are also\nable to adapt to a changing workload and dynamically adjust their caching\nstrategy accordingly. The proposed cache manager model is generic and\napplicable to other types of caches, such as file system caches. This project\nis the first, to our knowledge, to model cache manager decisions as a\nmulti-task control problem.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:03:51 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Alabed", "Sami", ""]]}, {"id": "1909.13844", "submitter": "Thomas Elsken", "authors": "Christoph Schorn, Thomas Elsken, Sebastian Vogel, Armin Runge, Andre\n  Guntoro, Gerd Ascheid", "title": "Automated design of error-resilient and hardware-efficient deep neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying deep neural networks (DNNs) in mobile and safety-critical systems,\nsuch as autonomous vehicles, demands a reliable and efficient execution on\nhardware. Optimized dedicated hardware accelerators are being developed to\nachieve this. However, the design of efficient and reliable hardware has become\nincreasingly difficult, due to the increased complexity of modern integrated\ncircuit technology and its sensitivity against hardware faults, such as random\nbit-flips. It is thus desirable to exploit optimization potential for error\nresilience and efficiency also at the algorithmic side, e.g., by optimizing the\narchitecture of the DNN. Since there are numerous design choices for the\narchitecture of DNNs, with partially opposing effects on the preferred\ncharacteristics (such as small error rates at low latency), multi-objective\noptimization strategies are necessary. In this paper, we develop an\nevolutionary optimization technique for the automated design of\nhardware-optimized DNN architectures. For this purpose, we derive a set of\neasily computable objective functions, which enable the fast evaluation of DNN\narchitectures with respect to their hardware efficiency and error resilience\nsolely based on the network topology. We observe a strong correlation between\npredicted error resilience and actual measurements obtained from fault\ninjection simulations. Furthermore, we analyze two different quantization\nschemes for efficient DNN computation and find significant differences\nregarding their effect on error resilience.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:08:22 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Schorn", "Christoph", ""], ["Elsken", "Thomas", ""], ["Vogel", "Sebastian", ""], ["Runge", "Armin", ""], ["Guntoro", "Andre", ""], ["Ascheid", "Gerd", ""]]}, {"id": "1909.13846", "submitter": "Maximilian Baader", "authors": "Maximilian Baader, Matthew Mirman, Martin Vechev", "title": "Universal Approximation with Certified Networks", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks to be certifiably robust is critical to ensure their\nsafety against adversarial attacks. However, it is currently very difficult to\ntrain a neural network that is both accurate and certifiably robust. In this\nwork we take a step towards addressing this challenge. We prove that for every\ncontinuous function $f$, there exists a network $n$ such that: (i) $n$\napproximates $f$ arbitrarily close, and (ii) simple interval bound propagation\nof a region $B$ through $n$ yields a result that is arbitrarily close to the\noptimal output of $f$ on $B$. Our result can be seen as a Universal\nApproximation Theorem for interval-certified ReLU networks. To the best of our\nknowledge, this is the first work to prove the existence of accurate,\ninterval-certified networks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:11:23 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 19:14:37 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Baader", "Maximilian", ""], ["Mirman", "Matthew", ""], ["Vechev", "Martin", ""]]}, {"id": "1909.13857", "submitter": "Anit Kumar Sahu", "authors": "Satya Narayan Shukla, Anit Kumar Sahu, Devin Willmott, J. Zico Kolter", "title": "Black-box Adversarial Attacks with Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of black-box adversarial attacks, where the aim is to\ngenerate adversarial examples using information limited to loss function\nevaluations of input-output pairs. We use Bayesian optimization~(BO) to\nspecifically cater to scenarios involving low query budgets to develop query\nefficient adversarial attacks. We alleviate the issues surrounding BO in\nregards to optimizing high dimensional deep learning models by effective\ndimension upsampling techniques. Our proposed approach achieves performance\ncomparable to the state of the art black-box adversarial attacks albeit with a\nmuch lower average query count. In particular, in low query budget regimes, our\nproposed method reduces the query count up to $80\\%$ with respect to the state\nof the art methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:35:02 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Shukla", "Satya Narayan", ""], ["Sahu", "Anit Kumar", ""], ["Willmott", "Devin", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1909.13861", "submitter": "Jonathan Schneider", "authors": "Yuan Deng, Jon Schneider, Balusubramanian Sivan", "title": "Strategizing against No-regret Learners", "comments": "11 pages. NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How should a player who repeatedly plays a game against a no-regret learner\nstrategize to maximize his utility? We study this question and show that under\nsome mild assumptions, the player can always guarantee himself a utility of at\nleast what he would get in a Stackelberg equilibrium of the game. When the\nno-regret learner has only two actions, we show that the player cannot get any\nhigher utility than the Stackelberg equilibrium utility. But when the no-regret\nlearner has more than two actions and plays a mean-based no-regret strategy, we\nshow that the player can get strictly higher than the Stackelberg equilibrium\nutility. We provide a characterization of the optimal game-play for the player\nagainst a mean-based no-regret learner as a solution to a control problem. When\nthe no-regret learner's strategy also guarantees him a no-swap regret, we show\nthat the player cannot get anything higher than a Stackelberg equilibrium\nutility.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:41:56 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Deng", "Yuan", ""], ["Schneider", "Jon", ""], ["Sivan", "Balusubramanian", ""]]}, {"id": "1909.13863", "submitter": "Adrian Bulat", "authors": "Adrian Bulat and Georgios Tzimiropoulos", "title": "XNOR-Net++: Improved Binary Neural Networks", "comments": "Accepted to BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an improved training algorithm for binary neural networks\nin which both weights and activations are binary numbers. A key but fairly\noverlooked feature of the current state-of-the-art method of XNOR-Net is the\nuse of analytically calculated real-valued scaling factors for re-weighting the\noutput of binary convolutions. We argue that analytic calculation of these\nfactors is sub-optimal. Instead, in this work, we make the following\ncontributions: (a) we propose to fuse the activation and weight scaling factors\ninto a single one that is learned discriminatively via backpropagation. (b)\nMore importantly, we explore several ways of constructing the shape of the\nscale factors while keeping the computational budget fixed. (c) We empirically\nmeasure the accuracy of our approximations and show that they are significantly\nmore accurate than the analytically calculated one. (d) We show that our\napproach significantly outperforms XNOR-Net within the same computational\nbudget when tested on the challenging task of ImageNet classification, offering\nup to 6\\% accuracy gain.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:42:09 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Bulat", "Adrian", ""], ["Tzimiropoulos", "Georgios", ""]]}, {"id": "1909.13870", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Tom\\'as Lozano-P\\'erez", "title": "Learning Compact Models for Planning with Exogenous Processes", "comments": "CoRL 2019 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of approximate model minimization for MDPs in which\nthe state is partitioned into endogenous and (much larger) exogenous\ncomponents. An exogenous state variable is one whose dynamics are independent\nof the agent's actions. We formalize the mask-learning problem, in which the\nagent must choose a subset of exogenous state variables to reason about when\nplanning; doing planning in such a reduced state space can often be\nsignificantly more efficient than planning in the full model. We then explore\nthe various value functions at play within this setting, and describe\nconditions under which a policy for a reduced model will be optimal for the\nfull MDP. The analysis leads us to a tractable approximate algorithm that draws\nupon the notion of mutual information among exogenous state variables. We\nvalidate our approach in simulated robotic manipulation domains where a robot\nis placed in a busy environment, in which there are many other agents also\ninteracting with the objects. Visit http://tinyurl.com/chitnis-exogenous for a\nsupplementary video.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:51:12 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Chitnis", "Rohan", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""]]}, {"id": "1909.13874", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Shubham Tulsiani, Saurabh Gupta, Abhinav Gupta", "title": "Efficient Bimanual Manipulation Using Learned Task Schemas", "comments": "ICRA 2020 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of effectively composing skills to solve sparse-reward\ntasks in the real world. Given a set of parameterized skills (such as exerting\na force or doing a top grasp at a location), our goal is to learn policies that\ninvoke these skills to efficiently solve such tasks. Our insight is that for\nmany tasks, the learning process can be decomposed into learning a\nstate-independent task schema (a sequence of skills to execute) and a policy to\nchoose the parameterizations of the skills in a state-dependent manner. For\nsuch tasks, we show that explicitly modeling the schema's state-independence\ncan yield significant improvements in sample efficiency for model-free\nreinforcement learning algorithms. Furthermore, these schemas can be\ntransferred to solve related tasks, by simply re-learning the parameterizations\nwith which the skills are invoked. We find that doing so enables learning to\nsolve sparse-reward tasks on real-world robotic systems very efficiently. We\nvalidate our approach experimentally over a suite of robotic bimanual\nmanipulation tasks, both in simulation and on real hardware. See videos at\nhttp://tinyurl.com/chitnis-schema.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:55:09 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 16:58:56 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Chitnis", "Rohan", ""], ["Tulsiani", "Shubham", ""], ["Gupta", "Saurabh", ""], ["Gupta", "Abhinav", ""]]}]