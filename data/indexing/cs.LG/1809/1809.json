[{"id": "1809.00065", "submitter": "Siwakorn Srisakaokul", "authors": "Siwakorn Srisakaokul, Yuhao Zhang, Zexuan Zhong, Wei Yang, Tao Xie, Bo\n  Li", "title": "MULDEF: Multi-model-based Defense Against Adversarial Examples for\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being popularly used in many applications, neural network models have\nbeen found to be vulnerable to adversarial examples, i.e., carefully crafted\nexamples aiming to mislead machine learning models. Adversarial examples can\npose potential risks on safety and security critical applications. However,\nexisting defense approaches are still vulnerable to attacks, especially in a\nwhite-box attack scenario. To address this issue, we propose a new defense\napproach, named MulDef, based on robustness diversity. Our approach consists of\n(1) a general defense framework based on multiple models and (2) a technique\nfor generating these multiple models to achieve high defense capability. In\nparticular, given a target model, our framework includes multiple models\n(constructed from the target model) to form a model family. The model family is\ndesigned to achieve robustness diversity (i.e., an adversarial example\nsuccessfully attacking one model cannot succeed in attacking other models in\nthe family). At runtime, a model is randomly selected from the family to be\napplied on each input example. Our general framework can inspire rich future\nresearch to construct a desirable model family achieving higher robustness\ndiversity. Our evaluation results show that MulDef (with only up to 5 models in\nthe family) can substantially improve the target model's accuracy on\nadversarial examples by 22-74% in a white-box attack scenario, while\nmaintaining similar accuracy on legitimate examples.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 21:22:52 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 01:37:19 GMT"}, {"version": "v3", "created": "Sat, 27 Jul 2019 03:53:19 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Srisakaokul", "Siwakorn", ""], ["Zhang", "Yuhao", ""], ["Zhong", "Zexuan", ""], ["Yang", "Wei", ""], ["Xie", "Tao", ""], ["Li", "Bo", ""]]}, {"id": "1809.00068", "submitter": "Wei Wang", "authors": "Wei Wang and Taro Watanabe and Macduff Hughes and Tetsuji Nakagawa and\n  Ciprian Chelba", "title": "Denoising Neural Machine Translation Training with Trusted Data and\n  Online Data Selection", "comments": "11 pages, 2018 Third Conference on Machine Translation (WMT18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring domain relevance of data and identifying or selecting well-fit\ndomain data for machine translation (MT) is a well-studied topic, but denoising\nis not yet. Denoising is concerned with a different type of data quality and\ntries to reduce the negative impact of data noise on MT training, in\nparticular, neural MT (NMT) training. This paper generalizes methods for\nmeasuring and selecting data for domain MT and applies them to denoising NMT\ntraining. The proposed approach uses trusted data and a denoising curriculum\nrealized by online data selection. Intrinsic and extrinsic evaluations of the\napproach show its significant effectiveness for NMT to train on data with\nsevere noise.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 22:01:45 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Wang", "Wei", ""], ["Watanabe", "Taro", ""], ["Hughes", "Macduff", ""], ["Nakagawa", "Tetsuji", ""], ["Chelba", "Ciprian", ""]]}, {"id": "1809.00072", "submitter": "Shubham Jain", "authors": "Shubham Jain, Abhronil Sengupta, Kaushik Roy, Anand Raghunathan", "title": "RxNN: A Framework for Evaluating Deep Neural Networks on Resistive\n  Crossbars", "comments": "13 pages, 16 figures, Accepted in IEEE Transactions on Computer-Aided\n  Design of Integrated Circuits and Systems (TCAD) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resistive crossbars designed with non-volatile memory devices have emerged as\npromising building blocks for Deep Neural Network (DNN) hardware, due to their\nability to compactly and efficiently realize vector-matrix multiplication\n(VMM), the dominant computational kernel in DNNs. However, a key challenge with\nresistive crossbars is that they suffer from a range of device and circuit\nlevel non-idealities such as interconnect parasitics, peripheral circuits,\nsneak paths, and process variations. These non-idealities can lead to errors in\nVMMs, eventually degrading the DNN's accuracy. It is therefore critical to\nstudy the impact of crossbar non-idealities on the accuracy of large-scale\nDNNs. However, this is challenging because existing device and circuit models\nare too slow to use in application-level evaluations.\n  We present RxNN, a fast and accurate simulation framework to evaluate\nlarge-scale DNNs on resistive crossbar systems. RxNN splits and maps the\ncomputations involved in each DNN layer into crossbar operations, and evaluates\nthem using a Fast Crossbar Model (FCM) that accurately captures the errors\narising due to crossbar non-idealities while being four-to-five orders of\nmagnitude faster than circuit simulation. FCM models a crossbar-based VMM\noperation using three stages - non-linear models for the input and output\nperipheral circuits (DACs and ADCs), and an equivalent non-ideal conductance\nmatrix for the core crossbar array. We implement RxNN by extending the Caffe\nmachine learning framework and use it to evaluate a suite of six large-scale\nDNNs developed for the ImageNet Challenge. Our experiments reveal that\nresistive crossbar non-idealities can lead to significant accuracy degradations\n(9.6%-32%) for these large-scale DNNs. To the best of our knowledge, this work\nis the first quantitative evaluation of the accuracy of large-scale DNNs on\nresistive crossbar based hardware.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 22:22:53 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 15:20:13 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 03:33:11 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Jain", "Shubham", ""], ["Sengupta", "Abhronil", ""], ["Roy", "Kaushik", ""], ["Raghunathan", "Anand", ""]]}, {"id": "1809.00082", "submitter": "Anastasis Kratsios", "authors": "Anastasis Kratsios and Cody Hyndman", "title": "NEU: A Meta-Algorithm for Universal UAP-Invariant Feature Representation", "comments": "28 pages: main body, 24 pages: appendix, 8 Figures, 11 Tables", "journal-ref": "Journal of Machine Learning Research (JMLR), Volume: 22; 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective feature representation is key to the predictive performance of any\nalgorithm. This paper introduces a meta-procedure, called Non-Euclidean\nUpgrading (NEU), which learns feature maps that are expressive enough to embed\nthe universal approximation property (UAP) into most model classes while only\noutputting feature maps that preserve any model class's UAP. We show that NEU\ncan learn any feature map with these two properties if that feature map is\nasymptotically deformable into the identity. We also find that the\nfeature-representations learned by NEU are always submanifolds of the feature\nspace. NEU's properties are derived from a new deep neural model that is\nuniversal amongst all orientation-preserving homeomorphisms on the input space.\nWe derive qualitative and quantitative approximation guarantees for this\narchitecture. We quantify the number of parameters required for this new\narchitecture to memorize any set of input-output pairs while simultaneously\nfixing every point of the input space lying outside some compact set, and we\nquantify the size of this set as a function of our model's depth. Moreover, we\nshow that no deep feed-forward network with commonly used activation function\nhas all these properties. NEU's performance is evaluated against competing\nmachine learning methods on various regression and dimension reduction tasks\nboth with financial and simulated data.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 23:38:00 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 16:43:31 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 12:23:47 GMT"}, {"version": "v4", "created": "Mon, 10 May 2021 09:50:03 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Kratsios", "Anastasis", ""], ["Hyndman", "Cody", ""]]}, {"id": "1809.00083", "submitter": "Haicang Zhang", "authors": "Haicang Zhang, Qi Zhang, Fusong Ju, Jianwei Zhu, Shiwei Sun, Yujuan\n  Gao, Ziwei Xie, Minghua Deng, Shiwei Sun, Wei-Mou Zheng, Dongbo Bu", "title": "Predicting protein inter-residue contacts using composite likelihood\n  maximization and deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of inter-residue contacts of a protein is important to\ncalcu- lating its tertiary structure. Analysis of co-evolutionary events among\nresidues has been proved effective to inferring inter-residue contacts. The\nMarkov ran- dom field (MRF) technique, although being widely used for contact\nprediction, suffers from the following dilemma: the actual likelihood function\nof MRF is accurate but time-consuming to calculate, in contrast, approximations\nto the actual likelihood, say pseudo-likelihood, are efficient to calculate but\ninaccu- rate. Thus, how to achieve both accuracy and efficiency simultaneously\nremains a challenge. In this study, we present such an approach (called clmDCA)\nfor contact prediction. Unlike plmDCA using pseudo-likelihood, i.e., the\nproduct of conditional probability of individual residues, our approach uses\ncomposite- likelihood, i.e., the product of conditional probability of all\nresidue pairs. Com- posite likelihood has been theoretically proved as a better\napproximation to the actual likelihood function than pseudo-likelihood.\nMeanwhile, composite likelihood is still efficient to maximize, thus ensuring\nthe efficiency of clmDCA. We present comprehensive experiments on popular\nbenchmark datasets, includ- ing PSICOV dataset and CASP-11 dataset, to show\nthat: i) clmDCA alone outperforms the existing MRF-based approaches in\nprediction accuracy. ii) When equipped with deep learning technique for\nrefinement, the prediction ac- curacy of clmDCA was further significantly\nimproved, suggesting the suitability of clmDCA for subsequent refinement\nprocedure. We further present successful application of the predicted contacts\nto accurately build tertiary structures for proteins in the PSICOV dataset.\n  Accessibility: The software clmDCA and a server are publicly accessible\nthrough http://protein.ict.ac.cn/clmDCA/.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 23:38:41 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Zhang", "Haicang", ""], ["Zhang", "Qi", ""], ["Ju", "Fusong", ""], ["Zhu", "Jianwei", ""], ["Sun", "Shiwei", ""], ["Gao", "Yujuan", ""], ["Xie", "Ziwei", ""], ["Deng", "Minghua", ""], ["Sun", "Shiwei", ""], ["Zheng", "Wei-Mou", ""], ["Bu", "Dongbo", ""]]}, {"id": "1809.00095", "submitter": "Yoojin Choi", "authors": "Yoojin Choi, Mostafa El-Khamy, Jungwon Lee", "title": "Learning Sparse Low-Precision Neural Networks With Learnable\n  Regularization", "comments": "IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2996936", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning deep neural networks (DNNs) that consist of\nlow-precision weights and activations for efficient inference of fixed-point\noperations. In training low-precision networks, gradient descent in the\nbackward pass is performed with high-precision weights while quantized\nlow-precision weights and activations are used in the forward pass to calculate\nthe loss function for training. Thus, the gradient descent becomes suboptimal,\nand accuracy loss follows. In order to reduce the mismatch in the forward and\nbackward passes, we utilize mean squared quantization error (MSQE)\nregularization. In particular, we propose using a learnable regularization\ncoefficient with the MSQE regularizer to reinforce the convergence of\nhigh-precision weights to their quantized values. We also investigate how\npartial L2 regularization can be employed for weight pruning in a similar\nmanner. Finally, combining weight pruning, quantization, and entropy coding, we\nestablish a low-precision DNN compression pipeline. In our experiments, the\nproposed method yields low-precision MobileNet and ShuffleNet models on\nImageNet classification with the state-of-the-art compression ratios of 7.13\nand 6.79, respectively. Moreover, we examine our method for image super\nresolution networks to produce 8-bit low-precision models at negligible\nperformance loss.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 01:28:21 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 00:41:54 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Choi", "Yoojin", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "1809.00101", "submitter": "Lingbo Liu", "authors": "Lingbo Liu, Ruimao Zhang, Jiefeng Peng, Guanbin Li, Bowen Du, and\n  Liang Lin", "title": "Attentive Crowd Flow Machines", "comments": "ACM MM, full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic flow prediction is crucial for urban traffic management and public\nsafety. Its key challenges lie in how to adaptively integrate the various\nfactors that affect the flow changes. In this paper, we propose a unified\nneural network module to address this problem, called Attentive Crowd Flow\nMachine~(ACFM), which is able to infer the evolution of the crowd flow by\nlearning dynamic representations of temporally-varying data with an attention\nmechanism. Specifically, the ACFM is composed of two progressive ConvLSTM units\nconnected with a convolutional layer for spatial weight prediction. The first\nLSTM takes the sequential flow density representation as input and generates a\nhidden state at each time-step for attention map inference, while the second\nLSTM aims at learning the effective spatial-temporal feature expression from\nattentionally weighted crowd flow features. Based on the ACFM, we further build\na deep architecture with the application to citywide crowd flow prediction,\nwhich naturally incorporates the sequential and periodic data as well as other\nexternal influences. Extensive experiments on two standard benchmarks (i.e.,\ncrowd flow in Beijing and New York City) show that the proposed method achieves\nsignificant improvements over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 02:22:57 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Liu", "Lingbo", ""], ["Zhang", "Ruimao", ""], ["Peng", "Jiefeng", ""], ["Li", "Guanbin", ""], ["Du", "Bowen", ""], ["Lin", "Liang", ""]]}, {"id": "1809.00175", "submitter": "Kelvin Hsu", "authors": "Kelvin Hsu, Richard Nock, Fabio Ramos", "title": "Hyperparameter Learning for Conditional Kernel Mean Embeddings with\n  Rademacher Complexity Bounds", "comments": "Best Student Machine Learning Paper Award Winner at ECML-PKDD 2018\n  (European Conference on Machine Learning and Principles and Practice of\n  Knowledge Discovery in Databases)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional kernel mean embeddings are nonparametric models that encode\nconditional expectations in a reproducing kernel Hilbert space. While they\nprovide a flexible and powerful framework for probabilistic inference, their\nperformance is highly dependent on the choice of kernel and regularization\nhyperparameters. Nevertheless, current hyperparameter tuning methods\npredominantly rely on expensive cross validation or heuristics that is not\noptimized for the inference task. For conditional kernel mean embeddings with\ncategorical targets and arbitrary inputs, we propose a hyperparameter learning\nframework based on Rademacher complexity bounds to prevent overfitting by\nbalancing data fit against model complexity. Our approach only requires batch\nupdates, allowing scalable kernel hyperparameter tuning without invoking kernel\napproximations. Experiments demonstrate that our learning framework outperforms\ncompeting methods, and can be further extended to incorporate and learn deep\nneural network weights to improve generalization.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 13:33:31 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 21:08:09 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 04:29:37 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Hsu", "Kelvin", ""], ["Nock", "Richard", ""], ["Ramos", "Fabio", ""]]}, {"id": "1809.00224", "submitter": "Jack Parry", "authors": "Jack Parry", "title": "Finding the Answers with Definition Models", "comments": "MSc Dissertation, University of Edinburgh, <10,000 words", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by a previous attempt to answer crossword questions using neural\nnetworks (Hill, Cho, Korhonen, & Bengio, 2015), this dissertation implements\nextensions to improve the performance of this existing definition model on the\ntask of answering crossword questions. A discussion and evaluation of the\noriginal implementation finds that there are some ways in which the recurrent\nneural model could be extended. Insights from related fields neural language\nmodeling and neural machine translation provide the justification and means\nrequired for these extensions. Two extensions are applied to the LSTM encoder,\nfirst taking the average of LSTM states across the sequence and secondly using\na bidirectional LSTM, both implementations serve to improve model performance\non a definitions and crossword test set. In order to improve performance on\ncrossword questions, the training data is increased to include crossword\nquestions and answers, and this serves to improve results on definitions as\nwell as crossword questions. The final experiments are conducted using sub-word\nunit segmentation, first on the source side and then later preliminary\nexperimentation is conducted to facilitate character-level output. Initially,\nan exact reproduction of the baseline results proves unsuccessful. Despite\nthis, the extensions improve performance, allowing the definition model to\nsurpass the performance of the recurrent neural network variants of the\nprevious work (Hill, et al., 2015).\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 17:21:01 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Parry", "Jack", ""]]}, {"id": "1809.00233", "submitter": "Ahmet Sayar", "authors": "Serife Acikalin, Suleyman Eken, Ahmet Sayar", "title": "Sleep Stage Classification: Scalability Evaluations of Distributed\n  Approaches", "comments": "Proceedings of The Third International Conference on Data Mining,\n  Internet Computing, and Big Data, Konya, Turkey 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing and analyzing of massive clinical data are resource intensive and\ntime consuming with traditional analytic tools. Electroencephalogram (EEG) is\none of the major technologies in detecting and diagnosing various brain\ndisorders, and produces huge volume big data to process. In this study, we\npropose a big data framework to diagnose sleep disorders by classifying the\nsleep stages from EEG signals. The framework is developed with open source\nSparkMlib Libraries. We also tested and evaluated the proposed framework by\nmeasuring the scalabilities of well-known classification algorithms on\nphysionet sleep records.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 18:39:57 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Acikalin", "Serife", ""], ["Eken", "Suleyman", ""], ["Sayar", "Ahmet", ""]]}, {"id": "1809.00238", "submitter": "Sabri Pllana", "authors": "Yasser Alsouda, Sabri Pllana, Arianit Kurti", "title": "A Machine Learning Driven IoT Solution for Noise Classification in Smart\n  Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine learning based method for noise classification using a\nlow-power and inexpensive IoT unit. We use Mel-frequency cepstral coefficients\nfor audio feature extraction and supervised classification algorithms (that is,\nsupport vector machine and k-nearest neighbors) for noise classification. We\nevaluate our approach experimentally with a dataset of about 3000 sound samples\ngrouped in eight sound classes (such as, car horn, jackhammer, or street\nmusic). We explore the parameter space of support vector machine and k-nearest\nneighbors algorithms to estimate the optimal parameter values for\nclassification of sound samples in the dataset under study. We achieve a noise\nclassification accuracy in the range 85% -- 100%. Training and testing of our\nk-nearest neighbors (k = 1) implementation on Raspberry Pi Zero W is less than\na second for a dataset with features of more than 3000 sound samples.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 19:11:53 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Alsouda", "Yasser", ""], ["Pllana", "Sabri", ""], ["Kurti", "Arianit", ""]]}, {"id": "1809.00241", "submitter": "Ankit Parag Shah", "authors": "Ankit Shah, Harini Kesavamoorthy, Poorva Rane, Pramati Kalwad,\n  Alexander Hauptmann, Florian Metze", "title": "Activity Recognition on a Large Scale in Short Videos - Moments in Time\n  Dataset", "comments": "Action recognition submission for Moments in Time Dataset - Improved\n  results over challenge submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Moments capture a huge part of our lives. Accurate recognition of these\nmoments is challenging due to the diverse and complex interpretation of the\nmoments. Action recognition refers to the act of classifying the desired\naction/activity present in a given video. In this work, we perform experiments\non Moments in Time dataset to recognize accurately activities occurring in 3\nsecond clips. We use state of the art techniques for visual, auditory and\nspatio temporal localization and develop method to accurately classify the\nactivity in the Moments in Time dataset. Our novel approach of using Visual\nBased Textual features and fusion techniques performs well providing an overall\n89.23 % Top - 5 accuracy on the 20 classes - a significant improvement over the\nBaseline TRN model.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 19:39:06 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 15:37:34 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Shah", "Ankit", ""], ["Kesavamoorthy", "Harini", ""], ["Rane", "Poorva", ""], ["Kalwad", "Pramati", ""], ["Hauptmann", "Alexander", ""], ["Metze", "Florian", ""]]}, {"id": "1809.00251", "submitter": "Adrian Viera", "authors": "Leonardo Le\\'on, Felipe Moreno-Vera, Renato Castro, Jos\\'e Nav\\'io,\n  Marco Capcha", "title": "Car Monitoring System in Apartment Garages by Small Autonomous Car using\n  Deep Learning", "comments": "13 pages, 12 figures, Version 1 accepted in SimBig 2018. Improving to\n  get better results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Currently, there is an increase in the number of Peruvian families living in\napartments instead of houses for the lots of advantage; However, in some cases\nthere are troubles such as robberies of goods that are usually left at the\nparking lots or the entrance of strangers that use the tenants parking lots\n(this last trouble sometimes is related to kidnappings or robberies in building\napartments). Due to these problems, the use of a self-driving mini-car is\nproposed to implement a monitoring system of license plates in an underground\ngarage inside a building using a deep learning model with the aim of recording\nthe vehicles and identifying their owners if they were tenants or not. In\naddition, the small robot has its own location system using beacons that allow\nus to identify the position of the parking lot corresponding to each tenant of\nthe building while the mini-car is on its way. Finally, one of the objectives\nof this work is to build a low-cost mini-robot that would replace expensive\ncameras or work together in order to keep safe the goods of tenants.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 21:00:58 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 01:00:32 GMT"}, {"version": "v3", "created": "Sat, 14 Sep 2019 21:40:42 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Le\u00f3n", "Leonardo", ""], ["Moreno-Vera", "Felipe", ""], ["Castro", "Renato", ""], ["Nav\u00edo", "Jos\u00e9", ""], ["Capcha", "Marco", ""]]}, {"id": "1809.00252", "submitter": "Devendra Singh Sachan", "authors": "Devendra Singh Sachan and Graham Neubig", "title": "Parameter Sharing Methods for Multilingual Self-Attentional Translation\n  Models", "comments": "Third Conference on Machine Translation (WMT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multilingual neural machine translation, it has been shown that sharing a\nsingle translation model between multiple languages can achieve competitive\nperformance, sometimes even leading to performance gains over bilingually\ntrained models. However, these improvements are not uniform; often multilingual\nparameter sharing results in a decrease in accuracy due to translation models\nnot being able to accommodate different languages in their limited parameter\nspace. In this work, we examine parameter sharing techniques that strike a\nhappy medium between full sharing and individual training, specifically\nfocusing on the self-attentional Transformer model. We find that the full\nparameter sharing approach leads to increases in BLEU scores mainly when the\ntarget languages are from a similar language family. However, even in the case\nwhere target languages are from different families where full parameter sharing\nleads to a noticeable drop in BLEU scores, our proposed methods for partial\nsharing of parameters can lead to substantial improvements in translation\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 21:12:09 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 08:34:40 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Sachan", "Devendra Singh", ""], ["Neubig", "Graham", ""]]}, {"id": "1809.00263", "submitter": "Qiangeng Xu", "authors": "Qiangeng Xu, Hanwang Zhang, Weiyue Wang, Peter N. Belhumeur, Ulrich\n  Neumann", "title": "Stochastic Dynamics for Video Infilling", "comments": "Winter Conference on Applications of Computer Vision (WACV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a stochastic dynamics video infilling (SDVI)\nframework to generate frames between long intervals in a video. Our task\ndiffers from video interpolation which aims to produce transitional frames for\na short interval between every two frames and increase the temporal resolution.\nOur task, namely video infilling, however, aims to infill long intervals with\nplausible frame sequences. Our framework models the infilling as a constrained\nstochastic generation process and sequentially samples dynamics from the\ninferred distribution. SDVI consists of two parts: (1) a bi-directional\nconstraint propagation module to guarantee the spatial-temporal coherence among\nframes, (2) a stochastic sampling process to generate dynamics from the\ninferred distributions. Experimental results show that SDVI can generate clear\nframe sequences with varying contents. Moreover, motions in the generated\nsequence are realistic and able to transfer smoothly from the given start frame\nto the terminal frame. Our project site is\nhttps://xharlie.github.io/projects/project_sites/SDVI/video_results.html\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 22:58:49 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 03:25:49 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 04:56:46 GMT"}, {"version": "v4", "created": "Thu, 6 Jun 2019 02:24:44 GMT"}, {"version": "v5", "created": "Fri, 7 Jun 2019 09:13:07 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Xu", "Qiangeng", ""], ["Zhang", "Hanwang", ""], ["Wang", "Weiyue", ""], ["Belhumeur", "Peter N.", ""], ["Neumann", "Ulrich", ""]]}, {"id": "1809.00306", "submitter": "Xi Zhang", "authors": "Xi Zhang and Yixuan Li and Senzhang Wang and Binxing Fang and Philip\n  S. Yu", "title": "Enhancing Stock Market Prediction with Extended Coupled Hidden Markov\n  Model over Multi-Sourced Data", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional stock market prediction methods commonly only utilize the\nhistorical trading data, ignoring the fact that stock market fluctuations can\nbe impacted by various other information sources such as stock related events.\nAlthough some recent works propose event-driven prediction approaches by\nconsidering the event data, how to leverage the joint impacts of multiple data\nsources still remains an open research problem. In this work, we study how to\nexplore multiple data sources to improve the performance of the stock\nprediction. We introduce an Extended Coupled Hidden Markov Model incorporating\nthe news events with the historical trading data. To address the data sparsity\nissue of news events for each single stock, we further study the fluctuation\ncorrelations between the stocks and incorporate the correlations into the model\nto facilitate the prediction task. Evaluations on China A-share market data in\n2016 show the superior performance of our model against previous methods.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 07:48:24 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Zhang", "Xi", ""], ["Li", "Yixuan", ""], ["Wang", "Senzhang", ""], ["Fang", "Binxing", ""], ["Yu", "Philip S.", ""]]}, {"id": "1809.00338", "submitter": "Jian Zhao", "authors": "Jian Zhao, Yu Cheng, Yi Cheng, Yang Yang, Haochong Lan, Fang Zhao, Lin\n  Xiong, Yan Xu, Jianshu Li, Sugiri Pranata, Shengmei Shen, Junliang Xing,\n  Hengzhu Liu, Shuicheng Yan, Jiashi Feng", "title": "Look Across Elapse: Disentangled Representation Learning and\n  Photorealistic Cross-Age Face Synthesis for Age-Invariant Face Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the remarkable progress in face recognition related technologies,\nreliably recognizing faces across ages still remains a big challenge. The\nappearance of a human face changes substantially over time, resulting in\nsignificant intra-class variations. As opposed to current techniques for\nage-invariant face recognition, which either directly extract age-invariant\nfeatures for recognition, or first synthesize a face that matches target age\nbefore feature extraction, we argue that it is more desirable to perform both\ntasks jointly so that they can leverage each other. To this end, we propose a\ndeep Age-Invariant Model (AIM) for face recognition in the wild with three\ndistinct novelties. First, AIM presents a novel unified deep architecture\njointly performing cross-age face synthesis and recognition in a mutual\nboosting way. Second, AIM achieves continuous face rejuvenation/aging with\nremarkable photorealistic and identity-preserving properties, avoiding the\nrequirement of paired data and the true age of testing samples. Third, we\ndevelop effective and novel training strategies for end-to-end learning the\nwhole deep architecture, which generates powerful age-invariant face\nrepresentations explicitly disentangled from the age variation. Moreover, we\npropose a new large-scale Cross-Age Face Recognition (CAFR) benchmark dataset\nto facilitate existing efforts and push the frontiers of age-invariant face\nrecognition research. Extensive experiments on both our CAFR and several other\ncross-age datasets (MORPH, CACD and FG-NET) demonstrate the superiority of the\nproposed AIM model over the state-of-the-arts. Benchmarking our model on one of\nthe most popular unconstrained face recognition datasets IJB-C additionally\nverifies the promising generalizability of AIM in recognizing faces in the\nwild.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 13:58:37 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 01:53:17 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Zhao", "Jian", ""], ["Cheng", "Yu", ""], ["Cheng", "Yi", ""], ["Yang", "Yang", ""], ["Lan", "Haochong", ""], ["Zhao", "Fang", ""], ["Xiong", "Lin", ""], ["Xu", "Yan", ""], ["Li", "Jianshu", ""], ["Pranata", "Sugiri", ""], ["Shen", "Shengmei", ""], ["Xing", "Junliang", ""], ["Liu", "Hengzhu", ""], ["Yan", "Shuicheng", ""], ["Feng", "Jiashi", ""]]}, {"id": "1809.00343", "submitter": "Guangxu Zhu", "authors": "Guangxu Zhu and Dongzhu Liu and Yuqing Du and Changsheng You and Jun\n  Zhang and Kaibin Huang", "title": "Towards an Intelligent Edge: Wireless Communication Meets Machine\n  Learning", "comments": "submitted to IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent revival of artificial intelligence (AI) is revolutionizing almost\nevery branch of science and technology. Given the ubiquitous smart mobile\ngadgets and Internet of Things (IoT) devices, it is expected that a majority of\nintelligent applications will be deployed at the edge of wireless networks.\nThis trend has generated strong interests in realizing an \"intelligent edge\" to\nsupport AI-enabled applications at various edge devices. Accordingly, a new\nresearch area, called edge learning, emerges, which crosses and revolutionizes\ntwo disciplines: wireless communication and machine learning. A major theme in\nedge learning is to overcome the limited computing power, as well as limited\ndata, at each edge device. This is accomplished by leveraging the mobile edge\ncomputing (MEC) platform and exploiting the massive data distributed over a\nlarge number of edge devices. In such systems, learning from distributed data\nand communicating between the edge server and devices are two critical and\ncoupled aspects, and their fusion poses many new research challenges. This\narticle advocates a new set of design principles for wireless communication in\nedge learning, collectively called learning-driven communication. Illustrative\nexamples are provided to demonstrate the effectiveness of these design\nprinciples, and unique research opportunities are identified.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 14:18:40 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Zhu", "Guangxu", ""], ["Liu", "Dongzhu", ""], ["Du", "Yuqing", ""], ["You", "Changsheng", ""], ["Zhang", "Jun", ""], ["Huang", "Kaibin", ""]]}, {"id": "1809.00366", "submitter": "David Cortes", "authors": "David Cortes", "title": "Cold-start recommendations in Collective Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the ability of collective matrix factorization models in\nrecommender systems to make predictions about users and items for which there\nis side information available but no feedback or interactions data, and\nproposes a new formulation with a faster cold-start prediction formula that can\nbe used in real-time systems. While these cold-start recommendations are not as\ngood as warm-start ones, they were found to be of better quality than\nnon-personalized recommendations, and predictions about new users were found to\nbe more reliable than those about new items. The formulation proposed here\nresulted in improved cold-start recommendations in many scenarios, at the\nexpense of worse warm-start ones.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 16:24:38 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 15:07:38 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Cortes", "David", ""]]}, {"id": "1809.00381", "submitter": "Rachel Bittner", "authors": "Rachel M. Bittner and Brian McFee and Juan P. Bello", "title": "Multitask Learning for Fundamental Frequency Estimation in Music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental frequency (f0) estimation from polyphonic music includes the\ntasks of multiple-f0, melody, vocal, and bass line estimation. Historically\nthese problems have been approached separately, and only recently, using\nlearning-based approaches. We present a multitask deep learning architecture\nthat jointly estimates outputs for various tasks including multiple-f0, melody,\nvocal and bass line estimation, and is trained using a large,\nsemi-automatically annotated dataset. We show that the multitask model\noutperforms its single-task counterparts, and explore the effect of various\ndesign decisions in our approach, and show that it performs better or at least\ncompetitively when compared against strong baseline methods.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 20:03:09 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Bittner", "Rachel M.", ""], ["McFee", "Brian", ""], ["Bello", "Juan P.", ""]]}, {"id": "1809.00397", "submitter": "Sowmya Munukutla", "authors": "Akshita Mittel, Sowmya Munukutla, Himanshi Yadav", "title": "Visual Transfer between Atari Games using Competitive Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of deep reinforcement learning agents to transfer\nknowledge from one environment to another. More specifically, the method takes\nadvantage of asynchronous advantage actor critic (A3C) architecture to\ngeneralize a target game using an agent trained on a source game in Atari.\nInstead of fine-tuning a pre-trained model for the target game, we propose a\nlearning approach to update the model using multiple agents trained in parallel\nwith different representations of the target game. Visual mapping between video\nsequences of transfer pairs is used to derive new representations of the target\ngame; training on these visual representations of the target game improves\nmodel updates in terms of performance, data efficiency and stability. In order\nto demonstrate the functionality of the architecture, Atari games Pong-v0 and\nBreakout-v0 are being used from the OpenAI gym environment; as the source and\ntarget environment.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 21:34:28 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Mittel", "Akshita", ""], ["Munukutla", "Sowmya", ""], ["Yadav", "Himanshi", ""]]}, {"id": "1809.00403", "submitter": "Gang Chen", "authors": "Gang Chen and Yiming Peng and Mengjie Zhang", "title": "Effective Exploration for Deep Reinforcement Learning via Bootstrapped\n  Q-Ensembles under Tsallis Entropy Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep reinforcement learning (DRL) has achieved outstanding success\non solving many difficult and large-scale RL problems. However the high sample\ncost required for effective learning often makes DRL unaffordable in\nresource-limited applications. With the aim of improving sample efficiency and\nlearning performance, we will develop a new DRL algorithm in this paper that\nseamless integrates entropy-induced and bootstrap-induced techniques for\nefficient and deep exploration of the learning environment. Specifically, a\ngeneral form of Tsallis entropy regularizer will be utilized to drive\nentropy-induced exploration based on efficient approximation of optimal\naction-selection policies. Different from many existing works that rely on\naction dithering strategies for exploration, our algorithm is efficient in\nexploring actions with clear exploration value. Meanwhile, by employing an\nensemble of Q-networks under varied Tsallis entropy regularization, the\ndiversity of the ensemble can be further enhanced to enable effective\nbootstrap-induced exploration. Experiments on Atari game playing tasks clearly\ndemonstrate that our new algorithm can achieve more efficient and effective\nexploration for DRL, in comparison to recently proposed exploration methods\nincluding Bootstrapped Deep Q-Network and UCB Q-Ensemble.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 22:17:52 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 01:45:01 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Chen", "Gang", ""], ["Peng", "Yiming", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1809.00410", "submitter": "Disha Shrivastava", "authors": "Disha Shrivastava, Abhijit Mishra, Karthik Sankaranarayanan", "title": "Modeling Topical Coherence in Discourse without Supervision", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coherence of text is an important attribute to be measured for both manually\nand automatically generated discourse; but well-defined quantitative metrics\nfor it are still elusive. In this paper, we present a metric for scoring\ntopical coherence of an input paragraph on a real-valued scale by analyzing its\nunderlying topical structure. We first extract all possible topics that the\nsentences of a paragraph of text are related to. Coherence of this text is then\nmeasured by computing: (a) the degree of uncertainty of the topics with respect\nto the paragraph, and (b) the relatedness between these topics. All components\nof our modular framework rely only on unlabeled data and WordNet, thus making\nit completely unsupervised, which is an important feature for general-purpose\nusage of any metric. Experiments are conducted on two datasets - a publicly\navailable dataset for essay grading (representing human discourse), and a\nsynthetic dataset constructed by mixing content from multiple paragraphs\ncovering diverse topics. Our evaluation shows that the measured coherence\nscores are positively correlated with the ground truth for both the datasets.\nFurther validation to our coherence scores is provided by conducting human\nevaluation on the synthetic data, showing a significant agreement of 79.3%\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 23:49:31 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Shrivastava", "Disha", ""], ["Mishra", "Abhijit", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "1809.00414", "submitter": "Disha Shrivastava", "authors": "Disha Shrivastava, Sreyash Kenkre, Santosh Penubothula", "title": "Hypernyms Through Intra-Article Organization in Wikipedia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new measure for unsupervised hypernym detection and\ndirectionality. The motivation is to keep the measure computationally light and\nportatable across languages. We show that the relative physical location of\nwords in explanatory articles captures the directionality property. Further,\nthe phrases in section titles of articles about the word, capture the semantic\nsimilarity needed for hypernym detection task. We experimentally show that the\ncombination of features coming from these two simple measures suffices to\nproduce results comparable with the best unsupervised measures in terms of the\naverage precision.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 00:04:49 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Shrivastava", "Disha", ""], ["Kenkre", "Sreyash", ""], ["Penubothula", "Santosh", ""]]}, {"id": "1809.00494", "submitter": "Diego Esteves", "authors": "Diego Esteves, Aniketh Janardhan Reddy, Piyush Chawla and Jens Lehmann", "title": "Belittling the Source: Trustworthiness Indicators to Obfuscate Fake News\n  on the Web", "comments": null, "journal-ref": "EMNLP 2018: Conference on Empirical Methods in Natural Language\n  Processing (The First Workshop on Fact Extraction and Verification)", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of the internet, the number of fake-news online has been\nproliferating every year. The consequences of such phenomena are manifold,\nranging from lousy decision-making process to bullying and violence episodes.\nTherefore, fact-checking algorithms became a valuable asset. To this aim, an\nimportant step to detect fake-news is to have access to a credibility score for\na given information source. However, most of the widely used Web indicators\nhave either been shut-down to the public (e.g., Google PageRank) or are not\nfree for use (Alexa Rank). Further existing databases are short-manually\ncurated lists of online sources, which do not scale. Finally, most of the\nresearch on the topic is theoretical-based or explore confidential data in a\nrestricted simulation environment. In this paper we explore current research,\nhighlight the challenges and propose solutions to tackle the problem of\nclassifying websites into a credibility scale. The proposed model automatically\nextracts source reputation cues and computes a credibility factor, providing\nvaluable insights which can help in belittling dubious and confirming trustful\nunknown websites. Experimental results outperform state of the art in the\n2-classes and 5-classes setting.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 08:37:33 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Esteves", "Diego", ""], ["Reddy", "Aniketh Janardhan", ""], ["Chawla", "Piyush", ""], ["Lehmann", "Jens", ""]]}, {"id": "1809.00510", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Louis Annabi, Oksana Hagen, Michael\n  Garcia-Ortiz, David Filliat", "title": "Flatland: a Lightweight First-Person 2-D Environment for Reinforcement\n  Learning", "comments": "Accepted to the Workshop on Continual Unsupervised Sensorimotor\n  Learning (ICDL-EpiRob 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flatland is a simple, lightweight environment for fast prototyping and\ntesting of reinforcement learning agents. It is of lower complexity compared to\nsimilar 3D platforms (e.g. DeepMind Lab or VizDoom), but emulates physical\nproperties of the real world, such as continuity, multi-modal\npartially-observable states with first-person view and coherent physics. We\npropose to use it as an intermediary benchmark for problems related to Lifelong\nLearning. Flatland is highly customizable and offers a wide range of task\ndifficulty to extensively evaluate the properties of artificial agents. We\nexperiment with three reinforcement learning baseline agents and show that they\ncan rapidly solve a navigation task in Flatland. A video of an agent acting in\nFlatland is available here: https://youtu.be/I5y6Y2ZypdA.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 09:07:30 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 08:29:30 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Annabi", "Louis", ""], ["Hagen", "Oksana", ""], ["Garcia-Ortiz", "Michael", ""], ["Filliat", "David", ""]]}, {"id": "1809.00542", "submitter": "Nikola Simidjievski", "authors": "Matej Petkovi\\'c, Redouane Boumghar, Martin Breskvar, Sa\\v{s}o\n  D\\v{z}eroski, Dragi Kocev, Jurica Levati\\'c, Luke Lucas, Alja\\v{z} Osojnik,\n  Bernard \\v{Z}enko and Nikola Simidjievski", "title": "Machine learning for predicting thermal power consumption of the Mars\n  Express Spacecraft", "comments": null, "journal-ref": "IEEE Aerospace and Electronic Systems Magazine. 34(7), 46-60.\n  (2019)", "doi": "10.1109/MAES.2019.2915456", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The thermal subsystem of the Mars Express (MEX) spacecraft keeps the on-board\nequipment within its pre-defined operating temperatures range. To plan and\noptimize the scientific operations of MEX, its operators need to estimate in\nadvance, as accurately as possible, the power consumption of the thermal\nsubsystem. The remaining power can then be allocated for scientific purposes.\nWe present a machine learning pipeline for efficiently constructing accurate\npredictive models for predicting the power of the thermal subsystem on board\nMEX. In particular, we employ state-of-the-art feature engineering approaches\nfor transforming raw telemetry data, in turn used for constructing accurate\nmodels with different state-of-the-art machine learning methods. We show that\nthe proposed pipeline considerably improve our previous (competition-winning)\nwork in terms of time efficiency and predictive performance. Moreover, while\nachieving superior predictive performance, the constructed models also provide\nimportant insight into the spacecraft's behavior, allowing for further analyses\nand optimal planning of MEX's operation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 10:43:02 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 13:43:33 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Petkovi\u0107", "Matej", ""], ["Boumghar", "Redouane", ""], ["Breskvar", "Martin", ""], ["D\u017eeroski", "Sa\u0161o", ""], ["Kocev", "Dragi", ""], ["Levati\u0107", "Jurica", ""], ["Lucas", "Luke", ""], ["Osojnik", "Alja\u017e", ""], ["\u017denko", "Bernard", ""], ["Simidjievski", "Nikola", ""]]}, {"id": "1809.00543", "submitter": "Fabian Schilling", "authors": "Fabian Schilling, Julien Lecoeur, Fabrizio Schiano, Dario Floreano", "title": "Learning Vision-based Cohesive Flight in Drone Swarms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a data-driven approach to learning vision-based\ncollective behavior from a simple flocking algorithm. We simulate a swarm of\nquadrotor drones and formulate the controller as a regression problem in which\nwe generate 3D velocity commands directly from raw camera images. The dataset\nis created by simultaneously acquiring omnidirectional images and computing the\ncorresponding control command from the flocking algorithm. We show that a\nconvolutional neural network trained on the visual inputs of the drone can\nlearn not only robust collision avoidance but also coherence of the flock in a\nsample-efficient manner. The neural controller effectively learns to localize\nother agents in the visual input, which we show by visualizing the regions with\nthe most influence on the motion of an agent. This weakly supervised saliency\nmap can be computed efficiently and may be used as a prior for subsequent\ndetection and relative localization of other agents. We remove the dependence\non sharing positions among flock members by taking only local visual\ninformation into account for control. Our work can therefore be seen as the\nfirst step towards a fully decentralized, vision-based flock without the need\nfor communication or visual markers to aid detection of other agents.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 10:44:28 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Schilling", "Fabian", ""], ["Lecoeur", "Julien", ""], ["Schiano", "Fabrizio", ""], ["Floreano", "Dario", ""]]}, {"id": "1809.00593", "submitter": "Tanguy Kerdoncuff", "authors": "Tanguy Kerdoncuff, R\\'emi Emonet", "title": "IoU is not submodular", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short article aims at demonstrate that the Intersection over Union (or\nJaccard index) is not a submodular function. This mistake has been made in an\narticle which is cited and used as a foundation in another article. The\nIntersection of Union is widely used in machine learning as a cost function\nespecially for imbalance data and semantic segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 13:21:28 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Kerdoncuff", "Tanguy", ""], ["Emonet", "R\u00e9mi", ""]]}, {"id": "1809.00594", "submitter": "Sanli Tang", "authors": "Sanli Tang, Xiaolin Huang, Mingjian Chen, Chengjin Sun, and Jie Yang", "title": "Adversarial Attack Type I: Cheat Classifiers by Significant Changes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great success of deep neural networks, the adversarial attack can\ncheat some well-trained classifiers by small permutations. In this paper, we\npropose another type of adversarial attack that can cheat classifiers by\nsignificant changes. For example, we can significantly change a face but\nwell-trained neural networks still recognize the adversarial and the original\nexample as the same person. Statistically, the existing adversarial attack\nincreases Type II error and the proposed one aims at Type I error, which are\nhence named as Type II and Type I adversarial attack, respectively. The two\ntypes of attack are equally important but are essentially different, which are\nintuitively explained and numerically evaluated. To implement the proposed\nattack, a supervised variation autoencoder is designed and then the classifier\nis attacked by updating the latent variables using gradient information.\n{Besides, with pre-trained generative models, Type I attack on latent spaces is\ninvestigated as well.} Experimental results show that our method is practical\nand effective to generate Type I adversarial examples on large-scale image\ndatasets. Most of these generated examples can pass detectors designed for\ndefending Type II attack and the strengthening strategy is only efficient with\na specific type attack, both implying that the underlying reasons for Type I\nand Type II attack are different.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 13:25:06 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 13:00:58 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Tang", "Sanli", ""], ["Huang", "Xiaolin", ""], ["Chen", "Mingjian", ""], ["Sun", "Chengjin", ""], ["Yang", "Jie", ""]]}, {"id": "1809.00615", "submitter": "Dorjan Hitaj", "authors": "Dorjan Hitaj, Luigi V. Mancini", "title": "Have You Stolen My Model? Evasion Attacks Against Deep Neural Network\n  Watermarking Techniques", "comments": "7 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have had enormous impact on various domains of computer\nscience, considerably outperforming previous state of the art machine learning\ntechniques. To achieve this performance, neural networks need large quantities\nof data and huge computational resources, which heavily increases their\nconstruction costs. The increased cost of building a good deep neural network\nmodel gives rise to a need for protecting this investment from potential\ncopyright infringements. Legitimate owners of a machine learning model want to\nbe able to reliably track and detect a malicious adversary that tries to steal\nthe intellectual property related to the model. Recently, this problem was\ntackled by introducing in deep neural networks the concept of watermarking,\nwhich allows a legitimate owner to embed some secret information(watermark) in\na given model. The watermark allows the legitimate owner to detect copyright\ninfringements of his model. This paper focuses on verifying the robustness and\nreliability of state-of- the-art deep neural network watermarking schemes. We\nshow that, a malicious adversary, even in scenarios where the watermark is\ndifficult to remove, can still evade the verification by the legitimate owners,\nthus avoiding the detection of model theft.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 14:25:46 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Hitaj", "Dorjan", ""], ["Mancini", "Luigi V.", ""]]}, {"id": "1809.00653", "submitter": "Vlad Niculae", "authors": "Vlad Niculae, Andr\\'e F. T. Martins, Claire Cardie", "title": "Towards Dynamic Computation Graphs via Sparse Latent Structure", "comments": "EMNLP 2018; 9 pages (incl. appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep NLP models benefit from underlying structures in the data---e.g., parse\ntrees---typically extracted using off-the-shelf parsers. Recent attempts to\njointly learn the latent structure encounter a tradeoff: either make\nfactorization assumptions that limit expressiveness, or sacrifice end-to-end\ndifferentiability. Using the recently proposed SparseMAP inference, which\nretrieves a sparse distribution over latent structures, we propose a novel\napproach for end-to-end learning of latent structure predictors jointly with a\ndownstream predictor. To the best of our knowledge, our method is the first to\nenable unrestricted dynamic computation graph construction from the global\nlatent structure, while maintaining differentiability.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 16:52:19 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Niculae", "Vlad", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Cardie", "Claire", ""]]}, {"id": "1809.00716", "submitter": "Sajad Saeedi", "authors": "Wenbin Li (1), Sajad Saeedi (1), John McCormac (1), Ronald Clark (1),\n  Dimos Tzoumanikas (1), Qing Ye (2), Yuzhong Huang (2), Rui Tang (2), Stefan\n  Leutenegger (1) ((1) Department of Computing, Imperial College London, London\n  UK, SW7 2AZ (2) KooLab, Kujiale.com, Hangzhou China)", "title": "InteriorNet: Mega-scale Multi-sensor Photo-realistic Indoor Scenes\n  Dataset", "comments": "British Machine Vision Conference (BMVC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets have gained an enormous amount of popularity in the computer vision\ncommunity, from training and evaluation of Deep Learning-based methods to\nbenchmarking Simultaneous Localization and Mapping (SLAM). Without a doubt,\nsynthetic imagery bears a vast potential due to scalability in terms of amounts\nof data obtainable without tedious manual ground truth annotations or\nmeasurements. Here, we present a dataset with the aim of providing a higher\ndegree of photo-realism, larger scale, more variability as well as serving a\nwider range of purposes compared to existing datasets. Our dataset leverages\nthe availability of millions of professional interior designs and millions of\nproduction-level furniture and object assets -- all coming with fine geometric\ndetails and high-resolution texture. We render high-resolution and high\nframe-rate video sequences following realistic trajectories while supporting\nvarious camera types as well as providing inertial measurements. Together with\nthe release of the dataset, we will make executable program of our interactive\nsimulator software as well as our renderer available at\nhttps://interiornetdataset.github.io. To showcase the usability and uniqueness\nof our dataset, we show benchmarking results of both sparse and dense SLAM\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 20:42:27 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Li", "Wenbin", ""], ["Saeedi", "Sajad", ""], ["McCormac", "John", ""], ["Clark", "Ronald", ""], ["Tzoumanikas", "Dimos", ""], ["Ye", "Qing", ""], ["Huang", "Yuzhong", ""], ["Tang", "Rui", ""], ["Leutenegger", "Stefan", ""]]}, {"id": "1809.00734", "submitter": "Ivana Malenica", "authors": "Mark J. van der Laan and Ivana Malenica", "title": "Robust Estimation of Data-Dependent Causal Effects based on Observing a\n  Single Time-Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the case that one observes a single time-series, where at each time\nt one observes a data record O(t) involving treatment nodes A(t), possible\ncovariates L(t) and an outcome node Y(t). The data record at time t carries\ninformation for an (potentially causal) effect of the treatment A(t) on the\noutcome Y(t), in the context defined by a fixed dimensional summary measure\nCo(t). We are concerned with defining causal effects that can be consistently\nestimated, with valid inference, for sequentially randomized experiments\nwithout further assumptions. More generally, we consider the case when the\n(possibly causal) effects can be estimated in a double robust manner, analogue\nto double robust estimation of effects in the i.i.d. causal inference\nliterature. We propose a general class of averages of conditional\n(context-specific) causal parameters that can be estimated in a double robust\nmanner, therefore fully utilizing the sequential randomization. We propose a\ntargeted maximum likelihood estimator (TMLE) of these causal parameters, and\npresent a general theorem establishing the asymptotic consistency and normality\nof the TMLE. We extend our general framework to a number of typically studied\ncausal target parameters, including a sequentially adaptive design within a\nsingle unit that learns the optimal treatment rule for the unit over time. Our\nwork opens up robust statistical inference for causal questions based on\nobserving a single time-series on a particular unit.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 22:02:11 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["van der Laan", "Mark J.", ""], ["Malenica", "Ivana", ""]]}, {"id": "1809.00758", "submitter": "Myungsu Chae", "authors": "Myungsu Chae, Tae-Ho Kim, Young Hoon Shin, June-Woo Kim, and Soo-Young\n  Lee", "title": "End-to-end Multimodal Emotion and Gender Recognition with Dynamic Joint\n  Loss Weights", "comments": "IROS 2018 Workshop on Crossmodal Learning for Intelligent Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning is a method for improving the generalizability of\nmultiple tasks. In order to perform multiple classification tasks with one\nneural network model, the losses of each task should be combined. Previous\nstudies have mostly focused on multiple prediction tasks using joint loss with\nstatic weights for training models, choosing the weights between tasks without\nmaking sufficient considerations by setting them uniformly or empirically. In\nthis study, we propose a method to calculate joint loss using dynamic weights\nto improve the total performance, instead of the individual performance, of\ntasks. We apply this method to design an end-to-end multimodal emotion and\ngender recognition model using audio and video data. This approach provides\nproper weights for the loss of each task when the training process ends. In our\nexperiments, emotion and gender recognition with the proposed method yielded a\nlower joint loss, which is computed as the negative log-likelihood, than using\nstatic weights for joint loss. Moreover, our proposed model has better\ngeneralizability than other models. To the best of our knowledge, this research\nis the first to demonstrate the strength of using dynamic weights for joint\nloss for maximizing overall performance in emotion and gender recognition\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 00:52:25 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 06:55:13 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2018 04:16:54 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Chae", "Myungsu", ""], ["Kim", "Tae-Ho", ""], ["Shin", "Young Hoon", ""], ["Kim", "June-Woo", ""], ["Lee", "Soo-Young", ""]]}, {"id": "1809.00770", "submitter": "I-Chao Shen", "authors": "Shu-Hsuan Hsu, I-Chao Shen, Bing-Yu Chen", "title": "Transferring Deep Reinforcement Learning with Adversarial Objective and\n  Augmentation", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, deep reinforcement learning has been proven to solve\nproblems which have complex states like video games or board games. The next\nstep of intelligent agents would be able to generalize between tasks, and using\nprior experience to pick up new skills more quickly. However, most\nreinforcement learning algorithms for now are often suffering from catastrophic\nforgetting even when facing a very similar target task. Our approach enables\nthe agents to generalize knowledge from a single source task, and boost the\nlearning progress with a semisupervised learning method when facing a new task.\nWe evaluate this approach on Atari games, which is a popular reinforcement\nlearning benchmark, and show that it outperforms common baselines based on\npre-training and fine-tuning.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 02:13:37 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Hsu", "Shu-Hsuan", ""], ["Shen", "I-Chao", ""], ["Chen", "Bing-Yu", ""]]}, {"id": "1809.00782", "submitter": "Bhuwan Dhingra", "authors": "Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan\n  Salakhutdinov and William W. Cohen", "title": "Open Domain Question Answering Using Early Fusion of Knowledge Bases and\n  Text", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Domain Question Answering (QA) is evolving from complex pipelined\nsystems to end-to-end deep neural networks. Specialized neural models have been\ndeveloped for extracting answers from either text alone or Knowledge Bases\n(KBs) alone. In this paper we look at a more practical setting, namely QA over\nthe combination of a KB and entity-linked text, which is appropriate when an\nincomplete KB is available with a large text corpus. Building on recent\nadvances in graph representation learning we propose a novel model, GRAFT-Net,\nfor extracting answers from a question-specific subgraph containing text and KB\nentities and relations. We construct a suite of benchmark tasks for this\nproblem, varying the difficulty of questions, the amount of training data, and\nKB completeness. We show that GRAFT-Net is competitive with the\nstate-of-the-art when tested using either KBs or text alone, and vastly\noutperforms existing methods in the combined setting. Source code is available\nat https://github.com/OceanskySun/GraftNet .\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 03:15:56 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Sun", "Haitian", ""], ["Dhingra", "Bhuwan", ""], ["Zaheer", "Manzil", ""], ["Mazaitis", "Kathryn", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "1809.00794", "submitter": "Zhiting Hu", "authors": "Zhiting Hu, Haoran Shi, Bowen Tan, Wentao Wang, Zichao Yang, Tiancheng\n  Zhao, Junxian He, Lianhui Qin, Di Wang, Xuezhe Ma, Zhengzhong Liu, Xiaodan\n  Liang, Wangrong Zhu, Devendra Singh Sachan, Eric P. Xing", "title": "Texar: A Modularized, Versatile, and Extensible Toolkit for Text\n  Generation", "comments": "ACL 2019 demo, expanded version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Texar, an open-source toolkit aiming to support the broad set of\ntext generation tasks that transform any inputs into natural language, such as\nmachine translation, summarization, dialog, content manipulation, and so forth.\nWith the design goals of modularity, versatility, and extensibility in mind,\nTexar extracts common patterns underlying the diverse tasks and methodologies,\ncreates a library of highly reusable modules, and allows arbitrary model\narchitectures and algorithmic paradigms. In Texar, model architecture,\ninference, and learning processes are properly decomposed. Modules at a high\nconcept level can be freely assembled and plugged in/swapped out. The toolkit\nalso supports a rich set of large-scale pretrained models. Texar is thus\nparticularly suitable for researchers and practitioners to do fast prototyping\nand experimentation. The versatile toolkit also fosters technique sharing\nacross different text generation tasks. Texar supports both TensorFlow and\nPyTorch, and is released under Apache License 2.0 at https://www.texar.io.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 04:40:34 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 00:12:39 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Hu", "Zhiting", ""], ["Shi", "Haoran", ""], ["Tan", "Bowen", ""], ["Wang", "Wentao", ""], ["Yang", "Zichao", ""], ["Zhao", "Tiancheng", ""], ["He", "Junxian", ""], ["Qin", "Lianhui", ""], ["Wang", "Di", ""], ["Ma", "Xuezhe", ""], ["Liu", "Zhengzhong", ""], ["Liang", "Xiaodan", ""], ["Zhu", "Wangrong", ""], ["Sachan", "Devendra Singh", ""], ["Xing", "Eric P.", ""]]}, {"id": "1809.00811", "submitter": "Ahmed BenSaid", "authors": "Ahmed Ben Said and Abdelkarim Erradi and Azadeh Ghari Neiat and Athman\n  Bouguettaya", "title": "A Deep Learning Spatiotemporal Prediction Framework for Mobile\n  Crowdsourced Services", "comments": null, "journal-ref": null, "doi": "10.1007/s11036-018-1105-0", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This papers presents a deep learning-based framework to predict crowdsourced\nservice availability spatially and temporally. A novel two-stage prediction\nmodel is introduced based on historical spatio-temporal traces of mobile\ncrowdsourced services. The prediction model first clusters mobile crowdsourced\nservices into regions. The availability prediction of a mobile crowdsourced\nservice at a certain location and time is then formulated as a classification\nproblem. To determine the availability duration of predicted mobile\ncrowdsourced services, we formulate a forecasting task of time series using the\nGramian Angular Field. We validated the effectiveness of the proposed framework\nthrough multiple experiments.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 07:03:58 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Said", "Ahmed Ben", ""], ["Erradi", "Abdelkarim", ""], ["Neiat", "Azadeh Ghari", ""], ["Bouguettaya", "Athman", ""]]}, {"id": "1809.00832", "submitter": "Eunji Jeong", "authors": "Eunji Jeong, Joo Seong Jeong, Soojeong Kim, Gyeong-In Yu, Byung-Gon\n  Chun", "title": "Improving the Expressiveness of Deep Learning Frameworks with Recursion", "comments": "Appeared in EuroSys 2018. 13 pages, 11 figures", "journal-ref": "EuroSys 2018: Thirteenth EuroSys Conference, April 23-26, 2018,\n  Porto, Portugal", "doi": "10.1145/3190508.3190530", "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recursive neural networks have widely been used by researchers to handle\napplications with recursively or hierarchically structured data. However,\nembedded control flow deep learning frameworks such as TensorFlow, Theano,\nCaffe2, and MXNet fail to efficiently represent and execute such neural\nnetworks, due to lack of support for recursion. In this paper, we add recursion\nto the programming model of existing frameworks by complementing their design\nwith recursive execution of dataflow graphs as well as additional APIs for\nrecursive definitions. Unlike iterative implementations, which can only\nunderstand the topological index of each node in recursive data structures, our\nrecursive implementation is able to exploit the recursive relationships between\nnodes for efficient execution based on parallel computation. We present an\nimplementation on TensorFlow and evaluation results with various recursive\nneural network models, showing that our recursive implementation not only\nconveys the recursive nature of recursive neural networks better than other\nimplementations, but also uses given resources more effectively to reduce\ntraining and inference time.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 08:31:21 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Jeong", "Eunji", ""], ["Jeong", "Joo Seong", ""], ["Kim", "Soojeong", ""], ["Yu", "Gyeong-In", ""], ["Chun", "Byung-Gon", ""]]}, {"id": "1809.00836", "submitter": "Andrea Esuli", "authors": "Andrea Esuli, Alejandro Moreo Fern\\'andez, Fabrizio Sebastiani", "title": "A Recurrent Neural Network for Sentiment Quantification", "comments": "Accepted for publication at CIKM 2018", "journal-ref": null, "doi": "10.1145/3269206.3269287", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification is a supervised learning task that consists in predicting,\ngiven a set of classes C and a set D of unlabelled items, the prevalence (or\nrelative frequency) p(c|D) of each class c in C. Quantification can in\nprinciple be solved by classifying all the unlabelled items and counting how\nmany of them have been attributed to each class. However, this \"classify and\ncount\" approach has been shown to yield suboptimal quantification accuracy;\nthis has established quantification as a task of its own, and given rise to a\nnumber of methods specifically devised for it. We propose a recurrent neural\nnetwork architecture for quantification (that we call QuaNet) that observes the\nclassification predictions to learn higher-order \"quantification embeddings\",\nwhich are then refined by incorporating quantification predictions of simple\nclassify-and-count-like methods. We test {QuaNet on sentiment quantification on\ntext, showing that it substantially outperforms several state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 08:41:53 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Esuli", "Andrea", ""], ["Fern\u00e1ndez", "Alejandro Moreo", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1809.00846", "submitter": "Ping Luo", "authors": "Ping Luo and Xinjiang Wang and Wenqi Shao and Zhanglin Peng", "title": "Towards Understanding Regularization in Batch Normalization", "comments": "International Conference on Learning Representations (ICLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) improves both convergence and generalization in\ntraining neural networks. This work understands these phenomena theoretically.\nWe analyze BN by using a basic block of neural networks, consisting of a kernel\nlayer, a BN layer, and a nonlinear activation function. This basic network\nhelps us understand the impacts of BN in three aspects. First, by viewing BN as\nan implicit regularizer, BN can be decomposed into population normalization\n(PN) and gamma decay as an explicit regularization. Second, learning dynamics\nof BN and the regularization show that training converged with large maximum\nand effective learning rate. Third, generalization of BN is explored by using\nstatistical mechanics. Experiments demonstrate that BN in convolutional neural\nnetworks share the same traits of regularization as the above analyses.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 09:01:10 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 17:56:50 GMT"}, {"version": "v3", "created": "Sun, 30 Sep 2018 06:11:53 GMT"}, {"version": "v4", "created": "Wed, 24 Apr 2019 05:23:45 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Luo", "Ping", ""], ["Wang", "Xinjiang", ""], ["Shao", "Wenqi", ""], ["Peng", "Zhanglin", ""]]}, {"id": "1809.00852", "submitter": "Huanhuan Yu", "authors": "Huanhuan Yu, Menglei Hu and Songcan Chen", "title": "Multi-target Unsupervised Domain Adaptation without Exactly Shared\n  Categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation (UDA) aims to learn the unlabeled target\ndomain by transferring the knowledge of the labeled source domain. To date,\nmost of the existing works focus on the scenario of one source domain and one\ntarget domain (1S1T), and just a few works concern the scenario of multiple\nsource domains and one target domain (mS1T). While, to the best of our\nknowledge, almost no work concerns the scenario of one source domain and\nmultiple target domains (1SmT), in which these unlabeled target domains may not\nnecessarily share the same categories, therefore, contrasting to mS1T, 1SmT is\nmore challenging. Accordingly, for such a new UDA scenario, we propose a UDA\nframework through the model parameter adaptation (PA-1SmT). A key ingredient of\nPA-1SmT is to transfer knowledge through adaptive learning of a common model\nparameter dictionary, which is completely different from existing popular\nmethods for UDA, such as subspace alignment, distribution matching etc., and\ncan also be directly used for DA of privacy protection due to the fact that the\nknowledge is transferred just via the model parameters rather than data itself.\nFinally, our experimental results on three domain adaptation benchmark datasets\ndemonstrate the superiority of our framework.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 09:18:19 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 07:13:46 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Yu", "Huanhuan", ""], ["Hu", "Menglei", ""], ["Chen", "Songcan", ""]]}, {"id": "1809.00862", "submitter": "Omar Mohammed", "authors": "Omar Mohammed, Gerard Bailly, Damien Pellier", "title": "Handwriting styles: benchmarks and evaluation metrics", "comments": "Submitted to IEEE International Workshop on Deep and Transfer\n  Learning (DTL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the style of handwriting generation is a challenging problem,\nsince it is not well defined. It is a key component in order to develop in\ndeveloping systems with more personalized experiences with humans. In this\npaper, we propose baseline benchmarks, in order to set anchors to estimate the\nrelative quality of different handwriting style methods. This will be done\nusing deep learning techniques, which have shown remarkable results in\ndifferent machine learning tasks, learning classification, regression, and most\nrelevant to our work, generating temporal sequences. We discuss the challenges\nassociated with evaluating our methods, which is related to evaluation of\ngenerative models in general. We then propose evaluation metrics, which we find\nrelevant to this problem, and we discuss how we evaluate the evaluation\nmetrics. In this study, we use IRON-OFF dataset. To the best of our knowledge,\nthere is no work done before in generating handwriting (either in terms of\nmethodology or the performance metrics), our in exploring styles using this\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 09:54:25 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Mohammed", "Omar", ""], ["Bailly", "Gerard", ""], ["Pellier", "Damien", ""]]}, {"id": "1809.00901", "submitter": "Hye Won Chung", "authors": "Hye Won Chung, Ji Oon Lee, Doyeon Kim, Alfred O. Hero", "title": "Parity Queries for Binary Classification", "comments": "26 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.HC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a query-based data acquisition problem that aims to recover the\nvalues of $k$ binary variables from parity (XOR) measurements of chosen subsets\nof the variables. Assume the response model where only a randomly selected\nsubset of the measurements is received. We propose a method for designing a\nsequence of queries so that the variables can be identified with high\nprobability using as few ($n$) measurements as possible. We define the query\ndifficulty $\\bar{d}$ as the average size of the query subsets and the sample\ncomplexity $n$ as the minimum number of measurements required to attain a given\nrecovery accuracy. We obtain fundamental trade-offs between recovery accuracy,\nquery difficulty, and sample complexity. In particular, the necessary and\nsufficient sample complexity required for recovering all $k$ variables with\nhigh probability is $n = c_0 \\max\\{k, (k \\log k)/\\bar{d}\\}$ and the sample\ncomplexity for recovering a fixed proportion $(1-\\delta)k$ of the variables for\n$\\delta=o(1)$ is $n = c_1\\max\\{k, (k \\log(1/\\delta))/\\bar{d}\\}$, where $c_0,\nc_1>0$.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 11:43:20 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 03:03:49 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Chung", "Hye Won", ""], ["Lee", "Ji Oon", ""], ["Kim", "Doyeon", ""], ["Hero", "Alfred O.", ""]]}, {"id": "1809.00918", "submitter": "Geewook Kim", "authors": "Geewook Kim and Kazuki Fukui and Hidetoshi Shimodaira", "title": "Segmentation-free Compositional $n$-gram Embedding", "comments": "NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new type of representation learning method that models words,\nphrases and sentences seamlessly. Our method does not depend on word\nsegmentation and any human-annotated resources (e.g., word dictionaries), yet\nit is very effective for noisy corpora written in unsegmented languages such as\nChinese and Japanese. The main idea of our method is to ignore word boundaries\ncompletely (i.e., segmentation-free), and construct representations for all\ncharacter $n$-grams in a raw corpus with embeddings of compositional\nsub-$n$-grams. Although the idea is simple, our experiments on various\nbenchmarks and real-world datasets show the efficacy of our proposal.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 12:32:54 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 16:10:31 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Kim", "Geewook", ""], ["Fukui", "Kazuki", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "1809.00929", "submitter": "Dongrui Wu", "authors": "Yuqi Cui and Dongrui Wu", "title": "EEG-Based Driver Drowsiness Estimation Using Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, including convolutional neural networks (CNNs), has started\nfinding applications in brain-computer interfaces (BCIs). However, so far most\nsuch approaches focused on BCI classification problems. This paper extends\nEEGNet, a 3-layer CNN model for BCI classification, to BCI regression, and also\nutilizes a novel spectral meta-learner for regression (SMLR) approach to\naggregate multiple EEGNets for improved performance. Our model uses the power\nspectral density (PSD) of EEG signals as the input. Compared with raw EEG\ninputs, the PSD inputs can reduce the computational cost significantly, yet\nachieve much better regression performance. Experiments on driver drowsiness\nestimation from EEG signals demonstrate the outstanding performance of our\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 23:01:43 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Cui", "Yuqi", ""], ["Wu", "Dongrui", ""]]}, {"id": "1809.00932", "submitter": "Hu Ding", "authors": "Hu Ding", "title": "Faster Balanced Clusterings in High Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of constrained clustering has attracted significant attention in\nthe past decades. In this paper, we study the balanced $k$-center, $k$-median,\nand $k$-means clustering problems where the size of each cluster is constrained\nby the given lower and upper bounds. The problems are motivated by the\napplications in processing large-scale data in high dimension. Existing methods\noften need to compute complicated matchings (or min cost flows) to satisfy the\nbalance constraint, and thus suffer from high complexities especially in high\ndimension. We develop an effective framework for the three balanced clustering\nproblems to address this issue, and our method is based on a novel spatial\npartition idea in geometry. For the balanced $k$-center clustering, we provide\na $4$-approximation algorithm that improves the existing approximation factors;\nfor the balanced $k$-median and $k$-means clusterings, our algorithms yield\nconstant and $(1+\\epsilon)$-approximation factors with any $\\epsilon>0$. More\nimportantly, our algorithms achieve linear or nearly linear running times when\n$k$ is a constant, and significantly improve the existing ones. Our results can\nbe easily extended to metric balanced clusterings and the running times are\nsub-linear in terms of the complexity of $n$-point metric.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 13:07:52 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 01:59:04 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Ding", "Hu", ""]]}, {"id": "1809.00934", "submitter": "Xingyi Song", "authors": "Xingyi Song, Johann Petrak, Angus Roberts", "title": "A Deep Neural Network Sentence Level Classification Method with Context\n  Information", "comments": "Accepted at EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the sentence classification task, context formed from sentences adjacent\nto the sentence being classified can provide important information for\nclassification. This context is, however, often ignored. Where methods do make\nuse of context, only small amounts are considered, making it difficult to\nscale. We present a new method for sentence classification, Context-LSTM-CNN,\nthat makes use of potentially large contexts. The method also utilizes\nlong-range dependencies within the sentence being classified, using an LSTM,\nand short-span features, using a stacked CNN. Our experiments demonstrate that\nthis approach consistently improves over previous methods on two different\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 14:45:33 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Song", "Xingyi", ""], ["Petrak", "Johann", ""], ["Roberts", "Angus", ""]]}, {"id": "1809.00946", "submitter": "Jerry Li", "authors": "Jerry Li", "title": "Twin-GAN -- Unpaired Cross-Domain Image Translation with Weight-Sharing\n  GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for translating unlabeled images from one domain into\nanalog images in another domain. We employ a progressively growing\nskip-connected encoder-generator structure and train it with a GAN loss for\nrealistic output, a cycle consistency loss for maintaining same-domain\ntranslation identity, and a semantic consistency loss that encourages the\nnetwork to keep the input semantic features in the output. We apply our\nframework on the task of translating face images, and show that it is capable\nof learning semantic mappings for face images with no supervised one-to-one\nimage mapping.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 23:09:03 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Li", "Jerry", ""]]}, {"id": "1809.00947", "submitter": "Kleomenis Katevas", "authors": "Kleomenis Katevas, Katrin H\\\"ansel, Richard Clegg, Ilias Leontiadis,\n  Hamed Haddadi, Laurissa Tokarchuk", "title": "Finding Dory in the Crowd: Detecting Social Interactions using\n  Multi-Modal Mobile Sensing", "comments": "21 pages, 6 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remembering our day-to-day social interactions is challenging even if you\naren't a blue memory challenged fish. The ability to automatically detect and\nremember these types of interactions is not only beneficial for individuals\ninterested in their behavior in crowded situations, but also of interest to\nthose who analyze crowd behavior. Currently, detecting social interactions is\noften performed using a variety of methods including ethnographic studies,\ncomputer vision techniques and manual annotation-based data analysis. However,\nmobile phones offer easier means for data collection that is easy to analyze\nand can preserve the user's privacy. In this work, we present a system for\ndetecting stationary social interactions inside crowds, leveraging multi-modal\nmobile sensing data such as Bluetooth Smart (BLE), accelerometer and gyroscope.\nTo inform the development of such system, we conducted a study with 24\nparticipants, where we asked them to socialize with each other for 45 minutes.\nWe built a machine learning system based on gradient-boosted trees that\npredicts both 1:1 and group interactions with 77.8% precision and 86.5% recall,\na 30.2% performance increase compared to a proximity-based approach. By\nutilizing a community detection-based method, we further detected the various\ngroup formation that exist within the crowd. Using mobile phone sensors already\ncarried by the majority of people in a crowd makes our approach particularly\nwell suited to real-life analysis of crowd behavior and influence strategies.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 11:30:19 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 09:11:52 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Katevas", "Kleomenis", ""], ["H\u00e4nsel", "Katrin", ""], ["Clegg", "Richard", ""], ["Leontiadis", "Ilias", ""], ["Haddadi", "Hamed", ""], ["Tokarchuk", "Laurissa", ""]]}, {"id": "1809.00948", "submitter": "Jonas Adler", "authors": "Jonas Adler, Sebastian Lunz, Olivier Verdier, Carola-Bibiane\n  Sch\\\"onlieb and Ozan \\\"Oktem", "title": "Task adapted reconstruction for inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers the problem of performing a task defined on a model\nparameter that is only observed indirectly through noisy data in an ill-posed\ninverse problem. A key aspect is to formalize the steps of reconstruction and\ntask as appropriate estimators (non-randomized decision rules) in statistical\nestimation problems. The implementation makes use of (deep) neural networks to\nprovide a differentiable parametrization of the family of estimators for both\nsteps. These networks are combined and jointly trained against suitable\nsupervised training data in order to minimize a joint differentiable loss\nfunction, resulting in an end-to-end task adapted reconstruction method. The\nsuggested framework is generic, yet adaptable, with a plug-and-play structure\nfor adjusting both the inverse problem and the task at hand. More precisely,\nthe data model (forward operator and statistical model of the noise) associated\nwith the inverse problem is exchangeable, e.g., by using neural network\narchitecture given by a learned iterative method. Furthermore, any task that is\nencodable as a trainable neural network can be used. The approach is\ndemonstrated on joint tomographic image reconstruction, classification and\njoint tomographic image reconstruction segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 11:44:48 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Adler", "Jonas", ""], ["Lunz", "Sebastian", ""], ["Verdier", "Olivier", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""], ["\u00d6ktem", "Ozan", ""]]}, {"id": "1809.00953", "submitter": "Burak Satar", "authors": "Burak Satar, Ahmet Emir Dirik", "title": "Deep Learning Based Vehicle Make-Model Classification", "comments": "10 pages, ICANN 2018: Artificial Neural Networks and Machine Learning", "journal-ref": "Lecture Notes in Computer Science book series 2018 (LNCS, volume\n  11141). Springer, Cham", "doi": "10.1007/978-3-030-01424-7_53", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper studies the problems of vehicle make & model classification. Some\nof the main challenges are reaching high classification accuracy and reducing\nthe annotation time of the images. To address these problems, we have created a\nfine-grained database using online vehicle marketplaces of Turkey. A pipeline\nis proposed to combine an SSD (Single Shot Multibox Detector) model with a CNN\n(Convolutional Neural Network) model to train on the database. In the pipeline,\nwe first detect the vehicles by following an algorithm which reduces the time\nfor annotation. Then, we feed them into the CNN model. It is reached\napproximately 4% better classification accuracy result than using a\nconventional CNN model. Next, we propose to use the detected vehicles as ground\ntruth bounding box (GTBB) of the images and feed them into an SSD model in\nanother pipeline. At this stage, it is reached reasonable classification\naccuracy result without using perfectly shaped GTBB. Lastly, an application is\nimplemented in a use case by using our proposed pipelines. It detects the\nunauthorized vehicles by comparing their license plate numbers and make &\nmodels. It is assumed that license plates are readable.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 14:05:31 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 20:46:17 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Satar", "Burak", ""], ["Dirik", "Ahmet Emir", ""]]}, {"id": "1809.00957", "submitter": "Pankaj Roy", "authors": "Pankaj Raj Roy and Guillaume-Alexandre Bilodeau", "title": "Road User Abnormal Trajectory Detection using a Deep Autoencoder", "comments": "This paper has been accepted for oral presentation at ISVC'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the development of a method that detects abnormal\ntrajectories of road users at traffic intersections. The main difficulty with\nthis is the fact that there are very few abnormal data and the normal ones are\ninsufficient for the training of any kinds of machine learning model. To tackle\nthese problems, we proposed the solution of using a deep autoencoder network\ntrained solely through augmented data considered as normal. By generating\nartificial abnormal trajectories, our method is tested on four different\noutdoor urban users scenes and performs better compared to some classical\noutlier detection methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 23:18:52 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Roy", "Pankaj Raj", ""], ["Bilodeau", "Guillaume-Alexandre", ""]]}, {"id": "1809.00961", "submitter": "Ram Krishna Pandey", "authors": "Ram Krishna Pandey, Nabagata Saha, Samarjit Karmakar, A G Ramakrishnan", "title": "MSCE: An edge preserving robust loss function for improving\n  super-resolution algorithms", "comments": "Accepted in ICONIP-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advancement in the deep learning technologies such as CNNs\nand GANs, there is significant improvement in the quality of the images\nreconstructed by deep learning based super-resolution (SR) techniques. In this\nwork, we propose a robust loss function based on the preservation of edges\nobtained by the Canny operator. This loss function, when combined with the\nexisting loss function such as mean square error (MSE), gives better SR\nreconstruction measured in terms of PSNR and SSIM. Our proposed loss function\nguarantees improved performance on any existing algorithm using MSE loss\nfunction, without any increase in the computational complexity during testing.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 22:00:10 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Pandey", "Ram Krishna", ""], ["Saha", "Nabagata", ""], ["Karmakar", "Samarjit", ""], ["Ramakrishnan", "A G", ""]]}, {"id": "1809.00972", "submitter": "Yurui Qu", "authors": "Yurui Qu, Li Jing, Yichen Shen, Min Qiu, Marin Soljacic", "title": "Migrating Knowledge between Physical Scenarios based on Artificial\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is known to be data-hungry, which hinders its application in\nmany areas of science when datasets are small. Here, we propose to use transfer\nlearning methods to migrate knowledge between different physical scenarios and\nsignificantly improve the prediction accuracy of artificial neural networks\ntrained on a small dataset. This method can help reduce the demand for\nexpensive data by making use of additional inexpensive data. First, we\ndemonstrate that in predicting the transmission from multilayer photonic film,\nthe relative error rate is reduced by 46.8% (26.5%) when the source data comes\nfrom 10-layer (8-layer) films and the target data comes from 8-layer (10-layer)\nfilms. Second, we show that the relative error rate is decreased by 22% when\nknowledge is transferred between two very different physical scenarios:\ntransmission from multilayer films and scattering from multilayer\nnanoparticles. Finally, we propose a multi-task learning method to improve the\nperformance of different physical scenarios simultaneously in which each task\nonly has a small dataset.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 20:46:50 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 01:17:20 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Qu", "Yurui", ""], ["Jing", "Li", ""], ["Shen", "Yichen", ""], ["Qiu", "Min", ""], ["Soljacic", "Marin", ""]]}, {"id": "1809.00973", "submitter": "Philipp Petersen", "authors": "Philipp Petersen, Felix Voigtlaender", "title": "Equivalence of approximation by convolutional neural networks and\n  fully-connected networks", "comments": null, "journal-ref": "Proc. Amer. Math. Soc. 148 (2020), 1567-1581", "doi": null, "report-no": null, "categories": "math.FA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks are the most widely used type of neural\nnetworks in applications. In mathematical analysis, however, mostly\nfully-connected networks are studied. In this paper, we establish a connection\nbetween both network architectures. Using this connection, we show that all\nupper and lower bounds concerning approximation rates of {fully-connected}\nneural networks for functions $f \\in \\mathcal{C}$ -- for an arbitrary function\nclass $\\mathcal{C}$ -- translate to essentially the same bounds concerning\napproximation rates of convolutional neural networks for functions $f \\in\n{\\mathcal{C}^{equi}}$, with the class ${\\mathcal{C}^{equi}}$ consisting of all\ntranslation equivariant functions whose first coordinate belongs to\n$\\mathcal{C}$. All presented results consider exclusively the case of\nconvolutional neural networks without any pooling operation and with circular\nconvolutions, i.e., not based on zero-padding.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 13:56:23 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2018 10:59:29 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 14:41:14 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Petersen", "Philipp", ""], ["Voigtlaender", "Felix", ""]]}, {"id": "1809.00977", "submitter": "Jacob Nogas", "authors": "Jacob Nogas, Shehroz S. Khan, Alex Mihailidis", "title": "DeepFall -- Non-invasive Fall Detection with Deep Spatio-Temporal\n  Convolutional Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human falls rarely occur; however, detecting falls is very important from the\nhealth and safety perspective. Due to the rarity of falls, it is difficult to\nemploy supervised classification techniques to detect them. Moreover, in these\nhighly skewed situations it is also difficult to extract domain specific\nfeatures to identify falls. In this paper, we present a novel framework,\n\\textit{DeepFall}, which formulates the fall detection problem as an anomaly\ndetection problem. The \\textit{DeepFall} framework presents the novel use of\ndeep spatio-temporal convolutional autoencoders to learn spatial and temporal\nfeatures from normal activities using non-invasive sensing modalities. We also\npresent a new anomaly scoring method that combines the reconstruction score of\nframes across a temporal window to detect unseen falls. We tested the\n\\textit{DeepFall} framework on three publicly available datasets collected\nthrough non-invasive sensing modalities, thermal camera and depth cameras and\nshow superior results in comparison to traditional autoencoder methods to\nidentify unseen falls.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 16:41:58 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 18:06:38 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 18:12:14 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Nogas", "Jacob", ""], ["Khan", "Shehroz S.", ""], ["Mihailidis", "Alex", ""]]}, {"id": "1809.00999", "submitter": "Abdallah Moussawi", "authors": "Abdallah Moussawi", "title": "Towards Large Scale Training Of Autoencoders For Collaborative Filtering", "comments": "2 pages, ACM RecSys 2018 Late-breaking Results Track (Posters)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply a mini-batch based negative sampling method to\nefficiently train a latent factor autoencoder model on large scale and sparse\ndata for implicit feedback collaborative filtering. We compare our work against\na state-of-the-art baseline model on different experimental datasets and show\nthat this method can lead to a good and fast approximation of the baseline\nmodel performance. The source code is available in\nhttps://github.com/amoussawi/recoder .\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 22:34:29 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 00:13:30 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 07:44:07 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Moussawi", "Abdallah", ""]]}, {"id": "1809.01000", "submitter": "Fei Jiang", "authors": "Fei Jiang, Guosheng Yin", "title": "Bayesian Outdoor Defect Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Bayesian defect detector to facilitate the defect detection on\nthe motion blurred images on rough texture surfaces. To enhance the accuracy of\nBayesian detection on removing non-defect pixels, we develop a class of\nreflected non-local prior distributions, which is constructed by using the mode\nof a distribution to subtract its density. The reflected non-local priors\nforces the Bayesian detector to approach 0 at the non-defect locations. We\nconduct experiments studies to demonstrate the superior performance of the\nBayesian detector in eliminating the non-defect points. We implement the\nBayesian detector in the motion blurred drone images, in which the detector\nsuccessfully identifies the hail damages on the rough surface and substantially\nenhances the accuracy of the entire defect detection pipeline.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 12:36:36 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Jiang", "Fei", ""], ["Yin", "Guosheng", ""]]}, {"id": "1809.01015", "submitter": "Nicolo' Savioli", "authors": "Nicol\\'o Savioli, Miguel Silva Vieira, Pablo Lamata, Giovanni Montana", "title": "Automated segmentation on the entire cardiac cycle using a deep learning\n  work-flow", "comments": "6 pages, 2 figures, published on IEEE Xplore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The segmentation of the left ventricle (LV) from CINE MRI images is essential\nto infer important clinical parameters. Typically, machine learning algorithms\nfor automated LV segmentation use annotated contours from only two cardiac\nphases, diastole, and systole. In this work, we present an analysis work-flow\nfor fully-automated LV segmentation that learns from images acquired through\nthe cardiac cycle. The workflow consists of three components: first, for each\nimage in the sequence, we perform an automated localization and subsequent\ncropping of the bounding box containing the cardiac silhouette. Second, we\nidentify the LV contours using a Temporal Fully Convolutional Neural Network\n(T-FCNN), which extends Fully Convolutional Neural Networks (FCNN) through a\nrecurrent mechanism enforcing temporal coherence across consecutive frames.\nFinally, we further defined the boundaries using either one of two components:\nfully-connected Conditional Random Fields (CRFs) with Gaussian edge potentials\nand Semantic Flow. Our initial experiments suggest that significant improvement\nin performance can potentially be achieved by using a recurrent neural network\ncomponent that explicitly learns cardiac motion patterns whilst performing LV\nsegmentation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 17:07:31 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Savioli", "Nicol\u00f3", ""], ["Vieira", "Miguel Silva", ""], ["Lamata", "Pablo", ""], ["Montana", "Giovanni", ""]]}, {"id": "1809.01017", "submitter": "Tamara Mchedlidze David", "authors": "Moritz Klammler and Tamara Mchedlidze and Alexey Pak", "title": "Aesthetic Discrimination of Graph Layouts", "comments": "Appears in the Proceedings of the 26th International Symposium on\n  Graph Drawing and Network Visualization (GD 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the following basic question: given two layouts of the\nsame graph, which one is more aesthetically pleasing? We propose a neural\nnetwork-based discriminator model trained on a labeled dataset that decides\nwhich of two layouts has a higher aesthetic quality. The feature vectors used\nas inputs to the model are based on known graph drawing quality metrics,\nclassical statistics, information-theoretical quantities, and two-point\nstatistics inspired by methods of condensed matter physics. The large corpus of\nlayout pairs used for training and testing is constructed using force-directed\ndrawing algorithms and the layouts that naturally stem from the process of\ngraph generation. It is further extended using data augmentation techniques.\nThe mean prediction accuracy of our model is 95.70%, outperforming\ndiscriminators based on stress and on the linear combination of popular quality\nmetrics by a statistically significant margin.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 14:19:43 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Klammler", "Moritz", ""], ["Mchedlidze", "Tamara", ""], ["Pak", "Alexey", ""]]}, {"id": "1809.01018", "submitter": "Chen Chao", "authors": "Chao Chen and Boyuan Jiang and Xinyu Jin", "title": "Parameter Transfer Extreme Learning Machine based on Projective Model", "comments": "This paper was accepted as an oral paper by IJCNN 2018", "journal-ref": "2018 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2018.8489244", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years, transfer learning has attracted much attention in the community\nof machine learning. In this paper, we mainly focus on the tasks of parameter\ntransfer under the framework of extreme learning machine (ELM). Unlike the\nexisting parameter transfer approaches, which incorporate the source model\ninformation into the target by regularizing the di erence between the source\nand target domain parameters, an intuitively appealing projective-model is\nproposed to bridge the source and target model parameters. Specifically, we\nformulate the parameter transfer in the ELM networks by the means of parameter\nprojection, and train the model by optimizing the projection matrix and\nclassifier parameters jointly. Further more, the `L2,1-norm structured sparsity\npenalty is imposed on the source domain parameters, which encourages the joint\nfeature selection and parameter transfer. To evaluate the e ectiveness of the\nproposed method, comprehensive experiments on several commonly used domain\nadaptation datasets are presented. The results show that the proposed method\nsignificantly outperforms the non-transfer ELM networks and other classical\ntransfer learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 14:24:19 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 14:40:22 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Chen", "Chao", ""], ["Jiang", "Boyuan", ""], ["Jin", "Xinyu", ""]]}, {"id": "1809.01022", "submitter": "Yuan He", "authors": "Yuan He and Ming Jiang and Chunming Zhao", "title": "A Neural Network Aided Approach for LDPC Coded DCO-OFDM with Clipping\n  Distortion", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a neural network-aided bit-interleaved coded modulation\n(NN-BICM) receiver is designed to mitigate the nonlinear clipping distortion in\nthe LDPC coded direct currentbiased optical orthogonal frequency division\nmultiplexing (DCOOFDM) systems. Taking the cross-entropy as loss function, a\nfeed forward network is trained by backpropagation algorithm to output the\ncondition probability through the softmax activation function, thereby\nassisting in a modified log-likelihood ratio (LLR) improvement. To reduce the\ncomplexity, this feed-forward network simplifies the input layer with a single\nsymbol and the corresponding Gaussian variance instead of focusing on the\ninter-carrier interference between multiple subcarriers. On the basis of the\nneural network-aided BICM with Gray labelling, we propose a novel stacked\nnetwork architecture of the bitinterleaved coded modulation with iterative\ndecoding (NN-BICMID). Its performance has been improved further by calculating\nthe condition probability with the aid of a priori probability that derived\nfrom the extrinsic LLRs in the LDPC decoder at the last iteration, at the\nexpense of customizing neural network detectors at each iteration time\nseparately. Utilizing the optimal DC bias as the midpoint of the dynamic\nregion, the simulation results demonstrate that both the NN-BICM and NN-BICM-ID\nschemes achieve noticeable performance gains than other counterparts, in which\nthe NN-BICM-ID clearly outperforms NN-BICM with various modulation and coding\nschemes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 14:31:42 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["He", "Yuan", ""], ["Jiang", "Ming", ""], ["Zhao", "Chunming", ""]]}, {"id": "1809.01062", "submitter": "Richard Oentaryo", "authors": "Richard J. Oentaryo, Xavier Jayaraj Siddarth Ashok, Ee-Peng Lim,\n  Philips Kokoh Prasetyo", "title": "JobComposer: Career Path Optimization via Multicriteria Utility Learning", "comments": null, "journal-ref": "ECML-PKDD Data Science for Human Capital Management 2018", "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With online professional network platforms (OPNs, e.g., LinkedIn, Xing, etc.)\nbecoming popular on the web, people are now turning to these platforms to\ncreate and share their professional profiles, to connect with others who share\nsimilar professional aspirations and to explore new career opportunities. These\nplatforms however do not offer a long-term roadmap to guide career progression\nand improve workforce employability. The career trajectories of OPN users can\nserve as a reference but they are not always optimal. A career plan can also be\ndevised through consultation with career coaches, whose knowledge may however\nbe limited to a few industries. To address the above limitations, we present a\nnovel data-driven approach dubbed JobComposer to automate career path planning\nand optimization. Its key premise is that the observed career trajectories in\nOPNs may not necessarily be optimal, and can be improved by learning to\nmaximize the sum of payoffs attainable by following a career path. At its\nheart, JobComposer features a decomposition-based multicriteria utility\nlearning procedure to achieve the best tradeoff among different payoff criteria\nin career path planning. Extensive studies using a city state-based OPN dataset\ndemonstrate that JobComposer returns career paths better than other baseline\nmethods and the actual career paths.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 16:09:15 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Oentaryo", "Richard J.", ""], ["Ashok", "Xavier Jayaraj Siddarth", ""], ["Lim", "Ee-Peng", ""], ["Prasetyo", "Philips Kokoh", ""]]}, {"id": "1809.01074", "submitter": "Mahtab Ahmed", "authors": "Mahtab Ahmed, Muhammad Rifayat Samee, Robert E. Mercer", "title": "A Novel Neural Sequence Model with Multiple Attentions for Word Sense\n  Disambiguation", "comments": "9 pages, 3 Figures, Accepted as a conference paper in ICMLA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Word sense disambiguation (WSD) is a well researched problem in computational\nlinguistics. Different research works have approached this problem in different\nways. Some state of the art results that have been achieved for this problem\nare by supervised models in terms of accuracy, but they often fall behind\nflexible knowledge-based solutions which use engineered features as well as\nhuman annotators to disambiguate every target word. This work focuses on\nbridging this gap using neural sequence models incorporating the well-known\nattention mechanism. The main gist of our work is to combine multiple\nattentions on different linguistic features through weights and to provide a\nunified framework for doing this. This weighted attention allows the model to\neasily disambiguate the sense of an ambiguous word by attending over a suitable\nportion of a sentence. Our extensive experiments show that multiple attention\nenables a more versatile encoder-decoder model leading to state of the art\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 16:28:36 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Ahmed", "Mahtab", ""], ["Samee", "Muhammad Rifayat", ""], ["Mercer", "Robert E.", ""]]}, {"id": "1809.01079", "submitter": "Yuan Wu", "authors": "Yuan Wu, Lingling Li and Lian Li", "title": "Chi-Square Test Neural Network: A New Binary Classifier based on\n  Backpropagation Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the chi-square test neural network: a single hidden layer\nbackpropagation neural network using chi-square test theorem to redefine the\ncost function and the error function. The weights and thresholds are modified\nusing standard backpropagation algorithm. The proposed approach has the\nadvantage of making consistent data distribution over training and testing\nsets. It can be used for binary classification. The experimental results on\nreal world data sets indicate that the proposed algorithm can significantly\nimprove the classification accuracy comparing to related approaches.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 16:38:01 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Wu", "Yuan", ""], ["Li", "Lingling", ""], ["Li", "Lian", ""]]}, {"id": "1809.01090", "submitter": "Lu Bai", "authors": "Lu Bai, Yuhang Jiao, Luca Rossi, Lixin Cui, Jian Cheng, Edwin R.\n  Hancock", "title": "Graph Convolutional Neural Networks based on Quantum Vertex Saliency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new Quantum Spatial Graph Convolutional Neural Network\n(QSGCNN) model that can directly learn a classification function for graphs of\narbitrary sizes. Unlike state-of-the-art Graph Convolutional Neural Network\n(GCNN) models, the proposed QSGCNN model incorporates the process of\nidentifying transitive aligned vertices between graphs, and transforms\narbitrary sized graphs into fixed-sized aligned vertex grid structures. In\norder to learn representative graph characteristics, a new quantum spatial\ngraph convolution is proposed and employed to extract multi-scale vertex\nfeatures, in terms of quantum information propagation between grid vertices of\neach graph. Since the quantum spatial convolution preserves the grid structures\nof the input vertices (i.e., the convolution layer does not change the original\nspatial sequence of vertices), the proposed QSGCNN model allows to directly\nemploy the traditional convolutional neural network architecture to further\nlearn from the global graph topology, providing an end-to-end deep learning\narchitecture that integrates the graph representation and learning in the\nquantum spatial graph convolution layer and the traditional convolutional layer\nfor graph classifications. We demonstrate the effectiveness of the proposed\nQSGCNN model in relation to existing state-of-the-art methods. The proposed\nQSGCNN model addresses the shortcomings of information loss and imprecise\ninformation representation arising in existing GCN models associated with the\nuse of SortPooling or SumPooling layers. Experiments on benchmark graph\nclassification datasets demonstrate the effectiveness of the proposed QSGCNN\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 16:53:04 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 20:52:53 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Bai", "Lu", ""], ["Jiao", "Yuhang", ""], ["Rossi", "Luca", ""], ["Cui", "Lixin", ""], ["Cheng", "Jian", ""], ["Hancock", "Edwin R.", ""]]}, {"id": "1809.01093", "submitter": "Aleksandar Bojchevski", "authors": "Aleksandar Bojchevski, Stephan G\\\"unnemann", "title": "Adversarial Attacks on Node Embeddings via Graph Poisoning", "comments": "ICML 2019, PMLR 97:695-704", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of network representation learning is to learn low-dimensional node\nembeddings that capture the graph structure and are useful for solving\ndownstream tasks. However, despite the proliferation of such methods, there is\ncurrently no study of their robustness to adversarial attacks. We provide the\nfirst adversarial vulnerability analysis on the widely used family of methods\nbased on random walks. We derive efficient adversarial perturbations that\npoison the network structure and have a negative effect on both the quality of\nthe embeddings and the downstream tasks. We further show that our attacks are\ntransferable since they generalize to many models and are successful even when\nthe attacker is restricted.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 16:59:53 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 01:51:36 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 16:16:11 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Bojchevski", "Aleksandar", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1809.01096", "submitter": "Asim Mazin", "authors": "Asim Mazin, Mohamed Elkourdi, and Richard D. Gitlin", "title": "Accelerating Beam Sweeping in mmWave Standalone 5G New Radios using\n  Recurrent Neural Networks", "comments": "4 pages and 4 Figures. It was presented at VTC 2018-Fall", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter wave (mmWave) is a key technology to support high data rate\ndemands for 5G applications. Highly directional transmissions are crucial at\nthese frequencies to compensate for high isotropic pathloss. This reliance on\ndi- rectional beamforming, however, makes the cell discovery (cell search)\nchallenging since both base station (gNB) and user equipment (UE) jointly\nperform a search over angular space to locate potential beams to initiate\ncommunication. In the cell discovery phase, sequential beam sweeping is\nperformed through the angular coverage region in order to transmit\nsynchronization signals. The sweeping pattern can either be a linear rotation\nor a hopping pattern that makes use of additional information. This paper\nproposes beam sweeping pattern prediction, based on the dynamic distribution of\nuser traffic, using a form of recurrent neural networks (RNNs) called Gated\nRecurrent Unit (GRU). The spatial distribution of users is inferred from data\nin call detail records (CDRs) of the cellular network. Results show that the\nusers spatial distribution and their approximate location (direction) can be\naccurately predicted based on CDRs data using GRU, which is then used to\ncalculate the sweeping pattern in the angular domain during cell search.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 17:02:35 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Mazin", "Asim", ""], ["Elkourdi", "Mohamed", ""], ["Gitlin", "Richard D.", ""]]}, {"id": "1809.01123", "submitter": "Yuan-Ting Hu", "authors": "Yuan-Ting Hu, Jia-Bin Huang, Alexander G. Schwing", "title": "VideoMatch: Matching based Video Object Segmentation", "comments": "Accepted to ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video object segmentation is challenging yet important in a wide variety of\napplications for video analysis. Recent works formulate video object\nsegmentation as a prediction task using deep nets to achieve appealing\nstate-of-the-art performance. Due to the formulation as a prediction task, most\nof these methods require fine-tuning during test time, such that the deep nets\nmemorize the appearance of the objects of interest in the given video. However,\nfine-tuning is time-consuming and computationally expensive, hence the\nalgorithms are far from real time. To address this issue, we develop a novel\nmatching based algorithm for video object segmentation. In contrast to\nmemorization based classification techniques, the proposed approach learns to\nmatch extracted features to a provided template without memorizing the\nappearance of the objects. We validate the effectiveness and the robustness of\nthe proposed method on the challenging DAVIS-16, DAVIS-17, Youtube-Objects and\nJumpCut datasets. Extensive results show that our method achieves comparable\nperformance without fine-tuning and is much more favorable in terms of\ncomputational time.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 17:59:53 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Hu", "Yuan-Ting", ""], ["Huang", "Jia-Bin", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "1809.01129", "submitter": "Zac Cranko", "authors": "Zac Cranko, Simon Kornblith, Zhan Shi, Richard Nock", "title": "Lipschitz Networks and Distributional Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust risk minimisation has several advantages: it has been studied with\nregards to improving the generalisation properties of models and robustness to\nadversarial perturbation. We bound the distributionally robust risk for a model\nclass rich enough to include deep neural networks by a regularised empirical\nrisk involving the Lipschitz constant of the model. This allows us to\ninterpretand quantify the robustness properties of a deep neural network. As an\napplication we show the distributionally robust risk upperbounds the\nadversarial training risk.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 03:12:40 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Cranko", "Zac", ""], ["Kornblith", "Simon", ""], ["Shi", "Zhan", ""], ["Nock", "Richard", ""]]}, {"id": "1809.01133", "submitter": "Timos Papadopoulos", "authors": "Timos Papadopoulos, Stephen J. Roberts and Katherine J. Willis", "title": "Automated bird sound recognition in realistic settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CY cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluated the effectiveness of an automated bird sound identification\nsystem in a situation that emulates a realistic, typical application. We\ntrained classification algorithms on a crowd-sourced collection of bird audio\nrecording data and restricted our training methods to be completely free of\nmanual intervention. The approach is hence directly applicable to the analysis\nof multiple species collections, with labelling provided by crowd-sourced\ncollection. We evaluated the performance of the bird sound recognition system\non a realistic number of candidate classes, corresponding to real conditions.\nWe investigated the use of two canonical classification methods, chosen due to\ntheir widespread use and ease of interpretation, namely a k Nearest Neighbour\n(kNN) classifier with histogram-based features and a Support Vector Machine\n(SVM) with time-summarisation features. We further investigated the use of a\ncertainty measure, derived from the output probabilities of the classifiers, to\nenhance the interpretability and reliability of the class decisions. Our\nresults demonstrate that both identification methods achieved similar\nperformance, but we argue that the use of the kNN classifier offers somewhat\nmore flexibility. Furthermore, we show that employing an outcome certainty\nmeasure provides a valuable and consistent indicator of the reliability of\nclassification results. Our use of generic training data and our investigation\nof probabilistic classification methodologies that can flexibly address the\nvariable number of candidate species/classes that are expected to be\nencountered in the field, directly contribute to the development of a practical\nbird sound identification system with potentially global application. Further,\nwe show that certainty measures associated with identification outcomes can\nsignificantly contribute to the practical usability of the overall system.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 10:26:37 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Papadopoulos", "Timos", ""], ["Roberts", "Stephen J.", ""], ["Willis", "Katherine J.", ""]]}, {"id": "1809.01185", "submitter": "Yang Lu", "authors": "Yang Young Lu, Yingying Fan, Jinchi Lv, William Stafford Noble", "title": "DeepPINK: reproducible feature selection in deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become increasingly popular in both supervised and\nunsupervised machine learning thanks to its outstanding empirical performance.\nHowever, because of their intrinsic complexity, most deep learning methods are\nlargely treated as black box tools with little interpretability. Even though\nrecent attempts have been made to facilitate the interpretability of deep\nneural networks (DNNs), existing methods are susceptible to noise and lack of\nrobustness.\n  Therefore, scientists are justifiably cautious about the reproducibility of\nthe discoveries, which is often related to the interpretability of the\nunderlying statistical models. In this paper, we describe a method to increase\nthe interpretability and reproducibility of DNNs by incorporating the idea of\nfeature selection with controlled error rate. By designing a new DNN\narchitecture and integrating it with the recently proposed knockoffs framework,\nwe perform feature selection with a controlled error rate, while maintaining\nhigh power. This new method, DeepPINK (Deep feature selection using\nPaired-Input Nonlinear Knockoffs), is applied to both simulated and real data\nsets to demonstrate its empirical utility.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 18:24:37 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 04:17:27 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Lu", "Yang Young", ""], ["Fan", "Yingying", ""], ["Lv", "Jinchi", ""], ["Noble", "William Stafford", ""]]}, {"id": "1809.01225", "submitter": "Tsung-Yu Hsieh", "authors": "Tsung-Yu Hsieh, Yasser EL-Manzalawy, Yiwei Sun, Vasant Honavar", "title": "Compositional Stochastic Average Gradient for Machine Learning and\n  Related Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning, statistical inference, and portfolio optimization\nproblems require minimization of a composition of expected value functions\n(CEVF). Of particular interest is the finite-sum versions of such compositional\noptimization problems (FS-CEVF). Compositional stochastic variance reduced\ngradient (C-SVRG) methods that combine stochastic compositional gradient\ndescent (SCGD) and stochastic variance reduced gradient descent (SVRG) methods\nare the state-of-the-art methods for FS-CEVF problems. We introduce\ncompositional stochastic average gradient descent (C-SAG) a novel extension of\nthe stochastic average gradient method (SAG) to minimize composition of\nfinite-sum functions. C-SAG, like SAG, estimates gradient by incorporating\nmemory of previous gradient information. We present theoretical analyses of\nC-SAG which show that C-SAG, like SAG, and C-SVRG, achieves a linear\nconvergence rate when the objective function is strongly convex; However, C-CAG\nachieves lower oracle query complexity per iteration than C-SVRG. Finally, we\npresent results of experiments showing that C-SAG converges substantially\nfaster than full gradient (FG), as well as C-SVRG.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 19:58:06 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 14:57:46 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Hsieh", "Tsung-Yu", ""], ["EL-Manzalawy", "Yasser", ""], ["Sun", "Yiwei", ""], ["Honavar", "Vasant", ""]]}, {"id": "1809.01229", "submitter": "Sotirios Chatzis", "authors": "Kyriakos Tolias and Sotirios Chatzis", "title": "t-Exponential Memory Networks for Question-Answering Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in deep learning have brought to the fore models that can\nmake multiple computational steps in the service of completing a task; these\nare capable of describ- ing long-term dependencies in sequential data. Novel\nrecurrent attention models over possibly large external memory modules\nconstitute the core mechanisms that enable these capabilities. Our work\naddresses learning subtler and more complex underlying temporal dynamics in\nlanguage modeling tasks that deal with sparse sequential data. To this end, we\nimprove upon these recent advances, by adopting concepts from the field of\nBayesian statistics, namely variational inference. Our proposed approach\nconsists in treating the network parameters as latent variables with a prior\ndistribution imposed over them. Our statistical assumptions go beyond the\nstandard practice of postulating Gaussian priors. Indeed, to allow for handling\noutliers, which are prevalent in long observed sequences of multivariate data,\nmultivariate t-exponential distributions are imposed. On this basis, we proceed\nto infer corresponding posteriors; these can be used for inference and\nprediction at test time, in a way that accounts for the uncertainty in the\navailable sparse training data. Specifically, to allow for our approach to best\nexploit the merits of the t-exponential family, our method considers a new\nt-divergence measure, which generalizes the concept of the Kullback-Leibler\ndivergence. We perform an extensive experimental evaluation of our approach,\nusing challenging language modeling benchmarks, and illustrate its superiority\nover existing state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 20:09:01 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Tolias", "Kyriakos", ""], ["Chatzis", "Sotirios", ""]]}, {"id": "1809.01266", "submitter": "Lei Ma", "authors": "Xiaofei Xie, Lei Ma, Felix Juefei-Xu, Hongxu Chen, Minhui Xue, Bo Li,\n  Yang Liu, Jianjun Zhao, Jianxiong Yin, and Simon See", "title": "DeepHunter: Hunting Deep Neural Network Defects via Coverage-Guided\n  Fuzzing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In company with the data explosion over the past decade, deep neural network\n(DNN) based software has experienced unprecedented leap and is becoming the key\ndriving force of many novel industrial applications, including many\nsafety-critical scenarios such as autonomous driving. Despite great success\nachieved in various human intelligence tasks, similar to traditional software,\nDNNs could also exhibit incorrect behaviors caused by hidden defects causing\nsevere accidents and losses. In this paper, we propose DeepHunter, an automated\nfuzz testing framework for hunting potential defects of general-purpose DNNs.\nDeepHunter performs metamorphic mutation to generate new semantically preserved\ntests, and leverages multiple plugable coverage criteria as feedback to guide\nthe test generation from different perspectives. To be scalable towards\npractical-sized DNNs, DeepHunter maintains multiple tests in a batch, and\nprioritizes the tests selection based on active feedback. The effectiveness of\nDeepHunter is extensively investigated on 3 popular datasets (MNIST, CIFAR-10,\nImageNet) and 7 DNNs with diverse complexities, under a large set of 6 coverage\ncriteria as feedback. The large-scale experiments demonstrate that DeepHunter\ncan (1) significantly boost the coverage with guidance; (2) generate useful\ntests to detect erroneous behaviors and facilitate the DNN model quality\nevaluation; (3) accurately capture potential defects during DNN quantization\nfor platform migration.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 23:07:45 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 00:49:53 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 05:36:16 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Juefei-Xu", "Felix", ""], ["Chen", "Hongxu", ""], ["Xue", "Minhui", ""], ["Li", "Bo", ""], ["Liu", "Yang", ""], ["Zhao", "Jianjun", ""], ["Yin", "Jianxiong", ""], ["See", "Simon", ""]]}, {"id": "1809.01272", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "Unsupervised Statistical Machine Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While modern machine translation has relied on large parallel corpora, a\nrecent line of work has managed to train Neural Machine Translation (NMT)\nsystems from monolingual corpora only (Artetxe et al., 2018c; Lample et al.,\n2018). Despite the potential of this approach for low-resource settings,\nexisting systems are far behind their supervised counterparts, limiting their\npractical interest. In this paper, we propose an alternative approach based on\nphrase-based Statistical Machine Translation (SMT) that significantly closes\nthe gap with supervised systems. Our method profits from the modular\narchitecture of SMT: we first induce a phrase table from monolingual corpora\nthrough cross-lingual embedding mappings, combine it with an n-gram language\nmodel, and fine-tune hyperparameters through an unsupervised MERT variant. In\naddition, iterative backtranslation improves results further, yielding, for\ninstance, 14.08 and 26.22 BLEU points in WMT 2014 English-German and\nEnglish-French, respectively, an improvement of more than 7-10 BLEU points over\nprevious unsupervised systems, and closing the gap with supervised SMT (Moses\ntrained on Europarl) down to 2-5 BLEU points. Our implementation is available\nat https://github.com/artetxem/monoses\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 23:22:28 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "1809.01293", "submitter": "Changyou Chen", "authors": "Jianyi Zhang and Ruiyi Zhang and Lawrence Carin and Changyou Chen", "title": "Stochastic Particle-Optimization Sampling and the Non-Asymptotic\n  Convergence Theory", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle-optimization-based sampling (POS) is a recently developed effective\nsampling technique that interactively updates a set of particles. A\nrepresentative algorithm is the Stein variational gradient descent (SVGD). We\nprove, under certain conditions, SVGD experiences a theoretical pitfall, {\\it\ni.e.}, particles tend to collapse. As a remedy, we generalize POS to a\nstochastic setting by injecting random noise into particle updates, thus\nyielding particle-optimization sampling (SPOS). Notably, for the first time, we\ndevelop {\\em non-asymptotic convergence theory} for the SPOS framework (related\nto SVGD), characterizing algorithm convergence in terms of the 1-Wasserstein\ndistance w.r.t.\\! the numbers of particles and iterations. Somewhat\nsurprisingly, with the same number of updates (not too large) for each\nparticle, our theory suggests adopting more particles does not necessarily lead\nto a better approximation of a target distribution, due to limited\ncomputational budget and numerical errors. This phenomenon is also observed in\nSVGD and verified via an experiment on synthetic data. Extensive experimental\nresults verify our theory and demonstrate the effectiveness of our proposed\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 01:55:28 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 02:53:58 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2019 19:45:25 GMT"}, {"version": "v4", "created": "Sat, 27 Jul 2019 02:45:30 GMT"}, {"version": "v5", "created": "Sun, 29 Mar 2020 07:44:09 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Zhang", "Jianyi", ""], ["Zhang", "Ruiyi", ""], ["Carin", "Lawrence", ""], ["Chen", "Changyou", ""]]}, {"id": "1809.01316", "submitter": "Donghyeon Kim", "authors": "Donghyeon Kim, Jinhyuk Lee, Donghee Choi, Jaehoon Choi, Jaewoo Kang", "title": "Learning User Preferences and Understanding Calendar Contexts for Event\n  Scheduling", "comments": "CIKM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With online calendar services gaining popularity worldwide, calendar data has\nbecome one of the richest context sources for understanding human behavior.\nHowever, event scheduling is still time-consuming even with the development of\nonline calendars. Although machine learning based event scheduling models have\nautomated scheduling processes to some extent, they often fail to understand\nsubtle user preferences and complex calendar contexts with event titles written\nin natural language. In this paper, we propose Neural Event Scheduling\nAssistant (NESA) which learns user preferences and understands calendar\ncontexts, directly from raw online calendars for fully automated and highly\neffective event scheduling. We leverage over 593K calendar events for NESA to\nlearn scheduling personal events, and we further utilize NESA for\nmulti-attendee event scheduling. NESA successfully incorporates deep neural\nnetworks such as Bidirectional Long Short-Term Memory, Convolutional Neural\nNetwork, and Highway Network for learning the preferences of each user and\nunderstanding calendar context based on natural languages. The experimental\nresults show that NESA significantly outperforms previous baseline models in\nterms of various evaluation metrics on both personal and multi-attendee event\nscheduling tasks. Our qualitative analysis demonstrates the effectiveness of\neach layer in NESA and learned user preferences.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 04:15:13 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 15:52:06 GMT"}, {"version": "v3", "created": "Sat, 18 Jul 2020 10:58:03 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Kim", "Donghyeon", ""], ["Lee", "Jinhyuk", ""], ["Choi", "Donghee", ""], ["Choi", "Jaehoon", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1809.01353", "submitter": "Matteo Ronchetti", "authors": "Matteo Ronchetti", "title": "IKA: Independent Kernel Approximator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new method for low rank kernel approximation called\nIKA. The main advantage of IKA is that it produces a function $\\psi(x)$ defined\nas a linear combination of arbitrarily chosen functions. In contrast the\napproximation produced by Nystr\\\"om method is a linear combination of kernel\nevaluations. The proposed method consistently outperformed Nystr\\\"om method in\na comparison on the STL-10 dataset. Numerical results are reproducible using\nthe source code available at https://gitlab.com/matteo-ronchetti/IKA\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 06:49:12 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Ronchetti", "Matteo", ""]]}, {"id": "1809.01354", "submitter": "Quan Chen", "authors": "Quan Chen, Tiezheng Ge, Yanyu Xu, Zhiqiang Zhang, Xinxin Yang, Kun Gai", "title": "Semantic Human Matting", "comments": "ACM Multimedia 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human matting, high quality extraction of humans from natural images, is\ncrucial for a wide variety of applications. Since the matting problem is\nseverely under-constrained, most previous methods require user interactions to\ntake user designated trimaps or scribbles as constraints. This user-in-the-loop\nnature makes them difficult to be applied to large scale data or time-sensitive\nscenarios. In this paper, instead of using explicit user input constraints, we\nemploy implicit semantic constraints learned from data and propose an automatic\nhuman matting algorithm (SHM). SHM is the first algorithm that learns to\njointly fit both semantic information and high quality details with deep\nnetworks. In practice, simultaneously learning both coarse semantics and fine\ndetails is challenging. We propose a novel fusion strategy which naturally\ngives a probabilistic estimation of the alpha matte. We also construct a very\nlarge dataset with high quality annotations consisting of 35,513 unique\nforegrounds to facilitate the learning and evaluation of human matting.\nExtensive experiments on this dataset and plenty of real images show that SHM\nachieves comparable results with state-of-the-art interactive matting methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 06:50:24 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 12:36:31 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Chen", "Quan", ""], ["Ge", "Tiezheng", ""], ["Xu", "Yanyu", ""], ["Zhang", "Zhiqiang", ""], ["Yang", "Xinxin", ""], ["Gai", "Kun", ""]]}, {"id": "1809.01357", "submitter": "Mike Wu", "authors": "Mike Wu, Milan Mosse, Noah Goodman, Chris Piech", "title": "Zero Shot Learning for Code Education: Rubric Sampling with Deep\n  Learning Inference", "comments": "To appear at AAAI 2019; 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern computer science education, massive open online courses (MOOCs) log\nthousands of hours of data about how students solve coding challenges. Being so\nrich in data, these platforms have garnered the interest of the machine\nlearning community, with many new algorithms attempting to autonomously provide\nfeedback to help future students learn. But what about those first hundred\nthousand students? In most educational contexts (i.e. classrooms), assignments\ndo not have enough historical data for supervised learning. In this paper, we\nintroduce a human-in-the-loop \"rubric sampling\" approach to tackle the \"zero\nshot\" feedback challenge. We are able to provide autonomous feedback for the\nfirst students working on an introductory programming assignment with accuracy\nthat substantially outperforms data-hungry algorithms and approaches human\nlevel fidelity. Rubric sampling requires minimal teacher effort, can associate\nfeedback with specific parts of a student's solution and can articulate a\nstudent's misconceptions in the language of the instructor. Deep learning\ninference enables rubric sampling to further improve as more assignment\nspecific student data is acquired. We demonstrate our results on a novel\ndataset from Code.org, the world's largest programming education platform.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 07:13:30 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 04:23:42 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Wu", "Mike", ""], ["Mosse", "Milan", ""], ["Goodman", "Noah", ""], ["Piech", "Chris", ""]]}, {"id": "1809.01369", "submitter": "Vahid Mostofi", "authors": "Vahid Mostofi, Sadegh Aliakbary", "title": "Towards quantitative methods to assess network generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing generative models is not an easy task. Generative models should\nsynthesize graphs which are not replicates of real networks but show\ntopological features similar to real graphs. We introduce an approach for\nassessing graph generative models using graph classifiers. The inability of an\nestablished graph classifier for distinguishing real and synthesized graphs\ncould be considered as a performance measurement for graph generators.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 07:56:11 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Mostofi", "Vahid", ""], ["Aliakbary", "Sadegh", ""]]}, {"id": "1809.01382", "submitter": "St\\'ephane Ga\\\"iffas", "authors": "Jaouad Mourtada, St\\'ephane Ga\\\"iffas", "title": "On the optimality of the Hedge algorithm in the stochastic regime", "comments": null, "journal-ref": "Journal of Machine Learning Research, 20(83), 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the behavior of the Hedge algorithm in the online\nstochastic setting. We prove that anytime Hedge with decreasing learning rate,\nwhich is one of the simplest algorithm for the problem of prediction with\nexpert advice, is surprisingly both worst-case optimal and adaptive to the\neasier stochastic and adversarial with a gap problems. This shows that, in\nspite of its small, non-adaptive learning rate, Hedge possesses the same\noptimal regret guarantee in the stochastic case as recently introduced adaptive\nalgorithms. Moreover, our analysis exhibits qualitative differences with other\nvariants of the Hedge algorithm, such as the fixed-horizon version (with\nconstant learning rate) and the one based on the so-called \"doubling trick\",\nboth of which fail to adapt to the easier stochastic setting. Finally, we\ndiscuss the limitations of anytime Hedge and the improvements provided by\nsecond-order regret bounds in the stochastic case.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 08:32:01 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 09:34:03 GMT"}, {"version": "v3", "created": "Mon, 8 Jul 2019 21:38:24 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Mourtada", "Jaouad", ""], ["Ga\u00efffas", "St\u00e9phane", ""]]}, {"id": "1809.01407", "submitter": "Xiaohang Zhan", "authors": "Xiaohang Zhan, Ziwei Liu, Junjie Yan, Dahua Lin, Chen Change Loy", "title": "Consensus-Driven Propagation in Massive Unlabeled Data for Face\n  Recognition", "comments": "In ECCV 2018. More details at the project page:\n  http://mmlab.ie.cuhk.edu.hk/projects/CDP/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition has witnessed great progress in recent years, mainly\nattributed to the high-capacity model designed and the abundant labeled data\ncollected. However, it becomes more and more prohibitive to scale up the\ncurrent million-level identity annotations. In this work, we show that\nunlabeled face data can be as effective as the labeled ones. Here, we consider\na setting closely mimicking the real-world scenario, where the unlabeled data\nare collected from unconstrained environments and their identities are\nexclusive from the labeled ones. Our main insight is that although the class\ninformation is not available, we can still faithfully approximate these\nsemantic relationships by constructing a relational graph in a bottom-up\nmanner. We propose Consensus-Driven Propagation (CDP) to tackle this\nchallenging problem with two modules, the \"committee\" and the \"mediator\", which\nselect positive face pairs robustly by carefully aggregating multi-view\ninformation. Extensive experiments validate the effectiveness of both modules\nto discard outliers and mine hard positives. With CDP, we achieve a compelling\naccuracy of 78.18% on MegaFace identification challenge by using only 9% of the\nlabels, comparing to 61.78% when no unlabeled data are used and 78.52% when all\nlabels are employed.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 09:41:16 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 08:43:56 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Zhan", "Xiaohang", ""], ["Liu", "Ziwei", ""], ["Yan", "Junjie", ""], ["Lin", "Dahua", ""], ["Loy", "Chen Change", ""]]}, {"id": "1809.01434", "submitter": "Arnab Karmakar", "authors": "Arnab Karmakar, Deepak Mishra, Anandmayee Tej", "title": "Stellar Cluster Detection using GMM with Deep Variational Autoencoder", "comments": "5 pages, 7 figures, under review in IEEE RAICS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.GA astro-ph.SR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting stellar clusters have always been an important research problem in\nAstronomy. Although images do not convey very detailed information in detecting\nstellar density enhancements, we attempt to understand if new machine learning\ntechniques can reveal patterns that would assist in drawing better inferences\nfrom the available image data. This paper describes an unsupervised approach in\ndetecting star clusters using Deep Variational Autoencoder combined with a\nGaussian Mixture Model. We show that our method works significantly well in\ncomparison with state-of-the-art detection algorithm in recognizing a variety\nof star clusters even in the presence of noise and distortion.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 11:06:06 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Karmakar", "Arnab", ""], ["Mishra", "Deepak", ""], ["Tej", "Anandmayee", ""]]}, {"id": "1809.01452", "submitter": "Prabod Rathnayaka", "authors": "Prabod Rathnayaka, Supun Abeysinghe, Chamod Samarajeewa, Isura\n  Manchanayake, Malaka Walpola", "title": "Sentylic at IEST 2018: Gated Recurrent Neural Network and Capsule\n  Network Based Approach for Implicit Emotion Detection", "comments": "accepted to the 9th Workshop on Computational Approaches to\n  Subjectivity, Sentiment & Social Media Analysis, part of the EMNLP 2018\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present the system we have used for the Implicit WASSA 2018\nImplicit Emotion Shared Task. The task is to predict the emotion of a tweet of\nwhich the explicit mentions of emotion terms have been removed. The idea is to\ncome up with a model which has the ability to implicitly identify the emotion\nexpressed given the context words. We have used a Gated Recurrent Neural\nNetwork (GRU) and a Capsule Network based model for the task. Pre-trained word\nembeddings have been utilized to incorporate contextual knowledge about words\ninto the model. GRU layer learns latent representations using the input word\nembeddings. Subsequent Capsule Network layer learns high-level features from\nthat hidden representation. The proposed model managed to achieve a macro-F1\nscore of 0.692.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 12:04:35 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Rathnayaka", "Prabod", ""], ["Abeysinghe", "Supun", ""], ["Samarajeewa", "Chamod", ""], ["Manchanayake", "Isura", ""], ["Walpola", "Malaka", ""]]}, {"id": "1809.01465", "submitter": "Simon Jenni", "authors": "Simon Jenni, Paolo Favaro", "title": "Deep Bilevel Learning", "comments": "ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel regularization approach to train neural networks that\nenjoys better generalization and test error than standard stochastic gradient\ndescent. Our approach is based on the principles of cross-validation, where a\nvalidation set is used to limit the model overfitting. We formulate such\nprinciples as a bilevel optimization problem. This formulation allows us to\ndefine the optimization of a cost on the validation set subject to another\noptimization on the training set. The overfitting is controlled by introducing\nweights on each mini-batch in the training set and by choosing their values so\nthat they minimize the error on the validation set. In practice, these weights\ndefine mini-batch learning rates in a gradient descent update equation that\nfavor gradients with better generalization capabilities. Because of its\nsimplicity, this approach can be integrated with other regularization methods\nand training schemes. We evaluate extensively our proposed algorithm on several\nneural network architectures and datasets, and find that it consistently\nimproves the generalization of the model, especially when labels are noisy.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 12:50:24 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Jenni", "Simon", ""], ["Favaro", "Paolo", ""]]}, {"id": "1809.01471", "submitter": "Ecem Sogancioglu", "authors": "Ecem Sogancioglu, Shi Hu, Davide Belli, Bram van Ginneken", "title": "Chest X-ray Inpainting with Deep Generative Models", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative adversarial networks have been successfully applied to inpainting\nin natural images. However, the current state-of-the-art models have not yet\nbeen widely adopted in the medical imaging domain. In this paper, we\ninvestigate the performance of three recently published deep learning based\ninpainting models: context encoders, semantic image inpainting, and the\ncontextual attention model, applied to chest x-rays, as the chest exam is the\nmost commonly performed radiological procedure. We train these generative\nmodels on 1.2M 128 $\\times$ 128 patches from 60K healthy x-rays, and learn to\npredict the center 64 $\\times$ 64 region in each patch. We test the models on\nboth the healthy and abnormal radiographs. We evaluate the results by visual\ninspection and comparing the PSNR scores. The outputs of the models are in most\ncases highly realistic. We show that the methods have potential to enhance and\ndetect abnormalities. In addition, we perform a 2AFC observer study and show\nthat an experienced human observer performs poorly in detecting inpainted\nregions, particularly those generated by the contextual attention model.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 09:21:22 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Sogancioglu", "Ecem", ""], ["Hu", "Shi", ""], ["Belli", "Davide", ""], ["van Ginneken", "Bram", ""]]}, {"id": "1809.01477", "submitter": "Sahib Singh Budhiraja", "authors": "Sahib Singh Budhiraja, Vijay Mago", "title": "A Supervised Learning Approach For Heading Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As the Portable Document Format (PDF) file format increases in popularity,\nresearch in analysing its structure for text extraction and analysis is\nnecessary. Detecting headings can be a crucial component of classifying and\nextracting meaningful data. This research involves training a supervised\nlearning model to detect headings with features carefully selected through\nrecursive feature elimination. The best performing classifier had an accuracy\nof 96.95%, sensitivity of 0.986 and a specificity of 0.953. This research into\nheading detection contributes to the field of PDF based text extraction and can\nbe applied to the automation of large scale PDF text analysis in a variety of\nprofessional and policy based contexts.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 19:31:05 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Budhiraja", "Sahib Singh", ""], ["Mago", "Vijay", ""]]}, {"id": "1809.01478", "submitter": "Yu Meng", "authors": "Yu Meng, Jiaming Shen, Chao Zhang, Jiawei Han", "title": "Weakly-Supervised Neural Text Classification", "comments": "CIKM 2018 Full Paper", "journal-ref": null, "doi": "10.1145/3269206.3271737", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are gaining increasing popularity for the classic text\nclassification task, due to their strong expressive power and less requirement\nfor feature engineering. Despite such attractiveness, neural text\nclassification models suffer from the lack of training data in many real-world\napplications. Although many semi-supervised and weakly-supervised text\nclassification models exist, they cannot be easily applied to deep neural\nmodels and meanwhile support limited supervision types. In this paper, we\npropose a weakly-supervised method that addresses the lack of training data in\nneural text classification. Our method consists of two modules: (1) a\npseudo-document generator that leverages seed information to generate\npseudo-labeled documents for model pre-training, and (2) a self-training module\nthat bootstraps on real unlabeled data for model refinement. Our method has the\nflexibility to handle different types of weak supervision and can be easily\nintegrated into existing deep neural models for text classification. We have\nperformed extensive experiments on three real-world datasets from different\ndomains. The results demonstrate that our proposed method achieves inspiring\nperformance without requiring excessive training data and outperforms baseline\nmethods significantly.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 02:56:25 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 04:34:59 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Meng", "Yu", ""], ["Shen", "Jiaming", ""], ["Zhang", "Chao", ""], ["Han", "Jiawei", ""]]}, {"id": "1809.01479", "submitter": "Andreas Hanselowski Dr.", "authors": "Andreas Hanselowski, Hao Zhang, Zile Li, Daniil Sorokin, Benjamin\n  Schiller, Claudia Schulz, Iryna Gurevych", "title": "UKP-Athene: Multi-Sentence Textual Entailment for Claim Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fact Extraction and VERification (FEVER) shared task was launched to\nsupport the development of systems able to verify claims by extracting\nsupporting or refuting facts from raw text. The shared task organizers provide\na large-scale dataset for the consecutive steps involved in claim verification,\nin particular, document retrieval, fact extraction, and claim classification.\nIn this paper, we present our claim verification pipeline approach, which,\naccording to the preliminary results, scored third in the shared task, out of\n23 competing systems. For the document retrieval, we implemented a new entity\nlinking approach. In order to be able to rank candidate facts and classify a\nclaim on the basis of several selected facts, we introduce two extensions to\nthe Enhanced LSTM (ESIM).\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 14:06:11 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 10:45:21 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2019 13:42:34 GMT"}, {"version": "v4", "created": "Wed, 8 May 2019 15:35:47 GMT"}, {"version": "v5", "created": "Thu, 9 May 2019 08:00:19 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hanselowski", "Andreas", ""], ["Zhang", "Hao", ""], ["Li", "Zile", ""], ["Sorokin", "Daniil", ""], ["Schiller", "Benjamin", ""], ["Schulz", "Claudia", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1809.01494", "submitter": "Marzieh Saeidi", "authors": "Marzieh Saeidi, Max Bartolo, Patrick Lewis, Sameer Singh, Tim\n  Rockt\\\"aschel, Mike Sheldon, Guillaume Bouchard, Sebastian Riedel", "title": "Interpretation of Natural Language Rules in Conversational Machine\n  Reading", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work in machine reading focuses on question answering problems where the\nanswer is directly expressed in the text to read. However, many real-world\nquestion answering problems require the reading of text not because it contains\nthe literal answer, but because it contains a recipe to derive an answer\ntogether with the reader's background knowledge. One example is the task of\ninterpreting regulations to answer \"Can I...?\" or \"Do I have to...?\" questions\nsuch as \"I am working in Canada. Do I have to carry on paying UK National\nInsurance?\" after reading a UK government website about this topic. This task\nrequires both the interpretation of rules and the application of background\nknowledge. It is further complicated due to the fact that, in practice, most\nquestions are underspecified, and a human assistant will regularly have to ask\nclarification questions such as \"How long have you been working abroad?\" when\nthe answer cannot be directly derived from the question and text. In this\npaper, we formalise this task and develop a crowd-sourcing strategy to collect\n32k task instances based on real-world rules and crowd-generated questions and\nscenarios. We analyse the challenges of this task and assess its difficulty by\nevaluating the performance of rule-based and machine-learning baselines. We\nobserve promising results when no background knowledge is necessary, and\nsubstantial room for improvement whenever background knowledge is needed.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 19:44:51 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Saeidi", "Marzieh", ""], ["Bartolo", "Max", ""], ["Lewis", "Patrick", ""], ["Singh", "Sameer", ""], ["Rockt\u00e4schel", "Tim", ""], ["Sheldon", "Mike", ""], ["Bouchard", "Guillaume", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1809.01495", "submitter": "Laure Soulier", "authors": "Wafa Aissa, Laure Soulier, Ludovic Denoyer", "title": "A Reinforcement Learning-driven Translation Model for Search-Oriented\n  Conversational Systems", "comments": "This is the author's pre-print version of the work. It is posted here\n  for your personal use, not for redistribution. Please cite the definitive\n  version which will be published in Proceedings of the 2018 EMNLP Workshop\n  SCAI: The 2nd International Workshop on Search-Oriented Conversational AI -\n  ISBN: 978-1-948087-75-9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search-oriented conversational systems rely on information needs expressed in\nnatural language (NL). We focus here on the understanding of NL expressions for\nbuilding keyword-based queries. We propose a reinforcement-learning-driven\ntranslation model framework able to 1) learn the translation from NL\nexpressions to queries in a supervised way, and, 2) to overcome the lack of\nlarge-scale dataset by framing the translation model as a word selection\napproach and injecting relevance feedback in the learning process. Experiments\nare carried out on two TREC datasets and outline the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 15:11:49 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Aissa", "Wafa", ""], ["Soulier", "Laure", ""], ["Denoyer", "Ludovic", ""]]}, {"id": "1809.01496", "submitter": "Jieyu Zhao", "authors": "Jieyu Zhao, Yichao Zhou, Zeyu Li, Wei Wang and Kai-Wei Chang", "title": "Learning Gender-Neutral Word Embeddings", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding models have become a fundamental component in a wide range of\nNatural Language Processing (NLP) applications. However, embeddings trained on\nhuman-generated corpora have been demonstrated to inherit strong gender\nstereotypes that reflect social constructs. To address this concern, in this\npaper, we propose a novel training procedure for learning gender-neutral word\nembeddings. Our approach aims to preserve gender information in certain\ndimensions of word vectors while compelling other dimensions to be free of\ngender influence. Based on the proposed method, we generate a Gender-Neutral\nvariant of GloVe (GN-GloVe). Quantitative and qualitative experiments\ndemonstrate that GN-GloVe successfully isolates gender information without\nsacrificing the functionality of the embedding model.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 21:11:09 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Zhao", "Jieyu", ""], ["Zhou", "Yichao", ""], ["Li", "Zeyu", ""], ["Wang", "Wei", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1809.01498", "submitter": "Benjamin Wilson", "authors": "Matthias Leimeister, Benjamin J. Wilson", "title": "Skip-gram word embeddings in hyperbolic space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has demonstrated that embeddings of tree-like graphs in\nhyperbolic space surpass their Euclidean counterparts in performance by a large\nmargin. Inspired by these results and scale-free structure in the word\nco-occurrence graph, we present an algorithm for learning word embeddings in\nhyperbolic space from free text. An objective function based on the hyperbolic\ndistance is derived and included in the skip-gram negative-sampling\narchitecture of word2vec. The hyperbolic word embeddings are then evaluated on\nword similarity and analogy benchmarks. The results demonstrate the potential\nof hyperbolic word embeddings, particularly in low dimensions, though without\nclear superiority over their Euclidean counterparts. We further discuss\nsubtleties in the formulation of the analogy task in curved spaces.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 13:54:45 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 12:36:58 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Leimeister", "Matthias", ""], ["Wilson", "Benjamin J.", ""]]}, {"id": "1809.01499", "submitter": "Samuel Carton", "authors": "Samuel Carton, Qiaozhu Mei, Paul Resnick", "title": "Extractive Adversarial Networks: High-Recall Explanations for\n  Identifying Personal Attacks in Social Media Posts", "comments": "Accepted to EMNLP 2018 Code and data available at\n  https://github.com/shcarton/rcnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an adversarial method for producing high-recall explanations of\nneural text classifier decisions. Building on an existing architecture for\nextractive explanations via hard attention, we add an adversarial layer which\nscans the residual of the attention for remaining predictive signal. Motivated\nby the important domain of detecting personal attacks in social media comments,\nwe additionally demonstrate the importance of manually setting a semantically\nappropriate `default' behavior for the model by explicitly manipulating its\nbias term. We develop a validation set of human-annotated personal attacks to\nevaluate the impact of these changes.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 00:15:30 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 20:59:09 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Carton", "Samuel", ""], ["Mei", "Qiaozhu", ""], ["Resnick", "Paul", ""]]}, {"id": "1809.01506", "submitter": "Prakhar Ganesh", "authors": "Prakhar Ganesh, Puneet Rakheja", "title": "VLSTM: Very Long Short-Term Memory Networks for High-Frequency Trading", "comments": "4 pages + 1 page references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.TR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Financial trading is at the forefront of time-series analysis, and has grown\nhand-in-hand with it. The advent of electronic trading has allowed complex\nmachine learning solutions to enter the field of financial trading. Financial\nmarkets have both long term and short term signals and thus a good predictive\nmodel in financial trading should be able to incorporate them together. One of\nthe most sought after forms of electronic trading is high-frequency trading\n(HFT), typically known for microsecond sensitive changes, which results in a\ntremendous amount of data. LSTMs are one of the most capable variants of the\nRNN family that can handle long-term dependencies, but even they are not\nequipped to handle such long sequences of the order of thousands of data points\nlike in HFT. We propose very-long short term memory networks, or VLSTMs, to\ndeal with such extreme length sequences. We explore the importance of VLSTMs in\nthe context of HFT. We compare our model on publicly available dataset and got\na 3.14\\% increase in F1-score over the existing state-of-the-art time-series\nforecasting models. We also show that our model has great parallelization\npotential, which is essential for practical purposes when trading on such\nmarkets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 13:44:12 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 09:02:39 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 13:15:45 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Ganesh", "Prakhar", ""], ["Rakheja", "Puneet", ""]]}, {"id": "1809.01534", "submitter": "Daniel Watson", "authors": "Daniel Watson, Nasser Zalmout, Nizar Habash", "title": "Utilizing Character and Word Embeddings for Text Normalization with\n  Sequence-to-Sequence Models", "comments": "Accepted in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text normalization is an important enabling technology for several NLP tasks.\nRecently, neural-network-based approaches have outperformed well-established\nmodels in this task. However, in languages other than English, there has been\nlittle exploration in this direction. Both the scarcity of annotated data and\nthe complexity of the language increase the difficulty of the problem. To\naddress these challenges, we use a sequence-to-sequence model with\ncharacter-based attention, which in addition to its self-learned character\nembeddings, uses word embeddings pre-trained with an approach that also models\nsubword information. This provides the neural model with access to more\nlinguistic information especially suitable for text normalization, without\nlarge parallel corpora. We show that providing the model with word-level\nfeatures bridges the gap for the neural network approach to achieve a\nstate-of-the-art F1 score on a standard Arabic language correction shared task\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 16:44:04 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Watson", "Daniel", ""], ["Zalmout", "Nasser", ""], ["Habash", "Nizar", ""]]}, {"id": "1809.01560", "submitter": "Victor Gallego", "authors": "Victor Gallego, Roi Naveiro, David Rios Insua", "title": "Reinforcement Learning under Threats", "comments": "Extends the verson published at the Proceedings of the AAAI\n  Conference on Artificial Intelligence 33,\n  https://www.aaai.org/ojs/index.php/AAAI/article/view/5106", "journal-ref": null, "doi": "10.1609/aaai.v33i01.33019939", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several reinforcement learning (RL) scenarios, mainly in security\nsettings, there may be adversaries trying to interfere with the reward\ngenerating process. In this paper, we introduce Threatened Markov Decision\nProcesses (TMDPs), which provide a framework to support a decision maker\nagainst a potential adversary in RL. Furthermore, we propose a level-$k$\nthinking scheme resulting in a new learning framework to deal with TMDPs. After\nintroducing our framework and deriving theoretical results, relevant empirical\nevidence is given via extensive experiments, showing the benefits of accounting\nfor adversaries while the agent learns.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 14:56:09 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 12:15:05 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Gallego", "Victor", ""], ["Naveiro", "Roi", ""], ["Insua", "David Rios", ""]]}, {"id": "1809.01564", "submitter": "Julian Nubert", "authors": "Julian Nubert, Nicholas Giai Truong, Abel Lim, Herbert Ilhan Tanujaya,\n  Leah Lim, Mai Anh Vu", "title": "Traffic Density Estimation using a Convolutional Neural Network", "comments": "Machine Learning Project National University of Singapore. 6 pages, 5\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this project is to introduce and present a machine learning\napplication that aims to improve the quality of life of people in Singapore. In\nparticular, we investigate the use of machine learning solutions to tackle the\nproblem of traffic congestion in Singapore. In layman's terms, we seek to make\nSingapore (or any other city) a smoother place. To accomplish this aim, we\npresent an end-to-end system comprising of 1. A traffic density estimation\nalgorithm at traffic lights/junctions and 2. a suitable traffic signal control\nalgorithms that make use of the density information for better traffic control.\nTraffic density estimation can be obtained from traffic junction images using\nvarious machine learning techniques (combined with CV tools). After research\ninto various advanced machine learning methods, we decided on convolutional\nneural networks (CNNs). We conducted experiments on our algorithms, using the\npublicly available traffic camera dataset published by the Land Transport\nAuthority (LTA) to demonstrate the feasibility of this approach. With these\ntraffic density estimates, different traffic algorithms can be applied to\nminimize congestion at traffic junctions in general.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 15:03:23 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Nubert", "Julian", ""], ["Truong", "Nicholas Giai", ""], ["Lim", "Abel", ""], ["Tanujaya", "Herbert Ilhan", ""], ["Lim", "Leah", ""], ["Vu", "Mai Anh", ""]]}, {"id": "1809.01571", "submitter": "Shaohan Chen", "authors": "Shaohan Chen, Chuanhou Gao", "title": "Knowledge Integrated Classifier Design Based on Utility Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a systematic framework to design a classification model\nthat yields a classifier which optimizes a utility function based on prior\nknowledge. Specifically, as the data size grows, we prove that the produced\nclassifier asymptotically converges to the optimal classifier, an extended\nversion of the Bayes rule, which maximizes the utility function. Therefore, we\nprovide a meaningful theoretical interpretation for modeling with the knowledge\nincorporated. Our knowledge incorporation method allows domain experts to guide\nthe classifier towards correctly classifying data that they think to be more\nsignificant.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 15:14:08 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Chen", "Shaohan", ""], ["Gao", "Chuanhou", ""]]}, {"id": "1809.01575", "submitter": "Heinke Hihn", "authors": "Heinke Hihn, Sebastian Gottwald, and Daniel A. Braun", "title": "Bounded Rational Decision-Making with Adaptive Neural Network Priors", "comments": "Published in ANNPR 2018: Artificial Neural Networks in Pattern\n  Recognition", "journal-ref": "Pancioni L., Schwenker F., Trentin E. (eds) Artificial Neural\n  Networks in Pattern Recognition. ANNPR 2018. Lecture Notes in Computer\n  Science, vol 11081. Springer, Cham", "doi": "10.1007/978-3-319-99978-4_17", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bounded rationality investigates utility-optimizing decision-makers with\nlimited information-processing power. In particular, information theoretic\nbounded rationality models formalize resource constraints abstractly in terms\nof relative Shannon information, namely the Kullback-Leibler Divergence between\nthe agents' prior and posterior policy. Between prior and posterior lies an\nanytime deliberation process that can be instantiated by sample-based\nevaluations of the utility function through Markov Chain Monte Carlo (MCMC)\noptimization. The most simple model assumes a fixed prior and can relate\nabstract information-theoretic processing costs to the number of sample\nevaluations. However, more advanced models would also address the question of\nlearning, that is how the prior is adapted over time such that generated prior\nproposals become more efficient. In this work we investigate generative neural\nnetworks as priors that are optimized concurrently with anytime sample-based\ndecision-making processes such as MCMC. We evaluate this approach on toy\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 08:36:09 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Hihn", "Heinke", ""], ["Gottwald", "Sebastian", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1809.01577", "submitter": "Chenguang Lu", "authors": "Chenguang Lu", "title": "From Bayesian Inference to Logical Bayesian Inference: A New\n  Mathematical Frame for Semantic Communication and Machine Learning", "comments": "12 Pages, 1 figure, 31 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Inference (BI) uses the Bayes' posterior whereas Logical Bayesian\nInference (LBI) uses the truth function or membership function as the inference\ntool. LBI was proposed because BI was not compatible with the classical Bayes'\nprediction and didn't use logical probability and hence couldn't express\nsemantic meaning. In LBI, statistical probability and logical probability are\nstrictly distinguished, used at the same time, and linked by the third kind of\nBayes' Theorem. The Shannon channel consists of a set of transition probability\nfunctions whereas the semantic channel consists of a set of truth functions.\nWhen a sample is large enough, we can directly derive the semantic channel from\nShannon's channel. Otherwise, we can use parameters to construct truth\nfunctions and use the Maximum Semantic Information (MSI) criterion to optimize\nthe truth functions. The MSI criterion is equivalent to the Maximum Likelihood\n(ML) criterion, and compatible with the Regularized Least Square (RLS)\ncriterion. By matching the two channels one with another, we can obtain the\nChannels' Matching (CM) algorithm. This algorithm can improve multi-label\nclassifications, maximum likelihood estimations (including unseen instance\nclassifications), and mixture models. In comparison with BI, LBI 1) uses the\nprior P(X) of X instead of that of Y or {\\theta} and fits cases where the\nsource P(X) changes, 2) can be used to solve the denotations of labels, and 3)\nis more compatible with the classical Bayes' prediction and likelihood method.\nLBI also provides a confirmation measure between -1 and 1 for induction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 11:39:11 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Lu", "Chenguang", ""]]}, {"id": "1809.01587", "submitter": "Minsuk Kahng", "authors": "Minsuk Kahng, Nikhil Thorat, Duen Horng Chau, Fernanda Vi\\'egas,\n  Martin Wattenberg", "title": "GAN Lab: Understanding Complex Deep Generative Models using Interactive\n  Visual Experimentation", "comments": "This paper will be published in the IEEE Transactions on\n  Visualization and Computer Graphics, 25(1), January 2019, and presented at\n  IEEE VAST 2018", "journal-ref": null, "doi": "10.1109/TVCG.2018.2864500", "report-no": null, "categories": "cs.HC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success in deep learning has generated immense interest among\npractitioners and students, inspiring many to learn about this new technology.\nWhile visual and interactive approaches have been successfully developed to\nhelp people more easily learn deep learning, most existing tools focus on\nsimpler models. In this work, we present GAN Lab, the first interactive\nvisualization tool designed for non-experts to learn and experiment with\nGenerative Adversarial Networks (GANs), a popular class of complex deep\nlearning models. With GAN Lab, users can interactively train generative models\nand visualize the dynamic training process's intermediate results. GAN Lab\ntightly integrates an model overview graph that summarizes GAN's structure, and\na layered distributions view that helps users interpret the interplay between\nsubmodels. GAN Lab introduces new interactive experimentation features for\nlearning complex deep learning models, such as step-by-step training at\nmultiple levels of abstraction for understanding intricate training dynamics.\nImplemented using TensorFlow.js, GAN Lab is accessible to anyone via modern web\nbrowsers, without the need for installation or specialized hardware, overcoming\na major practical challenge in deploying interactive tools for deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 15:51:50 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Kahng", "Minsuk", ""], ["Thorat", "Nikhil", ""], ["Chau", "Duen Horng", ""], ["Vi\u00e9gas", "Fernanda", ""], ["Wattenberg", "Martin", ""]]}, {"id": "1809.01588", "submitter": "Anna Seigal", "authors": "Max Pfeffer, Anna Seigal, Bernd Sturmfels", "title": "Learning Paths from Signature Tensors", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG math.AG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix congruence extends naturally to the setting of tensors. We apply\nmethods from tensor decomposition, algebraic geometry and numerical\noptimization to this group action. Given a tensor in the orbit of another\ntensor, we compute a matrix which transforms one to the other. Our primary\napplication is an inverse problem from stochastic analysis: the recovery of\npaths from their third order signature tensors. We establish identifiability\nresults, both exact and numerical, for piecewise linear paths, polynomial\npaths, and generic dictionaries. Numerical optimization is applied for recovery\nfrom inexact data. We also compute the shortest path with a given signature\ntensor.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 15:52:35 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 10:28:57 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Pfeffer", "Max", ""], ["Seigal", "Anna", ""], ["Sturmfels", "Bernd", ""]]}, {"id": "1809.01604", "submitter": "Julian Dolby", "authors": "Kavitha Srinivas, Abraham Gale, Julian Dolby", "title": "Merging datasets through deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Merging datasets is a key operation for data analytics. A frequent\nrequirement for merging is joining across columns that have different surface\nforms for the same entity (e.g., the name of a person might be represented as\n\"Douglas Adams\" or \"Adams, Douglas\"). Similarly, ontology alignment can require\nrecognizing distinct surface forms of the same entity, especially when\nontologies are independently developed. However, data management systems are\ncurrently limited to performing merges based on string equality, or at best\nusing string similarity. We propose an approach to performing merges based on\ndeep learning models. Our approach depends on (a) creating a deep learning\nmodel that maps surface forms of an entity into a set of vectors such that\nalternate forms for the same entity are closest in vector space, (b) indexing\nthese vectors using a nearest neighbors algorithm to find the forms that can be\npotentially joined together. To build these models, we had to adapt techniques\nfrom metric learning due to the characteristics of the data; specifically we\ndescribe novel sample selection techniques and loss functions that work for\nthis problem. To evaluate our approach, we used Wikidata as ground truth and\nbuilt models from datasets with approximately 1.1M people's names (200K\nidentities) and 130K company names (70K identities). We developed models that\nallow for joins with precision@1 of .75-.81 and recall of .74-.81. We make the\nmodels available for aligning people or companies across multiple datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 16:19:26 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Srinivas", "Kavitha", ""], ["Gale", "Abraham", ""], ["Dolby", "Julian", ""]]}, {"id": "1809.01605", "submitter": "Tadesse Zemicheal", "authors": "Thomas G. Dietterich, Tadesse Zemicheal", "title": "Anomaly Detection in the Presence of Missing Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Standard methods for anomaly detection assume that all features are observed\nat both learning time and prediction time. Such methods cannot process data\ncontaining missing values. This paper studies five strategies for handling\nmissing values in test queries: (a) mean imputation, (b) MAP imputation, (c)\nreduction (reduced-dimension anomaly detectors via feature bagging), (d)\nmarginalization (for density estimators only), and (e) proportional\ndistribution (for tree-based methods only). Our analysis suggests that MAP\nimputation and proportional distribution should give better results than mean\nimputation, reduction, and marginalization. These hypotheses are largely\nconfirmed by experimental studies on synthetic data and on anomaly detection\nbenchmark data sets using the Isolation Forest (IF), LODA, and EGMM anomaly\ndetection algorithms. However, marginalization worked surprisingly well for\nEGMM, and there are exceptions where reduction works well on some benchmark\nproblems. We recommend proportional distribution for IF, MAP imputation for\nLODA, and marginalization for EGMM.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 16:21:05 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Dietterich", "Thomas G.", ""], ["Zemicheal", "Tadesse", ""]]}, {"id": "1809.01625", "submitter": "Md Ashad Alam PhD", "authors": "Md. Ashad Alam and Mohammad Shahjama and Md. Ferdush Rahman", "title": "Gene Shaving using influence function of a kernel method", "comments": "14 pages, 6 figures, submitted to ICCIT2018, Bangladesh", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying significant subsets of the genes, gene shaving is an essential\nand challenging issue for biomedical research for a huge number of genes and\nthe complex nature of biological networks,. Since positive definite kernel\nbased methods on genomic information can improve the prediction of diseases, in\nthis paper we proposed a new method, \"kernel gene shaving (kernel canonical\ncorrelation analysis (kernel CCA) based gene shaving). This problem is\naddressed using the influence function of the kernel CCA. To investigate the\nperformance of the proposed method in a comparison of three popular gene\nselection methods (T-test, SAM and LIMMA), we were used extensive simulated and\nreal microarray gene expression datasets. The performance measures AUC was\ncomputed for each of the methods. The achievement of the proposed method has\nimproved than the three well-known gene selection methods. In real data\nanalysis, the proposed method identified a subsets of $210$ genes out of $2000$\ngenes. The network of these genes has significantly more interactions than\nexpected, which indicates that they may function in a concerted effort on colon\ncancer.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 17:09:00 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Alam", "Md. Ashad", ""], ["Shahjama", "Mohammad", ""], ["Rahman", "Md. Ferdush", ""]]}, {"id": "1809.01628", "submitter": "Mariana Souza", "authors": "Mariana A. Souza, George D. C. Cavalcanti, Rafael M. O. Cruz, Robert\n  Sabourin", "title": "Online local pool generation for dynamic classifier selection: an\n  extended version", "comments": "Extended version of the paper: M. A. Souza, G. D. Cavalcanti, R. M.\n  Cruz, R. Sabourin, Online local pool generation for dynamic classifier\n  selection, Pattern Recognition 85 (2019) 132 - 148", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Classifier Selection (DCS) techniques have difficulty in selecting\nthe most competent classifier in a pool, even when its presence is assured.\nSince the DCS techniques rely only on local data to estimate a classifier's\ncompetence, the manner in which the pool is generated could affect the choice\nof the best classifier for a given sample. That is, the global perspective in\nwhich pools are generated may not help the DCS techniques in selecting a\ncompetent classifier for samples that are likely to be mislabelled. Thus, we\npropose in this work an online pool generation method that produces a locally\naccurate pool for test samples in difficult regions of the feature space. The\ndifficulty of a given area is determined by the classification difficulty of\nthe samples in it. That way, by using classifiers that were generated in a\nlocal scope, it could be easier for the DCS techniques to select the best one\nfor the difficult samples. For the query samples in easy regions, a simple\nnearest neighbors rule is used. In the extended version of this work, a deep\nanalysis on the correlation between instance hardness and the performance of\nDCS techniques is presented. An instance hardness measure that conveys the\ndegree of local class overlap is then used to decide when the local pool is\nused in the proposed scheme. The proposed method yielded significantly greater\nrecognition rates in comparison to a Bagging-generated pool and two other\nglobal pool generation schemes for all DCS techniques evaluated. The proposed\nscheme's performance was also significantly superior to three state-of-the-art\nclassification models and statistically equivalent to five of them. Moreover,\nan extended analysis on the computational complexity of the proposed method and\nof several DS techniques is presented in this version. We also provide the\nimplementation of the proposed technique using the DESLib library on GitHub.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 17:13:02 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Souza", "Mariana A.", ""], ["Cavalcanti", "George D. C.", ""], ["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""]]}, {"id": "1809.01635", "submitter": "Andrew Bray", "authors": "Simon Couch, Zeki Kazan, Kaiyan Shi, Andrew Bray, and Adam Groce", "title": "A Differentially Private Wilcoxon Signed-Rank Test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Hypothesis tests are a crucial statistical tool for data mining and are the\nworkhorse of scientific research in many fields. Here we present a\ndifferentially private analogue of the classic Wilcoxon signed-rank hypothesis\ntest, which is used when comparing sets of paired (e.g., before-and-after) data\nvalues. We present not only a private estimate of the test statistic, but a\nmethod to accurately compute a p-value and assess statistical significance. We\nevaluate our test on both simulated and real data. Compared to the only\nexisting private test for this situation, that of Task and Clifton, we find\nthat our test requires less than half as much data to achieve the same\nstatistical power.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 17:21:52 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Couch", "Simon", ""], ["Kazan", "Zeki", ""], ["Shi", "Kaiyan", ""], ["Bray", "Andrew", ""], ["Groce", "Adam", ""]]}, {"id": "1809.01697", "submitter": "Zirui Xu", "authors": "Zirui Xu, Fuxun Yu, Chenchen Liu, Xiang Chen", "title": "HASP: A High-Performance Adaptive Mobile Security Enhancement Against\n  Malicious Speech Recognition", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, machine learning based Automatic Speech Recognition (ASR) technique\nhas widely spread in smartphones, home devices, and public facilities. As\nconvenient as this technology can be, a considerable security issue also raises\n-- the users' speech content might be exposed to malicious ASR monitoring and\ncause severe privacy leakage. In this work, we propose HASP -- a\nhigh-performance security enhancement approach to solve this security issue on\nmobile devices. Leveraging ASR systems' vulnerability to the adversarial\nexamples, HASP is designed to cast human imperceptible adversarial noises to\nreal-time speech and effectively perturb malicious ASR monitoring by increasing\nthe Word Error Rate (WER). To enhance the practical performance on mobile\ndevices, HASP is also optimized for effective adaptation to the human speech\ncharacteristics, environmental noises, and mobile computation scenarios. The\nexperiments show that HASP can achieve optimal real-time security enhancement:\nit can lead an average WER of 84.55% for perturbing the malicious ASR\nmonitoring, and the data processing speed is 15x to 40x faster compared to the\nstate-of-the-art methods. Moreover, HASP can effectively perturb various ASR\nsystems, demonstrating a strong transferability.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 00:47:50 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Xu", "Zirui", ""], ["Yu", "Fuxun", ""], ["Liu", "Chenchen", ""], ["Chen", "Xiang", ""]]}, {"id": "1809.01701", "submitter": "Athindran Ramesh Kumar", "authors": "Athindran Ramesh Kumar, Balaraman Ravindran, Anand Raghunathan", "title": "Pack and Detect: Fast Object Detection in Videos Using\n  Region-of-Interest Packing", "comments": "Proceedings of the ACM India Joint International Conference on Data\n  Science and Management of Data. 2019", "journal-ref": null, "doi": "10.1145/3297001.3297020", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Object detection in videos is an important task in computer vision for\nvarious applications such as object tracking, video summarization and video\nsearch. Although great progress has been made in improving the accuracy of\nobject detection in recent years due to the rise of deep neural networks, the\nstate-of-the-art algorithms are highly computationally intensive. In order to\naddress this challenge, we make two important observations in the context of\nvideos: (i) Objects often occupy only a small fraction of the area in each\nvideo frame, and (ii) There is a high likelihood of strong temporal correlation\nbetween consecutive frames. Based on these observations, we propose Pack and\nDetect (PaD), an approach to reduce the computational requirements of object\ndetection in videos. In PaD, only selected video frames called anchor frames\nare processed at full size. In the frames that lie between anchor frames\n(inter-anchor frames), regions of interest (ROIs) are identified based on the\ndetections in the previous frame. We propose an algorithm to pack the ROIs of\neach inter-anchor frame together into a reduced-size frame. The computational\nrequirements of the detector are reduced due to the lower size of the input. In\norder to maintain the accuracy of object detection, the proposed algorithm\nexpands the ROIs greedily to provide additional background around each object\nto the detector. PaD can use any underlying neural network architecture to\nprocess the full-size and reduced-size frames. Experiments using the ImageNet\nvideo object detection dataset indicate that PaD can potentially reduce the\nnumber of FLOPS required for a frame by $4\\times$. This leads to an overall\nincrease in throughput of $1.25\\times$ on a 2.1 GHz Intel Xeon server with a\nNVIDIA Titan X GPU at the cost of $1.1\\%$ drop in accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 19:29:34 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 21:31:47 GMT"}, {"version": "v3", "created": "Sat, 26 Jan 2019 02:46:43 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 04:44:14 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Kumar", "Athindran Ramesh", ""], ["Ravindran", "Balaraman", ""], ["Raghunathan", "Anand", ""]]}, {"id": "1809.01703", "submitter": "Lucas Vinh Tran", "authors": "Lucas Vinh Tran, Yi Tay, Shuai Zhang, Gao Cong, Xiaoli Li", "title": "HyperML: A Boosting Metric Learning Approach in Hyperbolic Space for\n  Recommender Systems", "comments": "Accepted at WSDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the notion of learning user and item representations\nin non-Euclidean space. Specifically, we study the connection between metric\nlearning in hyperbolic space and collaborative filtering by exploring Mobius\ngyrovector spaces where the formalism of the spaces could be utilized to\ngeneralize the most common Euclidean vector operations. Overall, this work aims\nto bridge the gap between Euclidean and hyperbolic geometry in recommender\nsystems through metric learning approach. We propose HyperML (Hyperbolic Metric\nLearning), a conceptually simple but highly effective model for boosting the\nperformance. Via a series of extensive experiments, we show that our proposed\nHyperML not only outperforms their Euclidean counterparts, but also achieves\nstate-of-the-art performance on multiple benchmark datasets, demonstrating the\neffectiveness of personalized recommendation in hyperbolic geometry.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 19:30:54 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 05:26:57 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2019 09:12:07 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Tran", "Lucas Vinh", ""], ["Tay", "Yi", ""], ["Zhang", "Shuai", ""], ["Cong", "Gao", ""], ["Li", "Xiaoli", ""]]}, {"id": "1809.01706", "submitter": "Niharika Gauraha", "authors": "Niharika Gauraha and Akshay Chaturvedi", "title": "A Limitation of V-Matrix based Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To estimate the conditional probability functions based on the direct problem\nsetting, V-matrix based method was proposed. We construct V-matrix based\nconstrained quadratic programming problems for which the inequality constraints\nare inconsistent. In particular, we would like to present that the constrained\nquadratic optimization problem for conditional probability estimation using\nV-matrix method may not have a consistent solution always.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 18:15:31 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Gauraha", "Niharika", ""], ["Chaturvedi", "Akshay", ""]]}, {"id": "1809.01712", "submitter": "Bhavya Kailkhura", "authors": "Gowtham Muniraju, Bhavya Kailkhura, Jayaraman J. Thiagarajan,\n  Peer-Timo Bremer, Cihan Tepedelenlioglu, Andreas Spanias", "title": "Coverage-Based Designs Improve Sample Mining and Hyper-Parameter\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling one or more effective solutions from large search spaces is a\nrecurring idea in machine learning, and sequential optimization has become a\npopular solution. Typical examples include data summarization, sample mining\nfor predictive modeling and hyper-parameter optimization. Existing solutions\nattempt to adaptively trade-off between global exploration and local\nexploitation, wherein the initial exploratory sample is critical to their\nsuccess. While discrepancy-based samples have become the de facto approach for\nexploration, results from computer graphics suggest that coverage-based\ndesigns, e.g. Poisson disk sampling, can be a superior alternative. In order to\nsuccessfully adopt coverage-based sample designs to ML applications, which were\noriginally developed for 2-d image analysis, we propose fundamental advances by\nconstructing a parameterized family of designs with provably improved coverage\ncharacteristics, and by developing algorithms for effective sample synthesis.\nUsing experiments in sample mining and hyper-parameter optimization for\nsupervised learning, we show that our approach consistently outperforms\nexisting exploratory sampling methods in both blind exploration, and sequential\nsearch with Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 19:59:38 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 23:41:03 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2019 18:21:15 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Muniraju", "Gowtham", ""], ["Kailkhura", "Bhavya", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Bremer", "Peer-Timo", ""], ["Tepedelenlioglu", "Cihan", ""], ["Spanias", "Andreas", ""]]}, {"id": "1809.01715", "submitter": "Olga Taran", "authors": "Olga Taran, Shideh Rezaeifar, Slava Voloshynovskiy", "title": "Bridging machine learning and cryptography in defence against\n  adversarial attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, deep learning algorithms have become very popular thanks\nto the achieved performance in many machine learning and computer vision tasks.\nHowever, most of the deep learning architectures are vulnerable to so called\nadversarial examples. This questions the security of deep neural networks (DNN)\nfor many security- and trust-sensitive domains. The majority of the proposed\nexisting adversarial attacks are based on the differentiability of the DNN cost\nfunction.Defence strategies are mostly based on machine learning and signal\nprocessing principles that either try to detect-reject or filter out the\nadversarial perturbations and completely neglect the classical cryptographic\ncomponent in the defence. In this work, we propose a new defence mechanism\nbased on the second Kerckhoffs's cryptographic principle which states that the\ndefence and classification algorithm are supposed to be known, but not the key.\nTo be compliant with the assumption that the attacker does not have access to\nthe secret key, we will primarily focus on a gray-box scenario and do not\naddress a white-box one. More particularly, we assume that the attacker does\nnot have direct access to the secret block, but (a) he completely knows the\nsystem architecture, (b) he has access to the data used for training and\ntesting and (c) he can observe the output of the classifier for each given\ninput. We show empirically that our system is efficient against most famous\nstate-of-the-art attacks in black-box and gray-box scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 20:16:14 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Taran", "Olga", ""], ["Rezaeifar", "Shideh", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1809.01722", "submitter": "Hau-tieng Wu", "authors": "Yu-Ting Lin, Yu-Lun Lo, Chen-Yun Lin, Hau-Tieng Wu, Martin G. Frasch", "title": "Unexpected sawtooth artifact in beat-to-beat pulse transit time measured\n  from patient monitor data", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0221319", "report-no": null, "categories": "q-bio.QM cs.LG eess.SP physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object: It is increasingly popular to collect as much data as possible in the\nhospital setting from clinical monitors for research purposes. However, in this\nsetup the data calibration issue is often not discussed and, rather, implicitly\nassumed, while the clinical monitors might not be designed for the data\nanalysis purpose. We hypothesize that this calibration issue for a secondary\nanalysis may become an important source of artifacts in patient monitor data.\nWe test an off-the-shelf integrated photoplethysmography (PPG) and\nelectrocardiogram (ECG) monitoring device for its ability to yield a reliable\npulse transit time (PTT) signal. Approach: This is a retrospective clinical\nstudy using two databases: one containing 35 subjects who underwent\nlaparoscopic cholecystectomy, another containing 22 subjects who underwent\nspontaneous breathing test in the intensive care unit. All data sets include\nrecordings of PPG and ECG using a commonly deployed patient monitor. We\ncalculated the PTT signal offline. Main Results: We report a novel constant\noscillatory pattern in the PTT signal and identify this pattern as a sawtooth\nartifact. We apply an approach based on the de-shape method to visualize,\nquantify and validate this sawtooth artifact. Significance: The PPG and ECG\nsignals not designed for the PTT evaluation may contain unwanted artifacts. The\nPTT signal should be calibrated before analysis to avoid erroneous\ninterpretation of its physiological meaning.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 17:35:09 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 14:41:54 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Lin", "Yu-Ting", ""], ["Lo", "Yu-Lun", ""], ["Lin", "Chen-Yun", ""], ["Wu", "Hau-Tieng", ""], ["Frasch", "Martin G.", ""]]}, {"id": "1809.01728", "submitter": "George Sterpu", "authors": "George Sterpu, Christian Saam, Naomi Harte", "title": "Attention-based Audio-Visual Fusion for Robust Automatic Speech\n  Recognition", "comments": "In ICMI'18, October 16-20, 2018, Boulder, CO, USA. Equation (2)\n  corrected on this version", "journal-ref": null, "doi": "10.1145/3242969.3243014", "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition can potentially benefit from the lip motion\npatterns, complementing acoustic speech to improve the overall recognition\nperformance, particularly in noise. In this paper we propose an audio-visual\nfusion strategy that goes beyond simple feature concatenation and learns to\nautomatically align the two modalities, leading to enhanced representations\nwhich increase the recognition accuracy in both clean and noisy conditions. We\ntest our strategy on the TCD-TIMIT and LRS2 datasets, designed for large\nvocabulary continuous speech recognition, applying three types of noise at\ndifferent power ratios. We also exploit state of the art Sequence-to-Sequence\narchitectures, showing that our method can be easily integrated. Results show\nrelative improvements from 7% up to 30% on TCD-TIMIT over the acoustic modality\nalone, depending on the acoustic noise level. We anticipate that the fusion\nstrategy can easily generalise to many other multimodal tasks which involve\ncorrelated modalities. Code available online on GitHub:\nhttps://github.com/georgesterpu/Sigmedia-AVSR\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 20:38:48 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 16:35:16 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 11:21:28 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Sterpu", "George", ""], ["Saam", "Christian", ""], ["Harte", "Naomi", ""]]}, {"id": "1809.01733", "submitter": "David Burth Kurka", "authors": "Eirina Bourtsoulatze, David Burth Kurka and Deniz Gunduz", "title": "Deep Joint Source-Channel Coding for Wireless Image Transmission", "comments": "To appear in IEEE Transactions on Cognitive Communications and\n  Networking", "journal-ref": null, "doi": "10.1109/TCCN.2019.2919300", "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a joint source and channel coding (JSCC) technique for wireless\nimage transmission that does not rely on explicit codes for either compression\nor error correction; instead, it directly maps the image pixel values to the\ncomplex-valued channel input symbols. We parameterize the encoder and decoder\nfunctions by two convolutional neural networks (CNNs), which are trained\njointly, and can be considered as an autoencoder with a non-trainable layer in\nthe middle that represents the noisy communication channel. Our results show\nthat the proposed deep JSCC scheme outperforms digital transmission\nconcatenating JPEG or JPEG2000 compression with a capacity achieving channel\ncode at low signal-to-noise ratio (SNR) and channel bandwidth values in the\npresence of additive white Gaussian noise (AWGN). More strikingly, deep JSCC\ndoes not suffer from the ``cliff effect'', and it provides a graceful\nperformance degradation as the channel SNR varies with respect to the SNR value\nassumed during training. In the case of a slow Rayleigh fading channel, deep\nJSCC learns noise resilient coded representations and significantly outperforms\nseparation-based digital communication at all SNR and channel bandwidth values.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 08:28:51 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2018 22:15:22 GMT"}, {"version": "v3", "created": "Sat, 16 Mar 2019 17:41:45 GMT"}, {"version": "v4", "created": "Mon, 17 Jun 2019 19:07:59 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Bourtsoulatze", "Eirina", ""], ["Kurka", "David Burth", ""], ["Gunduz", "Deniz", ""]]}, {"id": "1809.01740", "submitter": "Matthew Engelhard", "authors": "Matthew Engelhard, Hongteng Xu, Lawrence Carin, Jason A Oliver,\n  Matthew Hallyburton, F Joseph McClernon", "title": "Predicting Smoking Events with a Time-Varying Semi-Parametric Hawkes\n  Process Model", "comments": "Presented at Machine Learning for Healthcare 2018, Stanford, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health risks from cigarette smoking -- the leading cause of preventable death\nin the United States -- can be substantially reduced by quitting. Although most\nsmokers are motivated to quit, the majority of quit attempts fail. A number of\nstudies have explored the role of self-reported symptoms, physiologic\nmeasurements, and environmental context on smoking risk, but less work has\nfocused on the temporal dynamics of smoking events, including daily patterns\nand related nicotine effects. In this work, we examine these dynamics and\nimprove risk prediction by modeling smoking as a self-triggering process, in\nwhich previous smoking events modify current risk. Specifically, we fit smoking\nevents self-reported by 42 smokers to a time-varying semi-parametric Hawkes\nprocess (TV-SPHP) developed for this purpose. Results show that the TV-SPHP\nachieves superior prediction performance compared to related and existing\nmodels, with the incorporation of time-varying predictors having greatest\nbenefit over longer prediction windows. Moreover, the impact function\nillustrates previously unknown temporal dynamics of smoking, with possible\nconnections to nicotine metabolism to be explored in future work through a\nrandomized study design. By more effectively predicting smoking events and\nexploring a self-triggering component of smoking risk, this work supports\ndevelopment of novel or improved cessation interventions that aim to reduce\ndeath from smoking.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 21:37:27 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Engelhard", "Matthew", ""], ["Xu", "Hongteng", ""], ["Carin", "Lawrence", ""], ["Oliver", "Jason A", ""], ["Hallyburton", "Matthew", ""], ["McClernon", "F Joseph", ""]]}, {"id": "1809.01749", "submitter": "Mohammad Golbabaee", "authors": "Mohammad Golbabaee, Dongdong Chen, Pedro A. G\\'omez, Marion I. Menzel,\n  Mike E. Davies", "title": "Geometry of Deep Learning for Magnetic Resonance Fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current popular methods for Magnetic Resonance Fingerprint (MRF) recovery are\nbottlenecked by the heavy storage and computation requirements of a\ndictionary-matching (DM) step due to the growing size and complexity of the\nfingerprint dictionaries in multi-parametric quantitative MRI applications. In\nthis paper we study a deep learning approach to address these shortcomings.\nCoupled with a dimensionality reduction first layer, the proposed MRF-Net is\nable to reconstruct quantitative maps by saving more than 60 times in memory\nand computations required for a DM baseline. Fine-grid manifold enumeration\ni.e. the MRF dictionary is only used for training the network and not during\nimage reconstruction. We show that the MRF-Net provides a piece-wise affine\napproximation to the Bloch response manifold projection and that rather than\nmemorizing the dictionary, the network efficiently clusters this manifold and\nlearns a set of hierarchical matched-filters for affine regression of the NMR\ncharacteristics in each segment.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 22:10:16 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 20:46:12 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Golbabaee", "Mohammad", ""], ["Chen", "Dongdong", ""], ["G\u00f3mez", "Pedro A.", ""], ["Menzel", "Marion I.", ""], ["Davies", "Mike E.", ""]]}, {"id": "1809.01765", "submitter": "Tomoya Murata", "authors": "Tomoya Murata, Taiji Suzuki", "title": "Sample Efficient Stochastic Gradient Iterative Hard Thresholding Method\n  for Stochastic Sparse Linear Regression with Limited Attribute Observation", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop new stochastic gradient methods for efficiently solving sparse\nlinear regression in a partial attribute observation setting, where learners\nare only allowed to observe a fixed number of actively chosen attributes per\nexample at training and prediction times. It is shown that the methods achieve\nessentially a sample complexity of $O(1/\\varepsilon)$ to attain an error of\n$\\varepsilon$ under a variant of restricted eigenvalue condition, and the rate\nhas better dependency on the problem dimension than existing methods.\nParticularly, if the smallest magnitude of the non-zero components of the\noptimal solution is not too small, the rate of our proposed {\\it Hybrid}\nalgorithm can be boosted to near the minimax optimal sample complexity of {\\it\nfull information} algorithms. The core ideas are (i) efficient construction of\nan unbiased gradient estimator by the iterative usage of the hard thresholding\noperator for configuring an exploration algorithm; and (ii) an adaptive\ncombination of the exploration and an exploitation algorithms for quickly\nidentifying the support of the optimum and efficiently searching the optimal\nparameter in its support. Experimental results are presented to validate our\ntheoretical findings and the superiority of our proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 23:54:33 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 13:11:35 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2018 04:43:52 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Murata", "Tomoya", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1809.01771", "submitter": "Roger Stein", "authors": "Roger A. Stein, Patricia A. Jaques, Joao F. Valiati", "title": "An Analysis of Hierarchical Text Classification Using Word Embeddings", "comments": "Article accepted for publication in Information Sciences on Sep 1st,\n  2018", "journal-ref": null, "doi": "10.1016/j.ins.2018.09.001", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient distributed numerical word representation models (word embeddings)\ncombined with modern machine learning algorithms have recently yielded\nconsiderable improvement on automatic document classification tasks. However,\nthe effectiveness of such techniques has not been assessed for the hierarchical\ntext classification (HTC) yet. This study investigates the application of those\nmodels and algorithms on this specific problem by means of experimentation and\nanalysis. We trained classification models with prominent machine learning\nalgorithm implementations---fastText, XGBoost, SVM, and Keras' CNN---and\nnoticeable word embeddings generation methods---GloVe, word2vec, and\nfastText---with publicly available data and evaluated them with measures\nspecifically appropriate for the hierarchical context. FastText achieved an\n${}_{LCA}F_1$ of 0.893 on a single-labeled version of the RCV1 dataset. An\nanalysis indicates that using word embeddings and its flavors is a very\npromising approach for HTC.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 00:31:51 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Stein", "Roger A.", ""], ["Jaques", "Patricia A.", ""], ["Valiati", "Joao F.", ""]]}, {"id": "1809.01772", "submitter": "Tianle Ma", "authors": "Tianle Ma and Aidong Zhang", "title": "Multi-view Factorization AutoEncoder with Network Constraints for\n  Multi-omic Integrative Analysis", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-omic data provides multiple views of the same patients. Integrative\nanalysis of multi-omic data is crucial to elucidate the molecular underpinning\nof disease etiology. However, multi-omic data has the \"big p, small N\" problem\n(the number of features is large, but the number of samples is small), it is\nchallenging to train a complicated machine learning model from the multi-omic\ndata alone and make it generalize well. Here we propose a framework termed\nMulti-view Factorization AutoEncoder with network constraints to integrate\nmulti-omic data with domain knowledge (biological interactions networks). Our\nframework employs deep representation learning to learn feature embeddings and\npatient embeddings simultaneously, enabling us to integrate feature interaction\nnetwork and patient view similarity network constraints into the training\nobjective. The whole framework is end-to-end differentiable. We applied our\napproach to the TCGA Pan-cancer dataset and achieved satisfactory results to\npredict disease progression-free interval (PFI) and patient overall survival\n(OS) events. Code will be made publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 00:34:38 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Ma", "Tianle", ""], ["Zhang", "Aidong", ""]]}, {"id": "1809.01774", "submitter": "Mahmoud Nabil", "authors": "Mahmoud Nabil, Muhammad Ismail, Mohamed Mahmoud, Mostafa Shahin,\n  Khalid Qaraqe, Erchin Serpedin", "title": "Deep Recurrent Electricity Theft Detection in AMI Networks with Random\n  Tuning of Hyper-parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Modern smart grids rely on advanced metering infrastructure (AMI) networks\nfor monitoring and billing purposes. However, such an approach suffers from\nelectricity theft cyberattacks. Different from the existing research that\nutilizes shallow, static, and customer-specific-based electricity theft\ndetectors, this paper proposes a generalized deep recurrent neural network\n(RNN)-based electricity theft detector that can effectively thwart these\ncyberattacks. The proposed model exploits the time series nature of the\ncustomers' electricity consumption to implement a gated recurrent unit\n(GRU)-RNN, hence, improving the detection performance. In addition, the\nproposed RNN-based detector adopts a random search analysis in its learning\nstage to appropriately fine-tune its hyper-parameters. Extensive test studies\nare carried out to investigate the detector's performance using publicly\navailable real data of 107,200 energy consumption days from 200 customers.\nSimulation results demonstrate the superior performance of the proposed\ndetector compared with state-of-the-art electricity theft detectors.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 00:41:01 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Nabil", "Mahmoud", ""], ["Ismail", "Muhammad", ""], ["Mahmoud", "Mohamed", ""], ["Shahin", "Mostafa", ""], ["Qaraqe", "Khalid", ""], ["Serpedin", "Erchin", ""]]}, {"id": "1809.01797", "submitter": "Qingyun Wang", "authors": "Qingyun Wang, Xiaoman Pan, Lifu Huang, Boliang Zhang, Zhiying Jiang,\n  Heng Ji, Kevin Knight", "title": "Describing a Knowledge Base", "comments": "12 pages. Accepted by The 11th International Conference on Natural\n  Language Generation (INLG 2018) Code at\n  https://github.com/EagleW/Describing_a_Knowledge_Base", "journal-ref": null, "doi": "10.18653/v1/W18-6502", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to automatically generate natural language descriptions about an input\nstructured knowledge base (KB). We build our generation framework based on a\npointer network which can copy facts from the input KB, and add two attention\nmechanisms: (i) slot-aware attention to capture the association between a slot\ntype and its corresponding slot value; and (ii) a new \\emph{table position\nself-attention} to capture the inter-dependencies among related slots. For\nevaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we\npropose a KB reconstruction based metric by extracting a KB from the generation\noutput and comparing it with the input KB. We also create a new data set which\nincludes 106,216 pairs of structured KBs and their corresponding natural\nlanguage descriptions for two distinct entity types. Experiments show that our\napproach significantly outperforms state-of-the-art methods. The reconstructed\nKB achieves 68.8% - 72.6% F-score.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 02:56:58 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 04:36:18 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wang", "Qingyun", ""], ["Pan", "Xiaoman", ""], ["Huang", "Lifu", ""], ["Zhang", "Boliang", ""], ["Jiang", "Zhiying", ""], ["Ji", "Heng", ""], ["Knight", "Kevin", ""]]}, {"id": "1809.01804", "submitter": "Shiqi Liu", "authors": "Shiqi Liu, Jingxin Liu, Qian Zhao, Xiangyong Cao, Huibin Li, Hongying\n  Meng, Sheng Liu, Deyu Meng", "title": "Discovering Influential Factors in Variational Autoencoder", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of machine learning, it is still a critical issue to identify\nand supervise the learned representation without manually intervening or\nintuition assistance to extract useful knowledge or serve for the downstream\ntasks. In this work, we focus on supervising the influential factors extracted\nby the variational autoencoder(VAE). The VAE is proposed to learn independent\nlow dimension representation while facing the problem that sometimes pre-set\nfactors are ignored. We argue that the mutual information of the input and each\nlearned factor of the representation plays a necessary indicator of discovering\nthe influential factors. We find the VAE objective inclines to induce mutual\ninformation sparsity in factor dimension over the data intrinsic dimension and\nresults in some non-influential factors whose function on data reconstruction\ncould be ignored. We show mutual information also influences the lower bound of\nVAE's reconstruction error and downstream classification task. To make such\nindicator applicable, we design an algorithm for calculating the mutual\ninformation for VAE and prove its consistency. Experimental results on MNIST,\nCelebA and DEAP datasets show that mutual information can help determine\ninfluential factors, of which some are interpretable and can be used to further\ngeneration and classification tasks, and help discover the variant that\nconnects with emotion on DEAP dataset.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 03:33:06 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 07:39:12 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Liu", "Shiqi", ""], ["Liu", "Jingxin", ""], ["Zhao", "Qian", ""], ["Cao", "Xiangyong", ""], ["Li", "Huibin", ""], ["Meng", "Hongying", ""], ["Liu", "Sheng", ""], ["Meng", "Deyu", ""]]}, {"id": "1809.01812", "submitter": "Zhuang Ma", "authors": "Zhuang Ma, Michael Collins", "title": "Noise Contrastive Estimation and Negative Sampling for Conditional\n  Models: Consistency and Statistical Efficiency", "comments": "To appear in EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise Contrastive Estimation (NCE) is a powerful parameter estimation method\nfor log-linear models, which avoids calculation of the partition function or\nits derivatives at each training step, a computationally demanding step in many\ncases. It is closely related to negative sampling methods, now widely used in\nNLP. This paper considers NCE-based estimation of conditional models.\nConditional models are frequently encountered in practice; however there has\nnot been a rigorous theoretical analysis of NCE in this setting, and we will\nargue there are subtle but important questions when generalizing NCE to the\nconditional case. In particular, we analyze two variants of NCE for conditional\nmodels: one based on a classification objective, the other based on a ranking\nobjective. We show that the ranking-based variant of NCE gives consistent\nparameter estimates under weaker assumptions than the classification-based\nmethod; we analyze the statistical efficiency of the ranking-based and\nclassification-based variants of NCE; finally we describe experiments on\nsynthetic data and language modeling showing the effectiveness and trade-offs\nof both methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 04:11:46 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Ma", "Zhuang", ""], ["Collins", "Michael", ""]]}, {"id": "1809.01817", "submitter": "Brian Moore", "authors": "Brian E. Moore, Saiprasad Ravishankar, Raj Rao Nadakuditi, and Jeffrey\n  A. Fessler", "title": "Online Adaptive Image Reconstruction (OnAIR) Using Dictionary Models", "comments": "To appear in IEEE Transactions on Computational Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity and low-rank models have been popular for reconstructing images and\nvideos from limited or corrupted measurements. Dictionary or transform learning\nmethods are useful in applications such as denoising, inpainting, and medical\nimage reconstruction. This paper proposes a framework for online (or\ntime-sequential) adaptive reconstruction of dynamic image sequences from linear\n(typically undersampled) measurements. We model the spatiotemporal patches of\nthe underlying dynamic image sequence as sparse in a dictionary, and we\nsimultaneously estimate the dictionary and the images sequentially from\nstreaming measurements. Multiple constraints on the adapted dictionary are also\nconsidered such as a unitary matrix, or low-rank dictionary atoms that provide\nadditional efficiency or robustness. The proposed online algorithms are memory\nefficient and involve simple updates of the dictionary atoms, sparse\ncoefficients, and images. Numerical experiments demonstrate the usefulness of\nthe proposed methods in inverse problems such as video reconstruction or\ninpainting from noisy, subsampled pixels, and dynamic magnetic resonance image\nreconstruction from very limited measurements.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 04:40:50 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 06:51:29 GMT"}, {"version": "v3", "created": "Mon, 22 Jul 2019 02:43:46 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Moore", "Brian E.", ""], ["Ravishankar", "Saiprasad", ""], ["Nadakuditi", "Raj Rao", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1809.01818", "submitter": "Chin-Wei Huang", "authors": "Chin-Wei Huang, Shawn Tan, Alexandre Lacoste, Aaron Courville", "title": "Improving Explorability in Variational Inference with Annealed\n  Variational Objectives", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the advances in the representational capacity of approximate\ndistributions for variational inference, the optimization process can still\nlimit the density that is ultimately learned. We demonstrate the drawbacks of\nbiasing the true posterior to be unimodal, and introduce Annealed Variational\nObjectives (AVO) into the training of hierarchical variational methods.\nInspired by Annealed Importance Sampling, the proposed method facilitates\nlearning by incorporating energy tempering into the optimization objective. In\nour experiments, we demonstrate our method's robustness to deterministic warm\nup, and the benefits of encouraging exploration in the latent space.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 04:41:21 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 02:17:05 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 01:33:11 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Huang", "Chin-Wei", ""], ["Tan", "Shawn", ""], ["Lacoste", "Alexandre", ""], ["Courville", "Aaron", ""]]}, {"id": "1809.01819", "submitter": "Saachi Jain", "authors": "Saachi Jain, David Hallac, Rok Sosic, Jure Leskovec", "title": "MASA: Motif-Aware State Assignment in Noisy Time Series Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex systems, such as airplanes, cars, or financial markets, produce\nmultivariate time series data consisting of a large number of system\nmeasurements over a period of time. Such data can be interpreted as a sequence\nof states, where each state represents a prototype of system behavior. An\nimportant problem in this domain is to identify repeated sequences of states,\nknown as motifs. Such motifs correspond to complex behaviors that capture\ncommon sequences of state transitions. For example, in automotive data, a motif\nof \"making a turn\" might manifest as a sequence of states: slowing down,\nturning the wheel, and then speeding back up. However, discovering these motifs\nis challenging, because the individual states and state assignments are\nunknown, have different durations, and need to be jointly learned from the\nnoisy time series. Here we develop motif-aware state assignment (MASA), a\nmethod to discover common motifs in noisy time series data and leverage those\nmotifs to more robustly assign states to measurements. We formulate the problem\nof motif discovery as a large optimization problem, which we solve using an\nexpectation-maximization type approach. MASA performs well in the presence of\nnoise in the input data and is scalable to very large datasets. Experiments on\nsynthetic data show that MASA outperforms state-of-the-art baselines by up to\n38.2%, and two case studies demonstrate how our approach discovers insightful\nmotifs in the presence of noise in real-world time series data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 04:50:08 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 00:24:56 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Jain", "Saachi", ""], ["Hallac", "David", ""], ["Sosic", "Rok", ""], ["Leskovec", "Jure", ""]]}, {"id": "1809.01829", "submitter": "Paarth Neekhara", "authors": "Paarth Neekhara, Shehzeen Hussain, Shlomo Dubnov, Farinaz Koushanfar", "title": "Adversarial Reprogramming of Text Classification Neural Networks", "comments": "Published as a conference paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Reprogramming has demonstrated success in utilizing pre-trained\nneural network classifiers for alternative classification tasks without\nmodification to the original network. An adversary in such an attack scenario\ntrains an additive contribution to the inputs to repurpose the neural network\nfor the new classification task. While this reprogramming approach works for\nneural networks with a continuous input space such as that of images, it is not\ndirectly applicable to neural networks trained for tasks such as text\nclassification, where the input space is discrete. Repurposing such\nclassification networks would require the attacker to learn an adversarial\nprogram that maps inputs from one discrete space to the other. In this work, we\nintroduce a context-based vocabulary remapping model to reprogram neural\nnetworks trained on a specific sequence classification task, for a new sequence\nclassification task desired by the adversary. We propose training procedures\nfor this adversarial program in both white-box and black-box settings. We\ndemonstrate the application of our model by adversarially repurposing various\ntext-classification models including LSTM, bi-directional LSTM and CNN for\nalternate classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 05:29:46 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 11:26:02 GMT"}, {"version": "v3", "created": "Sat, 23 Feb 2019 07:49:02 GMT"}, {"version": "v4", "created": "Thu, 15 Aug 2019 05:16:18 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Neekhara", "Paarth", ""], ["Hussain", "Shehzeen", ""], ["Dubnov", "Shlomo", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1809.01833", "submitter": "Shahab Asoodeh", "authors": "Tingran Gao, Shahab Asoodeh, Yi Huang, and James Evans", "title": "Wasserstein Soft Label Propagation on Hypergraphs: Algorithm and\n  Generalization Error Bounds", "comments": "To appear in Proc. AAAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent interests of developing machine learning and data mining\nalgorithms on hypergraphs, we investigate in this paper the semi-supervised\nlearning algorithm of propagating \"soft labels\" (e.g. probability\ndistributions, class membership scores) over hypergraphs, by means of optimal\ntransportation. Borrowing insights from Wasserstein propagation on graphs\n[Solomon et al. 2014], we re-formulate the label propagation procedure as a\nmessage-passing algorithm, which renders itself naturally to a generalization\napplicable to hypergraphs through Wasserstein barycenters. Furthermore, in a\nPAC learning framework, we provide generalization error bounds for propagating\none-dimensional distributions on graphs and hypergraphs using 2-Wasserstein\ndistance, by establishing the \\textit{algorithmic stability} of the proposed\nsemi-supervised learning algorithm. These theoretical results also shed new\nlights upon deeper understandings of the Wasserstein propagation on graphs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 05:48:50 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 22:39:46 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Gao", "Tingran", ""], ["Asoodeh", "Shahab", ""], ["Huang", "Yi", ""], ["Evans", "James", ""]]}, {"id": "1809.01843", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Gal Dalal, Bruno Scherrer, Shie Mannor", "title": "How to Combine Tree-Search Methods in Reinforcement Learning", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite-horizon lookahead policies are abundantly used in Reinforcement\nLearning and demonstrate impressive empirical success. Usually, the lookahead\npolicies are implemented with specific planning methods such as Monte Carlo\nTree Search (e.g. in AlphaZero). Referring to the planning problem as tree\nsearch, a reasonable practice in these implementations is to back up the value\nonly at the leaves while the information obtained at the root is not leveraged\nother than for updating the policy. Here, we question the potency of this\napproach. Namely, the latter procedure is non-contractive in general, and its\nconvergence is not guaranteed. Our proposed enhancement is straightforward and\nsimple: use the return from the optimal tree path to back up the values at the\ndescendants of the root. This leads to a $\\gamma^h$-contracting procedure,\nwhere $\\gamma$ is the discount factor and $h$ is the tree depth. To establish\nour results, we first introduce a notion called \\emph{multiple-step greedy\nconsistency}. We then provide convergence rates for two algorithmic\ninstantiations of the above enhancement in the presence of noise injected to\nboth the tree search stage and value estimation stage.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 06:40:08 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 07:26:42 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Efroni", "Yonathan", ""], ["Dalal", "Gal", ""], ["Scherrer", "Bruno", ""], ["Mannor", "Shie", ""]]}, {"id": "1809.01845", "submitter": "Matthew Blaschko", "authors": "Maxim Berman, Matthew B. Blaschko, Amal Rannen Triki, Jiaqian Yu", "title": "Yes, IoU loss is submodular - as a function of the mispredictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is a response to [7] in which it is claimed that [13, Proposition\n11] is false. We demonstrate here that this assertion in [7] is false, and is\nbased on a misreading of the notion of set membership in [13, Proposition 11].\nWe maintain that [13, Proposition 11] is true.\n  ([7] = arXiv:1809.00593, [13] = arXiv:1512.07797)\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 06:57:36 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Berman", "Maxim", ""], ["Blaschko", "Matthew B.", ""], ["Triki", "Amal Rannen", ""], ["Yu", "Jiaqian", ""]]}, {"id": "1809.01852", "submitter": "Junyuan Shang", "authors": "Junyuan Shang, Cao Xiao, Tengfei Ma, Hongyan Li, Jimeng Sun", "title": "GAMENet: Graph Augmented MEmory Networks for Recommending Medication\n  Combination", "comments": "AAAI 2019; change the template and fix some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent progress in deep learning is revolutionizing the healthcare domain\nincluding providing solutions to medication recommendations, especially\nrecommending medication combination for patients with complex health\nconditions. Existing approaches either do not customize based on patient health\nhistory, or ignore existing knowledge on drug-drug interactions (DDI) that\nmight lead to adverse outcomes. To fill this gap, we propose the Graph\nAugmented Memory Networks (GAMENet), which integrates the drug-drug\ninteractions knowledge graph by a memory module implemented as a graph\nconvolutional networks, and models longitudinal patient records as the query.\nIt is trained end-to-end to provide safe and personalized recommendation of\nmedication combination. We demonstrate the effectiveness and safety of GAMENet\nby comparing with several state-of-the-art methods on real EHR data. GAMENet\noutperformed all baselines in all effectiveness measures, and also achieved\n3.60% DDI rate reduction from existing EHR data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 07:30:13 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 06:56:54 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 04:27:19 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Shang", "Junyuan", ""], ["Xiao", "Cao", ""], ["Ma", "Tengfei", ""], ["Li", "Hongyan", ""], ["Sun", "Jimeng", ""]]}, {"id": "1809.01859", "submitter": "Congzhe Cao", "authors": "Congzhe Cao, Duanshun Li and Ivan Fair", "title": "Deep Learning-Based Decoding for Constrained Sequence Codes", "comments": "7 pages, 6 figures, accepted by IEEE Global Communications Conference\n  Workshop - Machine learning for communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Constrained sequence codes have been widely used in modern communication and\ndata storage systems. Sequences encoded with constrained sequence codes satisfy\nconstraints imposed by the physical channel, hence enabling efficient and\nreliable transmission of coded symbols. Traditional encoding and decoding of\nconstrained sequence codes rely on table look-up, which is prone to errors that\noccur during transmission. In this paper, we introduce constrained sequence\ndecoding based on deep learning. With multiple layer perception (MLP) networks\nand convolutional neural networks (CNNs), we are able to achieve low bit error\nrates that are close to maximum a posteriori probability (MAP) decoding as well\nas improve the system throughput. Moreover, implementation of\ncapacity-achieving fixed-length codes, where the complexity is prohibitively\nhigh with table look-up decoding, becomes practical with deep learning-based\ndecoding.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 07:44:33 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Cao", "Congzhe", ""], ["Li", "Duanshun", ""], ["Fair", "Ivan", ""]]}, {"id": "1809.01887", "submitter": "Wei Wang", "authors": "Wei Wang (1) and Xucheng Li (2) ((1) Atkins (SNC-Lavalin), UK, (2)\n  Shenzhen Urban Transport Planning Center Co. Ltd, China)", "title": "Travel Speed Prediction with a Hierarchical Convolutional Neural Network\n  and Long Short-Term Memory Model Framework", "comments": "17 pages, 10 Figures, 4 Tables; To be presented in European Transport\n  Conference in Dublin, Oct 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced travel information and warning, if provided accurately, can help\nroad users avoid traffic congestion through dynamic route planning and behavior\nchange. It also enables traffic control centres mitigate the impact of\ncongestion by activating Intelligent Transport System (ITS) proactively. Deep\nlearning has become increasingly popular in recent years, following a surge of\ninnovative GPU technology, high-resolution, big datasets and thriving machine\nlearning algorithms. However, there are few examples exploiting this emerging\ntechnology to develop applications for traffic prediction. This is largely due\nto the difficulty in capturing random, seasonal, non-linear, and\nspatio-temporal correlated nature of traffic data. In this paper, we propose a\ndata-driven modelling approach with a novel hierarchical D-CLSTM-t deep\nlearning model for short-term traffic speed prediction, a framework combined\nwith convolutional neural network (CNN) and long short-term memory (LSTM)\nmodels. A deep CNN model is employed to learn the spatio-temporal traffic\npatterns of the input graphs, which are then fed into a deep LSTM model for\nsequence learning. To capture traffic seasonal variations, time of the day and\nday of the week indicators are fused with trained features. The model is\ntrained end-to-end to predict travel speed in 15 to 90 minutes in the future.\nWe compare the model performance against other baseline models including CNN,\nLGBM, LSTM, and traditional speed-flow curves. Experiment results show that the\nD-CLSTM-t outperforms other models considerably. Model tests show that speed\nupstream also responds sensibly to a sudden accident occurring downstream. Our\nD-CLSTM-t model framework is also highly scalable for future extension such as\nfor network-wide traffic prediction, which can also be improved by including\nadditional features such as weather, long term seasonality and accident\ninformation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 09:00:57 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 07:39:40 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Wang", "Wei", ""], ["Li", "Xucheng", ""]]}, {"id": "1809.01890", "submitter": "Koichi Hamada", "authors": "Koichi Hamada, Kentaro Tachibana, Tianqi Li, Hiroto Honda, Yusuke\n  Uchida", "title": "Full-body High-resolution Anime Generation with Progressive\n  Structure-conditional Generative Adversarial Networks", "comments": "Accepted to ECCV 2018 Workshop: Computer Vision for Fashion, Art and\n  Design. Project page is at https://dena.com/intl/anime-generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Progressive Structure-conditional Generative Adversarial Networks\n(PSGAN), a new framework that can generate full-body and high-resolution\ncharacter images based on structural information. Recent progress in generative\nadversarial networks with progressive training has made it possible to generate\nhigh-resolution images. However, existing approaches have limitations in\nachieving both high image quality and structural consistency at the same time.\nOur method tackles the limitations by progressively increasing the resolution\nof both generated images and structural conditions during training. In this\npaper, we empirically demonstrate the effectiveness of this method by showing\nthe comparison with existing approaches and video generation results of diverse\nanime characters at 1024x1024 based on target pose sequences. We also create a\nnovel dataset containing full-body 1024x1024 high-resolution images and exact\n2D pose keypoints using Unity 3D Avatar models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 09:09:40 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Hamada", "Koichi", ""], ["Tachibana", "Kentaro", ""], ["Li", "Tianqi", ""], ["Honda", "Hiroto", ""], ["Uchida", "Yusuke", ""]]}, {"id": "1809.01898", "submitter": "Jo\\~ao R. Campos", "authors": "Jo\\~ao R. Campos, Marco Vieira, Ernesto Costa", "title": "Propheticus: Generalizable Machine Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to recent technological developments, Machine Learning (ML), a subfield\nof Artificial Intelligence (AI), has been successfully used to process and\nextract knowledge from a variety of complex problems. However, a thorough ML\napproach is complex and highly dependent on the problem at hand. Additionally,\nimplementing the logic required to execute the experiments is no small nor\ntrivial deed, consequentially increasing the probability of faulty code which\ncan compromise the results. Propheticus is a data-driven framework which\nresults of the need for a tool that abstracts some of the inherent complexity\nof ML, whilst being easy to understand and use, as well as to adapt and expand\nto assist the user's specific needs. Propheticus systematizes and enforces\nvarious complex concepts of an ML experiment workflow, taking into account the\nnature of both the problem and the data. It contains functionalities to execute\nall the different tasks, from data preprocessing, to results analysis and\ncomparison. Notwithstanding, it can be fairly easily adapted to different\nproblems due to its flexible architecture, and customized as needed to address\nthe user's needs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 09:26:03 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Campos", "Jo\u00e3o R.", ""], ["Vieira", "Marco", ""], ["Costa", "Ernesto", ""]]}, {"id": "1809.01906", "submitter": "Felix Leibfried", "authors": "Felix Leibfried, Peter Vrancx", "title": "Model-Based Regularization for Deep Reinforcement Learning with\n  Transcoder Networks", "comments": "Presented at the NIPS Deep Reinforcement Learning Workshop, Montreal,\n  Canada, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new optimization objective for value-based deep\nreinforcement learning. We extend conventional Deep Q-Networks (DQNs) by adding\na model-learning component yielding a transcoder network. The prediction errors\nfor the model are included in the basic DQN loss as additional regularizers.\nThis augmented objective leads to a richer training signal that provides\nfeedback at every time step. Moreover, because learning an environment model\nshares a common structure with the RL problem, we hypothesize that the\nresulting objective improves both sample efficiency and performance. We\nempirically confirm our hypothesis on a range of 20 games from the Atari\nbenchmark attaining superior results over vanilla DQN without model-based\nregularization.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 09:49:18 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 13:30:16 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Leibfried", "Felix", ""], ["Vrancx", "Peter", ""]]}, {"id": "1809.01913", "submitter": "Kshitij Tiwari", "authors": "Kshitij Tiwari", "title": "Hands-on Experience with Gaussian Processes (GPs): Implementing GPs in\n  Python - I", "comments": "34 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document serves to complement our website which was developed with the\naim of exposing the students to Gaussian Processes (GPs). GPs are\nnon-parametric Bayesian regression models that are largely used by\nstatisticians and geospatial data scientists for modeling spatial data. Several\nopen source libraries spanning from Matlab [1], Python [2], R [3] etc., are\nalready available for simple plug-and-use. The objective of this handout and in\nturn the website was to allow the users to develop stand-alone GPs in Python by\nrelying on minimal external dependencies. To this end, we only use the default\npython modules and assist the users in developing their own GPs from scratch\ngiving them an in-depth knowledge of what goes on under the hood. The module\ncovers GP inference using maximum likelihood estimation (MLE) and gives\nexamples of 1D (dummy) spatial data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 10:19:50 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Tiwari", "Kshitij", ""]]}, {"id": "1809.01921", "submitter": "Shenda Hong", "authors": "Shenda Hong, Cao Xiao, Trong Nghia Hoang, Tengfei Ma, Hongyan Li,\n  Jimeng Sun", "title": "RDPD: Rich Data Helps Poor Data via Imitation", "comments": "Published in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In many situations, we need to build and deploy separate models in related\nenvironments with different data qualities. For example, an environment with\nstrong observation equipments (e.g., intensive care units) often provides\nhigh-quality multi-modal data, which are acquired from multiple sensory devices\nand have rich-feature representations. On the other hand, an environment with\npoor observation equipment (e.g., at home) only provides low-quality, uni-modal\ndata with poor-feature representations. To deploy a competitive model in a\npoor-data environment without requiring direct access to multi-modal data\nacquired from a rich-data environment, this paper develops and presents a\nknowledge distillation (KD) method (RDPD) to enhance a predictive model trained\non poor data using knowledge distilled from a high-complexity model trained on\nrich, private data. We evaluated RDPD on three real-world datasets and shown\nthat its distilled model consistently outperformed all baselines across all\ndatasets, especially achieving the greatest performance improvement over a\nmodel trained only on low-quality data by 24.56% on PR-AUC and 12.21% on\nROC-AUC, and over that of a state-of-the-art KD model by 5.91% on PR-AUC and\n4.44% on ROC-AUC.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 10:57:51 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 02:38:48 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 16:48:36 GMT"}, {"version": "v4", "created": "Sat, 24 Aug 2019 14:50:17 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hong", "Shenda", ""], ["Xiao", "Cao", ""], ["Hoang", "Trong Nghia", ""], ["Ma", "Tengfei", ""], ["Li", "Hongyan", ""], ["Sun", "Jimeng", ""]]}, {"id": "1809.01926", "submitter": "Alessio Burrello", "authors": "Alessio Burrello, Kaspar Schindler, Luca Benini, Abbas Rahimi", "title": "One-shot Learning for iEEG Seizure Detection Using End-to-end Binary\n  Operations: Local Binary Patterns with Hyperdimensional Computing", "comments": "Published as a conference paper at the IEEE BioCAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient binarized algorithm for both learning and\nclassification of human epileptic seizures from intracranial\nelectroencephalography (iEEG). The algorithm combines local binary patterns\nwith brain-inspired hyperdimensional computing to enable end-to-end learning\nand inference with binary operations. The algorithm first transforms iEEG time\nseries from each electrode into local binary pattern codes. Then atomic\nhigh-dimensional binary vectors are used to construct composite representations\nof seizures across all electrodes. For the majority of our patients (10 out of\n16), the algorithm quickly learns from one or two seizures (i.e., one-/few-shot\nlearning) and perfectly generalizes on 27 further seizures. For other patients,\nthe algorithm requires three to six seizures for learning. Overall, our\nalgorithm surpasses the state-of-the-art methods for detecting 65 novel\nseizures with higher specificity and sensitivity, and lower memory footprint.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 11:39:12 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Burrello", "Alessio", ""], ["Schindler", "Kaspar", ""], ["Benini", "Luca", ""], ["Rahimi", "Abbas", ""]]}, {"id": "1809.01962", "submitter": "Saurabh Garg", "authors": "Saurabh Garg, Tanmay Parekh, Preethi Jyothi", "title": "Code-switched Language Models Using Dual RNNs and Same-Source\n  Pretraining", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work focuses on building language models (LMs) for code-switched text.\nWe propose two techniques that significantly improve these LMs: 1) A novel\nrecurrent neural network unit with dual components that focus on each language\nin the code-switched text separately 2) Pretraining the LM using synthetic text\nfrom a generative model estimated using the training data. We demonstrate the\neffectiveness of our proposed techniques by reporting perplexities on a\nMandarin-English task and derive significant reductions in perplexity.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 13:12:27 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Garg", "Saurabh", ""], ["Parekh", "Tanmay", ""], ["Jyothi", "Preethi", ""]]}, {"id": "1809.01991", "submitter": "Fabrizio Sebastiani", "authors": "Fabrizio Sebastiani", "title": "Evaluation Measures for Quantification: An Axiomatic Approach", "comments": "36 pages, 2 figures. Submitted for publication in the Information\n  Retrieval Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification is the task of estimating, given a set $\\sigma$ of unlabelled\nitems and a set of classes $\\mathcal{C}=\\{c_{1}, \\ldots, c_{|\\mathcal{C}|}\\}$,\nthe prevalence (or `relative frequency') in $\\sigma$ of each class $c_{i}\\in\n\\mathcal{C}$. While quantification may in principle be solved by classifying\neach item in $\\sigma$ and counting how many such items have been labelled with\n$c_{i}$, it has long been shown that this `classify and count' (CC) method\nyields suboptimal quantification accuracy. As a result, quantification is no\nlonger considered a mere byproduct of classification, and has evolved as a task\nof its own. While the scientific community has devoted a lot of attention to\ndevising more accurate quantification methods, it has not devoted much to\ndiscussing what properties an \\emph{evaluation measure for quantification}\n(EMQ) should enjoy, and which EMQs should be adopted as a result. This paper\nlies down a number of interesting properties that an EMQ may or may not enjoy,\ndiscusses if (and when) each of these properties is desirable, surveys the EMQs\nthat have been used so far, and discusses whether they enjoy or not the above\nproperties. As a result of this investigation, some of the EMQs that have been\nused in the literature turn out to be severely unfit, while others emerge as\ncloser to what the quantification community actually needs. However, a\nsignificant result is that no existing EMQ satisfies all the properties\nidentified as desirable, thus indicating that more research is needed in order\nto identify (or synthesize) a truly adequate EMQ.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 13:47:53 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Sebastiani", "Fabrizio", ""]]}, {"id": "1809.01997", "submitter": "Han Xiao", "authors": "Han Xiao, Feng Wang, Jianfeng Yan, Jingyao Zheng", "title": "Dual Ask-Answer Network for Machine Reading Comprehension", "comments": "8 pages, 5 figures, 4 tables. Code is available at\n  https://github.com/hanxiao/daanet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are three modalities in the reading comprehension setting: question,\nanswer and context. The task of question answering or question generation aims\nto infer an answer or a question when given the counterpart based on context.\nWe present a novel two-way neural sequence transduction model that connects\nthree modalities, allowing it to learn two tasks simultaneously and mutually\nbenefit one another. During training, the model receives\nquestion-context-answer triplets as input and captures the cross-modal\ninteraction via a hierarchical attention process. Unlike previous joint\nlearning paradigms that leverage the duality of question generation and\nquestion answering at data level, we solve such dual tasks at the architecture\nlevel by mirroring the network structure and partially sharing components at\ndifferent layers. This enables the knowledge to be transferred from one task to\nanother, helping the model to find a general representation for each modality.\nThe evaluation on four public datasets shows that our dual-learning model\noutperforms the mono-learning counterpart as well as the state-of-the-art joint\nmodels on both question answering and question generation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 13:57:03 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 10:55:43 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Xiao", "Han", ""], ["Wang", "Feng", ""], ["Yan", "Jianfeng", ""], ["Zheng", "Jingyao", ""]]}, {"id": "1809.01999", "submitter": "David Ha", "authors": "David Ha and J\\\"urgen Schmidhuber", "title": "Recurrent World Models Facilitate Policy Evolution", "comments": "To appear at NIPS 2018, selected for an oral presentation. arXiv\n  admin note: substantial text overlap with arXiv:1803.10122", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A generative recurrent neural network is quickly trained in an unsupervised\nmanner to model popular reinforcement learning environments through compressed\nspatio-temporal representations. The world model's extracted features are fed\ninto compact and simple policies trained by evolution, achieving state of the\nart results in various environments. We also train our agent entirely inside of\nan environment generated by its own internal world model, and transfer this\npolicy back into the actual environment. Interactive version of paper at\nhttps://worldmodels.github.io\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 22:25:12 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Ha", "David", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1809.02010", "submitter": "Michael Smith", "authors": "Michael Thomas Smith, Mauricio A Alvarez, Neil D Lawrence", "title": "Gaussian Process Regression for Binned Data", "comments": "10 pages (+1 supp), 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many datasets are in the form of tables of binned data. Performing regression\non these data usually involves either reading off bin heights, ignoring data\nfrom neighbouring bins or interpolating between bins thus over or\nunderestimating the true bin integrals.\n  In this paper we propose an elegant method for performing Gaussian Process\n(GP) regression given such binned data, allowing one to make probabilistic\npredictions of the latent function which produced the binned data.\n  We look at several applications. First, for differentially private\nregression; second, to make predictions over other integrals; and third when\nthe input regions are irregularly shaped collections of polytopes.\n  In summary, our method provides an effective way of analysing binned data\nsuch that one can use more information from the histogram representation, and\nthus reconstruct a more useful and precise density for making predictions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 14:28:26 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 13:09:32 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Smith", "Michael Thomas", ""], ["Alvarez", "Mauricio A", ""], ["Lawrence", "Neil D", ""]]}, {"id": "1809.02032", "submitter": "Tristan Aumentado-Armstrong", "authors": "Tristan Aumentado-Armstrong", "title": "Latent Molecular Optimization for Targeted Therapeutic Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.BM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We devise an approach for targeted molecular design, a problem of interest in\ncomputational drug discovery: given a target protein site, we wish to generate\na chemical with both high binding affinity to the target and satisfactory\npharmacological properties. This problem is made difficult by the enormity and\ndiscreteness of the space of potential therapeutics, as well as the\ngraph-structured nature of biomolecular surface sites. Using a dataset of\nprotein-ligand complexes, we surmount these issues by extracting a signature of\nthe target site with a graph convolutional network and by encoding the discrete\nchemical into a continuous latent vector space. The latter embedding permits\ngradient-based optimization in molecular space, which we perform using learned\ndifferentiable models of binding affinity and other pharmacological properties.\nWe show that our approach is able to efficiently optimize these multiple\nobjectives and discover new molecules with potentially useful binding\nproperties, validated via docking methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 17:19:41 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Aumentado-Armstrong", "Tristan", ""]]}, {"id": "1809.02052", "submitter": "Maurizio Ferrari Dacrema", "authors": "Maurizio Ferrari Dacrema and Paolo Cremonesi", "title": "Eigenvalue analogy for confidence estimation in item-based recommender\n  systems", "comments": null, "journal-ref": "Proceedings of the Late-Breaking Results track part of the Twelfth\n  ACM Conference on Recommender Systems (RecSys 2018)", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item-item collaborative filtering (CF) models are a well known and studied\nfamily of recommender systems, however current literature does not provide any\ntheoretical explanation of the conditions under which item-based\nrecommendations will succeed or fail.\n  We investigate the existence of an ideal item-based CF method able to make\nperfect recommendations. This CF model is formalized as an eigenvalue problem,\nwhere estimated ratings are equivalent to the true (unknown) ratings multiplied\nby a user-specific eigenvalue of the similarity matrix. Preliminary experiments\nshow that the magnitude of the eigenvalue is proportional to the accuracy of\nrecommendations for that user and therefore it can provide reliable measure of\nconfidence.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 10:22:19 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 21:23:03 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Dacrema", "Maurizio Ferrari", ""], ["Cremonesi", "Paolo", ""]]}, {"id": "1809.02064", "submitter": "Lionel Blond\\'e", "authors": "Lionel Blond\\'e, Alexandros Kalousis", "title": "Sample-Efficient Imitation Learning via Generative Adversarial Nets", "comments": "Published as a conference paper for AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GAIL is a recent successful imitation learning architecture that exploits the\nadversarial training procedure introduced in GANs. Albeit successful at\ngenerating behaviours similar to those demonstrated to the agent, GAIL suffers\nfrom a high sample complexity in the number of interactions it has to carry out\nin the environment in order to achieve satisfactory performance. We\ndramatically shrink the amount of interactions with the environment necessary\nto learn well-behaved imitation policies, by up to several orders of magnitude.\nOur framework, operating in the model-free regime, exhibits a significant\nincrease in sample-efficiency over previous methods by simultaneously a)\nlearning a self-tuned adversarially-trained surrogate reward and b) leveraging\nan off-policy actor-critic architecture. We show that our approach is simple to\nimplement and that the learned agents remain remarkably stable, as shown in our\nexperiments that span a variety of continuous control tasks. Video\nvisualisations available at: \\url{https://youtu.be/-nCsqUJnRKU}.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 15:55:16 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 15:31:32 GMT"}, {"version": "v3", "created": "Fri, 8 Mar 2019 12:00:07 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Blond\u00e9", "Lionel", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1809.02066", "submitter": "Dianhui Wang", "authors": "Ming Li and Dianhui Wang", "title": "Two Dimensional Stochastic Configuration Networks for Image Data\n  Analytics", "comments": "This paper has been submitted to IEEE Transactions on Cybernetics, on\n  August 30, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic configuration networks (SCNs) as a class of randomized learner\nmodel have been successfully employed in data analytics due to its universal\napproximation capability and fast modelling property. The technical essence\nlies in stochastically configuring hidden nodes (or basis functions) based on a\nsupervisory mechanism rather than data-independent randomization as usually\nadopted for building randomized neural networks. Given image data modelling\ntasks, the use of one-dimensional SCNs potentially demolishes the spatial\ninformation of images, and may result in undesirable performance. This paper\nextends the original SCNs to two-dimensional version, termed 2DSCNs, for fast\nbuilding randomized learners with matrix-inputs. Some theoretical analyses on\nthe goodness of 2DSCNs against SCNs, including the complexity of the random\nparameter space, and the superiority of generalization, are presented.\nEmpirical results over one regression, four benchmark handwritten digits\nclassification, and two human face recognition datasets demonstrate that the\nproposed 2DSCNs perform favourably and show good potential for image data\nanalytics.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 15:59:06 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Li", "Ming", ""], ["Wang", "Dianhui", ""]]}, {"id": "1809.02069", "submitter": "Yilong Yang", "authors": "Yilong Yang, Zhuyifan Ye, Yan Su, Qianqian Zhao, Xiaoshan Li, Defang\n  Ouyang", "title": "Deep learning for in vitro prediction of pharmaceutical formulations", "comments": null, "journal-ref": null, "doi": "10.1016/j.apsb.2018.09.010", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current pharmaceutical formulation development still strongly relies on the\ntraditional trial-and-error approach by individual experiences of\npharmaceutical scientists, which is laborious, time-consuming and costly.\nRecently, deep learning has been widely applied in many challenging domains\nbecause of its important capability of automatic feature extraction. The aim of\nthis research is to use deep learning to predict pharmaceutical formulations.\nIn this paper, two different types of dosage forms were chosen as model\nsystems. Evaluation criteria suitable for pharmaceutics were applied to\nassessing the performance of the models. Moreover, an automatic dataset\nselection algorithm was developed for selecting the representative data as\nvalidation and test datasets. Six machine learning methods were compared with\ndeep learning. The result shows the accuracies of both two deep neural networks\nwere above 80% and higher than other machine learning models, which showed good\nprediction in pharmaceutical formulations. In summary, deep learning with the\nautomatic data splitting algorithm and the evaluation criteria suitable for\npharmaceutical formulation data was firstly developed for the prediction of\npharmaceutical formulations. The cross-disciplinary integration of\npharmaceutics and artificial intelligence may shift the paradigm of\npharmaceutical researches from experience-dependent studies to data-driven\nmethodologies.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 16:03:18 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Yang", "Yilong", ""], ["Ye", "Zhuyifan", ""], ["Su", "Yan", ""], ["Zhao", "Qianqian", ""], ["Li", "Xiaoshan", ""], ["Ouyang", "Defang", ""]]}, {"id": "1809.02070", "submitter": "Tianfu Wu", "authors": "Sameera Lanka and Tianfu Wu", "title": "ARCHER: Aggressive Rewards to Counter bias in Hindsight Experience\n  Replay", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay is an important technique for addressing\nsample-inefficiency in deep reinforcement learning (RL), but faces difficulty\nin learning from binary and sparse rewards due to disproportionately few\nsuccessful experiences in the replay buffer. Hindsight experience replay (HER)\nwas recently proposed to tackle this difficulty by manipulating unsuccessful\ntransitions, but in doing so, HER introduces a significant bias in the replay\nbuffer experiences and therefore achieves a suboptimal improvement in\nsample-efficiency. In this paper, we present an analysis on the source of bias\nin HER, and propose a simple and effective method to counter the bias, to most\neffectively harness the sample-efficiency provided by HER. Our method,\nmotivated by counter-factual reasoning and called ARCHER, extends HER with a\ntrade-off to make rewards calculated for hindsight experiences numerically\ngreater than real rewards. We validate our algorithm on two continuous control\nenvironments from DeepMind Control Suite - Reacher and Finger, which simulate\nmanipulation tasks with a robotic arm - in combination with various reward\nfunctions, task complexities and goal sampling strategies. Our experiments\nconsistently demonstrate that countering bias using more aggressive hindsight\nrewards increases sample efficiency, thus establishing the greater benefit of\nARCHER in RL applications with limited computing budget.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 16:08:39 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 00:31:16 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Lanka", "Sameera", ""], ["Wu", "Tianfu", ""]]}, {"id": "1809.02094", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, I\\~nigo Lopez-Gazpio, Eneko Agirre", "title": "Uncovering divergent linguistic information in word embeddings with\n  lessons for intrinsic and extrinsic evaluation", "comments": "CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the recent success of word embeddings, it has been argued that\nthere is no such thing as an ideal representation for words, as different\nmodels tend to capture divergent and often mutually incompatible aspects like\nsemantics/syntax and similarity/relatedness. In this paper, we show that each\nembedding model captures more information than directly apparent. A linear\ntransformation that adjusts the similarity order of the model without any\nexternal resource can tailor it to achieve better results in those aspects,\nproviding a new perspective on how embeddings encode divergent linguistic\ninformation. In addition, we explore the relation between intrinsic and\nextrinsic evaluation, as the effect of our transformations in downstream tasks\nis higher for unsupervised systems than for supervised ones.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 17:08:21 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Lopez-Gazpio", "I\u00f1igo", ""], ["Agirre", "Eneko", ""]]}, {"id": "1809.02104", "submitter": "Tom Goldstein", "authors": "Ali Shafahi, W. Ronny Huang, Christoph Studer, Soheil Feizi, Tom\n  Goldstein", "title": "Are adversarial examples inevitable?", "comments": null, "journal-ref": "International Conference on Learning Representations, 2019.\n  https://openreview.net/forum?id=r1lWUoA9FQ", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide range of defenses have been proposed to harden neural networks against\nadversarial attacks. However, a pattern has emerged in which the majority of\nadversarial defenses are quickly broken by new attacks. Given the lack of\nsuccess at generating robust defenses, we are led to ask a fundamental\nquestion: Are adversarial attacks inevitable? This paper analyzes adversarial\nexamples from a theoretical perspective, and identifies fundamental bounds on\nthe susceptibility of a classifier to adversarial attacks. We show that, for\ncertain classes of problems, adversarial examples are inescapable. Using\nexperiments, we explore the implications of theoretical guarantees for\nreal-world problems and discuss how factors such as dimensionality and image\ncomplexity limit a classifier's robustness against adversarial examples.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 17:26:58 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 19:34:04 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 21:18:27 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Shafahi", "Ali", ""], ["Huang", "W. Ronny", ""], ["Studer", "Christoph", ""], ["Feizi", "Soheil", ""], ["Goldstein", "Tom", ""]]}, {"id": "1809.02105", "submitter": "Yen-Yu Chang", "authors": "Yen-Yu Chang, Fan-Yun Sun, Yueh-Hua Wu, Shou-De Lin", "title": "A Memory-Network Based Solution for Multivariate Time-Series Forecasting", "comments": "8 pages, 4 figures, submitted to AAAI 2019. arXiv admin note: text\n  overlap with arXiv:1703.07015 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series forecasting is extensively studied throughout the\nyears with ubiquitous applications in areas such as finance, traffic,\nenvironment, etc. Still, concerns have been raised on traditional methods for\nincapable of modeling complex patterns or dependencies lying in real word data.\nTo address such concerns, various deep learning models, mainly Recurrent Neural\nNetwork (RNN) based methods, are proposed. Nevertheless, capturing extremely\nlong-term patterns while effectively incorporating information from other\nvariables remains a challenge for time-series forecasting. Furthermore,\nlack-of-explainability remains one serious drawback for deep neural network\nmodels. Inspired by Memory Network proposed for solving the question-answering\ntask, we propose a deep learning based model named Memory Time-series network\n(MTNet) for time series forecasting. MTNet consists of a large memory\ncomponent, three separate encoders, and an autoregressive component to train\njointly. Additionally, the attention mechanism designed enable MTNet to be\nhighly interpretable. We can easily tell which part of the historic data is\nreferenced the most.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 17:29:10 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Chang", "Yen-Yu", ""], ["Sun", "Fan-Yun", ""], ["Wu", "Yueh-Hua", ""], ["Lin", "Shou-De", ""]]}, {"id": "1809.02112", "submitter": "Yueh-Hua Wu", "authors": "Yueh-Hua Wu, Fan-Yun Sun, Yen-Yu Chang, Shou-De Lin", "title": "ANS: Adaptive Network Scaling for Deep Rectifier Reinforcement Learning\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides a thorough study on how reward scaling can affect\nperformance of deep reinforcement learning agents. In particular, we would like\nto answer the question that how does reward scaling affect non-saturating ReLU\nnetworks in RL? This question matters because ReLU is one of the most effective\nactivation functions for deep learning models. We also propose an Adaptive\nNetwork Scaling framework to find a suitable scale of the rewards during\nlearning for better performance. We conducted empirical studies to justify the\nsolution.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 17:39:18 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 03:27:13 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 08:00:32 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Wu", "Yueh-Hua", ""], ["Sun", "Fan-Yun", ""], ["Chang", "Yen-Yu", ""], ["Lin", "Shou-De", ""]]}, {"id": "1809.02121", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Matan Haroush, Nadav Merlis, Daniel J. Mankowitz and Shie\n  Mannor", "title": "Learn What Not to Learn: Action Elimination with Deep Reinforcement\n  Learning", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems (pp. 3566-3577).\n  2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning how to act when there are many available actions in each state is a\nchallenging task for Reinforcement Learning (RL) agents, especially when many\nof the actions are redundant or irrelevant. In such cases, it is sometimes\neasier to learn which actions not to take. In this work, we propose the\nAction-Elimination Deep Q-Network (AE-DQN) architecture that combines a Deep RL\nalgorithm with an Action Elimination Network (AEN) that eliminates sub-optimal\nactions. The AEN is trained to predict invalid actions, supervised by an\nexternal elimination signal provided by the environment. Simulations\ndemonstrate a considerable speedup and added robustness over vanilla DQN in\ntext-based games with over a thousand discrete actions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 17:52:41 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 08:21:20 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 14:30:13 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zahavy", "Tom", ""], ["Haroush", "Matan", ""], ["Merlis", "Nadav", ""], ["Mankowitz", "Daniel J.", ""], ["Mannor", "Shie", ""]]}, {"id": "1809.02129", "submitter": "Safa Messaoud", "authors": "Safa Messaoud, David Forsyth, Alexander G. Schwing", "title": "Structural Consistency and Controllability for Diverse Colorization", "comments": "Accepted to ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colorizing a given gray-level image is an important task in the media and\nadvertising industry. Due to the ambiguity inherent to colorization (many\nshades are often plausible), recent approaches started to explicitly model\ndiversity. However, one of the most obvious artifacts, structural\ninconsistency, is rarely considered by existing methods which predict\nchrominance independently for every pixel. To address this issue, we develop a\nconditional random field based variational auto-encoder formulation which is\nable to achieve diversity while taking into account structural consistency.\nMoreover, we introduce a controllability mecha- nism that can incorporate\nexternal constraints from diverse sources in- cluding a user interface.\nCompared to existing baselines, we demonstrate that our method obtains more\ndiverse and globally consistent coloriza- tions on the LFW, LSUN-Church and\nILSVRC-2015 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 17:59:57 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Messaoud", "Safa", ""], ["Forsyth", "David", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "1809.02130", "submitter": "Simen Eide", "authors": "Simen Eide and Ning Zhou", "title": "Deep neural network marketplace recommenders in online experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendations are broadly used in marketplaces to match users with items\nrelevant to their interests and needs. To understand user intent and tailor\nrecommendations to their needs, we use deep learning to explore various\nheterogeneous data available in marketplaces. This paper focuses on the\nchallenge of measuring recommender performance and summarizes the online\nexperiment results with several promising types of deep neural network\nrecommenders - hybrid item representation models combining features from user\nengagement and content, sequence-based models, and multi-armed bandit models\nthat optimize user engagement by re-ranking proposals from multiple submodels.\nThe recommenders are currently running in production at the leading Norwegian\nmarketplace FINN.no and serves over one million visitors everyday.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 07:56:33 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Eide", "Simen", ""], ["Zhou", "Ning", ""]]}, {"id": "1809.02131", "submitter": "Audun Mathias {\\O}ygard", "authors": "Simen Eide, Audun M. {\\O}ygard, Ning Zhou", "title": "Five lessons from building a deep neural network recommender", "comments": "Fixed typos. Removed \"staged training strategy\" result, as it will\n  vary a lot depending on how the stages are designed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation algorithms are widely adopted in marketplaces to help users\nfind the items they are looking for. The sparsity of the items by user matrix\nand the cold-start issue in marketplaces pose challenges for the off-the-shelf\nmatrix factorization based recommender systems. To understand user intent and\ntailor recommendations to their needs, we use deep learning to explore various\nheterogeneous data available in marketplaces. This paper summarizes five\nlessons we learned from experimenting with state-of-the-art deep learning\nrecommenders at the leading Norwegian marketplace FINN.no. We design a hybrid\nrecommender system that takes the user-generated contents of a marketplace\n(including text, images and meta attributes) and combines them with user\nbehavior data such as page views and messages to provide recommendations for\nmarketplace items. Among various tactics we experimented with, the following\nfive show the best impact: staged training instead of end-to-end training,\nleveraging rich user behaviors beyond page views, using user behaviors as noisy\nlabels to train embeddings, using transfer learning to solve the unbalanced\ndata problem, and using attention mechanisms in the hybrid model. This system\nis currently running with around 20% click-through-rate in production at\nFINN.no and serves over one million visitors everyday.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 08:08:42 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 20:40:58 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Eide", "Simen", ""], ["\u00d8ygard", "Audun M.", ""], ["Zhou", "Ning", ""]]}, {"id": "1809.02145", "submitter": "Alexia Jolicoeur-Martineau", "authors": "Alexia Jolicoeur-Martineau", "title": "GANs beyond divergence minimization", "comments": "Associated repository:\n  https://github.com/AlexiaJM/GANsBeyondDivergenceMin", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) can be interpreted as an adversarial\ngame between two players, a discriminator D and a generator G, in which D\nlearns to classify real from fake data and G learns to generate realistic data\nby \"fooling\" D into thinking that fake data is actually real data. Currently, a\ndominating view is that G actually learns by minimizing a divergence given that\nthe general objective function is a divergence when D is optimal. However, this\nview has been challenged due to inconsistencies between theory and practice. In\nthis paper, we discuss of the properties associated with most loss functions\nfor G (e.g., saturating/non-saturating f-GAN, LSGAN, WGAN, etc.). We show that\nthese loss functions are not divergences and do not have the same equilibrium\nas expected of divergences. This suggests that G does not need to minimize the\nsame objective function as D maximize, nor maximize the objective of D after\nswapping real data with fake data (non-saturating GAN) but can instead use a\nwide range of possible loss functions to learn to generate realistic data. We\ndefine GANs through two separate and independent D maximization and G\nminimization steps. We generalize the generator step to four new classes of\nloss functions, most of which are actual divergences (while traditional G loss\nfunctions are not). We test a wide variety of loss functions from these four\nclasses on a synthetic dataset and on CIFAR-10. We observe that most loss\nfunctions converge well and provide comparable data generation quality to\nnon-saturating GAN, LSGAN, and WGAN-GP generator loss functions, whether we use\ndivergences or non-divergences. These results suggest that GANs do not conform\nwell to the divergence minimization theory and form a much broader range of\nmodels than previously assumed.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 18:00:26 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Jolicoeur-Martineau", "Alexia", ""]]}, {"id": "1809.02153", "submitter": "Cole Hawkins", "authors": "Cole Hawkins and Zheng Zhang", "title": "Variational Bayesian Inference for Robust Streaming Tensor Factorization\n  and Completion", "comments": "ICDM 2018. arXiv admin note: substantial text overlap with\n  arXiv:1809.01265", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming tensor factorization is a powerful tool for processing high-volume\nand multi-way temporal data in Internet networks, recommender systems and\nimage/video data analysis. Existing streaming tensor factorization algorithms\nrely on least-squares data fitting and they do not possess a mechanism for\ntensor rank determination. This leaves them susceptible to outliers and\nvulnerable to over-fitting. This paper presents a Bayesian robust streaming\ntensor factorization model to identify sparse outliers, automatically determine\nthe underlying tensor rank and accurately fit low-rank structure. We implement\nour model in Matlab and compare it with existing algorithms on tensor datasets\ngenerated from dynamic MRI and Internet traffic.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 18:22:49 GMT"}, {"version": "v2", "created": "Mon, 31 Dec 2018 16:34:54 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Hawkins", "Cole", ""], ["Zhang", "Zheng", ""]]}, {"id": "1809.02154", "submitter": "Felipe Alberto Ramos Almendares", "authors": "J. B. Cabral, B. S\\'anchez, F. Ramos, S. Gurovich, P. Granitto and J.\n  Vanderplas", "title": "From FATS to feets: Further improvements to an astronomical feature\n  extraction tool based on machine learning", "comments": "accepted in Astronomy and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms are highly useful for the classification of time\nseries data in astronomy in this era of peta-scale public survey data releases.\nThese methods can facilitate the discovery of new unknown events in most\nastrophysical areas, as well as improving the analysis of samples of known\nphenomena. Machine learning algorithms use features extracted from collected\ndata as input predictive variables. A public tool called Feature Analysis for\nTime Series (FATS) has proved an excellent workhorse for feature extraction,\nparticularly light curve classification for variable objects. In this study, we\npresent a major improvement to FATS, which corrects inconvenient design\nchoices, minor details, and documentation for the re-engineering process. This\nimprovement comprises a new Python package called \"feets\", which is important\nfor future code-refactoring for astronomical software tools.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 18:23:36 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Cabral", "J. B.", ""], ["S\u00e1nchez", "B.", ""], ["Ramos", "F.", ""], ["Gurovich", "S.", ""], ["Granitto", "P.", ""], ["Vanderplas", "J.", ""]]}, {"id": "1809.02157", "submitter": "Dino Oglic", "authors": "Dino Oglic and Thomas G\\\"artner", "title": "Scalable Learning in Reproducing Kernel Krein Spaces", "comments": "The version accepted for presentation at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first mathematically complete derivation of the Nystr\\\"om\nmethod for low-rank approximation of indefinite kernels and propose an\nefficient method for finding an approximate eigendecomposition of such kernel\nmatrices. Building on this result, we devise highly scalable methods for\nlearning in reproducing kernel Kre\\u{\\i}n spaces. The devised approaches\nprovide a principled and theoretically well-founded means to tackle large scale\nlearning problems with indefinite kernels. The main motivation for our work\ncomes from problems with structured representations (e.g., graphs, strings,\ntime-series), where it is relatively easy to devise a pairwise (dis)similarity\nfunction based on intuition and/or knowledge of domain experts. Such functions\nare typically not positive definite and it is often well beyond the expertise\nof practitioners to verify this condition. The effectiveness of the devised\napproaches is evaluated empirically using indefinite kernels defined on\nstructured and vectorial data representations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 18:26:06 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 22:36:00 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Oglic", "Dino", ""], ["G\u00e4rtner", "Thomas", ""]]}, {"id": "1809.02162", "submitter": "Aryan Mokhtari", "authors": "Aryan Mokhtari and Asuman Ozdaglar and Ali Jadbabaie", "title": "Escaping Saddle Points in Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of escaping from saddle points in smooth\nnonconvex optimization problems subject to a convex set $\\mathcal{C}$. We\npropose a generic framework that yields convergence to a second-order\nstationary point of the problem, if the convex set $\\mathcal{C}$ is simple for\na quadratic objective function. Specifically, our results hold if one can find\na $\\rho$-approximate solution of a quadratic program subject to $\\mathcal{C}$\nin polynomial time, where $\\rho<1$ is a positive constant that depends on the\nstructure of the set $\\mathcal{C}$. Under this condition, we show that the\nsequence of iterates generated by the proposed framework reaches an\n$(\\epsilon,\\gamma)$-second order stationary point (SOSP) in at most\n$\\mathcal{O}(\\max\\{\\epsilon^{-2},\\rho^{-3}\\gamma^{-3}\\})$ iterations. We\nfurther characterize the overall complexity of reaching an SOSP when the convex\nset $\\mathcal{C}$ can be written as a set of quadratic constraints and the\nobjective function Hessian has a specific structure over the convex set\n$\\mathcal{C}$. Finally, we extend our results to the stochastic setting and\ncharacterize the number of stochastic gradient and Hessian evaluations to reach\nan $(\\epsilon,\\gamma)$-SOSP.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 18:34:36 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 04:33:29 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Mokhtari", "Aryan", ""], ["Ozdaglar", "Asuman", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1809.02188", "submitter": "Garrett Bernstein", "authors": "Garrett Bernstein and Daniel Sheldon", "title": "Differentially Private Bayesian Inference for Exponential Families", "comments": "NIPS 2018. Code available at\n  https://github.com/gbernstein6/private_bayesian_expfam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of private inference has been sparked by growing concern regarding\nthe analysis of data when it stems from sensitive sources. We present the first\nmethod for private Bayesian inference in exponential families that properly\naccounts for noise introduced by the privacy mechanism. It is efficient because\nit works only with sufficient statistics and not individual data. Unlike other\nmethods, it gives properly calibrated posterior beliefs in the non-asymptotic\ndata regime.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 19:40:59 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 16:31:59 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 15:22:12 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Bernstein", "Garrett", ""], ["Sheldon", "Daniel", ""]]}, {"id": "1809.02196", "submitter": "Felipe Tobar", "authors": "Felipe Tobar", "title": "Bayesian Nonparametric Spectral Estimation", "comments": "11 pages. In Advances in Neural Information Processing Systems, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral estimation (SE) aims to identify how the energy of a signal (e.g., a\ntime series) is distributed across different frequencies. This can become\nparticularly challenging when only partial and noisy observations of the signal\nare available, where current methods fail to handle uncertainty appropriately.\nIn this context, we propose a joint probabilistic model for signals,\nobservations and spectra, where SE is addressed as an exact inference problem.\nAssuming a Gaussian process prior over the signal, we apply Bayes' rule to find\nthe analytic posterior distribution of the spectrum given a set of\nobservations. Besides its expressiveness and natural account of spectral\nuncertainty, the proposed model also provides a functional-form representation\nof the power spectral density, which can be optimised efficiently. Comparison\nwith previous approaches, in particular against Lomb-Scargle, is addressed\ntheoretically and also experimentally in three different scenarios. Code and\ndemo available at https://github.com/GAMES-UChile/BayesianSpectralEstimation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 19:53:32 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 18:41:02 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Tobar", "Felipe", ""]]}, {"id": "1809.02206", "submitter": "Akshat Agarwal", "authors": "Akshat Agarwal, Ryan Hope, Katia Sycara", "title": "Challenges of Context and Time in Reinforcement Learning: Introducing\n  Space Fortress as a Benchmark", "comments": "8 pages. Code available at https://github.com/agakshat/spacefortress\n  .Supersedes arXiv:1805.06824", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in deep reinforcement learning (RL) has coalesced around improving\nperformance on benchmarks like the Arcade Learning Environment. However, these\nbenchmarks conspicuously miss important characteristics like abrupt\ncontext-dependent shifts in strategy and temporal sensitivity that are often\npresent in real-world domains. As a result, RL research has not focused on\nthese challenges, resulting in algorithms which do not understand critical\nchanges in context, and have little notion of real world time. To tackle this\nissue, this paper introduces the game of Space Fortress as a RL benchmark which\nincorporates these characteristics. We show that existing state-of-the-art RL\nalgorithms are unable to learn to play the Space Fortress game. We then confirm\nthat this poor performance is due to the RL algorithms' context insensitivity\nand reward sparsity. We also identify independent axes along which to vary\ncontext and temporal sensitivity, allowing Space Fortress to be used as a\ntestbed for understanding both characteristics in combination and also in\nisolation. We release Space Fortress as an open-source Gym environment.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 20:17:44 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Agarwal", "Akshat", ""], ["Hope", "Ryan", ""], ["Sycara", "Katia", ""]]}, {"id": "1809.02209", "submitter": "Chai Wah Wu", "authors": "Chai Wah Wu", "title": "ProdSumNet: reducing model parameters in deep neural networks via\n  product-of-sums matrix decompositions", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general framework for reducing the number of trainable model\nparameters in deep learning networks by decomposing linear operators as a\nproduct of sums of simpler linear operators. Recently proposed deep learning\narchitectures such as CNN, KFC, Dilated CNN, etc. are all subsumed in this\nframework and we illustrate other types of neural network architectures within\nthis framework. We show that good accuracy on MNIST and Fashion MNIST can be\nobtained using a relatively small number of trainable parameters. In addition,\nsince implementation of the convolutional layer is resource-heavy, we consider\nan approach in the transform domain that obviates the need for convolutional\nlayers. One of the advantages of this general framework over prior approaches\nis that the number of trainable parameters is not fixed and can be varied\narbitrarily. In particular, we illustrate the tradeoff of varying the number of\ntrainable variables and the corresponding error rate. As an example, by using\nthis decomposition on a reference CNN architecture for MNIST with over 3x10^6\ntrainable parameters, we are able to obtain an accuracy of 98.44% using only\n3554 trainable parameters.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 20:50:40 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 20:34:09 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Wu", "Chai Wah", ""]]}, {"id": "1809.02213", "submitter": "Yuan Yuan", "authors": "Yuan Yuan, Xiaojing Dong, Chen Dong, Yiwen Sun, Zhenyu Yan, Abhishek\n  Pani", "title": "Dynamic Hierarchical Empirical Bayes: A Predictive Model Applied to\n  Online Advertising", "comments": "AdKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting keywords performance, such as number of impressions, click-through\nrate (CTR), conversion rate (CVR), revenue per click (RPC), and cost per click\n(CPC), is critical for sponsored search in the online advertising industry. An\ninteresting phenomenon is that, despite the size of the overall data, the data\nare very sparse at the individual unit level. To overcome the sparsity and\nleverage hierarchical information across the data structure, we propose a\nDynamic Hierarchical Empirical Bayesian (DHEB) model that dynamically\ndetermines the hierarchy through a data-driven process and provides\nshrinkage-based estimations. Our method is also equipped with an efficient\nempirical approach to derive inferences through the hierarchy. We evaluate the\nproposed method in both simulated and real-world datasets and compare to\nseveral competitive models. The results favor the proposed method among all\ncomparisons in terms of both accuracy and efficiency. In the end, we design a\ntwo-phase system to serve prediction in real time.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 20:56:47 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Yuan", "Yuan", ""], ["Dong", "Xiaojing", ""], ["Dong", "Chen", ""], ["Sun", "Yiwen", ""], ["Yan", "Zhenyu", ""], ["Pani", "Abhishek", ""]]}, {"id": "1809.02230", "submitter": "Sai Kumar Arava", "authors": "Ning li, Sai Kumar Arava, Chen Dong, Zhenyu Yan, Abhishek Pani", "title": "Deep Neural Net with Attention for Multi-channel Multi-touch Attribution", "comments": "6 pages ; It got published in AdKDD 2018 workshop as part of KDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customers are usually exposed to online digital advertisement channels, such\nas email marketing, display advertising, paid search engine marketing, along\ntheir way to purchase or subscribe products( aka. conversion). The marketers\ntrack all the customer journey data and try to measure the effectiveness of\neach advertising channel. The inference about the influence of each channel\nplays an important role in budget allocation and inventory pricing decisions.\nSeveral simplistic rule-based strategies and data-driven algorithmic strategies\nhave been widely used in marketing field, but they do not address the issues,\nsuch as channel interaction, time dependency, user characteristics. In this\npaper, we propose a novel attribution algorithm based on deep learning to\nassess the impact of each advertising channel. We present Deep Neural Net With\nAttention multi-touch attribution model (DNAMTA) model in a supervised learning\nfashion of predicting if a series of events leads to conversion, and it leads\nus to have a deep understanding of the dynamic interaction effects between\nmedia channels. DNAMTA also incorporates user-context information, such as user\ndemographics and behavior, as control variables to reduce the estimation biases\nof media effects. We used computational experiment of large real world\nmarketing dataset to demonstrate that our proposed model is superior to\nexisting methods in both conversion prediction and media channel influence\nevaluation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 21:43:20 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["li", "Ning", ""], ["Arava", "Sai Kumar", ""], ["Dong", "Chen", ""], ["Yan", "Zhenyu", ""], ["Pani", "Abhishek", ""]]}, {"id": "1809.02233", "submitter": "Andrew Green", "authors": "Ryan Ferguson and Andrew Green", "title": "Deeply Learning Derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses deep learning to value derivatives. The approach is broadly\napplicable, and we use a call option on a basket of stocks as an example. We\nshow that the deep learning model is accurate and very fast, capable of\nproducing valuations a million times faster than traditional models. We develop\na methodology to randomly generate appropriate training data and explore the\nimpact of several parameters including layer width and depth, training data\nquality and quantity on model speed and accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 21:59:46 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 19:12:10 GMT"}, {"version": "v3", "created": "Thu, 20 Sep 2018 19:25:29 GMT"}, {"version": "v4", "created": "Wed, 17 Oct 2018 20:25:14 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Ferguson", "Ryan", ""], ["Green", "Andrew", ""]]}, {"id": "1809.02235", "submitter": "Kevin Jamieson", "authors": "Kevin Jamieson and Lalit Jain", "title": "A Bandit Approach to Multiple Testing with False Discovery Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an adaptive sampling approach for multiple testing which aims to\nmaximize statistical power while ensuring anytime false discovery control. We\nconsider $n$ distributions whose means are partitioned by whether they are\nbelow or equal to a baseline (nulls), versus above the baseline (actual\npositives). In addition, each distribution can be sequentially and repeatedly\nsampled. Inspired by the multi-armed bandit literature, we provide an algorithm\nthat takes as few samples as possible to exceed a target true positive\nproportion (i.e. proportion of actual positives discovered) while giving\nanytime control of the false discovery proportion (nulls predicted as actual\npositives). Our sample complexity results match known information theoretic\nlower bounds and through simulations we show a substantial performance\nimprovement over uniform sampling and an adaptive elimination style algorithm.\nGiven the simplicity of the approach, and its sample efficiency, the method has\npromise for wide adoption in the biological sciences, clinical testing for drug\ndiscovery, and online A/B/n testing problems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 22:08:20 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 17:57:55 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 20:35:51 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Jamieson", "Kevin", ""], ["Jain", "Lalit", ""]]}, {"id": "1809.02244", "submitter": "Razieh Nabi", "authors": "Razieh Nabi, Daniel Malinsky, Ilya Shpitser", "title": "Learning Optimal Fair Policies", "comments": null, "journal-ref": "The Thirty-sixth International Conference on Machine Learning\n  (ICML 2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic discriminatory biases present in our society influence the way\ndata is collected and stored, the way variables are defined, and the way\nscientific findings are put into practice as policy. Automated decision\nprocedures and learning algorithms applied to such data may serve to perpetuate\nexisting injustice or unfairness in our society. In this paper, we consider how\nto make optimal but fair decisions, which \"break the cycle of injustice\" by\ncorrecting for the unfair dependence of both decisions and outcomes on\nsensitive features (e.g., variables that correspond to gender, race,\ndisability, or other protected attributes). We use methods from causal\ninference and constrained optimization to learn optimal policies in a way that\naddresses multiple potential biases which afflict data analysis in sensitive\ncontexts, extending the approach of (Nabi and Shpitser 2018). Our proposal\ncomes equipped with the theoretical guarantee that the chosen fair policy will\ninduce a joint distribution for new instances that satisfies given fairness\nconstraints. We illustrate our approach with both synthetic data and real\ncriminal justice data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 22:46:49 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 17:51:33 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 19:57:39 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Nabi", "Razieh", ""], ["Malinsky", "Daniel", ""], ["Shpitser", "Ilya", ""]]}, {"id": "1809.02262", "submitter": "Yunpeng Zhao", "authors": "Yunpeng Zhao, Qing Pan and Chengan Du", "title": "Logistic Regression Augmented Community Detection for Network Data with\n  Application in Identifying Autism-Related Gene Pathways", "comments": null, "journal-ref": "Biometrics (2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When searching for gene pathways leading to specific disease outcomes,\nadditional information on gene characteristics is often available that may\nfacilitate to differentiate genes related to the disease from irrelevant\nbackground when connections involving both types of genes are observed and\ntheir relationships to the disease are unknown. We propose method to single out\nirrelevant background genes with the help of auxiliary information through a\nlogistic regression, and cluster relevant genes into cohesive groups using the\nadjacency matrix. Expectation-maximization algorithm is modified to maximize a\njoint pseudo-likelihood assuming latent indicators for relevance to the disease\nand latent group memberships as well as Poisson or multinomial distributed link\nnumbers within and between groups. A robust version allowing arbitrary linkage\npatterns within the background is further derived. Asymptotic consistency of\nlabel assignments under the stochastic blockmodel is proven. Superior\nperformance and robustness in finite samples are observed in simulation\nstudies. The proposed robust method identifies previously missed gene sets\nunderlying autism related neurological diseases using diverse data sources\nincluding de novo mutations, gene expressions and protein-protein interactions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 00:38:20 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Zhao", "Yunpeng", ""], ["Pan", "Qing", ""], ["Du", "Chengan", ""]]}, {"id": "1809.02270", "submitter": "Hong Xu", "authors": "Kexuan Sun and Shudan Zhong and Hong Xu", "title": "Learning Embeddings of Directed Networks with Text-Associated\n  Nodes---with Applications in Software Package Dependency Networks", "comments": "10 pages, 6 figures, 3 tables. 2020 BigGraphs Workshop at IEEE\n  BigData 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A network embedding consists of a vector representation for each node in the\nnetwork. Its usefulness has been shown in many real-world application domains,\nsuch as social networks and web networks. Directed networks with text\nassociated with each node, such as software package dependency networks, are\ncommonplace. However, to the best of our knowledge, their embeddings have\nhitherto not been specifically studied. In this paper, we propose PCTADW-1 and\nPCTADW-2, two algorithms based on neural networks that learn embeddings of\ndirected networks with text associated with each node. We create two new\nnode-labeled such networks: The package dependency networks in two popular\nGNU/Linux distributions, Debian and Fedora. We experimentally demonstrate that\nthe embeddings produced by our algorithms resulted in node classification with\nbetter quality than those of various baselines on these two networks. We\nobserve that there exist systematic presence of analogies (similar to those in\nword embeddings) in the network embeddings of software package dependency\nnetworks. To the best of our knowledge, this is the first time that such\nsystematic presence of analogies is observed in network and document\nembeddings. We further demonstrate that these network embeddings can be novelly\nused for better understanding software attributes, such as the development\nprocess and user interface of software, etc.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 01:33:13 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 00:04:41 GMT"}, {"version": "v3", "created": "Sat, 13 Oct 2018 07:44:24 GMT"}, {"version": "v4", "created": "Wed, 20 Feb 2019 03:15:50 GMT"}, {"version": "v5", "created": "Thu, 26 Nov 2020 09:40:25 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Sun", "Kexuan", ""], ["Zhong", "Shudan", ""], ["Xu", "Hong", ""]]}, {"id": "1809.02288", "submitter": "Longhao Yuan", "authors": "Longhao Yuan, Chao Li, Danilo Mandic, Jianting Cao, Qibin Zhao", "title": "Tensor Ring Decomposition with Rank Minimization on Latent Space: An\n  Efficient Approach for Tensor Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In tensor completion tasks, the traditional low-rank tensor decomposition\nmodels suffer from the laborious model selection problem due to their high\nmodel sensitivity. In particular, for tensor ring (TR) decomposition, the\nnumber of model possibilities grows exponentially with the tensor order, which\nmakes it rather challenging to find the optimal TR decomposition. In this\npaper, by exploiting the low-rank structure of the TR latent space, we propose\na novel tensor completion method which is robust to model selection. In\ncontrast to imposing the low-rank constraint on the data space, we introduce\nnuclear norm regularization on the latent TR factors, resulting in the\noptimization step using singular value decomposition (SVD) being performed at a\nmuch smaller scale. By leveraging the alternating direction method of\nmultipliers (ADMM) scheme, the latent TR factors with optimal rank and the\nrecovered tensor can be obtained simultaneously. Our proposed algorithm is\nshown to effectively alleviate the burden of TR-rank selection, thereby greatly\nreducing the computational cost. The extensive experimental results on both\nsynthetic and real-world data demonstrate the superior performance and\nefficiency of the proposed approach against the state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 03:05:08 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 08:03:46 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Yuan", "Longhao", ""], ["Li", "Chao", ""], ["Mandic", "Danilo", ""], ["Cao", "Jianting", ""], ["Zhao", "Qibin", ""]]}, {"id": "1809.02292", "submitter": "Daoming Lyu", "authors": "Bo Liu, Tengyang Xie, Yangyang Xu, Mohammad Ghavamzadeh, Yinlam Chow,\n  Daoming Lyu, Daesub Yoon", "title": "A Block Coordinate Ascent Algorithm for Mean-Variance Optimization", "comments": "Accepted by NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk management in dynamic decision problems is a primary concern in many\nfields, including financial investment, autonomous driving, and healthcare. The\nmean-variance function is one of the most widely used objective functions in\nrisk management due to its simplicity and interpretability. Existing algorithms\nfor mean-variance optimization are based on multi-time-scale stochastic\napproximation, whose learning rate schedules are often hard to tune, and have\nonly asymptotic convergence proof. In this paper, we develop a model-free\npolicy search framework for mean-variance optimization with finite-sample error\nbound analysis (to local optima). Our starting point is a reformulation of the\noriginal mean-variance function with its Fenchel dual, from which we propose a\nstochastic block coordinate ascent policy search algorithm. Both the asymptotic\nconvergence guarantee of the last iteration's solution and the convergence rate\nof the randomly picked solution are provided, and their applicability is\ndemonstrated on several benchmark domains.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 03:15:20 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 02:33:24 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 19:31:34 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Liu", "Bo", ""], ["Xie", "Tengyang", ""], ["Xu", "Yangyang", ""], ["Ghavamzadeh", "Mohammad", ""], ["Chow", "Yinlam", ""], ["Lyu", "Daoming", ""], ["Yoon", "Daesub", ""]]}, {"id": "1809.02302", "submitter": "Chaoyou Fu", "authors": "Chaoyou Fu, Liangchen Song, Xiang Wu, Guoli Wang, Ran He", "title": "Neurons Merging Layer: Towards Progressive Redundancy Reduction for Deep\n  Supervised Hashing", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep supervised hashing has become an active topic in information retrieval.\nIt generates hashing bits by the output neurons of a deep hashing network.\nDuring binary discretization, there often exists much redundancy between\nhashing bits that degenerates retrieval performance in terms of both storage\nand accuracy. This paper proposes a simple yet effective Neurons Merging Layer\n(NMLayer) for deep supervised hashing. A graph is constructed to represent the\nredundancy relationship between hashing bits that is used to guide the learning\nof a hashing network. Specifically, it is dynamically learned by a novel\nmechanism defined in our active and frozen phases. According to the learned\nrelationship, the NMLayer merges the redundant neurons together to balance the\nimportance of each output neuron. Moreover, multiple NMLayers are progressively\ntrained for a deep hashing network to learn a more compact hashing code from a\nlong redundant code. Extensive experiments on four datasets demonstrate that\nour proposed method outperforms state-of-the-art hashing methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 04:10:47 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 01:35:24 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 10:03:12 GMT"}, {"version": "v4", "created": "Tue, 26 Nov 2019 08:40:00 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Fu", "Chaoyou", ""], ["Song", "Liangchen", ""], ["Wu", "Xiang", ""], ["Wang", "Guoli", ""], ["He", "Ran", ""]]}, {"id": "1809.02306", "submitter": "Takashi Wada", "authors": "Takashi Wada, Tomoharu Iwata", "title": "Unsupervised Cross-lingual Word Embedding by Multilingual Neural\n  Language Models", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised method to obtain cross-lingual embeddings without\nany parallel data or pre-trained word embeddings. The proposed model, which we\ncall multilingual neural language models, takes sentences of multiple languages\nas an input. The proposed model contains bidirectional LSTMs that perform as\nforward and backward language models, and these networks are shared among all\nthe languages. The other parameters, i.e. word embeddings and linear\ntransformation between hidden states and outputs, are specific to each\nlanguage. The shared LSTMs can capture the common sentence structure among all\nlanguages. Accordingly, word embeddings of each language are mapped into a\ncommon latent space, making it possible to measure the similarity of words\nacross multiple languages. We evaluate the quality of the cross-lingual word\nembeddings on a word alignment task. Our experiments demonstrate that our model\ncan obtain cross-lingual embeddings of much higher quality than existing\nunsupervised models when only a small amount of monolingual data (i.e. 50k\nsentences) are available, or the domains of monolingual data are different\nacross languages.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 04:17:40 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Wada", "Takashi", ""], ["Iwata", "Tomoharu", ""]]}, {"id": "1809.02314", "submitter": "Kaito Fujii", "authors": "Kaito Fujii and Tasuku Soma", "title": "Fast greedy algorithms for dictionary selection with generalized\n  sparsity constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dictionary selection, several atoms are selected from finite candidates\nthat successfully approximate given data points in the sparse representation.\nWe propose a novel efficient greedy algorithm for dictionary selection. Not\nonly does our algorithm work much faster than the known methods, but it can\nalso handle more complex sparsity constraints, such as average sparsity. Using\nnumerical experiments, we show that our algorithm outperforms the known methods\nfor dictionary selection, achieving competitive performances with dictionary\nlearning algorithms in a smaller running time.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 05:20:12 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Fujii", "Kaito", ""], ["Soma", "Tasuku", ""]]}, {"id": "1809.02322", "submitter": "Dmitrii Marin", "authors": "Dmitrii Marin and Meng Tang and Ismail Ben Ayed and Yuri Boykov", "title": "Beyond Gradient Descent for Regularized Segmentation Losses", "comments": "https://github.com/dmitrii-marin/adm-seg", "journal-ref": "In IEEE conference on Computer Vision and Pattern Recognition\n  (CVPR), Long Beach, CA, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simplicity of gradient descent (GD) made it the default method for\ntraining ever-deeper and complex neural networks. Both loss functions and\narchitectures are often explicitly tuned to be amenable to this basic local\noptimization. In the context of weakly-supervised CNN segmentation, we\ndemonstrate a well-motivated loss function where an alternative optimizer (ADM)\nachieves the state-of-the-art while GD performs poorly. Interestingly, GD\nobtains its best result for a \"smoother\" tuning of the loss function. The\nresults are consistent across different network architectures. Our loss is\nmotivated by well-understood MRF/CRF regularization models in \"shallow\"\nsegmentation and their known global solvers. Our work suggests that network\ndesign/training should pay more attention to optimization methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 06:41:17 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 15:56:13 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Marin", "Dmitrii", ""], ["Tang", "Meng", ""], ["Ayed", "Ismail Ben", ""], ["Boykov", "Yuri", ""]]}, {"id": "1809.02337", "submitter": "Bj\\\"orn Barz", "authors": "Bj\\\"orn Barz, Christoph K\\\"ading, Joachim Denzler", "title": "Information-Theoretic Active Learning for Content-Based Image Retrieval", "comments": "GCPR 2018 paper (14 pages text + 2 pages references + 6 pages\n  appendix)", "journal-ref": "Pattern Recognition. GCPR 2018. Lecture Notes in Computer Science,\n  vol 11269, pp. 650-666", "doi": "10.1007/978-3-030-12939-2_45", "report-no": null, "categories": "cs.CV cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Information-Theoretic Active Learning (ITAL), a novel batch-mode\nactive learning method for binary classification, and apply it for acquiring\nmeaningful user feedback in the context of content-based image retrieval.\nInstead of combining different heuristics such as uncertainty, diversity, or\ndensity, our method is based on maximizing the mutual information between the\npredicted relevance of the images and the expected user feedback regarding the\nselected batch. We propose suitable approximations to this computationally\ndemanding problem and also integrate an explicit model of user behavior that\naccounts for possible incorrect labels and unnameable instances. Furthermore,\nour approach does not only take the structure of the data but also the expected\nmodel output change caused by the user feedback into account. In contrast to\nother methods, ITAL turns out to be highly flexible and provides\nstate-of-the-art performance across various datasets, such as MIRFLICKR and\nImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 07:57:26 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 15:19:35 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Barz", "Bj\u00f6rn", ""], ["K\u00e4ding", "Christoph", ""], ["Denzler", "Joachim", ""]]}, {"id": "1809.02341", "submitter": "Zhize Li", "authors": "Zhize Li, Jian Li", "title": "A Fast Anderson-Chebyshev Acceleration for Nonlinear Optimization", "comments": "To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anderson acceleration (or Anderson mixing) is an efficient acceleration\nmethod for fixed point iterations $x_{t+1}=G(x_t)$, e.g., gradient descent can\nbe viewed as iteratively applying the operation $G(x) \\triangleq x-\\alpha\\nabla\nf(x)$. It is known that Anderson acceleration is quite efficient in practice\nand can be viewed as an extension of Krylov subspace methods for nonlinear\nproblems. In this paper, we show that Anderson acceleration with Chebyshev\npolynomial can achieve the optimal convergence rate\n$O(\\sqrt{\\kappa}\\ln\\frac{1}{\\epsilon})$, which improves the previous result\n$O(\\kappa\\ln\\frac{1}{\\epsilon})$ provided by (Toth and Kelley, 2015) for\nquadratic functions. Moreover, we provide a convergence analysis for minimizing\ngeneral nonlinear problems. Besides, if the hyperparameters (e.g., the\nLipschitz smooth parameter $L$) are not available, we propose a guessing\nalgorithm for guessing them dynamically and also prove a similar convergence\nrate. Finally, the experimental results demonstrate that the proposed\nAnderson-Chebyshev acceleration method converges significantly faster than\nother algorithms, e.g., vanilla gradient descent (GD), Nesterov's Accelerated\nGD. Also, these algorithms combined with the proposed guessing algorithm\n(guessing the hyperparameters dynamically) achieve much better performance.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 08:12:56 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 13:30:50 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2019 17:51:19 GMT"}, {"version": "v4", "created": "Sun, 1 Mar 2020 13:47:58 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Li", "Zhize", ""], ["Li", "Jian", ""]]}, {"id": "1809.02352", "submitter": "Willem Waegeman", "authors": "Willem Waegeman, Krzysztof Dembczynski, Eyke Huellermeier", "title": "Multi-Target Prediction: A Unifying View on Problems and Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-target prediction (MTP) is concerned with the simultaneous prediction\nof multiple target variables of diverse type. Due to its enormous application\npotential, it has developed into an active and rapidly expanding research field\nthat combines several subfields of machine learning, including multivariate\nregression, multi-label classification, multi-task learning, dyadic prediction,\nzero-shot learning, network inference, and matrix completion. In this paper, we\npresent a unifying view on MTP problems and methods. First, we formally discuss\ncommonalities and differences between existing MTP problems. To this end, we\nintroduce a general framework that covers the above subfields as special cases.\nAs a second contribution, we provide a structured overview of MTP methods. This\nis accomplished by identifying a number of key properties, which distinguish\nsuch methods and determine their suitability for different types of problems.\nFinally, we also discuss a few challenges for future research.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 08:38:02 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Waegeman", "Willem", ""], ["Dembczynski", "Krzysztof", ""], ["Huellermeier", "Eyke", ""]]}, {"id": "1809.02362", "submitter": "Fabian Hornung", "authors": "Philipp Grohs, Fabian Hornung, Arnulf Jentzen, Philippe von\n  Wurstemberger", "title": "A proof that artificial neural networks overcome the curse of\n  dimensionality in the numerical approximation of Black-Scholes partial\n  differential equations", "comments": "124 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG math.PR q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs) have very successfully been used in\nnumerical simulations for a series of computational problems ranging from image\nclassification/image recognition, speech recognition, time series analysis,\ngame intelligence, and computational advertising to numerical approximations of\npartial differential equations (PDEs). Such numerical simulations suggest that\nANNs have the capacity to very efficiently approximate high-dimensional\nfunctions and, especially, such numerical simulations indicate that ANNs seem\nto admit the fundamental power to overcome the curse of dimensionality when\napproximating the high-dimensional functions appearing in the above named\ncomputational problems. There are also a series of rigorous mathematical\napproximation results for ANNs in the scientific literature. Some of these\nmathematical results prove convergence without convergence rates and some of\nthese mathematical results even rigorously establish convergence rates but\nthere are only a few special cases where mathematical results can rigorously\nexplain the empirical success of ANNs when approximating high-dimensional\nfunctions. The key contribution of this article is to disclose that ANNs can\nefficiently approximate high-dimensional functions in the case of numerical\napproximations of Black-Scholes PDEs. More precisely, this work reveals that\nthe number of required parameters of an ANN to approximate the solution of the\nBlack-Scholes PDE grows at most polynomially in both the reciprocal of the\nprescribed approximation accuracy $\\varepsilon > 0$ and the PDE dimension $d\n\\in \\mathbb{N}$ and we thereby prove, for the first time, that ANNs do indeed\novercome the curse of dimensionality in the numerical approximation of\nBlack-Scholes PDEs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 09:03:55 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Grohs", "Philipp", ""], ["Hornung", "Fabian", ""], ["Jentzen", "Arnulf", ""], ["von Wurstemberger", "Philippe", ""]]}, {"id": "1809.02383", "submitter": "Haruo Hosoya", "authors": "Haruo Hosoya", "title": "Group-based Learning of Disentangled Representations with\n  Generalizability for Novel Contents", "comments": null, "journal-ref": "published in IJCAI 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensory data are often comprised of independent content and transformation\nfactors. For example, face images may have shapes as content and poses as\ntransformation. To infer separately these factors from given data, various\n``disentangling'' models have been proposed. However, many of these are\nsupervised or semi-supervised, either requiring attribute labels that are often\nunavailable or disallowing for generalization over new contents. In this study,\nwe introduce a novel deep generative model, called group-based variational\nautoencoders. In this, we assume no explicit labels, but a weaker form of\nstructure that groups together data instances having the same content but\ntransformed differently; we thereby separately estimate a group-common factor\nas content and an instance-specific factor as transformation. This approach\nallows for learning to represent a general continuous space of contents, which\ncan accommodate unseen contents. Despite the simplicity, our model succeeded in\nlearning, from five datasets, content representations that are highly separate\nfrom the transformation representation and generalizable to data with novel\ncontents. We further provide detailed analysis of the latent content code and\nshow insight into how our model obtains the notable transformation invariance\nand content generalizability.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:00:54 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 00:55:30 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Hosoya", "Haruo", ""]]}, {"id": "1809.02387", "submitter": "Yubin Deng", "authors": "Yubin Deng, Ke Yu, Dahua Lin, Xiaoou Tang, Chen Change Loy", "title": "Improving On-policy Learning with Statistical Reward Accumulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has obtained significant breakthroughs in recent\nyears. Most methods in deep-RL achieve good results via the maximization of the\nreward signal provided by the environment, typically in the form of discounted\ncumulative returns. Such reward signals represent the immediate feedback of a\nparticular action performed by an agent. However, tasks with sparse reward\nsignals are still challenging to on-policy methods. In this paper, we introduce\nan effective characterization of past reward statistics (which can be seen as\nlong-term feedback signals) to supplement this immediate reward feedback. In\nparticular, value functions are learned with multi-critics supervision,\nenabling complex value functions to be more easily approximated in on-policy\nlearning, even when the reward signals are sparse. We also introduce a novel\nexploration mechanism called \"hot-wiring\" that can give a boost to seemingly\ntrapped agents. We demonstrate the effectiveness of our advantage actor\nmulti-critic (A2MC) method across the discrete domains in Atari games as well\nas continuous domains in the MuJoCo environments. A video demo is provided at\nhttps://youtu.be/zBmpf3Yz8tc.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:10:12 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Deng", "Yubin", ""], ["Yu", "Ke", ""], ["Lin", "Dahua", ""], ["Tang", "Xiaoou", ""], ["Loy", "Chen Change", ""]]}, {"id": "1809.02394", "submitter": "Jiajie Peng", "authors": "Hansheng Xue, Jiajie Peng, Xuequn Shang", "title": "Deep Feature Learning of Multi-Network Topology for Node Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are ubiquitous structure that describes complex relationships\nbetween different entities in the real world. As a critical component of\nprediction task over nodes in networks, learning the feature representation of\nnodes has become one of the most active areas recently. Network Embedding,\naiming to learn non-linear and low-dimensional feature representation based on\nnetwork topology, has been proved to be helpful on tasks of network analysis,\nespecially node classification. For many real-world systems, multiple types of\nrelations are naturally represented by multiple networks. However, existing\nnetwork embedding methods mainly focus on single network embedding and neglect\nthe information shared among different networks. In this paper, we propose a\nnovel multiple network embedding method based on semisupervised autoencoder,\nnamed DeepMNE, which captures complex topological structures of multi-networks\nand takes the correlation among multi-networks into account. We evaluate\nDeepMNE on the task of node classification with two real-world datasets. The\nexperimental results demonstrate the superior performance of our method over\nfour state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:36:22 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Xue", "Hansheng", ""], ["Peng", "Jiajie", ""], ["Shang", "Xuequn", ""]]}, {"id": "1809.02397", "submitter": "Xavier Renard", "authors": "Xavier Renard, Thibault Laugel, Marie-Jeanne Lesot, Christophe\n  Marsala, Marcin Detyniecki", "title": "Detecting Potential Local Adversarial Examples for Human-Interpretable\n  Defense", "comments": "presented at 2018 ECML/PKDD Workshop on Recent Advances in\n  Adversarial Machine Learning (Nemesis 2018), Dublin, Ireland", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are increasingly used in the industry to make\ndecisions such as credit insurance approval. Some people may be tempted to\nmanipulate specific variables, such as the age or the salary, in order to get\nbetter chances of approval. In this ongoing work, we propose to discuss, with a\nfirst proposition, the issue of detecting a potential local adversarial example\non classical tabular data by providing to a human expert the locally critical\nfeatures for the classifier's decision, in order to control the provided\ninformation and avoid a fraud.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:39:47 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Renard", "Xavier", ""], ["Laugel", "Thibault", ""], ["Lesot", "Marie-Jeanne", ""], ["Marsala", "Christophe", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1809.02403", "submitter": "Kan Ren", "authors": "Kan Ren, Jiarui Qin, Lei Zheng, Zhengyu Yang, Weinan Zhang, Lin Qiu,\n  Yong Yu", "title": "Deep Recurrent Survival Analysis", "comments": "AAAI 2019. Supplemental material, slides, code:\n  https://github.com/rk2900/drsa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival analysis is a hotspot in statistical research for modeling\ntime-to-event information with data censorship handling, which has been widely\nused in many applications such as clinical research, information system and\nother fields with survivorship bias. Many works have been proposed for survival\nanalysis ranging from traditional statistic methods to machine learning models.\nHowever, the existing methodologies either utilize counting-based statistics on\nthe segmented data, or have a pre-assumption on the event probability\ndistribution w.r.t. time. Moreover, few works consider sequential patterns\nwithin the feature space. In this paper, we propose a Deep Recurrent Survival\nAnalysis model which combines deep learning for conditional probability\nprediction at fine-grained level of the data, and survival analysis for\ntackling the censorship. By capturing the time dependency through modeling the\nconditional probability of the event for each sample, our method predicts the\nlikelihood of the true event occurrence and estimates the survival rate over\ntime, i.e., the probability of the non-occurrence of the event, for the\ncensored data. Meanwhile, without assuming any specific form of the event\nprobability distribution, our model shows great advantages over the previous\nworks on fitting various sophisticated data distributions. In the experiments\non the three real-world tasks from different fields, our model significantly\noutperforms the state-of-the-art solutions under various metrics.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 11:13:44 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 11:40:19 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Ren", "Kan", ""], ["Qin", "Jiarui", ""], ["Zheng", "Lei", ""], ["Yang", "Zhengyu", ""], ["Zhang", "Weinan", ""], ["Qiu", "Lin", ""], ["Yu", "Yong", ""]]}, {"id": "1809.02440", "submitter": "Hugo Richard", "authors": "Hugo Richard (PARIETAL), Ana Pinho (NEUROSPIN), Bertrand Thirion\n  (PARIETAL), Guillaume Charpiat (TAU)", "title": "Optimizing deep video representation to match brain activity", "comments": null, "journal-ref": "2018 Conference on Cognitive Computational Neuroscience, Sep 2018,\n  Philadelphia, United States", "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The comparison of observed brain activity with the statistics generated by\nartificial intelligence systems is useful to probe brain functional\norganization under ecological conditions. Here we study fMRI activity in ten\nsubjects watching color natural movies and compute deep representations of\nthese movies with an architecture that relies on optical flow and image\ncontent. The association of activity in visual areas with the different layers\nof the deep architecture displays complexity-related contrasts across visual\nareas and reveals a striking foveal/peripheral dichotomy.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 12:37:50 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Richard", "Hugo", "", "PARIETAL"], ["Pinho", "Ana", "", "NEUROSPIN"], ["Thirion", "Bertrand", "", "PARIETAL"], ["Charpiat", "Guillaume", "", "TAU"]]}, {"id": "1809.02441", "submitter": "Jangho Kim", "authors": "Jangho Kim, Jeesoo Kim, Nojun Kwak", "title": "StackNet: Stacking Parameters for Continual learning", "comments": "CVPR 2020 Workshop on Continual Learning in Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a neural network for a classification task typically assumes that\nthe data to train are given from the beginning. However, in the real world,\nadditional data accumulate gradually and the model requires additional training\nwithout accessing the old training data. This usually leads to the catastrophic\nforgetting problem which is inevitable for the traditional training methodology\nof neural networks. In this paper, we propose a continual learning method that\nis able to learn additional tasks while retaining the performance of previously\nlearned tasks by stacking parameters. Composed of two complementary components,\nthe index module and the StackNet, our method estimates the index of the\ncorresponding task for an input sample with the index module and utilizes a\nparticular portion of StackNet with this index. The StackNet guarantees no\ndegradation in the performance of the previously learned tasks and the index\nmodule shows high confidence in finding the origin of an input sample. Compared\nto the previous work of PackNet, our method is competitive and highly\nintuitive.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 12:39:13 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 08:10:25 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 01:23:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Kim", "Jangho", ""], ["Kim", "Jeesoo", ""], ["Kwak", "Nojun", ""]]}, {"id": "1809.02444", "submitter": "Lei Ma", "authors": "Alvin Chan, Lei Ma, Felix Juefei-Xu, Xiaofei Xie, Yang Liu, and Yew\n  Soon Ong", "title": "Metamorphic Relation Based Adversarial Attacks on Differentiable Neural\n  Computer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN), while becoming the driving force of many novel\ntechnology and achieving tremendous success in many cutting-edge applications,\nare still vulnerable to adversarial attacks. Differentiable neural computer\n(DNC) is a novel computing machine with DNN as its central controller operating\non an external memory module for data processing. The unique architecture of\nDNC contributes to its state-of-the-art performance in tasks which requires the\nability to represent variables and data structure as well as to store data over\nlong timescales. However, there still lacks a comprehensive study on how\nadversarial examples affect DNC in terms of robustness. In this paper, we\npropose metamorphic relation based adversarial techniques for a range of tasks\ndescribed in the natural processing language domain. We show that the\nnear-perfect performance of the DNC in bAbI logical question answering tasks\ncan be degraded by adversarially injected sentences. We further perform\nin-depth study on the role of DNC's memory size in its robustness and analyze\nthe potential reason causing why DNC fails. Our study demonstrates the current\nchallenges and potential opportunities towards constructing more robust DNCs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 12:44:19 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Chan", "Alvin", ""], ["Ma", "Lei", ""], ["Juefei-Xu", "Felix", ""], ["Xie", "Xiaofei", ""], ["Liu", "Yang", ""], ["Ong", "Yew Soon", ""]]}, {"id": "1809.02482", "submitter": "Fragkiskos  Malliaros", "authors": "Duong Nguyen and Fragkiskos D. Malliaros", "title": "BiasedWalk: Biased Sampling for Representation Learning on Graphs", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding algorithms are able to learn latent feature representations\nof nodes, transforming networks into lower dimensional vector representations.\nTypical key applications, which have effectively been addressed using network\nembeddings, include link prediction, multilabel classification and community\ndetection. In this paper, we propose BiasedWalk, a scalable, unsupervised\nfeature learning algorithm that is based on biased random walks to sample\ncontext information about each node in the network. Our random-walk based\nsampling can behave as Breath-First-Search (BFS) and Depth-First-Search (DFS)\nsamplings with the goal to capture homophily and role equivalence between the\nnodes in the network. We have performed a detailed experimental evaluation\ncomparing the performance of the proposed algorithm against various baseline\nmethods, on several datasets and learning tasks. The experiment results show\nthat the proposed method outperforms the baseline ones in most of the tasks and\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 13:58:37 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Nguyen", "Duong", ""], ["Malliaros", "Fragkiskos D.", ""]]}, {"id": "1809.02495", "submitter": "Junchi Li", "authors": "Chris Junchi Li", "title": "A note on concentration inequality for vector-valued martingales with\n  weak exponential-type tails", "comments": "This short note has been merged and integrated into a follow-up work\n  arXiv:2003.03532. Communications on v2 are still welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel martingale concentration inequalities for martingale\ndifferences with finite Orlicz-$\\psi_\\alpha$ norms. Such martingale differences\nwith weak exponential-type tails scatters in many statistical applications and\ncan be heavier than sub-exponential distributions. In the case of one\ndimension, we prove in general that for a sequence of scalar-valued\nsupermartingale difference, the tail bound depends solely on the sum of squared\nOrlicz-$\\psi_\\alpha$ norms instead of the maximal Orlicz-$\\psi_\\alpha$ norm,\ngeneralizing the results of Lesigne & Voln\\'y (2001) and Fan et al. (2012). In\nthe multidimensional case, using a dimension reduction lemma proposed by\nKallenberg & Sztencel (1991) we show that essentially the same concentration\ntail bound holds for vector-valued martingale difference sequences.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 06:57:52 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 19:00:34 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 00:44:29 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Li", "Chris Junchi", ""]]}, {"id": "1809.02497", "submitter": "Rudrajit Das", "authors": "Rudrajit Das, Aditya Golatkar and Suyash P. Awate", "title": "Sparse Kernel PCA for Outlier Detection", "comments": "Accepted at IEEE ICMLA 2018 for Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new method to perform Sparse Kernel Principal\nComponent Analysis (SKPCA) and also mathematically analyze the validity of\nSKPCA. We formulate SKPCA as a constrained optimization problem with elastic\nnet regularization (Hastie et al.) in kernel feature space and solve it. We\nconsider outlier detection (where KPCA is employed) as an application for\nSKPCA, using the RBF kernel. We test it on 5 real-world datasets and show that\nby using just 4% (or even less) of the principal components (PCs), where each\nPC has on average less than 12% non-zero elements in the worst case among all 5\ndatasets, we are able to nearly match and in 3 datasets even outperform KPCA.\nWe also compare the performance of our method with a recently proposed method\nfor SKPCA by Wang et al. and show that our method performs better in terms of\nboth accuracy and sparsity. We also provide a novel probabilistic proof to\njustify the existence of sparse solutions for KPCA using the RBF kernel. To the\nbest of our knowledge, this is the first attempt at theoretically analyzing the\nvalidity of SKPCA.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 14:23:03 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 18:35:15 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Das", "Rudrajit", ""], ["Golatkar", "Aditya", ""], ["Awate", "Suyash P.", ""]]}, {"id": "1809.02499", "submitter": "Hongyu Guo", "authors": "Hongyu Guo and Yongyi Mao and Richong Zhang", "title": "MixUp as Locally Linear Out-Of-Manifold Regularization", "comments": "Accepted by AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MixUp is a recently proposed data-augmentation scheme, which linearly\ninterpolates a random pair of training examples and correspondingly the one-hot\nrepresentations of their labels. Training deep neural networks with such\nadditional data is shown capable of significantly improving the predictive\naccuracy of the current art. The power of MixUp, however, is primarily\nestablished empirically and its working and effectiveness have not been\nexplained in any depth. In this paper, we develop an understanding for MixUp as\na form of \"out-of-manifold regularization\", which imposes certain \"local\nlinearity\" constraints on the model's input space beyond the data manifold.\nThis analysis enables us to identify a limitation of MixUp, which we call\n\"manifold intrusion\". In a nutshell, manifold intrusion in MixUp is a form of\nunder-fitting resulting from conflicts between the synthetic labels of the\nmixed-up examples and the labels of original training data. Such a phenomenon\nusually happens when the parameters controlling the generation of mixing\npolicies are not sufficiently fine-tuned on the training data. To address this\nissue, we propose a novel adaptive version of MixUp, where the mixing policies\nare automatically learned from the data using an additional network and\nobjective function designed to avoid manifold intrusion. The proposed\nregularizer, AdaMixUp, is empirically evaluated on several benchmark datasets.\nExtensive experiments demonstrate that AdaMixUp improves upon MixUp when\napplied to the current art of deep classification models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 14:26:17 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 01:11:46 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 19:37:01 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Guo", "Hongyu", ""], ["Mao", "Yongyi", ""], ["Zhang", "Richong", ""]]}, {"id": "1809.02503", "submitter": "Mohammad Golbabaee", "authors": "Mohammad Golbabaee, Zhouye Chen, Yves Wiaux, Mike E. Davies", "title": "CoverBLIP: scalable iterative matched filtering for MR Fingerprint\n  recovery", "comments": "In Proceedings of Joint Annual Meeting ISMRM-ESMRMB 2018 - Paris", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current proposed solutions for the high dimensionality of the MRF\nreconstruction problem rely on a linear compression step to reduce the matching\ncomputations and boost the efficiency of fast but non-scalable searching\nschemes such as the KD-trees. However such methodologies often introduce an\nunfavourable compromise in the estimation accuracy when applied to nonlinear\ndata structures such as the manifold of Bloch responses with possible increased\ndynamic complexity and growth in data population. To address this shortcoming\nwe propose an inexact iterative reconstruction method, dubbed as the Cover\nBLoch response Iterative Projection (CoverBLIP). Iterative methods improve the\naccuracy of their non-iterative counterparts and are additionally robust\nagainst certain accelerated approximate updates, without compromising their\nfinal accuracy. Leveraging on these results, we accelerate matched-filtering\nusing an ANNS algorithm based on Cover trees with a robustness feature against\nthe curse of dimensionality.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 08:58:09 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Golbabaee", "Mohammad", ""], ["Chen", "Zhouye", ""], ["Wiaux", "Yves", ""], ["Davies", "Mike E.", ""]]}, {"id": "1809.02505", "submitter": "Liu Liu", "authors": "Liu Liu, Ji Liu, Cho-Jui Hsieh, Dacheng Tao", "title": "Stochastically Controlled Stochastic Gradient for the Convex and\n  Non-convex Composition problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the convex and non-convex composition problem with\nthe structure $\\frac{1}{n}\\sum\\nolimits_{i = 1}^n {{F_i}( {G( x )} )}$, where\n$G( x )=\\frac{1}{n}\\sum\\nolimits_{j = 1}^n {{G_j}( x )} $ is the inner\nfunction, and $F_i(\\cdot)$ is the outer function. We explore the variance\nreduction based method to solve the composition optimization. Due to the fact\nthat when the number of inner function and outer function are large, it is not\nreasonable to estimate them directly, thus we apply the stochastically\ncontrolled stochastic gradient (SCSG) method to estimate the gradient of the\ncomposition function and the value of the inner function. The query complexity\nof our proposed method for the convex and non-convex problem is equal to or\nbetter than the current method for the composition problem. Furthermore, we\nalso present the mini-batch version of the proposed method, which has the\nimproved the query complexity with related to the size of the mini-batch.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 12:04:47 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Liu", "Liu", ""], ["Liu", "Ji", ""], ["Hsieh", "Cho-Jui", ""], ["Tao", "Dacheng", ""]]}, {"id": "1809.02506", "submitter": "Mohammad Golbabaee", "authors": "Arnold Julian Vinoj Benjamin, Pedro A. G\\'omez, Mohammad Golbabaee,\n  Tim Sprenger, Marion I. Menzel, Mike E. Davies, Ian Marshall", "title": "Balanced multi-shot EPI for accelerated Cartesian MRF: An alternative to\n  spiral MRF", "comments": "Proceedings of the Joint Annual Meeting ISMRM-ESMRMB 2018 - Paris", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main purpose of this study is to show that a highly accelerated Cartesian\nMRF scheme using a multi-shot EPI readout (i.e. multi-shot EPI-MRF) can produce\ngood quality multi-parametric maps such as T1, T2 and proton density (PD) in a\nsufficiently short scan duration that is similar to conventional MRF. This\nmulti-shot approach allows considerable subsampling while traversing the entire\nk-space trajectory, can yield better SNR, reduced blurring, less distortion and\ncan also be used to collect higher resolution data compared to existing\nsingle-shot EPI-MRF implementations. The generated parametric maps are compared\nto an accelerated spiral MRF implementation with the same acquisition\nparameters to evaluate the performance of this method. Additionally, an\niterative reconstruction algorithm is applied to improve the accuracy of\nparametric map estimations and the fast convergence of EPI-MRF is also\ndemonstrated.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 12:51:58 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Benjamin", "Arnold Julian Vinoj", ""], ["G\u00f3mez", "Pedro A.", ""], ["Golbabaee", "Mohammad", ""], ["Sprenger", "Tim", ""], ["Menzel", "Marion I.", ""], ["Davies", "Mike E.", ""], ["Marshall", "Ian", ""]]}, {"id": "1809.02512", "submitter": "Guilherme Gomes", "authors": "Guilherme Gomes and Vinayak Rao and Jennifer Neville", "title": "Multi-level hypothesis testing for populations of heterogeneous networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider hypothesis testing and anomaly detection on\ndatasets where each observation is a weighted network. Examples of such data\ninclude brain connectivity networks from fMRI flow data, or word co-occurrence\ncounts for populations of individuals. Current approaches to hypothesis testing\nfor weighted networks typically requires thresholding the edge-weights, to\ntransform the data to binary networks. This results in a loss of information,\nand outcomes are sensitivity to choice of threshold levels. Our work avoids\nthis, and we consider weighted-graph observations in two situations, 1) where\neach graph belongs to one of two populations, and 2) where entities belong to\none of two populations, with each entity possessing multiple graphs (indexed\ne.g. by time). Specifically, we propose a hierarchical Bayesian hypothesis\ntesting framework that models each population with a mixture of latent space\nmodels for weighted networks, and then tests populations of networks for\ndifferences in distribution over components. Our framework is capable of\npopulation-level, entity-specific, as well as edge-specific hypothesis testing.\nWe apply it to synthetic data and three real-world datasets: two social media\ndatasets involving word co-occurrences from discussions on Twitter of the\npolitical unrest in Brazil, and on Instagram concerning Attention Deficit\nHyperactivity Disorder (ADHD) and depression drugs, and one medical dataset\ninvolving fMRI brain-scans of human subjects. The results show that our\nproposed method has lower Type I error and higher statistical power compared to\nalternatives that need to threshold the edge weights. Moreover, they show our\nproposed method is better suited to deal with highly heterogeneous datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 14:44:11 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Gomes", "Guilherme", ""], ["Rao", "Vinayak", ""], ["Neville", "Jennifer", ""]]}, {"id": "1809.02519", "submitter": "David Madras", "authors": "David Madras, Elliot Creager, Toniann Pitassi, Richard Zemel", "title": "Fairness Through Causal Awareness: Learning Latent-Variable Models for\n  Biased Data", "comments": "Accepted as a conference paper at ACM Conference on Fairness,\n  Accountability, and Transparency (ACM FAT*) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do we learn from biased data? Historical datasets often reflect\nhistorical prejudices; sensitive or protected attributes may affect the\nobserved treatments and outcomes. Classification algorithms tasked with\npredicting outcomes accurately from these datasets tend to replicate these\nbiases. We advocate a causal modeling approach to learning from biased data,\nexploring the relationship between fair classification and intervention. We\npropose a causal model in which the sensitive attribute confounds both the\ntreatment and the outcome. Building on prior work in deep learning and\ngenerative modeling, we describe how to learn the parameters of this causal\nmodel from observational data alone, even in the presence of unobserved\nconfounders. We show experimentally that fairness-aware causal modeling\nprovides better estimates of the causal effects between the sensitive\nattribute, the treatment, and the outcome. We further present evidence that\nestimating these causal effects can help learn policies that are both more\naccurate and fair, when presented with a historically biased dataset.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 15:00:44 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 19:35:07 GMT"}, {"version": "v3", "created": "Mon, 3 Dec 2018 04:16:13 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Madras", "David", ""], ["Creager", "Elliot", ""], ["Pitassi", "Toniann", ""], ["Zemel", "Richard", ""]]}, {"id": "1809.02560", "submitter": "Jong-Chyi Su", "authors": "Jong-Chyi Su and Matheus Gadelha and Rui Wang and Subhransu Maji", "title": "A Deeper Look at 3D Shape Classifiers", "comments": "Accepted to Second Workshop on 3D Reconstruction Meets Semantics,\n  ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the role of representations and architectures for classifying\n3D shapes in terms of their computational efficiency, generalization, and\nrobustness to adversarial transformations. By varying the number of training\nexamples and employing cross-modal transfer learning we study the role of\ninitialization of existing deep architectures for 3D shape classification. Our\nanalysis shows that multiview methods continue to offer the best generalization\neven without pretraining on large labeled image datasets, and even when trained\non simplified inputs such as binary silhouettes. Furthermore, the performance\nof voxel-based 3D convolutional networks and point-based architectures can be\nimproved via cross-modal transfer from image representations. Finally, we\nanalyze the robustness of 3D shape classifiers to adversarial transformations\nand present a novel approach for generating adversarial perturbations of a 3D\nshape for multiview classifiers using a differentiable renderer. We find that\npoint-based networks are more robust to point position perturbations while\nvoxel-based and multiview networks are easily fooled with the addition of\nimperceptible noise to the input.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 16:10:23 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 18:14:18 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Su", "Jong-Chyi", ""], ["Gadelha", "Matheus", ""], ["Wang", "Rui", ""], ["Maji", "Subhransu", ""]]}, {"id": "1809.02587", "submitter": "Pedro Morgado", "authors": "Pedro Morgado, Nuno Vasconcelos, Timothy Langlois and Oliver Wang", "title": "Self-Supervised Generation of Spatial Audio for 360 Video", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach to convert mono audio recorded by a 360 video camera\ninto spatial audio, a representation of the distribution of sound over the full\nviewing sphere. Spatial audio is an important component of immersive 360 video\nviewing, but spatial audio microphones are still rare in current 360 video\nproduction. Our system consists of end-to-end trainable neural networks that\nseparate individual sound sources and localize them on the viewing sphere,\nconditioned on multi-modal analysis of audio and 360 video frames. We introduce\nseveral datasets, including one filmed ourselves, and one collected in-the-wild\nfrom YouTube, consisting of 360 videos uploaded with spatial audio. During\ntraining, ground-truth spatial audio serves as self-supervision and a mixed\ndown mono track forms the input to our network. Using our approach, we show\nthat it is possible to infer the spatial location of sound sources based only\non 360 video and a mono audio track.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 17:25:59 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Morgado", "Pedro", ""], ["Vasconcelos", "Nuno", ""], ["Langlois", "Timothy", ""], ["Wang", "Oliver", ""]]}, {"id": "1809.02589", "submitter": "Naganand Yadati", "authors": "Naganand Yadati, Madhav Nimishakavi, Prateek Yadav, Vikram Nitin,\n  Anand Louis, Partha Talukdar", "title": "HyperGCN: A New Method of Training Graph Convolutional Networks on\n  Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world network datasets such as co-authorship, co-citation, email\ncommunication, etc., relationships are complex and go beyond pairwise.\nHypergraphs provide a flexible and natural modeling tool to model such complex\nrelationships. The obvious existence of such complex relationships in many\nreal-world networks naturaly motivates the problem of learning with\nhypergraphs. A popular learning paradigm is hypergraph-based semi-supervised\nlearning (SSL) where the goal is to assign labels to initially unlabeled\nvertices in a hypergraph. Motivated by the fact that a graph convolutional\nnetwork (GCN) has been effective for graph-based SSL, we propose HyperGCN, a\nnovel GCN for SSL on attributed hypergraphs. Additionally, we show how HyperGCN\ncan be used as a learning-based approach for combinatorial optimisation on\nNP-hard hypergraph problems. We demonstrate HyperGCN's effectiveness through\ndetailed experimentation on real-world hypergraphs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 17:27:25 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 19:41:23 GMT"}, {"version": "v3", "created": "Sat, 26 Jan 2019 17:45:32 GMT"}, {"version": "v4", "created": "Wed, 22 May 2019 13:48:41 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Yadati", "Naganand", ""], ["Nimishakavi", "Madhav", ""], ["Yadav", "Prateek", ""], ["Nitin", "Vikram", ""], ["Louis", "Anand", ""], ["Talukdar", "Partha", ""]]}, {"id": "1809.02591", "submitter": "Remi Tachet Des Combes", "authors": "Remi Tachet, Philip Bachman and Harm van Seijen", "title": "Learning Invariances for Policy Generalization", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent progress has spawned very powerful machine learning systems,\nthose agents remain extremely specialized and fail to transfer the knowledge\nthey gain to similar yet unseen tasks. In this paper, we study a simple\nreinforcement learning problem and focus on learning policies that encode the\nproper invariances for generalization to different settings. We evaluate three\npotential methods for policy generalization: data augmentation, meta-learning\nand adversarial training. We find our data augmentation method to be effective,\nand study the potential of meta-learning and adversarial learning as\nalternative task-agnostic approaches.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 17:32:19 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 12:57:19 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Tachet", "Remi", ""], ["Bachman", "Philip", ""], ["van Seijen", "Harm", ""]]}, {"id": "1809.02592", "submitter": "Yihao Fang", "authors": "Yihao Fang, Rong Zheng, and Xiaodan Zhu", "title": "Logographic Subword Model for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel logographic subword model is proposed to reinterpret logograms as\nabstract subwords for neural machine translation. Our approach drastically\nreduces the size of an artificial neural network, while maintaining comparable\nBLEU scores as those attained with the baseline RNN and CNN seq2seq models. The\nsmaller model size also leads to shorter training and inference time.\nExperiments demonstrate that in the tasks of English-Chinese/Chinese-English\ntranslation, the reduction of those aspects can be from $11\\%$ to as high as\n$77\\%$. Compared to previous subword models, abstract subwords can be applied\nto various logographic languages. Considering most of the logographic languages\nare ancient and very low resource languages, these advantages are very\ndesirable for archaeological computational linguistic applications such as a\nresource-limited offline hand-held Demotic-English translator.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 17:34:34 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Fang", "Yihao", ""], ["Zheng", "Rong", ""], ["Zhu", "Xiaodan", ""]]}, {"id": "1809.02596", "submitter": "Val Andrei Fajardo", "authors": "Val Andrei Fajardo, David Findlay, Roshanak Houmanfar, Charu Jaiswal,\n  Jiaxi Liang, Honglei Xie", "title": "VOS: a Method for Variational Oversampling of Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalanced datasets are common in real-world applications that range\nfrom credit card fraud detection to rare disease diagnostics. Several popular\nclassification algorithms assume that classes are approximately balanced, and\nhence build the accompanying objective function to maximize an overall accuracy\nrate. In these situations, optimizing the overall accuracy will lead to highly\nskewed predictions towards the majority class. Moreover, the negative business\nimpact resulting from false positives (positive samples incorrectly classified\nas negative) can be detrimental. Many methods have been proposed to address the\nclass imbalance problem, including methods such as over-sampling,\nunder-sampling and cost-sensitive methods. In this paper, we consider the\nover-sampling method, where the aim is to augment the original dataset with\nsynthetically created observations of the minority classes. In particular,\ninspired by the recent advances in generative modelling techniques (e.g.,\nVariational Inference and Generative Adversarial Networks), we introduce a new\noversampling technique based on variational autoencoders. Our experiments show\nthat the new method is superior in augmenting datasets for downstream\nclassification tasks when compared to traditional oversampling methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 17:40:16 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Fajardo", "Val Andrei", ""], ["Findlay", "David", ""], ["Houmanfar", "Roshanak", ""], ["Jaiswal", "Charu", ""], ["Liang", "Jiaxi", ""], ["Xie", "Honglei", ""]]}, {"id": "1809.02599", "submitter": "Stephen Whitelam", "authors": "Stephen Whitelam", "title": "Improving the accuracy of nearest-neighbor classification using\n  principled construction and stochastic sampling of training-set centroids", "comments": null, "journal-ref": "Entropy 23, 149 (2021)", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conceptually simple way to classify images is to directly compare test-set\ndata and training-set data. The accuracy of this approach is limited by the\nmethod of comparison used, and by the extent to which the training-set data\ncover configuration space. Here we show that this coverage can be substantially\nincreased using coarse graining (replacing groups of images by their centroids)\nand stochastic sampling (using distinct sets of centroids in combination). We\nuse the MNIST and Fashion-MNIST data sets to show that a principled\ncoarse-graining algorithm can convert training images into fewer image\ncentroids without loss of accuracy of classification of test-set images by\nnearest-neighbor classification. Distinct batches of centroids can be used in\ncombination as a means of stochastically sampling configuration space, and can\nclassify test-set data more accurately than can the unaltered training set. On\nthe MNIST and Fashion-MNIST data sets this approach converts nearest-neighbor\nclassification from a mid-ranking- to an upper-ranking member of the set of\nclassical machine-learning techniques.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 17:49:38 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 18:20:07 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 18:18:51 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Whitelam", "Stephen", ""]]}, {"id": "1809.02612", "submitter": "Sven Krippendorf", "authors": "Harold Erbin, Sven Krippendorf", "title": "GANs for generating EFT models", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": "10.1016/j.physletb.2020.135798", "report-no": "LMU-ASC 58/18", "categories": "cs.LG hep-ph hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a way of generating models by the computer, satisfying both\nexperimental and theoretical constraints. In particular, we present a framework\nwhich allows the generation of effective field theories. We use Generative\nAdversarial Networks to generate these models and we generate examples which go\nbeyond the examples known to the machine. As a starting point, we apply this\nidea to the generation of supersymmetric field theories. In this case, the\nmachine knows consistent examples of supersymmetric field theories with a\nsingle field and generates new examples of such theories. In the generated\npotentials we find distinct properties, here the number of minima in the scalar\npotential, with values not found in the training data. We comment on potential\nfurther applications of this framework.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 18:00:01 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Erbin", "Harold", ""], ["Krippendorf", "Sven", ""]]}, {"id": "1809.02627", "submitter": "Arthur Juliani", "authors": "Arthur Juliani, Vincent-Pierre Berges, Ervin Teng, Andrew Cohen,\n  Jonathan Harper, Chris Elion, Chris Goy, Yuan Gao, Hunter Henry, Marwan\n  Mattar, Danny Lange", "title": "Unity: A General Platform for Intelligent Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence have been driven by the presence\nof increasingly realistic and complex simulated environments. However, many of\nthe existing environments provide either unrealistic visuals, inaccurate\nphysics, low task complexity, restricted agent perspective, or a limited\ncapacity for interaction among artificial agents. Furthermore, many platforms\nlack the ability to flexibly configure the simulation, making the simulated\nenvironment a black-box from the perspective of the learning system. In this\nwork, we propose a novel taxonomy of existing simulation platforms and discuss\nthe highest level class of general platforms which enable the development of\nlearning environments that are rich in visual, physical, task, and social\ncomplexity. We argue that modern game engines are uniquely suited to act as\ngeneral platforms and as a case study examine the Unity engine and open source\nUnity ML-Agents Toolkit. We then survey the research enabled by Unity and the\nUnity ML-Agents Toolkit, discussing the kinds of research a flexible,\ninteractive and easily configurable general platform can facilitate.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 18:13:25 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:59:11 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Juliani", "Arthur", ""], ["Berges", "Vincent-Pierre", ""], ["Teng", "Ervin", ""], ["Cohen", "Andrew", ""], ["Harper", "Jonathan", ""], ["Elion", "Chris", ""], ["Goy", "Chris", ""], ["Gao", "Yuan", ""], ["Henry", "Hunter", ""], ["Mattar", "Marwan", ""], ["Lange", "Danny", ""]]}, {"id": "1809.02630", "submitter": "Jie Chen", "authors": "Tengfei Ma, Jie Chen, Cao Xiao", "title": "Constrained Generation of Semantically Valid Graphs via Regularizing\n  Variational Autoencoders", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have achieved remarkable success in various data\ndomains, including images, time series, and natural languages. There remain,\nhowever, substantial challenges for combinatorial structures, including graphs.\nOne of the key challenges lies in the difficulty of ensuring semantic validity\nin context. For examples, in molecular graphs, the number of bonding-electron\npairs must not exceed the valence of an atom; whereas in protein interaction\nnetworks, two proteins may be connected only when they belong to the same or\ncorrelated gene ontology terms. These constraints are not easy to be\nincorporated into a generative model. In this work, we propose a regularization\nframework for variational autoencoders as a step toward semantic validity. We\nfocus on the matrix representation of graphs and formulate penalty terms that\nregularize the output distribution of the decoder to encourage the satisfaction\nof validity constraints. Experimental results confirm a much higher likelihood\nof sampling valid graphs in our approach, compared with others reported in the\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 18:27:16 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 21:21:01 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Ma", "Tengfei", ""], ["Chen", "Jie", ""], ["Xiao", "Cao", ""]]}, {"id": "1809.02637", "submitter": "Vrindavan Harrison", "authors": "Vrindavan Harrison and Marilyn Walker", "title": "Neural Generation of Diverse Questions using Answer Focus, Contextual\n  and Linguistic Features", "comments": "Accepted to appear at INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Generation is the task of automatically creating questions from\ntextual input. In this work we present a new Attentional Encoder--Decoder\nRecurrent Neural Network model for automatic question generation. Our model\nincorporates linguistic features and an additional sentence embedding to\ncapture meaning at both sentence and word levels. The linguistic features are\ndesigned to capture information related to named entity recognition, word case,\nand entity coreference resolution. In addition our model uses a copying\nmechanism and a special answer signal that enables generation of numerous\ndiverse questions on a given sentence. Our model achieves state of the art\nresults of 19.98 Bleu_4 on a benchmark Question Generation dataset,\noutperforming all previously published results by a significant margin. A human\nevaluation also shows that these added features improve the quality of the\ngenerated questions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 18:47:20 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 21:50:26 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Harrison", "Vrindavan", ""], ["Walker", "Marilyn", ""]]}, {"id": "1809.02652", "submitter": "Harris Chan", "authors": "Harris Chan, Atef Chaudhury, Kevin Shen", "title": "Are You Sure You Want To Do That? Classification with Verification", "comments": "9 pages, 5 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification systems typically act in isolation, meaning they are required\nto implicitly memorize the characteristics of all candidate classes in order to\nclassify. The cost of this is increased memory usage and poor sample\nefficiency. We propose a model which instead verifies using reference images\nduring the classification process, reducing the burden of memorization. The\nmodel uses iterative nondifferentiable queries in order to classify an image.\nWe demonstrate that such a model is feasible to train and can match baseline\naccuracy while being more parameter efficient. However, we show that finding\nthe correct balance between image recognition and verification is essential to\npushing the model towards desired behavior, suggesting that a pipeline of\nrecognition followed by verification is a more promising approach.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 19:59:43 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 03:04:38 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Chan", "Harris", ""], ["Chaudhury", "Atef", ""], ["Shen", "Kevin", ""]]}, {"id": "1809.02657", "submitter": "Palash Goyal", "authors": "Palash Goyal, Sujit Rokka Chhetri, Arquimedes Canedo", "title": "dyngraph2vec: Capturing Network Dynamics using Dynamic Graph\n  Representation Learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2019.06.024", "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning graph representations is a fundamental task aimed at capturing\nvarious properties of graphs in vector space. The most recent methods learn\nsuch representations for static networks. However, real world networks evolve\nover time and have varying dynamics. Capturing such evolution is key to\npredicting the properties of unseen networks. To understand how the network\ndynamics affect the prediction performance, we propose an embedding approach\nwhich learns the structure of evolution in dynamic graphs and can predict\nunseen links with higher precision. Our model, dyngraph2vec, learns the\ntemporal transitions in the network using a deep architecture composed of dense\nand recurrent layers. We motivate the need of capturing dynamics for prediction\non a toy data set created using stochastic block models. We then demonstrate\nthe efficacy of dyngraph2vec over existing state-of-the-art methods on two real\nworld data sets. We observe that learning dynamics can improve the quality of\nembedding and yield better performance in link prediction.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 20:03:51 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 14:49:56 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Goyal", "Palash", ""], ["Chhetri", "Sujit Rokka", ""], ["Canedo", "Arquimedes", ""]]}, {"id": "1809.02665", "submitter": "Michael Jacobs", "authors": "Sanghyun Choi, Nikita Ivkin, Vladimir Braverman, Michael A. Jacobs", "title": "DreamNLP: Novel NLP System for Clinical Report Metadata Extraction using\n  Count Sketch Data Streaming Algorithm: Preliminary Results", "comments": "13 pages, 3 figures, US patent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting information from electronic health records (EHR) is a challenging\ntask since it requires prior knowledge of the reports and some natural language\nprocessing algorithm (NLP). With the growing number of EHR implementations,\nsuch knowledge is increasingly challenging to obtain in an efficient manner. We\naddress this challenge by proposing a novel methodology to analyze large sets\nof EHRs using a modified Count Sketch data streaming algorithm termed DreamNLP.\nBy using DreamNLP, we generate a dictionary of frequently occurring terms or\nheavy hitters in the EHRs using low computational memory compared to\nconventional counting approach other NLP programs use. We demonstrate the\nextraction of the most important breast diagnosis features from the EHRs in a\nset of patients that underwent breast imaging. Based on the analysis,\nextraction of these terms would be useful for defining important features for\ndownstream tasks such as machine learning for precision medicine.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 01:42:29 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Choi", "Sanghyun", ""], ["Ivkin", "Nikita", ""], ["Braverman", "Vladimir", ""], ["Jacobs", "Michael A.", ""]]}, {"id": "1809.02670", "submitter": "Zhen Zhang", "authors": "Zhen Zhang, Mianzhi Wang, Yijian Xiang, Yan Huang, Arye Nehorai", "title": "RetGK: Graph Kernels based on Return Probabilities of Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-structured data arise in wide applications, such as computer vision,\nbioinformatics, and social networks. Quantifying similarities among graphs is a\nfundamental problem. In this paper, we develop a framework for computing graph\nkernels, based on return probabilities of random walks. The advantages of our\nproposed kernels are that they can effectively exploit various node attributes,\nwhile being scalable to large datasets. We conduct extensive graph\nclassification experiments to evaluate our graph kernels. The experimental\nresults show that our graph kernels significantly outperform existing\nstate-of-the-art approaches in both accuracy and computational efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 20:57:52 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Zhang", "Zhen", ""], ["Wang", "Mianzhi", ""], ["Xiang", "Yijian", ""], ["Huang", "Yan", ""], ["Nehorai", "Arye", ""]]}, {"id": "1809.02687", "submitter": "Ran Ding", "authors": "Ran Ding, Ramesh Nallapati, Bing Xiang", "title": "Coherence-Aware Neural Topic Modeling", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are evaluated based on their ability to describe documents well\n(i.e. low perplexity) and to produce topics that carry coherent semantic\nmeaning. In topic modeling so far, perplexity is a direct optimization target.\nHowever, topic coherence, owing to its challenging computation, is not\noptimized for and is only evaluated after training. In this work, under a\nneural variational inference framework, we propose methods to incorporate a\ntopic coherence objective into the training process. We demonstrate that such a\ncoherence-aware topic model exhibits a similar level of perplexity as baseline\nmodels but achieves substantially higher topic coherence.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 21:43:30 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Ding", "Ran", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1809.02707", "submitter": "Cem Tekin", "authors": "Alihan H\\\"uy\\\"uk and Cem Tekin", "title": "Analysis of Thompson Sampling for Combinatorial Multi-armed Bandit with\n  Probabilistically Triggered Arms", "comments": "To appear in the Proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the regret of combinatorial Thompson sampling (CTS) for the\ncombinatorial multi-armed bandit with probabilistically triggered arms under\nthe semi-bandit feedback setting. We assume that the learner has access to an\nexact optimization oracle but does not know the expected base arm outcomes\nbeforehand. When the expected reward function is Lipschitz continuous in the\nexpected base arm outcomes, we derive $O(\\sum_{i =1}^m \\log T / (p_i\n\\Delta_i))$ regret bound for CTS, where $m$ denotes the number of base arms,\n$p_i$ denotes the minimum non-zero triggering probability of base arm $i$ and\n$\\Delta_i$ denotes the minimum suboptimality gap of base arm $i$. We also\ncompare CTS with combinatorial upper confidence bound (CUCB) via numerical\nexperiments on a cascading bandit problem.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 23:14:44 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 13:08:48 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["H\u00fcy\u00fck", "Alihan", ""], ["Tekin", "Cem", ""]]}, {"id": "1809.02709", "submitter": "Liyu Gong", "authors": "Liyu Gong, Qiang Cheng", "title": "Exploiting Edge Features in Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge features contain important information about graphs. However, current\nstate-of-the-art neural network models designed for graph learning, e.g. graph\nconvolutional networks (GCN) and graph attention networks (GAT), adequately\nutilize edge features, especially multi-dimensional edge features. In this\npaper, we build a new framework for a family of new graph neural network models\nthat can more sufficiently exploit edge features, including those of undirected\nor multi-dimensional edges. The proposed framework can consolidate current\ngraph neural network models; e.g. graph convolutional networks (GCN) and graph\nattention networks (GAT). The proposed framework and new models have the\nfollowing novelties: First, we propose to use doubly stochastic normalization\nof graph edge features instead of the commonly used row or symmetric\nnormalization approches used in current graph neural networks. Second, we\nconstruct new formulas for the operations in each individual layer so that they\ncan handle multi-dimensional edge features. Third, for the proposed new\nframework, edge features are adaptive across network layers. As a result, our\nproposed new framework and new models can exploit a rich source of graph\ninformation. We apply our new models to graph node classification on several\ncitation networks, whole graph classification, and regression on several\nmolecular datasets. Compared with the current state-of-the-art methods, i.e.\nGCNs and GAT, our models obtain better performance, which testify to the\nimportance of exploiting edge features in graph neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 23:18:59 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 18:55:36 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Gong", "Liyu", ""], ["Cheng", "Qiang", ""]]}, {"id": "1809.02721", "submitter": "Marcelo Prates", "authors": "Marcelo O. R. Prates, Pedro H. C. Avelar, Henrique Lemos, Luis Lamb,\n  Moshe Vardi", "title": "Learning to Solve NP-Complete Problems - A Graph Neural Network for\n  Decision TSP", "comments": "Accepted for presentation at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNN) are a promising technique for bridging\ndifferential programming and combinatorial domains. GNNs employ trainable\nmodules which can be assembled in different configurations that reflect the\nrelational structure of each problem instance. In this paper, we show that GNNs\ncan learn to solve, with very little supervision, the decision variant of the\nTraveling Salesperson Problem (TSP), a highly relevant $\\mathcal{NP}$-Complete\nproblem. Our model is trained to function as an effective message-passing\nalgorithm in which edges (embedded with their weights) communicate with\nvertices for a number of iterations after which the model is asked to decide\nwhether a route with cost $<C$ exists. We show that such a network can be\ntrained with sets of dual examples: given the optimal tour cost $C^{*}$, we\nproduce one decision instance with target cost $x\\%$ smaller and one with\ntarget cost $x\\%$ larger than $C^{*}$. We were able to obtain $80\\%$ accuracy\ntraining with $-2\\%,+2\\%$ deviations, and the same trained model can generalize\nfor more relaxed deviations with increasing performance. We also show that the\nmodel is capable of generalizing for larger problem sizes. Finally, we provide\na method for predicting the optimal route cost within $2\\%$ deviation from the\nground truth. In summary, our work shows that Graph Neural Networks are\npowerful enough to solve $\\mathcal{NP}$-Complete problems which combine\nsymbolic and numeric data.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 00:11:51 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 18:02:19 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 12:10:20 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Prates", "Marcelo O. R.", ""], ["Avelar", "Pedro H. C.", ""], ["Lemos", "Henrique", ""], ["Lamb", "Luis", ""], ["Vardi", "Moshe", ""]]}, {"id": "1809.02727", "submitter": "Richeng Jin", "authors": "Richeng Jin, Xiaofan He and Huaiyu Dai", "title": "Decentralized Differentially Private Without-Replacement Stochastic\n  Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning has achieved remarkable results in a wide variety of\ndomains, the training of models often requires large datasets that may need to\nbe collected from different individuals. As sensitive information may be\ncontained in the individual's dataset, sharing training data may lead to severe\nprivacy concerns. Therefore, there is a compelling need to develop\nprivacy-aware machine learning methods, for which one effective approach is to\nleverage the generic framework of differential privacy. Considering that\nstochastic gradient descent (SGD) is one of the mostly adopted methods for\nlarge-scale machine learning problems, two decentralized differentially private\nSGD algorithms are proposed in this work. Particularly, we focus on SGD without\nreplacement due to its favorable structure for practical implementation. In\naddition, both privacy and convergence analysis are provided for the proposed\nalgorithms. Finally, extensive experiments are performed to verify the\ntheoretical results and demonstrate the effectiveness of the proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 01:10:59 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 23:21:35 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 19:01:59 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Jin", "Richeng", ""], ["He", "Xiaofan", ""], ["Dai", "Huaiyu", ""]]}, {"id": "1809.02728", "submitter": "Daniel Smolyak", "authors": "Kathryn Gray, Daniel Smolyak, Sarkhan Badirli, George Mohler", "title": "Coupled IGMM-GANs for deep multimodal anomaly detection in human\n  mobility data", "comments": "Submitted and pending notification from AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting anomalous activity in human mobility data has a number of\napplications including road hazard sensing, telematic based insurance, and\nfraud detection in taxi services and ride sharing. In this paper we address two\nchallenges that arise in the study of anomalous human trajectories: 1) a lack\nof ground truth data on what defines an anomaly and 2) the dependence of\nexisting methods on significant pre-processing and feature engineering. While\ngenerative adversarial networks seem like a natural fit for addressing these\nchallenges, we find that existing GAN based anomaly detection algorithms\nperform poorly due to their inability to handle multimodal patterns. For this\npurpose we introduce an infinite Gaussian mixture model coupled with\n(bi-directional) generative adversarial networks, IGMM-GAN, that is able to\ngenerate synthetic, yet realistic, human mobility data and simultaneously\nfacilitates multimodal anomaly detection. Through estimation of a generative\nprobability density on the space of human trajectories, we are able to generate\nrealistic synthetic datasets that can be used to benchmark existing anomaly\ndetection methods. The estimated multimodal density also allows for a natural\ndefinition of outlier that we use for detecting anomalous trajectories. We\nillustrate our methodology and its improvement over existing GAN anomaly\ndetection on several human mobility datasets, along with MNIST.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 01:11:10 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Gray", "Kathryn", ""], ["Smolyak", "Daniel", ""], ["Badirli", "Sarkhan", ""], ["Mohler", "George", ""]]}, {"id": "1809.02731", "submitter": "Shuai Tang", "authors": "Shuai Tang, Virginia R. de Sa", "title": "Exploiting Invertible Decoders for Unsupervised Sentence Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The encoder-decoder models for unsupervised sentence representation learning\ntend to discard the decoder after being trained on a large unlabelled corpus,\nsince only the encoder is needed to map the input sentence into a vector\nrepresentation. However, parameters learnt in the decoder also contain useful\ninformation about language. In order to utilise the decoder after learning, we\npresent two types of decoding functions whose inverse can be easily derived\nwithout expensive inverse calculation. Therefore, the inverse of the decoding\nfunction serves as another encoder that produces sentence representations. We\nshow that, with careful design of the decoding functions, the model learns good\nsentence representations, and the ensemble of the representations produced from\nthe encoder and the inverse of the decoder demonstrate even better\ngeneralisation ability and solid transferability.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 01:20:45 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 00:35:49 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 04:53:58 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Tang", "Shuai", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1809.02740", "submitter": "Tim Leathart", "authors": "Tim Leathart, Eibe Frank, Bernhard Pfahringer, Geoffrey Holmes", "title": "Ensembles of Nested Dichotomies with Multiple Subset Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A system of nested dichotomies is a method of decomposing a multi-class\nproblem into a collection of binary problems. Such a system recursively applies\nbinary splits to divide the set of classes into two subsets, and trains a\nbinary classifier for each split. Many methods have been proposed to perform\nthis split, each with various advantages and disadvantages. In this paper, we\npresent a simple, general method for improving the predictive performance of\nnested dichotomies produced by any subset selection techniques that employ\nrandomness to construct the subsets. We provide a theoretical expectation for\nperformance improvements, as well as empirical results showing that our method\nimproves the root mean squared error of nested dichotomies, regardless of\nwhether they are employed as an individual model or in an ensemble setting.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 02:10:52 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 02:26:07 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Leathart", "Tim", ""], ["Frank", "Eibe", ""], ["Pfahringer", "Bernhard", ""], ["Holmes", "Geoffrey", ""]]}, {"id": "1809.02744", "submitter": "Tim Leathart", "authors": "Tim Leathart, Eibe Frank, Bernhard Pfahringer, Geoffrey Holmes", "title": "On the Calibration of Nested Dichotomies for Large Multiclass Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested dichotomies are used as a method of transforming a multiclass\nclassification problem into a series of binary problems. A tree structure is\ninduced that recursively splits the set of classes into subsets, and a binary\nclassification model learns to discriminate between the two subsets of classes\nat each node. In this paper, we demonstrate that these nested dichotomies\ntypically exhibit poor probability calibration, even when the base binary\nmodels are well calibrated. We also show that this problem is exacerbated when\nthe binary models are poorly calibrated. We discuss the effectiveness of\ndifferent calibration strategies and show that accuracy and log-loss can be\nsignificantly improved by calibrating both the internal base models and the\nfull nested dichotomy structure, especially when the number of classes is high.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 02:24:42 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 02:22:15 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2018 22:15:49 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Leathart", "Tim", ""], ["Frank", "Eibe", ""], ["Pfahringer", "Bernhard", ""], ["Holmes", "Geoffrey", ""]]}, {"id": "1809.02745", "submitter": "Hiroshi Kajino", "authors": "Hiroshi Kajino", "title": "Molecular Hypergraph Grammar with its Application to Molecular\n  Optimization", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular optimization aims to discover novel molecules with desirable\nproperties. Two fundamental challenges are: (i) it is not trivial to generate\nvalid molecules in a controllable way due to hard chemical constraints such as\nthe valency conditions, and (ii) it is often costly to evaluate a property of a\nnovel molecule, and therefore, the number of property evaluations is limited.\nThese challenges are to some extent alleviated by a combination of a\nvariational autoencoder (VAE) and Bayesian optimization (BO). VAE converts a\nmolecule into/from its latent continuous vector, and BO optimizes a latent\ncontinuous vector (and its corresponding molecule) within a limited number of\nproperty evaluations. While the most recent work, for the first time, achieved\n100% validity, its architecture is rather complex due to auxiliary neural\nnetworks other than VAE, making it difficult to train. This paper presents a\nmolecular hypergraph grammar variational autoencoder (MHG-VAE), which uses a\nsingle VAE to achieve 100% validity. Our idea is to develop a graph grammar\nencoding the hard chemical constraints, called molecular hypergraph grammar\n(MHG), which guides VAE to always generate valid molecules. We also present an\nalgorithm to construct MHG from a set of molecules.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 02:25:52 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 04:52:44 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Kajino", "Hiroshi", ""]]}, {"id": "1809.02786", "submitter": "Dan Peng", "authors": "Dan Peng, Zizhan Zheng, Xiaofeng Zhang", "title": "Structure-Preserving Transformation: Generating Diverse and Transferable\n  Adversarial Examples", "comments": "The AAAI-2019 Workshop on Artificial Intelligence for Cyber Security\n  (AICS)", "journal-ref": null, "doi": null, "report-no": "AICS/2019/09", "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are perturbed inputs designed to fool machine learning\nmodels. Most recent works on adversarial examples for image classification\nfocus on directly modifying pixels with minor perturbations. A common\nrequirement in all these works is that the malicious perturbations should be\nsmall enough (measured by an L_p norm for some p) so that they are\nimperceptible to humans. However, small perturbations can be unnecessarily\nrestrictive and limit the diversity of adversarial examples generated. Further,\nan L_p norm based distance metric ignores important structure patterns hidden\nin images that are important to human perception. Consequently, even the minor\nperturbation introduced in recent works often makes the adversarial examples\nless natural to humans. More importantly, they often do not transfer well and\nare therefore less effective when attacking black-box models especially for\nthose protected by a defense mechanism. In this paper, we propose a\nstructure-preserving transformation (SPT) for generating natural and diverse\nadversarial examples with extremely high transferability. The key idea of our\napproach is to allow perceptible deviation in adversarial examples while\nkeeping structure patterns that are central to a human classifier. Empirical\nresults on the MNIST and the fashion-MNIST datasets show that adversarial\nexamples generated by our approach can easily bypass strong adversarial\ntraining. Further, they transfer well to other target models with no loss or\nlittle loss of successful attack rate.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 10:26:50 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 15:42:00 GMT"}, {"version": "v3", "created": "Sat, 22 Dec 2018 09:07:32 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Peng", "Dan", ""], ["Zheng", "Zizhan", ""], ["Zhang", "Xiaofeng", ""]]}, {"id": "1809.02804", "submitter": "Zhi-Hua Zhou", "authors": "Peng Zhao, Le-Wen Cai, Zhi-Hua Zhou", "title": "Handling Concept Drift via Model Reuse", "comments": null, "journal-ref": "Machine Learning, 2020, 109(3): 533-568", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications, data are often collected in the form of\nstream, and thus the distribution usually changes in nature, which is referred\nas concept drift in literature. We propose a novel and effective approach to\nhandle concept drift via model reuse, leveraging previous knowledge by reusing\nmodels. Each model is associated with a weight representing its reusability\ntowards current data, and the weight is adaptively adjusted according to the\nmodel performance. We provide generalization and regret analysis. Experimental\nresults also validate the superiority of our approach on both synthetic and\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 14:13:46 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhao", "Peng", ""], ["Cai", "Le-Wen", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1809.02811", "submitter": "Zacarias Curi Filho", "authors": "Zacarias Curi and Alceu de Souza Britto Jr and Emerson Cabrera Paraiso", "title": "Multi-label Classification of User Reactions in Online News", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase in the number of Internet users and the strong interaction\nbrought by Web 2.0 made the Opinion Mining an important task in the area of\nnatural language processing. Although several methods are capable of performing\nthis task, few use multi-label classification, where there is a group of true\nlabels for each example. This type of classification is useful for situations\nwhere the opinions are analyzed from the perspective of the reader, this\nhappens because each person can have different interpretations and opinions on\nthe same subject. This paper discuss the efficiency of problem transformation\nmethods combined with different classification algorithms for the task of\nmulti-label classification of reactions in news texts. To do that, extensive\ntests were carried out on two news corpora written in Brazilian Portuguese\nannotated with reactions. A new corpus called BFRC-PT is presented. In the\ntests performed, the highest number of correct predictions was obtained with\nthe Classifier Chains method combined with the Random Forest algorithm. When\nconsidering the class distribution, the best results were obtained with the\nBinary Relevance method combined with the LSTM and Random Forest algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 14:47:26 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 16:33:30 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Curi", "Zacarias", ""], ["Britto", "Alceu de Souza", "Jr"], ["Paraiso", "Emerson Cabrera", ""]]}, {"id": "1809.02836", "submitter": "Yiding Hao", "authors": "Yiding Hao, William Merrill, Dana Angluin, Robert Frank, Noah Amsel,\n  Andrew Benz, and Simon Mendelsohn", "title": "Context-Free Transductions with Neural Stacks", "comments": "To appear in the proceedings of the Analyzing and Interpreting Neural\n  Networks for NLP workshop at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the behavior of stack-augmented recurrent neural network\n(RNN) models. Due to the architectural similarity between stack RNNs and\npushdown transducers, we train stack RNN models on a number of tasks, including\nstring reversal, context-free language modelling, and cumulative XOR\nevaluation. Examining the behavior of our networks, we show that\nstack-augmented RNNs can discover intuitive stack-based strategies for solving\nour tasks. However, stack RNNs are more difficult to train than classical\narchitectures such as LSTMs. Rather than employ stack-based strategies, more\ncomplex networks often find approximate solutions by using the stack as\nunstructured memory.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 17:04:53 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Hao", "Yiding", ""], ["Merrill", "William", ""], ["Angluin", "Dana", ""], ["Frank", "Robert", ""], ["Amsel", "Noah", ""], ["Benz", "Andrew", ""], ["Mendelsohn", "Simon", ""]]}, {"id": "1809.02838", "submitter": "Linfeng Liu", "authors": "Linfeng Liu, Liping Liu", "title": "Non-Parametric Variational Inference with Graph Convolutional Networks\n  for Gaussian Processes", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference for GP models with non-Gaussian noises is computationally expensive\nwhen dealing with large datasets. Many recent inference methods approximate the\nposterior distribution with a simpler distribution defined on a small number of\ninducing points. The inference is accurate only when data points have strong\ncorrelation with these inducing points. In this paper, we consider the\ninference problem in a different direction: GP function values in the posterior\nare mostly correlated in short distance. We construct a variational\ndistribution such that the inference for a data point considers only its\nneighborhood. With this construction, the variational lower bound is highly\ndecomposible, hence we can run stochastic optimization with very small batches.\nWe then train Graph Convolutional Networks as a reusable model to identify\nvariational parameters for each data point. Model reuse greatly reduces the\nnumber of parameters and the number of iterations needed in optimization. The\nproposed method significantly speeds up the inference and often gets more\naccurate results than previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 17:20:45 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Liu", "Linfeng", ""], ["Liu", "Liping", ""]]}, {"id": "1809.02839", "submitter": "Chi-Chung Chen", "authors": "Chi-Chung Chen, Chia-Lin Yang, Hsiang-Yun Cheng", "title": "Efficient and Robust Parallel DNN Training through Model Parallelism on\n  Multi-GPU Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training process of Deep Neural Network (DNN) is compute-intensive, often\ntaking days to weeks to train a DNN model. Therefore, parallel execution of DNN\ntraining on GPUs is a widely adopted approach to speed up the process nowadays.\nDue to the implementation simplicity, data parallelism is currently the most\ncommonly used parallelization method. Nonetheless, data parallelism suffers\nfrom excessive inter-GPU communication overhead due to frequent weight\nsynchronization among GPUs. Another approach is pipelined model parallelism,\nwhich partitions a DNN model among GPUs, and processes multiple mini-batches\nconcurrently. This approach can significantly reduce inter-GPU communication\ncost compared to data parallelism. However, pipelined model parallelism faces\nthe weight staleness issue; that is, gradients are computed with stale weights,\nleading to training instability and accuracy loss. In this paper, we present a\npipelined model parallel execution method that enables high GPU utilization\nwhile maintaining robust training accuracy via a novel weight prediction\ntechnique, SpecTrain. Experimental results show that our proposal achieves up\nto 8.91x speedup compared to data parallelism on a 4-GPU platform while\nmaintaining comparable model accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 17:21:58 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 04:04:34 GMT"}, {"version": "v3", "created": "Sun, 28 Apr 2019 15:36:28 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 10:13:24 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Chen", "Chi-Chung", ""], ["Yang", "Chia-Lin", ""], ["Cheng", "Hsiang-Yun", ""]]}, {"id": "1809.02840", "submitter": "Lisa Zhang", "authors": "Lisa Zhang, Gregory Rosenblatt, Ethan Fetaya, Renjie Liao, William E.\n  Byrd, Matthew Might, Raquel Urtasun, Richard Zemel", "title": "Neural Guided Constraint Logic Programming for Program Synthesis", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing programs using example input/outputs is a classic problem in\nartificial intelligence. We present a method for solving Programming By Example\n(PBE) problems by using a neural model to guide the search of a constraint\nlogic programming system called miniKanren. Crucially, the neural model uses\nminiKanren's internal representation as input; miniKanren represents a PBE\nproblem as recursive constraints imposed by the provided examples. We explore\nRecurrent Neural Network and Graph Neural Network models. We contribute a\nmodified miniKanren, drivable by an external agent, available at\nhttps://github.com/xuexue/neuralkanren. We show that our neural-guided approach\nusing constraints can synthesize programs faster in many cases, and\nimportantly, can generalize to larger problems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 17:25:33 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 10:51:08 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 12:10:05 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Zhang", "Lisa", ""], ["Rosenblatt", "Gregory", ""], ["Fetaya", "Ethan", ""], ["Liao", "Renjie", ""], ["Byrd", "William E.", ""], ["Might", "Matthew", ""], ["Urtasun", "Raquel", ""], ["Zemel", "Richard", ""]]}, {"id": "1809.02855", "submitter": "Amr El-Wakeel", "authors": "Amr S. El-Wakeel, Aboelmagd Noureldin, Hossam S. Hassanein and Nizar\n  Zorba", "title": "iDriveSense: Dynamic Route Planning Involving Roads Quality Information", "comments": "Globecom 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the expeditious growth in the information and communication\ntechnologies, smart cities have raised the expectations in terms of efficient\nfunctioning and management. One key aspect of residents' daily comfort is\nassured through affording reliable traffic management and route planning.\nComprehensively, the majority of the present trip planning applications and\nservice providers are enabling their trip planning recommendations relying on\nshortest paths and/or fastest routes. However, such suggestions may discount\ndrivers' preferences with respect to safe and less disturbing trips. Road\nanomalies such as cracks, potholes, and manholes induce risky driving scenarios\nand can lead to vehicles damages and costly repairs. Accordingly, in this\npaper, we propose a crowdsensing based dynamic route planning system.\nLeveraging both the vehicle motion sensors and the inertial sensors within the\nsmart devices, road surface types and anomalies have been detected and\ncategorized. In addition, the monitored events are geo-referenced utilizing GPS\nreceivers on both vehicles and smart devices. Consequently, road segments\nassessments are conducted using fuzzy system models based on aspects such as\nthe number of anomalies and their severity levels in each road segment.\nAfterward, another fuzzy model is adopted to recommend the best trip routes\nbased on the road segments quality in each potential route. Extensive road\nexperiments are held to build and show the potential of the proposed system.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 19:21:09 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["El-Wakeel", "Amr S.", ""], ["Noureldin", "Aboelmagd", ""], ["Hassanein", "Hossam S.", ""], ["Zorba", "Nizar", ""]]}, {"id": "1809.02860", "submitter": "Lu Bai", "authors": "Lixin Cui, Lu Bai, Zhihong Zhang, Yue Wang, Edwin R. Hancock", "title": "Identifying The Most Informative Features Using A Structurally\n  Interacting Elastic Net", "comments": "Neurocomputing (Accept/In Press), ISSN: 0925-2312", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection can efficiently identify the most informative features with\nrespect to the target feature used in training. However, state-of-the-art\nvector-based methods are unable to encapsulate the relationships between\nfeature samples into the feature selection process, thus leading to significant\ninformation loss. To address this problem, we propose a new graph-based\nstructurally interacting elastic net method for feature selection.\nSpecifically, we commence by constructing feature graphs that can incorporate\npairwise relationship between samples. With the feature graphs to hand, we\npropose a new information theoretic criterion to measure the joint relevance of\ndifferent pairwise feature combinations with respect to the target feature\ngraph representation. This measure is used to obtain a structural interaction\nmatrix where the elements represent the proposed information theoretic measure\nbetween feature pairs. We then formulate a new optimization model through the\ncombination of the structural interaction matrix and an elastic net regression\nmodel for the feature subset selection problem. This allows us to a) preserve\nthe information of the original vectorial space, b) remedy the information loss\nof the original feature space caused by using graph representation, and c)\npromote a sparse solution and also encourage correlated features to be\nselected. Because the proposed optimization problem is non-convex, we develop\nan efficient alternating direction multiplier method (ADMM) to locate the\noptimal solutions. Extensive experiments on various datasets demonstrate the\neffectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 19:40:14 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Cui", "Lixin", ""], ["Bai", "Lu", ""], ["Zhang", "Zhihong", ""], ["Wang", "Yue", ""], ["Hancock", "Edwin R.", ""]]}, {"id": "1809.02861", "submitter": "Ambra Demontis Ph.D.", "authors": "Ambra Demontis, Marco Melis, Maura Pintor, Matthew Jagielski, Battista\n  Biggio, Alina Oprea, Cristina Nita-Rotaru, Fabio Roli", "title": "Why Do Adversarial Attacks Transfer? Explaining Transferability of\n  Evasion and Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferability captures the ability of an attack against a machine-learning\nmodel to be effective against a different, potentially unknown, model.\nEmpirical evidence for transferability has been shown in previous work, but the\nunderlying reasons why an attack transfers or not are not yet well understood.\nIn this paper, we present a comprehensive analysis aimed to investigate the\ntransferability of both test-time evasion and training-time poisoning attacks.\nWe provide a unifying optimization framework for evasion and poisoning attacks,\nand a formal definition of transferability of such attacks. We highlight two\nmain factors contributing to attack transferability: the intrinsic adversarial\nvulnerability of the target model, and the complexity of the surrogate model\nused to optimize the attack. Based on these insights, we define three metrics\nthat impact an attack's transferability. Interestingly, our results derived\nfrom theoretical analysis hold for both evasion and poisoning attacks, and are\nconfirmed experimentally using a wide range of linear and non-linear\nclassifiers and datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 19:44:47 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 01:15:43 GMT"}, {"version": "v3", "created": "Wed, 12 Jun 2019 08:52:37 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 10:01:26 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Demontis", "Ambra", ""], ["Melis", "Marco", ""], ["Pintor", "Maura", ""], ["Jagielski", "Matthew", ""], ["Biggio", "Battista", ""], ["Oprea", "Alina", ""], ["Nita-Rotaru", "Cristina", ""], ["Roli", "Fabio", ""]]}, {"id": "1809.02864", "submitter": "Kfir Levy Yehuda", "authors": "Kfir Y. Levy, Alp Yurtsever, Volkan Cevher", "title": "Online Adaptive Methods, Universality and Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for convex unconstrained optimization that, without\nany modifications, ensures: (i) accelerated convergence rate for smooth\nobjectives, (ii) standard convergence rate in the general (non-smooth) setting,\nand (iii) standard convergence rate in the stochastic optimization setting. To\nthe best of our knowledge, this is the first method that simultaneously applies\nto all of the above settings. At the heart of our method is an adaptive\nlearning rate rule that employs importance weights, in the spirit of adaptive\nonline learning algorithms (Duchi et al., 2011; Levy, 2017), combined with an\nupdate that linearly couples two sequences, in the spirit of (Allen-Zhu and\nOrecchia, 2017). An empirical examination of our method demonstrates its\napplicability to the above mentioned scenarios and corroborates our theoretical\nfindings.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 20:02:20 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Levy", "Kfir Y.", ""], ["Yurtsever", "Alp", ""], ["Cevher", "Volkan", ""]]}, {"id": "1809.02869", "submitter": "Pedram Daee", "authors": "Tomi Peltola, Mustafa Mert \\c{C}elikok, Pedram Daee, Samuel Kaski", "title": "Machine Teaching of Active Sequential Learners", "comments": "24 pages, 16 figures. This version focuses more on machine teaching\n  while the previous version focused more on human-computer interaction and\n  user modelling. The title has been updated accordingly. Code and data\n  available at\n  https://github.com/AaltoPML/machine-teaching-of-active-sequential-learners .\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine teaching addresses the problem of finding the best training data that\ncan guide a learning algorithm to a target model with minimal effort. In\nconventional settings, a teacher provides data that are consistent with the\ntrue data distribution. However, for sequential learners which actively choose\ntheir queries, such as multi-armed bandits and active learners, the teacher can\nonly provide responses to the learner's queries, not design the full data. In\nthis setting, consistent teachers can be sub-optimal for finite horizons. We\nformulate this sequential teaching problem, which current techniques in machine\nteaching do not address, as a Markov decision process, with the dynamics\nnesting a model of the learner and the actions being the teacher's responses.\nFurthermore, we address the complementary problem of learning from a teacher\nthat plans: to recognise the teaching intent of the responses, the learner is\nendowed with a model of the teacher. We test the formulation with multi-armed\nbandit learners in simulated experiments and a user study. The results show\nthat learning is improved by (i) planning teaching and (ii) the learner having\na model of the teacher. The approach gives tools to taking into account\nstrategic (planning) behaviour of users of interactive intelligent systems,\nsuch as recommendation engines, by considering them as boundedly optimal\nteachers.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 20:39:31 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 10:40:50 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 06:30:11 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Peltola", "Tomi", ""], ["\u00c7elikok", "Mustafa Mert", ""], ["Daee", "Pedram", ""], ["Kaski", "Samuel", ""]]}, {"id": "1809.02880", "submitter": "Zachary Ross", "authors": "Zachary E. Ross, Yisong Yue, Men-Andrin Meier, Egill Hauksson, Thomas\n  H. Heaton", "title": "PhaseLink: A Deep Learning Approach to Seismic Phase Association", "comments": "9 figures", "journal-ref": null, "doi": "10.1029/2018JB016674", "report-no": null, "categories": "cs.LG physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seismic phase association is a fundamental task in seismology that pertains\nto linking together phase detections on different sensors that originate from a\ncommon earthquake. It is widely employed to detect earthquakes on permanent and\ntemporary seismic networks, and underlies most seismicity catalogs produced\naround the world. This task can be challenging because the number of sources is\nunknown, events frequently overlap in time, or can occur simultaneously in\ndifferent parts of a network. We present PhaseLink, a framework based on recent\nadvances in deep learning for grid-free earthquake phase association. Our\napproach learns to link phases together that share a common origin, and is\ntrained entirely on tens of millions of synthetic sequences of P- and S-wave\narrival times generated using a simple 1D velocity model. Our approach is\nsimple to implement for any tectonic regime, suitable for real-time processing,\nand can naturally incorporate errors in arrival time picks. Rather than tuning\na set of ad hoc hyperparameters to improve performance, PhaseLink can be\nimproved by simply adding examples of problematic cases to the training\ndataset. We demonstrate the state-of-the-art performance of PhaseLink on a\nchallenging recent sequence from southern California, and synthesized sequences\nfrom Japan designed to test the point at which the method fails. For the\nexamined datasets, PhaseLink can precisely associate P- and S-picks to events\nthat are separated by ~12 seconds in origin time. This approach is expected to\nimprove the resolution of seismicity catalogs, add stability to real-time\nseismic monitoring, and streamline automated processing of large seismic\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 21:39:29 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 20:44:10 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Ross", "Zachary E.", ""], ["Yue", "Yisong", ""], ["Meier", "Men-Andrin", ""], ["Hauksson", "Egill", ""], ["Heaton", "Thomas H.", ""]]}, {"id": "1809.02882", "submitter": "Weicheng Kuo", "authors": "Weicheng Kuo, Christian H\\\"ane, Esther Yuh, Pratik Mukherjee, and\n  Jitendra Malik", "title": "Cost-Sensitive Active Learning for Intracranial Hemorrhage Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning for clinical applications is subject to stringent performance\nrequirements, which raises a need for large labeled datasets. However, the\nenormous cost of labeling medical data makes this challenging. In this paper,\nwe build a cost-sensitive active learning system for the problem of\nintracranial hemorrhage detection and segmentation on head computed tomography\n(CT). We show that our ensemble method compares favorably with the\nstate-of-the-art, while running faster and using less memory. Moreover, our\nexperiments are done using a substantially larger dataset than earlier papers\non this topic. Since the labeling time could vary tremendously across examples,\nwe model the labeling time and optimize the return on investment. We validate\nthis idea by core-set selection on our large labeled dataset and by growing it\nwith data from the wild.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 21:43:18 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Kuo", "Weicheng", ""], ["H\u00e4ne", "Christian", ""], ["Yuh", "Esther", ""], ["Mukherjee", "Pratik", ""], ["Malik", "Jitendra", ""]]}, {"id": "1809.02918", "submitter": "Yali Du", "authors": "Yali Du, Meng Fang, Jinfeng Yi, Jun Cheng, Dacheng Tao", "title": "Towards Query Efficient Black-box Attacks: An Input-free Perspective", "comments": "Accepted by 11th ACM Workshop on Artificial Intelligence and Security\n  (AISec) with the 25th ACM Conference on Computer and Communications Security\n  (CCS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have highlighted that deep neural networks (DNNs) are\nvulnerable to adversarial attacks, even in a black-box scenario. However, most\nof the existing black-box attack algorithms need to make a huge amount of\nqueries to perform attacks, which is not practical in the real world. We note\none of the main reasons for the massive queries is that the adversarial example\nis required to be visually similar to the original image, but in many cases,\nhow adversarial examples look like does not matter much. It inspires us to\nintroduce a new attack called \\emph{input-free} attack, under which an\nadversary can choose an arbitrary image to start with and is allowed to add\nperceptible perturbations on it. Following this approach, we propose two\ntechniques to significantly reduce the query complexity. First, we initialize\nan adversarial example with a gray color image on which every pixel has roughly\nthe same importance for the target model. Then we shrink the dimension of the\nattack space by perturbing a small region and tiling it to cover the input\nimage. To make our algorithm more effective, we stabilize a projected gradient\nascent algorithm with momentum, and also propose a heuristic approach for\nregion size selection. Through extensive experiments, we show that with only\n1,701 queries on average, we can perturb a gray image to any target class of\nImageNet with a 100\\% success rate on InceptionV3. Besides, our algorithm has\nsuccessfully defeated two real-world systems, the Clarifai food detection API\nand the Baidu Animal Identification API.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 03:49:06 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Du", "Yali", ""], ["Fang", "Meng", ""], ["Yi", "Jinfeng", ""], ["Cheng", "Jun", ""], ["Tao", "Dacheng", ""]]}, {"id": "1809.02925", "submitter": "Jonathan Tompson", "authors": "Ilya Kostrikov, Kumar Krishna Agrawal, Debidatta Dwibedi, Sergey\n  Levine, Jonathan Tompson", "title": "Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward\n  Bias in Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify two issues with the family of algorithms based on the Adversarial\nImitation Learning framework. The first problem is implicit bias present in the\nreward functions used in these algorithms. While these biases might work well\nfor some environments, they can also lead to sub-optimal behavior in others.\nSecondly, even though these algorithms can learn from few expert\ndemonstrations, they require a prohibitively large number of interactions with\nthe environment in order to imitate the expert for many real-world\napplications. In order to address these issues, we propose a new algorithm\ncalled Discriminator-Actor-Critic that uses off-policy Reinforcement Learning\nto reduce policy-environment interaction sample complexity by an average factor\nof 10. Furthermore, since our reward function is designed to be unbiased, we\ncan apply our algorithm to many problems without making any task-specific\nadjustments.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 05:37:25 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 17:27:25 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Kostrikov", "Ilya", ""], ["Agrawal", "Kumar Krishna", ""], ["Dwibedi", "Debidatta", ""], ["Levine", "Sergey", ""], ["Tompson", "Jonathan", ""]]}, {"id": "1809.02926", "submitter": "Liting Sun", "authors": "Liting Sun, Wei Zhan and Masayoshi Tomizuka", "title": "Probabilistic Prediction of Interactive Driving Behavior via\n  Hierarchical Inverse Reinforcement Learning", "comments": "ITSC2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles (AVs) are on the road. To safely and efficiently interact\nwith other road participants, AVs have to accurately predict the behavior of\nsurrounding vehicles and plan accordingly. Such prediction should be\nprobabilistic, to address the uncertainties in human behavior. Such prediction\nshould also be interactive, since the distribution over all possible\ntrajectories of the predicted vehicle depends not only on historical\ninformation, but also on future plans of other vehicles that interact with it.\nTo achieve such interaction-aware predictions, we propose a probabilistic\nprediction approach based on hierarchical inverse reinforcement learning (IRL).\nFirst, we explicitly consider the hierarchical trajectory-generation process of\nhuman drivers involving both discrete and continuous driving decisions. Based\non this, the distribution over all future trajectories of the predicted vehicle\nis formulated as a mixture of distributions partitioned by the discrete\ndecisions. Then we apply IRL hierarchically to learn the distributions from\nreal human demonstrations. A case study for the ramp-merging driving scenario\nis provided. The quantitative results show that the proposed approach can\naccurately predict both the discrete driving decisions such as yield or pass as\nwell as the continuous trajectories.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 05:44:16 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Sun", "Liting", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1809.02927", "submitter": "Jiachen Li", "authors": "Jiachen Li, Hengbo Ma, Wei Zhan and Masayoshi Tomizuka", "title": "Generic Probabilistic Interactive Situation Recognition and Prediction:\n  From Virtual to Real", "comments": "Accepted by The 21st IEEE International Conference on Intelligent\n  Transportation Systems (2018 IEEE ITSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and robust recognition and prediction of traffic situation plays an\nimportant role in autonomous driving, which is a prerequisite for risk\nassessment and effective decision making. Although there exist a lot of works\ndealing with modeling driver behavior of a single object, it remains a\nchallenge to make predictions for multiple highly interactive agents that react\nto each other simultaneously. In this work, we propose a generic probabilistic\nhierarchical recognition and prediction framework which employs a two-layer\nHidden Markov Model (TLHMM) to obtain the distribution of potential situations\nand a learning-based dynamic scene evolution model to sample a group of future\ntrajectories. Instead of predicting motions of a single entity, we propose to\nget the joint distribution by modeling multiple interactive agents as a whole\nsystem. Moreover, due to the decoupling property of the layered structure, our\nmodel is suitable for knowledge transfer from simulation to real world\napplications as well as among different traffic scenarios, which can reduce the\ncomputational efforts of training and the demand for a large data amount. A\ncase study of highway ramp merging scenario is demonstrated to verify the\neffectiveness and accuracy of the proposed framework.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 06:02:50 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Li", "Jiachen", ""], ["Ma", "Hengbo", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1809.02963", "submitter": "Naoki Hayashi", "authors": "Naoki Hayashi", "title": "Variational Approximation Error in Bayesian Non-negative Matrix\n  Factorization", "comments": "21 pages. 1 table. Revision in Neural Networks", "journal-ref": "Neural Networks, Volume 126, June 2020, pp. 65-75", "doi": "10.1016/j.neunet.2020.03.009", "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) is a knowledge discovery method that\nis used in many fields. Variational inference and Gibbs sampling methods for it\nare also wellknown. However, the variational approximation error has not been\nclarified yet, because NMF is not statistically regular and the prior\ndistribution used in variational Bayesian NMF (VBNMF) has zero or divergence\npoints. In this paper, using algebraic geometrical methods, we theoretically\nanalyze the difference in negative log evidence (a.k.a. free energy) between\nVBNMF and Bayesian NMF, i.e., the Kullback-Leibler divergence between the\nvariational posterior and the true posterior. We derive an upper bound for the\nlearning coefficient (a.k.a. the real log canonical threshold) in Bayesian NMF.\nBy using the upper bound, we find a lower bound for the approximation error,\nasymptotically. The result quantitatively shows how well the VBNMF algorithm\ncan approximate Bayesian NMF; the lower bound depends on the hyperparameters\nand the true nonnegative rank. A numerical experiment demonstrates the\ntheoretical result.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 12:56:37 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 11:17:07 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 12:31:34 GMT"}, {"version": "v4", "created": "Thu, 20 Feb 2020 11:00:13 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Hayashi", "Naoki", ""]]}, {"id": "1809.03006", "submitter": "Alexei Botchkarev", "authors": "Alexei Botchkarev", "title": "Performance Metrics (Error Measures) in Machine Learning Regression,\n  Forecasting and Prognostics: Properties and Typology", "comments": null, "journal-ref": "Interdisciplinary Journal of Information, Knowledge, and\n  Management, 2019, 14, 45-79", "doi": "10.28945/4184", "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance metrics (error measures) are vital components of the evaluation\nframeworks in various fields. The intention of this study was to overview of a\nvariety of performance metrics and approaches to their classification. The main\ngoal of the study was to develop a typology that will help to improve our\nknowledge and understanding of metrics and facilitate their selection in\nmachine learning regression, forecasting and prognostics. Based on the analysis\nof the structure of numerous performance metrics, we propose a framework of\nmetrics which includes four (4) categories: primary metrics, extended metrics,\ncomposite metrics, and hybrid sets of metrics. The paper identified three (3)\nkey components (dimensions) that determine the structure and properties of\nprimary metrics: method of determining point distance, method of normalization,\nmethod of aggregation of point distances over a data set.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 16:58:33 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Botchkarev", "Alexei", ""]]}, {"id": "1809.03008", "submitter": "Kai Xiao", "authors": "Kai Y. Xiao, Vincent Tjeng, Nur Muhammad Shafiullah, Aleksander Madry", "title": "Training for Faster Adversarial Robustness Verification via Inducing\n  ReLU Stability", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR) 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the concept of co-design in the context of neural network\nverification. Specifically, we aim to train deep neural networks that not only\nare robust to adversarial perturbations but also whose robustness can be\nverified more easily. To this end, we identify two properties of network models\n- weight sparsity and so-called ReLU stability - that turn out to significantly\nimpact the complexity of the corresponding verification task. We demonstrate\nthat improving weight sparsity alone already enables us to turn computationally\nintractable verification problems into tractable ones. Then, improving ReLU\nstability leads to an additional 4-13x speedup in verification times. An\nimportant feature of our methodology is its \"universality,\" in the sense that\nit can be used with a broad range of training procedures and verification\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 17:10:16 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 17:58:07 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 21:04:31 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Xiao", "Kai Y.", ""], ["Tjeng", "Vincent", ""], ["Shafiullah", "Nur Muhammad", ""], ["Madry", "Aleksander", ""]]}, {"id": "1809.03018", "submitter": "Houtao Deng", "authors": "Houtao Deng, Ganesh Krishnan, Ji Chen, Dong Liang", "title": "Leveraging Elastic Demand for Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand variance can result in a mismatch between planned supply and actual\ndemand. Demand shaping strategies such as pricing can be used to shift elastic\ndemand to reduce the imbalance. In this work, we propose to consider elastic\ndemand in the forecasting phase. We present a method to reallocate the\nhistorical elastic demand to reduce variance, thus making forecasting and\nsupply planning more effective.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 18:19:10 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Deng", "Houtao", ""], ["Krishnan", "Ganesh", ""], ["Chen", "Ji", ""], ["Liang", "Dong", ""]]}, {"id": "1809.03019", "submitter": "Samet Oymak", "authors": "Samet Oymak", "title": "Stochastic Gradient Descent Learns State Equations with Nonlinear\n  Activations", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study discrete time dynamical systems governed by the state equation\n$h_{t+1}=\\phi(Ah_t+Bu_t)$. Here $A,B$ are weight matrices, $\\phi$ is an\nactivation function, and $u_t$ is the input data. This relation is the backbone\nof recurrent neural networks (e.g. LSTMs) which have broad applications in\nsequential learning tasks. We utilize stochastic gradient descent to learn the\nweight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We\nprove that SGD estimate linearly converges to the ground truth weights while\nusing near-optimal sample size. Our results apply to increasing activations\nwhose derivatives are bounded away from zero. The analysis is based on i) a\nnovel SGD convergence result with nonlinear activations and ii) careful\nstatistical characterization of the state vector. Numerical experiments verify\nthe fast convergence of SGD on ReLU and leaky ReLU in consistence with our\ntheory.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 18:22:26 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Oymak", "Samet", ""]]}, {"id": "1809.03041", "submitter": "Denali Molitor", "authors": "Denali Molitor and Deanna Needell", "title": "An iterative method for classification of binary data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's data driven world, storing, processing, and gleaning insights from\nlarge-scale data are major challenges. Data compression is often required in\norder to store large amounts of high-dimensional data, and thus, efficient\ninference methods for analyzing compressed data are necessary. Building on a\nrecently designed simple framework for classification using binary data, we\ndemonstrate that one can improve classification accuracy of this approach\nthrough iterative applications whose output serves as input to the next\napplication. As a side consequence, we show that the original framework can be\nused as a data preprocessing step to improve the performance of other methods,\nsuch as support vector machines. For several simple settings, we showcase the\nability to obtain theoretical guarantees for the accuracy of the iterative\nclassification method. The simplicity of the underlying classification\nframework makes it amenable to theoretical analysis and studying this approach\nwill hopefully serve as a step toward developing theory for more sophisticated\ndeep learning technologies.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 20:37:10 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Molitor", "Denali", ""], ["Needell", "Deanna", ""]]}, {"id": "1809.03044", "submitter": "Alexander Kuhnle", "authors": "Alexander Kuhnle, Huiyuan Xie, Ann Copestake", "title": "How clever is the FiLM model, and how clever can it be?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FiLM model achieves close-to-perfect performance on the diagnostic CLEVR\ndataset and is distinguished from other such models by having a comparatively\nsimple and easily transferable architecture. In this paper, we investigate in\nmore detail the ability of FiLM to learn various linguistic constructions. Our\nmain results show that (a) FiLM is not able to learn relational statements\nstraight away except for very simple instances, (b) training on a broader set\nof instances as well as pretraining on simpler instance types can help\nalleviate these learning difficulties, (c) mixing is less robust than\npretraining and very sensitive to the compositional structure of the dataset.\nOverall, our results suggest that the approach of big all-encompassing datasets\nand the paradigm of \"the effectiveness of data\" may have fundamental\nlimitations.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 21:08:57 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Kuhnle", "Alexander", ""], ["Xie", "Huiyuan", ""], ["Copestake", "Ann", ""]]}, {"id": "1809.03045", "submitter": "Agniva Chowdhury", "authors": "Agniva Chowdhury, Jiasen Yang, Petros Drineas", "title": "Randomized Iterative Algorithms for Fisher Discriminant Analysis", "comments": "23 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fisher discriminant analysis (FDA) is a widely used method for classification\nand dimensionality reduction. When the number of predictor variables greatly\nexceeds the number of observations, one of the alternatives for conventional\nFDA is regularized Fisher discriminant analysis (RFDA). In this paper, we\npresent a simple, iterative, sketching-based algorithm for RFDA that comes with\nprovable accuracy guarantees when compared to the conventional approach. Our\nanalysis builds upon two simple structural results that boil down to randomized\nmatrix multiplication, a fundamental and well-understood primitive of\nrandomized linear algebra. We analyze the behavior of RFDA when the ridge\nleverage and the standard leverage scores are used to select predictor\nvariables and we prove that accurate approximations can be achieved by a sample\nwhose size depends on the effective degrees of freedom of the RFDA problem. Our\nresults yield significant improvements over existing approaches and our\nempirical evaluations support our theoretical analyses.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 21:10:30 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 04:51:12 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Chowdhury", "Agniva", ""], ["Yang", "Jiasen", ""], ["Drineas", "Petros", ""]]}, {"id": "1809.03048", "submitter": "Alexander Mamonov V", "authors": "Vladimir Druskin, Alexander V. Mamonov and Mikhail Zaslavsky", "title": "Distance preserving model order reduction of graph-Laplacians and\n  cluster analysis", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-Laplacians and their spectral embeddings play an important role in\nmultiple areas of machine learning. This paper is focused on graph-Laplacian\ndimension reduction for the spectral clustering of data as a primary\napplication. Spectral embedding provides a low-dimensional parametrization of\nthe data manifold which makes the subsequent task (e.g., clustering) much\neasier. However, despite reducing the dimensionality of data, the overall\ncomputational cost may still be prohibitive for large data sets due to two\nfactors. First, computing the partial eigendecomposition of the graph-Laplacian\ntypically requires a large Krylov subspace. Second, after the spectral\nembedding is complete, one still has to operate with the same number of data\npoints. For example, clustering of the embedded data is typically performed\nwith various relaxations of k-means which computational cost scales poorly with\nrespect to the size of data set. In this work, we switch the focus from the\nentire data set to a subset of graph vertices (target subset). We develop two\nnovel algorithms for such low-dimensional representation of the original graph\nthat preserves important global distances between the nodes of the target\nsubset. In particular, it allows to ensure that target subset clustering is\nconsistent with the spectral clustering of the full data set if one would\nperform such. That is achieved by a properly parametrized reduced-order model\n(ROM) of the graph-Laplacian that approximates accurately the diffusion\ntransfer function of the original graph for inputs and outputs restricted to\nthe target subset. Working with a small target subset reduces greatly the\nrequired dimension of Krylov subspace and allows to exploit the conventional\nalgorithms (like approximations of k-means) in the regimes when they are most\nrobust and efficient.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 22:04:15 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 17:48:12 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Druskin", "Vladimir", ""], ["Mamonov", "Alexander V.", ""], ["Zaslavsky", "Mikhail", ""]]}, {"id": "1809.03051", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Xiaoli Z. Fern, Prasad Tadepalli", "title": "Attentional Multi-Reading Sarcasm Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing sarcasm often requires a deep understanding of multiple sources\nof information, including the utterance, the conversational context, and real\nworld facts. Most of the current sarcasm detection systems consider only the\nutterance in isolation. There are some limited attempts toward taking into\naccount the conversational context. In this paper, we propose an interpretable\nend-to-end model that combines information from both the utterance and the\nconversational context to detect sarcasm, and demonstrate its effectiveness\nthrough empirical evaluations. We also study the behavior of the proposed model\nto provide explanations for the model's decisions. Importantly, our model is\ncapable of determining the impact of utterance and conversational context on\nthe model's decisions. Finally, we provide an ablation study to illustrate the\nimpact of different components of the proposed model.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 22:33:20 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Ghaeini", "Reza", ""], ["Fern", "Xiaoli Z.", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1809.03054", "submitter": "Filip Hanzely", "authors": "Filip Hanzely and Konstantin Mishchenko and Peter Richtarik", "title": "SEGA: Variance Reduction via Gradient Sketching", "comments": "Accepted to the NIPS conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a randomized first order optimization method--SEGA (SkEtched\nGrAdient method)-- which progressively throughout its iterations builds a\nvariance-reduced estimate of the gradient from random linear measurements\n(sketches) of the gradient obtained from an oracle. In each iteration, SEGA\nupdates the current estimate of the gradient through a sketch-and-project\noperation using the information provided by the latest sketch, and this is\nsubsequently used to compute an unbiased estimate of the true gradient through\na random relaxation procedure. This unbiased estimate is then used to perform a\ngradient step. Unlike standard subspace descent methods, such as coordinate\ndescent, SEGA can be used for optimization problems with a non-separable\nproximal term. We provide a general convergence analysis and prove linear\nconvergence for strongly convex objectives. In the special case of coordinate\nsketches, SEGA can be enhanced with various techniques such as importance\nsampling, minibatching and acceleration, and its rate is up to a small constant\nfactor identical to the best-known rate of coordinate descent.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 22:40:52 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 07:51:59 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Hanzely", "Filip", ""], ["Mishchenko", "Konstantin", ""], ["Richtarik", "Peter", ""]]}, {"id": "1809.03060", "submitter": "S\\\"oren Mindermann", "authors": "S\\\"oren Mindermann, Rohin Shah, Adam Gleave, Dylan Hadfield-Menell", "title": "Active Inverse Reward Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designers of AI agents often iterate on the reward function in a\ntrial-and-error process until they get the desired behavior, but this only\nguarantees good behavior in the training environment. We propose structuring\nthis process as a series of queries asking the user to compare between\ndifferent reward functions. Thus we can actively select queries for maximum\ninformativeness about the true reward. In contrast to approaches asking the\ndesigner for optimal behavior, this allows us to gather additional information\nby eliciting preferences between suboptimal behaviors. After each query, we\nneed to update the posterior over the true reward function from observing the\nproxy reward function chosen by the designer. The recently proposed Inverse\nReward Design (IRD) enables this. Our approach substantially outperforms IRD in\ntest environments. In particular, it can query the designer about\ninterpretable, linear reward functions and still infer non-linear ones.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 23:30:59 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 15:52:24 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 17:41:15 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Mindermann", "S\u00f6ren", ""], ["Shah", "Rohin", ""], ["Gleave", "Adam", ""], ["Hadfield-Menell", "Dylan", ""]]}, {"id": "1809.03062", "submitter": "Julius Berner", "authors": "Julius Berner, Philipp Grohs, Arnulf Jentzen", "title": "Analysis of the Generalization Error: Empirical Risk Minimization over\n  Deep Artificial Neural Networks Overcomes the Curse of Dimensionality in the\n  Numerical Approximation of Black-Scholes Partial Differential Equations", "comments": null, "journal-ref": "SIAM Journal on Mathematics of Data Science 2(3), 2020, pp.\n  631-657", "doi": "10.1137/19M125649X", "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of new classification and regression algorithms based on\nempirical risk minimization (ERM) over deep neural network hypothesis classes,\ncoined deep learning, revolutionized the area of artificial intelligence,\nmachine learning, and data analysis. In particular, these methods have been\napplied to the numerical solution of high-dimensional partial differential\nequations with great success. Recent simulations indicate that deep\nlearning-based algorithms are capable of overcoming the curse of dimensionality\nfor the numerical solution of Kolmogorov equations, which are widely used in\nmodels from engineering, finance, and the natural sciences. The present paper\nconsiders under which conditions ERM over a deep neural network hypothesis\nclass approximates the solution of a $d$-dimensional Kolmogorov equation with\naffine drift and diffusion coefficients and typical initial values arising from\nproblems in computational finance up to error $\\varepsilon$. We establish that,\nwith high probability over draws of training samples, such an approximation can\nbe achieved with both the size of the hypothesis class and the number of\ntraining samples scaling only polynomially in $d$ and $\\varepsilon^{-1}$. It\ncan be concluded that ERM over deep neural network hypothesis classes overcomes\nthe curse of dimensionality for the numerical solution of linear Kolmogorov\nequations with affine coefficients.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 23:50:37 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 15:33:20 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 12:46:12 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Berner", "Julius", ""], ["Grohs", "Philipp", ""], ["Jentzen", "Arnulf", ""]]}, {"id": "1809.03063", "submitter": "Mohammad Mahmoody", "authors": "Saeed Mahloujifar, Dimitrios I. Diochnos, Mohammad Mahmoody", "title": "The Curse of Concentration in Robust Learning: Evasion and Poisoning\n  Attacks from Concentration of Measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern machine learning classifiers are shown to be vulnerable to\nadversarial perturbations of the instances. Despite a massive amount of work\nfocusing on making classifiers robust, the task seems quite challenging. In\nthis work, through a theoretical study, we investigate the adversarial risk and\nrobustness of classifiers and draw a connection to the well-known phenomenon of\nconcentration of measure in metric measure spaces. We show that if the metric\nprobability space of the test instance is concentrated, any classifier with\nsome initial constant error is inherently vulnerable to adversarial\nperturbations.\n  One class of concentrated metric probability spaces are the so-called Levy\nfamilies that include many natural distributions. In this special case, our\nattacks only need to perturb the test instance by at most $O(\\sqrt n)$ to make\nit misclassified, where $n$ is the data dimension. Using our general result\nabout Levy instance spaces, we first recover as special case some of the\npreviously proved results about the existence of adversarial examples. However,\nmany more Levy families are known (e.g., product distribution under the Hamming\ndistance) for which we immediately obtain new attacks that find adversarial\nexamples of distance $O(\\sqrt n)$.\n  Finally, we show that concentration of measure for product spaces implies the\nexistence of forms of \"poisoning\" attacks in which the adversary tampers with\nthe training data with the goal of degrading the classifier. In particular, we\nshow that for any learning algorithm that uses $m$ training examples, there is\nan adversary who can increase the probability of any \"bad property\" (e.g.,\nfailing on a particular test instance) that initially happens with\nnon-negligible probability to $\\approx 1$ by substituting only $\\tilde{O}(\\sqrt\nm)$ of the examples with other (still correctly labeled) examples.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 23:57:29 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 04:31:04 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Diochnos", "Dimitrios I.", ""], ["Mahmoody", "Mohammad", ""]]}, {"id": "1809.03066", "submitter": "Panayotis Mertikopoulos", "authors": "Benoit Duvocelle and Panayotis Mertikopoulos and Mathias Staudigl and\n  Dries Vermeulen", "title": "Learning in time-varying games", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine the long-run behavior of regret-minimizing agents\nin time-varying games with continuous action spaces. In its most basic form,\n(external) regret minimization guarantees that an agent's cumulative payoff is\nno worse asymptotically than that of the agent's best fixed action in\nhindsight. Going beyond this worst-case guarantee, we consider games that\nevolve over time and we examine the asymptotic behavior of a wide class of\nno-regret policies based on mirror descent. In this general context, we show\nthat the induced sequence of play (a) converges to Nash equilibrium in\ntime-varying games that stabilize in the long run to a strictly monotone limit;\nand (b) stays asymptotically close to the evolving equilibrium of the sequence\nof stage games (assuming they are strongly monotone). Our results apply to both\ngradient-based and payoff-based feedback - i.e., the \"bandit\" case where\nplayers only get to observe the payoffs of their chosen actions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 00:23:25 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 08:16:41 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Duvocelle", "Benoit", ""], ["Mertikopoulos", "Panayotis", ""], ["Staudigl", "Mathias", ""], ["Vermeulen", "Dries", ""]]}, {"id": "1809.03073", "submitter": "Bryon Aragam", "authors": "Chen Dan, Liu Leqi, Bryon Aragam, Pradeep Ravikumar, Eric P. Xing", "title": "Sample Complexity of Nonparametric Semi-Supervised Learning", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of semi-supervised learning (SSL) and\nintroduce new assumptions based on the mismatch between a mixture model learned\nfrom unlabeled data and the true mixture model induced by the (unknown) class\nconditional distributions. Under these assumptions, we establish an\n$\\Omega(K\\log K)$ labeled sample complexity bound without imposing parametric\nassumptions, where $K$ is the number of classes. Our results suggest that even\nin nonparametric settings it is possible to learn a near-optimal classifier\nusing only a few labeled samples. Unlike previous theoretical work which\nfocuses on binary classification, we consider general multiclass classification\n($K>2$), which requires solving a difficult permutation learning problem. This\npermutation defines a classifier whose classification error is controlled by\nthe Wasserstein distance between mixing measures, and we provide finite-sample\nresults characterizing the behaviour of the excess risk of this classifier.\nFinally, we describe three algorithms for computing these estimators based on a\nconnection to bipartite graph matching, and perform experiments to illustrate\nthe superiority of the MLE over the majority vote estimator.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 01:12:26 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Dan", "Chen", ""], ["Leqi", "Liu", ""], ["Aragam", "Bryon", ""], ["Ravikumar", "Pradeep", ""], ["Xing", "Eric P.", ""]]}, {"id": "1809.03075", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Christian Kroer, Tuomas Sandholm", "title": "Online Convex Optimization for Sequential Decision Processes and\n  Extensive-Form Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret minimization is a powerful tool for solving large-scale extensive-form\ngames. State-of-the-art methods rely on minimizing regret locally at each\ndecision point. In this work we derive a new framework for regret minimization\non sequential decision problems and extensive-form games with general compact\nconvex sets at each decision point and general convex losses, as opposed to\nprior work which has been for simplex decision points and linear losses. We\ncall our framework laminar regret decomposition. It generalizes the CFR\nalgorithm to this more general setting. Furthermore, our framework enables a\nnew proof of CFR even in the known setting, which is derived from a perspective\nof decomposing polytope regret, thereby leading to an arguably simpler\ninterpretation of the algorithm. Our generalization to convex compact sets and\nconvex losses allows us to develop new algorithms for several problems:\nregularized sequential decision making, regularized Nash equilibria in\nextensive-form games, and computing approximate extensive-form perfect\nequilibria. Our generalization also leads to the first regret-minimization\nalgorithm for computing reduced-normal-form quantal response equilibria based\non minimizing local regrets. Experiments show that our framework leads to\nalgorithms that scale at a rate comparable to the fastest variants of\ncounterfactual regret minimization for computing Nash equilibrium, and\ntherefore our approach leads to the first algorithm for computing quantal\nresponse equilibria in extremely large games. Finally we show that our\nframework enables a new kind of scalable opponent exploitation approach.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 01:28:24 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1809.03084", "submitter": "Kohei Yata", "authors": "Yusuke Narita, Shota Yasui, Kohei Yata", "title": "Efficient Counterfactual Learning from Bandit Feedback", "comments": "accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the most statistically efficient way to do off-policy evaluation and\noptimization with batch data from bandit feedback? For log data generated by\ncontextual bandit algorithms, we consider offline estimators for the expected\nreward from a counterfactual policy. Our estimators are shown to have lowest\nvariance in a wide class of estimators, achieving variance reduction relative\nto standard estimators. We then apply our estimators to improve advertisement\ndesign by a major advertisement company. Consistent with the theoretical\nresult, our estimators allow us to improve on the existing bandit algorithm\nwith more statistical confidence compared to a state-of-the-art benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:08:14 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 21:07:33 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 23:41:04 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Narita", "Yusuke", ""], ["Yasui", "Shota", ""], ["Yata", "Kohei", ""]]}, {"id": "1809.03090", "submitter": "Jason Klusowski M", "authors": "Andrew R. Barron, Jason M. Klusowski", "title": "Approximation and Estimation for High-Dimensional Deep Learning Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been experimentally observed in recent years that multi-layer\nartificial neural networks have a surprising ability to generalize, even when\ntrained with far more parameters than observations. Is there a theoretical\nbasis for this? The best available bounds on their metric entropy and\nassociated complexity measures are essentially linear in the number of\nparameters, which is inadequate to explain this phenomenon. Here we examine the\nstatistical risk (mean squared predictive error) of multi-layer networks with\n$\\ell^1$-type controls on their parameters and with ramp activation functions\n(also called lower-rectified linear units). In this setting, the risk is shown\nto be upper bounded by $[(L^3 \\log d)/n]^{1/2}$, where $d$ is the input\ndimension to each layer, $L$ is the number of layers, and $n$ is the sample\nsize. In this way, the input dimension can be much larger than the sample size\nand the estimator can still be accurate, provided the target function has such\n$\\ell^1$ controls and that the sample size is at least moderately large\ncompared to $L^3\\log d$. The heart of the analysis is the development of a\nsampling strategy that demonstrates the accuracy of a sparse covering of deep\nramp networks. Lower bounds show that the identified risk is close to being\noptimal.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:21:40 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 17:49:00 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Barron", "Andrew R.", ""], ["Klusowski", "Jason M.", ""]]}, {"id": "1809.03108", "submitter": "EPTCS", "authors": "Dana Angluin (Yale University), Dana Fisman (Ben-Gurion University)", "title": "Regular omega-Languages with an Informative Right Congruence", "comments": "In Proceedings GandALF 2018, arXiv:1809.02416", "journal-ref": "EPTCS 277, 2018, pp. 265-279", "doi": "10.4204/EPTCS.277.19", "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A regular language is almost fully characterized by its right congruence\nrelation. Indeed, a regular language can always be recognized by a DFA\nisomorphic to the automaton corresponding to its right congruence, henceforth\nthe Rightcon automaton. The same does not hold for regular omega-languages. The\nright congruence of a regular omega-language is not informative enough; many\nregular omega-languages have a trivial right congruence, and in general it is\nnot always possible to define an omega-automaton recognizing a given language\nthat is isomorphic to the rightcon automaton.\n  The class of weak regular omega-languages does have an informative right\ncongruence. That is, any weak regular omega-language can always be recognized\nby a deterministic B\\\"uchi automaton that is isomorphic to the rightcon\nautomaton. Weak regular omega-languages reside in the lower levels of the\nexpressiveness hierarchy of regular omega-languages. Are there more expressive\nsub-classes of regular omega languages that have an informative right\ncongruence? Can we fully characterize the class of languages with a trivial\nright congruence? In this paper we try to place some additional pieces of this\nbig puzzle.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 02:35:18 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Angluin", "Dana", "", "Yale University"], ["Fisman", "Dana", "", "Ben-Gurion University"]]}, {"id": "1809.03113", "submitter": "Changyou Chen", "authors": "Bai Li and Changyou Chen and Wenlin Wang and Lawrence Carin", "title": "Certified Adversarial Robustness with Additive Noise", "comments": "NIPS 2019; Code: https://github.com/Bai-Li/STN-Code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of adversarial data examples has drawn significant attention in\nthe deep-learning community; such data are seemingly minimally perturbed\nrelative to the original data, but lead to very different outputs from a\ndeep-learning algorithm. Although a significant body of work on developing\ndefensive models has been considered, most such models are heuristic and are\noften vulnerable to adaptive attacks. Defensive methods that provide\ntheoretical robustness guarantees have been studied intensively, yet most fail\nto obtain non-trivial robustness when a large-scale model and data are present.\nTo address these limitations, we introduce a framework that is scalable and\nprovides certified bounds on the norm of the input manipulation for\nconstructing adversarial examples. We establish a connection between robustness\nagainst adversarial perturbation and additive random noise, and propose a\ntraining strategy that can significantly improve the certified bounds. Our\nevaluation on MNIST, CIFAR-10 and ImageNet suggests that the proposed method is\nscalable to complicated models and large data sets, while providing competitive\nrobustness to state-of-the-art provable defense methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 03:03:06 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 00:59:24 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 21:05:10 GMT"}, {"version": "v4", "created": "Tue, 29 Oct 2019 03:35:55 GMT"}, {"version": "v5", "created": "Wed, 30 Oct 2019 01:12:08 GMT"}, {"version": "v6", "created": "Sun, 10 Nov 2019 06:24:53 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Li", "Bai", ""], ["Chen", "Changyou", ""], ["Wang", "Wenlin", ""], ["Carin", "Lawrence", ""]]}, {"id": "1809.03125", "submitter": "Michael Ekstrand", "authors": "Michael D. Ekstrand", "title": "LensKit for Python: Next-Generation Software for Recommender System\n  Experiments", "comments": "8 pages; accepted for publication in CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412778", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LensKit is an open-source toolkit for building, researching, and learning\nabout recommender systems. First released in 2010 as a Java framework, it has\nsupported diverse published research, small-scale production deployments, and\neducation in both MOOC and traditional classroom settings. In this paper, I\npresent the next generation of the LensKit project, re-envisioning the original\ntool's objectives as flexible Python package for supporting recommender systems\nresearch and development. LensKit for Python (LKPY) enables researchers and\nstudents to build robust, flexible, and reproducible experiments that make use\nof the large and growing PyData and Scientific Python ecosystem, including\nscikit-learn, TensorFlow, and PyTorch. To that end, it provides classical\ncollaborative filtering implementations, recommender system evaluation metrics,\ndata preparation routines, and tools for efficiently batch running\nrecommendation algorithms, all usable in any combination with each other or\nwith other Python software.\n  This paper describes the design goals, use cases, and capabilities of LKPY,\ncontextualized in a reflection on the successes and failures of the original\nLensKit for Java software.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 04:15:05 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 00:35:21 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 21:04:58 GMT"}, {"version": "v4", "created": "Thu, 3 Sep 2020 16:45:09 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Ekstrand", "Michael D.", ""]]}, {"id": "1809.03137", "submitter": "Zhen He", "authors": "Zhen He, Jian Li, Daxue Liu, Hangen He, David Barber", "title": "Tracking by Animation: Unsupervised Learning of Multi-Object Attentive\n  Trackers", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Multi-Object Tracking (MOT) from videos is a challenging computer\nvision task which has been extensively studied for decades. Most of the\nexisting MOT algorithms are based on the Tracking-by-Detection (TBD) paradigm\ncombined with popular machine learning approaches which largely reduce the\nhuman effort to tune algorithm parameters. However, the commonly used\nsupervised learning approaches require the labeled data (e.g., bounding boxes),\nwhich is expensive for videos. Also, the TBD framework is usually suboptimal\nsince it is not end-to-end, i.e., it considers the task as detection and\ntracking, but not jointly. To achieve both label-free and end-to-end learning\nof MOT, we propose a Tracking-by-Animation framework, where a differentiable\nneural model first tracks objects from input frames and then animates these\nobjects into reconstructed frames. Learning is then driven by the\nreconstruction error through backpropagation. We further propose a\nReprioritized Attentive Tracking to improve the robustness of data association.\nExperiments conducted on both synthetic and real video datasets show the\npotential of the proposed model. Our project page is publicly available at:\nhttps://github.com/zhen-he/tracking-by-animation\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 04:59:25 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 05:39:56 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 02:02:16 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["He", "Zhen", ""], ["Li", "Jian", ""], ["Liu", "Daxue", ""], ["He", "Hangen", ""], ["Barber", "David", ""]]}, {"id": "1809.03140", "submitter": "Venkateswararao Cherukuri", "authors": "Venkateswararao Cherukuri, Tiantong Guo, Steven J. Schiff, Vishal\n  Monga", "title": "Deep MR Image Super-Resolution Using Structural Priors", "comments": "Accepted to IEEE ICIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High resolution magnetic resonance (MR) images are desired for accurate\ndiagnostics. In practice, image resolution is restricted by factors like\nhardware, cost and processing constraints. Recently, deep learning methods have\nbeen shown to produce compelling state of the art results for image\nsuper-resolution. Paying particular attention to desired hi-resolution MR image\nstructure, we propose a new regularized network that exploits image priors,\nnamely a low-rank structure and a sharpness prior to enhance deep MR image\nsuperresolution. Our contributions are then incorporating these priors in an\nanalytically tractable fashion in the learning of a convolutional neural\nnetwork (CNN) that accomplishes the super-resolution task. This is particularly\nchallenging for the low rank prior, since the rank is not a differentiable\nfunction of the image matrix (and hence the network parameters), an issue we\naddress by pursuing differentiable approximations of the rank. Sharpness is\nemphasized by the variance of the Laplacian which we show can be implemented by\na fixed {\\em feedback} layer at the output of the network. Experiments\nperformed on two publicly available MR brain image databases exhibit promising\nresults particularly when training imagery is limited.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 05:20:26 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Cherukuri", "Venkateswararao", ""], ["Guo", "Tiantong", ""], ["Schiff", "Steven J.", ""], ["Monga", "Vishal", ""]]}, {"id": "1809.03142", "submitter": "Seongsik Park", "authors": "Seongsik Park, Seijoon Kim, Hyeokjun Choe, Sungroh Yoon", "title": "Fast and Efficient Information Transmission with Burst Spikes in Deep\n  Spiking Neural Networks", "comments": "Accepted to DAC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spiking neural networks (SNNs) are considered as one of the most\npromising artificial neural networks due to their energy efficient computing\ncapability. Recently, conversion of a trained deep neural network to an SNN has\nimproved the accuracy of deep SNNs. However, most of the previous studies have\nnot achieved satisfactory results in terms of inference speed and energy\nefficiency. In this paper, we propose a fast and energy-efficient information\ntransmission method with burst spikes and hybrid neural coding scheme in deep\nSNNs. Our experimental results showed the proposed methods can improve\ninference energy efficiency and shorten the latency.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 05:42:18 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 12:16:19 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Park", "Seongsik", ""], ["Kim", "Seijoon", ""], ["Choe", "Hyeokjun", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1809.03149", "submitter": "Weixun Wang", "authors": "Weixun Wang, Junqi Jin, Jianye Hao, Chunjie Chen, Chuan Yu, Weinan\n  Zhang, Jun Wang, Xiaotian Hao, Yixi Wang, Han Li, Jian Xu, Kun Gai", "title": "Learning Adaptive Display Exposure for Real-Time Advertising", "comments": "accepted by CIKM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In E-commerce advertising, where product recommendations and product ads are\npresented to users simultaneously, the traditional setting is to display ads at\nfixed positions. However, under such a setting, the advertising system loses\nthe flexibility to control the number and positions of ads, resulting in\nsub-optimal platform revenue and user experience. Consequently, major\ne-commerce platforms (e.g., Taobao.com) have begun to consider more flexible\nways to display ads. In this paper, we investigate the problem of advertising\nwith adaptive exposure: can we dynamically determine the number and positions\nof ads for each user visit under certain business constraints so that the\nplatform revenue can be increased? More specifically, we consider two types of\nconstraints: request-level constraint ensures user experience for each user\nvisit, and platform-level constraint controls the overall platform monetization\nrate. We model this problem as a Constrained Markov Decision Process with\nper-state constraint (psCMDP) and propose a constrained two-level reinforcement\nlearning approach to decompose the original problem into two relatively\nindependent sub-problems. To accelerate policy learning, we also devise a\nconstrained hindsight experience replay mechanism. Experimental evaluations on\nindustry-scale real-world datasets demonstrate the merits of our approach in\nboth obtaining higher revenue under the constraints and the effectiveness of\nthe constrained hindsight experience replay mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 06:15:42 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 01:55:56 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Wang", "Weixun", ""], ["Jin", "Junqi", ""], ["Hao", "Jianye", ""], ["Chen", "Chunjie", ""], ["Yu", "Chuan", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""], ["Hao", "Xiaotian", ""], ["Wang", "Yixi", ""], ["Li", "Han", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "1809.03152", "submitter": "Xun Yang", "authors": "Di Wu, Cheng Chen, Xun Yang, Xiujun Chen, Qing Tan, Jian Xu, Kun Gai", "title": "A Multi-Agent Reinforcement Learning Method for Impression Allocation in\n  Online Display Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online display advertising, guaranteed contracts and real-time bidding\n(RTB) are two major ways to sell impressions for a publisher. Despite the\nincreasing popularity of RTB, there is still half of online display advertising\nrevenue generated from guaranteed contracts. Therefore, simultaneously selling\nimpressions through both guaranteed contracts and RTB is a straightforward\nchoice for a publisher to maximize its yield. However, deriving the optimal\nstrategy to allocate impressions is not a trivial task, especially when the\nenvironment is unstable in real-world applications. In this paper, we formulate\nthe impression allocation problem as an auction problem where each contract can\nsubmit virtual bids for individual impressions. With this formulation, we\nderive the optimal impression allocation strategy by solving the optimal\nbidding functions for contracts. Since the bids from contracts are decided by\nthe publisher, we propose a multi-agent reinforcement learning (MARL) approach\nto derive cooperative policies for the publisher to maximize its yield in an\nunstable environment. The proposed approach also resolves the common challenges\nin MARL such as input dimension explosion, reward credit assignment, and\nnon-stationary environment. Experimental evaluations on large-scale real\ndatasets demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 06:38:22 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Wu", "Di", ""], ["Chen", "Cheng", ""], ["Yang", "Xun", ""], ["Chen", "Xiujun", ""], ["Tan", "Qing", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "1809.03154", "submitter": "Siddharth Prasad", "authors": "Zachary Chase and Siddharth Prasad", "title": "Learning Time Dependent Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore questions dealing with the learnability of models of choice over\ntime. We present a large class of preference models defined by a structural\ncriterion for which we are able to obtain an exponential improvement over\npreviously known learning bounds for more general preference models. This in\nparticular implies that the three most important discounted utility models of\nintertemporal choice -- exponential, hyperbolic, and quasi-hyperbolic\ndiscounting -- are learnable in the PAC setting with VC dimension that grows\nlogarithmically in the number of time periods. We also examine these models in\nthe framework of active learning. We find that the commonly studied\nstream-based setting is in general difficult to analyze for preference models,\nbut we provide a redeeming situation in which the learner can indeed improve\nupon the guarantees provided by PAC learning. In contrast to the stream-based\nsetting, we show that if the learner is given full power over the data he\nlearns from -- in the form of learning via membership queries -- even very\nnaive algorithms significantly outperform the guarantees provided by higher\nlevel active learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 06:49:07 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Chase", "Zachary", ""], ["Prasad", "Siddharth", ""]]}, {"id": "1809.03185", "submitter": "Francesco La Rosa", "authors": "Francesco La Rosa, M\\'ario Jo\\~ao Fartaria, Tobias Kober, Jonas\n  Richiardi, Cristina Granziera, Jean-Philippe Thiran, Meritxell Bach Cuadra", "title": "Shallow vs deep learning architectures for white matter lesion\n  segmentation in the early stages of multiple sclerosis", "comments": "Accepted to the MICCAI 2018 Brain Lesion (BrainLes) workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a comparison of a shallow and a deep learning\narchitecture for the automated segmentation of white matter lesions in MR\nimages of multiple sclerosis patients. In particular, we train and test both\nmethods on early stage disease patients, to verify their performance in\nchallenging conditions, more similar to a clinical setting than what is\ntypically provided in multiple sclerosis segmentation challenges. Furthermore,\nwe evaluate a prototype naive combination of the two methods, which refines the\nfinal segmentation. All methods were trained on 32 patients, and the evaluation\nwas performed on a pure test set of 73 cases. Results show low lesion-wise\nfalse positives (30%) for the deep learning architecture, whereas the shallow\narchitecture yields the best Dice coefficient (63%) and volume difference\n(19%). Combining both shallow and deep architectures further improves the\nlesion-wise metrics (69% and 26% lesion-wise true and false positive rate,\nrespectively).\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 08:50:34 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["La Rosa", "Francesco", ""], ["Fartaria", "M\u00e1rio Jo\u00e3o", ""], ["Kober", "Tobias", ""], ["Richiardi", "Jonas", ""], ["Granziera", "Cristina", ""], ["Thiran", "Jean-Philippe", ""], ["Cuadra", "Meritxell Bach", ""]]}, {"id": "1809.03194", "submitter": "Agustinus Kristiadi", "authors": "Debanjan Chaudhuri, Agustinus Kristiadi, Jens Lehmann, and Asja\n  Fischer", "title": "Improving Response Selection in Multi-Turn Dialogue Systems by\n  Incorporating Domain Knowledge", "comments": "Published as conference paper at CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building systems that can communicate with humans is a core problem in\nArtificial Intelligence. This work proposes a novel neural network architecture\nfor response selection in an end-to-end multi-turn conversational dialogue\nsetting. The architecture applies context level attention and incorporates\nadditional external knowledge provided by descriptions of domain-specific\nwords. It uses a bi-directional Gated Recurrent Unit (GRU) for encoding context\nand responses and learns to attend over the context words given the latent\nresponse representation and vice versa.In addition, it incorporates external\ndomain specific information using another GRU for encoding the domain keyword\ndescriptions. This allows better representation of domain-specific keywords in\nresponses and hence improves the overall performance. Experimental results show\nthat our model outperforms all other state-of-the-art methods for response\nselection in multi-turn conversations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 09:10:25 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 17:34:42 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 10:11:29 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Chaudhuri", "Debanjan", ""], ["Kristiadi", "Agustinus", ""], ["Lehmann", "Jens", ""], ["Fischer", "Asja", ""]]}, {"id": "1809.03207", "submitter": "Jessa Bekker", "authors": "Jessa Bekker, Pieter Robberechts, and Jesse Davis", "title": "Beyond the Selected Completely At Random Assumption for Learning from\n  Positive and Unlabeled Data", "comments": null, "journal-ref": "European Conference on Machine Learning and Principles and\n  Practice of Knowledge Discovery in Databases 2019 (ECMLPKDD 2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most positive and unlabeled data is subject to selection biases. The labeled\nexamples can, for example, be selected from the positive set because they are\neasier to obtain or more obviously positive. This paper investigates how\nlearning can be ena BHbled in this setting. We propose and theoretically\nanalyze an empirical-risk-based method for incorporating the labeling\nmechanism. Additionally, we investigate under which assumptions learning is\npossible when the labeling mechanism is not fully understood and propose a\npractical method to enable this. Our empirical analysis supports the\ntheoretical results and shows that taking into account the possibility of a\nselection bias, even when the labeling mechanism is unknown, improves the\ntrained classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 09:23:32 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 19:23:38 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 05:36:10 GMT"}, {"version": "v4", "created": "Fri, 28 Jun 2019 09:41:04 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Bekker", "Jessa", ""], ["Robberechts", "Pieter", ""], ["Davis", "Jesse", ""]]}, {"id": "1809.03214", "submitter": "Karl Kurzer", "authors": "Peter Wolf, Karl Kurzer, Tobias Wingert, Florian Kuhnt, J. Marius\n  Z\\\"ollner", "title": "Adaptive Behavior Generation for Autonomous Driving using Deep\n  Reinforcement Learning with Compact Semantic States", "comments": null, "journal-ref": null, "doi": "10.1109/IVS.2018.8500427", "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making the right decision in traffic is a challenging task that is highly\ndependent on individual preferences as well as the surrounding environment.\nTherefore it is hard to model solely based on expert knowledge. In this work we\nuse Deep Reinforcement Learning to learn maneuver decisions based on a compact\nsemantic state representation. This ensures a consistent model of the\nenvironment across scenarios as well as a behavior adaptation function,\nenabling on-line changes of desired behaviors without re-training. The input\nfor the neural network is a simulated object list similar to that of Radar or\nLidar sensors, superimposed by a relational semantic scene description. The\nstate as well as the reward are extended by a behavior adaptation function and\na parameterization respectively. With little expert knowledge and a set of\nmid-level actions, it can be seen that the agent is capable to adhere to\ntraffic rules and learns to drive safely in a variety of situations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 09:35:27 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wolf", "Peter", ""], ["Kurzer", "Karl", ""], ["Wingert", "Tobias", ""], ["Kuhnt", "Florian", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "1809.03225", "submitter": "Alexander Von Rohr", "authors": "Alexander von Rohr, Sebastian Trimpe, Alonso Marco, Peer Fischer,\n  Stefano Palagi", "title": "Gait learning for soft microrobots controlled by light fields", "comments": "8 pages, 7 figures, to appear in the proceedings of the IEEE/RSJ\n  International Conference on Intelligent Robots and Systems 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soft microrobots based on photoresponsive materials and controlled by light\nfields can generate a variety of different gaits. This inherent flexibility can\nbe exploited to maximize their locomotion performance in a given environment\nand used to adapt them to changing conditions. Albeit, because of the lack of\naccurate locomotion models, and given the intrinsic variability among\nmicrorobots, analytical control design is not possible. Common data-driven\napproaches, on the other hand, require running prohibitive numbers of\nexperiments and lead to very sample-specific results. Here we propose a\nprobabilistic learning approach for light-controlled soft microrobots based on\nBayesian Optimization (BO) and Gaussian Processes (GPs). The proposed approach\nresults in a learning scheme that is data-efficient, enabling gait optimization\nwith a limited experimental budget, and robust against differences among\nmicrorobot samples. These features are obtained by designing the learning\nscheme through the comparison of different GP priors and BO settings on a\nsemi-synthetic data set. The developed learning scheme is validated in\nmicrorobot experiments, resulting in a 115% improvement in a microrobot's\nlocomotion performance with an experimental budget of only 20 tests. These\nencouraging results lead the way toward self-adaptive microrobotic systems\nbased on light-controlled soft microrobots and probabilistic learning control.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 10:00:46 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["von Rohr", "Alexander", ""], ["Trimpe", "Sebastian", ""], ["Marco", "Alonso", ""], ["Fischer", "Peer", ""], ["Palagi", "Stefano", ""]]}, {"id": "1809.03267", "submitter": "Sebastian Bischoff", "authors": "Sebastian Bischoff", "title": "Feature Learning for Meta-Paths in Knowledge Graphs", "comments": "Bachelor's Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we study the problem of feature learning on heterogeneous\nknowledge graphs. These features can be used to perform tasks such as link\nprediction, classification and clustering on graphs. Knowledge graphs provide\nrich semantics encoded in the edge and node types. Meta-paths consist of these\ntypes and abstract paths in the graph. Until now, meta-paths can only be used\nas categorical features with high redundancy and are therefore unsuitable for\nmachine learning models. We propose meta-path embeddings to solve this problem\nby learning semantical and compact vector representations of them. Current\ngraph embedding methods only embed nodes and edge types and therefore miss\nsemantics encoded in the combination of them. Our method embeds meta-paths\nusing the skipgram model with an extension to deal with the redundancy and high\namount of meta-paths in big knowledge graphs. We critically evaluate our\nembedding approach by predicting links on Wikidata. The experiments indicate\nthat we learn a sensible embedding of the meta-paths but can improve it\nfurther.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 09:31:52 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Bischoff", "Sebastian", ""]]}, {"id": "1809.03272", "submitter": "Le Trieu Phong", "authors": "Le Trieu Phong and Tran Thi Phuong", "title": "Privacy-Preserving Deep Learning via Weight Transmission", "comments": "Full version of a conference paper at NSS 2017", "journal-ref": "IEEE Transactions on Information Forensics and Security (Volume:\n  14, Issue: 11, Nov. 2019)", "doi": "10.1109/TIFS.2019.2911169", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the scenario that multiple data owners wish to apply a\nmachine learning method over the combined dataset of all owners to obtain the\nbest possible learning output but do not want to share the local datasets owing\nto privacy concerns. We design systems for the scenario that the stochastic\ngradient descent (SGD) algorithm is used as the machine learning method because\nSGD (or its variants) is at the heart of recent deep learning techniques over\nneural networks. Our systems differ from existing systems in the following\nfeatures: {\\bf (1)} any activation function can be used, meaning that no\nprivacy-preserving-friendly approximation is required; {\\bf (2)} gradients\ncomputed by SGD are not shared but the weight parameters are shared instead;\nand {\\bf (3)} robustness against colluding parties even in the extreme case\nthat only one honest party exists. We prove that our systems, while\nprivacy-preserving, achieve the same learning accuracy as SGD and hence retain\nthe merit of deep learning with respect to accuracy. Finally, we conduct\nseveral experiments using benchmark datasets, and show that our systems\noutperform previous system in terms of learning accuracies.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 12:36:05 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 06:43:25 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 06:44:53 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Phong", "Le Trieu", ""], ["Phuong", "Tran Thi", ""]]}, {"id": "1809.03291", "submitter": "Elena Smirnova", "authors": "Elena Smirnova", "title": "Action-conditional Sequence Modeling for Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many online applications interactions between a user and a web-service are\norganized in a sequential way, e.g., user browsing an e-commerce website. In\nthis setting, recommendation system acts throughout user navigation by showing\nitems. Previous works have addressed this recommendation setup through the task\nof predicting the next item user will interact with. In particular, Recurrent\nNeural Networks (RNNs) has been shown to achieve substantial improvements over\ncollaborative filtering baselines. In this paper, we consider interactions\ntriggered by the recommendations of deployed recommender system in addition to\nbrowsing behavior. Indeed, it is reported that in online services interactions\nwith recommendations represent up to 30\\% of total interactions. Moreover, in\npractice, recommender system can greatly influence user behavior by promoting\nspecific items. In this paper, we extend the RNN modeling framework by taking\ninto account user interaction with recommended items. We propose and evaluate\nRNN architectures that consist of the recommendation action module and the\nstate-action fusion module. Using real-world large-scale datasets we\ndemonstrate improved performance on the next item prediction task compared to\nthe baselines.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 14:37:30 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Smirnova", "Elena", ""]]}, {"id": "1809.03306", "submitter": "Kuntoro Adi Nugroho", "authors": "Kuntoro Adi Nugroho", "title": "A Comparison of Handcrafted and Deep Neural Network Feature Extraction\n  for Classifying Optical Coherence Tomography (OCT) Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optical Coherence Tomography allows ophthalmologist to obtain cross-section\nimaging of eye retina. Assisted with digital image analysis methods, effective\ndisease detection could be performed. Various methods exist to extract feature\nfrom OCT images. The proposed study aims to compare the effectiveness of\nhandcrafted and deep neural network features. The evaluated dataset consist of\n32339 instances distributed in four classes, namely CNV, DME, DRUSEN, and\nNORMAL. The methods are Histogram of Oriented Gradient (HOG), Local Binary\nPattern (LBP), DenseNet-169, and ResNet50. As a result, the deep neural network\nbased methods outperformed the handcrafted feature with 88% and 89% accuracy\nfor DenseNet and ResNet compared to 50 % and 42 % for HOG and LBP respectively.\nThe deep neural network based methods also demonstrated better result on the\nunder represented class.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 03:18:17 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Nugroho", "Kuntoro Adi", ""]]}, {"id": "1809.03308", "submitter": "Fang Liu", "authors": "Fang Liu, Li Feng, Richard Kijowski", "title": "MANTIS: Model-Augmented Neural neTwork with Incoherent k-space Sampling\n  for efficient MR T2 mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative mapping of magnetic resonance (MR) parameters have been shown as\nvaluable methods for improved assessment of a range of diseases. Due to the\nneed to image an anatomic structure multiple times, parameter mapping usually\nrequires long scan times compared to conventional static imaging. Therefore,\naccelerated parameter mapping is highly-desirable and remains a topic of great\ninterest in the MR research community. While many recent deep learning methods\nhave focused on highly efficient image reconstruction for conventional static\nMR imaging, applications of deep learning for dynamic imaging and in particular\naccelerated parameter mapping have been limited. The purpose of this work was\nto develop and evaluate a novel deep learning-based reconstruction framework\ncalled Model-Augmented Neural neTwork with Incoherent k-space Sampling (MANTIS)\nfor efficient MR parameter mapping. Our approach combines end-to-end CNN\nmapping with k-space consistency using the concept of cyclic loss to further\nenforce data and model fidelity. Incoherent k-space sampling is used to improve\nreconstruction performance. A physical model is incorporated into the proposed\nframework, so that the parameter maps can be efficiently estimated directly\nfrom undersampled images. The performance of MANTIS was demonstrated for the\nspin-spin relaxation time (T2) mapping of the knee joint. Compared to\nconventional reconstruction approaches that exploited image sparsity, MANTIS\nyielded lower errors and higher similarity with respect to the reference in the\nT2 estimation. Our study demonstrated that the proposed MANTIS framework, with\na combination of end-to-end CNN mapping, signal model-augmented data\nconsistency, and incoherent k-space sampling, represents a promising approach\nfor efficient MR parameter mapping. MANTIS can potentially be extended to other\ntypes of parameter mapping with appropriate models.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 21:43:49 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Liu", "Fang", ""], ["Feng", "Li", ""], ["Kijowski", "Richard", ""]]}, {"id": "1809.03316", "submitter": "Farzaneh Mahdisoltani", "authors": "Farzaneh Mahdisoltani, Roland Memisevic, David Fleet", "title": "Hierarchical Video Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a hierarchical architecture for video understanding that\nexploits the structure of real world actions by capturing targets at different\nlevels of granularity. We design the model such that it first learns simpler\ncoarse-grained tasks, and then moves on to learn more fine-grained targets. The\nmodel is trained with a joint loss on different granularity levels. We\ndemonstrate empirical results on the recent release of Something-Something\ndataset, which provides a hierarchy of targets, namely coarse-grained action\ngroups, fine-grained action categories, and captions. Experiments suggest that\nmodels that exploit targets at different levels of granularity achieve better\nperformance on all levels.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 02:29:06 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Mahdisoltani", "Farzaneh", ""], ["Memisevic", "Roland", ""], ["Fleet", "David", ""]]}, {"id": "1809.03322", "submitter": "Jonathan Heras", "authors": "\\'Angela Casado and J\\'onathan Heras", "title": "Guiding the Creation of Deep Learning-based Object Detectors", "comments": "To be published in I Workshop en Deep Learning of the CAEPIA\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is a computer vision field that has applications in several\ncontexts ranging from biomedicine and agriculture to security. In the last\nyears, several deep learning techniques have greatly improved object detection\nmodels. Among those techniques, we can highlight the YOLO approach, that allows\nthe construction of accurate models that can be employed in real-time\napplications. However, as most deep learning techniques, YOLO has a steep\nlearning curve and creating models using this approach might be challenging for\nnon-expert users. In this work, we tackle this problem by constructing a suite\nof Jupyter notebooks that democratizes the construction of object detection\nmodels using YOLO. The suitability of our approach has been proven with a\ndataset of stomata images where we have achieved a mAP of 90.91%.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 07:07:12 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Casado", "\u00c1ngela", ""], ["Heras", "J\u00f3nathan", ""]]}, {"id": "1809.03323", "submitter": "Michael Lash", "authors": "Michael T. Lash and Min Zhang and Xun Zhou and W. Nick Street and\n  Charles F. Lynch", "title": "Deriving Enhanced Geographical Representations via Similarity-based\n  Spectral Analysis: Predicting Colorectal Cancer Survival Curves in Iowa", "comments": "arXiv admin note: substantial text overlap with arXiv:1708.04714", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are capable of learning rich, nonlinear feature\nrepresentations shown to be beneficial in many predictive tasks. In this work,\nwe use such models to explore different geographical feature representations in\nthe context of predicting colorectal cancer survival curves for patients in the\nstate of Iowa, spanning the years 1989 to 2013. Specifically, we compare model\nperformance using \"area between the curves\" (ABC) to assess (a) whether\nsurvival curves can be reasonably predicted for colorectal cancer patients in\nthe state of Iowa, (b) whether geographical features improve predictive\nperformance, (c) whether a simple binary representation, or a richer, spectral\nanalysis-elicited representation perform better, and (d) whether spectral\nanalysis-based representations can be improved upon by leveraging\ngeographically-descriptive features. In exploring (d), we devise a\nsimilarity-based spectral analysis procedure, which allows for the combination\nof geographically relational and geographically descriptive features. Our\nfindings suggest that survival curves can be reasonably estimated on average,\nwith predictive performance deviating at the five-year survival mark among all\nmodels. We also find that geographical features improve predictive performance,\nand that better performance is obtained using richer, spectral\nanalysis-elicited features. Furthermore, we find that similarity-based spectral\nanalysis-elicited representations improve upon the original spectral analysis\nresults by approximately 40%.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 18:04:33 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Lash", "Michael T.", ""], ["Zhang", "Min", ""], ["Zhou", "Xun", ""], ["Street", "W. Nick", ""], ["Lynch", "Charles F.", ""]]}, {"id": "1809.03330", "submitter": "Stefano Rosa", "authors": "Zhihua Wang, Stefano Rosa, Yishu Miao, Zihang Lai, Linhai Xie, Andrew\n  Markham, Niki Trigoni", "title": "Neural Allocentric Intuitive Physics Prediction from Real Videos", "comments": "Added references, minor changes. arXiv admin note: text overlap with\n  arXiv:1506.02025 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to make rich predictions about the future dynamics of\nphysical objects from a glance. On the other hand, most existing computer\nvision approaches require strong assumptions about the underlying system,\nad-hoc modeling, or annotated datasets, to carry out even simple predictions.\nTo tackle this gap, we propose a new perspective on the problem of learning\nintuitive physics that is inspired by the spatial memory representation of\nobjects and spaces in human brains, in particular the co-existence of\negocentric and allocentric spatial representations. We present a generic\nframework that learns a layered representation of the physical world, using a\ncascade of invertible modules. In this framework, real images are first\nconverted to a synthetic domain representation that reduces complexity arising\nfrom lighting and texture. Then, an allocentric viewpoint transformer removes\nviewpoint complexity by projecting images to a canonical view. Finally, a novel\nRecurrent Latent Variation Network (RLVN) architecture learns the dynamics of\nthe objects interacting with the environment and predicts future motion,\nleveraging the availability of unlimited synthetic simulations. Predicted\nframes are then projected back to the original camera view and translated back\nto the real world domain. Experimental results show the ability of the\nframework to consistently and accurately predict several frames in the future\nand the ability to adapt to real images.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:33:56 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 12:05:28 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Wang", "Zhihua", ""], ["Rosa", "Stefano", ""], ["Miao", "Yishu", ""], ["Lai", "Zihang", ""], ["Xie", "Linhai", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1809.03343", "submitter": "Wenqing Li", "authors": "Wenqing Li, Chunhui Zhao, Biao Huang", "title": "Distributed dynamic modeling and monitoring for large-scale industrial\n  processes under closed-loop control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For large-scale industrial processes under closed-loop control, process\ndynamics directly resulting from control action are typical characteristics and\nmay show different behaviors between real faults and normal changes of\noperating conditions. However, conventional distributed monitoring approaches\ndo not consider the closed-loop control mechanism and only explore static\ncharacteristics, which thus are incapable of distinguishing between real\nprocess faults and nominal changes of operating conditions, leading to\nunnecessary alarms. In this regard, this paper proposes a distributed\nmonitoring method for closed-loop industrial processes by concurrently\nexploring static and dynamic characteristics. First, the large-scale\nclosed-loop process is decomposed into several subsystems by developing a\nsparse slow feature analysis (SSFA) algorithm which capture changes of both\nstatic and dynamic information. Second, distributed models are developed to\nseparately capture static and dynamic characteristics from the local and global\naspects. Based on the distributed monitoring system, a two-level monitoring\nstrategy is proposed to check different influences on process characteristics\nresulting from changes of the operating conditions and control action, and thus\nthe two changes can be well distinguished from each other. Case studies are\nconducted based on both benchmark data and real industrial process data to\nillustrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 06:06:54 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Li", "Wenqing", ""], ["Zhao", "Chunhui", ""], ["Huang", "Biao", ""]]}, {"id": "1809.03363", "submitter": "Ethan Harris", "authors": "Ethan Harris, Matthew Painter and Jonathon Hare", "title": "Torchbearer: A Model Fitting Library for PyTorch", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce torchbearer, a model fitting library for pytorch aimed at\nresearchers working on deep learning or differentiable programming. The\ntorchbearer library provides a high level metric and callback API that can be\nused for a wide range of applications. We also include a series of built in\ncallbacks that can be used for: model persistence, learning rate decay,\nlogging, data visualization and more. The extensive documentation includes an\nexample library for deep learning and dynamic programming problems and can be\nfound at http://torchbearer.readthedocs.io. The code is licensed under the MIT\nLicense and available at https://github.com/ecs-vlc/torchbearer.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 14:46:35 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Harris", "Ethan", ""], ["Painter", "Matthew", ""], ["Hare", "Jonathon", ""]]}, {"id": "1809.03368", "submitter": "Jorn Peters", "authors": "Jorn W.T. Peters and Max Welling", "title": "Probabilistic Binary Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low bit-width weights and activations are an effective way of combating the\nincreasing need for both memory and compute power of Deep Neural Networks. In\nthis work, we present a probabilistic training method for Neural Network with\nboth binary weights and activations, called BLRNet. By embracing stochasticity\nduring training, we circumvent the need to approximate the gradient of\nnon-differentiable functions such as sign(), while still obtaining a fully\nBinary Neural Network at test time. Moreover, it allows for anytime ensemble\npredictions for improved performance and uncertainty estimates by sampling from\nthe weight distribution. Since all operations in a layer of the BLRNet operate\non random variables, we introduce stochastic versions of Batch Normalization\nand max pooling, which transfer well to a deterministic network at test time.\nWe evaluate the BLRNet on multiple standardized benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 14:51:08 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Peters", "Jorn W. T.", ""], ["Welling", "Max", ""]]}, {"id": "1809.03371", "submitter": "Brijnesh Jain", "authors": "Brijnesh Jain", "title": "Revisiting Inaccuracies of Time Series Averaging under Dynamic Time\n  Warping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article revisits an analysis on inaccuracies of time series averaging\nunder dynamic time warping conducted by \\cite{Niennattrakul2007}. The authors\npresented a correctness-criterion and introduced drift-outs of averages from\nclusters. They claimed that averages are inaccurate if they are incorrect or\ndrift-outs. Furthermore, they conjectured that such inaccuracies are caused by\nthe lack of triangle inequality. We show that a rectified version of the\ncorrectness-criterion is unsatisfiable and that the concept of drift-out is\ngeometrically and operationally inconclusive. Satisfying the triangle\ninequality is insufficient to achieve correctness and unnecessary to overcome\nthe drift-out phenomenon. We place the concept of drift-out on a principled\nbasis and show that sample means as global minimizers of a Fr\\'echet function\nnever drift out. The adjusted drift-out is a way to test to which extent an\napproximation is coherent. Empirical results show that solutions obtained by\nthe state-of-the-art methods SSG and DBA are incoherent approximations of a\nsample mean in over a third of all trials.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 15:32:28 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Jain", "Brijnesh", ""]]}, {"id": "1809.03385", "submitter": "Dicong Qiu", "authors": "Dicong Qiu", "title": "SPASS: Scientific Prominence Active Search System with Deep Image\n  Captioning Network", "comments": "9 pages, 5 figures, 1 table. Preprint. Work in progress", "journal-ref": "Planetary and Space Science, 2020, 118: 104943", "doi": "10.1016/j.pss.2020.104943", "report-no": null, "categories": "cs.LG cs.CV cs.IR cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Planetary exploration missions with Mars rovers are complicated, which\ngenerally require elaborated task planning by human experts, from the path to\ntake to the images to capture. NASA has been using this process to acquire over\n22 million images from the planet Mars. In order to improve the degree of\nautomation and thus efficiency in this process, we propose a system for\nplanetary rovers to actively search for prominence of prespecified scientific\nfeatures in captured images. Scientists can prespecify such search tasks in\nnatural language and upload them to a rover, on which the deployed system\nconstantly captions captured images with a deep image captioning network and\ncompare the auto-generated captions to the prespecified search tasks by certain\nmetrics so as to prioritize those images for transmission. As a beneficial side\neffect, the proposed system can also be deployed to ground-based planetary data\nsystems as a content-based search engine.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 15:18:37 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Qiu", "Dicong", ""]]}, {"id": "1809.03395", "submitter": "Fuad Noman", "authors": "Fuad Noman, Sh-Hussain Salleh, Chee-Ming Ting, S. Balqis Samdin,\n  Hernando Ombao, Hadri Hussain", "title": "A Markov-Switching Model Approach to Heart Sound Segmentation and\n  Classification", "comments": null, "journal-ref": null, "doi": "10.1109/JBHI.2019.2925036", "report-no": null, "categories": "eess.SP cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: This paper considers challenges in developing algorithms for\naccurate segmentation and classification of heart sound (HS) signals. Methods:\nWe propose an approach based on Markov switching autoregressive model (MSAR) to\nsegmenting the HS into four fundamental components each with distinct\nsecond-order structure. The identified boundaries are then utilized for\nautomated classification of pathological HS using the continuous density hidden\nMarkov model (CD-HMM). The MSAR formulated in a state-space form is able to\ncapture simultaneously both the continuous hidden dynamics in HS, and the\nregime switching in the dynamics using a discrete Markov chain. This overcomes\nthe limitation of HMM which uses a single-layer of discrete states. We\nintroduce three schemes for model estimation: (1.) switching Kalman filter\n(SKF); (2.) refined SKF; (3.) fusion of SKF and the duration-dependent Viterbi\nalgorithm (SKF-Viterbi). Results: The proposed methods are evaluated on\nPhysionet/CinC Challenge 2016 database. The SKF-Viterbi significantly\noutperforms SKF by improvement of segmentation accuracy from 71% to 84.2%. The\nuse of CD-HMM as a classifier and Mel-frequency cepstral coefficients (MFCCs)\nas features can characterize not only the normal and abnormal morphologies of\nHS signals but also morphologies considered as unclassifiable (denoted as\nX-Factor). It gives classification rates with best gross F1 score of 90.19\n(without X-Factor) and 82.7 (with X-Factor) for abnormal beats. Conclusion: The\nproposed MSAR approach for automatic localization and detection of pathological\nHS shows a noticeable performance on large HS dataset. Significance: It has\npotential applications in heart monitoring systems to assist cardiologists for\npre-screening of heart pathologies.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 15:28:34 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Noman", "Fuad", ""], ["Salleh", "Sh-Hussain", ""], ["Ting", "Chee-Ming", ""], ["Samdin", "S. Balqis", ""], ["Ombao", "Hernando", ""], ["Hussain", "Hadri", ""]]}, {"id": "1809.03400", "submitter": "Hoda Heidari", "authors": "Hoda Heidari, Michele Loi, Krishna P. Gummadi, and Andreas Krause", "title": "A Moral Framework for Understanding of Fair ML through Economic Models\n  of Equality of Opportunity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.TH stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We map the recently proposed notions of algorithmic fairness to economic\nmodels of Equality of opportunity (EOP)---an extensively studied ideal of\nfairness in political philosophy. We formally show that through our conceptual\nmapping, many existing definition of algorithmic fairness, such as predictive\nvalue parity and equality of odds, can be interpreted as special cases of EOP.\nIn this respect, our work serves as a unifying moral framework for\nunderstanding existing notions of algorithmic fairness. Most importantly, this\nframework allows us to explicitly spell out the moral assumptions underlying\neach notion of fairness, and interpret recent fairness impossibility results in\na new light. Last but not least and inspired by luck egalitarian models of EOP,\nwe propose a new family of measures for algorithmic fairness. We illustrate our\nproposal empirically and show that employing a measure of algorithmic\n(un)fairness when its underlying moral assumptions are not satisfied, can have\ndevastating consequences for the disadvantaged group's welfare.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 15:33:51 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 14:54:00 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Heidari", "Hoda", ""], ["Loi", "Michele", ""], ["Gummadi", "Krishna P.", ""], ["Krause", "Andreas", ""]]}, {"id": "1809.03402", "submitter": "John Peruzzi", "authors": "John Peruzzi, Phillip Andrew Wingard, David Zucker", "title": "Does Your Phone Know Your Touch?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores supervised techniques for continuous anomaly detection\nfrom biometric touch screen data. A capacitive sensor array used to mimic a\ntouch screen as used to collect touch and swipe gestures from participants. The\ngestures are recorded over fixed segments of time, with position and force\nmeasured for each gesture. Support Vector Machine, Logistic Regression, and\nGaussian mixture models were tested to learn individual touch patterns. Test\nresults showed true negative and true positive scores of over 95% accuracy for\nall gesture types, with logistic regression models far outperforming the other\nmethods. A more expansive and varied data collection over longer periods of\ntime is needed to determine pragmatic usage of these results.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 15:39:07 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Peruzzi", "John", ""], ["Wingard", "Phillip Andrew", ""], ["Zucker", "David", ""]]}, {"id": "1809.03416", "submitter": "Nisansa de Silva", "authors": "Gathika Ratnayaka, Thejan Rupasinghe, Nisansa de Silva, Menuka\n  Warushavithana, Viraj Gamage, Amal Shehan Perera", "title": "Identifying Relationships Among Sentences in Court Case Transcripts\n  Using Discourse Relations", "comments": "Conference: 2018 International Conference on Advances in ICT for\n  Emerging Regions (ICTer)", "journal-ref": null, "doi": "10.1109/ICTER.2018.8615485", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Case Law has a significant impact on the proceedings of legal cases.\nTherefore, the information that can be obtained from previous court cases is\nvaluable to lawyers and other legal officials when performing their duties.\nThis paper describes a methodology of applying discourse relations between\nsentences when processing text documents related to the legal domain. In this\nstudy, we developed a mechanism to classify the relationships that can be\nobserved among sentences in transcripts of United States court cases. First, we\ndefined relationship types that can be observed between sentences in court case\ntranscripts. Then we classified pairs of sentences according to the\nrelationship type by combining a machine learning model and a rule-based\napproach. The results obtained through our system were evaluated using human\njudges. To the best of our knowledge, this is the first study where discourse\nrelationships between sentences have been used to determine relationships among\nsentences in legal court case transcripts.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 15:55:15 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2018 02:36:07 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Ratnayaka", "Gathika", ""], ["Rupasinghe", "Thejan", ""], ["de Silva", "Nisansa", ""], ["Warushavithana", "Menuka", ""], ["Gamage", "Viraj", ""], ["Perera", "Amal Shehan", ""]]}, {"id": "1809.03428", "submitter": "Ji Wang", "authors": "Ji Wang and Jianguo Zhang and Weidong Bao and Xiaomin Zhu and Bokai\n  Cao and Philip S. Yu", "title": "Not Just Privacy: Improving Performance of Private Deep Learning in\n  Mobile Cloud", "comments": "Conference version accepted by KDD'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing demand for on-device deep learning services calls for a highly\nefficient manner to deploy deep neural networks (DNNs) on mobile devices with\nlimited capacity. The cloud-based solution is a promising approach to enabling\ndeep learning applications on mobile devices where the large portions of a DNN\nare offloaded to the cloud. However, revealing data to the cloud leads to\npotential privacy risk. To benefit from the cloud data center without the\nprivacy risk, we design, evaluate, and implement a cloud-based framework ARDEN\nwhich partitions the DNN across mobile devices and cloud data centers. A simple\ndata transformation is performed on the mobile device, while the\nresource-hungry training and the complex inference rely on the cloud data\ncenter. To protect the sensitive information, a lightweight privacy-preserving\nmechanism consisting of arbitrary data nullification and random noise addition\nis introduced, which provides strong privacy guarantee. A rigorous privacy\nbudget analysis is given. Nonetheless, the private perturbation to the original\ndata inevitably has a negative impact on the performance of further inference\non the cloud side. To mitigate this influence, we propose a noisy training\nmethod to enhance the cloud-side network robustness to perturbed data. Through\nthe sophisticated design, ARDEN can not only preserve privacy but also improve\nthe inference performance. To validate the proposed ARDEN, a series of\nexperiments based on three image datasets and a real mobile application are\nconducted. The experimental results demonstrate the effectiveness of ARDEN.\nFinally, we implement ARDEN on a demo system to verify its practicality.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 16:09:58 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 02:50:41 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 11:21:17 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Wang", "Ji", ""], ["Zhang", "Jianguo", ""], ["Bao", "Weidong", ""], ["Zhu", "Xiaomin", ""], ["Cao", "Bokai", ""], ["Yu", "Philip S.", ""]]}, {"id": "1809.03447", "submitter": "Michal Garmulewicz", "authors": "Micha{\\l} Garmulewicz and Henryk Michalewski and Piotr Mi{\\l}o\\'s", "title": "Expert-augmented actor-critic for ViZDoom and Montezumas Revenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an expert-augmented actor-critic algorithm, which we evaluate on\ntwo environments with sparse rewards: Montezumas Revenge and a demanding maze\nfrom the ViZDoom suite. In the case of Montezumas Revenge, an agent trained\nwith our method achieves very good results consistently scoring above 27,000\npoints (in many experiments beating the first world). With an appropriate\nchoice of hyperparameters, our algorithm surpasses the performance of the\nexpert data. In a number of experiments, we have observed an unreported bug in\nMontezumas Revenge which allowed the agent to score more than 800,000 points.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 16:36:22 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Garmulewicz", "Micha\u0142", ""], ["Michalewski", "Henryk", ""], ["Mi\u0142o\u015b", "Piotr", ""]]}, {"id": "1809.03461", "submitter": "Xiu Yang", "authors": "Xiu Yang and Guzel Tartakovsky and Alexandre Tartakovsky", "title": "Physics-Informed Kriging: A Physics-Informed Gaussian Process Regression\n  Method for Data-Model Convergence", "comments": "Updated Figure 2(b),(c), Figure 3(c), Figure 4 and Figure 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new Gaussian process regression (GPR) method:\nphysics-informed Kriging (PhIK). In the standard data-driven Kriging, the\nunknown function of interest is usually treated as a Gaussian process with\nassumed stationary covariance with hyperparameters estimated from data. In\nPhIK, we compute the mean and covariance function from realizations of\navailable stochastic models, e.g., from realizations of governing stochastic\npartial differential equations solutions. Such a constructed Gaussian process\ngenerally is non-stationary, and does not assume a specific form of the\ncovariance function. Our approach avoids the costly optimization step in\ndata-driven GPR methods to identify the hyperparameters. More importantly, we\nprove that the physical constraints in the form of a deterministic linear\noperator are guaranteed in the resulting prediction. We also provide an error\nestimate in preserving the physical constraints when errors are included in the\nstochastic model realizations. To reduce the computational cost of obtaining\nstochastic model realizations, we propose a multilevel Monte Carlo estimate of\nthe mean and covariance functions. Further, we present an active learning\nalgorithm that guides the selection of additional observation locations. The\nefficiency and accuracy of PhIK are demonstrated for reconstructing a partially\nknown modified Branin function and learning a conservative tracer distribution\nfrom sparse concentration measurements.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 17:04:31 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 17:12:49 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Yang", "Xiu", ""], ["Tartakovsky", "Guzel", ""], ["Tartakovsky", "Alexandre", ""]]}, {"id": "1809.03470", "submitter": "Marek Wydmuch", "authors": "Marek Wydmuch, Micha{\\l} Kempka, Wojciech Ja\\'skowski", "title": "ViZDoom Competitions: Playing Doom from Pixels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first two editions of Visual Doom AI Competition,\nheld in 2016 and 2017. The challenge was to create bots that compete in a\nmulti-player deathmatch in a first-person shooter (FPS) game, Doom. The bots\nhad to make their decisions based solely on visual information, i.e., a raw\nscreen buffer. To play well, the bots needed to understand their surroundings,\nnavigate, explore, and handle the opponents at the same time. These aspects,\ntogether with the competitive multi-agent aspect of the game, make the\ncompetition a unique platform for evaluating the state of the art reinforcement\nlearning algorithms. The paper discusses the rules, solutions, results, and\nstatistics that give insight into the agents' behaviors. Best-performing agents\nare described in more detail. The results of the competition lead to the\nconclusion that, although reinforcement learning can produce capable Doom bots,\nthey still are not yet able to successfully compete against humans in this\ngame. The paper also revisits the ViZDoom environment, which is a flexible,\neasy to use, and efficient 3D platform for research for vision-based\nreinforcement learning, based on a well-recognized first-person perspective\ngame Doom.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 17:41:39 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Wydmuch", "Marek", ""], ["Kempka", "Micha\u0142", ""], ["Ja\u015bkowski", "Wojciech", ""]]}, {"id": "1809.03474", "submitter": "Mohammad Mahmoody", "authors": "Saeed Mahloujifar, Mohammad Mahmoody, Ameer Mohammed", "title": "Multi-party Poisoning through Generalized $p$-Tampering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a poisoning attack against a learning algorithm, an adversary tampers with\na fraction of the training data $T$ with the goal of increasing the\nclassification error of the constructed hypothesis/model over the final test\ndistribution. In the distributed setting, $T$ might be gathered gradually from\n$m$ data providers $P_1,\\dots,P_m$ who generate and submit their shares of $T$\nin an online way.\n  In this work, we initiate a formal study of $(k,p)$-poisoning attacks in\nwhich an adversary controls $k\\in[n]$ of the parties, and even for each\ncorrupted party $P_i$, the adversary submits some poisoned data $T'_i$ on\nbehalf of $P_i$ that is still \"$(1-p)$-close\" to the correct data $T_i$ (e.g.,\n$1-p$ fraction of $T'_i$ is still honestly generated). For $k=m$, this model\nbecomes the traditional notion of poisoning, and for $p=1$ it coincides with\nthe standard notion of corruption in multi-party computation.\n  We prove that if there is an initial constant error for the generated\nhypothesis $h$, there is always a $(k,p)$-poisoning attacker who can decrease\nthe confidence of $h$ (to have a small error), or alternatively increase the\nerror of $h$, by $\\Omega(p \\cdot k/m)$. Our attacks can be implemented in\npolynomial time given samples from the correct data, and they use no wrong\nlabels if the original distributions are not noisy.\n  At a technical level, we prove a general lemma about biasing bounded\nfunctions $f(x_1,\\dots,x_n)\\in[0,1]$ through an attack model in which each\nblock $x_i$ might be controlled by an adversary with marginal probability $p$\nin an online way. When the probabilities are independent, this coincides with\nthe model of $p$-tampering attacks, thus we call our model generalized\n$p$-tampering. We prove the power of such attacks by incorporating ideas from\nthe context of coin-flipping attacks into the $p$-tampering model and\ngeneralize the results in both of these areas.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 17:47:24 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 22:49:33 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""], ["Mohammed", "Ameer", ""]]}, {"id": "1809.03497", "submitter": "Dan Shiebler", "authors": "Dan Shiebler", "title": "A Correlation Maximization Approach for Cross Domain Co-Embeddings", "comments": "Submitted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although modern recommendation systems can exploit the structure in users'\nitem feedback, most are powerless in the face of new users who provide no\nstructure for them to exploit. In this paper we introduce ImplicitCE, an\nalgorithm for recommending items to new users during their sign-up flow.\nImplicitCE works by transforming users' implicit feedback towards auxiliary\ndomain items into an embedding in the target domain item embedding space.\nImplicitCE learns these embedding spaces and transformation function in an\nend-to-end fashion and can co-embed users and items with any differentiable\nsimilarity function. To train ImplicitCE we explore methods for maximizing the\ncorrelations between model predictions and users' affinities and introduce\nSample Correlation Update, a novel and extremely simple training strategy.\nFinally, we show that ImplicitCE trained with Sample Correlation Update\noutperforms a variety of state of the art algorithms and loss functions on both\na large scale Twitter dataset and the DBLP dataset.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 17:20:04 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Shiebler", "Dan", ""]]}, {"id": "1809.03534", "submitter": "Mahdi Khodayar", "authors": "Mahdi Khodayar, Jianhui Wang, Zhaoyu Wang", "title": "Energy Disaggregation via Deep Temporal Dictionary Learning", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the energy disaggregation problem, i.e. decomposing the\nelectricity signal of a whole home to its operating devices. First, we cast the\nproblem as a dictionary learning (DL) problem where the key electricity\npatterns representing consumption behaviors are extracted for each device and\nstored in a dictionary matrix. The electricity signal of each device is then\nmodeled by a linear combination of such patterns with sparse coefficients that\ndetermine the contribution of each device in the total electricity. Although\npopular, the classic DL approach is prone to high error in real-world\napplications including energy disaggregation, as it merely finds linear\ndictionaries. Moreover, this method lacks a recurrent structure; thus, it is\nunable to leverage the temporal structure of energy signals. Motivated by such\nshortcomings, we propose a novel optimization program where the dictionary and\nits sparse coefficients are optimized simultaneously with a deep neural model\nextracting powerful nonlinear features from the energy signals. A long\nshort-term memory auto-encoder (LSTM-AE) is proposed with tunable time\ndependent states to capture the temporal behavior of energy signals for each\ndevice. We learn the dictionary in the space of temporal features captured by\nthe LSTM-AE rather than the original space of the energy signals; hence, in\ncontrast to the traditional DL, here, a nonlinear dictionary is learned using\npowerful temporal features extracted from our deep model. Real experiments on\nthe publicly available Reference Energy Disaggregation Dataset (REDD) show\nsignificant improvement compared to the state-of-the-art methodologies in terms\nof the disaggregation accuracy and F-score metrics.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 18:26:39 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Khodayar", "Mahdi", ""], ["Wang", "Jianhui", ""], ["Wang", "Zhaoyu", ""]]}, {"id": "1809.03538", "submitter": "Mahdi Khodayar", "authors": "Mahdi Khodayar, Saeed Mohammadi, Mohammad Khodayar, Jianhui Wang,\n  Guangyi Liu", "title": "Convolutional Graph Auto-encoder: A Deep Generative Neural Architecture\n  for Probabilistic Spatio-temporal Solar Irradiance Forecasting", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning on graph-structured data is an important and omnipresent\ntask for a vast variety of applications including anomaly detection and dynamic\nnetwork analysis. In this paper, a deep generative model is introduced to\ncapture continuous probability densities corresponding to the nodes of an\narbitrary graph. In contrast to all learning formulations in the area of\ndiscriminative pattern recognition, we propose a scalable generative\noptimization/algorithm theoretically proved to capture distributions at the\nnodes of a graph. Our model is able to generate samples from the probability\ndensities learned at each node. This probabilistic data generation model, i.e.\nconvolutional graph auto-encoder (CGAE), is devised based on the localized\nfirst-order approximation of spectral graph convolutions, deep learning, and\nthe variational Bayesian inference. We apply our CGAE to a new problem, the\nspatio-temporal probabilistic solar irradiance prediction. Multiple solar\nradiation measurement sites in a wide area in northern states of the US are\nmodeled as an undirected graph. Using our proposed model, the distribution of\nfuture irradiance given historical radiation observations is estimated for\nevery site/node. Numerical results on the National Solar Radiation Database\nshow state-of-the-art performance for probabilistic radiation prediction on\ngeographically distributed irradiance data in terms of reliability, sharpness,\nand continuous ranked probability score.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 18:31:53 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Khodayar", "Mahdi", ""], ["Mohammadi", "Saeed", ""], ["Khodayar", "Mohammad", ""], ["Wang", "Jianhui", ""], ["Liu", "Guangyi", ""]]}, {"id": "1809.03541", "submitter": "Ramin Moghaddass", "authors": "Ramin Moghaddass and Cynthia Rudin", "title": "Bayesian Patchworks: An Approach to Case-Based Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Doctors often rely on their past experience in order to diagnose patients.\nFor a doctor with enough experience, almost every patient would have\nsimilarities to key cases seen in the past, and each new patient could be\nviewed as a mixture of these key past cases. Because doctors often tend to\nreason this way, an efficient computationally aided diagnostic tool that thinks\nin the same way might be helpful in locating key past cases of interest that\ncould assist with diagnosis. This article develops a novel mathematical model\nto mimic the type of logical thinking that physicians use when considering past\ncases. The proposed model can also provide physicians with explanations that\nwould be similar to the way they would naturally reason about cases. The\nproposed method is designed to yield predictive accuracy, computational\nefficiency, and insight into medical data; the key element is the insight into\nmedical data, in some sense we are automating a complicated process that\nphysicians might perform manually. We finally implemented the result of this\nwork on two publicly available healthcare datasets, for heart disease\nprediction and breast cancer prediction.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 18:40:46 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Moghaddass", "Ramin", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1809.03548", "submitter": "Isac Arnekvist", "authors": "Isac Arnekvist, Danica Kragic and Johannes A. Stork", "title": "VPE: Variational Policy Embedding for Transfer Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning methods are capable of solving complex problems, but\nresulting policies might perform poorly in environments that are even slightly\ndifferent. In robotics especially, training and deployment conditions often\nvary and data collection is expensive, making retraining undesirable.\nSimulation training allows for feasible training times, but on the other hand\nsuffers from a reality-gap when applied in real-world settings. This raises the\nneed of efficient adaptation of policies acting in new environments. We\nconsider this as a problem of transferring knowledge within a family of similar\nMarkov decision processes.\n  For this purpose we assume that Q-functions are generated by some\nlow-dimensional latent variable. Given such a Q-function, we can find a master\npolicy that can adapt given different values of this latent variable. Our\nmethod learns both the generative mapping and an approximate posterior of the\nlatent variables, enabling identification of policies for new tasks by\nsearching only in the latent space, rather than the space of all policies. The\nlow-dimensional space, and master policy found by our method enables policies\nto quickly adapt to new environments. We demonstrate the method on both a\npendulum swing-up task in simulation, and for simulation-to-real transfer on a\npushing task.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 18:55:19 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 11:39:07 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Arnekvist", "Isac", ""], ["Kragic", "Danica", ""], ["Stork", "Johannes A.", ""]]}, {"id": "1809.03553", "submitter": "Daniel Cullina", "authors": "Daniel Cullina, Negar Kiyavash, Prateek Mittal, H. Vincent Poor", "title": "Partial Recovery of Erd\\H{o}s-R\\'enyi Graph Alignment via $k$-Core\n  Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine information theoretic conditions under which it is possible to\npartially recover the alignment used to generate a pair of sparse, correlated\nErd\\H{o}s-R\\'enyi graphs. To prove our achievability result, we introduce the\n$k$-core alignment estimator. This estimator searches for an alignment in which\nthe intersection of the correlated graphs using this alignment has a minimum\ndegree of $k$. We prove a matching converse bound. As the number of vertices\ngrows, recovery of the alignment for a fraction of the vertices tending to one\nis possible when the average degree of the intersection of the graph pair tends\nto infinity. It was previously known that exact alignment is possible when this\naverage degree grows faster than the logarithm of the number of vertices.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 19:12:23 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 23:59:24 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Cullina", "Daniel", ""], ["Kiyavash", "Negar", ""], ["Mittal", "Prateek", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1809.03559", "submitter": "Ji Wang", "authors": "Ji Wang and Bokai Cao and Philip S. Yu and Lichao Sun and Weidong Bao\n  and Xiaomin Zhu", "title": "Deep Learning Towards Mobile Applications", "comments": "Conference version accepted by ICDCS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed an explosive growth of mobile devices. Mobile\ndevices are permeating every aspect of our daily lives. With the increasing\nusage of mobile devices and intelligent applications, there is a soaring demand\nfor mobile applications with machine learning services. Inspired by the\ntremendous success achieved by deep learning in many machine learning tasks, it\nbecomes a natural trend to push deep learning towards mobile applications.\nHowever, there exist many challenges to realize deep learning in mobile\napplications, including the contradiction between the miniature nature of\nmobile devices and the resource requirement of deep neural networks, the\nprivacy and security concerns about individuals' data, and so on. To resolve\nthese challenges, during the past few years, great leaps have been made in this\narea. In this paper, we provide an overview of the current challenges and\nrepresentative achievements about pushing deep learning on mobile devices from\nthree aspects: training with mobile data, efficient inference on mobile\ndevices, and applications of mobile deep learning. The former two aspects cover\nthe primary tasks of deep learning. Then, we go through our two recent\napplications that apply the data collected by mobile devices to inferring mood\ndisturbance and user identification. Finally, we conclude this paper with the\ndiscussion of the future of this area.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 19:28:57 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Wang", "Ji", ""], ["Cao", "Bokai", ""], ["Yu", "Philip S.", ""], ["Sun", "Lichao", ""], ["Bao", "Weidong", ""], ["Zhu", "Xiaomin", ""]]}, {"id": "1809.03566", "submitter": "Sikun Yang", "authors": "Sikun Yang, Heinz Koeppl", "title": "Collapsed Variational Inference for Nonparametric Bayesian Group Factor\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group factor analysis (GFA) methods have been widely used to infer the common\nstructure and the group-specific signals from multiple related datasets in\nvarious fields including systems biology and neuroimaging. To date, most\navailable GFA models require Gibbs sampling or slice sampling to perform\ninference, which prevents the practical application of GFA to large-scale data.\nIn this paper we present an efficient collapsed variational inference (CVI)\nalgorithm for the nonparametric Bayesian group factor analysis (NGFA) model\nbuilt upon an hierarchical beta Bernoulli process. Our CVI algorithm proceeds\nby marginalizing out the group-specific beta process parameters, and then\napproximating the true posterior in the collapsed space using mean field\nmethods. Experimental results on both synthetic and real-world data demonstrate\nthe effectiveness of our CVI algorithm for the NGFA compared with\nstate-of-the-art GFA methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 19:50:56 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 15:38:44 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Yang", "Sikun", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1809.03576", "submitter": "Xia Zhu", "authors": "Apoorv Vyas, Nataraj Jammalamadaka, Xia Zhu, Dipankar Das, Bharat\n  Kaul, Theodore L. Willke", "title": "Out-of-Distribution Detection Using an Ensemble of Self Supervised\n  Leave-out Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning methods form a critical part in commercially important\napplications such as autonomous driving and medical diagnostics, it is\nimportant to reliably detect out-of-distribution (OOD) inputs while employing\nthese algorithms. In this work, we propose an OOD detection algorithm which\ncomprises of an ensemble of classifiers. We train each classifier in a\nself-supervised manner by leaving out a random subset of training data as OOD\ndata and the rest as in-distribution (ID) data. We propose a novel margin-based\nloss over the softmax output which seeks to maintain at least a margin $m$\nbetween the average entropy of the OOD and in-distribution samples. In\nconjunction with the standard cross-entropy loss, we minimize the novel loss to\ntrain an ensemble of classifiers. We also propose a novel method to combine the\noutputs of the ensemble of classifiers to obtain OOD detection score and class\nprediction. Overall, our method convincingly outperforms Hendrycks et al.[7]\nand the current state-of-the-art ODIN[13] on several OOD detection benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 16:00:08 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Vyas", "Apoorv", ""], ["Jammalamadaka", "Nataraj", ""], ["Zhu", "Xia", ""], ["Das", "Dipankar", ""], ["Kaul", "Bharat", ""], ["Willke", "Theodore L.", ""]]}, {"id": "1809.03618", "submitter": "Rafael Ballester-Ripoll", "authors": "Rafael Ballester-Ripoll, Renato Pajarola", "title": "Visualization of High-dimensional Scalar Functions Using Principal\n  Parameterizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG cs.MM cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insightful visualization of multidimensional scalar fields, in particular\nparameter spaces, is key to many fields in computational science and\nengineering. We propose a principal component-based approach to visualize such\nfields that accurately reflects their sensitivity to input parameters. The\nmethod performs dimensionality reduction on the vast $L^2$ Hilbert space formed\nby all possible partial functions (i.e., those defined by fixing one or more\ninput parameters to specific values), which are projected to low-dimensional\nparameterized manifolds such as 3D curves, surfaces, and ensembles thereof. Our\nmapping provides a direct geometrical and visual interpretation in terms of\nSobol's celebrated method for variance-based sensitivity analysis. We\nfurthermore contribute a practical realization of the proposed method by means\nof tensor decomposition, which enables accurate yet interactive integration and\nmultilinear principal component analysis of high-dimensional models.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 08:35:12 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Ballester-Ripoll", "Rafael", ""], ["Pajarola", "Renato", ""]]}, {"id": "1809.03627", "submitter": "Sudipto Mukherjee", "authors": "Sudipto Mukherjee, Himanshu Asnani, Eugene Lin, Sreeram Kannan", "title": "ClusterGAN : Latent Space Clustering in Generative Adversarial Networks", "comments": "GANs, Clustering, Latent Space, Interpolation (v2 : Typos fixed, some\n  new experiments added, reported metrics on best validated model.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial networks (GANs) have obtained remarkable success in\nmany unsupervised learning tasks and unarguably, clustering is an important\nunsupervised learning problem. While one can potentially exploit the\nlatent-space back-projection in GANs to cluster, we demonstrate that the\ncluster structure is not retained in the GAN latent space.\n  In this paper, we propose ClusterGAN as a new mechanism for clustering using\nGANs. By sampling latent variables from a mixture of one-hot encoded variables\nand continuous latent variables, coupled with an inverse network (which\nprojects the data to the latent space) trained jointly with a clustering\nspecific loss, we are able to achieve clustering in the latent space. Our\nresults show a remarkable phenomenon that GANs can preserve latent space\ninterpolation across categories, even though the discriminator is never exposed\nto such vectors. We compare our results with various clustering baselines and\ndemonstrate superior performance on both synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 23:00:37 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 23:28:35 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Mukherjee", "Sudipto", ""], ["Asnani", "Himanshu", ""], ["Lin", "Eugene", ""], ["Kannan", "Sreeram", ""]]}, {"id": "1809.03650", "submitter": "Seong-Eun Moon", "authors": "Seong-Eun Moon, Soobeom Jang, Jong-Seok Lee", "title": "Evaluation of Preference of Multimedia Content using Deep Neural\n  Networks for Electroencephalography", "comments": "Accepted for the 10th International Conference on Quality of\n  Multimedia Experience (QoMEX 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of quality of experience (QoE) based on electroencephalography\n(EEG) has received great attention due to its capability of real-time QoE\nmonitoring of users. However, it still suffers from rather low recognition\naccuracy. In this paper, we propose a novel method using deep neural networks\ntoward improved modeling of EEG and thereby improved recognition accuracy. In\nparticular, we aim to model spatio-temporal characteristics relevant for QoE\nanalysis within learning models. The results demonstrate the effectiveness of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 01:51:24 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 01:14:00 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Moon", "Seong-Eun", ""], ["Jang", "Soobeom", ""], ["Lee", "Jong-Seok", ""]]}, {"id": "1809.03655", "submitter": "Tao Sun", "authors": "Lei Guan, Linbo Qiao, Dongsheng Li, Tao Sun, Keshi Ge, Xicheng Lu", "title": "An Efficient ADMM-Based Algorithm to Nonconvex Penalized Support Vector\n  Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machines (SVMs) with sparsity-inducing nonconvex penalties\nhave received considerable attentions for the characteristics of automatic\nclassification and variable selection. However, it is quite challenging to\nsolve the nonconvex penalized SVMs due to their nondifferentiability,\nnonsmoothness and nonconvexity. In this paper, we propose an efficient\nADMM-based algorithm to the nonconvex penalized SVMs. The proposed algorithm\ncovers a large class of commonly used nonconvex regularization terms including\nthe smooth clipped absolute deviation (SCAD) penalty, minimax concave penalty\n(MCP), log-sum penalty (LSP) and capped-$\\ell_1$ penalty. The computational\ncomplexity analysis shows that the proposed algorithm enjoys low computational\ncost. Moreover, the convergence of the proposed algorithm is guaranteed.\nExtensive experimental evaluations on five benchmark datasets demonstrate the\nsuperior performance of the proposed algorithm to other three state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 02:08:15 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Guan", "Lei", ""], ["Qiao", "Linbo", ""], ["Li", "Dongsheng", ""], ["Sun", "Tao", ""], ["Ge", "Keshi", ""], ["Lu", "Xicheng", ""]]}, {"id": "1809.03668", "submitter": "Alex Biddulph", "authors": "Alexander Biddulph, Trent Houlistion, Alexandre Mendes, Stephan K.\n  Chalup", "title": "Comparing Computing Platforms for Deep Learning on a Humanoid Robot", "comments": "12 pages, 5 figures", "journal-ref": "Neural Information Processing, 11307 (2018), 120-131", "doi": "10.1007/978-3-030-04239-4_11", "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this study is to test two different computing platforms with\nrespect to their suitability for running deep networks as part of a humanoid\nrobot software system. One of the platforms is the CPU-centered Intel NUC7i7BNH\nand the other is a NVIDIA Jetson TX2 system that puts more emphasis on GPU\nprocessing. The experiments addressed a number of benchmarking tasks including\npedestrian detection using deep neural networks. Some of the results were\nunexpected but demonstrate that platforms exhibit both advantages and\ndisadvantages when taking computational performance and electrical power\nrequirements of such a system into account.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 03:25:36 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2019 23:38:47 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Biddulph", "Alexander", ""], ["Houlistion", "Trent", ""], ["Mendes", "Alexandre", ""], ["Chalup", "Stephan K.", ""]]}, {"id": "1809.03672", "submitter": "Guorui Zhou", "authors": "Guorui Zhou and Na Mou and Ying Fan and Qi Pi and Weijie Bian and\n  Chang Zhou and Xiaoqiang Zhu and Kun Gai", "title": "Deep Interest Evolution Network for Click-Through Rate Prediction", "comments": "9 pages. Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate~(CTR) prediction, whose goal is to estimate the\nprobability of the user clicks, has become one of the core tasks in advertising\nsystems. For CTR prediction model, it is necessary to capture the latent user\ninterest behind the user behavior data. Besides, considering the changing of\nthe external environment and the internal cognition, user interest evolves over\ntime dynamically. There are several CTR prediction methods for interest\nmodeling, while most of them regard the representation of behavior as the\ninterest directly, and lack specially modeling for latent interest behind the\nconcrete behavior. Moreover, few work consider the changing trend of interest.\nIn this paper, we propose a novel model, named Deep Interest Evolution\nNetwork~(DIEN), for CTR prediction. Specifically, we design interest extractor\nlayer to capture temporal interests from history behavior sequence. At this\nlayer, we introduce an auxiliary loss to supervise interest extracting at each\nstep. As user interests are diverse, especially in the e-commerce system, we\npropose interest evolving layer to capture interest evolving process that is\nrelative to the target item. At interest evolving layer, attention mechanism is\nembedded into the sequential structure novelly, and the effects of relative\ninterests are strengthened during interest evolution. In the experiments on\nboth public and industrial datasets, DIEN significantly outperforms the\nstate-of-the-art solutions. Notably, DIEN has been deployed in the display\nadvertisement system of Taobao, and obtained 20.7\\% improvement on CTR.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 03:52:37 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 04:08:27 GMT"}, {"version": "v3", "created": "Tue, 6 Nov 2018 05:28:48 GMT"}, {"version": "v4", "created": "Wed, 7 Nov 2018 09:45:31 GMT"}, {"version": "v5", "created": "Fri, 16 Nov 2018 06:48:37 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Zhou", "Guorui", ""], ["Mou", "Na", ""], ["Fan", "Ying", ""], ["Pi", "Qi", ""], ["Bian", "Weijie", ""], ["Zhou", "Chang", ""], ["Zhu", "Xiaoqiang", ""], ["Gai", "Kun", ""]]}, {"id": "1809.03702", "submitter": "Nan Rosemary Ke", "authors": "Nan Rosemary Ke, Anirudh Goyal, Olexa Bilaniuk, Jonathan Binas,\n  Michael C. Mozer, Chris Pal, Yoshua Bengio", "title": "Sparse Attentive Backtracking: Temporal CreditAssignment Through\n  Reminding", "comments": "To appear as a Spotlight presentation at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning long-term dependencies in extended temporal sequences requires\ncredit assignment to events far back in the past. The most common method for\ntraining recurrent neural networks, back-propagation through time (BPTT),\nrequires credit information to be propagated backwards through every single\nstep of the forward computation, potentially over thousands or millions of time\nsteps. This becomes computationally expensive or even infeasible when used with\nlong sequences. Importantly, biological brains are unlikely to perform such\ndetailed reverse replay over very long sequences of internal states (consider\ndays, months, or years.) However, humans are often reminded of past memories or\nmental states which are associated with the current mental state. We consider\nthe hypothesis that such memory associations between past and present could be\nused for credit assignment through arbitrarily long sequences, propagating the\ncredit assigned to the current state to the associated past state. Based on\nthis principle, we study a novel algorithm which only back-propagates through a\nfew of these temporal skip connections, realized by a learned attention\nmechanism that associates current states with relevant past states. We\ndemonstrate in experiments that our method matches or outperforms regular BPTT\nand truncated BPTT in tasks involving particularly long-term dependencies, but\nwithout requiring the biologically implausible backward replay through the\nwhole history of states. Additionally, we demonstrate that the proposed method\ntransfers to longer sequences significantly better than LSTMs trained with BPTT\nand LSTMs trained with full self-attention.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 07:04:47 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Ke", "Nan Rosemary", ""], ["Goyal", "Anirudh", ""], ["Bilaniuk", "Olexa", ""], ["Binas", "Jonathan", ""], ["Mozer", "Michael C.", ""], ["Pal", "Chris", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1809.03705", "submitter": "Xiaoxiao Du", "authors": "Xiaoxiao Du and Ram Vasudevan and Matthew Johnson-Roberson", "title": "Bio-LSTM: A Biomechanically Inspired Recurrent Neural Network for 3D\n  Pedestrian Pose and Gait Prediction", "comments": "Typo corrected after Eq.(2)", "journal-ref": "IEEE Robotics and Automation Letters, vol. 4, no. 2, pp.\n  1501-1508, April 2019", "doi": "10.1109/LRA.2019.2895266", "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications such as autonomous driving, it is important to understand,\ninfer, and anticipate the intention and future behavior of pedestrians. This\nability allows vehicles to avoid collisions and improve ride safety and\nquality. This paper proposes a biomechanically inspired recurrent neural\nnetwork (Bio-LSTM) that can predict the location and 3D articulated body pose\nof pedestrians in a global coordinate frame, given 3D poses and locations\nestimated in prior frames with inaccuracy. The proposed network is able to\npredict poses and global locations for multiple pedestrians simultaneously, for\npedestrians up to 45 meters from the cameras (urban intersection scale). The\noutputs of the proposed network are full-body 3D meshes represented in Skinned\nMulti-Person Linear (SMPL) model parameters. The proposed approach relies on a\nnovel objective function that incorporates the periodicity of human walking\n(gait), the mirror symmetry of the human body, and the change of ground\nreaction forces in a human gait cycle. This paper presents prediction results\non the PedX dataset, a large-scale, in-the-wild data set collected at real\nurban intersections with heavy pedestrian traffic. Results show that the\nproposed network can successfully learn the characteristics of pedestrian gait\nand produce accurate and consistent 3D pose predictions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 07:11:32 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 17:50:07 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 15:28:14 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Du", "Xiaoxiao", ""], ["Vasudevan", "Ram", ""], ["Johnson-Roberson", "Matthew", ""]]}, {"id": "1809.03707", "submitter": "Hector Basevi", "authors": "M. Wagner, H. Basevi, R. Shetty, W. Li, M. Malinowski, M. Fritz, A.\n  Leonardis", "title": "Answering Visual What-If Questions: From Actions to Predicted Scene\n  Descriptions", "comments": "Paper: 18 pages, 5 figures, 5 tables. Supplementary material: 3\n  pages, 1 figure, 1 table. To be published in VLEASE ECCV 2018 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-depth scene descriptions and question answering tasks have greatly\nincreased the scope of today's definition of scene understanding. While such\ntasks are in principle open ended, current formulations primarily focus on\ndescribing only the current state of the scenes under consideration. In\ncontrast, in this paper, we focus on the future states of the scenes which are\nalso conditioned on actions. We posit this as a question answering task, where\nan answer has to be given about a future scene state, given observations of the\ncurrent scene, and a question that includes a hypothetical action. Our solution\nis a hybrid model which integrates a physics engine into a question answering\narchitecture in order to anticipate future scene states resulting from\nobject-object interactions caused by an action. We demonstrate first results on\nthis challenging new problem and compare to baselines, where we outperform\nfully data-driven end-to-end learning approaches.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 07:22:28 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 16:39:39 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Wagner", "M.", ""], ["Basevi", "H.", ""], ["Shetty", "R.", ""], ["Li", "W.", ""], ["Malinowski", "M.", ""], ["Fritz", "M.", ""], ["Leonardis", "A.", ""]]}, {"id": "1809.03721", "submitter": "Seungjoon Yang", "authors": "Jinhyeok Jang, Hyunjoong Cho, Jaehong Kim, Jaeyeon Lee, and Seungjoon\n  Yang", "title": "Deep Asymmetric Networks with a Set of Node-wise Variant Activation\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents deep asymmetric networks with a set of node-wise variant\nactivation functions. The nodes' sensitivities are affected by activation\nfunction selections such that the nodes with smaller indices become\nincreasingly more sensitive. As a result, features learned by the nodes are\nsorted by the node indices in the order of their importance. Asymmetric\nnetworks not only learn input features but also the importance of those\nfeatures. Nodes of lesser importance in asymmetric networks can be pruned to\nreduce the complexity of the networks, and the pruned networks can be retrained\nwithout incurring performance losses. We validate the feature-sorting property\nusing both shallow and deep asymmetric networks as well as deep asymmetric\nnetworks transferred from famous networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 08:09:25 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 07:24:15 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Jang", "Jinhyeok", ""], ["Cho", "Hyunjoong", ""], ["Kim", "Jaehong", ""], ["Lee", "Jaeyeon", ""], ["Yang", "Seungjoon", ""]]}, {"id": "1809.03776", "submitter": "Ryota Suzuki", "authors": "Ryota Suzuki, Shingo Takahashi, Murtuza Petladwala, and Shigeru\n  Kohmoto", "title": "Solving Non-identifiable Latent Feature Models", "comments": "Submitted to NIPS 2018 (https://nips.cc/). 15 pages , 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent feature models (LFM)s are widely employed for extracting latent\nstructures of data. While offering high, parameter estimation is difficult with\nLFMs because of the combinational nature of latent features, and\nnon-identifiability is a particularly difficult problem when parameter\nestimation is not unique and there exists equivalent solutions. In this paper,\na necessary and sufficient condition for non-identifiability is shown. The\ncondition is significantly related to dependency of features, and this implies\nthat non-identifiability may often occur in real-world applications. A novel\nmethod for parameter estimation that solves the non-identifiability problem is\nalso proposed. This method can be combined as a post-process with existing\nmethods and can find an appropriate solution by hopping efficiently through\nequivalent solutions. We have evaluated the effectiveness of the method on both\nsynthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 10:11:48 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 05:46:55 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Suzuki", "Ryota", ""], ["Takahashi", "Shingo", ""], ["Petladwala", "Murtuza", ""], ["Kohmoto", "Shigeru", ""]]}, {"id": "1809.03779", "submitter": "Zenith Purisha", "authors": "Zenith Purisha, Carl Jidling, Niklas Wahlstr\\\"om, Simo S\\\"arkk\\\"a,\n  Thomas B. Sch\\\"on", "title": "Probabilistic approach to limited-data computed tomography\n  reconstruction", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6420/ab2e2a", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the inverse problem of reconstructing the internal\nstructure of an object from limited x-ray projections. We use a Gaussian\nprocess prior to model the target function and estimate its (hyper)parameters\nfrom measured data. In contrast to other established methods, this comes with\nthe advantage of not requiring any manual parameter tuning, which usually\narises in classical regularization strategies. Our method uses a basis function\nexpansion technique for the Gaussian process which significantly reduces the\ncomputational complexity and avoids the need for numerical integration. The\napproach also allows for reformulation of come classical regularization methods\nas Laplacian and Tikhonov regularization as Gaussian process regression, and\nhence provides an efficient algorithm and principled means for their parameter\ntuning. Results from simulated and real data indicate that this approach is\nless sensitive to streak artifacts as compared to the commonly used method of\nfiltered backprojection.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 10:16:44 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 09:07:08 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2019 08:30:06 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Purisha", "Zenith", ""], ["Jidling", "Carl", ""], ["Wahlstr\u00f6m", "Niklas", ""], ["S\u00e4rkk\u00e4", "Simo", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1809.03817", "submitter": "Qingnan Sun", "authors": "Qingnan Sun, Marko V. Jankovic, Lia Bally, Stavroula G. Mougiakakou", "title": "Predicting Blood Glucose with an LSTM and Bi-LSTM Based Deep Neural\n  Network", "comments": "5 pages, submitted to 2018 14th Symposium on Neural Networks and\n  Applications (NEUREL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep learning network was used to predict future blood glucose levels, as\nthis can permit diabetes patients to take action before imminent hyperglycaemia\nand hypoglycaemia. A sequential model with one long-short-term memory (LSTM)\nlayer, one bidirectional LSTM layer and several fully connected layers was used\nto predict blood glucose levels for different prediction horizons. The method\nwas trained and tested on 26 datasets from 20 real patients. The proposed\nnetwork outperforms the baseline methods in terms of all evaluation criteria.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 12:26:46 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Sun", "Qingnan", ""], ["Jankovic", "Marko V.", ""], ["Bally", "Lia", ""], ["Mougiakakou", "Stavroula G.", ""]]}, {"id": "1809.03832", "submitter": "Antti Koskela", "authors": "Antti Koskela and Antti Honkela", "title": "Learning Rate Adaptation for Federated and Differentially Private\n  Learning", "comments": "17 pages, 9 figures", "journal-ref": "AISTATS (2020) 2465-2475", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an algorithm for the adaptation of the learning rate for\nstochastic gradient descent (SGD) that avoids the need for validation set use.\nThe idea for the adaptiveness comes from the technique of extrapolation: to get\nan estimate for the error against the gradient flow which underlies SGD, we\ncompare the result obtained by one full step and two half-steps. The algorithm\nis applied in two separate frameworks: federated and differentially private\nlearning. Using examples of deep neural networks we empirically show that the\nadaptive algorithm is competitive with manually tuned commonly used\noptimisation methods for differentially privately training. We also show that\nit works robustly in the case of federated learning unlike commonly used\noptimisation methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 13:04:19 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 13:34:05 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 10:30:52 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Koskela", "Antti", ""], ["Honkela", "Antti", ""]]}, {"id": "1809.03839", "submitter": "Seiichi Kuroki", "authors": "Seiichi Kuroki, Nontawat Charoenphakdee, Han Bao, Junya Honda, Issei\n  Sato, Masashi Sugiyama", "title": "Unsupervised Domain Adaptation Based on Source-guided Discrepancy", "comments": "To appear in AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation is the problem setting where data generating\ndistributions in the source and target domains are different, and labels in the\ntarget domain are unavailable. One important question in unsupervised domain\nadaptation is how to measure the difference between the source and target\ndomains. A previously proposed discrepancy that does not use the source domain\nlabels requires high computational cost to estimate and may lead to a loose\ngeneralization error bound in the target domain. To mitigate these problems, we\npropose a novel discrepancy called source-guided discrepancy (S-disc), which\nexploits labels in the source domain. As a consequence, S-disc can be computed\nefficiently with a finite sample convergence guarantee. In addition, we show\nthat S-disc can provide a tighter generalization error bound than the one based\non an existing discrepancy. Finally, we report experimental results that\ndemonstrate the advantages of S-disc over the existing discrepancies.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 13:11:30 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 11:36:35 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 09:54:32 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Kuroki", "Seiichi", ""], ["Charoenphakdee", "Nontawat", ""], ["Bao", "Han", ""], ["Honda", "Junya", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1809.03851", "submitter": "Pieter Van Molle", "authors": "Pieter Van Molle, Miguel De Strooper, Tim Verbelen, Bert\n  Vankeirsbilck, Pieter Simoens, Bart Dhoedt", "title": "Visualizing Convolutional Neural Networks to Improve Decision Support\n  for Skin Lesion Classification", "comments": "8 pages, 6 figures, Workshop on Interpretability of Machine\n  Intelligence in Medical Image Computing at MICCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of their state-of-the-art performance in computer vision, CNNs are\nbecoming increasingly popular in a variety of fields, including medicine.\nHowever, as neural networks are black box function approximators, it is\ndifficult, if not impossible, for a medical expert to reason about their\noutput. This could potentially result in the expert distrusting the network\nwhen he or she does not agree with its output. In such a case, explaining why\nthe CNN makes a certain decision becomes valuable information. In this paper,\nwe try to open the black box of the CNN by inspecting and visualizing the\nlearned feature maps, in the field of dermatology. We show that, to some\nextent, CNNs focus on features similar to those used by dermatologists to make\na diagnosis. However, more research is required for fully explaining their\noutput.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 13:17:38 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Van Molle", "Pieter", ""], ["De Strooper", "Miguel", ""], ["Verbelen", "Tim", ""], ["Vankeirsbilck", "Bert", ""], ["Simoens", "Pieter", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1809.03864", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Alexander Amini, Mathias Lechner, Felix Naser, Radu\n  Grosu, Daniela Rus", "title": "Response Characterization for Auditing Cell Dynamics in Long Short-term\n  Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel method to interpret recurrent neural\nnetworks (RNNs), particularly long short-term memory networks (LSTMs) at the\ncellular level. We propose a systematic pipeline for interpreting individual\nhidden state dynamics within the network using response characterization\nmethods. The ranked contribution of individual cells to the network's output is\ncomputed by analyzing a set of interpretable metrics of their decoupled step\nand sinusoidal responses. As a result, our method is able to uniquely identify\nneurons with insightful dynamics, quantify relationships between dynamical\nproperties and test accuracy through ablation analysis, and interpret the\nimpact of network capacity on a network's dynamical distribution. Finally, we\ndemonstrate generalizability and scalability of our method by evaluating a\nseries of different benchmark sequential datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 13:27:36 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Amini", "Alexander", ""], ["Lechner", "Mathias", ""], ["Naser", "Felix", ""], ["Grosu", "Radu", ""], ["Rus", "Daniela", ""]]}, {"id": "1809.03868", "submitter": "Hao Zhang", "authors": "Hao Zhang, Stephen Zahorian, Xiao Chen, Peter Guzewich, Xiaoyu Liu", "title": "Dual-label Deep LSTM Dereverberation For Speaker Verification", "comments": "4 pages, 3 figures, submitted to Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a reverberation removal approach for speaker\nverification, utilizing dual-label deep neural networks (DNNs). The networks\nperform feature mapping between the spectral features of reverberant and clean\nspeech. Long short term memory recurrent neural networks (LSTMs) are trained to\nmap corrupted Mel filterbank (MFB) features to two sets of labels: i) the clean\nMFB features, and ii) either estimated pitch tracks or the fast Fourier\ntransform (FFT) spectrogram of clean speech. The performance of reverberation\nremoval is evaluated by equal error rates (EERs) of speaker verification\nexperiments.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 04:55:24 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Zhang", "Hao", ""], ["Zahorian", "Stephen", ""], ["Chen", "Xiao", ""], ["Guzewich", "Peter", ""], ["Liu", "Xiaoyu", ""]]}, {"id": "1809.03964", "submitter": "Hao Wang", "authors": "Hao Wang, Bojin Zhuang and Yang Chen, Ni Li, Dongxia Wei", "title": "Deep Inferential Spatial-Temporal Network for Forecasting Air Pollution\n  Concentrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air pollution poses a serious threat to human health as well as economic\ndevelopment around the world. To meet the increasing demand for accurate\npredictions for air pollutions, we proposed a Deep Inferential Spatial-Temporal\nNetwork to deal with the complicated non-linear spatial and temporal\ncorrelations. We forecast three air pollutants (i.e., PM2.5, PM10 and O3) of\nmonitoring stations over the next 48 hours, using a hybrid deep learning model\nconsists of inferential predictor (inference for regions without air pollution\nreadings), spatial predictor (capturing spatial correlations using CNN) and\ntemporal predictor (capturing temporal relationship using sequence-to-sequence\nmodel with simplified attention mechanism). Our proposed model considers\nhistorical air pollution records and historical meteorological data. We\nevaluate our model on a large-scale dataset containing air pollution records of\n35 monitoring stations and grid meteorological data in Beijing, China. Our\nmodel outperforms other state-of-art methods in terms of SMAPE and RMSE.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 15:15:04 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Wang", "Hao", ""], ["Zhuang", "Bojin", ""], ["Chen", "Yang", ""], ["Li", "Ni", ""], ["Wei", "Dongxia", ""]]}, {"id": "1809.03986", "submitter": "Emmanouil Zampetakis", "authors": "Constantinos Daskalakis and Themis Gouleakis and Christos Tzamos and\n  Manolis Zampetakis", "title": "Efficient Statistics, in High Dimensions, from Truncated Samples", "comments": "Appeared at 59th Annual IEEE Symposium on Foundations of Computer\n  Science (FOCS), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an efficient algorithm for the classical problem, going back to\nGalton, Pearson, and Fisher, of estimating, with arbitrary accuracy the\nparameters of a multivariate normal distribution from truncated samples.\nTruncated samples from a $d$-variate normal ${\\cal\nN}(\\mathbf{\\mu},\\mathbf{\\Sigma})$ means a samples is only revealed if it falls\nin some subset $S \\subseteq \\mathbb{R}^d$; otherwise the samples are hidden and\ntheir count in proportion to the revealed samples is also hidden. We show that\nthe mean $\\mathbf{\\mu}$ and covariance matrix $\\mathbf{\\Sigma}$ can be\nestimated with arbitrary accuracy in polynomial-time, as long as we have oracle\naccess to $S$, and $S$ has non-trivial measure under the unknown $d$-variate\nnormal distribution. Additionally we show that without oracle access to $S$,\nany non-trivial estimation is impossible.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 15:42:43 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 18:39:09 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Gouleakis", "Themis", ""], ["Tzamos", "Christos", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "1809.04019", "submitter": "Emilia Apostolova PhD", "authors": "Emilia Apostolova and R. Andrew Kreek", "title": "Training and Prediction Data Discrepancies: Challenges of Text\n  Classification with Noisy, Historical Data", "comments": "2018 The 4th Workshop on Noisy User-generated Text (W-NUT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry datasets used for text classification are rarely created for that\npurpose. In most cases, the data and target predictions are a by-product of\naccumulated historical data, typically fraught with noise, present in both the\ntext-based document, as well as in the targeted labels. In this work, we\naddress the question of how well performance metrics computed on noisy,\nhistorical data reflect the performance on the intended future machine learning\nmodel input. The results demonstrate the utility of dirty training datasets\nused to build prediction models for cleaner (and different) prediction inputs.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 16:43:52 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Apostolova", "Emilia", ""], ["Kreek", "R. Andrew", ""]]}, {"id": "1809.04059", "submitter": "Vaibhav Rastogi", "authors": "Jinman Zhao, Aws Albarghouthi, Vaibhav Rastogi, Somesh Jha, Damien\n  Octeau", "title": "Neural-Augmented Static Analysis of Android Communication", "comments": "Appears in Proceedings of the 2018 ACM Joint European Software\n  Engineering Conference and Symposium on the Foundations of Software\n  Engineering (ESEC/FSE)", "journal-ref": null, "doi": "10.1145/3236024.3236066", "report-no": null, "categories": "cs.PL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of discovering communication links between\napplications in the popular Android mobile operating system, an important\nproblem for security and privacy in Android. Any scalable static analysis in\nthis complex setting is bound to produce an excessive amount of\nfalse-positives, rendering it impractical. To improve precision, we propose to\naugment static analysis with a trained neural-network model that estimates the\nprobability that a communication link truly exists. We describe a\nneural-network architecture that encodes abstractions of communicating objects\nin two applications and estimates the probability with which a link indeed\nexists. At the heart of our architecture are type-directed encoders (TDE), a\ngeneral framework for elegantly constructing encoders of a compound data type\nby recursively composing encoders for its constituent types. We evaluate our\napproach on a large corpus of Android applications, and demonstrate that it\nachieves very high accuracy. Further, we conduct thorough interpretability\nstudies to understand the internals of the learned neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 17:50:47 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Zhao", "Jinman", ""], ["Albarghouthi", "Aws", ""], ["Rastogi", "Vaibhav", ""], ["Jha", "Somesh", ""], ["Octeau", "Damien", ""]]}, {"id": "1809.04067", "submitter": "Minjia Zhang", "authors": "Minjia Zhang, Yuxiong He", "title": "Zoom: SSD-based Vector Search for Optimizing Accuracy, Latency and\n  Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of machine learning and deep learning, vector search\nbecomes instrumental to many information retrieval systems, to search and find\nbest matches to user queries based on their semantic similarities.These online\nservices require the search architecture to be both effective with high\naccuracy and efficient with low latency and memory footprint, which existing\nwork fails to offer. We develop, Zoom, a new vector search solution that\ncollaboratively optimizes accuracy, latency and memory based on a multiview\napproach. (1) A \"preview\" step generates a small set of good candidates,\nleveraging compressed vectors in memory for reduced footprint and fast lookup.\n(2) A \"fullview\" step on SSDs reranks those candidates with their full-length\nvector, striking high accuracy. Our evaluation shows that, Zoom achieves an\norder of magnitude improvements on efficiency while attaining equal or higher\naccuracy, comparing with the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 23:46:33 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Zhang", "Minjia", ""], ["He", "Yuxiong", ""]]}, {"id": "1809.04069", "submitter": "Ruobing Wang", "authors": "Zhiyuan Ma, Ping Wang, Zehui Gao, Ruobing Wang, Koroush Khalighi", "title": "Estimate the Warfarin Dose by Ensemble of Machine Learning Algorithms", "comments": "other authors do not agree to submit to arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Warfarin dosing remains challenging due to narrow therapeutic index and\nhighly individual variability. Incorrect warfarin dosing is associated with\ndevastating adverse events. Remarkable efforts have been made to develop the\nmachine learning based warfarin dosing algorithms incorporating clinical\nfactors and genetic variants such as polymorphisms in CYP2C9 and VKORC1. The\nmost widely validated pharmacogenetic algorithm is the IWPC algorithm based on\nmultivariate linear regression (MLR). However, with only a single algorithm,\nthe prediction performance may reach an upper limit even with optimal\nparameters. Here, we present novel algorithms using stacked generalization\nframeworks to estimate the warfarin dose, within which different types of\nmachine learning algorithms function together through a meta-machine learning\nmodel to maximize the prediction accuracy. Compared to the IWPC-derived MLR\nalgorithm, Stack 1 and 2 based on stacked generalization frameworks performed\nsignificantly better overall. Subgroup analysis revealed that the mean of the\npercentage of patients whose predicted dose of warfarin within 20% of the\nactual stable therapeutic dose (mean percentage within 20%) for Stack 1 was\nimproved by 12.7% (from 42.47% to 47.86%) in Asians and by 13.5% (from 22.08%\nto 25.05%) in the low-dose group compared to that for MLR, respectively. These\ndata suggest that our algorithms would especially benefit patients required low\nwarfarin maintenance dose, as subtle changes in warfarin dose could lead to\nadverse clinical events (thrombosis or bleeding) in patients with low dose. Our\nstudy offers novel pharmacogenetic algorithms for clinical trials and practice.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 22:18:37 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 14:36:49 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Ma", "Zhiyuan", ""], ["Wang", "Ping", ""], ["Gao", "Zehui", ""], ["Wang", "Ruobing", ""], ["Khalighi", "Koroush", ""]]}, {"id": "1809.04091", "submitter": "Pooya Ronagh", "authors": "Behrooz Sepehry, Ehsan Iranmanesh, Michael P. Friedlander and Pooya\n  Ronagh", "title": "Quantum Algorithms for Structured Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC math.OC quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two quantum algorithms for solving structured prediction\nproblems. We first show that a stochastic gradient descent that uses the\nquantum minimum finding algorithm and takes its probabilistic failure into\naccount solves the structured prediction problem with a runtime that scales\nwith the square root of the size of the label space, and in $\\widetilde\nO\\left(1/\\epsilon\\right)$ with respect to the precision, $\\epsilon$, of the\nsolution. Motivated by robust inference techniques in machine learning, we then\nintroduce another quantum algorithm that solves a smooth approximation of the\nstructured prediction problem with a similar quantum speedup in the size of the\nlabel space and a similar scaling in the precision parameter. In doing so, we\nanalyze a variant of stochastic gradient descent for convex optimization in the\npresence of an additive error in the calculation of the gradients, and show\nthat its convergence rate does not deteriorate if the additive errors are of\nthe order $O(\\sqrt\\epsilon)$. This algorithm uses quantum Gibbs sampling at\ntemperature $\\Omega (\\epsilon)$ as a subroutine. Based on these theoretical\nobservations, we propose a method for using quantum Gibbs samplers to combine\nfeedforward neural networks with probabilistic graphical models for quantum\nmachine learning. Our numerical results using Monte Carlo simulations on an\nimage tagging task demonstrate the benefit of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 18:04:11 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 18:00:21 GMT"}, {"version": "v3", "created": "Tue, 8 Jan 2019 19:13:05 GMT"}, {"version": "v4", "created": "Thu, 28 Feb 2019 00:45:51 GMT"}, {"version": "v5", "created": "Thu, 1 Jul 2021 20:43:29 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Sepehry", "Behrooz", ""], ["Iranmanesh", "Ehsan", ""], ["Friedlander", "Michael P.", ""], ["Ronagh", "Pooya", ""]]}, {"id": "1809.04110", "submitter": "Lichao Sun", "authors": "Lichao Sun, Lifang He, Zhipeng Huang, Bokai Cao, Congying Xia, Xiaokai\n  Wei and Philip S. Yu", "title": "Joint Embedding of Meta-Path and Meta-Graph for Heterogeneous\n  Information Networks", "comments": "accepted by ICBK 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-graph is currently the most powerful tool for similarity search on\nheterogeneous information networks,where a meta-graph is a composition of\nmeta-paths that captures the complex structural information. However, current\nrelevance computing based on meta-graph only considers the complex structural\ninformation, but ignores its embedded meta-paths information. To address this\nproblem, we proposeMEta-GrAph-based network embedding models, called MEGA and\nMEGA++, respectively. The MEGA model uses normalized relevance or similarity\nmeasures that are derived from a meta-graph and its embedded meta-paths between\nnodes simultaneously, and then leverages tensor decomposition method to perform\nnode embedding. The MEGA++ further facilitates the use of coupled tensor-matrix\ndecomposition method to obtain a joint embedding for nodes, which\nsimultaneously considers the hidden relations of all meta information of a\nmeta-graph.Extensive experiments on two real datasets demonstrate thatMEGA and\nMEGA++ are more effective than state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 19:03:31 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Sun", "Lichao", ""], ["He", "Lifang", ""], ["Huang", "Zhipeng", ""], ["Cao", "Bokai", ""], ["Xia", "Congying", ""], ["Wei", "Xiaokai", ""], ["Yu", "Philip S.", ""]]}, {"id": "1809.04120", "submitter": "Chaz Firestone", "authors": "Zhenglong Zhou, Chaz Firestone", "title": "Humans can decipher adversarial images", "comments": "14 pages, 4 figures", "journal-ref": "Nature Communications, 10, 1334 (2019)", "doi": "10.1038/s41467-019-08931-6", "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How similar is the human mind to the sophisticated machine-learning systems\nthat mirror its performance? Models of object categorization based on\nconvolutional neural networks (CNNs) have achieved human-level benchmarks in\nassigning known labels to novel images. These advances promise to support\ntransformative technologies such as autonomous vehicles and machine diagnosis;\nbeyond this, they also serve as candidate models for the visual system itself\n-- not only in their output but perhaps even in their underlying mechanisms and\nprinciples. However, unlike human vision, CNNs can be \"fooled\" by adversarial\nexamples -- carefully crafted images that appear as nonsense patterns to humans\nbut are recognized as familiar objects by machines, or that appear as one\nobject to humans and a different object to machines. This seemingly extreme\ndivergence between human and machine classification challenges the promise of\nthese new advances, both as applied image-recognition systems and also as\nmodels of the human mind. Surprisingly, however, little work has empirically\ninvestigated human classification of such adversarial stimuli: Does human and\nmachine performance fundamentally diverge? Or could humans decipher such images\nand predict the machine's preferred labels? Here, we show that human and\nmachine classification of adversarial stimuli are robustly related: In eight\nexperiments on five prominent and diverse adversarial imagesets, human subjects\nreliably identified the machine's chosen label over relevant foils. This\npattern persisted for images with strong antecedent identities, and even for\nimages described as \"totally unrecognizable to human eyes\". We suggest that\nhuman intuition may be a more reliable guide to machine (mis)classification\nthan has typically been imagined, and we explore the consequences of this\nresult for minds and machines alike.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 19:39:51 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 06:47:54 GMT"}, {"version": "v3", "created": "Sun, 3 Mar 2019 18:37:06 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Zhou", "Zhenglong", ""], ["Firestone", "Chaz", ""]]}, {"id": "1809.04121", "submitter": "Cameron Hoerig", "authors": "Cameron Hoerig, Jamshid Ghaboussi, and Michael F. Insana", "title": "Cartesian Neural Network Constitutive Models for Data-driven Elasticity\n  Imaging", "comments": "22 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elasticity images map biomechanical properties of soft tissues to aid in the\ndetection and diagnosis of pathological states. In particular, quasi-static\nultrasonic (US) elastography techniques use force-displacement measurements\nacquired during an US scan to parameterize the spatio-temporal stress-strain\nbehavior. Current methods use a model-based inverse approach to estimate the\nparameters associated with a chosen constitutive model. However, model-based\nmethods rely on simplifying assumptions of tissue biomechanical properties,\noften limiting elastography to imaging one or two linear-elastic parameters.\n  We previously described a data-driven method for building neural network\nconstitutive models (NNCMs) that learn stress-strain relationships from\nforce-displacement data. Using measurements acquired on gelatin phantoms, we\ndemonstrated the ability of NNCMs to characterize linear-elastic mechanical\nproperties without an initial model assumption and thus circumvent the\nmathematical constraints typically encountered in classic model-based\napproaches to the inverse problem. While successful, we were required to use a\npriori knowledge of the internal object shape to define the spatial\ndistribution of regions exhibiting different material properties.\n  Here, we introduce Cartesian neural network constitutive models (CaNNCMs)\nthat are capable of using data to model both linear-elastic mechanical\nproperties and their distribution in space. We demonstrate the ability of\nCaNNCMs to capture arbitrary material property distributions using\nstress-strain data from simulated phantoms. Furthermore, we show that a trained\nCaNNCM can be used to reconstruct a Young's modulus image. CaNNCMs are an\nimportant step toward data-driven modeling and imaging the complex mechanical\nproperties of soft tissues.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 19:41:30 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Hoerig", "Cameron", ""], ["Ghaboussi", "Jamshid", ""], ["Insana", "Michael F.", ""]]}, {"id": "1809.04127", "submitter": "Minghong Fang", "authors": "Minghong Fang, Guolei Yang, Neil Zhenqiang Gong, Jia Liu", "title": "Poisoning Attacks to Graph-Based Recommender Systems", "comments": "34th Annual Computer Security Applications Conference (ACSAC), 2018;\n  Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract appearing here is slightly shorter than that in the\n  PDF file", "journal-ref": null, "doi": "10.1145/3274694.3274706", "report-no": null, "categories": "cs.IR cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender system is an important component of many web services to help\nusers locate items that match their interests. Several studies showed that\nrecommender systems are vulnerable to poisoning attacks, in which an attacker\ninjects fake data to a given system such that the system makes recommendations\nas the attacker desires. However, these poisoning attacks are either agnostic\nto recommendation algorithms or optimized to recommender systems that are not\ngraph-based. Like association-rule-based and matrix-factorization-based\nrecommender systems, graph-based recommender system is also deployed in\npractice, e.g., eBay, Huawei App Store. However, how to design optimized\npoisoning attacks for graph-based recommender systems is still an open problem.\nIn this work, we perform a systematic study on poisoning attacks to graph-based\nrecommender systems. Due to limited resources and to avoid detection, we assume\nthe number of fake users that can be injected into the system is bounded. The\nkey challenge is how to assign rating scores to the fake users such that the\ntarget item is recommended to as many normal users as possible. To address the\nchallenge, we formulate the poisoning attacks as an optimization problem,\nsolving which determines the rating scores for the fake users. We also propose\ntechniques to solve the optimization problem. We evaluate our attacks and\ncompare them with existing attacks under white-box (recommendation algorithm\nand its parameters are known), gray-box (recommendation algorithm is known but\nits parameters are unknown), and black-box (recommendation algorithm is\nunknown) settings using two real-world datasets. Our results show that our\nattack is effective and outperforms existing attacks for graph-based\nrecommender systems. For instance, when 1% fake users are injected, our attack\ncan make a target item recommended to 580 times more normal users in certain\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 19:50:41 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Fang", "Minghong", ""], ["Yang", "Guolei", ""], ["Gong", "Neil Zhenqiang", ""], ["Liu", "Jia", ""]]}, {"id": "1809.04157", "submitter": "Xu Zhang", "authors": "Xu Zhang, Felix Xinnan Yu, Svebor Karaman, Wei Zhang, Shih-Fu Chang", "title": "Heated-Up Softmax Embedding", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric learning aims at learning a distance which is consistent with the\nsemantic meaning of the samples. The problem is generally solved by learning an\nembedding for each sample such that the embeddings of samples of the same\ncategory are compact while the embeddings of samples of different categories\nare spread-out in the feature space. We study the features extracted from the\nsecond last layer of a deep neural network based classifier trained with the\ncross entropy loss on top of the softmax layer. We show that training\nclassifiers with different temperature values of softmax function leads to\nfeatures with different levels of compactness. Leveraging these insights, we\npropose a \"heating-up\" strategy to train a classifier with increasing\ntemperatures, leading the corresponding embeddings to achieve state-of-the-art\nperformance on a variety of metric learning benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 20:56:02 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Zhang", "Xu", ""], ["Yu", "Felix Xinnan", ""], ["Karaman", "Svebor", ""], ["Zhang", "Wei", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1809.04176", "submitter": "Seyedehsara Nayer", "authors": "Seyedehsara Nayer and Namrata Vaswani", "title": "Phaseless Subspace Tracking", "comments": "To be appeared in GlobalSIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work takes the first steps towards solving the \"phaseless subspace\ntracking\" (PST) problem. PST involves recovering a time sequence of signals (or\nimages) from phaseless linear projections of each signal under the following\nstructural assumption: the signal sequence is generated from a much lower\ndimensional subspace (than the signal dimension) and this subspace can change\nover time, albeit gradually. It can be simply understood as a dynamic\n(time-varying subspace) extension of the low-rank phase retrieval problem\nstudied in recent work.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 21:30:56 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Nayer", "Seyedehsara", ""], ["Vaswani", "Namrata", ""]]}, {"id": "1809.04184", "submitter": "Liang-Chieh Chen", "authors": "Liang-Chieh Chen, Maxwell D. Collins, Yukun Zhu, George Papandreou,\n  Barret Zoph, Florian Schroff, Hartwig Adam, Jonathon Shlens", "title": "Searching for Efficient Multi-Scale Architectures for Dense Image\n  Prediction", "comments": "Accepted by NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of neural network architectures is an important component for\nachieving state-of-the-art performance with machine learning systems across a\nbroad array of tasks. Much work has endeavored to design and build\narchitectures automatically through clever construction of a search space\npaired with simple learning algorithms. Recent progress has demonstrated that\nsuch meta-learning methods may exceed scalable human-invented architectures on\nimage classification tasks. An open question is the degree to which such\nmethods may generalize to new domains. In this work we explore the construction\nof meta-learning techniques for dense image prediction focused on the tasks of\nscene parsing, person-part segmentation, and semantic image segmentation.\nConstructing viable search spaces in this domain is challenging because of the\nmulti-scale representation of visual information and the necessity to operate\non high resolution imagery. Based on a survey of techniques in dense image\nprediction, we construct a recursive search space and demonstrate that even\nwith efficient random search, we can identify architectures that outperform\nhuman-invented architectures and achieve state-of-the-art performance on three\ndense prediction tasks including 82.7\\% on Cityscapes (street scene parsing),\n71.3\\% on PASCAL-Person-Part (person-part segmentation), and 87.9\\% on PASCAL\nVOC 2012 (semantic image segmentation). Additionally, the resulting\narchitecture is more computationally efficient, requiring half the parameters\nand half the computational cost as previous state of the art systems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 22:36:01 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Chen", "Liang-Chieh", ""], ["Collins", "Maxwell D.", ""], ["Zhu", "Yukun", ""], ["Papandreou", "George", ""], ["Zoph", "Barret", ""], ["Schroff", "Florian", ""], ["Adam", "Hartwig", ""], ["Shlens", "Jonathon", ""]]}, {"id": "1809.04188", "submitter": "Jianguo Zhang", "authors": "Jianguo Zhang and Ji Wang and Lifang He and Zhao Li and Philip S. Yu", "title": "Layerwise Perturbation-Based Adversarial Training for Hard Drive Health\n  Degree Prediction", "comments": "The 2018 IEEE International Conference on Data Mining (ICDM'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of cloud computing and big data, the reliability of data\nstorage systems becomes increasingly important. Previous researchers have shown\nthat machine learning algorithms based on SMART attributes are effective\nmethods to predict hard drive failures. In this paper, we use SMART attributes\nto predict hard drive health degrees which are helpful for taking different\nfault tolerant actions in advance. Given the highly imbalanced SMART datasets,\nit is a nontrivial work to predict the health degree precisely. The proposed\nmodel would encounter overfitting and biased fitting problems if it is trained\nby the traditional methods. In order to resolve this problem, we propose two\nstrategies to better utilize imbalanced data and improve performance. Firstly,\nwe design a layerwise perturbation-based adversarial training method which can\nadd perturbations to any layers of a neural network to improve the\ngeneralization of the network. Secondly, we extend the training method to the\nsemi-supervised settings. Then, it is possible to utilize unlabeled data that\nhave a potential of failure to further improve the performance of the model.\nOur extensive experiments on two real-world hard drive datasets demonstrate the\nsuperiority of the proposed schemes for both supervised and semi-supervised\nclassification. The model trained by the proposed method can correctly predict\nthe hard drive health status 5 and 15 days in advance. Finally, we verify the\ngenerality of the proposed training method in other similar anomaly detection\ntasks where the dataset is imbalanced. The results argue that the proposed\nmethods are applicable to other domains.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 22:43:19 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 02:31:51 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 01:41:21 GMT"}, {"version": "v4", "created": "Fri, 28 Sep 2018 20:00:03 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zhang", "Jianguo", ""], ["Wang", "Ji", ""], ["He", "Lifang", ""], ["Li", "Zhao", ""], ["Yu", "Philip S.", ""]]}, {"id": "1809.04197", "submitter": "Pablo Moreno-Mu\\~noz", "authors": "Pablo Moreno-Mu\\~noz, David Ram\\'irez and Antonio Art\\'es-Rodr\\'iguez", "title": "Change-Point Detection on Hierarchical Circadian Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the problem of change-point detection on sequences of\nhigh-dimensional and heterogeneous observations, which also possess a periodic\ntemporal structure. Due to the dimensionality problem, when the time between\nchange-points is on the order of the dimension of the model parameters, drifts\nin the underlying distribution can be misidentified as changes. To overcome\nthis limitation, we assume that the observations lie in a lower-dimensional\nmanifold that admits a latent variable representation. In particular, we\npropose a hierarchical model that is computationally feasible, widely\napplicable to heterogeneous data and robust to missing instances. Additionally,\nthe observations' periodic dependencies are captured by non-stationary periodic\ncovariance functions. The proposed technique is particularly fitted to (and\nmotivated by) the problem of detecting changes in human behavior using\nsmartphones and its application to relapse detection in psychiatric patients.\nFinally, we validate the technique on synthetic examples and we demonstrate its\nutility in the detection of behavioral changes using real data acquired by\nsmartphones.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 23:36:31 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 14:12:48 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Moreno-Mu\u00f1oz", "Pablo", ""], ["Ram\u00edrez", "David", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""]]}, {"id": "1809.04198", "submitter": "Heinrich Jiang", "authors": "Andrew Cotter, Heinrich Jiang, Serena Wang, Taman Narayan, Maya Gupta,\n  Seungil You, Karthik Sridharan", "title": "Optimization with Non-Differentiable Constraints with Applications to\n  Fairness, Recall, Churn, and Other Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that many machine learning goals, such as improved fairness metrics,\ncan be expressed as constraints on the model's predictions, which we call rate\nconstraints. We study the problem of training non-convex models subject to\nthese rate constraints (or any non-convex and non-differentiable constraints).\nIn the non-convex setting, the standard approach of Lagrange multipliers may\nfail. Furthermore, if the constraints are non-differentiable, then one cannot\noptimize the Lagrangian with gradient-based methods. To solve these issues, we\nintroduce the proxy-Lagrangian formulation. This new formulation leads to an\nalgorithm that produces a stochastic classifier by playing a two-player\nnon-zero-sum game solving for what we call a semi-coarse correlated\nequilibrium, which in turn corresponds to an approximately optimal and feasible\nsolution to the constrained optimization problem. We then give a procedure\nwhich shrinks the randomized solution down to one that is a mixture of at most\n$m+1$ deterministic solutions, given $m$ constraints. This culminates in\nalgorithms that can solve non-convex constrained optimization problems with\npossibly non-differentiable and non-convex constraints with theoretical\nguarantees. We provide extensive experimental results enforcing a wide range of\npolicy goals including different fairness metrics, and other goals on accuracy,\ncoverage, recall, and churn.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 23:41:47 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Cotter", "Andrew", ""], ["Jiang", "Heinrich", ""], ["Wang", "Serena", ""], ["Narayan", "Taman", ""], ["Gupta", "Maya", ""], ["You", "Seungil", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1809.04206", "submitter": "Fan-Keng Sun", "authors": "Shun-Yao Shih, Fan-Keng Sun, Hung-yi Lee", "title": "Temporal Pattern Attention for Multivariate Time Series Forecasting", "comments": "Journal track of ECML/PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting multivariate time series data, such as prediction of electricity\nconsumption, solar power production, and polyphonic piano pieces, has numerous\nvaluable applications. However, complex and non-linear interdependencies\nbetween time steps and series complicate the task. To obtain accurate\nprediction, it is crucial to model long-term dependency in time series data,\nwhich can be achieved to some good extent by recurrent neural network (RNN)\nwith attention mechanism. Typical attention mechanism reviews the information\nat each previous time step and selects the relevant information to help\ngenerate the outputs, but it fails to capture the temporal patterns across\nmultiple time steps. In this paper, we propose to use a set of filters to\nextract time-invariant temporal patterns, which is similar to transforming time\nseries data into its \"frequency domain\". Then we proposed a novel attention\nmechanism to select relevant time series, and use its \"frequency domain\"\ninformation for forecasting. We applied the proposed model on several\nreal-world tasks and achieved state-of-the-art performance in all of them with\nonly one exception.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 00:40:40 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 06:09:10 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 23:17:57 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Shih", "Shun-Yao", ""], ["Sun", "Fan-Keng", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1809.04208", "submitter": "Seong-Eun Moon", "authors": "Seong-Eun Moon, Soobeom Jang, Jong-Seok Lee", "title": "Convolutional Neural Network Approach for EEG-based Emotion Recognition\n  using Brain Connectivity and its Spatial Information", "comments": "Accepted for the 2018 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition based on electroencephalography (EEG) has received\nattention as a way to implement human-centric services. However, there is still\nmuch room for improvement, particularly in terms of the recognition accuracy.\nIn this paper, we propose a novel deep learning approach using convolutional\nneural networks (CNNs) for EEG-based emotion recognition. In particular, we\nemploy brain connectivity features that have not been used with deep learning\nmodels in previous studies, which can account for synchronous activations of\ndifferent brain regions. In addition, we develop a method to effectively\ncapture asymmetric brain activity patterns that are important for emotion\nrecognition. Experimental results confirm the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 00:56:32 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Moon", "Seong-Eun", ""], ["Jang", "Soobeom", ""], ["Lee", "Jong-Seok", ""]]}, {"id": "1809.04214", "submitter": "Shun-Yao Shih", "authors": "Shun-Yao Shih, Heng-Yu Chi", "title": "Automatic, Personalized, and Flexible Playlist Generation using\n  Reinforcement Learning", "comments": "7 pages, 4 figures, ISMIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Songs can be well arranged by professional music curators to form a riveting\nplaylist that creates engaging listening experiences. However, it is\ntime-consuming for curators to timely rearrange these playlists for fitting\ntrends in future. By exploiting the techniques of deep learning and\nreinforcement learning, in this paper, we consider music playlist generation as\na language modeling problem and solve it by the proposed attention language\nmodel with policy gradient. We develop a systematic and interactive approach so\nthat the resulting playlists can be tuned flexibly according to user\npreferences. Considering a playlist as a sequence of words, we first train our\nattention RNN language model on baseline recommended playlists. By optimizing\nsuitable imposed reward functions, the model is thus refined for corresponding\npreferences. The experimental results demonstrate that our approach not only\ngenerates coherent playlists automatically but is also able to flexibly\nrecommend personalized playlists for diversity, novelty and freshness.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 01:32:11 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Shih", "Shun-Yao", ""], ["Chi", "Heng-Yu", ""]]}, {"id": "1809.04229", "submitter": "Soobeom Jang", "authors": "Soobeom Jang, Seong-Eun Moon and Jong-Seok Lee", "title": "EEG-based video identification using graph signal modeling and graph\n  convolutional neural network", "comments": "Accepted and presented at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel graph signal-based deep learning method for\nelectroencephalography (EEG) and its application to EEG-based video\nidentification. We present new methods to effectively represent EEG data as\nsignals on graphs, and learn them using graph convolutional neural networks.\nExperimental results for video identification using EEG responses obtained\nwhile watching videos show the effectiveness of the proposed approach in\ncomparison to existing methods. Effective schemes for graph signal\nrepresentation of EEG are also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 02:30:59 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Jang", "Soobeom", ""], ["Moon", "Seong-Eun", ""], ["Lee", "Jong-Seok", ""]]}, {"id": "1809.04259", "submitter": "Jinman Zhao", "authors": "Jinman Zhao, Sidharth Mudgal, Yingyu Liang", "title": "Generalizing Word Embeddings using Bag of Subwords", "comments": "Accepted to EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach the problem of generalizing pre-trained word embeddings beyond\nfixed-size vocabularies without using additional contextual information. We\npropose a subword-level word vector generation model that views words as bags\nof character $n$-grams. The model is simple, fast to train and provides good\nvectors for rare or unseen words. Experiments show that our model achieves\nstate-of-the-art performances in English word similarity task and in joint\nprediction of part-of-speech tag and morphosyntactic attributes in 23\nlanguages, suggesting our model's ability in capturing the relationship between\nwords' textual representations and their embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 05:15:32 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Zhao", "Jinman", ""], ["Mudgal", "Sidharth", ""], ["Liang", "Yingyu", ""]]}, {"id": "1809.04262", "submitter": "Samiulla Shaikh", "authors": "Rashmi Nagpal, Chetna Wadhwa, Mallika Gupta, Samiulla Shaikh, Sameep\n  Mehta, Vikram Goyal", "title": "Extracting Fairness Policies from Legal Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning community is recently exploring the implications of bias and\nfairness with respect to the AI applications. The definition of fairness for\nsuch applications varies based on their domain of application. The policies\ngoverning the use of such machine learning system in a given context are\ndefined by the constitutional laws of nations and regulatory policies enforced\nby the organizations that are involved in the usage. Fairness related laws and\npolicies are often spread across the large documents like constitution,\nagreements, and organizational regulations. These legal documents have long\ncomplex sentences in order to achieve rigorousness and robustness. Automatic\nextraction of fairness policies, or in general, any specific kind of policies\nfrom large legal corpus can be very useful for the study of bias and fairness\nin the context of AI applications.\n  We attempted to automatically extract fairness policies from publicly\navailable law documents using two approaches based on semantic relatedness. The\nexperiments reveal how classical Wordnet-based similarity and vector-based\nsimilarity differ in addressing this task. We have shown that similarity based\non word vectors beats the classical approach with a large margin, whereas other\nvector representations of senses and sentences fail to even match the classical\nbaseline. Further, we have presented thorough error analysis and reasoning to\nexplain the results with appropriate examples from the dataset for deeper\ninsights.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 05:44:23 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Nagpal", "Rashmi", ""], ["Wadhwa", "Chetna", ""], ["Gupta", "Mallika", ""], ["Shaikh", "Samiulla", ""], ["Mehta", "Sameep", ""], ["Goyal", "Vikram", ""]]}, {"id": "1809.04270", "submitter": "Stratos Idreos", "authors": "Abdul Wasay, Brian Hentschel, Yuze Liao, Sanyuan Chen, Stratos Idreos", "title": "MotherNets: Rapid Deep Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of deep neural networks significantly improve generalization\naccuracy. However, training neural network ensembles requires a large amount of\ncomputational resources and time. State-of-the-art approaches either train all\nnetworks from scratch leading to prohibitive training cost that allows only\nvery small ensemble sizes in practice, or generate ensembles by training a\nmonolithic architecture, which results in lower model diversity and decreased\nprediction accuracy. We propose MotherNets to enable higher accuracy and\npractical training cost for large and diverse neural network ensembles: A\nMotherNet captures the structural similarity across some or all members of a\ndeep neural network ensemble which allows us to share data movement and\ncomputation costs across these networks. We first train a single or a small set\nof MotherNets and, subsequently, we generate the target ensemble networks by\ntransferring the function from the trained MotherNet(s). Then, we continue to\ntrain these ensemble networks, which now converge drastically faster compared\nto training from scratch. MotherNets handle ensembles with diverse\narchitectures by clustering ensemble networks of similar architecture and\ntraining a separate MotherNet for every cluster. MotherNets also use clustering\nto control the accuracy vs. training cost tradeoff. We show that compared to\nstate-of-the-art approaches such as Snapshot Ensembles, Knowledge Distillation,\nand TreeNets, MotherNets provide a new Pareto frontier for the\naccuracy-training cost tradeoff. Crucially, training cost and accuracy\nimprovements continue to scale as we increase the ensemble size (2 to 3 percent\nreduced absolute test error rate and up to 35 percent faster training compared\nto Snapshot Ensembles). We verify these benefits over numerous neural network\narchitectures and large data sets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 06:36:31 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 02:53:18 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Wasay", "Abdul", ""], ["Hentschel", "Brian", ""], ["Liao", "Yuze", ""], ["Chen", "Sanyuan", ""], ["Idreos", "Stratos", ""]]}, {"id": "1809.04279", "submitter": "Trefor Evans", "authors": "Trefor W. Evans, Prasanth B. Nair", "title": "Discretely Relaxing Continuous Variables for tractable Variational\n  Inference", "comments": "Appears in the proceedings of the Advances in Neural Information\n  Processing Systems (NeurIPS), 2018. Full code is available at\n  https://github.com/treforevans/direct", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a new research direction in Bayesian variational inference with\ndiscrete latent variable priors where we exploit Kronecker matrix algebra for\nefficient and exact computations of the evidence lower bound (ELBO). The\nproposed \"DIRECT\" approach has several advantages over its predecessors; (i) it\ncan exactly compute ELBO gradients (i.e. unbiased, zero-variance gradient\nestimates), eliminating the need for high-variance stochastic gradient\nestimators and enabling the use of quasi-Newton optimization methods; (ii) its\ntraining complexity is independent of the number of training points, permitting\ninference on large datasets; and (iii) its posterior samples consist of sparse\nand low-precision quantized integers which permit fast inference on hardware\nlimited devices. In addition, our DIRECT models can exactly compute statistical\nmoments of the parameterized predictive posterior without relying on Monte\nCarlo sampling. The DIRECT approach is not practical for all likelihoods,\nhowever, we identify a popular model structure which is practical, and\ndemonstrate accurate inference using latent variables discretized as extremely\nlow-precision 4-bit quantized integers. While the ELBO computations considered\nin the numerical studies require over $10^{2352}$ log-likelihood evaluations,\nwe train on datasets with over two-million points in just seconds.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 07:05:30 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 20:06:10 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2019 22:29:41 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Evans", "Trefor W.", ""], ["Nair", "Prasanth B.", ""]]}, {"id": "1809.04281", "submitter": "Cheng-Zhi Anna Huang", "authors": "Cheng-Zhi Anna Huang, Ashish Vaswani, Jakob Uszkoreit, Noam Shazeer,\n  Ian Simon, Curtis Hawthorne, Andrew M. Dai, Matthew D. Hoffman, Monica\n  Dinculescu, Douglas Eck", "title": "Music Transformer", "comments": "Improved skewing section and accompanying figures. Previous titles\n  are \"An Improved Relative Self-Attention Mechanism for Transformer with\n  Application to Music Generation\" and \"Music Transformer\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music relies heavily on repetition to build structure and meaning.\nSelf-reference occurs on multiple timescales, from motifs to phrases to reusing\nof entire sections of music, such as in pieces with ABA structure. The\nTransformer (Vaswani et al., 2017), a sequence model based on self-attention,\nhas achieved compelling results in many generation tasks that require\nmaintaining long-range coherence. This suggests that self-attention might also\nbe well-suited to modeling music. In musical composition and performance,\nhowever, relative timing is critically important. Existing approaches for\nrepresenting relative positional information in the Transformer modulate\nattention based on pairwise distance (Shaw et al., 2018). This is impractical\nfor long sequences such as musical compositions since their memory complexity\nfor intermediate relative information is quadratic in the sequence length. We\npropose an algorithm that reduces their intermediate memory requirement to\nlinear in the sequence length. This enables us to demonstrate that a\nTransformer with our modified relative attention mechanism can generate\nminute-long compositions (thousands of steps, four times the length modeled in\nOore et al., 2018) with compelling structure, generate continuations that\ncoherently elaborate on a given motif, and in a seq2seq setup generate\naccompaniments conditioned on melodies. We evaluate the Transformer with our\nrelative attention mechanism on two datasets, JSB Chorales and\nPiano-e-Competition, and obtain state-of-the-art results on the latter.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 07:15:26 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 20:23:04 GMT"}, {"version": "v3", "created": "Wed, 12 Dec 2018 07:42:08 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Huang", "Cheng-Zhi Anna", ""], ["Vaswani", "Ashish", ""], ["Uszkoreit", "Jakob", ""], ["Shazeer", "Noam", ""], ["Simon", "Ian", ""], ["Hawthorne", "Curtis", ""], ["Dai", "Andrew M.", ""], ["Hoffman", "Matthew D.", ""], ["Dinculescu", "Monica", ""], ["Eck", "Douglas", ""]]}, {"id": "1809.04283", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth, Manik Bhandari, Prateek Yadav, Piyush Rai,\n  Chiranjib Bhattacharyya, Partha Talukdar", "title": "Incorporating Syntactic and Semantic Information in Word Embeddings\n  using Graph Convolutional Networks", "comments": "11 pages, 2 figures", "journal-ref": "57th Annual Meeting of the Association for Computational\n  Linguistics (ACL 2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have been widely adopted across several NLP applications.\nMost existing word embedding methods utilize sequential context of a word to\nlearn its embedding. While there have been some attempts at utilizing syntactic\ncontext of a word, such methods result in an explosion of the vocabulary size.\nIn this paper, we overcome this problem by proposing SynGCN, a flexible Graph\nConvolution based method for learning word embeddings. SynGCN utilizes the\ndependency context of a word without increasing the vocabulary size. Word\nembeddings learned by SynGCN outperform existing methods on various intrinsic\nand extrinsic tasks and provide an advantage when used with ELMo. We also\npropose SemGCN, an effective framework for incorporating diverse semantic\nknowledge for further enhancing learned word representations. We make the\nsource code of both models available to encourage reproducible research.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 07:31:06 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 12:10:15 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 21:54:13 GMT"}, {"version": "v4", "created": "Sat, 20 Jul 2019 13:14:37 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Bhandari", "Manik", ""], ["Yadav", "Prateek", ""], ["Rai", "Piyush", ""], ["Bhattacharyya", "Chiranjib", ""], ["Talukdar", "Partha", ""]]}, {"id": "1809.04288", "submitter": "Thao Le", "authors": "Thao Minh Le, Nobuyuki Shimizu, Takashi Miyazaki, Koichi Shinoda", "title": "Deep Learning Based Multi-modal Addressee Recognition in Visual Scenes\n  with Utterances", "comments": "Proceedings of the Twenty-Seventh International Joint Conference on\n  Artificial Intelligence Main track. Pages 1546-1553", "journal-ref": null, "doi": "10.24963/ijcai.2018/214", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of intelligent systems, such as smart speakers,\naddressee recognition has become a concern in human-computer interaction, as\nmore and more people expect such systems to understand complicated social\nscenes, including those outdoors, in cafeterias, and hospitals. Because\nprevious studies typically focused only on pre-specified tasks with limited\nconversational situations such as controlling smart homes, we created a mock\ndataset called Addressee Recognition in Visual Scenes with Utterances (ARVSU)\nthat contains a vast body of image variations in visual scenes with an\nannotated utterance and a corresponding addressee for each scenario. We also\npropose a multi-modal deep-learning-based model that takes different human\ncues, specifically eye gazes and transcripts of an utterance corpus, into\naccount to predict the conversational addressee from a specific speaker's view\nin various real-life conversational scenarios. To the best of our knowledge, we\nare the first to introduce an end-to-end deep learning model that combines\nvision and transcripts of utterance for addressee recognition. As a result, our\nstudy suggests that future addressee recognition can reach the ability to\nunderstand human intention in many social situations previously unexplored, and\nour modality dataset is a first step in promoting research in this field.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 07:43:23 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Le", "Thao Minh", ""], ["Shimizu", "Nobuyuki", ""], ["Miyazaki", "Takashi", ""], ["Shinoda", "Koichi", ""]]}, {"id": "1809.04294", "submitter": "Dominik Linzner", "authors": "Dominik Linzner and Heinz Koeppl", "title": "Cluster Variational Approximations for Structure Learning of\n  Continuous-Time Bayesian Networks from Incomplete Data", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous-time Bayesian networks (CTBNs) constitute a general and powerful\nframework for modeling continuous-time stochastic processes on networks. This\nmakes them particularly attractive for learning the directed structures among\ninteracting entities. However, if the available data is incomplete, one needs\nto simulate the prohibitively complex CTBN dynamics. Existing approximation\ntechniques, such as sampling and low-order variational methods, either scale\nunfavorably in system size, or are unsatisfactory in terms of accuracy.\nInspired by recent advances in statistical physics, we present a new\napproximation scheme based on cluster-variational methods significantly\nimproving upon existing variational approximations. We can analytically\nmarginalize the parameters of the approximate CTBN, as these are of secondary\nimportance for structure learning. This recovers a scalable scheme for direct\nstructure learning from incomplete and noisy time-series data. Our approach\noutperforms existing methods in terms of scalability.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 07:56:01 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 14:36:35 GMT"}, {"version": "v3", "created": "Mon, 17 Sep 2018 09:02:36 GMT"}, {"version": "v4", "created": "Fri, 12 Oct 2018 14:44:36 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Linzner", "Dominik", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1809.04322", "submitter": "Weihao Yuan", "authors": "Weihao Yuan, Kaiyu Hang, Haoran Song, Danica Kragic, Michael Y. Wang\n  and Johannes A. Stork", "title": "Reinforcement Learning in Topology-based Representation for Human Body\n  Movement with Whole Arm Manipulation", "comments": "Submitted to RA-L with ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moving a human body or a large and bulky object can require the strength of\nwhole arm manipulation (WAM). This type of manipulation places the load on the\nrobot's arms and relies on global properties of the interaction to\nsucceed---rather than local contacts such as grasping or non-prehensile\npushing. In this paper, we learn to generate motions that enable WAM for\nholding and transporting of humans in certain rescue or patient care scenarios.\nWe model the task as a reinforcement learning problem in order to provide a\nbehavior that can directly respond to external perturbation and human motion.\nFor this, we represent global properties of the robot-human interaction with\ntopology-based coordinates that are computed from arm and torso positions.\nThese coordinates also allow transferring the learned policy to other body\nshapes and sizes. For training and evaluation, we simulate a dynamic sea rescue\nscenario and show in quantitative experiments that the policy can solve unseen\nscenarios with differently-shaped humans, floating humans, or with perception\nnoise. Our qualitative experiments show the subsequent transporting after\nholding is achieved and we demonstrate that the policy can be directly\ntransferred to a real world setting.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 09:17:48 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Yuan", "Weihao", ""], ["Hang", "Kaiyu", ""], ["Song", "Haoran", ""], ["Kragic", "Danica", ""], ["Wang", "Michael Y.", ""], ["Stork", "Johannes A.", ""]]}, {"id": "1809.04332", "submitter": "Stefan Thaler", "authors": "Stefan Thaler, Vlado Menkovski, Milan Petkovic", "title": "Deep Learning in Information Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has a long tradition of helping to solve complex information\nsecurity problems that are difficult to solve manually. Machine learning\ntechniques learn models from data representations to solve a task. These data\nrepresentations are hand-crafted by domain experts. Deep Learning is a\nsub-field of machine learning, which uses models that are composed of multiple\nlayers. Consequently, representations that are used to solve a task are learned\nfrom the data instead of being manually designed.\n  In this survey, we study the use of DL techniques within the domain of\ninformation security. We systematically reviewed 77 papers and presented them\nfrom a data-centric perspective. This data-centric perspective reflects one of\nthe most crucial advantages of DL techniques -- domain independence. If\nDL-methods succeed to solve problems on a data type in one domain, they most\nlikely will also succeed on similar data from another domain. Other advantages\nof DL methods are unrivaled scalability and efficiency, both regarding the\nnumber of examples that can be analyzed as well as with respect of\ndimensionality of the input data. DL methods generally are capable of achieving\nhigh-performance and generalize well.\n  However, information security is a domain with unique requirements and\nchallenges. Based on an analysis of our reviewed papers, we point out\nshortcomings of DL-methods to those requirements and discuss further research\nopportunities.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 09:38:47 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Thaler", "Stefan", ""], ["Menkovski", "Vlado", ""], ["Petkovic", "Milan", ""]]}, {"id": "1809.04356", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Deep learning for time series classification: a review", "comments": "Accepted at Data Mining and Knowledge Discovery", "journal-ref": null, "doi": "10.1007/s10618-019-00619-1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time Series Classification (TSC) is an important and challenging problem in\ndata mining. With the increase of time series data availability, hundreds of\nTSC algorithms have been proposed. Among these methods, only a few have\nconsidered Deep Neural Networks (DNNs) to perform this task. This is surprising\nas deep learning has seen very successful applications in the last years. DNNs\nhave indeed revolutionized the field of computer vision especially with the\nadvent of novel deeper architectures such as Residual and Convolutional Neural\nNetworks. Apart from images, sequential data such as text and audio can also be\nprocessed with DNNs to reach state-of-the-art performance for document\nclassification and speech recognition. In this article, we study the current\nstate-of-the-art performance of deep learning algorithms for TSC by presenting\nan empirical study of the most recent DNN architectures for TSC. We give an\noverview of the most successful deep learning applications in various time\nseries domains under a unified taxonomy of DNNs for TSC. We also provide an\nopen source deep learning framework to the TSC community where we implemented\neach of the compared approaches and evaluated them on a univariate TSC\nbenchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By\ntraining 8,730 deep learning models on 97 time series datasets, we propose the\nmost exhaustive study of DNNs for TSC to date.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 10:55:33 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 17:49:17 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 08:14:31 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 14:41:18 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1809.04359", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias, Stefanos Zafeiriou", "title": "Training Deep Neural Networks with Different Datasets In-the-wild: The\n  Emotion Recognition Paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel procedure is presented in this paper, for training a deep\nconvolutional and recurrent neural network, taking into account both the\navailable training data set and some information extracted from similar\nnetworks trained with other relevant data sets. This information is included in\nan extended loss function used for the network training, so that the network\ncan have an improved performance when applied to the other data sets, without\nforgetting the learned knowledge from the original data set. Facial expression\nand emotion recognition in-the-wild is the test bed application that is used to\ndemonstrate the improved performance achieved using the proposed approach. In\nthis framework, we provide an experimental study on categorical emotion\nrecognition using datasets from a very recent related emotion recognition\nchallenge.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 11:16:31 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1809.04365", "submitter": "Ali Abrishami", "authors": "Ali Abrishami, Sadegh Aliakbary", "title": "Predicting citation counts based on deep neural network learning\n  techniques", "comments": null, "journal-ref": "Journal of Informetrics Volume 13, Issue 2, May 2019, Pages\n  485-499", "doi": "10.1016/j.joi.2019.02.011", "report-no": null, "categories": "cs.DL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing number of published scientific papers world-wide, the need\nto evaluation and quality assessment methods for research papers is increasing.\nScientific fields such as scientometrics, informetrics and bibliometrics\nestablish quantified analysis methods and measurements for scientific papers.\nIn this area, an important problem is to predict the future influence of a\npublished paper. Particularly, early discrimination between influential papers\nand insignificant papers may find important applications. In this regard, one\nof the most important metrics is the number of citations to the paper, since\nthis metric is widely utilized in the evaluation of scientific publications and\nmoreover, it serves as the basis for many other metrics such as h-index. In\nthis paper, we propose a novel method for predicting long-term citations of a\npaper based on the number of its citations in the first few years after\npublication. In order to train a citations prediction model, we employed\nartificial neural networks which is a powerful machine learning tool with\nrecently growing applications in many domains including image and text\nprocessing. The empirical experiments show that our proposed method\nout-performs state-of-the-art methods with respect to the prediction accuracy\nin both yearly and total prediction of the number of citations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 11:41:05 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 07:56:22 GMT"}, {"version": "v3", "created": "Sat, 16 Mar 2019 09:14:06 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Abrishami", "Ali", ""], ["Aliakbary", "Sadegh", ""]]}, {"id": "1809.04379", "submitter": "Yin Cheng Ng", "authors": "Yin Cheng Ng, Nicolo Colombo, Ricardo Silva", "title": "Bayesian Semi-supervised Learning with Graph Gaussian Processes", "comments": "To appear in NIPS 2018 Fixed an error in Figure 2. The previous arxiv\n  version contains two identical sub-figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-efficient Gaussian process-based Bayesian approach to the\nsemi-supervised learning problem on graphs. The proposed model shows extremely\ncompetitive performance when compared to the state-of-the-art graph neural\nnetworks on semi-supervised learning benchmark experiments, and outperforms the\nneural networks in active learning experiments where labels are scarce.\nFurthermore, the model does not require a validation data set for early\nstopping to control over-fitting. Our model can be viewed as an instance of\nempirical distribution regression weighted locally by network connectivity. We\nfurther motivate the intuitive construction of the model with a Bayesian linear\nmodel interpretation where the node features are filtered by an operator\nrelated to the graph Laplacian. The method can be easily implemented by\nadapting off-the-shelf scalable variational inference algorithms for Gaussian\nprocesses.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 12:26:00 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 15:30:20 GMT"}, {"version": "v3", "created": "Fri, 12 Oct 2018 15:30:26 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Ng", "Yin Cheng", ""], ["Colombo", "Nicolo", ""], ["Silva", "Ricardo", ""]]}, {"id": "1809.04397", "submitter": "Krishan Rajaratnam", "authors": "Krishan Rajaratnam and Kunal Shah and Jugal Kalita", "title": "Isolated and Ensemble Audio Preprocessing Methods for Detecting\n  Adversarial Examples against Automatic Speech Recognition", "comments": "Accepted for oral presentation at the 30th Conference on\n  Computational Linguistics and Speech Processing (ROCLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.CR cs.LG cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial attack is an exploitative process in which minute alterations\nare made to natural inputs, causing the inputs to be misclassified by neural\nmodels. In the field of speech recognition, this has become an issue of\nincreasing significance. Although adversarial attacks were originally\nintroduced in computer vision, they have since infiltrated the realm of speech\nrecognition. In 2017, a genetic attack was shown to be quite potent against the\nSpeech Commands Model. Limited-vocabulary speech classifiers, such as the\nSpeech Commands Model, are used in a variety of applications, particularly in\ntelephony; as such, adversarial examples produced by this attack pose as a\nmajor security threat. This paper explores various methods of detecting these\nadversarial examples with combinations of audio preprocessing. One particular\ncombined defense incorporating compressions, speech coding, filtering, and\naudio panning was shown to be quite effective against the attack on the Speech\nCommands Model, detecting audio adversarial examples with 93.5% precision and\n91.2% recall.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 05:12:15 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Rajaratnam", "Krishan", ""], ["Shah", "Kunal", ""], ["Kalita", "Jugal", ""]]}, {"id": "1809.04400", "submitter": "Martin Trapp", "authors": "Martin Trapp, Robert Peharz, Carl E. Rasmussen and Franz Pernkopf", "title": "Learning Deep Mixtures of Gaussian Process Experts Using Sum-Product\n  Networks", "comments": "Presented at the Workshop on Tractable Probabilistic Models (TPM\n  2018), ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Gaussian processes (GPs) are the method of choice for regression tasks,\nthey also come with practical difficulties, as inference cost scales cubic in\ntime and quadratic in memory. In this paper, we introduce a natural and\nexpressive way to tackle these problems, by incorporating GPs in sum-product\nnetworks (SPNs), a recently proposed tractable probabilistic model allowing\nexact and efficient inference. In particular, by using GPs as leaves of an SPN\nwe obtain a novel flexible prior over functions, which implicitly represents an\nexponentially large mixture of local GPs. Exact and efficient posterior\ninference in this model can be done in a natural interplay of the inference\nmechanisms in GPs and SPNs. Thereby, each GP is -- similarly as in a mixture of\nexperts approach -- responsible only for a subset of data points, which\neffectively reduces inference cost in a divide and conquer fashion. We show\nthat integrating GPs into the SPN framework leads to a promising probabilistic\nregression model which is: (1) computational and memory efficient, (2) allows\nefficient and exact posterior inference, (3) is flexible enough to mix\ndifferent kernel functions, and (4) naturally accounts for non-stationarities\nin time series. In a variate of experiments, we show that the SPN-GP model can\nlearn input dependent parameters and hyper-parameters and is on par with or\noutperforms the traditional GPs as well as state of the art approximations on\nreal-world data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 13:12:21 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Trapp", "Martin", ""], ["Peharz", "Robert", ""], ["Rasmussen", "Carl E.", ""], ["Pernkopf", "Franz", ""]]}, {"id": "1809.04403", "submitter": "Elizaveta Logacheva", "authors": "Pavel Ostyakov, Elizaveta Logacheva, Roman Suvorov, Vladimir Aliev,\n  Gleb Sterkin, Oleg Khomenko, and Sergey I. Nikolenko", "title": "Label Denoising with Large Ensembles of Heterogeneous Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in computer vision based on various convolutional\narchitectures, video understanding remains an important challenge. In this\nwork, we present and discuss a top solution for the large-scale video\nclassification (labeling) problem introduced as a Kaggle competition based on\nthe YouTube-8M dataset. We show and compare different approaches to\npreprocessing, data augmentation, model architectures, and model combination.\nOur final model is based on a large ensemble of video- and frame-level models\nbut fits into rather limiting hardware constraints. We apply an approach based\non knowledge distillation to deal with noisy labels in the original dataset and\nthe recently developed mixup technique to improve the basic models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 13:14:59 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 20:30:28 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Ostyakov", "Pavel", ""], ["Logacheva", "Elizaveta", ""], ["Suvorov", "Roman", ""], ["Aliev", "Vladimir", ""], ["Sterkin", "Gleb", ""], ["Khomenko", "Oleg", ""], ["Nikolenko", "Sergey I.", ""]]}, {"id": "1809.04423", "submitter": "Ramin M. Hasani", "authors": "Ramin Hasani, Mathias Lechner, Alexander Amini, Daniela Rus, Radu\n  Grosu", "title": "Can a Compact Neuronal Circuit Policy be Re-purposed to Learn Simple\n  Robotic Control?", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.08554", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural information processing system which is obtained by\nre-purposing the function of a biological neural circuit model, to govern\nsimulated and real-world control tasks. Inspired by the structure of the\nnervous system of the soil-worm, C. elegans, we introduce Neuronal Circuit\nPolicies (NCPs), defined as the model of biological neural circuits\nreparameterized for the control of an alternative task. We learn instances of\nNCPs to control a series of robotic tasks, including the autonomous parking of\na real-world rover robot. For reconfiguration of the purpose of the neural\ncircuit, we adopt a search-based optimization algorithm. Neuronal circuit\npolicies perform on par and in some cases surpass the performance of\ncontemporary deep learning models with the advantage leveraging significantly\nfewer learnable parameters and realizing interpretable dynamics at the\ncell-level.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 15:05:12 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 13:12:37 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Hasani", "Ramin", ""], ["Lechner", "Mathias", ""], ["Amini", "Alexander", ""], ["Rus", "Daniela", ""], ["Grosu", "Radu", ""]]}, {"id": "1809.04429", "submitter": "Muhammad Yousefnezhad", "authors": "Xiaoliang Sheng, Muhammad Yousefnezhad, Tonglin Xu, Ning Yuan,\n  Daoqiang Zhang", "title": "Gradient-based Representational Similarity Analysis with Searchlight for\n  Analyzing fMRI Data", "comments": "Conference: Chinese Conference on Pattern Recognition and Computer\n  Vision 2018 (PRCV18), 23-26/Nov, Guangzhou, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representational Similarity Analysis (RSA) aims to explore similarities\nbetween neural activities of different stimuli. Classical RSA techniques employ\nthe inverse of the covariance matrix to explore a linear model between the\nneural activities and task events. However, calculating the inverse of a\nlarge-scale covariance matrix is time-consuming and can reduce the stability\nand robustness of the final analysis. Notably, it becomes severe when the\nnumber of samples is too large. For facing this shortcoming, this paper\nproposes a novel RSA method called gradient-based RSA (GRSA). Moreover, the\nproposed method is not restricted to a linear model. In fact, there is a\ngrowing interest in finding more effective ways of using multi-subject and\nwhole-brain fMRI data. Searchlight technique can extend RSA from the localized\nbrain regions to the whole-brain regions with smaller memory footprint in each\nprocess. Based on Searchlight, we propose a new method called Spatiotemporal\nSearchlight GRSA (SSL-GRSA) that generalizes our ROI-based GRSA algorithm to\nthe whole-brain data. Further, our approach can handle some computational\nchallenges while dealing with large-scale, multi-subject fMRI data.\nExperimental studies on multi-subject datasets confirm that both proposed\napproaches achieve superior performance to other state-of-the-art RSA\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 13:40:59 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Sheng", "Xiaoliang", ""], ["Yousefnezhad", "Muhammad", ""], ["Xu", "Tonglin", ""], ["Yuan", "Ning", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1809.04430", "submitter": "Stanislav Nikolov", "authors": "Stanislav Nikolov, Sam Blackwell, Alexei Zverovitch, Ruheena Mendes,\n  Michelle Livne, Jeffrey De Fauw, Yojan Patel, Clemens Meyer, Harry Askham,\n  Bernardino Romera-Paredes, Christopher Kelly, Alan Karthikesalingam, Carlton\n  Chu, Dawn Carnell, Cheng Boon, Derek D'Souza, Syed Ali Moinuddin, Bethany\n  Garie, Yasmin McQuinlan, Sarah Ireland, Kiarna Hampton, Krystle Fuller, Hugh\n  Montgomery, Geraint Rees, Mustafa Suleyman, Trevor Back, C\\'ian Hughes,\n  Joseph R. Ledsam, Olaf Ronneberger", "title": "Deep learning to achieve clinically applicable segmentation of head and\n  neck anatomy for radiotherapy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over half a million individuals are diagnosed with head and neck cancer each\nyear worldwide. Radiotherapy is an important curative treatment for this\ndisease, but it requires manual time consuming delineation of radio-sensitive\norgans at risk (OARs). This planning process can delay treatment, while also\nintroducing inter-operator variability with resulting downstream radiation dose\ndifferences. While auto-segmentation algorithms offer a potentially time-saving\nsolution, the challenges in defining, quantifying and achieving expert\nperformance remain. Adopting a deep learning approach, we demonstrate a 3D\nU-Net architecture that achieves expert-level performance in delineating 21\ndistinct head and neck OARs commonly segmented in clinical practice. The model\nwas trained on a dataset of 663 deidentified computed tomography (CT) scans\nacquired in routine clinical practice and with both segmentations taken from\nclinical practice and segmentations created by experienced radiographers as\npart of this research, all in accordance with consensus OAR definitions. We\ndemonstrate the model's clinical applicability by assessing its performance on\na test set of 21 CT scans from clinical practice, each with the 21 OARs\nsegmented by two independent experts. We also introduce surface Dice similarity\ncoefficient (surface DSC), a new metric for the comparison of organ\ndelineation, to quantify deviation between OAR surface contours rather than\nvolumes, better reflecting the clinical task of correcting errors in the\nautomated organ segmentations. The model's generalisability is then\ndemonstrated on two distinct open source datasets, reflecting different centres\nand countries to model training. With appropriate validation studies and\nregulatory approvals, this system could improve the efficiency, consistency,\nand safety of radiotherapy pathways.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 13:42:38 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 11:09:59 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 17:43:14 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Nikolov", "Stanislav", ""], ["Blackwell", "Sam", ""], ["Zverovitch", "Alexei", ""], ["Mendes", "Ruheena", ""], ["Livne", "Michelle", ""], ["De Fauw", "Jeffrey", ""], ["Patel", "Yojan", ""], ["Meyer", "Clemens", ""], ["Askham", "Harry", ""], ["Romera-Paredes", "Bernardino", ""], ["Kelly", "Christopher", ""], ["Karthikesalingam", "Alan", ""], ["Chu", "Carlton", ""], ["Carnell", "Dawn", ""], ["Boon", "Cheng", ""], ["D'Souza", "Derek", ""], ["Moinuddin", "Syed Ali", ""], ["Garie", "Bethany", ""], ["McQuinlan", "Yasmin", ""], ["Ireland", "Sarah", ""], ["Hampton", "Kiarna", ""], ["Fuller", "Krystle", ""], ["Montgomery", "Hugh", ""], ["Rees", "Geraint", ""], ["Suleyman", "Mustafa", ""], ["Back", "Trevor", ""], ["Hughes", "C\u00edan", ""], ["Ledsam", "Joseph R.", ""], ["Ronneberger", "Olaf", ""]]}, {"id": "1809.04432", "submitter": "Isaac Karth", "authors": "Isaac Karth, Adam M. Smith", "title": "Addressing the Fundamental Tension of PCGML with Discriminative Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural content generation via machine learning (PCGML) is typically\nframed as the task of fitting a generative model to full-scale examples of a\ndesired content distribution. This approach presents a fundamental tension: the\nmore design effort expended to produce detailed training examples for shaping a\ngenerator, the lower the return on investment from applying PCGML in the first\nplace. In response, we propose the use of discriminative models (which capture\nthe validity of a design rather the distribution of the content) trained on\npositive and negative examples. Through a modest modification of\nWaveFunctionCollapse, a commercially-adopted PCG approach that we characterize\nas using elementary machine learning, we demonstrate a new mode of control for\nlearning-based generators. We demonstrate how an artist might craft a focused\nset of additional positive and negative examples by critique of the generator's\nprevious outputs. This interaction mode bridges PCGML with mixed-initiative\ndesign assistance tools by working with a machine to define a space of valid\ndesigns rather than just one new design.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 20:04:59 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Karth", "Isaac", ""], ["Smith", "Adam M.", ""]]}, {"id": "1809.04437", "submitter": "Suwon Shon", "authors": "Suwon Shon, Hao Tang, James Glass", "title": "Frame-level speaker embeddings for text-independent speaker recognition\n  and analysis of end-to-end model", "comments": "Accepted at SLT 2018; Supplement materials:\n  https://people.csail.mit.edu/swshon/supplement/slt18.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Convolutional Neural Network (CNN) based speaker\nrecognition model for extracting robust speaker embeddings. The embedding can\nbe extracted efficiently with linear activation in the embedding layer. To\nunderstand how the speaker recognition model operates with text-independent\ninput, we modify the structure to extract frame-level speaker embeddings from\neach hidden layer. We feed utterances from the TIMIT dataset to the trained\nnetwork and use several proxy tasks to study the networks ability to represent\nspeech input and differentiate voice identity. We found that the networks are\nbetter at discriminating broad phonetic classes than individual phonemes. In\nparticular, frame-level embeddings that belong to the same phonetic classes are\nsimilar (based on cosine distance) for the same speaker. The frame level\nrepresentation also allows us to analyze the networks at the frame level, and\nhas the potential for other analyses to improve speaker recognition.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 13:48:44 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Shon", "Suwon", ""], ["Tang", "Hao", ""], ["Glass", "James", ""]]}, {"id": "1809.04440", "submitter": "Yunsheng Bai", "authors": "Yunsheng Bai, Hao Ding, Yizhou Sun, Wei Wang", "title": "Learning-based Efficient Graph Similarity Computation via Multi-Scale\n  Convolutional Set Matching", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph similarity computation is one of the core operations in many\ngraph-based applications, such as graph similarity search, graph database\nanalysis, graph clustering, etc. Since computing the exact distance/similarity\nbetween two graphs is typically NP-hard, a series of approximate methods have\nbeen proposed with a trade-off between accuracy and speed. Recently, several\ndata-driven approaches based on neural networks have been proposed, most of\nwhich model the graph-graph similarity as the inner product of their\ngraph-level representations, with different techniques proposed for generating\none embedding per graph. However, using one fixed-dimensional embedding per\ngraph may fail to fully capture graphs in varying sizes and link structures, a\nlimitation that is especially problematic for the task of graph similarity\ncomputation, where the goal is to find the fine-grained difference between two\ngraphs. In this paper, we address the problem of graph similarity computation\nfrom another perspective, by directly matching two sets of node embeddings\nwithout the need to use fixed-dimensional vectors to represent whole graphs for\ntheir similarity computation. The model, GraphSim, achieves the\nstate-of-the-art performance on four real-world graph datasets under six out of\neight settings (here we count a specific dataset and metric combination as one\nsetting), compared to existing popular methods for approximate Graph Edit\nDistance (GED) and Maximum Common Subgraph (MCS) computation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 22:48:49 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 20:23:19 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Bai", "Yunsheng", ""], ["Ding", "Hao", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""]]}, {"id": "1809.04441", "submitter": "Zhuqing Liu", "authors": "Zhuqing Liu, Liyuanjun Lai, Lin Zhang", "title": "An empirical learning-based validation procedure for simulation workflow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation workflow is a top-level model for the design and control of\nsimulation process. It connects multiple simulation components with time and\ninteraction restrictions to form a complete simulation system. Before the\nconstruction and evaluation of the component models, the validation of\nupper-layer simulation workflow is of the most importance in a simulation\nsystem. However, the methods especially for validating simulation workflow is\nvery limit. Many of the existing validation techniques are domain-dependent\nwith cumbersome questionnaire design and expert scoring. Therefore, this paper\npresent an empirical learning-based validation procedure to implement a\nsemi-automated evaluation for simulation workflow. First, representative\nfeatures of general simulation workflow and their relations with validation\nindices are proposed. The calculation process of workflow credibility based on\nAnalytic Hierarchy Process (AHP) is then introduced. In order to make full use\nof the historical data and implement more efficient validation, four learning\nalgorithms, including back propagation neural network (BPNN), extreme learning\nmachine (ELM), evolving new-neuron (eNFN) and fast incremental gaussian mixture\nmodel (FIGMN), are introduced for constructing the empirical relation between\nthe workflow credibility and its features. A case study on a landing-process\nsimulation workflow is established to test the feasibility of the proposed\nprocedure. The experimental results also provide some useful overview of the\nstate-of-the-art learning algorithms on the credibility evaluation of\nsimulation models.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 00:48:04 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Liu", "Zhuqing", ""], ["Lai", "Liyuanjun", ""], ["Zhang", "Lin", ""]]}, {"id": "1809.04445", "submitter": "Vishnu Menon", "authors": "Vishnu Menon, Sheetal Kalyani", "title": "Structured and Unstructured Outlier Identification for Robust PCA: A Non\n  iterative, Parameter free Algorithm", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.04791", "journal-ref": null, "doi": "10.1109/TSP.2019.2905826", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust PCA, the problem of PCA in the presence of outliers has been\nextensively investigated in the last few years. Here we focus on Robust PCA in\nthe outlier model where each column of the data matrix is either an inlier or\nan outlier. Most of the existing methods for this model assumes either the\nknowledge of the dimension of the lower dimensional subspace or the fraction of\noutliers in the system. However in many applications knowledge of these\nparameters is not available. Motivated by this we propose a parameter free\noutlier identification method for robust PCA which a) does not require the\nknowledge of outlier fraction, b) does not require the knowledge of the\ndimension of the underlying subspace, c) is computationally simple and fast d)\ncan handle structured and unstructured outliers. Further, analytical guarantees\nare derived for outlier identification and the performance of the algorithm is\ncompared with the existing state of the art methods in both real and synthetic\ndata for various outlier structures.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 07:47:57 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Menon", "Vishnu", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1809.04458", "submitter": "Suwon Shon", "authors": "Suwon Shon, Wei-Ning Hsu, James Glass", "title": "Unsupervised Representation Learning of Speech for Dialect\n  Identification", "comments": "Accepted at SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the use of a factorized hierarchical variational\nautoencoder (FHVAE) model to learn an unsupervised latent representation for\ndialect identification (DID). An FHVAE can learn a latent space that separates\nthe more static attributes within an utterance from the more dynamic attributes\nby encoding them into two different sets of latent variables. Useful factors\nfor dialect identification, such as phonetic or linguistic content, are encoded\nby a segmental latent variable, while irrelevant factors that are relatively\nconstant within a sequence, such as a channel or a speaker information, are\nencoded by a sequential latent variable. The disentanglement property makes the\nsegmental latent variable less susceptible to channel and speaker variation,\nand thus reduces degradation from channel domain mismatch. We demonstrate that\non fully-supervised DID tasks, an end-to-end model trained on the features\nextracted from the FHVAE model achieves the best performance, compared to the\nsame model trained on conventional acoustic features and an i-vector based\nsystem. Moreover, we also show that the proposed approach can leverage a large\namount of unlabeled data for FHVAE training to learn domain-invariant features\nfor DID, and significantly improve the performance in a low-resource condition,\nwhere the labels for the in-domain data are not available.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 13:57:06 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Shon", "Suwon", ""], ["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1809.04461", "submitter": "Vinayakumar R", "authors": "Anu Vazhayil, Vinayakumar R and Soman KP", "title": "DeepProteomics: Protein family classification using Shallow and Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The knowledge regarding the function of proteins is necessary as it gives a\nclear picture of biological processes. Nevertheless, there are many protein\nsequences found and added to the databases but lacks functional annotation. The\nlaboratory experiments take a considerable amount of time for annotation of the\nsequences. This arises the need to use computational techniques to classify\nproteins based on their functions. In our work, we have collected the data from\nSwiss-Prot containing 40433 proteins which is grouped into 30 families. We pass\nit to recurrent neural network(RNN), long short term memory(LSTM) and gated\nrecurrent unit(GRU) model and compare it by applying trigram with deep neural\nnetwork and shallow neural network on the same dataset. Through this approach,\nwe could achieve maximum of around 78% accuracy for the classification of\nprotein families.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 17:48:01 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Vazhayil", "Anu", ""], ["R", "Vinayakumar", ""], ["KP", "Soman", ""]]}, {"id": "1809.04474", "submitter": "Matteo Hessel", "authors": "Matteo Hessel, Hubert Soyer, Lasse Espeholt, Wojciech Czarnecki, Simon\n  Schmitt, Hado van Hasselt", "title": "Multi-task Deep Reinforcement Learning with PopArt", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reinforcement learning community has made great strides in designing\nalgorithms capable of exceeding human performance on specific tasks. These\nalgorithms are mostly trained one task at the time, each new task requiring to\ntrain a brand new agent instance. This means the learning algorithm is general,\nbut each solution is not; each agent can only solve the one task it was trained\non. In this work, we study the problem of learning to master not one but\nmultiple sequential-decision tasks at once. A general issue in multi-task\nlearning is that a balance must be found between the needs of multiple tasks\ncompeting for the limited resources of a single learning system. Many learning\nalgorithms can get distracted by certain tasks in the set of tasks to solve.\nSuch tasks appear more salient to the learning process, for instance because of\nthe density or magnitude of the in-task rewards. This causes the algorithm to\nfocus on those salient tasks at the expense of generality. We propose to\nautomatically adapt the contribution of each task to the agent's updates, so\nthat all tasks have a similar impact on the learning dynamics. This resulted in\nstate of the art performance on learning to play all games in a set of 57\ndiverse Atari games. Excitingly, our method learned a single trained policy -\nwith a single set of weights - that exceeds median human performance. To our\nknowledge, this was the first time a single agent surpassed human-level\nperformance on this multi-task domain. The same approach also demonstrated\nstate of the art performance on a set of 30 tasks in the 3D reinforcement\nlearning platform DeepMind Lab.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 14:17:00 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Hessel", "Matteo", ""], ["Soyer", "Hubert", ""], ["Espeholt", "Lasse", ""], ["Czarnecki", "Wojciech", ""], ["Schmitt", "Simon", ""], ["van Hasselt", "Hado", ""]]}, {"id": "1809.04481", "submitter": "Yitong Sun", "authors": "Yitong Sun, Anna Gilbert, Ambuj Tewari", "title": "But How Does It Work in Theory? Linear SVM with Random Features", "comments": "Accepted by NeurIPS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that, under low noise assumptions, the support vector machine with\n$N\\ll m$ random features (RFSVM) can achieve the learning rate faster than\n$O(1/\\sqrt{m})$ on a training set with $m$ samples when an optimized feature\nmap is used. Our work extends the previous fast rate analysis of random\nfeatures method from least square loss to 0-1 loss. We also show that the\nreweighted feature selection method, which approximates the optimized feature\nmap, helps improve the performance of RFSVM in experiments on a synthetic data\nset.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 14:29:05 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 00:41:55 GMT"}, {"version": "v3", "created": "Tue, 8 Jan 2019 06:25:08 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Sun", "Yitong", ""], ["Gilbert", "Anna", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1809.04482", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Carl Doersch", "title": "The Visual QA Devil in the Details: The Impact of Early Fusion and Batch\n  Norm on CLEVR", "comments": "Presented at ECCV'18 Workshop on Shortcomings in Vision and Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual QA is a pivotal challenge for higher-level reasoning, requiring\nunderstanding language, vision, and relationships between many objects in a\nscene. Although datasets like CLEVR are designed to be unsolvable without such\ncomplex relational reasoning, some surprisingly simple feed-forward, \"holistic\"\nmodels have recently shown strong performance on this dataset. These models\nlack any kind of explicit iterative, symbolic reasoning procedure, which are\nhypothesized to be necessary for counting objects, narrowing down the set of\nrelevant objects based on several attributes, etc. The reason for this strong\nperformance is poorly understood. Hence, our work analyzes such models, and\nfinds that minor architectural elements are crucial to performance. In\nparticular, we find that \\textit{early fusion} of language and vision provides\nlarge performance improvements. This contrasts with the late fusion approaches\npopular at the dawn of Visual QA. We propose a simple module we call Multimodal\nCore, which we hypothesize performs the fundamental operations for multimodal\ntasks. We believe that understanding why these elements are so important to\ncomplex question answering will aid the design of better-performing algorithms\nfor Visual QA while minimizing hand-engineering effort.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 07:14:30 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Doersch", "Carl", ""]]}, {"id": "1809.04487", "submitter": "Jayesh Choudhari", "authors": "Srikanta Bedathur, Indrajit Bhattacharya, Jayesh Choudhari and Anirban\n  Dasgupta", "title": "Discovering Topical Interactions in Text-based Cascades using Hidden\n  Markov Hawkes Processes", "comments": "Accepted as a short paper at ICDM-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media conversations unfold based on complex interactions between\nusers, topics and time. While recent models have been proposed to capture\nnetwork strengths between users, users' topical preferences and temporal\npatterns between posting and response times, interaction patterns between\ntopics has not been studied. We propose the Hidden Markov Hawkes Process (HMHP)\nthat incorporates topical Markov Chains within Hawkes processes to jointly\nmodel topical interactions along with user-user and user-topic patterns. We\npropose a Gibbs sampling algorithm for HMHP that jointly infers the network\nstrengths, diffusion paths, the topics of the posts as well as the topic-topic\ninteractions. We show using experiments on real and semi-synthetic data that\nHMHP is able to generalize better and recover the network strengths, topics and\ndiffusion paths more accurately than state-of-the-art baselines. More\ninterestingly, HMHP finds insightful interactions between topics in real tweets\nwhich no existing model is able to do.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 14:36:27 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Bedathur", "Srikanta", ""], ["Bhattacharya", "Indrajit", ""], ["Choudhari", "Jayesh", ""], ["Dasgupta", "Anirban", ""]]}, {"id": "1809.04497", "submitter": "Abdul Fatir Ansari", "authors": "Abdul Fatir Ansari and Harold Soh", "title": "Hyperprior Induced Unsupervised Disentanglement of Latent\n  Representations", "comments": "AAAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of unsupervised disentanglement of latent\nrepresentations learnt via deep generative models. In contrast to current\napproaches that operate on the evidence lower bound (ELBO), we argue that\nstatistical independence in the latent space of VAEs can be enforced in a\nprincipled hierarchical Bayesian manner. To this effect, we augment the\nstandard VAE with an inverse-Wishart (IW) prior on the covariance matrix of the\nlatent code. By tuning the IW parameters, we are able to encourage (or\ndiscourage) independence in the learnt latent dimensions. Extensive\nexperimental results on a range of datasets (2DShapes, 3DChairs, 3DFaces and\nCelebA) show our approach to outperform the $\\beta$-VAE and is competitive with\nthe state-of-the-art FactorVAE. Our approach achieves significantly better\ndisentanglement and reconstruction on a new dataset (CorrelatedEllipses) which\nintroduces correlations between the factors of variation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 14:53:19 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 10:17:22 GMT"}, {"version": "v3", "created": "Sun, 6 Jan 2019 09:30:19 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Ansari", "Abdul Fatir", ""], ["Soh", "Harold", ""]]}, {"id": "1809.04506", "submitter": "Vincent Francois-Lavet", "authors": "Vincent Fran\\c{c}ois-Lavet, Yoshua Bengio, Doina Precup, Joelle Pineau", "title": "Combined Reinforcement Learning via Abstract Representations", "comments": "Accepted to the Thirty-Third AAAI Conference On Artificial\n  Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the quest for efficient and robust reinforcement learning methods, both\nmodel-free and model-based approaches offer advantages. In this paper we\npropose a new way of explicitly bridging both approaches via a shared\nlow-dimensional learned encoding of the environment, meant to capture\nsummarizing abstractions. We show that the modularity brought by this approach\nleads to good generalization while being computationally efficient, with\nplanning happening in a smaller latent state space. In addition, this approach\nrecovers a sufficient low-dimensional representation of the environment, which\nopens up new strategies for interpretable AI, exploration and transfer\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 15:12:49 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 23:47:15 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Fran\u00e7ois-Lavet", "Vincent", ""], ["Bengio", "Yoshua", ""], ["Precup", "Doina", ""], ["Pineau", "Joelle", ""]]}, {"id": "1809.04520", "submitter": "Sergey Rodionov", "authors": "Alexey Potapov, Sergey Rodionov", "title": "Genetic algorithms with DNN-based trainable crossover as an example of\n  partial specialization of general search", "comments": "AGI 2017 procedding, The final publication is available at\n  link.springer.com", "journal-ref": null, "doi": "10.1007/978-3-319-63703-7_10", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal induction relies on some general search procedure that is doomed to\nbe inefficient. One possibility to achieve both generality and efficiency is to\nspecialize this procedure w.r.t. any given narrow task. However, complete\nspecialization that implies direct mapping from the task parameters to\nsolutions (discriminative models) without search is not always possible. In\nthis paper, partial specialization of general search is considered in the form\nof genetic algorithms (GAs) with a specialized crossover operator. We perform a\nfeasibility study of this idea implementing such an operator in the form of a\ndeep feedforward neural network. GAs with trainable crossover operators are\ncompared with the result of complete specialization, which is also represented\nas a deep neural network. Experimental results show that specialized GAs can be\nmore efficient than both general GAs and discriminative models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 10:14:58 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Potapov", "Alexey", ""], ["Rodionov", "Sergey", ""]]}, {"id": "1809.04542", "submitter": "Shuang Liu", "authors": "Shuang Liu and Kamalika Chaudhuri", "title": "The Inductive Bias of Restricted f-GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks are a novel method for statistical inference\nthat have achieved much empirical success; however, the factors contributing to\nthis success remain ill-understood. In this work, we attempt to analyze\ngenerative adversarial learning -- that is, statistical inference as the result\nof a game between a generator and a discriminator -- with the view of\nunderstanding how it differs from classical statistical inference solutions\nsuch as maximum likelihood inference and the method of moments.\n  Specifically, we provide a theoretical characterization of the distribution\ninferred by a simple form of generative adversarial learning called restricted\nf-GANs -- where the discriminator is a function in a given function class, the\ndistribution induced by the generator is restricted to lie in a pre-specified\ndistribution class and the objective is similar to a variational form of the\nf-divergence. A consequence of our result is that for linear KL-GANs -- that\nis, when the discriminator is a linear function over some feature space and f\ncorresponds to the KL-divergence -- the distribution induced by the optimal\ngenerator is neither the maximum likelihood nor the method of moments solution,\nbut an interesting combination of both.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 16:19:49 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Liu", "Shuang", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1809.04547", "submitter": "Ole-Christoffer Granmo", "authors": "Geir Thore Berge, Ole-Christoffer Granmo, Tor Oddbj{\\o}rn Tveit,\n  Morten Goodwin, Lei Jiao, Bernt Viggo Matheussen", "title": "Using the Tsetlin Machine to Learn Human-Interpretable Rules for\n  High-Accuracy Text Categorization with Medical Applications", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical applications challenge today's text categorization techniques by\ndemanding both high accuracy and ease-of-interpretation. Although deep learning\nhas provided a leap ahead in accuracy, this leap comes at the sacrifice of\ninterpretability. To address this accuracy-interpretability challenge, we here\nintroduce, for the first time, a text categorization approach that leverages\nthe recently introduced Tsetlin Machine. In all brevity, we represent the terms\nof a text as propositional variables. From these, we capture categories using\nsimple propositional formulae, such as: if \"rash\" and \"reaction\" and\n\"penicillin\" then Allergy. The Tsetlin Machine learns these formulae from a\nlabelled text, utilizing conjunctive clauses to represent the particular facets\nof each category. Indeed, even the absence of terms (negated features) can be\nused for categorization purposes. Our empirical comparison with Na\\\"ive Bayes,\ndecision trees, linear support vector machines (SVMs), random forest, long\nshort-term memory (LSTM) neural networks, and other techniques, is quite\nconclusive. The Tsetlin Machine either performs on par with or outperforms all\nof the evaluated methods on both the 20 Newsgroups and IMDb datasets, as well\nas on a non-public clinical dataset. On average, the Tsetlin Machine delivers\nthe best recall and precision scores across the datasets. Finally, our GPU\nimplementation of the Tsetlin Machine executes 5 to 15 times faster than the\nCPU implementation, depending on the dataset. We thus believe that our novel\napproach can have a significant impact on a wide range of text analysis\napplications, forming a promising starting point for deeper natural language\nunderstanding with the Tsetlin Machine.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 16:34:44 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 21:59:17 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Berge", "Geir Thore", ""], ["Granmo", "Ole-Christoffer", ""], ["Tveit", "Tor Oddbj\u00f8rn", ""], ["Goodwin", "Morten", ""], ["Jiao", "Lei", ""], ["Matheussen", "Bernt Viggo", ""]]}, {"id": "1809.04556", "submitter": "Parag Jain", "authors": "Parag Jain, Abhijit Mishra, Amar Prakash Azad, Karthik\n  Sankaranarayanan", "title": "Unsupervised Controllable Text Formalization", "comments": "AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for controllable natural language\ntransformation. Realizing that the requirement of parallel corpus is\npractically unsustainable for controllable generation tasks, an unsupervised\ntraining scheme is introduced. The crux of the framework is a deep neural\nencoder-decoder that is reinforced with text-transformation knowledge through\nauxiliary modules (called scorers). The scorers, based on off-the-shelf\nlanguage processing tools, decide the learning scheme of the encoder-decoder\nbased on its actions. We apply this framework for the text-transformation task\nof formalizing an input text by improving its readability grade; the degree of\nrequired formalization can be controlled by the user at run-time. Experiments\non public datasets demonstrate the efficacy of our model towards: (a)\ntransforming a given text to a more formal style, and (b) introducing\nappropriate amount of formalness in the output text pertaining to the input\ncontrol. Our code and datasets are released for academic use.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 17:25:46 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 04:01:25 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 05:31:32 GMT"}, {"version": "v4", "created": "Tue, 20 Nov 2018 18:36:38 GMT"}, {"version": "v5", "created": "Sun, 3 Feb 2019 18:58:18 GMT"}, {"version": "v6", "created": "Wed, 20 Feb 2019 15:33:03 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Jain", "Parag", ""], ["Mishra", "Abhijit", ""], ["Azad", "Amar Prakash", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "1809.04558", "submitter": "Timo Korthals", "authors": "Timo Korthals, J\\\"urgen Leitner, Ulrich R\\\"uckert", "title": "Coordinated Heterogeneous Distributed Perception based on Latent Space\n  Representation", "comments": "IROS 2018 Second Workshop on Multi-robot Perception-Driven Control\n  and Planning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a reinforcement approach for distributed sensing based on the\nlatent space derived from multi-modal deep generative models. Our contribution\nprovides insights to the following benefits: Detections can be exchanged\neffectively between robots equipped with uni-modal sensors due to a shared\nlatent representation of information that is trained by a Variational Auto\nEncoder (VAE). Sensor-fusion can be applied asynchronously due to the\ngenerative feature of the VAE. Deep Q-Networks (DQNs) are trained to minimize\nuncertainty in latent space by coordinating robots to a Point-of-Interest (PoI)\nwhere their sensor modality can provide beneficial information about the PoI.\nAdditionally, we show that the decrease in uncertainty can be defined as the\ndirect reward signal for training the DQN.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 16:50:39 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Korthals", "Timo", ""], ["Leitner", "J\u00fcrgen", ""], ["R\u00fcckert", "Ulrich", ""]]}, {"id": "1809.04559", "submitter": "Andreea Anghel", "authors": "Andreea Anghel, Nikolaos Papandreou, Thomas Parnell, Alessandro De\n  Palma, Haralampos Pozidis", "title": "Benchmarking and Optimization of Gradient Boosting Decision Tree\n  Algorithms", "comments": "Workshop on Systems for ML and Open Source Software at NeurIPS 2018,\n  Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosting decision trees (GBDTs) have seen widespread adoption in\nacademia, industry and competitive data science due to their state-of-the-art\nperformance in many machine learning tasks. One relative downside to these\nmodels is the large number of hyper-parameters that they expose to the\nend-user. To maximize the predictive power of GBDT models, one must either\nmanually tune the hyper-parameters, or utilize automated techniques such as\nthose based on Bayesian optimization. Both of these approaches are\ntime-consuming since they involve repeatably training the model for different\nsets of hyper-parameters. A number of software GBDT packages have started to\noffer GPU acceleration which can help to alleviate this problem. In this paper,\nwe consider three such packages: XGBoost, LightGBM and Catboost. Firstly, we\nevaluate the performance of the GPU acceleration provided by these packages\nusing large-scale datasets with varying shapes, sparsities and learning tasks.\nThen, we compare the packages in the context of hyper-parameter optimization,\nboth in terms of how quickly each package converges to a good validation score,\nand in terms of generalization performance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 16:51:18 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 16:38:05 GMT"}, {"version": "v3", "created": "Thu, 17 Jan 2019 12:40:35 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Anghel", "Andreea", ""], ["Papandreou", "Nikolaos", ""], ["Parnell", "Thomas", ""], ["De Palma", "Alessandro", ""], ["Pozidis", "Haralampos", ""]]}, {"id": "1809.04564", "submitter": "Ali Ramezani-Kebrya", "authors": "Ali Ramezani-Kebrya, Ashish Khisti, Ben Liang", "title": "On the Stability and Convergence of Stochastic Gradient Descent with\n  Momentum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While momentum-based methods, in conjunction with the stochastic gradient\ndescent, are widely used when training machine learning models, there is little\ntheoretical understanding on the generalization error of such methods. In\npractice, the momentum parameter is often chosen in a heuristic fashion with\nlittle theoretical guidance. In the first part of this paper, for the case of\ngeneral loss functions, we analyze a modified momentum-based update rule, i.e.,\nthe method of early momentum, and develop an upper-bound on the generalization\nerror using the framework of algorithmic stability. Our results show that\nmachine learning models can be trained for multiple epochs of this method while\ntheir generalization errors are bounded. We also study the convergence of the\nmethod of early momentum by establishing an upper-bound on the expected norm of\nthe gradient. In the second part of the paper, we focus on the case of strongly\nconvex loss functions and the classical heavy-ball momentum update rule. We use\nthe framework of algorithmic stability to provide an upper-bound on the\ngeneralization error of the stochastic gradient method with momentum. We also\ndevelop an upper-bound on the expected true risk, in terms of the number of\ntraining steps, the size of the training set, and the momentum parameter.\nExperimental evaluations verify the consistency between the numerical results\nand our theoretical bounds and the effectiveness of the method of early\nmomentum for the case of non-convex loss functions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 17:02:08 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Ramezani-Kebrya", "Ali", ""], ["Khisti", "Ashish", ""], ["Liang", "Ben", ""]]}, {"id": "1809.04578", "submitter": "Jon Kleinberg", "authors": "Jon Kleinberg and Sendhil Mullainathan", "title": "Simplicity Creates Inequity: Implications for Fairness, Stereotypes, and\n  Interpretability", "comments": "Updated version incorporating additional results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DS cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms are increasingly used to aid, or in some cases supplant, human\ndecision-making, particularly for decisions that hinge on predictions. As a\nresult, two additional features in addition to prediction quality have\ngenerated interest: (i) to facilitate human interaction and understanding with\nthese algorithms, we desire prediction functions that are in some fashion\nsimple or interpretable; and (ii) because they influence consequential\ndecisions, we also want them to produce equitable allocations. We develop a\nformal model to explore the relationship between the demands of simplicity and\nequity. Although the two concepts appear to be motivated by qualitatively\ndistinct goals, we show a fundamental inconsistency between them. Specifically,\nwe formalize a general framework for producing simple prediction functions, and\nin this framework we establish two basic results. First, every simple\nprediction function is strictly improvable: there exists a more complex\nprediction function that is both strictly more efficient and also strictly more\nequitable. Put another way, using a simple prediction function both reduces\nutility for disadvantaged groups and reduces overall welfare relative to other\noptions. Second, we show that simple prediction functions necessarily create\nincentives to use information about individuals' membership in a disadvantaged\ngroup --- incentives that weren't present before simplification, and that work\nagainst these individuals. Thus, simplicity transforms disadvantage into bias\nagainst the disadvantaged group. Our results are not only about algorithms but\nabout any process that produces simple models, and as such they connect to the\npsychology of stereotypes and to an earlier economics literature on statistical\ndiscrimination.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 17:40:18 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 02:50:47 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Kleinberg", "Jon", ""], ["Mullainathan", "Sendhil", ""]]}, {"id": "1809.04618", "submitter": "Mert G\\\"urb\\\"uzbalaban", "authors": "Xuefeng Gao, Mert G\\\"urb\\\"uzbalaban, Lingjiong Zhu", "title": "Global Convergence of Stochastic Gradient Hamiltonian Monte Carlo for\n  Non-Convex Stochastic Optimization: Non-Asymptotic Performance Bounds and\n  Momentum-Based Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient Hamiltonian Monte Carlo (SGHMC) is a variant of\nstochastic gradient with momentum where a controlled and properly scaled\nGaussian noise is added to the stochastic gradients to steer the iterates\ntowards a global minimum. Many works reported its empirical success in practice\nfor solving stochastic non-convex optimization problems, in particular it has\nbeen observed to outperform overdamped Langevin Monte Carlo-based methods such\nas stochastic gradient Langevin dynamics (SGLD) in many applications. Although\nasymptotic global convergence properties of SGHMC are well known, its\nfinite-time performance is not well-understood. In this work, we study two\nvariants of SGHMC based on two alternative discretizations of the underdamped\nLangevin diffusion. We provide finite-time performance bounds for the global\nconvergence of both SGHMC variants for solving stochastic non-convex\noptimization problems with explicit constants. Our results lead to\nnon-asymptotic guarantees for both population and empirical risk minimization\nproblems. For a fixed target accuracy level, on a class of non-convex problems,\nwe obtain complexity bounds for SGHMC that can be tighter than those for SGLD.\nThese results show that acceleration with momentum is possible in the context\nof global non-convex optimization.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 18:08:15 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 00:38:48 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 15:44:21 GMT"}, {"version": "v4", "created": "Wed, 18 Nov 2020 01:46:53 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Gao", "Xuefeng", ""], ["G\u00fcrb\u00fczbalaban", "Mert", ""], ["Zhu", "Lingjiong", ""]]}, {"id": "1809.04621", "submitter": "Bruna Frade", "authors": "Bruna Vieira Frade and Erickson R. Nascimento", "title": "A Two-Step Learning Method For Detecting Landmarks on Faces From\n  Different Domains", "comments": "https://ieeexplore.ieee.org/document/8451026/", "journal-ref": null, "doi": "10.1109/ICIP.2018.8451026", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of fiducial points on faces has significantly been favored by\nthe rapid progress in the field of machine learning, in particular in the\nconvolution networks. However, the accuracy of most of the detectors strongly\ndepends on an enormous amount of annotated data. In this work, we present a\ndomain adaptation approach based on a two-step learning to detect fiducial\npoints on human and animal faces. We evaluate our method on three different\ndatasets composed of different animal faces (cats, dogs, and horses). The\nexperiments show that our method performs better than state of the art and can\nuse few annotated data to leverage the detection of landmarks reducing the\ndemand for large volume of annotated data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 18:14:12 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Frade", "Bruna Vieira", ""], ["Nascimento", "Erickson R.", ""]]}, {"id": "1809.04624", "submitter": "Walysson Vital Barbosa", "authors": "Walysson Vital Barbosa, Henrique Grandinetti Barbosa Amaral, Thiago\n  Lages Rocha, Erickson Rangel Nascimento", "title": "Visual-Quality-Driven Learning for Underwater Vision Enhancement", "comments": "Accepted for publication and presented in 2018 IEEE International\n  Conference on Image Processing (ICIP)", "journal-ref": null, "doi": "10.1109/ICIP.2018.8451356", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The image processing community has witnessed remarkable advances in enhancing\nand restoring images. Nevertheless, restoring the visual quality of underwater\nimages remains a great challenge. End-to-end frameworks might fail to enhance\nthe visual quality of underwater images since in several scenarios it is not\nfeasible to provide the ground truth of the scene radiance. In this work, we\npropose a CNN-based approach that does not require ground truth data since it\nuses a set of image quality metrics to guide the restoration learning process.\nThe experiments showed that our method improved the visual quality of\nunderwater images preserving their edges and also performed well considering\nthe UCIQE metric.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 18:22:38 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Barbosa", "Walysson Vital", ""], ["Amaral", "Henrique Grandinetti Barbosa", ""], ["Rocha", "Thiago Lages", ""], ["Nascimento", "Erickson Rangel", ""]]}, {"id": "1809.04632", "submitter": "Ali Hebbal", "authors": "Ali Hebbal, Loic Brevault, Mathieu Balesdent, El-Ghazali Talbi and\n  Nouredine Melab", "title": "Efficient Global Optimization using Deep Gaussian Processes", "comments": "12 pages, 11 Figures, 2 Tables, presented to the IEEE Congress on\n  Evolutionary Computation (IEEE CEC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Global Optimization (EGO) is widely used for the optimization of\ncomputationally expensive black-box functions. It uses a surrogate modeling\ntechnique based on Gaussian Processes (Kriging). However, due to the use of a\nstationary covariance, Kriging is not well suited for approximating non\nstationary functions. This paper explores the integration of Deep Gaussian\nprocesses (DGP) in EGO framework to deal with the non-stationary issues and\ninvestigates the induced challenges and opportunities. Numerical\nexperimentations are performed on analytical problems to highlight the\ndifferent aspects of DGP and EGO.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 13:18:50 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Hebbal", "Ali", ""], ["Brevault", "Loic", ""], ["Balesdent", "Mathieu", ""], ["Talbi", "El-Ghazali", ""], ["Melab", "Nouredine", ""]]}, {"id": "1809.04644", "submitter": "Paolo Frasca", "authors": "Wilbert Samuel Rossi, Jan Willem Polderman, Paolo Frasca", "title": "The closed loop between opinion formation and personalised\n  recommendations", "comments": "21 pages, 13 figures, 1 table. To be submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online platforms, recommender systems are responsible for directing users\nto relevant contents. In order to enhance the users' engagement, recommender\nsystems adapt their output to the reactions of the users, who are in turn\naffected by the recommended contents. In this work, we study a tractable\nanalytical model of a user that interacts with an online news aggregator, with\nthe purpose of making explicit the feedback loop between the evolution of the\nuser's opinion and the personalised recommendation of contents. More\nspecifically, we assume that the user is endowed with a scalar opinion about a\ncertain issue and seeks news about it on a news aggregator: this opinion is\ninfluenced by all received news, which are characterized by a binary position\non the issue at hand. The user is affected by a confirmation bias, that is, a\npreference for news that confirm her current opinion. The news aggregator\nrecommends items with the goal of maximizing the number of user's clicks (as a\nmeasure of her engagement): in order to fulfil its goal, the recommender has to\ncompromise between exploring the user's preferences and exploiting what it has\nlearned so far. After defining suitable metrics for the effectiveness of the\nrecommender systems (such as the click-through rate) and for its impact on the\nopinion, we perform both extensive numerical simulations and a mathematical\nanalysis of the model. We find that personalised recommendations markedly\naffect the evolution of opinions and favor the emergence of more extreme ones:\nthe intensity of these effects is inherently related to the effectiveness of\nthe recommender. We also show that by tuning the amount of randomness in the\nrecommendation algorithm, one can seek a balance between the effectiveness of\nthe recommendation system and its impact on the opinions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 19:37:35 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 13:54:54 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Rossi", "Wilbert Samuel", ""], ["Polderman", "Jan Willem", ""], ["Frasca", "Paolo", ""]]}, {"id": "1809.04663", "submitter": "Stephen Pfohl", "authors": "Stephen Pfohl, Ben Marafino, Adrien Coulet, Fatima Rodriguez, Latha\n  Palaniappan, Nigam H. Shah", "title": "Creating Fair Models of Atherosclerotic Cardiovascular Disease Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guidelines for the management of atherosclerotic cardiovascular disease\n(ASCVD) recommend the use of risk stratification models to identify patients\nmost likely to benefit from cholesterol-lowering and other therapies. These\nmodels have differential performance across race and gender groups with\ninconsistent behavior across studies, potentially resulting in an inequitable\ndistribution of beneficial therapy. In this work, we leverage adversarial\nlearning and a large observational cohort extracted from electronic health\nrecords (EHRs) to develop a \"fair\" ASCVD risk prediction model with reduced\nvariability in error rates across groups. We empirically demonstrate that our\napproach is capable of aligning the distribution of risk predictions\nconditioned on the outcome across several groups simultaneously for models\nbuilt from high-dimensional EHR data. We also discuss the relevance of these\nresults in the context of the empirical trade-off between fairness and model\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 20:28:29 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 00:04:36 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 04:50:04 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Pfohl", "Stephen", ""], ["Marafino", "Ben", ""], ["Coulet", "Adrien", ""], ["Rodriguez", "Fatima", ""], ["Palaniappan", "Latha", ""], ["Shah", "Nigam H.", ""]]}, {"id": "1809.04668", "submitter": "Balaji Sesha Sarath Pokuri", "authors": "Balaji Sesha Sarath Pokuri, Alec Lofquist, Chad M Risko and Baskar\n  Ganapathysubramanian", "title": "PARyOpt: A software for Parallel Asynchronous Remote Bayesian\n  Optimization", "comments": "14 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PARyOpt is a python based implementation of the Bayesian optimization routine\ndesigned for remote and asynchronous function evaluations. Bayesian\noptimization is especially attractive for computational optimization due to its\nlow cost function footprint as well as the ability to account for uncertainties\nin data. A key challenge to efficiently deploy any optimization strategy on\ndistributed computing systems is the synchronization step, where data from\nmultiple function calls is assimilated to identify the next campaign of\nfunction calls. Bayesian optimization provides an elegant approach to overcome\nthis issue via asynchronous updates. We formulate, develop and implement a\nparallel, asynchronous variant of Bayesian optimization. The framework is\nrobust and resilient to external failures. We show how such asynchronous\nevaluations help reduce the total optimization wall clock time for a suite of\ntest problems. Additionally, we show how the software design of the framework\nallows easy extension to response surface reconstruction (Kriging), providing a\nhigh performance software for autonomous exploration. The software is available\non PyPI, with examples and documentation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 20:50:19 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Pokuri", "Balaji Sesha Sarath", ""], ["Lofquist", "Alec", ""], ["Risko", "Chad M", ""], ["Ganapathysubramanian", "Baskar", ""]]}, {"id": "1809.04673", "submitter": "Rishabh Iyer", "authors": "Rishabh Iyer, Nimit Acharya, Tanuja Bompada, Denis Charles, Eren\n  Manavoglu", "title": "A Unified Batch Online Learning Framework for Click Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework for Batch Online Learning (OL) for Click\nPrediction in Search Advertisement. Machine Learning models once deployed, show\nnon-trivial accuracy and calibration degradation over time due to model\nstaleness. It is therefore necessary to regularly update models, and do so\nautomatically. This paper presents two paradigms of Batch Online Learning, one\nwhich incrementally updates the model parameters via an early stopping\nmechanism, and another which does so through a proximal regularization. We\nargue how both these schemes naturally trade-off between old and new data. We\nthen theoretically and empirically show that these two seemingly different\nschemes are closely related. Through extensive experiments, we demonstrate the\nutility of of our OL framework; how the two OL schemes relate to each other and\nhow they trade-off between the new and historical data. We then compare batch\nOL to full model retrains, and show how online learning is more robust to data\nissues. We also demonstrate the long term impact of Online Learning, the role\nof the initial Models in OL, the impact of delays in the update, and finally\nconclude with some implementation details and challenges in deploying a real\nworld online learning system in production. While this paper mostly focuses on\napplication of click prediction for search advertisement, we hope that the\nlessons learned here can be carried over to other problem domains.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 21:01:55 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Iyer", "Rishabh", ""], ["Acharya", "Nimit", ""], ["Bompada", "Tanuja", ""], ["Charles", "Denis", ""], ["Manavoglu", "Eren", ""]]}, {"id": "1809.04682", "submitter": "Amit Zohar", "authors": "Amit Zohar, Lior Wolf", "title": "Automatic Program Synthesis of Long Programs with a Learned Garbage\n  Collector", "comments": "Published at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of generating automatic code given sample\ninput-output pairs. We train a neural network to map from the current state and\nthe outputs to the program's next statement. The neural network optimizes\nmultiple tasks concurrently: the next operation out of a set of high level\ncommands, the operands of the next statement, and which variables can be\ndropped from memory. Using our method we are able to create programs that are\nmore than twice as long as existing state-of-the-art solutions, while improving\nthe success rate for comparable lengths, and cutting the run-time by two orders\nof magnitude. Our code, including an implementation of various literature\nbaselines, is publicly available at https://github.com/amitz25/PCCoder\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 21:25:28 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 15:58:09 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Zohar", "Amit", ""], ["Wolf", "Lior", ""]]}, {"id": "1809.04683", "submitter": "Shuhan Yuan", "authors": "Panpan Zheng, Shuhan Yuan, Xintao Wu", "title": "SAFE: A Neural Survival Analysis Model for Fraud Early Detection", "comments": "To appear in AAAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many online platforms have deployed anti-fraud systems to detect and prevent\nfraudulent activities. However, there is usually a gap between the time that a\nuser commits a fraudulent action and the time that the user is suspended by the\nplatform. How to detect fraudsters in time is a challenging problem. Most of\nthe existing approaches adopt classifiers to predict fraudsters given their\nactivity sequences along time. The main drawback of classification models is\nthat the prediction results between consecutive timestamps are often\ninconsistent. In this paper, we propose a survival analysis based fraud early\ndetection model, SAFE, which maps dynamic user activities to survival\nprobabilities that are guaranteed to be monotonically decreasing along time.\nSAFE adopts recurrent neural network (RNN) to handle user activity sequences\nand directly outputs hazard values at each timestamp, and then, survival\nprobability derived from hazard values is deployed to achieve consistent\npredictions. Because we only observe the user suspended time instead of the\nfraudulent activity time in the training data, we revise the loss function of\nthe regular survival model to achieve fraud early detection. Experimental\nresults on two real world datasets demonstrate that SAFE outperforms both the\nsurvival analysis model and recurrent neural network model alone as well as\nstate-of-the-art fraud early detection approaches.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 21:28:26 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 21:12:08 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Zheng", "Panpan", ""], ["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""]]}, {"id": "1809.04684", "submitter": "Jiahao Chen", "authors": "Jiahao Chen", "title": "Fair lending needs explainable models for responsible recommendation", "comments": "4 pages, position paper accepted for FATREC 2018 conference at ACM\n  RecSys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The financial services industry has unique explainability and fairness\nchallenges arising from compliance and ethical considerations in credit\ndecisioning. These challenges complicate the use of model machine learning and\nartificial intelligence methods in business decision processes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 21:29:20 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Chen", "Jiahao", ""]]}, {"id": "1809.04705", "submitter": "Hongteng Xu", "authors": "Hongteng Xu, Wenlin Wang, Wei Liu, Lawrence Carin", "title": "Distilled Wasserstein Learning for Word Embedding and Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Wasserstein method with a distillation mechanism, yielding\njoint learning of word embeddings and topics. The proposed method is based on\nthe fact that the Euclidean distance between word embeddings may be employed as\nthe underlying distance in the Wasserstein topic model. The word distributions\nof topics, their optimal transports to the word distributions of documents, and\nthe embeddings of words are learned in a unified framework. When learning the\ntopic model, we leverage a distilled underlying distance matrix to update the\ntopic distributions and smoothly calculate the corresponding optimal\ntransports. Such a strategy provides the updating of word embeddings with\nrobust guidance, improving the algorithmic convergence. As an application, we\nfocus on patient admission records, in which the proposed method embeds the\ncodes of diseases and procedures and learns the topics of admissions, obtaining\nsuperior performance on clinically-meaningful disease network construction,\nmortality prediction as a function of admission codes, and procedure\nrecommendation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 23:10:23 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Xu", "Hongteng", ""], ["Wang", "Wenlin", ""], ["Liu", "Wei", ""], ["Carin", "Lawrence", ""]]}, {"id": "1809.04720", "submitter": "Jeroen van Baar", "authors": "Jeroen van Baar, Alan Sullivan, Radu Cordorel, Devesh Jha, Diego\n  Romeres and Daniel Nikovski", "title": "Sim-to-Real Transfer Learning using Robustified Controllers in Robotic\n  Tasks involving Complex Dynamics", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robot tasks or controllers using deep reinforcement learning has\nbeen proven effective in simulations. Learning in simulation has several\nadvantages. For example, one can fully control the simulated environment,\nincluding halting motions while performing computations. Another advantage when\nrobots are involved, is that the amount of time a robot is occupied learning a\ntask---rather than being productive---can be reduced by transferring the\nlearned task to the real robot. Transfer learning requires some amount of\nfine-tuning on the real robot. For tasks which involve complex (non-linear)\ndynamics, the fine-tuning itself may take a substantial amount of time. In\norder to reduce the amount of fine-tuning we propose to learn robustified\ncontrollers in simulation. Robustified controllers are learned by exploiting\nthe ability to change simulation parameters (both appearance and dynamics) for\nsuccessive training episodes. An additional benefit for this approach is that\nit alleviates the precise determination of physics parameters for the\nsimulator, which is a non-trivial task. We demonstrate our proposed approach on\na real setup in which a robot aims to solve a maze game, which involves complex\ndynamics due to static friction and potentially large accelerations. We show\nthat the amount of fine-tuning in transfer learning for a robustified\ncontroller is substantially reduced compared to a non-robustified controller.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 00:27:31 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 14:26:13 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["van Baar", "Jeroen", ""], ["Sullivan", "Alan", ""], ["Cordorel", "Radu", ""], ["Jha", "Devesh", ""], ["Romeres", "Diego", ""], ["Nikovski", "Daniel", ""]]}, {"id": "1809.04729", "submitter": "Alireza Shafaei", "authors": "Alireza Shafaei, Mark Schmidt, James J. Little", "title": "A Less Biased Evaluation of Out-of-distribution Sample Detectors", "comments": "to appear in BMVC 2019; v2 is more compact, with more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, a learning system could receive an input that is unlike\nanything it has seen during training. Unfortunately, out-of-distribution\nsamples can lead to unpredictable behaviour. We need to know whether any given\ninput belongs to the population distribution of the training/evaluation data to\nprevent unpredictable behaviour in deployed systems. A recent surge of interest\nin this problem has led to the development of sophisticated techniques in the\ndeep learning literature. However, due to the absence of a standard problem\ndefinition or an exhaustive evaluation, it is not evident if we can rely on\nthese methods. What makes this problem different from a typical supervised\nlearning setting is that the distribution of outliers used in training may not\nbe the same as the distribution of outliers encountered in the application.\nClassical approaches that learn inliers vs. outliers with only two datasets can\nyield optimistic results. We introduce OD-test, a three-dataset evaluation\nscheme as a more reliable strategy to assess progress on this problem. We\npresent an exhaustive evaluation of a broad set of methods from related areas\non image classification tasks. Contrary to the existing results, we show that\nfor realistic applications of high-dimensional images the previous techniques\nhave low accuracy and are not reliable in practice.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 01:15:49 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 17:46:05 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Shafaei", "Alireza", ""], ["Schmidt", "Mark", ""], ["Little", "James J.", ""]]}, {"id": "1809.04737", "submitter": "Xintao Wu", "authors": "Yongkai Wu and Lu Zhang and Xintao Wu", "title": "Fairness-aware Classification: Criterion, Convexity, and Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness-aware classification is receiving increasing attention in the\nmachine learning fields. Recently research proposes to formulate the\nfairness-aware classification as constrained optimization problems. However,\nseveral limitations exist in previous works due to the lack of a theoretical\nframework for guiding the formulation. In this paper, we propose a general\nframework for learning fair classifiers which addresses previous limitations.\nThe framework formulates various commonly-used fairness metrics as convex\nconstraints that can be directly incorporated into classic classification\nmodels. Within the framework, we propose a constraint-free criterion on the\ntraining data which ensures that any classifier learned from the data is fair.\nWe also derive the constraints which ensure that the real fairness metric is\nsatisfied when surrogate functions are used to achieve convexity. Our framework\ncan be used to for formulating fairness-aware classification with fairness\nguarantee and computational efficiency. The experiments using real-world\ndatasets demonstrate our theoretical results and show the effectiveness of\nproposed framework and methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 01:56:57 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Wu", "Yongkai", ""], ["Zhang", "Lu", ""], ["Wu", "Xintao", ""]]}, {"id": "1809.04747", "submitter": "Tao Yang", "authors": "Tao Yang, Georgios Arvanitidis, Dongmei Fu, Xiaogang Li, and S{\\o}ren\n  Hauberg", "title": "Geodesic Clustering in Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are tremendously successful in learning\nlow-dimensional latent representations that well-describe the data. These\nrepresentations, however, tend to much distort relationships between points,\ni.e. pairwise distances tend to not reflect semantic similarities well. This\nrenders unsupervised tasks, such as clustering, difficult when working with the\nlatent representations. We demonstrate that taking the geometry of the\ngenerative model into account is sufficient to make simple clustering\nalgorithms work well over latent representations. Leaning on the recent finding\nthat deep generative models constitute stochastically immersed Riemannian\nmanifolds, we propose an efficient algorithm for computing geodesics (shortest\npaths) and computing distances in the latent space, while taking its distortion\ninto account. We further propose a new architecture for modeling uncertainty in\nvariational autoencoders, which is essential for understanding the geometry of\ndeep generative models. Experiments show that the geodesic distance is very\nlikely to reflect the internal structure of the data.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 02:37:53 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Yang", "Tao", ""], ["Arvanitidis", "Georgios", ""], ["Fu", "Dongmei", ""], ["Li", "Xiaogang", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "1809.04758", "submitter": "Dan Li", "authors": "Dan Li and Dacheng Chen and Jonathan Goh and See-kiong Ng", "title": "Anomaly Detection with Generative Adversarial Networks for Multivariate\n  Time Series", "comments": "This paper was presented in the 7th International Workshop on Big\n  Data, Streams and Heterogeneous Source Mining: Algorithms, Systems,\n  Programming Models and Applications on the ACM Knowledge Discovery and Data\n  Mining conference, August 2018, London, United Kingdom", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's Cyber-Physical Systems (CPSs) are large, complex, and affixed with\nnetworked sensors and actuators that are targets for cyber-attacks.\nConventional detection techniques are unable to deal with the increasingly\ndynamic and complex nature of the CPSs. On the other hand, the networked\nsensors and actuators generate large amounts of data streams that can be\ncontinuously monitored for intrusion events. Unsupervised machine learning\ntechniques can be used to model the system behaviour and classify deviant\nbehaviours as possible attacks. In this work, we proposed a novel Generative\nAdversarial Networks-based Anomaly Detection (GAN-AD) method for such complex\nnetworked CPSs. We used LSTM-RNN in our GAN to capture the distribution of the\nmultivariate time series of the sensors and actuators under normal working\nconditions of a CPS. Instead of treating each sensor's and actuator's time\nseries independently, we model the time series of multiple sensors and\nactuators in the CPS concurrently to take into account of potential latent\ninteractions between them. To exploit both the generator and the discriminator\nof our GAN, we deployed the GAN-trained discriminator together with the\nresiduals between generator-reconstructed data and the actual samples to detect\npossible anomalies in the complex CPS. We used our GAN-AD to distinguish\nabnormal attacked situations from normal working conditions for a complex\nsix-stage Secure Water Treatment (SWaT) system. Experimental results showed\nthat the proposed strategy is effective in identifying anomalies caused by\nvarious attacks with high detection rate and low false positive rate as\ncompared to existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 03:54:22 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 05:50:34 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 05:13:19 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Li", "Dan", ""], ["Chen", "Dacheng", ""], ["Goh", "Jonathan", ""], ["Ng", "See-kiong", ""]]}, {"id": "1809.04790", "submitter": "Jiliang Zhang", "authors": "Jiliang Zhang and Chen Li", "title": "Adversarial Examples: Opportunities and Challenges", "comments": "16 pages, 13 figures, 5 tables", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (2019)", "doi": "10.1109/TNNLS.2019.2933524", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have shown huge superiority over humans in image\nrecognition, speech processing, autonomous vehicles and medical diagnosis.\nHowever, recent studies indicate that DNNs are vulnerable to adversarial\nexamples (AEs), which are designed by attackers to fool deep learning models.\nDifferent from real examples, AEs can mislead the model to predict incorrect\noutputs while hardly be distinguished by human eyes, therefore threaten\nsecurity-critical deep-learning applications. In recent years, the generation\nand defense of AEs have become a research hotspot in the field of artificial\nintelligence (AI) security. This article reviews the latest research progress\nof AEs. First, we introduce the concept, cause, characteristics and evaluation\nmetrics of AEs, then give a survey on the state-of-the-art AE generation\nmethods with the discussion of advantages and disadvantages. After that, we\nreview the existing defenses and discuss their limitations. Finally, future\nresearch opportunities and challenges on AEs are prospected.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 06:09:32 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 11:09:01 GMT"}, {"version": "v3", "created": "Sun, 4 Aug 2019 04:54:27 GMT"}, {"version": "v4", "created": "Mon, 23 Sep 2019 13:04:37 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Zhang", "Jiliang", ""], ["Li", "Chen", ""]]}, {"id": "1809.04828", "submitter": "Raanan Rohekar", "authors": "Raanan Y. Rohekar, Yaniv Gurwicz, Shami Nisimov, Guy Koren, Gal Novik", "title": "Bayesian Structure Learning by Recursive Bootstrap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We address the problem of Bayesian structure learning for domains with\nhundreds of variables by employing non-parametric bootstrap, recursively. We\npropose a method that covers both model averaging and model selection in the\nsame framework. The proposed method deals with the main weakness of\nconstraint-based learning---sensitivity to errors in the independence\ntests---by a novel way of combining bootstrap with constraint-based learning.\nEssentially, we provide an algorithm for learning a tree, in which each node\nrepresents a scored CPDAG for a subset of variables and the level of the node\ncorresponds to the maximal order of conditional independencies that are encoded\nin the graph. As higher order independencies are tested in deeper recursive\ncalls, they benefit from more bootstrap samples, and therefore more resistant\nto the curse-of-dimensionality. Moreover, the re-use of stable low order\nindependencies allows greater computational efficiency. We also provide an\nalgorithm for sampling CPDAGs efficiently from their posterior given the\nlearned tree. We empirically demonstrate that the proposed algorithm scales\nwell to hundreds of variables, and learns better MAP models and more reliable\ncausal relationships between variables, than other state-of-the-art-methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 08:21:16 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Rohekar", "Raanan Y.", ""], ["Gurwicz", "Yaniv", ""], ["Nisimov", "Shami", ""], ["Koren", "Guy", ""], ["Novik", "Gal", ""]]}, {"id": "1809.04835", "submitter": "Haichao Shi", "authors": "Haichao Shi and Peng Li and Bo Wang and Zhenyu Wang", "title": "Image Captioning based on Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it has shown that the policy-gradient methods for reinforcement\nlearning have been utilized to train deep end-to-end systems on natural\nlanguage processing tasks. What's more, with the complexity of understanding\nimage content and diverse ways of describing image content in natural language,\nimage captioning has been a challenging problem to deal with. To the best of\nour knowledge, most state-of-the-art methods follow a pattern of sequential\nmodel, such as recurrent neural networks (RNN). However, in this paper, we\npropose a novel architecture for image captioning with deep reinforcement\nlearning to optimize image captioning tasks. We utilize two networks called\n\"policy network\" and \"value network\" to collaboratively generate the captions\nof images. The experiments are conducted on Microsoft COCO dataset, and the\nexperimental results have verified the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 08:40:21 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Shi", "Haichao", ""], ["Li", "Peng", ""], ["Wang", "Bo", ""], ["Wang", "Zhenyu", ""]]}, {"id": "1809.04855", "submitter": "Thomas Bird", "authors": "Thomas Bird, Julius Kunze and David Barber", "title": "Stochastic Variational Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Optimization forms a differentiable upper bound on an objective.\nWe show that approaches such as Natural Evolution Strategies and Gaussian\nPerturbation, are special cases of Variational Optimization in which the\nexpectations are approximated by Gaussian sampling. These approaches are of\nparticular interest because they are parallelizable. We calculate the\napproximate bias and variance of the corresponding gradient estimators and\ndemonstrate that using antithetic sampling or a baseline is crucial to mitigate\ntheir problems. We contrast these methods with an alternative parallelizable\nmethod, namely Directional Derivatives. We conclude that, for differentiable\nobjectives, using Directional Derivatives is preferable to using Variational\nOptimization to perform parallel Stochastic Gradient Descent.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 09:34:04 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Bird", "Thomas", ""], ["Kunze", "Julius", ""], ["Barber", "David", ""]]}, {"id": "1809.04891", "submitter": "Francesco Verdoja", "authors": "Francesco Verdoja, Jens Lundell, and Ville Kyrki", "title": "Deep Network Uncertainty Maps for Indoor Navigation", "comments": "Accepted for publication in \"2019 IEEE-RAS International Conference\n  on Humanoid Robots (Humanoids)\"", "journal-ref": "2019 IEEE-RAS 19th International Conference on Humanoid Robots\n  (Humanoids), Toronto, ON, Canada, 2019, pp. 112-119", "doi": "10.1109/Humanoids43949.2019.9035016", "report-no": null, "categories": "cs.RO cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most mobile robots for indoor use rely on 2D laser scanners for localization,\nmapping and navigation. These sensors, however, cannot detect transparent\nsurfaces or measure the full occupancy of complex objects such as tables. Deep\nNeural Networks have recently been proposed to overcome this limitation by\nlearning to estimate object occupancy. These estimates are nevertheless subject\nto uncertainty, making the evaluation of their confidence an important issue\nfor these measures to be useful for autonomous navigation and mapping. In this\nwork we approach the problem from two sides. First we discuss uncertainty\nestimation in deep models, proposing a solution based on a fully convolutional\nneural network. The proposed architecture is not restricted by the assumption\nthat the uncertainty follows a Gaussian model, as in the case of many popular\nsolutions for deep model uncertainty estimation, such as Monte-Carlo Dropout.\nWe present results showing that uncertainty over obstacle distances is actually\nbetter modeled with a Laplace distribution. Then, we propose a novel approach\nto build maps based on Deep Neural Network uncertainty models. In particular,\nwe present an algorithm to build a map that includes information over obstacle\ndistance estimates while taking into account the level of uncertainty in each\nestimate. We show how the constructed map can be used to increase global\nnavigation safety by planning trajectories which avoid areas of high\nuncertainty, enabling higher autonomy for mobile robots in indoor settings.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 11:33:32 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 14:17:28 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 10:53:16 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Verdoja", "Francesco", ""], ["Lundell", "Jens", ""], ["Kyrki", "Ville", ""]]}, {"id": "1809.04913", "submitter": "Pengcheng Li", "authors": "Pengcheng Li, Jinfeng Yi, Lijun Zhang", "title": "Query-Efficient Black-Box Attack by Active Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) as a popular machine learning model is found to be\nvulnerable to adversarial attack. This attack constructs adversarial examples\nby adding small perturbations to the raw input, while appearing unmodified to\nhuman eyes but will be misclassified by a well-trained classifier. In this\npaper, we focus on the black-box attack setting where attackers have almost no\naccess to the underlying models. To conduct black-box attack, a popular\napproach aims to train a substitute model based on the information queried from\nthe target DNN. The substitute model can then be attacked using existing\nwhite-box attack approaches, and the generated adversarial examples will be\nused to attack the target DNN. Despite its encouraging results, this approach\nsuffers from poor query efficiency, i.e., attackers usually needs to query a\nhuge amount of times to collect enough information for training an accurate\nsubstitute model. To this end, we first utilize state-of-the-art white-box\nattack methods to generate samples for querying, and then introduce an active\nlearning strategy to significantly reduce the number of queries needed.\nBesides, we also propose a diversity criterion to avoid the sampling bias. Our\nextensive experimental results on MNIST and CIFAR-10 show that the proposed\nmethod can reduce more than $90\\%$ of queries while preserve attacking success\nrates and obtain an accurate substitute model which is more than $85\\%$ similar\nwith the target oracle.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 12:35:18 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Li", "Pengcheng", ""], ["Yi", "Jinfeng", ""], ["Zhang", "Lijun", ""]]}, {"id": "1809.04931", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency", "title": "Multimodal Local-Global Ranking Fusion for Emotion Recognition", "comments": "ACM International Conference on Multimodal Interaction (ICMI 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition is a core research area at the intersection of artificial\nintelligence and human communication analysis. It is a significant technical\nchallenge since humans display their emotions through complex idiosyncratic\ncombinations of the language, visual and acoustic modalities. In contrast to\ntraditional multimodal fusion techniques, we approach emotion recognition from\nboth direct person-independent and relative person-dependent perspectives. The\ndirect person-independent perspective follows the conventional emotion\nrecognition approach which directly infers absolute emotion labels from\nobserved multimodal features. The relative person-dependent perspective\napproaches emotion recognition in a relative manner by comparing partial video\nsegments to determine if there was an increase or decrease in emotional\nintensity. Our proposed model integrates these direct and relative prediction\nperspectives by dividing the emotion recognition task into three easier\nsubtasks. The first subtask involves a multimodal local ranking of relative\nemotion intensities between two short segments of a video. The second subtask\nuses local rankings to infer global relative emotion ranks with a Bayesian\nranking algorithm. The third subtask incorporates both direct predictions from\nobserved multimodal behaviors and relative emotion ranks from local-global\nrankings for final emotion prediction. Our approach displays excellent\nperformance on an audio-visual emotion recognition benchmark and improves over\nother algorithms for multimodal fusion.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 09:44:01 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Liang", "Paul Pu", ""], ["Zadeh", "Amir", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1809.04933", "submitter": "Alejandro Baldominos", "authors": "Alejandro Baldominos, Iv\\'an Blanco, Antonio Jos\\'e Moreno, Rub\\'en\n  Iturrarte, \\'Oscar Bern\\'ardez and Carlos Afonso", "title": "Identifying Real Estate Opportunities using Machine Learning", "comments": "24 pages, 13 figures, 5 tables", "journal-ref": "Baldominos, A.; Blanco, I.; Moreno, A.J.; Iturrarte, R.;\n  Bern\\'ardez, \\'O.; Afonso, C. Identifying Real Estate Opportunities Using\n  Machine Learning. Appl. Sci. 2018, 8, 2321", "doi": "10.3390/app8112321", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The real estate market is exposed to many fluctuations in prices because of\nexisting correlations with many variables, some of which cannot be controlled\nor might even be unknown. Housing prices can increase rapidly (or in some\ncases, also drop very fast), yet the numerous listings available online where\nhouses are sold or rented are not likely to be updated that often. In some\ncases, individuals interested in selling a house (or apartment) might include\nit in some online listing, and forget about updating the price. In other cases,\nsome individuals might be interested in deliberately setting a price below the\nmarket price in order to sell the home faster, for various reasons. In this\npaper, we aim at developing a machine learning application that identifies\nopportunities in the real estate market in real time, i.e., houses that are\nlisted with a price substantially below the market price. This program can be\nuseful for investors interested in the housing market. We have focused in a use\ncase considering real estate assets located in the Salamanca district in Madrid\n(Spain) and listed in the most relevant Spanish online site for home sales and\nrentals. The application is formally implemented as a regression problem that\ntries to estimate the market price of a house given features retrieved from\npublic online listings. For building this application, we have performed a\nfeature engineering stage in order to discover relevant features that allows\nfor attaining a high predictive performance. Several machine learning\nalgorithms have been tested, including regression trees, k-nearest neighbors,\nsupport vector machines and neural networks, identifying advantages and\nhandicaps of each of them.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 13:19:23 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 11:53:32 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Baldominos", "Alejandro", ""], ["Blanco", "Iv\u00e1n", ""], ["Moreno", "Antonio Jos\u00e9", ""], ["Iturrarte", "Rub\u00e9n", ""], ["Bern\u00e1rdez", "\u00d3scar", ""], ["Afonso", "Carlos", ""]]}, {"id": "1809.04967", "submitter": "\\'Angel F. Garc\\'ia-Fern\\'andez", "authors": "\\'Angel F. Garc\\'ia-Fern\\'andez, Filip Tronarp, Simo S\\\"arkk\\\"a", "title": "Gaussian process classification using posterior linearisation", "comments": "\\'A. F. Garc\\'ia-Fern\\'andez, F. Tronarp and S. S\\\"arkk\\\"a, \"Gaussian\n  Process Classification Using Posterior Linearization,\" in IEEE Signal\n  Processing Letters, vol. 26, no. 5, pp. 735-739, May 2019", "journal-ref": null, "doi": "10.1109/LSP.2019.2906929", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new algorithm for Gaussian process classification based\non posterior linearisation (PL). In PL, a Gaussian approximation to the\nposterior density is obtained iteratively using the best possible linearisation\nof the conditional mean of the labels and accounting for the linearisation\nerror. PL has some theoretical advantages over expectation propagation (EP):\nall calculated covariance matrices are positive definite and there is a local\nconvergence theorem. In experimental data, PL has better performance than EP\nwith the noisy threshold likelihood and the parallel implementation of the\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 13:54:16 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 08:35:21 GMT"}, {"version": "v3", "created": "Thu, 18 Apr 2019 07:05:12 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Garc\u00eda-Fern\u00e1ndez", "\u00c1ngel F.", ""], ["Tronarp", "Filip", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "1809.04988", "submitter": "Eric Crawford", "authors": "Eric Crawford, Guillaume Rabusseau, Joelle Pineau", "title": "Sequential Coordination of Deep Models for Learning Visual Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving machine intelligence requires a smooth integration of perception\nand reasoning, yet models developed to date tend to specialize in one or the\nother; sophisticated manipulation of symbols acquired from rich perceptual\nspaces has so far proved elusive. Consider a visual arithmetic task, where the\ngoal is to carry out simple arithmetical algorithms on digits presented under\nnatural conditions (e.g. hand-written, placed randomly). We propose a\ntwo-tiered architecture for tackling this problem. The lower tier consists of a\nheterogeneous collection of information processing modules, which can include\npre-trained deep neural networks for locating and extracting characters from\nthe image, as well as modules performing symbolic transformations on the\nrepresentations extracted by perception. The higher tier consists of a\ncontroller, trained using reinforcement learning, which coordinates the modules\nin order to solve the high-level task. For instance, the controller may learn\nin what contexts to execute the perceptual networks and what symbolic\ntransformations to apply to their outputs. The resulting model is able to solve\na variety of tasks in the visual arithmetic domain, and has several advantages\nover standard, architecturally homogeneous feedforward networks including\nimproved sample efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 14:27:25 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Crawford", "Eric", ""], ["Rabusseau", "Guillaume", ""], ["Pineau", "Joelle", ""]]}, {"id": "1809.04993", "submitter": "Diego Romeres", "authors": "Diego Romeres, Devesh Jha, Alberto Dalla Libera, William Yerazunis and\n  Daniel Nikovski", "title": "Semiparametrical Gaussian Processes Learning of Forward Dynamical Models\n  for Navigating in a Circular Maze", "comments": "7 pages including the references, 5 figures. Changed title, improved\n  the structure of the article and the images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a problem of model learning for the purpose of learning\nhow to navigate a ball to a goal state in a circular maze environment with two\ndegrees of freedom. The motion of the ball in the maze environment is\ninfluenced by several non-linear effects such as dry friction and contacts,\nwhich are difficult to model physically. We propose a semiparametric model to\nestimate the motion dynamics of the ball based on Gaussian Process Regression\nequipped with basis functions obtained from physics first principles. The\naccuracy of this semiparametric model is shown not only in estimation but also\nin prediction at n-steps ahead and its compared with standard algorithms for\nmodel learning. The learned model is then used in a trajectory optimization\nalgorithm to compute ball trajectories. We propose the system presented in the\npaper as a benchmark problem for reinforcement and robot learning, for its\ninteresting and challenging dynamics and its relative ease of reproducibility.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 14:44:05 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 18:22:48 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Romeres", "Diego", ""], ["Jha", "Devesh", ""], ["Libera", "Alberto Dalla", ""], ["Yerazunis", "William", ""], ["Nikovski", "Daniel", ""]]}, {"id": "1809.04997", "submitter": "Takeshi Teshima", "authors": "Takeshi Teshima, Miao Xu, Issei Sato and Masashi Sugiyama", "title": "Clipped Matrix Completion: A Remedy for Ceiling Effects", "comments": "36 pages, 3 figures, The Thirty-Third AAAI Conference on Artificial\n  Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering a low-rank matrix from its clipped\nobservations. Clipping is conceivable in many scientific areas that obstructs\nstatistical analyses. On the other hand, matrix completion (MC) methods can\nrecover a low-rank matrix from various information deficits by using the\nprinciple of low-rank completion. However, the current theoretical guarantees\nfor low-rank MC do not apply to clipped matrices, as the deficit depends on the\nunderlying values. Therefore, the feasibility of clipped matrix completion\n(CMC) is not trivial. In this paper, we first provide a theoretical guarantee\nfor the exact recovery of CMC by using a trace-norm minimization algorithm.\nFurthermore, we propose practical CMC algorithms by extending ordinary MC\nmethods. Our extension is to use the squared hinge loss in place of the squared\nloss for reducing the penalty of over-estimation on clipped entries. We also\npropose a novel regularization term tailored for CMC. It is a combination of\ntwo trace-norm terms, and we theoretically bound the recovery error under the\nregularization. We demonstrate the effectiveness of the proposed methods\nthrough experiments using both synthetic and benchmark data for recommendation\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 14:46:54 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 04:44:31 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 11:39:24 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Teshima", "Takeshi", ""], ["Xu", "Miao", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1809.05014", "submitter": "Geoffrey Wolfer", "authors": "Geoffrey Wolfer and Aryeh Kontorovich", "title": "Statistical Estimation of Ergodic Markov Chain Kernel over Discrete\n  State Space", "comments": "Journal version of the extended abstract (ALT'19), to appear in\n  Bernoulli 2020+", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the statistical complexity of estimating the parameters of a\ndiscrete-state Markov chain kernel from a single long sequence of state\nobservations. In the finite case, we characterize (modulo logarithmic factors)\nthe minimax sample complexity of estimation with respect to the operator\ninfinity norm, while in the countably infinite case, we analyze the problem\nwith respect to a natural entry-wise norm derived from total variation. We show\nthat in both cases, the sample complexity is governed by the mixing properties\nof the unknown chain, for which, in the finite-state case, there are known\nfinite-sample estimators with fully empirical confidence intervals.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 15:37:19 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 13:57:14 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 12:42:03 GMT"}, {"version": "v4", "created": "Sat, 4 Apr 2020 08:13:15 GMT"}, {"version": "v5", "created": "Wed, 1 Jul 2020 09:37:22 GMT"}, {"version": "v6", "created": "Thu, 13 Aug 2020 09:04:36 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Wolfer", "Geoffrey", ""], ["Kontorovich", "Aryeh", ""]]}, {"id": "1809.05032", "submitter": "Yoshimasa Uematsu", "authors": "Yingying Fan, Jinchi Lv, Mahrad Sharifvaghefi and Yoshimasa Uematsu", "title": "IPAD: Stable Interpretable Forecasting with Knockoffs Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability and stability are two important features that are desired in\nmany contemporary big data applications arising in economics and finance. While\nthe former is enjoyed to some extent by many existing forecasting approaches,\nthe latter in the sense of controlling the fraction of wrongly discovered\nfeatures which can enhance greatly the interpretability is still largely\nunderdeveloped in the econometric settings. To this end, in this paper we\nexploit the general framework of model-X knockoffs introduced recently in\nCand\\`{e}s, Fan, Janson and Lv (2018), which is nonconventional for\nreproducible large-scale inference in that the framework is completely free of\nthe use of p-values for significance testing, and suggest a new method of\nintertwined probabilistic factors decoupling (IPAD) for stable interpretable\nforecasting with knockoffs inference in high-dimensional models. The recipe of\nthe method is constructing the knockoff variables by assuming a latent factor\nmodel that is exploited widely in economics and finance for the association\nstructure of covariates. Our method and work are distinct from the existing\nliterature in that we estimate the covariate distribution from data instead of\nassuming that it is known when constructing the knockoff variables, our\nprocedure does not require any sample splitting, we provide theoretical\njustifications on the asymptotic false discovery rate control, and the theory\nfor the power analysis is also established. Several simulation examples and the\nreal data analysis further demonstrate that the newly suggested method has\nappealing finite-sample performance with desired interpretability and stability\ncompared to some popularly used forecasting methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 08:08:10 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Fan", "Yingying", ""], ["Lv", "Jinchi", ""], ["Sharifvaghefi", "Mahrad", ""], ["Uematsu", "Yoshimasa", ""]]}, {"id": "1809.05042", "submitter": "Chris J. Maddison", "authors": "Chris J. Maddison, Daniel Paulin, Yee Whye Teh, Brendan O'Donoghue,\n  Arnaud Doucet", "title": "Hamiltonian Descent Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a family of optimization methods that achieve linear convergence\nusing first-order gradient information and constant step sizes on a class of\nconvex functions much larger than the smooth and strongly convex ones. This\nlarger class includes functions whose second derivatives may be singular or\nunbounded at their minima. Our methods are discretizations of conformal\nHamiltonian dynamics, which generalize the classical momentum method to model\nthe motion of a particle with non-standard kinetic energy exposed to a\ndissipative force and the gradient field of the function of interest. They are\nfirst-order in the sense that they require only gradient computation. Yet,\ncrucially the kinetic gradient map can be designed to incorporate information\nabout the convex conjugate in a fashion that allows for linear convergence on\nconvex functions that may be non-smooth or non-strongly convex. We study in\ndetail one implicit and two explicit methods. For one explicit method, we\nprovide conditions under which it converges to stationary points of non-convex\nfunctions. For all, we provide conditions on the convex function and kinetic\nenergy pair that guarantee linear convergence, and show that these conditions\ncan be satisfied by functions with power growth. In sum, these methods expand\nthe class of convex functions on which linear convergence is possible with\nfirst-order computation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 16:21:11 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Maddison", "Chris J.", ""], ["Paulin", "Daniel", ""], ["Teh", "Yee Whye", ""], ["O'Donoghue", "Brendan", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1809.05043", "submitter": "Amichai Painsky", "authors": "Amichai Painsky", "title": "PhD Dissertation: Generalized Independent Components Analysis Over\n  Finite Alphabets", "comments": "PhD Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent component analysis (ICA) is a statistical method for transforming\nan observable multi-dimensional random vector into components that are as\nstatistically independent as possible from each other. Usually the ICA\nframework assumes a model according to which the observations are generated\n(such as a linear transformation with additive noise). ICA over finite fields\nis a special case of ICA in which both the observations and the independent\ncomponents are over a finite alphabet. In this thesis we consider a formulation\nof the finite-field case in which an observation vector is decomposed to its\nindependent components (as much as possible) with no prior assumption on the\nway it was generated. This generalization is also known as Barlow's minimal\nredundancy representation and is considered an open problem. We propose several\ntheorems and show that this hard problem can be accurately solved with a branch\nand bound search tree algorithm, or tightly approximated with a series of\nlinear problems. Moreover, we show that there exists a simple transformation\n(namely, order permutation) which provides a greedy yet very effective\napproximation of the optimal solution. We further show that while not every\nrandom vector can be efficiently decomposed into independent components, the\nvast majority of vectors do decompose very well (that is, within a small\nconstant cost), as the dimension increases. In addition, we show that we may\npractically achieve this favorable constant cost with a complexity that is\nasymptotically linear in the alphabet size. Our contribution provides the first\nefficient set of solutions to Barlow's problem with theoretical and\ncomputational guarantees. Finally, we demonstrate our suggested framework in\nmultiple source coding applications.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 16:22:19 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 04:36:26 GMT"}, {"version": "v3", "created": "Sat, 17 Nov 2018 14:47:45 GMT"}, {"version": "v4", "created": "Tue, 20 Nov 2018 12:00:20 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Painsky", "Amichai", ""]]}, {"id": "1809.05050", "submitter": "Kai Xu", "authors": "Xiaogang Wang, Bin Zhou, Haiyue Fang, Xiaowu Chen, Qinping Zhao, Kai\n  Xu", "title": "Learning to Group and Label Fine-Grained Shape Components", "comments": "Accepted to SIGGRAPH Asia 2018. Corresponding Author: Kai Xu\n  (kevin.kai.xu@gmail.com)", "journal-ref": "ACM Transactions on Graphics, 2018", "doi": "10.1145/3272127.3275009", "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A majority of stock 3D models in modern shape repositories are assembled with\nmany fine-grained components. The main cause of such data form is the\ncomponent-wise modeling process widely practiced by human modelers. These\nmodeling components thus inherently reflect some function-based shape\ndecomposition the artist had in mind during modeling. On the other hand,\nmodeling components represent an over-segmentation since a functional part is\nusually modeled as a multi-component assembly. Based on these observations, we\nadvocate that labeled segmentation of stock 3D models should not overlook the\nmodeling components and propose a learning solution to grouping and labeling of\nthe fine-grained components. However, directly characterizing the shape of\nindividual components for the purpose of labeling is unreliable, since they can\nbe arbitrarily tiny and semantically meaningless. We propose to generate part\nhypotheses from the components based on a hierarchical grouping strategy, and\nperform labeling on those part groups instead of directly on the components.\nPart hypotheses are mid-level elements which are more probable to carry\nsemantic information. A multiscale 3D convolutional neural network is trained\nto extract context-aware features for the hypotheses. To accomplish a labeled\nsegmentation of the whole shape, we formulate higher-order conditional random\nfields (CRFs) to infer an optimal label assignment for all components.\nExtensive experiments demonstrate that our method achieves significantly robust\nlabeling results on raw 3D models from public shape repositories. Our work also\ncontributes the first benchmark for component-wise labeling.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 16:31:43 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Wang", "Xiaogang", ""], ["Zhou", "Bin", ""], ["Fang", "Haiyue", ""], ["Chen", "Xiaowu", ""], ["Zhao", "Qinping", ""], ["Xu", "Kai", ""]]}, {"id": "1809.05053", "submitter": "Alexis Conneau", "authors": "Alexis Conneau, Guillaume Lample, Ruty Rinott, Adina Williams, Samuel\n  R. Bowman, Holger Schwenk, Veselin Stoyanov", "title": "XNLI: Evaluating Cross-lingual Sentence Representations", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art natural language processing systems rely on supervision in\nthe form of annotated data to learn competent models. These models are\ngenerally trained on data in a single language (usually English), and cannot be\ndirectly used beyond that language. Since collecting data in every language is\nnot realistic, there has been a growing interest in cross-lingual language\nunderstanding (XLU) and low-resource cross-language transfer. In this work, we\nconstruct an evaluation set for XLU by extending the development and test sets\nof the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15\nlanguages, including low-resource languages such as Swahili and Urdu. We hope\nthat our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence\nunderstanding by providing an informative standard evaluation task. In\naddition, we provide several baselines for multilingual sentence understanding,\nincluding two based on machine translation systems, and two that use parallel\ndata to train aligned multilingual bag-of-words and LSTM encoders. We find that\nXNLI represents a practical and challenging evaluation suite, and that directly\ntranslating the test data yields the best performance among available\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 16:39:53 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Conneau", "Alexis", ""], ["Lample", "Guillaume", ""], ["Rinott", "Ruty", ""], ["Williams", "Adina", ""], ["Bowman", "Samuel R.", ""], ["Schwenk", "Holger", ""], ["Stoyanov", "Veselin", ""]]}, {"id": "1809.05054", "submitter": "Tianze Shi", "authors": "Tianze Shi, Kedar Tatwawadi, Kaushik Chakrabarti, Yi Mao, Oleksandr\n  Polozov, Weizhu Chen", "title": "IncSQL: Training Incremental Text-to-SQL Parsers with Non-Deterministic\n  Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a sequence-to-action parsing approach for the natural language to\nSQL task that incrementally fills the slots of a SQL query with feasible\nactions from a pre-defined inventory. To account for the fact that typically\nthere are multiple correct SQL queries with the same or very similar semantics,\nwe draw inspiration from syntactic parsing techniques and propose to train our\nsequence-to-action models with non-deterministic oracles. We evaluate our\nmodels on the WikiSQL dataset and achieve an execution accuracy of 83.7% on the\ntest set, a 2.1% absolute improvement over the models trained with traditional\nstatic oracles assuming a single correct target SQL query. When further\ncombined with the execution-guided decoding strategy, our model sets a new\nstate-of-the-art performance at an execution accuracy of 87.1%.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 16:42:21 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 17:55:37 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Shi", "Tianze", ""], ["Tatwawadi", "Kedar", ""], ["Chakrabarti", "Kaushik", ""], ["Mao", "Yi", ""], ["Polozov", "Oleksandr", ""], ["Chen", "Weizhu", ""]]}, {"id": "1809.05074", "submitter": "Diego Romeres", "authors": "Diego Romeres, Mattia Zorzi, Raffaello Camoriano, Silvio Traversaro\n  and Alessandro Chiuso", "title": "Derivative-free online learning of inverse dynamics models", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses online algorithms for inverse dynamics modelling in\nrobotics. Several model classes including rigid body dynamics (RBD) models,\ndata-driven models and semiparametric models (which are a combination of the\nprevious two classes) are placed in a common framework. While model classes\nused in the literature typically exploit joint velocities and accelerations,\nwhich need to be approximated resorting to numerical differentiation schemes,\nin this paper a new `derivative-free' framework is proposed that does not\nrequire this preprocessing step. An extensive experimental study with real data\nfrom the right arm of the iCub robot is presented, comparing different model\nclasses and estimation procedures, showing that the proposed `derivative-free'\nmethods outperform existing methodologies.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 17:29:35 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Romeres", "Diego", ""], ["Zorzi", "Mattia", ""], ["Camoriano", "Raffaello", ""], ["Traversaro", "Silvio", ""], ["Chiuso", "Alessandro", ""]]}, {"id": "1809.05077", "submitter": "Amichai Painsky", "authors": "Amichai Painsky", "title": "MSc Dissertation: Exclusive Row Biclustering for Gene Expression Using a\n  Combinatorial Auction Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of large microarray data has led to a growing interest in\nbiclustering methods in the past decade. Several algorithms have been proposed\nto identify subsets of genes and conditions according to different similarity\nmeasures and under varying constraints. In this paper we focus on the exclusive\nrow biclustering problem for gene expression data sets, in which each row can\nonly be a member of a single bicluster while columns can participate in\nmultiple ones. This type of biclustering may be adequate, for example, for\nclustering groups of cancer patients where each patient (row) is expected to be\ncarrying only a single type of cancer, while each cancer type is associated\nwith multiple (and possibly overlapping) genes (columns). We present a novel\nmethod to identify these exclusive row biclusters through a combination of\nexisting biclustering algorithms and combinatorial auction techniques. We\ndevise an approach for tuning the threshold for our algorithm based on\ncomparison to a null model in the spirit of the Gap statistic approach. We\ndemonstrate our approach on both synthetic and real-world gene expression data\nand show its power in identifying large span non-overlapping rows sub matrices,\nwhile considering their unique nature. The Gap statistic approach succeeds in\nidentifying appropriate thresholds in all our examples.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 17:37:16 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 04:42:48 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Painsky", "Amichai", ""]]}, {"id": "1809.05096", "submitter": "Gregory Palmer", "authors": "Gregory Palmer, Rahul Savani, Karl Tuyls", "title": "Negative Update Intervals in Deep Multi-Agent Reinforcement Learning", "comments": "11 Pages, 6 Figures, AAMAS2019 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Multi-Agent Reinforcement Learning (MA-RL), independent cooperative\nlearners must overcome a number of pathologies to learn optimal joint policies.\nAddressing one pathology often leaves approaches vulnerable towards others. For\ninstance, hysteretic Q-learning addresses miscoordination while leaving agents\nvulnerable towards misleading stochastic rewards. Other methods, such as\nleniency, have proven more robust when dealing with multiple pathologies\nsimultaneously. However, leniency has predominately been studied within the\ncontext of strategic form games (bimatrix games) and fully observable Markov\ngames consisting of a small number of probabilistic state transitions. This\nraises the question of whether these findings scale to more complex domains.\nFor this purpose we implement a temporally extend version of the Climb Game,\nwithin which agents must overcome multiple pathologies simultaneously,\nincluding relative overgeneralisation, stochasticity, the alter-exploration and\nmoving target problems, while learning from a large observation space. We find\nthat existing lenient and hysteretic approaches fail to consistently learn near\noptimal joint-policies in this environment. To address these pathologies we\nintroduce Negative Update Intervals-DDQN (NUI-DDQN), a Deep MA-RL algorithm\nwhich discards episodes yielding cumulative rewards outside the range of\nexpanding intervals. NUI-DDQN consistently gravitates towards optimal\njoint-policies in our environment, overcoming the outlined pathologies.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 15:46:55 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 09:20:12 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 09:34:03 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Palmer", "Gregory", ""], ["Savani", "Rahul", ""], ["Tuyls", "Karl", ""]]}, {"id": "1809.05127", "submitter": "Garrett Goh", "authors": "Khushmeen Sakloth, Wesley Beckner, Jim Pfaendtner, Garrett B. Goh", "title": "IL-Net: Using Expert Knowledge to Guide the Design of Furcated Neural\n  Networks", "comments": "Submitted to peer-reviewed ML conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) excel at extracting patterns. Through\nrepresentation learning and automated feature engineering on large datasets,\nsuch models have been highly successful in computer vision and natural language\napplications. Designing optimal network architectures from a principled or\nrational approach however has been less than successful, with the best\nsuccessful approaches utilizing an additional machine learning algorithm to\ntune the network hyperparameters. However, in many technical fields, there\nexist established domain knowledge and understanding about the subject matter.\nIn this work, we develop a novel furcated neural network architecture that\nutilizes domain knowledge as high-level design principles of the network. We\ndemonstrate proof-of-concept by developing IL-Net, a furcated network for\npredicting the properties of ionic liquids, which is a class of complex\nmulti-chemicals entities. Compared to existing state-of-the-art approaches, we\nshow that furcated networks can improve model accuracy by approximately 20-35%,\nwithout using additional labeled data. Lastly, we distill two key design\nprinciples for furcated networks that can be adapted to other domains.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 18:22:04 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Sakloth", "Khushmeen", ""], ["Beckner", "Wesley", ""], ["Pfaendtner", "Jim", ""], ["Goh", "Garrett B.", ""]]}, {"id": "1809.05139", "submitter": "Johan Ugander", "authors": "Stephen Ragain, Johan Ugander", "title": "Choosing to Rank", "comments": "39 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking data arises in a wide variety of application areas but remains\ndifficult to model, learn from, and predict. Datasets often exhibit\nmultimodality, intransitivity, or incomplete rankings---particularly when\ngenerated by humans---yet popular probabilistic models are often too rigid to\ncapture such complexities. In this work we leverage recent progress on similar\nchallenges in discrete choice modeling to form flexible and tractable\nchoice-based models for ranking data. We study choice representations, maps\nfrom rankings (complete or top-$k$) to collections of choices, as a way of\nforming ranking models from choice models. We focus on the repeated selection\n(RS) choice representation, first used to form the Plackett-Luce ranking model\nfrom the conditional multinomial logit choice model. We fully characterize, for\na prime number of alternatives, the choice representations that admit ranking\ndistributions with unit normalization, a desirably property that greatly\nsimplifies maximum likelihood estimation. We further show that only specific\nminor variations on repeated selection exhibit this property. Our choice-based\nranking models provide higher out-of-sample likelihood when compared to\nPlackett-Luce and Mallows models on a broad collection of ranking tasks\nincluding food preferences, ranked-choice elections, car racing, and search\nengine relevance tasks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 18:43:55 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 05:15:30 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Ragain", "Stephen", ""], ["Ugander", "Johan", ""]]}, {"id": "1809.05142", "submitter": "Ioannis C. Konstantakopoulos", "authors": "Ioannis C. Konstantakopoulos, Andrew R. Barkan, Shiying He, Tanya\n  Veeravalli, Huihan Liu, Costas Spanos", "title": "A Deep Learning and Gamification Approach to Energy Conservation at\n  Nanyang Technological University", "comments": "16 double pages, shorter version submitted to Applied Energy Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The implementation of smart building technology in the form of smart\ninfrastructure applications has great potential to improve sustainability and\nenergy efficiency by leveraging humans-in-the-loop strategy. However, human\npreference in regard to living conditions is usually unknown and heterogeneous\nin its manifestation as control inputs to a building. Furthermore, the\noccupants of a building typically lack the independent motivation necessary to\ncontribute to and play a key role in the control of smart building\ninfrastructure. Moreover, true human actions and their integration with\nsensing/actuation platforms remains unknown to the decision maker tasked with\nimproving operational efficiency. By modeling user interaction as a sequential\ndiscrete game between non-cooperative players, we introduce a gamification\napproach for supporting user engagement and integration in a human-centric\ncyber-physical system. We propose the design and implementation of a\nlarge-scale network game with the goal of improving the energy efficiency of a\nbuilding through the utilization of cutting-edge Internet of Things (IoT)\nsensors and cyber-physical systems sensing/actuation platforms. A benchmark\nutility learning framework that employs robust estimations for classical\ndiscrete choice models provided for the derived high dimensional imbalanced\ndata. To improve forecasting performance, we extend the benchmark utility\nlearning scheme by leveraging Deep Learning end-to-end training with Deep\nbi-directional Recurrent Neural Networks. We apply the proposed methods to high\ndimensional data from a social game experiment designed to encourage energy\nefficient behavior among smart building occupants in Nanyang Technological\nUniversity (NTU) residential housing. Using occupant-retrieved actions for\nresources such as lighting and A/C, we simulate the game defined by the\nestimated utility functions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 18:52:16 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 19:09:19 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Konstantakopoulos", "Ioannis C.", ""], ["Barkan", "Andrew R.", ""], ["He", "Shiying", ""], ["Veeravalli", "Tanya", ""], ["Liu", "Huihan", ""], ["Spanos", "Costas", ""]]}, {"id": "1809.05143", "submitter": "Nikita Klyuchnikov", "authors": "Nikita Klyuchnikov and Evgeny Burnaev", "title": "Gaussian Process Classification for Variable Fidelity Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address a classification problem where two sources of labels\nwith different levels of fidelity are available. Our approach is to combine\ndata from both sources by applying a co-kriging schema on latent functions,\nwhich allows the model to account item-dependent labeling discrepancy. We\nprovide an extension of Laplace inference for Gaussian process classification,\nthat takes into account multi-fidelity data. We evaluate the proposed method on\nreal and synthetic datasets and show that it is more resistant to different\nlevels of discrepancy between sources than other approaches for data fusion.\nOur method can provide accuracy/cost trade-off for a number of practical tasks\nsuch as crowd-sourced data annotation and feasibility regions construction in\nengineering design.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 18:59:37 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 10:24:10 GMT"}, {"version": "v3", "created": "Sat, 19 Oct 2019 20:48:04 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Klyuchnikov", "Nikita", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1809.05152", "submitter": "Dominik Baumann", "authors": "Dominik Baumann and Jia-Jie Zhu and Georg Martius and Sebastian Trimpe", "title": "Deep Reinforcement Learning for Event-Triggered Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event-triggered control (ETC) methods can achieve high-performance control\nwith a significantly lower number of samples compared to usual, time-triggered\nmethods. These frameworks are often based on a mathematical model of the system\nand specific designs of controller and event trigger. In this paper, we show\nhow deep reinforcement learning (DRL) algorithms can be leveraged to\nsimultaneously learn control and communication behavior from scratch, and\npresent a DRL approach that is particularly suitable for ETC. To our knowledge,\nthis is the first work to apply DRL to ETC. We validate the approach on\nmultiple control tasks and compare it to model-based event-triggering\nframeworks. In particular, we demonstrate that it can, other than many\nmodel-based ETC designs, be straightforwardly applied to nonlinear systems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 19:40:00 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Baumann", "Dominik", ""], ["Zhu", "Jia-Jie", ""], ["Martius", "Georg", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1809.05165", "submitter": "Siyue Wang", "authors": "Siyue Wang, Xiao Wang, Pu Zhao, Wujie Wen, David Kaeli, Peter Chin,\n  Xue Lin", "title": "Defensive Dropout for Hardening Deep Neural Networks under Adversarial\n  Attacks", "comments": "Accepted as conference paper on ICCAD 2018", "journal-ref": null, "doi": "10.1145/3240765.3264699", "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known vulnerable to adversarial attacks. That\nis, adversarial examples, obtained by adding delicately crafted distortions\nonto original legal inputs, can mislead a DNN to classify them as any target\nlabels. This work provides a solution to hardening DNNs under adversarial\nattacks through defensive dropout. Besides using dropout during training for\nthe best test accuracy, we propose to use dropout also at test time to achieve\nstrong defense effects. We consider the problem of building robust DNNs as an\nattacker-defender two-player game, where the attacker and the defender know\neach others' strategies and try to optimize their own strategies towards an\nequilibrium. Based on the observations of the effect of test dropout rate on\ntest accuracy and attack success rate, we propose a defensive dropout algorithm\nto determine an optimal test dropout rate given the neural network model and\nthe attacker's strategy for generating adversarial examples.We also investigate\nthe mechanism behind the outstanding defense effects achieved by the proposed\ndefensive dropout. Comparing with stochastic activation pruning (SAP), another\ndefense method through introducing randomness into the DNN model, we find that\nour defensive dropout achieves much larger variances of the gradients, which is\nthe key for the improved defense effects (much lower attack success rate). For\nexample, our defensive dropout can reduce the attack success rate from 100% to\n13.89% under the currently strongest attack i.e., C&W attack on MNIST dataset.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 20:26:32 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Wang", "Siyue", ""], ["Wang", "Xiao", ""], ["Zhao", "Pu", ""], ["Wen", "Wujie", ""], ["Kaeli", "David", ""], ["Chin", "Peter", ""], ["Lin", "Xue", ""]]}, {"id": "1809.05173", "submitter": "Jan Van Haaren", "authors": "Bart Aalbers, Jan Van Haaren", "title": "Distinguishing Between Roles of Football Players in Play-by-play Match\n  Event Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few decades, the player recruitment process in professional\nfootball has evolved into a multi-billion industry and has thus become of vital\nimportance. To gain insights into the general level of their candidate\nreinforcements, many professional football clubs have access to extensive video\nfootage and advanced statistics. However, the question whether a given player\nwould fit the team's playing style often still remains unanswered. In this\npaper, we aim to bridge that gap by proposing a set of 21 player roles and\nintroducing a method for automatically identifying the most applicable roles\nfor each player from play-by-play event data collected during matches.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 20:43:40 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Aalbers", "Bart", ""], ["Van Haaren", "Jan", ""]]}, {"id": "1809.05183", "submitter": "Isak Karlsson", "authors": "Isak Karlsson, Jonathan Rebane, Panagiotis Papapetrou, Aristides\n  Gionis", "title": "Explainable time series tweaking via irreversible and reversible\n  temporal transformations", "comments": "To appear in International Conference on Data Mining, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series classification has received great attention over the past decade\nwith a wide range of methods focusing on predictive performance by exploiting\nvarious types of temporal features. Nonetheless, little emphasis has been\nplaced on interpretability and explainability. In this paper, we formulate the\nnovel problem of explainable time series tweaking, where, given a time series\nand an opaque classifier that provides a particular classification decision for\nthe time series, we want to find the minimum number of changes to be performed\nto the given time series so that the classifier changes its decision to another\nclass. We show that the problem is NP-hard, and focus on two instantiations of\nthe problem, which we refer to as reversible and irreversible time series\ntweaking. The classifier under investigation is the random shapelet forest\nclassifier. Moreover, we propose two algorithmic solutions for the two problems\nalong with simple optimizations, as well as a baseline solution using the\nnearest neighbor classifier. An extensive experimental evaluation on a variety\nof real datasets demonstrates the usefulness and effectiveness of our problem\nformulation and solutions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 21:35:04 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Karlsson", "Isak", ""], ["Rebane", "Jonathan", ""], ["Papapetrou", "Panagiotis", ""], ["Gionis", "Aristides", ""]]}, {"id": "1809.05188", "submitter": "Jiachen Yang", "authors": "Jiachen Yang, Alireza Nakhaei, David Isele, Kikuo Fujimura, Hongyuan\n  Zha", "title": "CM3: Cooperative Multi-goal Multi-stage Multi-agent Reinforcement\n  Learning", "comments": "Published at International Conference on Learning Representations\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of cooperative multi-agent control problems require agents to\nachieve individual goals while contributing to collective success. This\nmulti-goal multi-agent setting poses difficulties for recent algorithms, which\nprimarily target settings with a single global reward, due to two new\nchallenges: efficient exploration for learning both individual goal attainment\nand cooperation for others' success, and credit-assignment for interactions\nbetween actions and goals of different agents. To address both challenges, we\nrestructure the problem into a novel two-stage curriculum, in which\nsingle-agent goal attainment is learned prior to learning multi-agent\ncooperation, and we derive a new multi-goal multi-agent policy gradient with a\ncredit function for localized credit assignment. We use a function augmentation\nscheme to bridge value and policy functions across the curriculum. The complete\narchitecture, called CM3, learns significantly faster than direct adaptations\nof existing algorithms on three challenging multi-goal multi-agent problems:\ncooperative navigation in difficult formations, negotiating multi-vehicle lane\nchanges in the SUMO traffic simulator, and strategic cooperation in a Checkers\nenvironment.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 21:46:54 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 05:04:45 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 21:24:17 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Yang", "Jiachen", ""], ["Nakhaei", "Alireza", ""], ["Isele", "David", ""], ["Fujimura", "Kikuo", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1809.05193", "submitter": "Rohan Bavishi", "authors": "Rohan Bavishi, Michael Pradel, Koushik Sen", "title": "Context2Name: A Deep Learning-Based Approach to Infer Natural Variable\n  Names from Usage Contexts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the JavaScript code deployed in the wild has been minified, a process\nin which identifier names are replaced with short, arbitrary and meaningless\nnames. Minified code occupies less space, but also makes the code extremely\ndifficult to manually inspect and understand. This paper presents Context2Name,\na deep learningbased technique that partially reverses the effect of\nminification by predicting natural identifier names for minified names. The\ncore idea is to predict from the usage context of a variable a name that\ncaptures the meaning of the variable. The approach combines a lightweight,\ntoken-based static analysis with an auto-encoder neural network that summarizes\nusage contexts and a recurrent neural network that predict natural names for a\ngiven usage context. We evaluate Context2Name with a large corpus of real-world\nJavaScript code and show that it successfully predicts 47.5% of all minified\nidentifiers while taking only 2.9 milliseconds on average to predict a name. A\ncomparison with the state-of-the-art tools JSNice and JSNaughty shows that our\napproach performs comparably in terms of accuracy while improving in terms of\nefficiency. Moreover, Context2Name complements the state-of-the-art by\npredicting 5.3% additional identifiers that are missed by both existing tools.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 20:52:10 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Bavishi", "Rohan", ""], ["Pradel", "Michael", ""], ["Sen", "Koushik", ""]]}, {"id": "1809.05214", "submitter": "Ignasi Clavera", "authors": "Ignasi Clavera, Jonas Rothfuss, John Schulman, Yasuhiro Fujita, Tamim\n  Asfour, Pieter Abbeel", "title": "Model-Based Reinforcement Learning via Meta-Policy Optimization", "comments": "First 2 authors contributed equally. Accepted for Conference on Robot\n  Learning (CoRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning approaches carry the promise of being data\nefficient. However, due to challenges in learning dynamics models that\nsufficiently match the real-world dynamics, they struggle to achieve the same\nasymptotic performance as model-free methods. We propose Model-Based\nMeta-Policy-Optimization (MB-MPO), an approach that foregoes the strong\nreliance on accurate learned dynamics models. Using an ensemble of learned\ndynamic models, MB-MPO meta-learns a policy that can quickly adapt to any model\nin the ensemble with one policy gradient step. This steers the meta-policy\ntowards internalizing consistent dynamics predictions among the ensemble while\nshifting the burden of behaving optimally w.r.t. the model discrepancies\ntowards the adaptation step. Our experiments show that MB-MPO is more robust to\nmodel imperfections than previous model-based approaches. Finally, we\ndemonstrate that our approach is able to match the asymptotic performance of\nmodel-free methods while requiring significantly less experience.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 01:15:28 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Clavera", "Ignasi", ""], ["Rothfuss", "Jonas", ""], ["Schulman", "John", ""], ["Fujita", "Yasuhiro", ""], ["Asfour", "Tamim", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1809.05241", "submitter": "Carlos H. C. Teixeira", "authors": "Carlos H. C. Teixeira, Leonardo Cotta, Bruno Ribeiro, Wagner Meira Jr", "title": "Graph Pattern Mining and Learning through User-defined Relations\n  (Extended Version)", "comments": "Extended version of the paper published in the ICDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose R-GPM, a parallel computing framework for graph\npattern mining (GPM) through a user-defined subgraph relation. More\nspecifically, we enable the computation of statistics of patterns through their\nsubgraph classes, generalizing traditional GPM methods. R-GPM provides\nefficient estimators for these statistics by employing a MCMC sampling\nalgorithm combined with several optimizations. We provide both theoretical\nguarantees and empirical evaluations of our estimators in application scenarios\nsuch as stochastic optimization of deep high-order graph neural network models\nand pattern (motif) counting. We also propose and evaluate optimizations that\nenable improvements of our estimators accuracy, while reducing their\ncomputational costs in up to 3-orders-of-magnitude. Finally,we show that R-GPM\nis scalable, providing near-linear speedups on 44 cores in all of our tests.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 03:16:09 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 20:45:41 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Teixeira", "Carlos H. C.", ""], ["Cotta", "Leonardo", ""], ["Ribeiro", "Bruno", ""], ["Meira", "Wagner", "Jr"]]}, {"id": "1809.05242", "submitter": "Ryan Robinett", "authors": "Ryan A. Robinett and Jeremy Kepner", "title": "Neural Network Topologies for Sparse Training", "comments": "4 Pages, 4 figures; accepted at MIT IEEE Undergraduate Research\n  Technology Conference 2018. Publication pending", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sizes of deep neural networks (DNNs) are rapidly outgrowing the capacity\nof hardware to store and train them. Research over the past few decades has\nexplored the prospect of sparsifying DNNs before, during, and after training by\npruning edges from the underlying topology. The resulting neural network is\nknown as a sparse neural network. More recent work has demonstrated the\nremarkable result that certain sparse DNNs can train to the same precision as\ndense DNNs at lower runtime and storage cost. An intriguing class of these\nsparse DNNs is the X-Nets, which are initialized and trained upon a sparse\ntopology with neither reference to a parent dense DNN nor subsequent pruning.\nWe present an algorithm that deterministically generates sparse DNN topologies\nthat, as a whole, are much more diverse than X-Net topologies, while preserving\nX-Nets' desired characteristics.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 03:19:04 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Robinett", "Ryan A.", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1809.05247", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Ian E.H. Yen, Jie Chen, and Rui Yan", "title": "Revisiting Random Binning Features: Fast Convergence and Strong\n  Parallelizability", "comments": "KDD16, Oral Paper, Add Code Link for generating Random Binning\n  Features", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel method has been developed as one of the standard approaches for\nnonlinear learning, which however, does not scale to large data set due to its\nquadratic complexity in the number of samples. A number of kernel approximation\nmethods have thus been proposed in the recent years, among which the random\nfeatures method gains much popularity due to its simplicity and direct\nreduction of nonlinear problem to a linear one. The Random Binning (RB)\nfeature, proposed in the first random-feature paper \\cite{rahimi2007random},\nhas drawn much less attention than the Random Fourier (RF) feature. In this\nwork, we observe that the RB features, with right choice of optimization\nsolver, could be orders-of-magnitude more efficient than other random features\nand kernel approximation methods under the same requirement of accuracy. We\nthus propose the first analysis of RB from the perspective of optimization,\nwhich by interpreting RB as a Randomized Block Coordinate Descent in the\ninfinite-dimensional space, gives a faster convergence rate compared to that of\nother random features. In particular, we show that by drawing $R$ random grids\nwith at least $\\kappa$ number of non-empty bins per grid in expectation, RB\nmethod achieves a convergence rate of $O(1/(\\kappa R))$, which not only\nsharpens its $O(1/\\sqrt{R})$ rate from Monte Carlo analysis, but also shows a\n$\\kappa$ times speedup over other random features under the same analysis\nframework. In addition, we demonstrate another advantage of RB in the\nL1-regularized setting, where unlike other random features, a RB-based\nCoordinate Descent solver can be parallelized with guaranteed speedup\nproportional to $\\kappa$. Our extensive experiments demonstrate the superior\nperformance of the RB features over other random features and kernel\napproximation methods. Our code and data is available at {\n\\url{https://github.com/teddylfwu/RB_GEN}}.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 04:06:35 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 02:49:53 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Wu", "Lingfei", ""], ["Yen", "Ian E. H.", ""], ["Chen", "Jie", ""], ["Yan", "Rui", ""]]}, {"id": "1809.05250", "submitter": "Mehmet Necip Kurt", "authors": "Mehmet Necip Kurt and Yasin Yilmaz and Xiaodong Wang", "title": "Real-Time Nonparametric Anomaly Detection in High-Dimensional Settings", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2020", "doi": "10.1109/TPAMI.2020.2970410", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely detection of abrupt anomalies is crucial for real-time monitoring and\nsecurity of modern systems producing high-dimensional data. With this goal, we\npropose effective and scalable algorithms. Proposed algorithms are\nnonparametric as both the nominal and anomalous multivariate data distributions\nare assumed unknown. We extract useful univariate summary statistics and\nperform anomaly detection in a single-dimensional space. We model anomalies as\npersistent outliers and propose to detect them via a cumulative sum-like\nalgorithm. In case the observed data have a low intrinsic dimensionality, we\nlearn a submanifold in which the nominal data are embedded and evaluate whether\nthe sequentially acquired data persistently deviate from the nominal\nsubmanifold. Further, in the general case, we learn an acceptance region for\nnominal data via Geometric Entropy Minimization and evaluate whether the\nsequentially observed data persistently fall outside the acceptance region. We\nprovide an asymptotic lower bound and an asymptotic approximation for the\naverage false alarm period of the proposed algorithm. Moreover, we provide a\nsufficient condition to asymptotically guarantee that the decision statistic of\nthe proposed algorithm does not diverge in the absence of anomalies.\nExperiments illustrate the effectiveness of the proposed schemes in quick and\naccurate anomaly detection in high-dimensional settings.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 04:21:58 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 21:59:43 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kurt", "Mehmet Necip", ""], ["Yilmaz", "Yasin", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1809.05255", "submitter": "Lingfei Wu", "authors": "Kun Xu, Lingfei Wu, Zhiguo Wang, Yansong Feng, Vadim Sheinin", "title": "SQL-to-Text Generation with Graph-to-Sequence Model", "comments": "EMNLP18, Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work approaches the SQL-to-text generation task using vanilla\nSeq2Seq models, which may not fully capture the inherent graph-structured\ninformation in SQL query. In this paper, we first introduce a strategy to\nrepresent the SQL query as a directed graph and then employ a graph-to-sequence\nmodel to encode the global structure information into node embeddings. This\nmodel can effectively learn the correlation between the SQL query pattern and\nits interpretation. Experimental results on the WikiSQL dataset and\nStackoverflow dataset show that our model significantly outperforms the Seq2Seq\nand Tree2Seq baselines, achieving the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 05:00:40 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 22:32:16 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Xu", "Kun", ""], ["Wu", "Lingfei", ""], ["Wang", "Zhiguo", ""], ["Feng", "Yansong", ""], ["Sheinin", "Vadim", ""]]}, {"id": "1809.05258", "submitter": "Mehmet Necip Kurt", "authors": "Mehmet Necip Kurt and Oyetunji Ogundijo and Chong Li and Xiaodong Wang", "title": "Online Cyber-Attack Detection in Smart Grid: A Reinforcement Learning\n  Approach", "comments": null, "journal-ref": "IEEE Transactions on Smart Grid, 2018", "doi": "10.1109/TSG.2018.2878570", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection of cyber-attacks is crucial for a safe and reliable operation\nof the smart grid. In the literature, outlier detection schemes making\nsample-by-sample decisions and online detection schemes requiring perfect\nattack models have been proposed. In this paper, we formulate the online\nattack/anomaly detection problem as a partially observable Markov decision\nprocess (POMDP) problem and propose a universal robust online detection\nalgorithm using the framework of model-free reinforcement learning (RL) for\nPOMDPs. Numerical studies illustrate the effectiveness of the proposed RL-based\nalgorithm in timely and accurate detection of cyber-attacks targeting the smart\ngrid.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 05:17:36 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kurt", "Mehmet Necip", ""], ["Ogundijo", "Oyetunji", ""], ["Li", "Chong", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1809.05259", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Ian En-Hsu Yen, Jinfeng Yi, Fangli Xu, Qi Lei, and Michael\n  Witbrock", "title": "Random Warping Series: A Random Features Method for Time-Series\n  Embedding", "comments": "AIStats18, Oral Paper, Add code link for generating RWS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data analytics has been a problem of substantial interests for\ndecades, and Dynamic Time Warping (DTW) has been the most widely adopted\ntechnique to measure dissimilarity between time series. A number of\nglobal-alignment kernels have since been proposed in the spirit of DTW to\nextend its use to kernel-based estimation method such as support vector\nmachine. However, those kernels suffer from diagonal dominance of the Gram\nmatrix and a quadratic complexity w.r.t. the sample size. In this work, we\nstudy a family of alignment-aware positive definite (p.d.) kernels, with its\nfeature embedding given by a distribution of \\emph{Random Warping Series\n(RWS)}. The proposed kernel does not suffer from the issue of diagonal\ndominance while naturally enjoys a \\emph{Random Features} (RF) approximation,\nwhich reduces the computational complexity of existing DTW-based techniques\nfrom quadratic to linear in terms of both the number and the length of\ntime-series. We also study the convergence of the RF approximation for the\ndomain of time series of unbounded length. Our extensive experiments on 16\nbenchmark datasets demonstrate that RWS outperforms or matches state-of-the-art\nclassification and clustering methods in both accuracy and computational time.\nOur code and data is available at {\n\\url{https://github.com/IBM/RandomWarpingSeries}}.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 05:19:51 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Wu", "Lingfei", ""], ["Yen", "Ian En-Hsu", ""], ["Yi", "Jinfeng", ""], ["Xu", "Fangli", ""], ["Lei", "Qi", ""], ["Witbrock", "Michael", ""]]}, {"id": "1809.05262", "submitter": "Joonsang Yu", "authors": "Joonsang Yu, Sungbum Kang and Kiyoung Choi", "title": "Network Recasting: A Universal Method for Network Architecture\n  Transformation", "comments": "AAAI 2019 Oral presentation, source codes are available on github:\n  https://github.com/joonsang-yu/Network-Recasting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes network recasting as a general method for network\narchitecture transformation. The primary goal of this method is to accelerate\nthe inference process through the transformation, but there can be many other\npractical applications. The method is based on block-wise recasting; it recasts\neach source block in a pre-trained teacher network to a target block in a\nstudent network. For the recasting, a target block is trained such that its\noutput activation approximates that of the source block. Such a block-by-block\nrecasting in a sequential manner transforms the network architecture while\npreserving the accuracy. This method can be used to transform an arbitrary\nteacher network type to an arbitrary student network type. It can even generate\na mixed-architecture network that consists of two or more types of block. The\nnetwork recasting can generate a network with fewer parameters and/or\nactivations, which reduce the inference time significantly. Naturally, it can\nbe used for network compression by recasting a trained network into a smaller\nnetwork of the same type. Our experiments show that it outperforms previous\ncompression approaches in terms of actual speedup on a GPU.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 05:39:15 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 09:38:15 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Yu", "Joonsang", ""], ["Kang", "Sungbum", ""], ["Choi", "Kiyoung", ""]]}, {"id": "1809.05274", "submitter": "Liyuan Xu", "authors": "Liyuan Xu, Junya Honda, Masashi Sugiyama", "title": "Dueling Bandits with Qualitative Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate and study a novel multi-armed bandit problem called the\nqualitative dueling bandit (QDB) problem, where an agent observes not numeric\nbut qualitative feedback by pulling each arm. We employ the same regret as the\ndueling bandit (DB) problem where the duel is carried out by comparing the\nqualitative feedback. Although we can naively use classic DB algorithms for\nsolving the QDB problem, this reduction significantly worsens the\nperformance---actually, in the QDB problem, the probability that one arm wins\nthe duel over another arm can be directly estimated without carrying out actual\nduels. In this paper, we propose such direct algorithms for the QDB problem.\nOur theoretical analysis shows that the proposed algorithms significantly\noutperform DB algorithms by incorporating the qualitative feedback, and\nexperimental results also demonstrate vast improvement over the existing DB\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 06:40:35 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 00:25:28 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Xu", "Liyuan", ""], ["Honda", "Junya", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1809.05284", "submitter": "Hiroshi Takahashi", "authors": "Hiroshi Takahashi, Tomoharu Iwata, Yuki Yamanaka, Masanori Yamada,\n  Satoshi Yagi", "title": "Variational Autoencoder with Implicit Optimal Priors", "comments": "9 pages, 9 figures, accepted at AAAI 2019. Code is available at\n  https://github.com/takahashihiroshi/vae_iop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder (VAE) is a powerful generative model that can\nestimate the probability of a data point by using latent variables. In the VAE,\nthe posterior of the latent variable given the data point is regularized by the\nprior of the latent variable using Kullback Leibler (KL) divergence. Although\nthe standard Gaussian distribution is usually used for the prior, this simple\nprior incurs over-regularization. As a sophisticated prior, the aggregated\nposterior has been introduced, which is the expectation of the posterior over\nthe data distribution. This prior is optimal for the VAE in terms of maximizing\nthe training objective function. However, KL divergence with the aggregated\nposterior cannot be calculated in a closed form, which prevents us from using\nthis optimal prior. With the proposed method, we introduce the density ratio\ntrick to estimate this KL divergence without modeling the aggregated posterior\nexplicitly. Since the density ratio trick does not work well in high\ndimensions, we rewrite this KL divergence that contains the high-dimensional\ndensity ratio into the sum of the analytically calculable term and the\nlow-dimensional density ratio term, to which the density ratio trick is\napplied. Experiments on various datasets show that the VAE with this implicit\noptimal prior achieves high density estimation performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 07:30:31 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 00:43:25 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Takahashi", "Hiroshi", ""], ["Iwata", "Tomoharu", ""], ["Yamanaka", "Yuki", ""], ["Yamada", "Masanori", ""], ["Yagi", "Satoshi", ""]]}, {"id": "1809.05292", "submitter": "Zaiyi Chen", "authors": "Zaiyi Chen", "title": "Efficient Rank Minimization via Solving Non-convexPenalties by Iterative\n  Shrinkage-Thresholding Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rank minimization (RM) is a wildly investigated task of finding solutions by\nexploiting low-rank structure of parameter matrices. Recently, solving RM\nproblem by leveraging non-convex relaxations has received significant\nattention. It has been demonstrated by some theoretical and experimental work\nthat non-convex relaxation, e.g. Truncated Nuclear Norm Regularization (TNNR)\nand Reweighted Nuclear Norm Regularization (RNNR), can provide a better\napproximation of original problems than convex relaxations. However, designing\nan efficient algorithm with theoretical guarantee remains a challenging\nproblem. In this paper, we propose a simple but efficient proximal-type method,\nnamely Iterative Shrinkage-Thresholding Algorithm(ISTA), with concrete analysis\nto solve rank minimization problems with both non-convex weighted and\nreweighted nuclear norm as low-rank regularizers. Theoretically, the proposed\nmethod could converge to the critical point under very mild assumptions with\nthe rate in the order of $O(1/T)$. Moreover, the experimental results on both\nsynthetic data and real world data sets show that proposed algorithm\noutperforms state-of-arts in both efficiency and accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 07:58:03 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Chen", "Zaiyi", ""]]}, {"id": "1809.05398", "submitter": "Kai Xu", "authors": "Chenyang Zhu, Kai Xu, Siddhartha Chaudhuri, Renjiao Yi, Hao Zhang", "title": "SCORES: Shape Composition with Recursive Substructure Priors", "comments": "Accepted to SIGGRAPH Asia 2018. Corresponding Author: Kai Xu\n  (kevin.kai.xu@gmail.com)", "journal-ref": "ACM Transactions on Graphics, 2018", "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SCORES, a recursive neural network for shape composition. Our\nnetwork takes as input sets of parts from two or more source 3D shapes and a\nrough initial placement of the parts. It outputs an optimized part structure\nfor the composed shape, leading to high-quality geometry construction. A unique\nfeature of our composition network is that it is not merely learning how to\nconnect parts. Our goal is to produce a coherent and plausible 3D shape,\ndespite large incompatibilities among the input parts. The network may\nsignificantly alter the geometry and structure of the input parts and\nsynthesize a novel shape structure based on the inputs, while adding or\nremoving parts to minimize a structure plausibility loss. We design SCORES as a\nrecursive autoencoder network. During encoding, the input parts are recursively\ngrouped to generate a root code. During synthesis, the root code is decoded,\nrecursively, to produce a new, coherent part assembly. Assembled shape\nstructures may be novel, with little global resemblance to training exemplars,\nyet have plausible substructures. SCORES therefore learns a hierarchical\nsubstructure shape prior based on per-node losses. It is trained on structured\nshapes from ShapeNet, and is applied iteratively to reduce the plausibility\nloss.We showresults of shape composition from multiple sources over different\ncategories of man-made shapes and compare with state-of-the-art alternatives,\ndemonstrating that our network can significantly expand the range of composable\nshapes for assembly-based modeling.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 13:20:06 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Zhu", "Chenyang", ""], ["Xu", "Kai", ""], ["Chaudhuri", "Siddhartha", ""], ["Yi", "Renjiao", ""], ["Zhang", "Hao", ""]]}, {"id": "1809.05465", "submitter": "Mingyuan Wang", "authors": "Mingyuan Wang, Adrian Barbu", "title": "Are screening methods useful in feature selection? An empirical study", "comments": "29 pages, 4 figures, 21 tables", "journal-ref": "PLoS One, 09/11/2019", "doi": "10.1371/journal.pone.0220842", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filter or screening methods are often used as a preprocessing step for\nreducing the number of variables used by a learning algorithm in obtaining a\nclassification or regression model. While there are many such filter methods,\nthere is a need for an objective evaluation of these methods. Such an\nevaluation is needed to compare them with each other and also to answer whether\nthey are at all useful, or a learning algorithm could do a better job without\nthem. For this purpose, many popular screening methods are partnered in this\npaper with three regression learners and five classification learners and\nevaluated on ten real datasets to obtain accuracy criteria such as R-square and\narea under the ROC curve (AUC). The obtained results are compared through curve\nplots and comparison tables in order to find out whether screening methods help\nimprove the performance of learning algorithms and how they fare with each\nother. Our findings revealed that the screening methods were useful in\nimproving the prediction of the best learner on two regression and two\nclassification datasets out of the ten datasets evaluated.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 15:21:53 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 15:36:17 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 02:12:27 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Wang", "Mingyuan", ""], ["Barbu", "Adrian", ""]]}, {"id": "1809.05476", "submitter": "Dimitrios Stamoulis", "authors": "Diana Marculescu, Dimitrios Stamoulis, Ermao Cai", "title": "Hardware-Aware Machine Learning: Modeling and Optimization", "comments": "ICCAD'18 Invited Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in Deep Learning (DL) applications have made DL models a\nkey component in almost every modern computing system. The increased popularity\nof DL applications deployed on a wide-spectrum of platforms have resulted in a\nplethora of design challenges related to the constraints introduced by the\nhardware itself. What is the latency or energy cost for an inference made by a\nDeep Neural Network (DNN)? Is it possible to predict this latency or energy\nconsumption before a model is trained? If yes, how can machine learners take\nadvantage of these models to design the hardware-optimal DNN for deployment?\nFrom lengthening battery life of mobile devices to reducing the runtime\nrequirements of DL models executing in the cloud, the answers to these\nquestions have drawn significant attention.\n  One cannot optimize what isn't properly modeled. Therefore, it is important\nto understand the hardware efficiency of DL models during serving for making an\ninference, before even training the model. This key observation has motivated\nthe use of predictive models to capture the hardware performance or energy\nefficiency of DL applications. Furthermore, DL practitioners are challenged\nwith the task of designing the DNN model, i.e., of tuning the hyper-parameters\nof the DNN architecture, while optimizing for both accuracy of the DL model and\nits hardware efficiency. Therefore, state-of-the-art methodologies have\nproposed hardware-aware hyper-parameter optimization techniques. In this paper,\nwe provide a comprehensive assessment of state-of-the-art work and selected\nresults on the hardware-aware modeling and optimization for DL applications. We\nalso highlight several open questions that are poised to give rise to novel\nhardware-aware designs in the next few years, as DL applications continue to\nsignificantly impact associated hardware systems and platforms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 15:53:14 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Marculescu", "Diana", ""], ["Stamoulis", "Dimitrios", ""], ["Cai", "Ermao", ""]]}, {"id": "1809.05483", "submitter": "Leonardo Gabrielli", "authors": "Leonardo Gabrielli, Stefano Tomassetti, Stefano Squartini, Carlo\n  Zinato, Stefano Guaiana", "title": "A Multi-Stage Algorithm for Acoustic Physical Model Parameters\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in computational acoustics is the identification of\nmodels that can simulate and predict the physical behavior of a system\ngenerating an acoustic signal. Whenever such models are used for commercial\napplications an additional constraint is the time-to-market, making automation\nof the sound design process desirable. In previous works, a computational sound\ndesign approach has been proposed for the parameter estimation problem\ninvolving timbre matching by deep learning, which was applied to the synthesis\nof pipe organ tones. In this work we refine previous results by introducing the\nformer approach in a multi-stage algorithm that also adds heuristics and a\nstochastic optimization method operating on objective cost functions based on\npsychoacoustics. The optimization method shows to be able to refine the first\nestimate given by the deep learning approach and substantially improve the\nobjective metrics, with the additional benefit of reducing the sound design\nprocess time. Subjective listening tests are also conducted to gather\nadditional insights on the results.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 16:05:51 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 14:39:56 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Gabrielli", "Leonardo", ""], ["Tomassetti", "Stefano", ""], ["Squartini", "Stefano", ""], ["Zinato", "Carlo", ""], ["Guaiana", "Stefano", ""]]}, {"id": "1809.05495", "submitter": "F\\'elix Cuadrado", "authors": "Luis M. Vaquero, Felix Cuadrado", "title": "Auto-tuning Distributed Stream Processing Systems using Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine tuning distributed systems is considered to be a craftsmanship, relying\non intuition and experience. This becomes even more challenging when the\nsystems need to react in near real time, as streaming engines have to do to\nmaintain pre-agreed service quality metrics. In this article, we present an\nautomated approach that builds on a combination of supervised and reinforcement\nlearning methods to recommend the most appropriate lever configurations based\non previous load. With this, streaming engines can be automatically tuned\nwithout requiring a human to determine the right way and proper time to deploy\nthem. This opens the door to new configurations that are not being applied\ntoday since the complexity of managing these systems has surpassed the\nabilities of human experts. We show how reinforcement learning systems can find\nsubstantially better configurations in less time than their human counterparts\nand adapt to changing workloads.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 16:36:05 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Vaquero", "Luis M.", ""], ["Cuadrado", "Felix", ""]]}, {"id": "1809.05504", "submitter": "Bryan Wilder", "authors": "Bryan Wilder, Bistra Dilkina, Milind Tambe", "title": "Melding the Data-Decisions Pipeline: Decision-Focused Learning for\n  Combinatorial Optimization", "comments": "Full version of paper accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating impact in real-world settings requires artificial intelligence\ntechniques to span the full pipeline from data, to predictive models, to\ndecisions. These components are typically approached separately: a machine\nlearning model is first trained via a measure of predictive accuracy, and then\nits predictions are used as input into an optimization algorithm which produces\na decision. However, the loss function used to train the model may easily be\nmisaligned with the end goal, which is to make the best decisions possible.\nHand-tuning the loss function to align with optimization is a difficult and\nerror-prone process (which is often skipped entirely).\n  We focus on combinatorial optimization problems and introduce a general\nframework for decision-focused learning, where the machine learning model is\ndirectly trained in conjunction with the optimization algorithm to produce\nhigh-quality decisions. Technically, our contribution is a means of integrating\ncommon classes of discrete optimization problems into deep learning or other\npredictive models, which are typically trained via gradient descent. The main\nidea is to use a continuous relaxation of the discrete problem to propagate\ngradients through the optimization procedure. We instantiate this framework for\ntwo broad classes of combinatorial problems: linear programs and submodular\nmaximization. Experimental results across a variety of domains show that\ndecision-focused learning often leads to improved optimization performance\ncompared to traditional methods. We find that standard measures of accuracy are\nnot a reliable proxy for a predictive model's utility in optimization, and our\nmethod's ability to specify the true goal as the model's training objective\nyields substantial dividends across a range of decision problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 17:08:04 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 00:14:56 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Wilder", "Bryan", ""], ["Dilkina", "Bistra", ""], ["Tambe", "Milind", ""]]}, {"id": "1809.05525", "submitter": "Pantita Palittapongarnpim", "authors": "Pantita Palittapongarnpim and Barry C. Sanders", "title": "Robustness of Quantum-Enhanced Adaptive Phase Estimation", "comments": "15 pages, 2 figures, 2 tables", "journal-ref": "Phys. Rev. A 100, 012106 (2019)", "doi": "10.1103/PhysRevA.100.012106", "report-no": null, "categories": "quant-ph cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As all physical adaptive quantum-enhanced metrology schemes operate under\nnoisy conditions with only partially understood noise characteristics, so a\npractical control policy must be robust even for unknown noise. We aim to\ndevise a test to evaluate the robustness of AQEM policies and assess the\nresource used by the policies. The robustness test is performed on QEAPE by\nsimulating the scheme under four phase-noise models corresponding to\nnormal-distribution noise, random-telegraph noise, skew-normal-distribution\nnoise, and log-normal-distribution noise. Control policies are devised either\nby an evolutionary algorithm under the same noisy conditions, albeit ignorant\nof its properties, or a Bayesian-based feedback method that assumes no noise.\nOur robustness test and resource comparison method can be used to determining\nthe efficacy and selecting a suitable policy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 17:56:25 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 02:44:02 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Palittapongarnpim", "Pantita", ""], ["Sanders", "Barry C.", ""]]}, {"id": "1809.05527", "submitter": "Y Cooper", "authors": "Y. Cooper", "title": "Gradient descent in higher codimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the behavior of gradient flow and of discrete and noisy gradient\ndescent. It is commonly noted that the addition of noise to the process of\ndiscrete gradient descent can affect the trajectory of gradient descent. In\nprevious work, we observed such effects. There, we considered the case where\nthe minima had codimension 1. In this note, we do some computer experiments and\nobserve the behavior of noisy gradient descent in the more complex setting of\nminima of higher codimension.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 17:58:27 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 14:14:44 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Cooper", "Y.", ""]]}, {"id": "1809.05550", "submitter": "Heejin Choi", "authors": "Heejin Choi", "title": "Efficient Structured Surrogate Loss and Regularization in Structured\n  Prediction", "comments": "PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this dissertation, we focus on several important problems in structured\nprediction. In structured prediction, the label has a rich intrinsic\nsubstructure, and the loss varies with respect to the predicted label and the\ntrue label pair. Structured SVM is an extension of binary SVM to adapt to such\nstructured tasks.\n  In the first part of the dissertation, we study the surrogate losses and its\nefficient methods. To minimize the empirical risk, a surrogate loss which upper\nbounds the loss, is used as a proxy to minimize the actual loss. Since the\nobjective function is written in terms of the surrogate loss, the choice of the\nsurrogate loss is important, and the performance depends on it. Another issue\nregarding the surrogate loss is the efficiency of the argmax label inference\nfor the surrogate loss. Efficient inference is necessary for the optimization\nsince it is often the most time-consuming step. We present a new class of\nsurrogate losses named bi-criteria surrogate loss, which is a generalization of\nthe popular surrogate losses. We first investigate an efficient method for a\nslack rescaling formulation as a starting point utilizing decomposability of\nthe model. Then, we extend the algorithm to the bi-criteria surrogate loss,\nwhich is very efficient and also shows performance improvements.\n  In the second part of the dissertation, another important issue of\nregularization is studied. Specifically, we investigate a problem of\nregularization in hierarchical classification when a structural imbalance\nexists in the label structure. We present a method to normalize the structure,\nas well as a new norm, namely shared Frobenius norm. It is suitable for\nhierarchical classification that adapts to the data in addition to the label\nstructure.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 18:11:33 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Choi", "Heejin", ""]]}, {"id": "1809.05551", "submitter": "Brayan Stiven Zapata Impata", "authors": "Brayan S. Zapata-Impata (1 and 2), Pablo Gil (1 and 2), Fernando\n  Torres (1 and 2) ((1) Automatics, Robotics and Artificial Vision Research\n  Group, Dept. of Physics, System Engineering and Signal Theory, University of\n  Alicante, Spain, (2) Computer Science Research Institute, University of\n  Alicante, Spain)", "title": "Non-Matrix Tactile Sensors: How Can Be Exploited Their Local\n  Connectivity For Predicting Grasp Stability?", "comments": "4 pages, 4 figures, to be presented at IEEE/RSJ IROS 2018 Workshop\n  RoboTac: New Progress in Tactile Perception and Learning in Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactile sensors supply useful information during the interaction with an\nobject that can be used for assessing the stability of a grasp. Most of the\nprevious works on this topic processed tactile readings as signals by\ncalculating hand-picked features. Some of them have processed these readings as\nimages calculating characteristics on matrix-like sensors. In this work, we\nexplore how non-matrix sensors (sensors with taxels not arranged exactly in a\nmatrix) can be processed as tactile images as well. In addition, we prove that\nthey can be used for predicting grasp stability by training a Convolutional\nNeural Network (CNN) with them. We captured over 2500 real three-fingered\ngrasps on 41 everyday objects to train a CNN that exploited the local\nconnectivity inherent on the non-matrix tactile sensors, achieving 94.2%\nF1-score on predicting stability.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 18:12:21 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Zapata-Impata", "Brayan S.", "", "1 and 2"], ["Gil", "Pablo", "", "1 and 2"], ["Torres", "Fernando", "", "1 and 2"]]}, {"id": "1809.05578", "submitter": "Fran\\c{c}ois Th\\'eberge", "authors": "Val\\'erie Poulin and Fran\\c{c}ois Th\\'eberge", "title": "Ensemble Clustering for Graphs", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": "10.1007/978-3-030-05411-3_19", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an ensemble clustering algorithm for graphs (ECG), which is based\non the Louvain algorithm and the concept of consensus clustering. We validate\nour approach by replicating a recently published study comparing graph\nclustering algorithms over artificial networks, showing that ECG outperforms\nthe leading algorithms from that study. We also illustrate how the ensemble\nobtained with ECG can be used to quantify the presence of community structure\nin the graph.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 20:38:20 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Poulin", "Val\u00e9rie", ""], ["Th\u00e9berge", "Fran\u00e7ois", ""]]}, {"id": "1809.05596", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran, Jaros{\\l}aw B{\\l}asiok", "title": "The Generic Holdout: Preventing False-Discoveries in Adaptive Data\n  Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive data analysis has posed a challenge to science due to its ability to\ngenerate false hypotheses on moderately large data sets. In general, with\nnon-adaptive data analyses (where queries to the data are generated without\nbeing influenced by answers to previous queries) a data set containing $n$\nsamples may support exponentially many queries in $n$. This number reduces to\nlinearly many under naive adaptive data analysis, and even sophisticated\nremedies such as the Reusable Holdout (Dwork et. al 2015) only allow\nquadratically many queries in $n$.\n  In this work, we propose a new framework for adaptive science which\nexponentially improves on this number of queries under a restricted yet\nscientifically relevant setting, where the goal of the scientist is to find a\nsingle (or a few) true hypotheses about the universe based on the samples. Such\na setting may describe the search for predictive factors of some disease based\non medical data, where the analyst may wish to try a number of predictive\nmodels until a satisfactory one is found.\n  Our solution, the Generic Holdout, involves two simple ingredients: (1) a\npartitioning of the data into a exploration set and a holdout set and (2) a\nlimited exposure strategy for the holdout set. An analyst is free to use the\nexploration set arbitrarily, but when testing hypotheses against the holdout\nset, the analyst only learns the answer to the question: \"Is the given\nhypothesis true (empirically) on the holdout set?\" -- and no more information,\nsuch as \"how well\" the hypothesis fits the holdout set. The resulting scheme is\nimmediate to analyze, but despite its simplicity we do not believe our method\nis obvious, as evidenced by the many violations in practice.\n  Our proposal can be seen as an alternative to pre-registration, and allows\nresearchers to get the benefits of adaptive data analysis without the problems\nof adaptivity.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 21:28:21 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Nakkiran", "Preetum", ""], ["B\u0142asiok", "Jaros\u0142aw", ""]]}, {"id": "1809.05606", "submitter": "Yimin Yang", "authors": "Yimin Yang, Q.M.Jonathan Wu, Xiexing Feng, Thangarajah Akilan", "title": "Non-iterative recomputation of dense layers for performance improvement\n  of DCNN", "comments": "11", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An iterative method of learning has become a paradigm for training deep\nconvolutional neural networks (DCNN). However, utilizing a non-iterative\nlearning strategy can accelerate the training process of the DCNN and\nsurprisingly such approach has been rarely explored by the deep learning (DL)\ncommunity. It motivates this paper to introduce a non-iterative learning\nstrategy that eliminates the backpropagation (BP) at the top dense or fully\nconnected (FC) layers of DCNN, resulting in, lower training time and higher\nperformance. The proposed method exploits the Moore-Penrose Inverse to pull\nback the current residual error to each FC layer, generating well-generalized\nfeatures. Then using the recomputed features, i.e., the new generalized\nfeatures the weights of each FC layer is computed according to the\nMoore-Penrose Inverse. We evaluate the proposed approach on six widely accepted\nobject recognition benchmark datasets: Scene-15, CIFAR-10, CIFAR-100, SUN-397,\nPlaces365, and ImageNet. The experimental results show that the proposed method\nobtains significant improvements over 30 state-of-the-art methods.\nInterestingly, it also indicates that any DCNN with the proposed method can\nprovide better performance than the same network with its original training\nbased on BP.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 22:24:52 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Yang", "Yimin", ""], ["Wu", "Q. M. Jonathan", ""], ["Feng", "Xiexing", ""], ["Akilan", "Thangarajah", ""]]}, {"id": "1809.05630", "submitter": "Raghuram Mandyam Annasamy", "authors": "Raghuram Mandyam Annasamy, Katia Sycara", "title": "Towards Better Interpretability in Deep Q-Networks", "comments": "Accepted at AAAI-19; (16 pages, 18 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning techniques have demonstrated superior performance\nin a wide variety of environments. As improvements in training algorithms\ncontinue at a brisk pace, theoretical or empirical studies on understanding\nwhat these networks seem to learn, are far behind. In this paper we propose an\ninterpretable neural network architecture for Q-learning which provides a\nglobal explanation of the model's behavior using key-value memories, attention\nand reconstructible embeddings. With a directed exploration strategy, our model\ncan reach training rewards comparable to the state-of-the-art deep Q-learning\nmodels. However, results suggest that the features extracted by the neural\nnetwork are extremely shallow and subsequent testing using out-of-sample\nexamples shows that the agent can easily overfit to trajectories seen during\ntraining.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 01:34:27 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 03:06:56 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Annasamy", "Raghuram Mandyam", ""], ["Sycara", "Katia", ""]]}, {"id": "1809.05650", "submitter": "Stephen Pauwels", "authors": "Stephen Pauwels, Toon Calders", "title": "Detecting and Explaining Drifts in Yearly Grant Applications", "comments": "BPI Challenge 2018 - Academic Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the lifetime of a Business Process changes can be made to the\nworkflow, the required resources, required documents, . . . . Different traces\nfrom the same Business Process within a single log file can thus differ\nsubstantially due to these changes. We propose a method that is able to detect\nconcept drift in multivariate log files with a dozen attributes. We test our\napproach on the BPI Challenge 2018 data con- sisting of applications for EU\ndirect payment from farmers in Germany where we use it to detect Concept Drift.\nIn contrast to other methods our algorithm does not require the manual\nselection of the features used to detect drift. Our method first creates a\nmodel that captures the re- lations between attributes and between events of\ndifferent time steps. This model is then used to score every event and trace.\nThese scores can be used to detect outlying cases and concept drift. Thanks to\nthe decomposability of the score we are able to perform detailed root-cause\nanalysis.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 05:06:25 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 08:14:12 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Pauwels", "Stephen", ""], ["Calders", "Toon", ""]]}, {"id": "1809.05662", "submitter": "Jingbin Zhong", "authors": "Jingbin Zhong and Xiaofeng Zhang", "title": "Wasserstein Autoencoders for Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recommender systems have long been investigated in the literature.\nRecently, users' implicit feedback like `click' or `browse' are considered to\nbe able to enhance the recommendation performance. Therefore, a number of\nattempts have been made to resolve this issue. Among them, the variational\nautoencoders (VAE) approach already achieves a superior performance. However,\nthe distributions of the encoded latent variables overlap a lot which may\nrestrict its recommendation ability. To cope with this challenge, this paper\ntries to extend the Wasserstein autoencoders (WAE) for collaborative filtering.\nParticularly, the loss function of the adapted WAE is re-designed by\nintroducing two additional loss terms: (1) the mutual information loss between\nthe distribution of latent variables and the assumed ground truth distribution,\nand (2) the L1 regularization loss introduced to restrict the encoded latent\nvariables to be sparse. Two different cost functions are designed for measuring\nthe distance between the implicit feedback data and its re-generated version of\ndata. Experiments are valuated on three widely adopted data sets, i.e., ML-20M,\nNetflix and LASTFM. Both the baseline and the state-of-the-art approaches are\nchosen for the performance comparison which are Mult-DAE, Mult-VAE, CDAE and\nSlim. The performance of the proposed approach outperforms the compared methods\nwith respect to evaluation criteria Recall@1, Recall@5 and NDCG@10, and this\ndemonstrates the efficacy of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 07:12:24 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 11:08:18 GMT"}, {"version": "v3", "created": "Sat, 6 Apr 2019 06:08:01 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhong", "Jingbin", ""], ["Zhang", "Xiaofeng", ""]]}, {"id": "1809.05689", "submitter": "Matthias Dorfer", "authors": "Matthias Dorfer, Jan Haji\\v{c} Jr., Gerhard Widmer", "title": "Attention as a Perspective for Learning Tempo-invariant Audio Queries", "comments": "The 2018 Joint Workshop on Machine Learning for Music", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current models for audio--sheet music retrieval via multimodal embedding\nspace learning use convolutional neural networks with a fixed-size window for\nthe input audio. Depending on the tempo of a query performance, this window\ncaptures more or less musical content, while notehead density in the score is\nlargely tempo-independent. In this work we address this disparity with a soft\nattention mechanism, which allows the model to encode only those parts of an\naudio excerpt that are most relevant with respect to efficient query codes.\nEmpirical results on classical piano music indicate that attention is\nbeneficial for retrieval performance, and exhibits intuitively appealing\nbehavior.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 10:03:15 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Dorfer", "Matthias", ""], ["Haji\u010d", "Jan", "Jr."], ["Widmer", "Gerhard", ""]]}, {"id": "1809.05693", "submitter": "Annamalai Narayanan", "authors": "Annamalai Narayanan, Charlie Soh, Lihui Chen, Yang Liu and Lipo Wang", "title": "apk2vec: Semi-supervised multi-view representation learning for\n  profiling Android applications", "comments": "International Conference on Data Mining, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building behavior profiles of Android applications (apps) with holistic, rich\nand multi-view information (e.g., incorporating several semantic views of an\napp such as API sequences, system calls, etc.) would help catering downstream\nanalytics tasks such as app categorization, recommendation and malware analysis\nsignificantly better. Towards this goal, we design a semi-supervised\nRepresentation Learning (RL) framework named apk2vec to automatically generate\na compact representation (aka profile/embedding) for a given app. More\nspecifically, apk2vec has the three following unique characteristics which make\nit an excellent choice for largescale app profiling: (1) it encompasses\ninformation from multiple semantic views such as API sequences, permissions,\netc., (2) being a semi-supervised embedding technique, it can make use of\nlabels associated with apps (e.g., malware family or app category labels) to\nbuild high quality app profiles, and (3) it combines RL and feature hashing\nwhich allows it to efficiently build profiles of apps that stream over time\n(i.e., online learning). The resulting semi-supervised multi-view hash\nembeddings of apps could then be used for a wide variety of downstream tasks\nsuch as the ones mentioned above. Our extensive evaluations with more than\n42,000 apps demonstrate that apk2vec's app profiles could significantly\noutperform state-of-the-art techniques in four app analytics tasks namely,\nmalware detection, familial clustering, app clone detection and app\nrecommendation.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 10:37:06 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Narayanan", "Annamalai", ""], ["Soh", "Charlie", ""], ["Chen", "Lihui", ""], ["Liu", "Yang", ""], ["Wang", "Lipo", ""]]}, {"id": "1809.05699", "submitter": "Kutlu Emre  Yilmaz", "authors": "Kutlu Emre Yilmaz, Osman Abul", "title": "Inferring Political Alignments of Twitter Users: A case study on 2017\n  Turkish constitutional referendum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing popularity of Twitter in politics is subject to commercial and\nacademic interest. To fully exploit the merits of this platform, reaching the\ntarget audience with desired political leanings is critical. This paper extends\nthe research on inferring political orientations of Twitter users to the case\nof 2017 Turkish constitutional referendum. After constructing a targeted\ndataset of tweets, we explore several types of potential features to build\naccurate machine learning based predictive models. In our experiments, a\nthree-class support vector machine (SVM) classifier trained on semantic\nfeatures achieves the best accuracy score of 89.9%. Moreover, an SVM classifier\ntrained on full-text features performs better than an SVM classifier trained on\nhashtags, with respective accuracy scores of 89.05% and 85.9%. Relatively high\naccuracy scores obtained by full-text features may point to differences in\nlanguage use, which deserves further research.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 11:04:30 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Yilmaz", "Kutlu Emre", ""], ["Abul", "Osman", ""]]}, {"id": "1809.05710", "submitter": "Masahito Kato", "authors": "Masahiro Kato, Liyuan Xu, Gang Niu, and Masashi Sugiyama", "title": "Alternate Estimation of a Classifier and the Class-Prior from Positive\n  and Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of learning a binary classifier only from positive data\nand unlabeled data (PU learning) and estimating the class-prior in unlabeled\ndata under the case-control scenario. Most of the recent methods of PU learning\nrequire an estimate of the class-prior probability in unlabeled data, and it is\nestimated in advance with another method. However, such a two-step approach\nwhich first estimates the class prior and then trains a classifier may not be\nthe optimal approach since the estimation error of the class-prior is not taken\ninto account when a classifier is trained. In this paper, we propose a novel\nunified approach to estimating the class-prior and training a classifier\nalternately. Our proposed method is simple to implement and computationally\nefficient. Through experiments, we demonstrate the practical usefulness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 12:49:41 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Kato", "Masahiro", ""], ["Xu", "Liyuan", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1809.05717", "submitter": "Thuong Nguyen Canh", "authors": "Thuong Nguyen Canh and Byeungwoo Jeon", "title": "Multi-Scale Deep Compressive Sensing Network", "comments": "4 pages, 4 figures, 2 tables, IEEE International Conference on Visual\n  Communication and Image Processing (VCIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With joint learning of sampling and recovery, the deep learning-based\ncompressive sensing (DCS) has shown significant improvement in performance and\nrunning time reduction. Its reconstructed image, however, losses high-frequency\ncontent especially at low subrates. This happens similarly in the multi-scale\nsampling scheme which also samples more low-frequency components. In this\npaper, we propose a multi-scale DCS convolutional neural network (MS-DCSNet) in\nwhich we convert image signal using multiple scale-based wavelet transform,\nthen capture it through convolution block by block across scales. The initial\nreconstructed image is directly recovered from multi-scale measurements.\nMulti-scale wavelet convolution is utilized to enhance the final reconstruction\nquality. The network is able to learn both multi-scale sampling and multi-scale\nreconstruction, thus results in better reconstruction quality.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 14:05:27 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 10:51:07 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Canh", "Thuong Nguyen", ""], ["Jeon", "Byeungwoo", ""]]}, {"id": "1809.05720", "submitter": "Nicholas Mattei", "authors": "Avinash Balakrishnan, Djallel Bouneffouf, Nicholas Mattei, Francesca\n  Rossi", "title": "Incorporating Behavioral Constraints in Online AI Systems", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI systems that learn through reward feedback about the actions they take are\nincreasingly deployed in domains that have significant impact on our daily\nlife. However, in many cases the online rewards should not be the only guiding\ncriteria, as there are additional constraints and/or priorities imposed by\nregulations, values, preferences, or ethical principles. We detail a novel\nonline agent that learns a set of behavioral constraints by observation and\nuses these learned constraints as a guide when making decisions in an online\nsetting while still being reactive to reward feedback. To define this agent, we\npropose to adopt a novel extension to the classical contextual multi-armed\nbandit setting and we provide a new algorithm called Behavior Constrained\nThompson Sampling (BCTS) that allows for online learning while obeying\nexogenous constraints. Our agent learns a constrained policy that implements\nthe observed behavioral constraints demonstrated by a teacher agent, and then\nuses this constrained policy to guide the reward-based online exploration and\nexploitation. We characterize the upper bound on the expected regret of the\ncontextual bandit algorithm that underlies our agent and provide a case study\nwith real world data in two application domains. Our experiments show that the\ndesigned agent is able to act within the set of behavior constraints without\nsignificantly degrading its overall reward performance.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 14:24:37 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Balakrishnan", "Avinash", ""], ["Bouneffouf", "Djallel", ""], ["Mattei", "Nicholas", ""], ["Rossi", "Francesca", ""]]}, {"id": "1809.05724", "submitter": "Pavan Kapanipathi", "authors": "Xiaoyan Wang, Pavan Kapanipathi, Ryan Musa, Mo Yu, Kartik\n  Talamadupula, Ibrahim Abdelaziz, Maria Chang, Achille Fokoue, Bassem Makni,\n  Nicholas Mattei, Michael Witbrock", "title": "Improving Natural Language Inference Using External Knowledge in the\n  Science Questions Domain", "comments": "9 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference (NLI) is fundamental to many Natural Language\nProcessing (NLP) applications including semantic search and question answering.\nThe NLI problem has gained significant attention thanks to the release of large\nscale, challenging datasets. Present approaches to the problem largely focus on\nlearning-based methods that use only textual information in order to classify\nwhether a given premise entails, contradicts, or is neutral with respect to a\ngiven hypothesis. Surprisingly, the use of methods based on structured\nknowledge -- a central topic in artificial intelligence -- has not received\nmuch attention vis-a-vis the NLI problem. While there are many open knowledge\nbases that contain various types of reasoning information, their use for NLI\nhas not been well explored. To address this, we present a combination of\ntechniques that harness knowledge graphs to improve performance on the NLI\nproblem in the science questions domain. We present the results of applying our\ntechniques on text, graph, and text-to-graph based models, and discuss\nimplications for the use of external knowledge in solving the NLI problem. Our\nmodel achieves the new state-of-the-art performance on the NLI problem over the\nSciTail science questions dataset.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 14:37:46 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 15:50:33 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Wang", "Xiaoyan", ""], ["Kapanipathi", "Pavan", ""], ["Musa", "Ryan", ""], ["Yu", "Mo", ""], ["Talamadupula", "Kartik", ""], ["Abdelaziz", "Ibrahim", ""], ["Chang", "Maria", ""], ["Fokoue", "Achille", ""], ["Makni", "Bassem", ""], ["Mattei", "Nicholas", ""], ["Witbrock", "Michael", ""]]}, {"id": "1809.05781", "submitter": "Bilal Farooq", "authors": "Melvin Wong and Bilal Farooq", "title": "Modelling Latent Travel Behaviour Characteristics with Generative\n  Machine Learning", "comments": "Published in the proceedings of IEEE Intelligent Transportation\n  Systems Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we implement an information-theoretic approach to travel\nbehaviour analysis by introducing a generative modelling framework to identify\ninformative latent characteristics in travel decision making. It involves\ndeveloping a joint tri-partite Bayesian graphical network model using a\nRestricted Boltzmann Machine (RBM) generative modelling framework. We apply\nthis framework on a mode choice survey data to identify abstract latent\nvariables and compare the performance with a traditional latent variable model\nwith specific latent preferences -- safety, comfort, and environmental. Data\ncollected from a joint stated and revealed preference mode choice survey in\nQuebec, Canada were used to calibrate the RBM model. Results show that a\nsignficant impact on model likelihood statistics and suggests that machine\nlearning tools are highly suitable for modelling complex networks of\nconditional independent behaviour interactions.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 23:57:34 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Wong", "Melvin", ""], ["Farooq", "Bilal", ""]]}, {"id": "1809.05786", "submitter": "Yasin Almalioglu", "authors": "Yasin Almalioglu, Muhamad Risqi U. Saputra, Pedro P. B. de Gusmao,\n  Andrew Markham, Niki Trigoni", "title": "GANVO: Unsupervised Deep Monocular Visual Odometry and Depth Estimation\n  with Generative Adversarial Networks", "comments": "ICRA 2019 - accepted", "journal-ref": "2019 International Conference on Robotics and Automation (ICRA)", "doi": "10.1109/ICRA.2019.8793512", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, supervised deep learning approaches have been extensively\nemployed in visual odometry (VO) applications, which is not feasible in\nenvironments where labelled data is not abundant. On the other hand,\nunsupervised deep learning approaches for localization and mapping in unknown\nenvironments from unlabelled data have received comparatively less attention in\nVO research. In this study, we propose a generative unsupervised learning\nframework that predicts 6-DoF pose camera motion and monocular depth map of the\nscene from unlabelled RGB image sequences, using deep convolutional Generative\nAdversarial Networks (GANs). We create a supervisory signal by warping view\nsequences and assigning the re-projection minimization to the objective loss\nfunction that is adopted in multi-view pose estimation and single-view depth\ngeneration network. Detailed quantitative and qualitative evaluations of the\nproposed framework on the KITTI and Cityscapes datasets show that the proposed\nmethod outperforms both existing traditional and unsupervised deep VO methods\nproviding better results for both pose estimation and depth recovery.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 00:27:09 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 14:01:53 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 12:45:15 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Almalioglu", "Yasin", ""], ["Saputra", "Muhamad Risqi U.", ""], ["de Gusmao", "Pedro P. B.", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1809.05788", "submitter": "Bilal Farooq", "authors": "Arash Kalatian and Bilal Farooq", "title": "Mobility Mode Detection Using WiFi Signals", "comments": "Published in the proceedings of IEEE International Smart Cities\n  Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilize Wi-Fi communications from smartphones to predict their mobility\nmode, i.e. walking, biking and driving. Wi-Fi sensors were deployed at four\nstrategic locations in a closed loop on streets in downtown Toronto. Deep\nneural network (Multilayer Perceptron) along with three decision tree based\nclassifiers (Decision Tree, Bagged Decision Tree and Random Forest) are\ndeveloped. Results show that the best prediction accuracy is achieved by\nMultilayer Perceptron, with 86.52% correct predictions of mobility modes.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 00:49:24 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Kalatian", "Arash", ""], ["Farooq", "Bilal", ""]]}, {"id": "1809.05814", "submitter": "Boyi Yang", "authors": "Boyi Yang, Adam Wright", "title": "Development of deep learning algorithms to categorize free-text notes\n  pertaining to diabetes: convolution neural networks achieve higher accuracy\n  than support vector machines", "comments": "9 pages, 4 figures, submitted to Journal of the American Medical\n  Informatics Association (JAMIA) on September 15th, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health professionals can use natural language processing (NLP) technologies\nwhen reviewing electronic health records (EHR). Machine learning free-text\nclassifiers can help them identify problems and make critical decisions. We aim\nto develop deep learning neural network algorithms that identify EHR progress\nnotes pertaining to diabetes and validate the algorithms at two institutions.\nThe data used are 2,000 EHR progress notes retrieved from patients with\ndiabetes and all notes were annotated manually as diabetic or non-diabetic.\nSeveral deep learning classifiers were developed, and their performances were\nevaluated with the area under the ROC curve (AUC). The convolutional neural\nnetwork (CNN) model with a separable convolution layer accurately identified\ndiabetes-related notes in the Brigham and Womens Hospital testing set with the\nhighest AUC of 0.975. Deep learning classifiers can be used to identify EHR\nprogress notes pertaining to diabetes. In particular, the CNN-based classifier\ncan achieve a higher AUC than an SVM-based classifier.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 04:21:38 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Yang", "Boyi", ""], ["Wright", "Adam", ""]]}, {"id": "1809.05815", "submitter": "Amichai Painsky", "authors": "Amichai Painsky, Saharon Rosset, Meir Feder", "title": "Linear Independent Component Analysis over Finite Fields: Algorithms and\n  Bounds", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2872006", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent Component Analysis (ICA) is a statistical tool that decomposes an\nobserved random vector into components that are as statistically independent as\npossible. ICA over finite fields is a special case of ICA, in which both the\nobservations and the decomposed components take values over a finite alphabet.\nThis problem is also known as minimal redundancy representation or factorial\ncoding. In this work we focus on linear methods for ICA over finite fields. We\nintroduce a basic lower bound which provides a fundamental limit to the ability\nof any linear solution to solve this problem. Based on this bound, we present a\ngreedy algorithm that outperforms all currently known methods. Importantly, we\nshow that the overhead of our suggested algorithm (compared with the lower\nbound) typically decreases, as the scale of the problem grows. In addition, we\nprovide a sub-optimal variant of our suggested method that significantly\nreduces the computational complexity at a relatively small cost in performance.\nFinally, we discuss the universal abilities of linear transformations in\ndecomposing random vectors, compared with existing non-linear solutions.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 04:33:21 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Painsky", "Amichai", ""], ["Rosset", "Saharon", ""], ["Feder", "Meir", ""]]}, {"id": "1809.05822", "submitter": "Wenhui Yu", "authors": "Wenhui Yu, Huidi Zhang, Xiangnan He, Xu Chen, Li Xiong, Zheng Qin", "title": "Aesthetic-based Clothing Recommendation", "comments": "WWW 2018", "journal-ref": null, "doi": "10.1145/3178876.3186146", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, product images have gained increasing attention in clothing\nrecommendation since the visual appearance of clothing products has a\nsignificant impact on consumers' decision. Most existing methods rely on\nconventional features to represent an image, such as the visual features\nextracted by convolutional neural networks (CNN features) and the\nscale-invariant feature transform algorithm (SIFT features), color histograms,\nand so on. Nevertheless, one important type of features, the \\emph{aesthetic\nfeatures}, is seldom considered. It plays a vital role in clothing\nrecommendation since a users' decision depends largely on whether the clothing\nis in line with her aesthetics, however the conventional image features cannot\nportray this directly. To bridge this gap, we propose to introduce the\naesthetic information, which is highly relevant with user preference, into\nclothing recommender systems. To achieve this, we first present the aesthetic\nfeatures extracted by a pre-trained neural network, which is a brain-inspired\ndeep structure trained for the aesthetic assessment task. Considering that the\naesthetic preference varies significantly from user to user and by time, we\nthen propose a new tensor factorization model to incorporate the aesthetic\nfeatures in a personalized manner. We conduct extensive experiments on\nreal-world datasets, which demonstrate that our approach can capture the\naesthetic preference of users and significantly outperform several\nstate-of-the-art recommendation methods.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 06:20:36 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Yu", "Wenhui", ""], ["Zhang", "Huidi", ""], ["He", "Xiangnan", ""], ["Chen", "Xu", ""], ["Xiong", "Li", ""], ["Qin", "Zheng", ""]]}, {"id": "1809.05839", "submitter": "Gautham Krishna Gudur", "authors": "Gautham Krishna G, Karthik Subramanian Nathan, Yogesh Kumar B, Ankith\n  A Prabhu, Ajay Kannan, Vineeth Vijayaraghavan", "title": "A Generic Multi-modal Dynamic Gesture Recognition System using Machine\n  Learning", "comments": "Accepted at IEEE Future of Information and Communications Conference\n  (FICC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human computer interaction facilitates intelligent communication between\nhumans and computers, in which gesture recognition plays a prominent role. This\npaper proposes a machine learning system to identify dynamic gestures using\ntri-axial acceleration data acquired from two public datasets. These datasets,\nuWave and Sony, were acquired using accelerometers embedded in Wii remotes and\nsmartwatches, respectively. A dynamic gesture signed by the user is\ncharacterized by a generic set of features extracted across time and frequency\ndomains. The system was analyzed from an end-user perspective and was modelled\nto operate in three modes. The modes of operation determine the subsets of data\nto be used for training and testing the system. From an initial set of seven\nclassifiers, three were chosen to evaluate each dataset across all modes\nrendering the system towards mode-neutrality and dataset-independence. The\nproposed system is able to classify gestures performed at varying speeds with\nminimum preprocessing, making it computationally efficient. Moreover, this\nsystem was found to run on a low-cost embedded platform - Raspberry Pi Zero\n(USD 5), making it economically viable.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 08:51:05 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["G", "Gautham Krishna", ""], ["Nathan", "Karthik Subramanian", ""], ["B", "Yogesh Kumar", ""], ["Prabhu", "Ankith A", ""], ["Kannan", "Ajay", ""], ["Vijayaraghavan", "Vineeth", ""]]}, {"id": "1809.05861", "submitter": "Jianlin Su", "authors": "Jianlin Su, Guang Wu", "title": "f-VAEs: Improve VAEs with Conditional Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we integrate VAEs and flow-based generative models\nsuccessfully and get f-VAEs. Compared with VAEs, f-VAEs generate more vivid\nimages, solved the blurred-image problem of VAEs. Compared with flow-based\nmodels such as Glow, f-VAE is more lightweight and converges faster, achieving\nthe same performance under smaller-size architecture.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 12:23:09 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Su", "Jianlin", ""], ["Wu", "Guang", ""]]}, {"id": "1809.05870", "submitter": "Jakub Mare\\v{c}ek", "authors": "Mark Kozdoba, Jakub Marecek, Tigran Tchrakian, and Shie Mannor", "title": "On-Line Learning of Linear Dynamical Systems: Exponential Forgetting in\n  Kalman Filters", "comments": null, "journal-ref": "Proceedings of the Thirty-Third AAAI Conference on Artificial\n  Intelligence, 2019. Pages: 4098-4105", "doi": "10.1609/aaai.v33i01.33014098", "report-no": null, "categories": "math.ST cs.AI cs.LG math.OC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kalman filter is a key tool for time-series forecasting and analysis. We show\nthat the dependence of a prediction of Kalman filter on the past is decaying\nexponentially, whenever the process noise is non-degenerate. Therefore, Kalman\nfilter may be approximated by regression on a few recent observations.\nSurprisingly, we also show that having some process noise is essential for the\nexponential decay. With no process noise, it may happen that the forecast\ndepends on all of the past uniformly, which makes forecasting more difficult.\n  Based on this insight, we devise an on-line algorithm for improper learning\nof a linear dynamical system (LDS), which considers only a few most recent\nobservations. We use our decay results to provide the first regret bounds\nw.r.t. to Kalman filters within learning an LDS. That is, we compare the\nresults of our algorithm to the best, in hindsight, Kalman filter for a given\nsignal. Also, the algorithm is practical: its per-update run-time is linear in\nthe regression depth.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 13:21:49 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Kozdoba", "Mark", ""], ["Marecek", "Jakub", ""], ["Tchrakian", "Tigran", ""], ["Mannor", "Shie", ""]]}, {"id": "1809.05872", "submitter": "Nir Baram", "authors": "Nir Baram, Shie Mannor", "title": "Inspiration Learning through Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current imitation learning techniques are too restrictive because they\nrequire the agent and expert to share the same action space. However,\noftentimes agents that act differently from the expert can solve the task just\nas good. For example, a person lifting a box can be imitated by a ceiling\nmounted robot or a desktop-based robotic-arm. In both cases, the end goal of\nlifting the box is achieved, perhaps using different strategies. We denote this\nsetup as \\textit{Inspiration Learning} - knowledge transfer between agents that\noperate in different action spaces. Since state-action expert demonstrations\ncan no longer be used, Inspiration learning requires novel methods to guide the\nagent towards the end goal. In this work, we rely on ideas of Preferential\nbased Reinforcement Learning (PbRL) to design Advantage Actor-Critic algorithms\nfor solving inspiration learning tasks. Unlike classic actor-critic\narchitectures, the critic we use consists of two parts: a) a state-value\nestimation as in common actor-critic algorithms and b) a single step reward\nfunction derived from an expert/agent classifier. We show that our method is\ncapable of extending the current imitation framework to new horizons. This\nincludes continuous-to-discrete action imitation, as well as primitive-to-macro\naction imitation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 13:37:45 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Baram", "Nir", ""], ["Mannor", "Shie", ""]]}, {"id": "1809.05877", "submitter": "Sanket Tavarageri", "authors": "Sanket Tavarageri, Nag Mani, Anand Ramasubramanian, Jaskiran Kalsi", "title": "A Data Analytics Framework for Aggregate Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many contexts, we have access to aggregate data, but individual level data\nis unavailable. For example, medical studies sometimes report only aggregate\nstatistics about disease prevalence because of privacy concerns. Even so, many\na time it is desirable, and in fact could be necessary to infer individual\nlevel characteristics from aggregate data. For instance, other researchers who\nwant to perform more detailed analysis of disease characteristics would require\nindividual level data. Similar challenges arise in other fields too including\npolitics, and marketing.\n  In this paper, we present an end-to-end pipeline for processing of aggregate\ndata to derive individual level statistics, and then using the inferred data to\ntrain machine learning models to answer questions of interest. We describe a\nnovel algorithm for reconstructing fine-grained data from summary statistics.\nThis step will create multiple candidate datasets which will form the input to\nthe machine learning models. The advantage of the highly parallel architecture\nwe propose is that uncertainty in the generated fine-grained data will be\ncompensated by the use of multiple candidate fine-grained datasets.\nConsequently, the answers derived from the machine learning models will be more\nvalid and usable. We validate our approach using data from a challenging\nmedical problem called Acute Traumatic Coagulopathy.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:13:34 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Tavarageri", "Sanket", ""], ["Mani", "Nag", ""], ["Ramasubramanian", "Anand", ""], ["Kalsi", "Jaskiran", ""]]}, {"id": "1809.05878", "submitter": "Adeyinka K. Akanbi MR", "authors": "Y. O. Agunbiade, J. O. Dehinbo, T. Zuva and A. K. Akanbi", "title": "Road Detection Technique Using Filters with Application to Autonomous\n  Driving System", "comments": "7 pages, 7 figures, International Journal of Computing,\n  Communications & Instrumentation Engg. (IJCCIE) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Autonomous driving systems are broadly used equipment in the industries and\nin our daily lives, they assist in production, but are majorly used for\nexploration in dangerous or unfamiliar locations. Thus, for a successful\nexploration, navigation plays a significant role. Road detection is an\nessential factor that assists autonomous robots achieved perfect navigation.\nVarious techniques using camera sensors have been proposed by numerous scholars\nwith inspiring results, but their techniques are still vulnerable to these\nenvironmental noises: rain, snow, light intensity and shadow. In addressing\nthese problems, this paper proposed to enhance the road detection system with\nfiltering algorithm to overcome these limitations. Normalized Differences Index\n(NDI) and morphological operation are the filtering algorithms used to address\nthe effect of shadow and guidance and re-guidance image filtering algorithms\nare used to address the effect of rain and/or snow, while dark channel image\nand specular-to-diffuse are the filters used to address light intensity\neffects. The experimental performance of the road detection system with\nfiltering algorithms was tested qualitatively and quantitatively using the\nfollowing evaluation schemes: False Negative Rate (FNR) and False Positive Rate\n(FPR). Comparison results of the road detection system with and without\nfiltering algorithm shows the filtering algorithm's capability to suppress the\neffect of environmental noises because better road/non-road classification is\nachieved by the road detection system. with filtering algorithm. This\nachievement has further improved path planning/region classification for\nautonomous driving system\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:14:36 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Agunbiade", "Y. O.", ""], ["Dehinbo", "J. O.", ""], ["Zuva", "T.", ""], ["Akanbi", "A. K.", ""]]}, {"id": "1809.05879", "submitter": "Abdallah Moussawi", "authors": "Abdallah Moussawi, Kamal Haddad and Anthony Chahine", "title": "An FPGA-Accelerated Design for Deep Learning Pedestrian Detection in\n  Self-Driving Vehicles", "comments": "7 pages. American University of Beirut, Faculty of Engineering and\n  Architecture Student and Alumni Conference 2017 FEASAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of self-driving vehicles comes the risk of accidents and the\nneed for higher safety, and protection for pedestrian detection in the\nfollowing scenarios: imminent crashes, thus the car should crash into an object\nand avoid the pedestrian, and in the case of road intersections, where it is\nimportant for the car to stop when pedestrians are crossing. Currently, a\nspecial topology of deep neural networks called Fused Deep Neural Network\n(F-DNN) is considered to be the state of the art in pedestrian detection, as it\nhas the lowest miss rate, yet it is very slow. Therefore, acceleration is\nneeded to speed up the performance. This project proposes two contributions to\naddress this problem, by using a deep neural network used for object detection,\ncalled Single Shot Multi-Box Detector (SSD). The first contribution is training\nand tuning the hyperparameters of SSD to improve pedestrian detection. The\nsecond contribution is a new FPGA design for accelerating the model on the\nAltera Arria 10 platform. The final system will be used in self-driving\nvehicles in real-time. Preliminary results of the improved SSD shows 3% higher\nmiss-rate than F-DNN on Caltech pedestrian detection benchmark, but 4x\nperformance improvement. The acceleration design is expected to achieve an\nadditional performance improvement significantly outweighing the minimal\ndifference in accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:16:33 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Moussawi", "Abdallah", ""], ["Haddad", "Kamal", ""], ["Chahine", "Anthony", ""]]}, {"id": "1809.05884", "submitter": "Yongcheng Liu", "authors": "Yongcheng Liu, Lu Sheng, Jing Shao, Junjie Yan, Shiming Xiang and\n  Chunhong Pan", "title": "Multi-Label Image Classification via Knowledge Distillation from\n  Weakly-Supervised Detection", "comments": "accepted by ACM Multimedia 2018, 9 pages, 4 figures, 5 tables", "journal-ref": null, "doi": "10.1145/3240508.3240567", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label image classification is a fundamental but challenging task\ntowards general visual understanding. Existing methods found the region-level\ncues (e.g., features from RoIs) can facilitate multi-label classification.\nNevertheless, such methods usually require laborious object-level annotations\n(i.e., object labels and bounding boxes) for effective learning of the\nobject-level visual features. In this paper, we propose a novel and efficient\ndeep framework to boost multi-label classification by distilling knowledge from\nweakly-supervised detection task without bounding box annotations.\nSpecifically, given the image-level annotations, (1) we first develop a\nweakly-supervised detection (WSD) model, and then (2) construct an end-to-end\nmulti-label image classification framework augmented by a knowledge\ndistillation module that guides the classification model by the WSD model\naccording to the class-level predictions for the whole image and the\nobject-level visual features for object RoIs. The WSD model is the teacher\nmodel and the classification model is the student model. After this cross-task\nknowledge distillation, the performance of the classification model is\nsignificantly improved and the efficiency is maintained since the WSD model can\nbe safely discarded in the test phase. Extensive experiments on two large-scale\ndatasets (MS-COCO and NUS-WIDE) show that our framework achieves superior\nperformances over the state-of-the-art methods on both performance and\nefficiency.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:35:03 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 12:28:58 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Liu", "Yongcheng", ""], ["Sheng", "Lu", ""], ["Shao", "Jing", ""], ["Yan", "Junjie", ""], ["Xiang", "Shiming", ""], ["Pan", "Chunhong", ""]]}, {"id": "1809.05886", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Meta-Embedding as Auxiliary Task Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings have been shown to benefit from ensambling several word\nembedding sources, often carried out using straightforward mathematical\noperations over the set of word vectors. More recently, self-supervised\nlearning has been used to find a lower-dimensional representation, similar in\nsize to the individual word embeddings within the ensemble. However, these\nmethods do not use the available manually labeled datasets that are often used\nsolely for the purpose of evaluation. We propose to reconstruct an ensemble of\nword embeddings as an auxiliary task that regularises a main task while both\ntasks share the learned meta-embedding layer. We carry out intrinsic evaluation\n(6 word similarity datasets and 3 analogy datasets) and extrinsic evaluation (4\ndownstream tasks). For intrinsic task evaluation, supervision comes from\nvarious labeled word similarity datasets. Our experimental results show that\nthe performance is improved for all word similarity datasets when compared to\nself-supervised learning methods with a mean increase of $11.33$ in Spearman\ncorrelation. Specifically, the proposed method shows the best performance in 4\nout of 6 of word similarity datasets when using a cosine reconstruction loss\nand Brier's word similarity loss. Moreover, improvements are also made when\nperforming word meta-embedding reconstruction in sequence tagging and sentence\nmeta-embedding for sentence classification.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:36:54 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 18:57:14 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1809.05888", "submitter": "Sanjay Sahay", "authors": "Mohit Sewak, Sanjay K. Sahay and Hemant Rathore", "title": "An investigation of a deep learning based malware detection system", "comments": "13 Pages, 4 figures", "journal-ref": "ACM, pp. 26, Proceedings of the 13th International Conference on\n  Availability, Reliability and Security (ARES), 27-30 Aug., 2018, University\n  of Hamburg, Germany", "doi": "10.1145/3230833.3230835", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a Deep Learning based system for malware detection. In the\ninvestigation, we experiment with different combination of Deep Learning\narchitectures including Auto-Encoders, and Deep Neural Networks with varying\nlayers over Malicia malware dataset on which earlier studies have obtained an\naccuracy of (98%) with an acceptable False Positive Rates (1.07%). But these\nresults were done using extensive man-made custom domain features and investing\ncorresponding feature engineering and design efforts. In our proposed approach,\nbesides improving the previous best results (99.21% accuracy and a False\nPositive Rate of 0.19%) indicates that Deep Learning based systems could\ndeliver an effective defense against malware. Since it is good in automatically\nextracting higher conceptual features from the data, Deep Learning based\nsystems could provide an effective, general and scalable mechanism for\ndetection of existing and unknown malware.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:39:28 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sewak", "Mohit", ""], ["Sahay", "Sanjay K.", ""], ["Rathore", "Hemant", ""]]}, {"id": "1809.05889", "submitter": "Sanjay Sahay", "authors": "Mohit Sewak, Sanjay K. Sahay and Hemant Rathore", "title": "Comparison of Deep Learning and the Classical Machine Learning Algorithm\n  for the Malware Detection", "comments": "11 Pages, 1 figure", "journal-ref": "IEEE, pp. 293-296, 19th IEEE/ACIS International Conference on\n  Software Engineering, Artificial Intelligence, Networking and\n  Parallel/Distributed Computing (SNPD), 2018", "doi": "10.1109/SNPD.2018.8441123", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Deep Learning has been showing promising results in various\nArtificial Intelligence applications like image recognition, natural language\nprocessing, language modeling, neural machine translation, etc. Although, in\ngeneral, it is computationally more expensive as compared to classical machine\nlearning techniques, their results are found to be more effective in some\ncases. Therefore, in this paper, we investigated and compared one of the Deep\nLearning Architecture called Deep Neural Network (DNN) with the classical\nRandom Forest (RF) machine learning algorithm for the malware classification.\nWe studied the performance of the classical RF and DNN with 2, 4 & 7 layers\narchitectures with the four different feature sets, and found that irrespective\nof the features inputs, the classical RF accuracy outperforms the DNN.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:40:16 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sewak", "Mohit", ""], ["Sahay", "Sanjay K.", ""], ["Rathore", "Hemant", ""]]}, {"id": "1809.05896", "submitter": "Markku Hinkka", "authors": "Markku Hinkka, Teemu Lehto, Keijo Heljanko, Alexander Jung", "title": "Classifying Process Instances Using Recurrent Neural Networks", "comments": "Proceedings of the BPM 2018 Workshops", "journal-ref": null, "doi": "10.1007/978-3-030-11641-5_25", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process Mining consists of techniques where logs created by operative systems\nare transformed into process models. In process mining tools it is often\ndesired to be able to classify ongoing process instances, e.g., to predict how\nlong the process will still require to complete, or to classify process\ninstances to different classes based only on the activities that have occurred\nin the process instance thus far. Recurrent neural networks and its subclasses,\nsuch as Gated Recurrent Unit (GRU) and Long Short-Term Memory (LSTM), have been\ndemonstrated to be able to learn relevant temporal features for subsequent\nclassification tasks. In this paper we apply recurrent neural networks to\nclassifying process instances. The proposed model is trained in a supervised\nfashion using labeled process instances extracted from event log traces. This\nis the first time we know of GRU having been used in classifying business\nprocess instances. Our main experimental results shows that GRU outperforms\nLSTM remarkably in training time while giving almost identical accuracies to\nLSTM models. Additional contributions of our paper are improving the\nclassification model training time by filtering infrequent activities, which is\na technique commonly used, e.g., in Natural Language Processing (NLP).\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 15:33:24 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Hinkka", "Markku", ""], ["Lehto", "Teemu", ""], ["Heljanko", "Keijo", ""], ["Jung", "Alexander", ""]]}, {"id": "1809.05910", "submitter": "Rana Hanocka", "authors": "Rana Hanocka, Amir Hertz, Noa Fish, Raja Giryes, Shachar Fleishman and\n  Daniel Cohen-Or", "title": "MeshCNN: A Network with an Edge", "comments": "For a two-minute explanation video see https://bit.ly/meshcnnvideo", "journal-ref": null, "doi": "10.1145/3306346.3322959", "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polygonal meshes provide an efficient representation for 3D shapes. They\nexplicitly capture both shape surface and topology, and leverage non-uniformity\nto represent large flat regions as well as sharp, intricate features. This\nnon-uniformity and irregularity, however, inhibits mesh analysis efforts using\nneural networks that combine convolution and pooling operations. In this paper,\nwe utilize the unique properties of the mesh for a direct analysis of 3D shapes\nusing MeshCNN, a convolutional neural network designed specifically for\ntriangular meshes. Analogous to classic CNNs, MeshCNN combines specialized\nconvolution and pooling layers that operate on the mesh edges, by leveraging\ntheir intrinsic geodesic connections. Convolutions are applied on edges and the\nfour edges of their incident triangles, and pooling is applied via an edge\ncollapse operation that retains surface topology, thereby, generating new mesh\nconnectivity for the subsequent convolutions. MeshCNN learns which edges to\ncollapse, thus forming a task-driven process where the network exposes and\nexpands the important features while discarding the redundant ones. We\ndemonstrate the effectiveness of our task-driven pooling on various learning\ntasks applied to 3D meshes.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 16:32:29 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 11:30:57 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Hanocka", "Rana", ""], ["Hertz", "Amir", ""], ["Fish", "Noa", ""], ["Giryes", "Raja", ""], ["Fleishman", "Shachar", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "1809.05916", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Curriculum-Based Neighborhood Sampling For Sequence Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of multi-step ahead prediction in language models is challenging\nconsidering the discrepancy between training and testing. At test time, a\nlanguage model is required to make predictions given past predictions as input,\ninstead of the past targets that are provided during training. This difference,\nknown as exposure bias, can lead to the compounding of errors along a generated\nsequence at test time.\n  In order to improve generalization in neural language models and address\ncompounding errors, we propose a curriculum learning based method that\ngradually changes an initially deterministic teacher policy to a gradually more\nstochastic policy, which we refer to as \\textit{Nearest-Neighbor Replacement\nSampling}. A chosen input at a given timestep is replaced with a sampled\nnearest neighbor of the past target with a truncated probability proportional\nto the cosine similarity between the original word and its top $k$ most similar\nwords. This allows the teacher to explore alternatives when the teacher\nprovides a sub-optimal policy or when the initial policy is difficult for the\nlearner to model. The proposed strategy is straightforward, online and requires\nlittle additional memory requirements. We report our main findings on two\nlanguage modelling benchmarks and find that the proposed approach performs\nparticularly well when used in conjunction with scheduled sampling, that too\nattempts to mitigate compounding errors in language models.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 17:17:56 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1809.05922", "submitter": "Tyler Hayes", "authors": "Tyler L. Hayes, Nathan D. Cahill, Christopher Kanan", "title": "Memory Efficient Experience Replay for Streaming Learning", "comments": "To appear in the IEEE International Conference on Robotics and\n  Automation (ICRA) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised machine learning, an agent is typically trained once and then\ndeployed. While this works well for static settings, robots often operate in\nchanging environments and must quickly learn new things from data streams. In\nthis paradigm, known as streaming learning, a learner is trained online, in a\nsingle pass, from a data stream that cannot be assumed to be independent and\nidentically distributed (iid). Streaming learning will cause conventional deep\nneural networks (DNNs) to fail for two reasons: 1) they need multiple passes\nthrough the entire dataset; and 2) non-iid data will cause catastrophic\nforgetting. An old fix to both of these issues is rehearsal. To learn a new\nexample, rehearsal mixes it with previous examples, and then this mixture is\nused to update the DNN. Full rehearsal is slow and memory intensive because it\nstores all previously observed examples, and its effectiveness for preventing\ncatastrophic forgetting has not been studied in modern DNNs. Here, we describe\nthe ExStream algorithm for memory efficient rehearsal and compare it to\nalternatives. We find that full rehearsal can eliminate catastrophic forgetting\nin a variety of streaming learning settings, with ExStream performing well\nusing far less memory and computation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 18:04:33 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 23:32:51 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Hayes", "Tyler L.", ""], ["Cahill", "Nathan D.", ""], ["Kanan", "Christopher", ""]]}, {"id": "1809.05929", "submitter": "Peter Mills", "authors": "Peter Mills", "title": "Solving for multi-class: a survey and synthesis", "comments": "Tried to cut out the fat and improve wording and organization.\n  Returned title to the original", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the best statistical classification algorithms are binary classifiers\nthat can only distinguish between one of two classes. The number of possible\nways of generalizing binary classification to multi-class increases\nexponentially with the number of classes. There is some indication that the\nbest method will depend on the dataset. Hence, we are particularly interested\nin data-driven solution design, whether based on prior considerations or on\nempirical examination of the data. Here we demonstrate how a recursive control\nlanguage can be used to describe a multitude of different partitioning\nstrategies in multi-class classification, including those in most common use.\nWe use it both to manually construct new partitioning configurations as well as\nto examine those that have been automatically designed.\n  Eight different strategies were tested on eight different datasets using a\nsupport vector machine (SVM) as the base binary classifier. Numerical results\nsuggest that a one-size-fits-all solution consisting of one-versus-one is\nappropriate for most datasets. Three datasets showed better accuracy using\ndifferent methods. The best solution for the most improved dataset exploited a\nproperty of the data to produce an uncertainty coefficient 36\\% higher (0.016\nabsolute gain) than one-vs.-one. For the same dataset, an adaptive solution\nthat empirically examined the data was also more accurate than one-vs.-one\nwhile being faster.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 18:28:08 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 01:18:02 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 17:49:01 GMT"}, {"version": "v4", "created": "Fri, 29 Mar 2019 00:05:43 GMT"}, {"version": "v5", "created": "Fri, 21 Jun 2019 02:27:58 GMT"}, {"version": "v6", "created": "Sat, 2 Nov 2019 18:58:18 GMT"}, {"version": "v7", "created": "Sun, 24 Jan 2021 18:04:01 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Mills", "Peter", ""]]}, {"id": "1809.05934", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey, Otkrist Gupta, Ramesh Raskar and Nikhil Naik", "title": "Maximum-Entropy Fine-Grained Classification", "comments": "Camera-ready, accepted to NIPS 2018, v2 has minor typo updates and\n  small changes in text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-Grained Visual Classification (FGVC) is an important computer vision\nproblem that involves small diversity within the different classes, and often\nrequires expert annotators to collect data. Utilizing this notion of small\nvisual diversity, we revisit Maximum-Entropy learning in the context of\nfine-grained classification, and provide a training routine that maximizes the\nentropy of the output probability distribution for training convolutional\nneural networks on FGVC tasks. We provide a theoretical as well as empirical\njustification of our approach, and achieve state-of-the-art performance across\na variety of classification tasks in FGVC, that can potentially be extended to\nany fine-tuning task. Our method is robust to different hyperparameter values,\namount of training data and amount of training label noise and can hence be a\nvaluable tool in many similar problems.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 18:58:22 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 21:11:37 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Gupta", "Otkrist", ""], ["Raskar", "Ramesh", ""], ["Naik", "Nikhil", ""]]}, {"id": "1809.05957", "submitter": "Jeffrey Regier", "authors": "Maxime Langevin, Edouard Mehlman, Jeffrey Regier, Romain Lopez,\n  Michael I. Jordan, and Nir Yosef", "title": "A Deep Generative Model for Semi-Supervised Classification with Noisy\n  Labels", "comments": "accepted to BayLearn 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class labels are often imperfectly observed, due to mistakes and to genuine\nambiguity among classes. We propose a new semi-supervised deep generative model\nthat explicitly models noisy labels, called the Mislabeled VAE (M-VAE). The\nM-VAE can perform better than existing deep generative models which do not\naccount for label noise. Additionally, the derivation of M-VAE gives new\ntheoretical insights into the popular M1+M2 semi-supervised model.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 21:04:47 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Langevin", "Maxime", ""], ["Mehlman", "Edouard", ""], ["Regier", "Jeffrey", ""], ["Lopez", "Romain", ""], ["Jordan", "Michael I.", ""], ["Yosef", "Nir", ""]]}, {"id": "1809.05964", "submitter": "Huidong Liu", "authors": "Huidong Liu, Yang Guo, Na Lei, Zhixin Shu, Shing-Tung Yau, Dimitris\n  Samaras, Xianfeng Gu", "title": "Latent Space Optimal Transport for Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Auto-Encoders enforce their learned intermediate latent-space\ndata distribution to be a simple distribution, such as an isotropic Gaussian.\nHowever, this causes the posterior collapse problem and loses manifold\nstructure which can be important for datasets such as facial images. A GAN can\ntransform a simple distribution to a latent-space data distribution and thus\npreserve the manifold structure, but optimizing a GAN involves solving a\nMin-Max optimization problem, which is difficult and not well understood so\nfar. Therefore, we propose a GAN-like method to transform a simple distribution\nto a data distribution in the latent space by solving only a minimization\nproblem. This minimization problem comes from training a discriminator between\na simple distribution and a latent-space data distribution. Then, we can\nexplicitly formulate an Optimal Transport (OT) problem that computes the\ndesired mapping between the two distributions. This means that we can transform\na distribution without solving the difficult Min-Max optimization problem.\nExperimental results on an eight-Gaussian dataset show that the proposed OT can\nhandle multi-cluster distributions. Results on the MNIST and the CelebA\ndatasets validate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 21:57:56 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Liu", "Huidong", ""], ["Guo", "Yang", ""], ["Lei", "Na", ""], ["Shu", "Zhixin", ""], ["Yau", "Shing-Tung", ""], ["Samaras", "Dimitris", ""], ["Gu", "Xianfeng", ""]]}, {"id": "1809.05992", "submitter": "Zheng Zhang", "authors": "Zheng Zhang, Li Liu, Jie Qin, Fan Zhu, Fumin Shen, Yong Xu, Ling Shao,\n  Heng Tao Shen", "title": "Highly-Economized Multi-View Binary Compression for Scalable Image\n  Clustering", "comments": "European Conference on Computer Vision (ECCV) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to economically cluster large-scale multi-view images is a long-standing\nproblem in computer vision. To tackle this challenge, we introduce a novel\napproach named Highly-economized Scalable Image Clustering (HSIC) that\nradically surpasses conventional image clustering methods via binary\ncompression. We intuitively unify the binary representation learning and\nefficient binary cluster structure learning into a joint framework. In\nparticular, common binary representations are learned by exploiting both\nsharable and individual information across multiple views to capture their\nunderlying correlations. Meanwhile, cluster assignment with robust binary\ncentroids is also performed via effective discrete optimization under L21-norm\nconstraint. By this means, heavy continuous-valued Euclidean distance\ncomputations can be successfully reduced by efficient binary XOR operations\nduring the clustering procedure. To our best knowledge, HSIC is the first\nbinary clustering work specifically designed for scalable multi-view image\nclustering. Extensive experimental results on four large-scale image datasets\nshow that HSIC consistently outperforms the state-of-the-art approaches, whilst\nsignificantly reducing computational time and memory footprint.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 01:35:42 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Zhang", "Zheng", ""], ["Liu", "Li", ""], ["Qin", "Jie", ""], ["Zhu", "Fan", ""], ["Shen", "Fumin", ""], ["Xu", "Yong", ""], ["Shao", "Ling", ""], ["Shen", "Heng Tao", ""]]}, {"id": "1809.05998", "submitter": "Zheng Zhang", "authors": "Jie Wen, Zheng Zhang, Yong Xu, Zuofeng Zhong", "title": "Incomplete Multi-view Clustering via Graph Regularized Matrix\n  Factorization", "comments": "ECCV 2018 International Workshop on Compact and Efficient Feature\n  Representation and Learning in Computer Vision (CEFRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering with incomplete views is a challenge in multi-view clustering. In\nthis paper, we provide a novel and simple method to address this issue.\nSpecifically, the proposed method simultaneously exploits the local information\nof each view and the complementary information among views to learn the common\nlatent representation for all samples, which can greatly improve the\ncompactness and discriminability of the obtained representation. Compared with\nthe conventional graph embedding methods, the proposed method does not\nintroduce any extra regularization term and corresponding penalty parameter to\npreserve the local structure of data, and thus does not increase the burden of\nextra parameter selection. By imposing the orthogonal constraint on the basis\nmatrix of each view, the proposed method is able to handle the out-of-sample.\nMoreover, the proposed method can be viewed as a unified framework for\nmulti-view learning since it can handle both incomplete and complete multi-view\nclustering and classification tasks. Extensive experiments conducted on several\nmulti-view datasets prove that the proposed method can significantly improve\nthe clustering performance.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 02:46:48 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Wen", "Jie", ""], ["Zhang", "Zheng", ""], ["Xu", "Yong", ""], ["Zhong", "Zuofeng", ""]]}, {"id": "1809.06004", "submitter": "Hu Xu", "authors": "Hu Xu, Bing Liu, Lei Shu, P. Yu", "title": "Open-world Learning and Application to Product Classification", "comments": "accepted by The Web Conference (WWW 2019) Previous title: Learning to\n  Accept New Classes without Training", "journal-ref": null, "doi": "10.1145/3308558.3313644", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic supervised learning makes the closed-world assumption, meaning that\nclasses seen in testing must have been seen in training. However, in the\ndynamic world, new or unseen class examples may appear constantly. A model\nworking in such an environment must be able to reject unseen classes (not seen\nor used in training). If enough data is collected for the unseen classes, the\nsystem should incrementally learn to accept/classify them. This learning\nparadigm is called open-world learning (OWL). Existing OWL methods all need\nsome form of re-training to accept or include the new classes in the overall\nmodel. In this paper, we propose a meta-learning approach to the problem. Its\nkey novelty is that it only needs to train a meta-classifier, which can then\ncontinually accept new classes when they have enough labeled data for the\nmeta-classifier to use, and also detect/reject future unseen classes. No\nre-training of the meta-classifier or a new overall classifier covering all old\nand new classes is needed. In testing, the method only uses the examples of the\nseen classes (including the newly added classes) on-the-fly for classification\nand rejection. Experimental results demonstrate the effectiveness of the new\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 03:08:58 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 23:25:46 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Xu", "Hu", ""], ["Liu", "Bing", ""], ["Shu", "Lei", ""], ["Yu", "P.", ""]]}, {"id": "1809.06009", "submitter": "Jessica Titensky", "authors": "Jessica S. Titensky, Hayden Jananthan, Jeremy Kepner", "title": "Uncertainty Propagation in Deep Neural Networks Using Extended Kalman\n  Filtering", "comments": "4 Pages, 8 figures. Accepted at MIT IEEE Undergraduate Research\n  Technology Conference 2018. Publication pending", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extended Kalman Filtering (EKF) can be used to propagate and quantify input\nuncertainty through a Deep Neural Network (DNN) assuming mild hypotheses on the\ninput distribution. This methodology yields results comparable to existing\nmethods of uncertainty propagation for DNNs while lowering the computational\noverhead considerably. Additionally, EKF allows model error to be naturally\nincorporated into the output uncertainty.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 03:30:58 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Titensky", "Jessica S.", ""], ["Jananthan", "Hayden", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1809.06018", "submitter": "Xi Zhang", "authors": "Xi Sheryl Zhang, Jingyuan Chou, Fei Wang", "title": "Integrative Analysis of Patient Health Records and Neuroimages via\n  Memory-based Graph Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the arrival of the big data era, more and more data are becoming readily\navailable in various real-world applications and those data are usually highly\nheterogeneous. Taking computational medicine as an example, we have both\nElectronic Health Records (EHR) and medical images for each patient. For\ncomplicated diseases such as Parkinson's and Alzheimer's, both EHR and\nneuroimaging information are very important for disease understanding because\nthey contain complementary aspects of the disease. However, EHR and neuroimage\nare completely different. So far the existing research has been mainly focusing\non one of them. In this paper, we proposed a framework, Memory-Based Graph\nConvolution Network (MemGCN), to perform integrative analysis with such\nmulti-modal data. Specifically, GCN is used to extract useful information from\nthe patients' neuroimages. The information contained in the patient EHRs before\nthe acquisition of each brain image is captured by a memory network because of\nits sequential nature. The information contained in each brain image is\ncombined with the information read out from the memory network to infer the\ndisease state at the image acquisition timestamp. To further enhance the\nanalytical power of MemGCN, we also designed a multi-hop strategy that allows\nmultiple reading and updating on the memory can be performed at each iteration.\nWe conduct experiments using the patient data from the Parkinson's Progression\nMarkers Initiative (PPMI) with the task of classification of Parkinson's\nDisease (PD) cases versus controls. We demonstrate that superior classification\nperformance can be achieved with our proposed framework, comparing with\nexisting approaches involving a single type of data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 04:45:39 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 14:02:12 GMT"}, {"version": "v3", "created": "Sun, 17 Mar 2019 06:06:25 GMT"}, {"version": "v4", "created": "Tue, 7 May 2019 04:11:54 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Zhang", "Xi Sheryl", ""], ["Chou", "Jingyuan", ""], ["Wang", "Fei", ""]]}, {"id": "1809.06019", "submitter": "Guang Cheng", "authors": "Meimei Liu, Jean Honorio, Guang Cheng", "title": "Statistically and Computationally Efficient Variance Estimator for\n  Kernel Ridge Regression", "comments": "To Appear in 2018 Allerton", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a random projection approach to estimate variance\nin kernel ridge regression. Our approach leads to a consistent estimator of the\ntrue variance, while being computationally more efficient. Our variance\nestimator is optimal for a large family of kernels, including cubic splines and\nGaussian kernels. Simulation analysis is conducted to support our theory.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 04:53:46 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Liu", "Meimei", ""], ["Honorio", "Jean", ""], ["Cheng", "Guang", ""]]}, {"id": "1809.06023", "submitter": "Mohammad Javad Khojasteh", "authors": "Mohammad Javad Khojasteh, Anatoly Khina, Massimo Franceschetti, and\n  Tara Javidi", "title": "Learning-based attacks in cyber-physical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.IT cs.LG cs.SY math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of learning-based attacks in a simple abstraction of\ncyber-physical systems---the case of a discrete-time, linear, time-invariant\nplant that may be subject to an attack that overrides the sensor readings and\nthe controller actions. The attacker attempts to learn the dynamics of the\nplant and subsequently override the controller's actuation signal, to destroy\nthe plant without being detected. The attacker can feed fictitious sensor\nreadings to the controller using its estimate of the plant dynamics and mimic\nthe legitimate plant operation. The controller, on the other hand, is\nconstantly on the lookout for an attack; once the controller detects an attack,\nit immediately shuts the plant off. In the case of scalar plants, we derive an\nupper bound on the attacker's deception probability for any measurable control\npolicy when the attacker uses an arbitrary learning algorithm to estimate the\nsystem dynamics. We then derive lower bounds for the attacker's deception\nprobability for both scalar and vector plants by assuming a specific\nauthentication test that inspects the empirical variance of the system\ndisturbance. We also show how the controller can improve the security of the\nsystem by superimposing a carefully crafted privacy-enhancing signal on top of\nthe \"nominal control policy.\" Finally, for nonlinear scalar dynamics that\nbelong to the Reproducing Kernel Hilbert Space (RKHS), we investigate the\nperformance of attacks based on nonlinear Gaussian-processes (GP) learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 05:22:38 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 01:36:07 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 22:45:47 GMT"}, {"version": "v4", "created": "Sun, 16 Feb 2020 02:23:01 GMT"}, {"version": "v5", "created": "Thu, 5 Mar 2020 23:23:17 GMT"}, {"version": "v6", "created": "Mon, 9 Mar 2020 04:48:15 GMT"}, {"version": "v7", "created": "Sat, 27 Jun 2020 07:34:11 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Khojasteh", "Mohammad Javad", ""], ["Khina", "Anatoly", ""], ["Franceschetti", "Massimo", ""], ["Javidi", "Tara", ""]]}, {"id": "1809.06024", "submitter": "Kean Ming Tan", "authors": "Kean Ming Tan, Zhaoran Wang, Tong Zhang, Han Liu, R. Dennis Cook", "title": "A convex formulation for high-dimensional sparse sliced inverse\n  regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sliced inverse regression is a popular tool for sufficient dimension\nreduction, which replaces covariates with a minimal set of their linear\ncombinations without loss of information on the conditional distribution of the\nresponse given the covariates. The estimated linear combinations include all\ncovariates, making results difficult to interpret and perhaps unnecessarily\nvariable, particularly when the number of covariates is large. In this paper,\nwe propose a convex formulation for fitting sparse sliced inverse regression in\nhigh dimensions. Our proposal estimates the subspace of the linear combinations\nof the covariates directly and performs variable selection simultaneously. We\nsolve the resulting convex optimization problem via the linearized alternating\ndirection methods of multiplier algorithm, and establish an upper bound on the\nsubspace distance between the estimated and the true subspaces. Through\nnumerical studies, we show that our proposal is able to identify the correct\ncovariates in the high-dimensional setting.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 05:23:39 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Tan", "Kean Ming", ""], ["Wang", "Zhaoran", ""], ["Zhang", "Tong", ""], ["Liu", "Han", ""], ["Cook", "R. Dennis", ""]]}, {"id": "1809.06025", "submitter": "Louis Ly", "authors": "Louis Ly and Yen-Hsi Richard Tsai", "title": "Greedy Algorithms for Sparse Sensor Placement via Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the exploration problem: an agent equipped with a depth sensor\nmust map out a previously unknown environment using as few sensor measurements\nas possible. We propose an approach based on supervised learning of a greedy\nalgorithm. We provide a bound on the optimality of the greedy algorithm using\nsubmodularity theory. Using a level set representation, we train a\nconvolutional neural network to determine vantage points that maximize\nvisibility. We show that this method drastically reduces the on-line\ncomputational cost and determines a small set of vantage points that solve the\nproblem. This enables us to efficiently produce highly-resolved and\ntopologically accurate maps of complex 3D environments. Unlike traditional\nnext-best-view and frontier-based strategies, the proposed method accounts for\ngeometric priors while evaluating potential vantage points. While existing deep\nlearning approaches focus on obstacle avoidance and local navigation, our\nmethod aims at finding near-optimal solutions to the more global exploration\nproblem. We present realistic simulations on 2D and 3D urban environments.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 05:24:14 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 07:47:57 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 14:58:54 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 04:25:57 GMT"}, {"version": "v5", "created": "Thu, 22 Oct 2020 19:40:05 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ly", "Louis", ""], ["Tsai", "Yen-Hsi Richard", ""]]}, {"id": "1809.06035", "submitter": "Arthur Mensch", "authors": "Arthur Mensch (PARIETAL), Julien Mairal (Thoth), Bertrand Thirion\n  (PARIETAL), Ga\\\"el Varoquaux (PARIETAL)", "title": "Extracting representations of cognition across neuroimaging studies\n  improves brain decoding", "comments": null, "journal-ref": "PLoS Computational Biology, Public Library of Science, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive brain imaging is accumulating datasets about the neural substrate\nof many different mental processes. Yet, most studies are based on few subjects\nand have low statistical power. Analyzing data across studies could bring more\nstatistical power; yet the current brain-imaging analytic framework cannot be\nused at scale as it requires casting all cognitive tasks in a unified\ntheoretical framework. We introduce a new methodology to analyze brain\nresponses across tasks without a joint model of the psychological processes.\nThe method boosts statistical power in small studies with specific cognitive\nfocus by analyzing them jointly with large studies that probe less focal mental\nprocesses. Our approach improves decoding performance for 80% of 35\nwidely-different functional-imaging studies. It finds commonalities across\ntasks in a data-driven way, via common brain representations that predict\nmental processes. These are brain networks tuned to psychological\nmanipulations. They outline interpretable and plausible brain structures. The\nextracted networks have been made available; they can be readily reused in new\nneuro-imaging studies. We provide a multi-study decoding tool to adapt to new\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 06:19:11 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 06:50:24 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 08:37:14 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Mensch", "Arthur", "", "PARIETAL"], ["Mairal", "Julien", "", "Thoth"], ["Thirion", "Bertrand", "", "PARIETAL"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL"]]}, {"id": "1809.06040", "submitter": "Manjesh Kumar Hanawal", "authors": "Manjesh K. Hanawal and Sumit J. Darak", "title": "Multi-Player Bandits: A Trekking Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic multi-armed bandits with many players. The players do not\nknow the number of players, cannot communicate with each other and if multiple\nplayers select a common arm they collide and none of them receive any reward.\nWe consider the static scenario, where the number of players remains fixed, and\nthe dynamic scenario, where the players enter and leave at any time. We provide\nalgorithms based on a novel `trekking approach' that guarantees constant regret\nfor the static case and sub-linear regret for the dynamic case with high\nprobability. The trekking approach eliminates the need to estimate the number\nof players resulting in fewer collisions and improved regret performance\ncompared to the state-of-the-art algorithms. We also develop an epoch-less\nalgorithm that eliminates any requirement of time synchronization across the\nplayers provided each player can detect the presence of other players on an\narm. We validate our theoretical guarantees using simulation based and real\ntest-bed based experiments.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 06:29:43 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Hanawal", "Manjesh K.", ""], ["Darak", "Sumit J.", ""]]}, {"id": "1809.06045", "submitter": "Dominique Vaufreydaz", "authors": "Pavan Vasishta (UGA, CHROMA), Dominique Vaufreydaz (PERVASIVE), Anne\n  Spalanzani (CHROMA)", "title": "Building Prior Knowledge: A Markov Based Pedestrian Prediction Model\n  Using Urban Environmental Data", "comments": "15 th International Conference on Control, Automation, Robotics and\n  Vision (ICARCV 2018), Nov 2018, Singapore, Singapore", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Vehicles navigating in urban areas have a need to understand and\npredict future pedestrian behavior for safer navigation. This high level of\nsituational awareness requires observing pedestrian behavior and extrapolating\ntheir positions to know future positions. While some work has been done in this\nfield using Hidden Markov Models (HMMs), one of the few observed drawbacks of\nthe method is the need for informed priors for learning behavior. In this work,\nan extension to the Growing Hidden Markov Model (GHMM) method is proposed to\nsolve some of these drawbacks. This is achieved by building on existing work\nusing potential cost maps and the principle of Natural Vision. As a\nconsequence, the proposed model is able to predict pedestrian positions more\nprecisely over a longer horizon compared to the state of the art. The method is\ntested over \"legal\" and \"illegal\" behavior of pedestrians, having trained the\nmodel with sparse observations and partial trajectories. The method, with no\ntraining data, is compared against a trained state of the art model. It is\nobserved that the proposed method is robust even in new, previously unseen\nareas.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 07:06:44 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Vasishta", "Pavan", "", "UGA, CHROMA"], ["Vaufreydaz", "Dominique", "", "PERVASIVE"], ["Spalanzani", "Anne", "", "CHROMA"]]}, {"id": "1809.06056", "submitter": "Min-Hsiu Hsieh", "authors": "Yuxuan Du and Min-Hsiu Hsieh and Tongliang Liu and Dacheng Tao", "title": "Implementable Quantum Classifier for Nonlinear Data", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this Letter, we propose a quantum machine learning scheme for the\nclassification of classical nonlinear data. The main ingredients of our method\nare variational quantum perceptron (VQP) and a quantum generalization of\nclassical ensemble learning. Our VQP employs parameterized quantum circuits to\nlearn a Grover search (or amplitude amplification) operation with classical\noptimization, and can achieve quadratic speedup in query complexity compared to\nits classical counterparts. We show how the trained VQP can be used to predict\nfuture data with $O(1)$ {query} complexity. Ultimately, a stronger nonlinear\nclassifier can be established, the so-called quantum ensemble learning (QEL),\nby combining a set of weak VQPs produced using a subsampling method. The\nsubsampling method has two significant advantages. First, all $T$ weak VQPs\nemployed in QEL can be trained in parallel, therefore, the query complexity of\nQEL is equal to that of each weak VQP multiplied by $T$. Second, it\ndramatically reduce the {runtime} complexity of encoding circuits that map\nclassical data to a quantum state because this dataset can be significantly\nsmaller than the original dataset given to QEL. This arguably provides a most\nsatisfactory solution to one of the most criticized issues in quantum machine\nlearning proposals. To conclude, we perform two numerical experiments for our\nVQP and QEL, implemented by Python and pyQuil library. Our experiments show\nthat excellent performance can be achieved using a very small quantum circuit\nsize that is implementable under current quantum hardware development.\nSpecifically, given a nonlinear synthetic dataset with $4$ features for each\nexample, the trained QEL can classify the test examples that are sampled away\nfrom the decision boundaries using $146$ single and two qubits quantum gates\nwith $92\\%$ accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 07:48:03 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Du", "Yuxuan", ""], ["Hsieh", "Min-Hsiu", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1809.06059", "submitter": "Hengtao He", "authors": "Hengtao He, Shi Jin, Chao-Kai Wen, Feifei Gao, Geoffrey Ye Li, and\n  Zongben Xu", "title": "Model-Driven Deep Learning for Physical Layer Communications", "comments": "20 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent communication is gradually considered as the mainstream direction\nin future wireless communications. As a major branch of machine learning, deep\nlearning (DL) has been applied in physical layer communications and has\ndemonstrated an impressive performance improvement in recent years. However,\nmost of the existing works related to DL focus on data-driven approaches, which\nconsider the communication system as a black box and train it by using a huge\nvolume of data. Training a network requires sufficient computing resources and\nextensive time, both of which are rarely found in communication devices. By\ncontrast, model-driven DL approaches combine communication domain knowledge\nwith DL to reduce the demand for computing resources and training time. This\narticle reviews the recent advancements in the application of model-driven DL\napproaches in physical layer communications, including transmission scheme,\nreceiver design, and channel information recovery. Several open issues for\nfurther research are also highlighted after presenting the comprehensive\nsurvey.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 07:52:58 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2019 21:18:18 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["He", "Hengtao", ""], ["Jin", "Shi", ""], ["Wen", "Chao-Kai", ""], ["Gao", "Feifei", ""], ["Li", "Geoffrey Ye", ""], ["Xu", "Zongben", ""]]}, {"id": "1809.06061", "submitter": "Katia Sycara", "authors": "Rahul Iyer, Yuezhang Li, Huao Li, Michael Lewis, Ramitha Sundar, Katia\n  Sycara", "title": "Transparency and Explanation in Deep Reinforcement Learning Neural\n  Networks", "comments": "8 pages, 5 figures, Accepted at AAAI/ACM Conference on AI, Ethics,\n  and Society 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous AI systems will be entering human society in the near future to\nprovide services and work alongside humans. For those systems to be accepted\nand trusted, the users should be able to understand the reasoning process of\nthe system, i.e. the system should be transparent. System transparency enables\nhumans to form coherent explanations of the system's decisions and actions.\nTransparency is important not only for user trust, but also for software\ndebugging and certification. In recent years, Deep Neural Networks have made\ngreat advances in multiple application areas. However, deep neural networks are\nopaque. In this paper, we report on work in transparency in Deep Reinforcement\nLearning Networks (DRLN). Such networks have been extremely successful in\naccurately learning action control in image input domains, such as Atari games.\nIn this paper, we propose a novel and general method that (a) incorporates\nexplicit object recognition processing into deep reinforcement learning models,\n(b) forms the basis for the development of \"object saliency maps\", to provide\nvisualization of internal states of DRLNs, thus enabling the formation of\nexplanations and (c) can be incorporated in any existing deep reinforcement\nlearning framework. We present computational results and human experiments to\nevaluate our approach.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 07:56:35 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Iyer", "Rahul", ""], ["Li", "Yuezhang", ""], ["Li", "Huao", ""], ["Lewis", "Michael", ""], ["Sundar", "Ramitha", ""], ["Sycara", "Katia", ""]]}, {"id": "1809.06064", "submitter": "Katia Sycara", "authors": "Yuezhang Li, Katia Sycara, Rahul Iyer", "title": "Object-sensitive Deep Reinforcement Learning", "comments": "15 pages, 6 figures, Accepted at 3rd Global Conference on Artificial\n  Intelligence (GCAI-17), Miami, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has become popular over recent years, showing\nsuperiority on different visual-input tasks such as playing Atari games and\nrobot navigation. Although objects are important image elements, few work\nconsiders enhancing deep reinforcement learning with object characteristics. In\nthis paper, we propose a novel method that can incorporate object recognition\nprocessing to deep reinforcement learning models. This approach can be adapted\nto any existing deep reinforcement learning frameworks. State-of-the-art\nresults are shown in experiments on Atari games. We also propose a new approach\ncalled \"object saliency maps\" to visually explain the actions made by deep\nreinforcement learning agents.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 07:59:36 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Li", "Yuezhang", ""], ["Sycara", "Katia", ""], ["Iyer", "Rahul", ""]]}, {"id": "1809.06098", "submitter": "Alberto Maria Metelli", "authors": "Alberto Maria Metelli, Matteo Papini, Francesco Faccio, and Marcello\n  Restelli", "title": "Policy Optimization via Importance Sampling", "comments": null, "journal-ref": "32nd Conference on Neural Information Processing Systems (NIPS\n  2018), Montr\\'eal, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy optimization is an effective reinforcement learning approach to solve\ncontinuous control tasks. Recent achievements have shown that alternating\nonline and offline optimization is a successful choice for efficient trajectory\nreuse. However, deciding when to stop optimizing and collect new trajectories\nis non-trivial, as it requires to account for the variance of the objective\nfunction estimate. In this paper, we propose a novel, model-free, policy search\nalgorithm, POIS, applicable in both action-based and parameter-based settings.\nWe first derive a high-confidence bound for importance sampling estimation;\nthen we define a surrogate objective function, which is optimized offline\nwhenever a new batch of trajectories is collected. Finally, the algorithm is\ntested on a selection of continuous control tasks, with both linear and deep\npolicies, and compared with state-of-the-art policy optimization methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 09:42:26 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 10:47:21 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Metelli", "Alberto Maria", ""], ["Papini", "Matteo", ""], ["Faccio", "Francesco", ""], ["Restelli", "Marcello", ""]]}, {"id": "1809.06121", "submitter": "Amir Abdi", "authors": "Amir H. Abdi, Pramit Saha, Praneeth Srungarapu, Sidney Fels", "title": "Muscle Excitation Estimation in Biomechanical Simulation Using NAF\n  Reinforcement Learning", "comments": "9 pages, 3 figures. Computational Biomechanics for Medicine. MICCAI\n  2019. Springer, Cham", "journal-ref": null, "doi": "10.1007/978-3-030-15923-8_11", "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motor control is a set of time-varying muscle excitations which generate\ndesired motions for a biomechanical system. Muscle excitations cannot be\ndirectly measured from live subjects. An alternative approach is to estimate\nmuscle activations using inverse motion-driven simulation. In this article, we\npropose a deep reinforcement learning method to estimate the muscle excitations\nin simulated biomechanical systems. Here, we introduce a custom-made reward\nfunction which incentivizes faster point-to-point tracking of target motion.\nMoreover, we deploy two new techniques, namely, episode-based hard update and\ndual buffer experience replay, to avoid feedback training loops. The proposed\nmethod is tested in four simulated 2D and 3D environments with 6 to 24 axial\nmuscles. The results show that the models were able to learn muscle excitations\nfor given motions after nearly 100,000 simulated steps. Moreover, the root mean\nsquare error in point-to-point reaching of the target across experiments was\nless than 1% of the length of the domain of motion. Our reinforcement learning\nmethod is far from the conventional dynamic approaches as the muscle control is\nderived functionally by a set of distributed neurons. This can open paths for\nneural activity interpretation of this phenomenon.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 10:38:20 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 21:12:12 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Abdi", "Amir H.", ""], ["Saha", "Pramit", ""], ["Srungarapu", "Praneeth", ""], ["Fels", "Sidney", ""]]}, {"id": "1809.06124", "submitter": "Ioannis Sarafis", "authors": "Ioannis Sarafis, Christos Diou, Anastasios Delopoulos", "title": "Span error bound for weighted SVM with applications in hyperparameter\n  selection", "comments": "35 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted SVM (or fuzzy SVM) is the most widely used SVM variant owning its\neffectiveness to the use of instance weights. Proper selection of the instance\nweights can lead to increased generalization performance. In this work, we\nextend the span error bound theory to weighted SVM and we introduce effective\nhyperparameter selection methods for the weighted SVM algorithm. The\nsignificance of the presented work is that enables the application of span\nbound and span-rule with weighted SVM. The span bound is an upper bound of the\nleave-one-out error that can be calculated using a single trained SVM model.\nThis is important since leave-one-out error is an almost unbiased estimator of\nthe test error. Similarly, the span-rule gives the actual value of the\nleave-one-out error. Thus, one can apply span bound and span-rule as\ncomputationally lightweight alternatives of leave-one-out procedure for\nhyperparameter selection. The main theoretical contributions are: (a) we prove\nthe necessary and sufficient condition for the existence of the span of a\nsupport vector in weighted SVM; and (b) we prove the extension of span bound\nand span-rule to weighted SVM. We experimentally evaluate the span bound and\nthe span-rule for hyperparameter selection and we compare them with other\nmethods that are applicable to weighted SVM: the $K$-fold cross-validation and\nthe ${\\xi}-{\\alpha}$ bound. Experiments on 14 benchmark data sets and data sets\nwith importance scores for the training instances show that: (a) the condition\nfor the existence of span in weighted SVM is satisfied almost always; (b) the\nspan-rule is the most effective method for weighted SVM hyperparameter\nselection; (c) the span-rule is the best predictor of the test error in the\nmean square error sense; and (d) the span-rule is efficient and, for certain\nproblems, it can be calculated faster than $K$-fold cross-validation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 10:50:25 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sarafis", "Ioannis", ""], ["Diou", "Christos", ""], ["Delopoulos", "Anastasios", ""]]}, {"id": "1809.06131", "submitter": "Bowen Cheng", "authors": "Bowen Cheng, Rong Xiao, Yandong Guo, Yuxiao Hu, Jianfeng Wang, Lei\n  Zhang", "title": "Revisit Multinomial Logistic Regression in Deep Learning: Data Dependent\n  Model Initialization for Image Recognition", "comments": "tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study in this paper how to initialize the parameters of multinomial\nlogistic regression (a fully connected layer followed with softmax and cross\nentropy loss), which is widely used in deep neural network (DNN) models for\nclassification problems. As logistic regression is widely known not having a\nclosed-form solution, it is usually randomly initialized, leading to several\ndeficiencies especially in transfer learning where all the layers except for\nthe last task-specific layer are initialized using a pre-trained model. The\ndeficiencies include slow convergence speed, possibility of stuck in local\nminimum, and the risk of over-fitting. To address those deficiencies, we first\nstudy the properties of logistic regression and propose a closed-form\napproximate solution named regularized Gaussian classifier (RGC). Then we adopt\nthis approximate solution to initialize the task-specific linear layer and\ndemonstrate superior performance over random initialization in terms of both\naccuracy and convergence speed on various tasks and datasets. For example, for\nimage classification, our approach can reduce the training time by 10 times and\nachieve 3.2% gain in accuracy for Flickr-style classification. For object\ndetection, our approach can also be 10 times faster in training for the same\naccuracy, or 5% better in terms of mAP for VOC 2007 with slightly longer\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 11:23:33 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Cheng", "Bowen", ""], ["Xiao", "Rong", ""], ["Guo", "Yandong", ""], ["Hu", "Yuxiao", ""], ["Wang", "Jianfeng", ""], ["Zhang", "Lei", ""]]}, {"id": "1809.06146", "submitter": "Manfred Eppe", "authors": "Manfred Eppe, Sven Magg and Stefan Wermter", "title": "Curriculum goal masking for continuous deep reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has recently gained a focus on problems where\npolicy or value functions are independent of goals. Evidence exists that the\nsampling of goals has a strong effect on the learning performance, but there is\na lack of general mechanisms that focus on optimizing the goal sampling\nprocess. In this work, we present a simple and general goal masking method that\nalso allows us to estimate a goal's difficulty level and thus realize a\ncurriculum learning approach for deep RL. Our results indicate that focusing on\ngoals with a medium difficulty level is appropriate for deep deterministic\npolicy gradient (DDPG) methods, while an \"aim for the stars and reach the\nmoon-strategy\", where hard goals are sampled much more often than simple goals,\nleads to the best learning performance in cases where DDPG is combined with for\nhindsight experience replay (HER). We demonstrate that the approach\nsignificantly outperforms standard goal sampling for different robotic object\nmanipulation problems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 12:01:02 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 12:02:59 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Eppe", "Manfred", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1809.06148", "submitter": "Astha Sharma", "authors": "Astha Sharma", "title": "Dynamics Estimation Using Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a plenty of research going on in field of robotics. One of the most\nimportant task is dynamic estimation of response during motion. One of the main\napplications of this research topics is the task of pouring, which is performed\ndaily and is commonly used while cooking. We present an approach to estimate\nresponse to a sequence of manipulation actions. We are experimenting with\npouring motion and the response is the change of the amount of water in the\npouring cup. The pouring motion is represented by rotation angle and the amount\nof water is represented by its weight. We are using recurrent neural networks\nfor building the neural network model to train on sequences which represents\n1307 trails of pouring. The model gives great results on unseen test data which\ndoes not too different with training data in terms of dimensions of the cup\nused for pouring and receiving. The loss obtained with this test data is\n4.5920. The model does not give good results on generalization experiments when\nwe provide a test set which has dimensions of the cup very different from those\nin training data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 12:01:54 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sharma", "Astha", ""]]}, {"id": "1809.06166", "submitter": "Nicholas Choma", "authors": "Nicholas Choma, Federico Monti, Lisa Gerhardt, Tomasz Palczewski,\n  Zahra Ronaghi, Prabhat, Wahid Bhimji, Michael M. Bronstein, Spencer R. Klein,\n  Joan Bruna", "title": "Graph Neural Networks for IceCube Signal Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tasks involving the analysis of geometric (graph- and manifold-structured)\ndata have recently gained prominence in the machine learning community, giving\nbirth to a rapidly developing field of geometric deep learning. In this work,\nwe leverage graph neural networks to improve signal detection in the IceCube\nneutrino observatory. The IceCube detector array is modeled as a graph, where\nvertices are sensors and edges are a learned function of the sensors' spatial\ncoordinates. As only a subset of IceCube's sensors is active during a given\nobservation, we note the adaptive nature of our GNN, wherein computation is\nrestricted to the input signal support. We demonstrate the effectiveness of our\nGNN architecture on a task classifying IceCube events, where it outperforms\nboth a traditional physics-based method as well as classical 3D convolution\nneural networks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 12:45:01 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Choma", "Nicholas", ""], ["Monti", "Federico", ""], ["Gerhardt", "Lisa", ""], ["Palczewski", "Tomasz", ""], ["Ronaghi", "Zahra", ""], ["Prabhat", "", ""], ["Bhimji", "Wahid", ""], ["Bronstein", "Michael M.", ""], ["Klein", "Spencer R.", ""], ["Bruna", "Joan", ""]]}, {"id": "1809.06176", "submitter": "Colin de Vrieze", "authors": "Colin de Vrieze, Ljiljana Simi\\'c, Petri M\\\"ah\\\"onen", "title": "The Importance of Being Earnest: Performance of Modulation\n  Classification for Real RF Signals", "comments": "published in DySPAN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital modulation classification (DMC) can be highly valuable for equipping\nradios with increased spectrum awareness in complex emerging wireless networks.\nHowever, as the existing literature is overwhelmingly based on theoretical or\nsimulation results, it is unclear how well DMC performs in practice. In this\npaper we study the performance of DMC in real-world wireless networks, using an\nextensive RF signal dataset of 250,000 over-the-air transmissions with\nheterogeneous transceiver hardware and co-channel interference. Our results\nshow that DMC can achieve a high classification accuracy even under the\nchallenging real-world conditions of modulated co-channel interference and\nlow-grade hardware. However, this only holds if the training dataset fully\ncaptures the variety of interference and hardware types in the real radio\nenvironment; otherwise, the DMC performance deteriorates significantly. Our\nwork has two important engineering implications. First, it shows that it is not\nstraightforward to exchange learned classifier models among dissimilar radio\nenvironments and devices in practice. Second, our analysis suggests that the\nkey missing link for real-world deployment of DMC is designing signal features\nthat generalize well to diverse wireless network scenarios. We are making our\nRF signal dataset publicly available as a step towards a unified framework for\nrealistic DMC evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:06:43 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 12:11:04 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["de Vrieze", "Colin", ""], ["Simi\u0107", "Ljiljana", ""], ["M\u00e4h\u00f6nen", "Petri", ""]]}, {"id": "1809.06179", "submitter": "Bilal Wehbe", "authors": "Bilal Wehbe, Octavio Arriaga, Mario Michael Krell, and Frank Kirchner", "title": "Learning of Multi-Context Models for Autonomous Underwater Vehicles", "comments": "6 pages, 7 figures, AUV 2018 author copy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-context model learning is crucial for marine robotics where several\nfactors can cause disturbances to the system's dynamics. This work addresses\nthe problem of identifying multiple contexts of an AUV model. We build a\nsimulation model of the robot from experimental data, and use it to fill in the\nmissing data and generate different model contexts. We implement an\narchitecture based on long-short-term-memory (LSTM) networks to learn the\ndifferent contexts directly from the data. We show that the LSTM network can\nachieve high classification accuracy compared to baseline methods, showing\nrobustness against noise and scaling efficiently on large datasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:12:47 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Wehbe", "Bilal", ""], ["Arriaga", "Octavio", ""], ["Krell", "Mario Michael", ""], ["Kirchner", "Frank", ""]]}, {"id": "1809.06186", "submitter": "Md. Abu Bakr Siddique", "authors": "Mohammad Mahmudur Rahman Khan, Rezoana Bente Arif, Md. Abu Bakr\n  Siddique, Mahjabin Rahman Oishe", "title": "Study and Observation of the Variation of Accuracies of KNN, SVM, LMNN,\n  ENN Algorithms on Eleven Different Datasets from UCI Machine Learning\n  Repository", "comments": "To be published in the 4th IEEE International Conference on\n  Electrical Engineering and Information & Communication Technology (iCEEiCT\n  2018)", "journal-ref": "2018 4th International Conference on Electrical Engineering and\n  Information & Communication Technology (iCEEiCT)", "doi": "10.1109/CEEICT.2018.8628041", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning qualifies computers to assimilate with data, without being\nsolely programmed [1, 2]. Machine learning can be classified as supervised and\nunsupervised learning. In supervised learning, computers learn an objective\nthat portrays an input to an output hinged on training input-output pairs [3].\nMost efficient and widely used supervised learning algorithms are K-Nearest\nNeighbors (KNN), Support Vector Machine (SVM), Large Margin Nearest Neighbor\n(LMNN), and Extended Nearest Neighbor (ENN). The main contribution of this\npaper is to implement these elegant learning algorithms on eleven different\ndatasets from the UCI machine learning repository to observe the variation of\naccuracies for each of the algorithms on all datasets. Analyzing the accuracy\nof the algorithms will give us a brief idea about the relationship of the\nmachine learning algorithms and the data dimensionality. All the algorithms are\ndeveloped in Matlab. Upon such accuracy observation, the comparison can be\nbuilt among KNN, SVM, LMNN, and ENN regarding their performances on each\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:27:43 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 12:11:41 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 16:57:47 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Khan", "Mohammad Mahmudur Rahman", ""], ["Arif", "Rezoana Bente", ""], ["Siddique", "Md. Abu Bakr", ""], ["Oishe", "Mahjabin Rahman", ""]]}, {"id": "1809.06187", "submitter": "Md. Abu Bakr Siddique", "authors": "Rezoana Bente Arif, Md. Abu Bakr Siddique, Mohammad Mahmudur Rahman\n  Khan, Mahjabin Rahman Oishe", "title": "Study and Observation of the Variations of Accuracies for Handwritten\n  Digits Recognition with Various Hidden Layers and Epochs using Convolutional\n  Neural Network", "comments": "To be published in the 4th IEEE International Conference on\n  Electrical Engineering and Information & Communication Technology (iCEEiCT\n  2018)", "journal-ref": "2018 4th International Conference on Electrical Engineering and\n  Information & Communication Technology (iCEEiCT)", "doi": "10.1109/CEEICT.2018.8628078", "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nowadays, deep learning can be employed to a wide ranges of fields including\nmedicine, engineering, etc. In deep learning, Convolutional Neural Network\n(CNN) is extensively used in the pattern and sequence recognition, video\nanalysis, natural language processing, spam detection, topic categorization,\nregression analysis, speech recognition, image classification, object\ndetection, segmentation, face recognition, robotics, and control. The benefits\nassociated with its near human level accuracies in large applications lead to\nthe growing acceptance of CNN in recent years. The primary contribution of this\npaper is to analyze the impact of the pattern of the hidden layers of a CNN\nover the overall performance of the network. To demonstrate this influence, we\napplied neural network with different layers on the Modified National Institute\nof Standards and Technology (MNIST) dataset. Also, is to observe the variations\nof accuracies of the network for various numbers of hidden layers and epochs\nand to make comparison and contrast among them. The system is trained utilizing\nstochastic gradient and backpropagation algorithm and tested with feedforward\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:28:02 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 12:08:57 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 16:56:11 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Arif", "Rezoana Bente", ""], ["Siddique", "Md. Abu Bakr", ""], ["Khan", "Mohammad Mahmudur Rahman", ""], ["Oishe", "Mahjabin Rahman", ""]]}, {"id": "1809.06188", "submitter": "Md. Abu Bakr Siddique", "authors": "Md. Abu Bakr Siddique, Mohammad Mahmudur Rahman Khan, Rezoana Bente\n  Arif, Zahidun Ashrafi", "title": "Study and Observation of the Variations of Accuracies for Handwritten\n  Digits Recognition with Various Hidden Layers and Epochs using Neural Network\n  Algorithm", "comments": "To be published in the 4th IEEE International Conference on\n  Electrical Engineering and Information & Communication Technology (iCEEiCT\n  2018)", "journal-ref": "2018 4th International Conference on Electrical Engineering and\n  Information & Communication Technology (iCEEiCT)", "doi": "10.1109/CEEICT.2018.8628144", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent days, Artificial Neural Network (ANN) can be applied to a vast\nmajority of fields including business, medicine, engineering, etc. The most\npopular areas where ANN is employed nowadays are pattern and sequence\nrecognition, novelty detection, character recognition, regression analysis,\nspeech recognition, image compression, stock market prediction, Electronic\nnose, security, loan applications, data processing, robotics, and control. The\nbenefits associated with its broad applications leads to increasing popularity\nof ANN in the era of 21st Century. ANN confers many benefits such as organic\nlearning, nonlinear data processing, fault tolerance, and self-repairing\ncompared to other conventional approaches. The primary objective of this paper\nis to analyze the influence of the hidden layers of a neural network over the\noverall performance of the network. To demonstrate this influence, we applied\nneural network with different layers on the MNIST dataset. Also, another goal\nis to observe the variations of accuracies of ANN for different numbers of\nhidden layers and epochs and to compare and contrast among them.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:28:19 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 12:06:34 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 16:54:07 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Siddique", "Md. Abu Bakr", ""], ["Khan", "Mohammad Mahmudur Rahman", ""], ["Arif", "Rezoana Bente", ""], ["Ashrafi", "Zahidun", ""]]}, {"id": "1809.06189", "submitter": "Md. Abu Bakr Siddique", "authors": "Mohammad Mahmudur Rahman Khan, Md. Abu Bakr Siddique, Rezoana Bente\n  Arif, Mahjabin Rahman Oishe", "title": "ADBSCAN: Adaptive Density-Based Spatial Clustering of Applications with\n  Noise for Identifying Clusters with Varying Densities", "comments": "To be published in the 4th IEEE International Conference on\n  Electrical Engineering and Information & Communication Technology (iCEEiCT\n  2018)", "journal-ref": "2018 4th International Conference on Electrical Engineering and\n  Information & Communication Technology (iCEEiCT)", "doi": "10.1109/CEEICT.2018.8628138", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Density-based spatial clustering of applications with noise (DBSCAN) is a\ndata clustering algorithm which has the high-performance rate for dataset where\nclusters have the constant density of data points. One of the significant\nattributes of this algorithm is noise cancellation. However, DBSCAN\ndemonstrates reduced performances for clusters with different densities.\nTherefore, in this paper, an adaptive DBSCAN is proposed which can work\nsignificantly well for identifying clusters with varying densities.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:28:35 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 12:03:42 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 16:51:05 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Khan", "Mohammad Mahmudur Rahman", ""], ["Siddique", "Md. Abu Bakr", ""], ["Arif", "Rezoana Bente", ""], ["Oishe", "Mahjabin Rahman", ""]]}, {"id": "1809.06201", "submitter": "Matthew Guzdial", "authors": "Zijin Luo, Matthew Guzdial, Nicholas Liao and Mark Riedl", "title": "Player Experience Extraction from Gameplay Video", "comments": "8 pages, 6 figures, AIIDE 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to extract the sequence of game events for a given player's\nplay-through has traditionally required access to the game's engine or source\ncode. This serves as a barrier to researchers, developers, and hobbyists who\nmight otherwise benefit from these game logs. In this paper we present two\napproaches to derive game logs from game video via convolutional neural\nnetworks and transfer learning. We evaluate the approaches in a Super Mario\nBros. clone, Mega Man and Skyrim. Our results demonstrate our approach\noutperforms random forest and other transfer baselines.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 22:00:46 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Luo", "Zijin", ""], ["Guzdial", "Matthew", ""], ["Liao", "Nicholas", ""], ["Riedl", "Mark", ""]]}, {"id": "1809.06209", "submitter": "Ahsan Tufail Mr.", "authors": "Ahsan Bin Tufail, Qiu-Na Zhang, Yong-Kui Ma", "title": "Binary Classification of Alzheimer Disease using sMRI Imaging modality\n  and Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1007/s10278-019-00265-5", "report-no": null, "categories": "cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease (AD) is an irreversible devastative neurodegenerative\ndisorder associated with progressive impairment of memory and cognitive\nfunctions. Its early diagnosis is crucial for the development of possible\nfuture treatment option(s). Structural magnetic resonance images (sMRI) plays\nan important role to help in understanding the anatomical changes related to AD\nespecially in its early stages. Conventional methods require the expertise of\ndomain experts and extract hand-picked features such as gray matter\nsubstructures and train a classifier to distinguish AD subjects from healthy\nsubjects. Different from these methods, this paper proposes to construct\nmultiple deep 2D convolutional neural networks (2D-CNNs) to learn the various\nfeatures from local brain images which are combined to make the final\nclassification for AD diagnosis. The whole brain image was passed through two\ntransfer learning architectures; Inception version 3 and Xception; as well as\ncustom Convolutional Neural Network (CNN) built with the help of separable\nconvolutional layers which can automatically learn the generic features from\nimaging data for classification. Our study is conducted using cross-sectional\nT1-weighted structural MRI brain images from Open Access Series of Imaging\nStudies (OASIS) database to maintain the size and contrast over different MRI\nscans. Experimental results show that the transfer learning approaches exceed\nthe performance of non-transfer learning based approaches demonstrating the\neffectiveness of these approaches for the binary AD classification task.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 01:46:37 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 14:02:39 GMT"}, {"version": "v3", "created": "Fri, 3 Apr 2020 18:04:27 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Tufail", "Ahsan Bin", ""], ["Zhang", "Qiu-Na", ""], ["Ma", "Yong-Kui", ""]]}, {"id": "1809.06213", "submitter": "Zhen Cui", "authors": "Zhen Cui, Chunyan Xu, Wenming Zheng and Jian Yang", "title": "Context-Dependent Diffusion Network for Visual Relationship Detection", "comments": "8 pages, 3 figures, 2018 ACM Multimedia Conference (MM'18)", "journal-ref": null, "doi": "10.1145/3240508.3240668", "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual relationship detection can bridge the gap between computer vision and\nnatural language for scene understanding of images. Different from pure object\nrecognition tasks, the relation triplets of subject-predicate-object lie on an\nextreme diversity space, such as \\textit{person-behind-person} and\n\\textit{car-behind-building}, while suffering from the problem of combinatorial\nexplosion. In this paper, we propose a context-dependent diffusion network\n(CDDN) framework to deal with visual relationship detection. To capture the\ninteractions of different object instances, two types of graphs, word semantic\ngraph and visual scene graph, are constructed to encode global context\ninterdependency. The semantic graph is built through language priors to model\nsemantic correlations across objects, whilst the visual scene graph defines the\nconnections of scene objects so as to utilize the surrounding scene\ninformation. For the graph-structured data, we design a diffusion network to\nadaptively aggregate information from contexts, which can effectively learn\nlatent representations of visual relationships and well cater to visual\nrelationship detection in view of its isomorphic invariance to graphs.\nExperiments on two widely-used datasets demonstrate that our proposed method is\nmore effective and achieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 02:13:45 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Cui", "Zhen", ""], ["Xu", "Chunyan", ""], ["Zheng", "Wenming", ""], ["Yang", "Jian", ""]]}, {"id": "1809.06214", "submitter": "ChengKuan Chen", "authors": "Cheng Kuan Chen, Zhu Feng Pan, Min Sun, Ming-Yu Liu", "title": "Unsupervised Stylish Image Description Generation via Domain Layer Norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing works on image description focus on generating\nexpressive descriptions. The only few works that are dedicated to generating\nstylish (e.g., romantic, lyric, etc.) descriptions suffer from limited style\nvariation and content digression. To address these limitations, we propose a\ncontrollable stylish image description generation model. It can learn to\ngenerate stylish image descriptions that are more related to image content and\ncan be trained with the arbitrary monolingual corpus without collecting new\npaired image and stylish descriptions. Moreover, it enables users to generate\nvarious stylish descriptions by plugging in style-specific parameters to\ninclude new styles into the existing model. We achieve this capability via a\nnovel layer normalization layer design, which we will refer to as the Domain\nLayer Norm (DLN). Extensive experimental validation and user study on various\nstylish image description generation tasks are conducted to show the\ncompetitive advantages of the proposed model.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 11:07:26 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Chen", "Cheng Kuan", ""], ["Pan", "Zhu Feng", ""], ["Sun", "Min", ""], ["Liu", "Ming-Yu", ""]]}, {"id": "1809.06219", "submitter": "Meenakshi Khosla", "authors": "Meenakshi Khosla, Keith Jamison, Amy Kuceyeski, Mert R. Sabuncu", "title": "Ensemble learning with 3D convolutional neural networks for\n  connectome-based prediction", "comments": "45 pages, 9 figures, 4 supplementary figures (To appear in\n  Neuroimage)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The specificty and sensitivity of resting state functional MRI (rs-fMRI)\nmeasurements depend on pre-processing choices, such as the parcellation scheme\nused to define regions of interest (ROIs). In this study, we critically\nevaluate the effect of brain parcellations on machine learning models applied\nto rs-fMRI data. Our experiments reveal a remarkable trend: On average, models\nwith stochastic parcellations consistently perform as well as models with\nwidely used atlases at the same spatial scale. We thus propose an ensemble\nlearning strategy to combine the predictions from models trained on\nconnectivity data extracted using different (e.g., stochastic) parcellations.\nWe further present an implementation of our ensemble learning strategy with a\nnovel 3D Convolutional Neural Network (CNN) approach. The proposed CNN approach\ntakes advantage of the full-resolution 3D spatial structure of rs-fMRI data and\nfits non-linear predictive models. Our ensemble CNN framework overcomes the\nlimitations of traditional machine learning models for connectomes that often\nrely on region-based summary statistics and/or linear models. We showcase our\napproach on a classification (autism patients versus healthy controls) and a\nregression problem (prediction of subject's age), and report promising results.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 17:55:10 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 21:55:28 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Khosla", "Meenakshi", ""], ["Jamison", "Keith", ""], ["Kuceyeski", "Amy", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1809.06222", "submitter": "Christoph Baur", "authors": "Salome Kazeminia, Christoph Baur, Arjan Kuijper, Bram van Ginneken,\n  Nassir Navab, Shadi Albarqouni, Anirban Mukhopadhyay", "title": "GANs for Medical Image Analysis", "comments": "Salome Kazeminia and Christoph Baur contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) and their extensions have carved open\nmany exciting ways to tackle well known and challenging medical image analysis\nproblems such as medical image de-noising, reconstruction, segmentation, data\nsimulation, detection or classification. Furthermore, their ability to\nsynthesize images at unprecedented levels of realism also gives hope that the\nchronic scarcity of labeled data in the medical field can be resolved with the\nhelp of these generative models. In this review paper, a broad overview of\nrecent literature on GANs for medical applications is given, the shortcomings\nand opportunities of the proposed methods are thoroughly discussed and\npotential future work is elaborated. We review the most relevant papers\npublished until the submission date. For quick access, important details such\nas the underlying method, datasets and performance are tabulated. An\ninteractive visualization which categorizes all papers to keep the review\nalive, is available at\nhttp://livingreview.in.tum.de/GANs_for_Medical_Applications.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 21:38:29 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 23:34:44 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 06:31:07 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Kazeminia", "Salome", ""], ["Baur", "Christoph", ""], ["Kuijper", "Arjan", ""], ["van Ginneken", "Bram", ""], ["Navab", "Nassir", ""], ["Albarqouni", "Shadi", ""], ["Mukhopadhyay", "Anirban", ""]]}, {"id": "1809.06226", "submitter": "Stergios Christodoulidis Mr.", "authors": "Stergios Christodoulidis, Mihir Sahasrabudhe, Maria Vakalopoulou,\n  Guillaume Chassagnon, Marie-Pierre Revel, Stavroula Mougiakakou, Nikos\n  Paragios", "title": "Linear and Deformable Image Registration with 3D Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration and in particular deformable registration methods are\npillars of medical imaging. Inspired by the recent advances in deep learning,\nwe propose in this paper, a novel convolutional neural network architecture\nthat couples linear and deformable registration within a unified architecture\nendowed with near real-time performance. Our framework is modular with respect\nto the global transformation component, as well as with respect to the\nsimilarity function while it guarantees smooth displacement fields. We evaluate\nthe performance of our network on the challenging problem of MRI lung\nregistration, and demonstrate superior performance with respect to state of the\nart elastic registration methods. The proposed deformation (between inspiration\n& expiration) was considered within a clinically relevant task of interstitial\nlung disease (ILD) classification and showed promising results.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 14:56:44 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Christodoulidis", "Stergios", ""], ["Sahasrabudhe", "Mihir", ""], ["Vakalopoulou", "Maria", ""], ["Chassagnon", "Guillaume", ""], ["Revel", "Marie-Pierre", ""], ["Mougiakakou", "Stavroula", ""], ["Paragios", "Nikos", ""]]}, {"id": "1809.06227", "submitter": "Tszhang Guo", "authors": "Tszhang Guo, Shiyu Chang, Mo Yu and Kun Bai", "title": "Improving Reinforcement Learning Based Image Captioning with Natural\n  Language Prior", "comments": "8 pages, 5 figures, EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Reinforcement Learning (RL) approaches have demonstrated advanced\nperformance in image captioning by directly optimizing the metric used for\ntesting. However, this shaped reward introduces learning biases, which reduces\nthe readability of generated text. In addition, the large sample space makes\ntraining unstable and slow. To alleviate these issues, we propose a simple\ncoherent solution that constrains the action space using an n-gram language\nprior. Quantitative and qualitative evaluations on benchmarks show that RL with\nthe simple add-on module performs favorably against its counterpart in terms of\nboth readability and speed of convergence. Human evaluation results show that\nour model is more human readable and graceful. The implementation will become\npublicly available upon the acceptance of the paper.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 17:21:56 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Guo", "Tszhang", ""], ["Chang", "Shiyu", ""], ["Yu", "Mo", ""], ["Bai", "Kun", ""]]}, {"id": "1809.06247", "submitter": "Mai Nguyen", "authors": "Ehab Abdelmaguid, Jolene Huang, Sanjay Kenchareddy, Disha Singla,\n  Laura Wilke, Mai H. Nguyen, Ilkay Altintas", "title": "Left Ventricle Segmentation and Volume Estimation on Cardiac MRI using\n  Deep Learning", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the United States, heart disease is the leading cause of death for both\nmen and women, accounting for 610,000 deaths each year [1]. Physicians use\nMagnetic Resonance Imaging (MRI) scans to take images of the heart in order to\nnon-invasively estimate its structural and functional parameters for\ncardiovascular diagnosis and disease management. The end-systolic volume (ESV)\nand end-diastolic volume (EDV) of the left ventricle (LV), and the ejection\nfraction (EF) are indicators of heart disease. These measures can be derived\nfrom the segmented contours of the LV; thus, consistent and accurate\nsegmentation of the LV from MRI images are critical to the accuracy of the ESV,\nEDV, and EF, and to non-invasive cardiac disease detection.\n  In this work, various image preprocessing techniques, model configurations\nusing the U-Net deep learning architecture, postprocessing methods, and\napproaches for volume estimation are investigated. An end-to-end analytics\npipeline with multiple stages is provided for automated LV segmentation and\nvolume estimation. First, image data are reformatted and processed from DICOM\nand NIfTI formats to raw images in array format. Secondly, raw images are\nprocessed with multiple image preprocessing methods and cropped to include only\nthe Region of Interest (ROI). Thirdly, preprocessed images are segmented using\nU-Net models. Lastly, post processing of segmented images to remove extra\ncontours along with intelligent slice and frame selection are applied, followed\nby calculation of the ESV, EDV, and EF. This analytics pipeline is implemented\nand runs on a distributed computing environment with a GPU cluster at the San\nDiego Supercomputer Center at UCSD.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 06:40:07 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 16:58:27 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Abdelmaguid", "Ehab", ""], ["Huang", "Jolene", ""], ["Kenchareddy", "Sanjay", ""], ["Singla", "Disha", ""], ["Wilke", "Laura", ""], ["Nguyen", "Mai H.", ""], ["Altintas", "Ilkay", ""]]}, {"id": "1809.06253", "submitter": "Leonardo Gutierrez", "authors": "Leonardo Gutierrez Gomez, Jean-Charles Delvenne", "title": "Multi-hop assortativities for networks classification", "comments": "20 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:1705.10817", "journal-ref": null, "doi": "10.1093/comnet/cny034", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several social, medical, engineering and biological challenges rely on\ndiscovering the functionality of networks from their structure and node\nmetadata, when it is available. For example, in chemoinformatics one might want\nto detect whether a molecule is toxic based on structure and atomic types, or\ndiscover the research field of a scientific collaboration network. Existing\ntechniques rely on counting or measuring structural patterns that are known to\nshow large variations from network to network, such as the number of triangles,\nor the assortativity of node metadata. We introduce the concept of multi-hop\nassortativity, that captures the similarity of the nodes situated at the\nextremities of a randomly selected path of a given length. We show that\nmulti-hop assortativity unifies various existing concepts and offers a\nversatile family of 'fingerprints' to characterize networks. These fingerprints\nallow in turn to recover the functionalities of a network, with the help of the\nmachine learning toolbox. Our method is evaluated empirically on established\nsocial and chemoinformatic network benchmarks. Results reveal that our\nassortativity based features are competitive providing highly accurate results\noften outperforming state of the art methods for the network classification\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 13:33:35 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 09:28:51 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Gomez", "Leonardo Gutierrez", ""], ["Delvenne", "Jean-Charles", ""]]}, {"id": "1809.06277", "submitter": "Adithya M Devraj", "authors": "Adithya M. Devraj, Ana Bu\\v{s}i\\'c, Sean Meyn", "title": "Optimal Matrix Momentum Stochastic Approximation and Applications to\n  Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acceleration is an increasingly common theme in the stochastic optimization\nliterature. The two most common examples are Nesterov's method, and Polyak's\nmomentum technique. In this paper two new algorithms are introduced for root\nfinding problems: 1) PolSA is a root finding algorithm with specially designed\nmatrix momentum, and 2) NeSA can be regarded as a variant of Nesterov's\nalgorithm, or a simplification of PolSA. The PolSA algorithm is new even in the\ncontext of optimization (when cast as a root finding problem).\n  The research surveyed in this paper is motivated by applications to\nreinforcement learning. It is well known that most variants of TD- and\nQ-learning may be cast as SA (stochastic approximation) algorithms, and the\ntools from general SA theory can be used to investigate convergence and bounds\non convergence rate. In particular, the asymptotic variance is a common metric\nof performance for SA algorithms, and is also one among many metrics used in\nassessing the performance of stochastic optimization algorithms. There are two\nwell known SA techniques that are known to have optimal asymptotic variance:\nthe Ruppert-Polyak averaging technique, and stochastic Newton-Raphson (SNR).\nThe former algorithm can have extremely bad transient performance, and the\nlatter can be computationally expensive. It is demonstrated here that parameter\nestimates from the new PolSA algorithm couple with those of the ideal (but more\ncomplex) SNR algorithm. The new algorithm is thus a third approach to obtain\noptimal asymptotic covariance.\n  These strong results require assumptions on the model. A linearized model is\nconsidered, and the noise is assumed to be a martingale difference sequence.\nNumerical results are obtained in a non-linear setting that is the motivation\nfor this work: In PolSA implementations of Q-learning it is observed that\ncoupling occurs with SNR in this non-ideal setting.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 15:32:20 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 23:21:45 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Devraj", "Adithya M.", ""], ["Bu\u0161i\u0107", "Ana", ""], ["Meyn", "Sean", ""]]}, {"id": "1809.06304", "submitter": "Andre Manoel", "authors": "Andre Manoel, Florent Krzakala, Ga\\\"el Varoquaux, Bertrand Thirion,\n  Lenka Zdeborov\\'a", "title": "Approximate message-passing for convex optimization with non-separable\n  penalties", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an iterative optimization scheme for convex objectives\nconsisting of a linear loss and a non-separable penalty, based on the\nexpectation-consistent approximation and the vector approximate message-passing\n(VAMP) algorithm. Specifically, the penalties we approach are convex on a\nlinear transformation of the variable to be determined, a notable example being\ntotal variation (TV). We describe the connection between message-passing\nalgorithms -- typically used for approximate inference -- and proximal methods\nfor optimization, and show that our scheme is, as VAMP, similar in nature to\nthe Peaceman-Rachford splitting, with the important difference that stepsizes\nare set adaptively. Finally, we benchmark the performance of our VAMP-like\niteration in problems where TV penalties are useful, namely classification in\ntask fMRI and reconstruction in tomography, and show faster convergence than\nthat of state-of-the-art approaches such as FISTA and ADMM in most settings.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 16:14:55 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Manoel", "Andre", ""], ["Krzakala", "Florent", ""], ["Varoquaux", "Ga\u00ebl", ""], ["Thirion", "Bertrand", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1809.06334", "submitter": "Edward Pyzer-Knapp", "authors": "Clyde Fare, Lukas Turcani, Edward O. Pyzer-Knapp", "title": "Powerful, transferable representations for molecules through intelligent\n  task selection in deep multitask networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical representations derived from deep learning are emerging as a\npowerful tool in areas such as drug discovery and materials innovation.\nCurrently, this methodology has three major limitations - the cost of\nrepresentation generation, risk of inherited bias, and the requirement for\nlarge amounts of data. We propose the use of multi-task learning in tandem with\ntransfer learning to address these limitations directly. In order to avoid\nintroducing unknown bias into multi-task learning through the task selection\nitself, we calculate task similarity through pairwise task affinity, and use\nthis measure to programmatically select tasks. We test this methodology on\nseveral real-world data sets to demonstrate its potential for execution in\ncomplex and low-data environments. Finally, we utilise the task similarity to\nfurther probe the expressiveness of the learned representation through a\ncomparison to a commonly used cheminformatics fingerprint, and show that the\ndeep representation is able to capture more expressive task-based information.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 17:06:06 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Fare", "Clyde", ""], ["Turcani", "Lukas", ""], ["Pyzer-Knapp", "Edward O.", ""]]}, {"id": "1809.06364", "submitter": "Eli Friedman", "authors": "Eli Friedman and Fred Fontaine", "title": "Generalizing Across Multi-Objective Reward Functions in Deep\n  Reinforcement Learning", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement-learning researchers treat the reward function as a part\nof the environment, meaning that the agent can only know the reward of a state\nif it encounters that state in a trial run. However, we argue that this is an\nunnecessary limitation and instead, the reward function should be provided to\nthe learning algorithm. The advantage is that the algorithm can then use the\nreward function to check the reward for states that the agent hasn't even\nencountered yet. In addition, the algorithm can simultaneously learn policies\nfor multiple reward functions. For each state, the algorithm would calculate\nthe reward using each of the reward functions and add the rewards to its\nexperience replay dataset. The Hindsight Experience Replay algorithm developed\nby Andrychowicz et al. (2017) does just this, and learns to generalize across a\ndistribution of sparse, goal-based rewards. We extend this algorithm to\nlinearly-weighted, multi-objective rewards and learn a single policy that can\ngeneralize across all linear combinations of the multi-objective reward.\nWhereas other multi-objective algorithms teach the Q-function to generalize\nacross the reward weights, our algorithm enables the policy to generalize, and\ncan thus be used with continuous actions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 17:59:13 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Friedman", "Eli", ""], ["Fontaine", "Fred", ""]]}, {"id": "1809.06367", "submitter": "Eugene Belilovsky", "authors": "Edouard Oyallon (CVN, GALEN), Sergey Zagoruyko (ENPC, LIGM), Gabriel\n  Huang (DIRO, MILA), Nikos Komodakis (ENPC, CSD-UOC, LIGM), Simon\n  Lacoste-Julien (DIRO, MILA), Matthew Blaschko (ESAT), Eugene Belilovsky\n  (DIRO, MILA)", "title": "Scattering Networks for Hybrid Representation Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1703.08961", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  Institute of Electrical and Electronics Engineers, 2018, pp.11", "doi": "10.1109/TPAMI.2018.2855738", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scattering networks are a class of designed Convolutional Neural Networks\n(CNNs) with fixed weights. We argue they can serve as generic representations\nfor modelling images. In particular, by working in scattering space, we achieve\ncompetitive results both for supervised and unsupervised learning tasks, while\nmaking progress towards constructing more interpretable CNNs. For supervised\nlearning, we demonstrate that the early layers of CNNs do not necessarily need\nto be learned, and can be replaced with a scattering network instead. Indeed,\nusing hybrid architectures, we achieve the best results with predefined\nrepresentations to-date, while being competitive with end-to-end learned CNNs.\nSpecifically, even applying a shallow cascade of small-windowed scattering\ncoefficients followed by 1$\\times$1-convolutions results in AlexNet accuracy on\nthe ILSVRC2012 classification task. Moreover, by combining scattering networks\nwith deep residual networks, we achieve a single-crop top-5 error of 11.4% on\nILSVRC2012. Also, we show they can yield excellent performance in the small\nsample regime on CIFAR-10 and STL-10 datasets, exceeding their end-to-end\ncounterparts, through their ability to incorporate geometrical priors. For\nunsupervised learning, scattering coefficients can be a competitive\nrepresentation that permits image recovery. We use this fact to train hybrid\nGANs to generate images. Finally, we empirically analyze several properties\nrelated to stability and reconstruction of images from scattering coefficients.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 06:27:40 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Oyallon", "Edouard", "", "CVN, GALEN"], ["Zagoruyko", "Sergey", "", "ENPC, LIGM"], ["Huang", "Gabriel", "", "DIRO, MILA"], ["Komodakis", "Nikos", "", "ENPC, CSD-UOC, LIGM"], ["Lacoste-Julien", "Simon", "", "DIRO, MILA"], ["Blaschko", "Matthew", "", "ESAT"], ["Belilovsky", "Eugene", "", "DIRO, MILA"]]}, {"id": "1809.06401", "submitter": "Hyung-Jin Yoon", "authors": "Hyung-Jin Yoon, Donghwan Lee, and Naira Hovakimyan", "title": "Hidden Markov Model Estimation-Based Q-learning for Partially Observable\n  Markov Decision Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective is to study an on-line Hidden Markov model (HMM)\nestimation-based Q-learning algorithm for partially observable Markov decision\nprocess (POMDP) on finite state and action sets. When the full state\nobservation is available, Q-learning finds the optimal action-value function\ngiven the current action (Q function). However, Q-learning can perform poorly\nwhen the full state observation is not available. In this paper, we formulate\nthe POMDP estimation into a HMM estimation problem and propose a recursive\nalgorithm to estimate both the POMDP parameter and Q function concurrently.\nAlso, we show that the POMDP estimation converges to a set of stationary points\nfor the maximum likelihood estimate, and the Q function estimation converges to\na fixed point that satisfies the Bellman optimality equation weighted on the\ninvariant distribution of the state belief determined by the HMM estimation\nprocess.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 18:40:48 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 14:35:05 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Yoon", "Hyung-Jin", ""], ["Lee", "Donghwan", ""], ["Hovakimyan", "Naira", ""]]}, {"id": "1809.06404", "submitter": "Ahmed Qureshi", "authors": "Ahmed H. Qureshi, Byron Boots and Michael C. Yip", "title": "Adversarial Imitation via Variational Inverse Reinforcement Learning", "comments": "Paper published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of learning the reward and policy from expert examples\nunder unknown dynamics. Our proposed method builds on the framework of\ngenerative adversarial networks and introduces the empowerment-regularized\nmaximum-entropy inverse reinforcement learning to learn near-optimal rewards\nand policies. Empowerment-based regularization prevents the policy from\noverfitting to expert demonstrations, which advantageously leads to more\ngeneralized behaviors that result in learning near-optimal rewards. Our method\nsimultaneously learns empowerment through variational information maximization\nalong with the reward and policy under the adversarial learning formulation. We\nevaluate our approach on various high-dimensional complex control tasks. We\nalso test our learned rewards in challenging transfer learning problems where\ntraining and testing environments are made to be different from each other in\nterms of dynamics or structure. The results show that our proposed method not\nonly learns near-optimal rewards and policies that are matching expert behavior\nbut also performs significantly better than state-of-the-art inverse\nreinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 18:47:47 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 19:27:41 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 23:32:23 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Qureshi", "Ahmed H.", ""], ["Boots", "Byron", ""], ["Yip", "Michael C.", ""]]}, {"id": "1809.06416", "submitter": "Kashyap Popat", "authors": "Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, Gerhard Weikum", "title": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 19:51:18 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Popat", "Kashyap", ""], ["Mukherjee", "Subhabrata", ""], ["Yates", "Andrew", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1809.06432", "submitter": "Pedro Mercado", "authors": "Pedro Mercado, Jessica Bosch, Martin Stoll", "title": "Node Classification for Signed Social Networks Using Diffuse Interface\n  Methods", "comments": "Accepted at ECML-PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.NA math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Signed networks contain both positive and negative kinds of interactions like\nfriendship and enmity. The task of node classification in non-signed graphs has\nproven to be beneficial in many real world applications, yet extensions to\nsigned networks remain largely unexplored. In this paper we introduce the first\nanalysis of node classification in signed social networks via diffuse interface\nmethods based on the Ginzburg-Landau functional together with different\nextensions of the graph Laplacian to signed networks. We show that blending the\ninformation from both positive and negative interactions leads to performance\nimprovement in real signed social networks, consistently outperforming the\ncurrent state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 11:41:37 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 18:39:37 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Mercado", "Pedro", ""], ["Bosch", "Jessica", ""], ["Stoll", "Martin", ""]]}, {"id": "1809.06452", "submitter": "Luca Laurenti", "authors": "Luca Cardelli, Marta Kwiatkowska, Luca Laurenti, Andrea Patane", "title": "Robustness Guarantees for Bayesian Inference with Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference and Gaussian processes are widely used in applications\nranging from robotics and control to biological systems. Many of these\napplications are safety-critical and require a characterization of the\nuncertainty associated with the learning model and formal guarantees on its\npredictions. In this paper we define a robustness measure for Bayesian\ninference against input perturbations, given by the probability that, for a\ntest point and a compact set in the input space containing the test point, the\nprediction of the learning model will remain $\\delta-$close for all the points\nin the set, for $\\delta>0.$ Such measures can be used to provide formal\nguarantees for the absence of adversarial examples. By employing the theory of\nGaussian processes, we derive tight upper bounds on the resulting robustness by\nutilising the Borell-TIS inequality, and propose algorithms for their\ncomputation. We evaluate our techniques on two examples, a GP regression\nproblem and a fully-connected deep neural network, where we rely on weak\nconvergence to GPs to study adversarial examples on the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 21:32:26 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 22:00:04 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Cardelli", "Luca", ""], ["Kwiatkowska", "Marta", ""], ["Laurenti", "Luca", ""], ["Patane", "Andrea", ""]]}, {"id": "1809.06463", "submitter": "Eugene Wong", "authors": "Eugene Wong", "title": "Self Configuration in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we first present a class of algorithms for training multi-level\nneural networks with a quadratic cost function one layer at a time starting\nfrom the input layer. The algorithm is based on the fact that for any layer to\nbe trained, the effect of a direct connection to an optimized linear output\nlayer can be computed without the connection being made. Thus, starting from\nthe input layer, we can train each layer in succession in isolation from the\nother layers. Once trained, the weights are kept fixed and the outputs of the\ntrained layer then serve as the inputs to the next layer to be trained. The\nresult is a very fast algorithm. The simplicity of this training arrangement\nallows the activation function and step size in weight adjustment to be\nadaptive and self-adjusting. Furthermore, the stability of the training process\nallows relatively large steps to be taken and thereby achieving in even greater\nspeeds. Finally, in our context configuring the network means determining the\nnumber of outputs for each layer. By decomposing the overall cost function into\nseparate components related to approximation and estimation, we obtain an\noptimization formula for determining the number of outputs for each layer. With\nthe ability to self-configure and set parameters, we now have more than a fast\ntraining algorithm, but the ability to build automatically a fully trained deep\nneural network starting with nothing more than data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 22:29:28 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Wong", "Eugene", ""]]}, {"id": "1809.06473", "submitter": "Sahin Geyik", "authors": "Rohan Ramanath, Hakan Inan, Gungor Polatkan, Bo Hu, Qi Guo, Cagri\n  Ozcaglar, Xianren Wu, Krishnaram Kenthapadi, Sahin Cem Geyik", "title": "Towards Deep and Representation Learning for Talent Search at LinkedIn", "comments": "This paper has been accepted for publication in ACM CIKM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Talent search and recommendation systems at LinkedIn strive to match the\npotential candidates to the hiring needs of a recruiter or a hiring manager\nexpressed in terms of a search query or a job posting. Recent work in this\ndomain has mainly focused on linear models, which do not take complex\nrelationships between features into account, as well as ensemble tree models,\nwhich introduce non-linearity but are still insufficient for exploring all the\npotential feature interactions, and strictly separate feature generation from\nmodeling. In this paper, we present the results of our application of deep and\nrepresentation learning models on LinkedIn Recruiter. Our key contributions\ninclude: (i) Learning semantic representations of sparse entities within the\ntalent search domain, such as recruiter ids, candidate ids, and skill entity\nids, for which we utilize neural network models that take advantage of LinkedIn\nEconomic Graph, and (ii) Deep models for learning recruiter engagement and\ncandidate response in talent search applications. We also explore learning to\nrank approaches applied to deep models, and show the benefits for the talent\nsearch use case. Finally, we present offline and online evaluation results for\nLinkedIn talent search and recommendation systems, and discuss potential\nchallenges along the path to a fully deep model architecture. The challenges\nand approaches discussed generalize to any multi-faceted search engine.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 23:11:50 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Ramanath", "Rohan", ""], ["Inan", "Hakan", ""], ["Polatkan", "Gungor", ""], ["Hu", "Bo", ""], ["Guo", "Qi", ""], ["Ozcaglar", "Cagri", ""], ["Wu", "Xianren", ""], ["Kenthapadi", "Krishnaram", ""], ["Geyik", "Sahin Cem", ""]]}, {"id": "1809.06474", "submitter": "Krishnakumar Balasubramanian", "authors": "Krishnakumar Balasubramanian, Saeed Ghadimi", "title": "Zeroth-order Nonconvex Stochastic Optimization: Handling Constraints,\n  High-Dimensionality and Saddle-Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and analyze zeroth-order stochastic approximation\nalgorithms for nonconvex and convex optimization, with a focus on addressing\nconstrained optimization, high-dimensional setting and saddle-point avoiding.\nTo handle constrained optimization, we first propose generalizations of the\nconditional gradient algorithm achieving rates similar to the standard\nstochastic gradient algorithm using only zeroth-order information. To\nfacilitate zeroth-order optimization in high-dimensions, we explore the\nadvantages of structural sparsity assumptions. Specifically, (i) we highlight\nan implicit regularization phenomenon where the standard stochastic gradient\nalgorithm with zeroth-order information adapts to the sparsity of the problem\nat hand by just varying the step-size and (ii) propose a truncated stochastic\ngradient algorithm with zeroth-order information, whose rate of convergence\ndepends only poly-logarithmically on the dimensionality. We next focus on\navoiding saddle-points in non-convex setting. Towards that, we interpret the\nGaussian smoothing technique for estimating gradient based on zeroth-order\ninformation as an instantiation of first-order Stein's identity. Based on this,\nwe provide a novel linear-(in dimension) time estimator of the Hessian matrix\nof a function using only zeroth-order information, which is based on\nsecond-order Stein's identity. We then provide an algorithm for avoiding\nsaddle-points, which is based on a zeroth-order cubic regularization Newton's\nmethod and discuss its convergence rates.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 23:30:05 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 02:53:46 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Balasubramanian", "Krishnakumar", ""], ["Ghadimi", "Saeed", ""]]}, {"id": "1809.06477", "submitter": "Shubhomoy Das", "authors": "Shubhomoy Das, Md Rakibul Islam, Nitthilan Kannappan Jayakodi,\n  Janardhan Rao Doppa", "title": "Active Anomaly Detection via Ensembles", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In critical applications of anomaly detection including computer security and\nfraud prevention, the anomaly detector must be configurable by the analyst to\nminimize the effort on false positives. One important way to configure the\nanomaly detector is by providing true labels for a few instances. We study the\nproblem of label-efficient active learning to automatically tune anomaly\ndetection ensembles and make four main contributions. First, we present an\nimportant insight into how anomaly detector ensembles are naturally suited for\nactive learning. This insight allows us to relate the greedy querying strategy\nto uncertainty sampling, with implications for label-efficiency. Second, we\npresent a novel formalism called compact description to describe the discovered\nanomalies and show that it can also be employed to improve the diversity of the\ninstances presented to the analyst without loss in the anomaly discovery rate.\nThird, we present a novel data drift detection algorithm that not only detects\nthe drift robustly, but also allows us to take corrective actions to adapt the\ndetector in a principled manner. Fourth, we present extensive experiments to\nevaluate our insights and algorithms in both batch and streaming settings. Our\nresults show that in addition to discovering significantly more anomalies than\nstate-of-the-art unsupervised baselines, our active learning algorithms under\nthe streaming-data setup are competitive with the batch setup.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 23:53:39 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Das", "Shubhomoy", ""], ["Islam", "Md Rakibul", ""], ["Jayakodi", "Nitthilan Kannappan", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "1809.06498", "submitter": "Deqiang Li", "authors": "Deqiang Li and Ramesh Baral and Tao Li and Han Wang and Qianmu Li and\n  Shouhuai Xu", "title": "HashTran-DNN: A Framework for Enhancing Robustness of Deep Neural\n  Networks against Adversarial Malware Samples", "comments": "13 pages (included references), 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial machine learning in the context of image processing and related\napplications has received a large amount of attention. However, adversarial\nmachine learning, especially adversarial deep learning, in the context of\nmalware detection has received much less attention despite its apparent\nimportance. In this paper, we present a framework for enhancing the robustness\nof Deep Neural Networks (DNNs) against adversarial malware samples, dubbed\nHashing Transformation Deep Neural Networks} (HashTran-DNN). The core idea is\nto use hash functions with a certain locality-preserving property to transform\nsamples to enhance the robustness of DNNs in malware classification. The\nframework further uses a Denoising Auto-Encoder (DAE) regularizer to\nreconstruct the hash representations of samples, making the resulting DNN\nclassifiers capable of attaining the locality information in the latent space.\nWe experiment with two concrete instantiations of the HashTran-DNN framework to\nclassify Android malware. Experimental results show that four known attacks can\nrender standard DNNs useless in classifying Android malware, that known\ndefenses can at most defend three of the four attacks, and that HashTran-DNN\ncan effectively defend against all of the four attacks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 01:39:04 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Li", "Deqiang", ""], ["Baral", "Ramesh", ""], ["Li", "Tao", ""], ["Wang", "Han", ""], ["Li", "Qianmu", ""], ["Xu", "Shouhuai", ""]]}, {"id": "1809.06514", "submitter": "Berk Ustun", "authors": "Berk Ustun, Alexander Spangher, Yang Liu", "title": "Actionable Recourse in Linear Classification", "comments": "Extended version. ACM Conference on Fairness, Accountability and\n  Transparency [FAT2019]", "journal-ref": null, "doi": "10.1145/3287560.3287566", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are increasingly used to automate decisions that\naffect humans - deciding who should receive a loan, a job interview, or a\nsocial service. In such applications, a person should have the ability to\nchange the decision of a model. When a person is denied a loan by a credit\nscore, for example, they should be able to alter its input variables in a way\nthat guarantees approval. Otherwise, they will be denied the loan as long as\nthe model is deployed. More importantly, they will lack the ability to\ninfluence a decision that affects their livelihood.\n  In this paper, we frame these issues in terms of recourse, which we define as\nthe ability of a person to change the decision of a model by altering\nactionable input variables (e.g., income vs. age or marital status). We present\ninteger programming tools to ensure recourse in linear classification problems\nwithout interfering in model development. We demonstrate how our tools can\ninform stakeholders through experiments on credit scoring problems. Our results\nshow that recourse can be significantly affected by standard practices in model\ndevelopment, and motivate the need to evaluate recourse in practice.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 03:08:02 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 01:32:32 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Ustun", "Berk", ""], ["Spangher", "Alexander", ""], ["Liu", "Yang", ""]]}, {"id": "1809.06517", "submitter": "Youhei Akimoto", "authors": "Kouhei Nishida, Hernan Aguirre, Shota Saito, Shinichi Shirakawa,\n  Youhei Akimoto", "title": "Parameterless Stochastic Natural Gradient Method for Discrete\n  Optimization and its Application to Hyper-Parameter Optimization for Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black box discrete optimization (BBDO) appears in wide range of engineering\ntasks. Evolutionary or other BBDO approaches have been applied, aiming at\nautomating necessary tuning of system parameters, such as hyper parameter\ntuning of machine learning based systems when being installed for a specific\ntask. However, automation is often jeopardized by the need of strategy\nparameter tuning for BBDO algorithms. An expert with the domain knowledge must\nundergo time-consuming strategy parameter tuning. This paper proposes a\nparameterless BBDO algorithm based on information geometric optimization, a\nrecent framework for black box optimization using stochastic natural gradient.\nInspired by some theoretical implications, we develop an adaptation mechanism\nfor strategy parameters of the stochastic natural gradient method for discrete\nsearch domains. The proposed algorithm is evaluated on commonly used test\nproblems. It is further extended to two examples of simultaneous optimization\nof the hyper parameters and the connection weights of deep learning models,\nleading to a faster optimization than the existing approaches without any\neffort of parameter tuning.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 03:27:49 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Nishida", "Kouhei", ""], ["Aguirre", "Hernan", ""], ["Saito", "Shota", ""], ["Shirakawa", "Shinichi", ""], ["Akimoto", "Youhei", ""]]}, {"id": "1809.06546", "submitter": "Jian Liang", "authors": "Jian Liang, Ziqi Liu, Jiayu Zhou, Xiaoqian Jiang, Changshui Zhang, Fei\n  Wang", "title": "Model-Protected Multi-Task Learning", "comments": "Supplemental materials are attached at the end of the main paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) refers to the paradigm of learning multiple related\ntasks together. In contrast, in single-task learning (STL) each individual task\nis learned independently. MTL often leads to better trained models because they\ncan leverage the commonalities among related tasks. However, because MTL\nalgorithms can ``leak\" information from different models across different\ntasks, MTL poses a potential security risk. Specifically, an adversary may\nparticipate in the MTL process through one task and thereby acquire the model\ninformation for another task. The previously proposed privacy-preserving MTL\nmethods protect data instances rather than models, and some of them may\nunderperform in comparison with STL methods. In this paper, we propose a\nprivacy-preserving MTL framework to prevent information from each model leaking\nto other models based on a perturbation of the covariance matrix of the model\nmatrix. We study two popular MTL approaches for instantiation, namely, learning\nthe low-rank and group-sparse patterns of the model matrix. Our algorithms can\nbe guaranteed not to underperform compared with STL methods. We build our\nmethods based upon tools for differential privacy, and privacy guarantees,\nutility bounds are provided, and heterogeneous privacy budgets are considered.\nThe experiments demonstrate that our algorithms outperform the baseline methods\nconstructed by existing privacy-preserving MTL methods on the proposed\nmodel-protection problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 06:16:38 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 05:40:27 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 13:52:39 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Liang", "Jian", ""], ["Liu", "Ziqi", ""], ["Zhou", "Jiayu", ""], ["Jiang", "Xiaoqian", ""], ["Zhang", "Changshui", ""], ["Wang", "Fei", ""]]}, {"id": "1809.06569", "submitter": "Yu-Hsun Lin", "authors": "Yu-Hsun Lin, Chun-Nan Chou, Edward Y. Chang", "title": "MBS: Macroblock Scaling for CNN Model Reduction", "comments": "8 pages (Accepted by CVPR'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the macroblock scaling (MBS) algorithm, which can be\napplied to various CNN architectures to reduce their model size. MBS adaptively\nreduces each CNN macroblock depending on its information redundancy measured by\nour proposed effective flops. Empirical studies conducted with ImageNet and\nCIFAR-10 attest that MBS can reduce the model size of some already compact CNN\nmodels, e.g., MobileNetV2 (25.03% further reduction) and ShuffleNet (20.74%),\nand even ultra-deep ones such as ResNet-101 (51.67%) and ResNet-1202 (72.71%)\nwith negligible accuracy degradation. MBS also performs better reduction at a\nmuch lower cost than the state-of-the-art optimization-based methods do. MBS's\nsimplicity and efficiency, its flexibility to work with any CNN model, and its\nscalability to work with models of any depth make it an attractive choice for\nCNN model size reduction.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 07:40:46 GMT"}, {"version": "v2", "created": "Sun, 14 Apr 2019 09:33:59 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Lin", "Yu-Hsun", ""], ["Chou", "Chun-Nan", ""], ["Chang", "Edward Y.", ""]]}, {"id": "1809.06570", "submitter": "Izumi Karino", "authors": "Izumi Karino, Kazutoshi Tanaka, Ryuma Niiyama, and Yasuo Kuniyoshi", "title": "Switching Isotropic and Directional Exploration with Parameter Space\n  Noise in Deep Reinforcement Learning", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an exploration method for deep reinforcement learning\nbased on parameter space noise. Recent studies have experimentally shown that\nparameter space noise results in better exploration than the commonly used\naction space noise. Previous methods devised a way to update the diagonal\ncovariance matrix of a noise distribution and did not consider the direction of\nthe noise vector and its correlation. In addition, fast updates of the noise\ndistribution are required to facilitate policy learning. We propose a method\nthat deforms the noise distribution according to the accumulated returns and\nthe noises that have led to the returns. Moreover, this method switches\nisotropic exploration and directional exploration in parameter space with\nregard to obtained rewards. We validate our exploration strategy in the OpenAI\nGym continuous environments and modified environments with sparse rewards. The\nproposed method achieves results that are competitive with a previous method at\nbaseline tasks. Moreover, our approach exhibits better performance in sparse\nreward environments by exploration with the switching strategy.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 07:43:00 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 04:33:12 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Karino", "Izumi", ""], ["Tanaka", "Kazutoshi", ""], ["Niiyama", "Ryuma", ""], ["Kuniyoshi", "Yasuo", ""]]}, {"id": "1809.06573", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng, Georg N\\\"uhrenberg, Hirotoshi Yasuoka", "title": "Runtime Monitoring Neuron Activation Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For using neural networks in safety critical domains, it is important to know\nif a decision made by a neural network is supported by prior similarities in\ntraining. We propose runtime neuron activation pattern monitoring - after the\nstandard training process, one creates a monitor by feeding the training data\nto the network again in order to store the neuron activation patterns in\nabstract form. In operation, a classification decision over an input is further\nsupplemented by examining if a pattern similar (measured by Hamming distance)\nto the generated pattern is contained in the monitor. If the monitor does not\ncontain any pattern similar to the generated pattern, it raises a warning that\nthe decision is not based on the training data. Our experiments show that, by\nadjusting the similarity-threshold for activation patterns, the monitors can\nreport a significant portion of misclassfications to be not supported by\ntraining with a small false-positive rate, when evaluated on a test set.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 07:54:43 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 06:53:27 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["N\u00fchrenberg", "Georg", ""], ["Yasuoka", "Hirotoshi", ""]]}, {"id": "1809.06640", "submitter": "Xiaotong Ni", "authors": "Xiaotong Ni", "title": "Neural Network Decoders for Large-Distance 2D Toric Codes", "comments": null, "journal-ref": "Quantum 4, 310 (2020)", "doi": "10.22331/q-2020-08-24-310", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We still do not have perfect decoders for topological codes that can satisfy\nall needs of different experimental setups. Recently, a few neural network\nbased decoders have been studied, with the motivation that they can adapt to a\nwide range of noise models, and can easily run on dedicated chips without a\nfull-fledged computer. The later feature might lead to fast speed and the\nability to operate at low temperatures. However, a question which has not been\naddressed in previous works is whether neural network decoders can handle 2D\ntopological codes with large distances. In this work, we provide a positive\nanswer for the toric code. The structure of our neural network decoder is\ninspired by the renormalization group decoder. With a fairly strict policy on\ntraining time, when the bit-flip error rate is lower than $9\\%$ and syndrome\nextraction is perfect, the neural network decoder performs better when code\ndistance increases. With a less strict policy, we find it is not hard for the\nneural decoder to achieve a performance close to the minimum-weight perfect\nmatching algorithm. The numerical simulation is done up to code distance\n$d=64$. Last but not least, we describe and analyze a few failed approaches.\nThey guide us to the final design of our neural decoder, but also serve as a\ncaution when we gauge the versatility of stock deep neural networks. The source\ncode of our neural decoder can be found at\nhttps://github.com/XiaotongNi/toric-code-neural-decoder .\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 11:01:42 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 19:20:13 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 02:43:19 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ni", "Xiaotong", ""]]}, {"id": "1809.06686", "submitter": "Byung-Hak Kim", "authors": "Byung-Hak Kim, Ethan Vizitei, Varun Ganapathi", "title": "Domain Adaptation for Real-Time Student Performance Prediction", "comments": "arXiv admin note: text overlap with arXiv:1804.07405", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly fast development and update cycle of online course contents, and\ndiverse demographics of students in each online classroom, make student\nperformance prediction in real-time (before the course finishes) and/or on\ncurriculum without specific historical performance data available interesting\ntopics for both industrial research and practical needs. In this research, we\ntackle the problem of real-time student performance prediction with on-going\ncourses in a domain adaptation framework, which is a system trained on\nstudents' labeled outcome from one set of previous coursework but is meant to\nbe deployed on another. In particular, we first introduce recently-developed\nGritNet architecture which is the current state of the art for student\nperformance prediction problem, and develop a new \\emph{unsupervised} domain\nadaptation method to transfer a GritNet trained on a past course to a new\ncourse without any (students' outcome) label. Our results for real Udacity\nstudents' graduation predictions show that the GritNet not only\n\\emph{generalizes} well from one course to another across different Nanodegree\nprograms, but enhances real-time predictions explicitly in the first few weeks\nwhen accurate predictions are most challenging.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 21:47:57 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 02:12:36 GMT"}, {"version": "v3", "created": "Sun, 17 Mar 2019 14:48:12 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Kim", "Byung-Hak", ""], ["Vizitei", "Ethan", ""], ["Ganapathi", "Varun", ""]]}, {"id": "1809.06687", "submitter": "Jinjin Gu", "authors": "Jinjin Gu, Haoyu Chen, Guolong Liu, Gaoqi Liang, Xinlei Wang, Junhua\n  Zhao", "title": "Super-Resolution Perception for Industrial Sensor Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the problem formulation and methodology framework\nof Super-Resolution Perception (SRP) on industrial sensor data. Industrial\nintelligence relies on high-quality industrial sensor data for system control,\ndiagnosis, fault detection, identification, and monitoring. However, the\nprovision of high-quality data may be expensive in some cases. In this paper,\nwe propose a novel machine learning problem -- the SRP problem as\nreconstructing high-quality data from unsatisfactory sensor data in industrial\nsystems. Advanced generative models are then proposed to solve the SRP problem.\nThis technology makes it possible to empower existing industrial facilities\nwithout upgrading existing sensors or deploying additional sensors. We first\nmathematically formulate the SRP problem under the Maximum a Posteriori (MAP)\nestimation framework. A case study is then presented, which performs SRP on\nsmart meter data. A network, namely SRPNet, is proposed to generate\nhigh-frequency load data from low-frequency data. We further employ a novel\nrecognition-based loss and relativistic adversarial loss to constraint the\nreconstruction of waveforms explicitly. Experiments demonstrate that our SRP\nmodel can reconstruct high-frequency data effectively. Moreover, the\nreconstructed high-frequency data can lead to better appliance monitoring\nresults without changing the monitoring appliances.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 14:10:57 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 14:09:55 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Gu", "Jinjin", ""], ["Chen", "Haoyu", ""], ["Liu", "Guolong", ""], ["Liang", "Gaoqi", ""], ["Wang", "Xinlei", ""], ["Zhao", "Junhua", ""]]}, {"id": "1809.06688", "submitter": "Maolin Shi", "authors": "Maolin Shi, Xueguan Song, Wei Sun", "title": "Geology prediction based on operation data of TBM: comparison between\n  deep neural network and statistical learning methods", "comments": "26 pages, 7 figures", "journal-ref": "2019 1st International Conference on Industrial Artificial\n  Intelligence (IAI)", "doi": "10.1109/ICIAI.2019.8850794", "report-no": null, "categories": "physics.geo-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tunnel boring machine (TBM) is a complex engineering system widely used for\ntunnel construction. In view of the complicated construction environments, it\nis necessary to predict geology conditions prior to excavation. In recent\nyears, massive operation data of TBM has been recorded, and mining these data\ncan provide important references and useful information for designers and\noperators of TBM. In this work, a geology prediction approach is proposed based\non deep neural network and operation data. It can provide relatively accurate\ngeology prediction results ahead of the tunnel face compared with the other\nprediction models based on statistical learning methods. The application case\nstudy on a tunnel in China shows that the proposed approach can accurately\nestimate the geological conditions prior to excavation, especially for the\nshort range ahead of training data. This work can be regarded as a good\ncomplement to the geophysical prospecting approach during the construction of\ntunnels, and also highlights the applicability and potential of deep neural\nnetworks for other data mining tasks of TBMs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 05:14:37 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Shi", "Maolin", ""], ["Song", "Xueguan", ""], ["Sun", "Wei", ""]]}, {"id": "1809.06693", "submitter": "Yuri G. Gordienko", "authors": "Nikita Gordienko, Yuriy Kochura, Vlad Taran, Gang Peng, Yuri Gordienko\n  and Sergii Stirenko", "title": "Capsule Deep Neural Network for Recognition of Historical Graffiti\n  Handwriting", "comments": "6 pages, 8 figures, accepted for 2018 IEEE Ukraine Student, Young\n  Professional and Women in Engineering Congress (UKRSYW), October 2-6, 2018\n  (Kyiv, Ukraine). arXiv admin note: text overlap with arXiv:1808.10862", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic recognition of the historical letters (XI-XVIII centuries) carved\non the stoned walls of St.Sophia cathedral in Kyiv (Ukraine) was demonstrated\nby means of capsule deep learning neural network. It was applied to the image\ndataset of the carved Glagolitic and Cyrillic letters (CGCL), which was\nassembled and pre-processed recently for recognition and prediction by machine\nlearning methods\n(https://www.kaggle.com/yoctoman/graffiti-st-sophia-cathedral-kyiv). CGCL\ndataset contains >4000 images for glyphs of 34 letters which are hardly\nrecognized by experts even in contrast to notMNIST dataset with the better\nimages of 10 letters taken from different fonts. Despite the much worse quality\nof CGCL dataset and extremely low number of samples (in comparison to notMNIST\ndataset) the capsule network model demonstrated much better results than the\npreviously used convolutional neural network (CNN). The validation accuracy\n(and validation loss) was higher (lower) for capsule network model than for CNN\nwithout data augmentation even. The area under curve (AUC) values for receiver\noperating characteristic (ROC) were also higher for the capsule network model\nthan for CNN model: 0.88-0.93 (capsule network) and 0.50 (CNN) without data\naugmentation, 0.91-0.95 (capsule network) and 0.51 (CNN) with lossless data\naugmentation, and similar results of 0.91-0.93 (capsule network) and 0.9 (CNN)\nin the regime of lossless data augmentation only. The confusion matrixes were\nmuch better for capsule network than for CNN model and gave the much lower type\nI (false positive) and type II (false negative) values in all three regimes of\ndata augmentation. These results supports the previous claims that capsule-like\nnetworks allow to reduce error rates not only on MNIST digit dataset, but on\nthe other notMNIST letter dataset and the more complex CGCL handwriting\ngraffiti letter dataset also.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 17:02:13 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Gordienko", "Nikita", ""], ["Kochura", "Yuriy", ""], ["Taran", "Vlad", ""], ["Peng", "Gang", ""], ["Gordienko", "Yuri", ""], ["Stirenko", "Sergii", ""]]}, {"id": "1809.06697", "submitter": "Luis Alfredo Moctezuma", "authors": "Luis Alfredo Moctezuma and Marta Molinas", "title": "EEG-based Subjects Identification based on Biometrics of Imagined Speech\n  using EMD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When brain activity is translated into commands for real applications, the\npotential for human capacities augmentation is promising. In this paper, EMD is\nused to decompose EEG signals during Imagined Speech in order to use it as a\nbiometric marker for creating a Biometric Recognition System. For each EEG\nchannel, the most relevant Intrinsic Mode Functions (IMFs) are decided based on\nthe Minkowski distance, and for each IMF 4 features are computed: Instantaneous\nand Teager energy distribution and Higuchi and Petrosian Fractal Dimension. To\ntest the proposed method, a dataset with 20 subjects who imagined 30\nrepetitions of 5 words in Spanish, is used. Four classifiers are used for this\ntask - random forest, SVM, naive Bayes, and k-NN - and their performances are\ncompared. The accuracy obtained (up to 0.92 using Linear SVM) after 10-folds\ncross-validation suggest that the proposed method based on EMD can be valuable\nfor creating EEG-based biometrics of imagined speech for Subjects\nidentification.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 14:17:08 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Moctezuma", "Luis Alfredo", ""], ["Molinas", "Marta", ""]]}, {"id": "1809.06705", "submitter": "Anthony Bagnall Dr", "authors": "A. Bagnall, M. Flynn, J. Large, J. Line, A. Bostrom and G. Cawley", "title": "Is rotation forest the best classifier for problems with continuous\n  features?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In short, our experiments suggest that yes, on average, rotation forest is\nbetter than the most common alternatives when all the attributes are\nreal-valued. Rotation forest is a tree based ensemble that performs transforms\non subsets of attributes prior to constructing each tree. We present an\nempirical comparison of classifiers for problems with only real-valued\nfeatures. We evaluate classifiers from three families of algorithms: support\nvector machines; tree-based ensembles; and neural networks tuned with a large\ngrid search. We compare classifiers on unseen data based on the quality of the\ndecision rule (using classification error) the ability to rank cases (area\nunder the receiver operating characteristic) and the probability estimates\n(using negative log likelihood). We conclude that, in answer to the question\nposed in the title, yes, rotation forest is significantly more accurate on\naverage than competing techniques when compared on three distinct sets of\ndatasets. Further, we assess the impact of the design features of rotation\nforest through an ablative study that transforms random forest into rotation\nforest. We identify the major limitation of rotation forest as its scalability,\nparticularly in number of attributes. To overcome this problem we develop a\nmodel to predict the train time of the algorithm and hence propose a contract\nversion of rotation forest where a run time cap is imposed {\\em a priori}. We\ndemonstrate that on large problems rotation forest can be made an order of\nmagnitude faster without significant loss of accuracy. We also show that there\nis no real benefit (on average) from tuning rotation forest. We maintain that\nwithout any domain knowledge to indicate an algorithm preference, rotation\nforest should be the default algorithm of choice for problems with continuous\nattributes.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 13:33:45 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 14:44:32 GMT"}, {"version": "v3", "created": "Sat, 25 Apr 2020 12:29:53 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bagnall", "A.", ""], ["Flynn", "M.", ""], ["Large", "J.", ""], ["Line", "J.", ""], ["Bostrom", "A.", ""], ["Cawley", "G.", ""]]}, {"id": "1809.06709", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Yatin Chaudhary and Florian Buettner and Hinrich\n  Sch\\\"utze", "title": "Document Informed Neural Autoregressive Topic Models with Distributional\n  Prior", "comments": "AAAI2019. arXiv admin note: substantial text overlap with\n  arXiv:1808.03793", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two challenges in topic models: (1) Context information around\nwords helps in determining their actual meaning, e.g., \"networks\" used in the\ncontexts \"artificial neural networks\" vs. \"biological neuron networks\".\nGenerative topic models infer topic-word distributions, taking no or only\nlittle context into account. Here, we extend a neural autoregressive topic\nmodel to exploit the full context information around words in a document in a\nlanguage modeling fashion. The proposed model is named as iDocNADE. (2) Due to\nthe small number of word occurrences (i.e., lack of context) in short text and\ndata sparsity in a corpus of few documents, the application of topic models is\nchallenging on such texts. Therefore, we propose a simple and efficient way of\nincorporating external knowledge into neural autoregressive topic models: we\nuse embeddings as a distributional prior. The proposed variants are named as\nDocNADEe and iDocNADEe.\n  We present novel neural autoregressive topic model variants that consistently\noutperform state-of-the-art generative topic models in terms of generalization,\ninterpretability (topic coherence) and applicability (retrieval and\nclassification) over 7 long-text and 8 short-text datasets from diverse\ndomains.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 12:48:16 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:25:06 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Gupta", "Pankaj", ""], ["Chaudhary", "Yatin", ""], ["Buettner", "Florian", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1809.06719", "submitter": "Ameet Deshpande", "authors": "Ameet Deshpande, Srikanth Sarma, Ashutosh Jha, Balaraman Ravindran", "title": "Improvements on Hindsight Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse reward problems are one of the biggest challenges in Reinforcement\nLearning. Goal-directed tasks are one such sparse reward problems where a\nreward signal is received only when the goal is reached. One promising way to\ntrain an agent to perform goal-directed tasks is to use Hindsight Learning\napproaches. In these approaches, even when an agent fails to reach the desired\ngoal, the agent learns to reach the goal it achieved instead. Doing this over\nmultiple trajectories while generalizing the policy learned from the achieved\ngoals, the agent learns a goal conditioned policy to reach any goal. One such\napproach is Hindsight Experience replay which uses an off-policy Reinforcement\nLearning algorithm to learn a goal conditioned policy. In this approach, a\nreplay of the past transitions happens in a uniformly random fashion. Another\napproach is to use a Hindsight version of the policy gradients to directly\nlearn a policy. In this work, we discuss different ways to replay past\ntransitions to improve learning in hindsight experience replay focusing on\nprioritized variants in particular. Also, we implement the Hindsight Policy\ngradient methods to robotic tasks.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 17:07:33 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 19:40:31 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Deshpande", "Ameet", ""], ["Sarma", "Srikanth", ""], ["Jha", "Ashutosh", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1809.06750", "submitter": "Johannes Dornheim", "authors": "Johannes Dornheim, Norbert Link", "title": "Multiobjective Reinforcement Learning for Reconfigurable Adaptive\n  Optimal Control of Manufacturing Processes", "comments": "Conference, Preprint, 978-1-5386-5925-0/18/$31.00 \\c{opyright} 2018\n  IEEE", "journal-ref": "2018 IEEE International Symposium on Electronics and\n  Telecommunications (ISETC)", "doi": "10.1109/ISETC.2018.8583854", "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In industrial applications of adaptive optimal control often multiple\ncontrary objectives have to be considered. The weights (relative importance) of\nthe objectives are often not known during the design of the control and can\nchange with changing production conditions and requirements. In this work a\nnovel model-free multiobjective reinforcement learning approach for adaptive\noptimal control of manufacturing processes is proposed. The approach enables\nsample-efficient learning in sequences of control configurations, given by\nparticular objective weights.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 14:04:03 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 10:03:47 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Dornheim", "Johannes", ""], ["Link", "Norbert", ""]]}, {"id": "1809.06751", "submitter": "Anthony Bagnall Dr", "authors": "James Large, Anthony Bagnall, Simon Malinowski and Romain Tavenard", "title": "From BOP to BOSS and Beyond: Time Series Classification with Dictionary\n  Based Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A family of algorithms for time series classification (TSC) involve running a\nsliding window across each series, discretising the window to form a word,\nforming a histogram of word counts over the dictionary, then constructing a\nclassifier on the histograms. A recent evaluation of two of this type of\nalgorithm, Bag of Patterns (BOP) and Bag of Symbolic Fourier Approximation\nSymbols (BOSS) found a significant difference in accuracy between these\nseemingly similar algorithms. We investigate this phenomenon by deconstructing\nthe classifiers and measuring the relative importance of the four key\ncomponents between BOP and BOSS. We find that whilst ensembling is a key\ncomponent for both algorithms, the effect of the other components is mixed and\nmore complex. We conclude that BOSS represents the state of the art for\ndictionary based TSC. Both BOP and BOSS can be classed as bag of words\napproaches. These are particularly popular in Computer Vision for tasks such as\nimage classification. Converting approaches from vision requires careful\nengineering. We adapt three techniques used in Computer Vision for TSC: Scale\nInvariant Feature Transform; Spatial Pyramids; and Histrogram Intersection. We\nfind that using Spatial Pyramids in conjunction with BOSS (SP) produces a\nsignificantly more accurate classifier. SP is significantly more accurate than\nstandard benchmarks and the original BOSS algorithm. It is not significantly\nworse than the best shapelet based approach, and is only outperformed by\nHIVE-COTE, an ensemble that includes BOSS as a constituent module.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 14:04:33 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Large", "James", ""], ["Bagnall", "Anthony", ""], ["Malinowski", "Simon", ""], ["Tavenard", "Romain", ""]]}, {"id": "1809.06781", "submitter": "Sam Green", "authors": "Jieliang Luo, Sam Green, Peter Feghali, George Legrady, and \\c{C}etin\n  Kaya Ko\\c{c}", "title": "Visual Diagnostics for Deep Reinforcement Learning Policy Development", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vision-based reinforcement learning techniques often use convolutional\nneural networks (CNN) as universal function approximators to choose which\naction to take for a given visual input. Until recently, CNNs have been treated\nlike black-box functions, but this mindset is especially dangerous when used\nfor control in safety-critical settings. In this paper, we present our\nextensions of CNN visualization algorithms to the domain of vision-based\nreinforcement learning. We use a simulated drone environment as an example\nscenario. These visualization algorithms are an important tool for behavior\nintrospection and provide insight into the qualities and flaws of trained\npolicies when interacting with the physical world. A video may be seen at\nhttps://sites.google.com/view/drlvisual .\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 18:59:12 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 22:21:09 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Luo", "Jieliang", ""], ["Green", "Sam", ""], ["Feghali", "Peter", ""], ["Legrady", "George", ""], ["Ko\u00e7", "\u00c7etin Kaya", ""]]}, {"id": "1809.06784", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta and Zhaoyuan Yang", "title": "Adversarial Reinforcement Learning for Observer Design in Autonomous\n  Systems under Cyber Attacks", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex autonomous control systems are subjected to sensor failures,\ncyber-attacks, sensor noise, communication channel failures, etc. that\nintroduce errors in the measurements. The corrupted information, if used for\nmaking decisions, can lead to degraded performance. We develop a framework for\nusing adversarial deep reinforcement learning to design observer strategies\nthat are robust to adversarial errors in information channels. We further show\nthrough simulation studies that the learned observation strategies perform\nremarkably well when the adversary's injected errors are bounded in some sense.\nWe use neural network as function approximator in our studies with the\nunderstanding that any other suitable function approximating class can be used\nwithin our framework.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 12:28:02 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Gupta", "Abhishek", ""], ["Yang", "Zhaoyuan", ""]]}, {"id": "1809.06796", "submitter": "Jialin Dong", "authors": "Jialin Dong and Yuanming Shi", "title": "Nonconvex Demixing From Bilinear Measurements", "comments": "This paper has been accepted by IEEE Transactions on Signal\n  Processing", "journal-ref": null, "doi": "10.1109/TSP.2018.2864660", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of demixing a sequence of source signals from the sum\nof noisy bilinear measurements. It is a generalized mathematical model for\nblind demixing with blind deconvolution, which is prevalent across the areas of\ndictionary learning, image processing, and communications. However, state-of-\nthe-art convex methods for blind demixing via semidefinite programming are\ncomputationally infeasible for large-scale problems. Although the existing\nnonconvex algorithms are able to address the scaling issue, they normally\nrequire proper regularization to establish optimality guarantees. The\nadditional regularization yields tedious algorithmic parameters and pessimistic\nconvergence rates with conservative step sizes. To address the limitations of\nexisting methods, we thus develop a provable nonconvex demixing procedure\nviaWirtinger flow, much like vanilla gradient descent, to harness the benefits\nof regularization-free fast convergence rate with aggressive step size and\ncomputational optimality guarantees. This is achieved by exploiting the benign\ngeometry of the blind demixing problem, thereby revealing that Wirtinger flow\nenforces the regularization-free iterates in the region of strong convexity and\nqualified level of smoothness, where the step size can be chosen aggressively.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 15:31:43 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 09:48:31 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Dong", "Jialin", ""], ["Shi", "Yuanming", ""]]}, {"id": "1809.06798", "submitter": "Emre Yilmaz", "authors": "Longting Xu, Rohan Kumar Das, Emre Y{\\i}lmaz, Jichen Yang, Haizhou Li", "title": "Generative x-vectors for text-independent speaker verification", "comments": "Accepted for publication at SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker verification (SV) systems using deep neural network embeddings,\nso-called the x-vector systems, are becoming popular due to its good\nperformance superior to the i-vector systems. The fusion of these systems\nprovides improved performance benefiting both from the discriminatively trained\nx-vectors and generative i-vectors capturing distinct speaker characteristics.\nIn this paper, we propose a novel method to include the complementary\ninformation of i-vector and x-vector, that is called generative x-vector. The\ngenerative x-vector utilizes a transformation model learned from the i-vector\nand x-vector representations of the background data. Canonical correlation\nanalysis is applied to derive this transformation model, which is later used to\ntransform the standard x-vectors of the enrollment and test segments to the\ncorresponding generative x-vectors. The SV experiments performed on the NIST\nSRE 2010 dataset demonstrate that the system using generative x-vectors\nprovides considerably better performance than the baseline i-vector and\nx-vector systems. Furthermore, the generative x-vectors outperform the fusion\nof i-vector and x-vector systems for long-duration utterances, while yielding\ncomparable results for short-duration utterances.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 06:04:54 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Xu", "Longting", ""], ["Das", "Rohan Kumar", ""], ["Y\u0131lmaz", "Emre", ""], ["Yang", "Jichen", ""], ["Li", "Haizhou", ""]]}, {"id": "1809.06827", "submitter": "Ioan Gabriel Bucur", "authors": "Ioan Gabriel Bucur, Tom van Bussel, Tom Claassen, Tom Heskes", "title": "A Bayesian Approach for Inferring Local Causal Structure in Gene\n  Regulatory Networks", "comments": "12 pages, 4 figures, 3 tables", "journal-ref": "PMLR 72 (2018) 37-48", "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene regulatory networks play a crucial role in controlling an organism's\nbiological processes, which is why there is significant interest in developing\ncomputational methods that are able to extract their structure from\nhigh-throughput genetic data. A typical approach consists of a series of\nconditional independence tests on the covariance structure meant to\nprogressively reduce the space of possible causal models. We propose a novel\nefficient Bayesian method for discovering the local causal relationships among\ntriplets of (normally distributed) variables. In our approach, we score the\npatterns in the covariance matrix in one go and we incorporate the available\nbackground knowledge in the form of priors over causal structures. Our method\nis flexible in the sense that it allows for different types of causal\nstructures and assumptions. We apply the approach to the task of inferring gene\nregulatory networks by learning regulatory relationships between gene\nexpression levels. We show that our algorithm produces stable and conservative\nposterior probability estimates over local causal structures that can be used\nto derive an honest ranking of the most meaningful regulatory relationships. We\ndemonstrate the stability and efficacy of our method both on simulated data and\non real-world data from an experiment on yeast.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 16:51:48 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Bucur", "Ioan Gabriel", ""], ["van Bussel", "Tom", ""], ["Claassen", "Tom", ""], ["Heskes", "Tom", ""]]}, {"id": "1809.06848", "submitter": "Remi Tachet Des Combes", "authors": "Remi Tachet, Mohammad Pezeshki, Samira Shabanian, Aaron Courville,\n  Yoshua Bengio", "title": "On the Learning Dynamics of Deep Neural Networks", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While a lot of progress has been made in recent years, the dynamics of\nlearning in deep nonlinear neural networks remain to this day largely\nmisunderstood. In this work, we study the case of binary classification and\nprove various properties of learning in such networks under strong assumptions\nsuch as linear separability of the data. Extending existing results from the\nlinear case, we confirm empirical observations by proving that the\nclassification error also follows a sigmoidal shape in nonlinear architectures.\nWe show that given proper initialization, learning expounds parallel\nindependent modes and that certain regions of parameter space might lead to\nfailed training. We also demonstrate that input norm and features' frequency in\nthe dataset lead to distinct convergence speeds which might shed some light on\nthe generalization capabilities of deep neural networks. We provide a\ncomparison between the dynamics of learning with cross-entropy and hinge\nlosses, which could prove useful to understand recent progress in the training\nof generative adversarial networks. Finally, we identify a phenomenon that we\nbaptize gradient starvation where the most frequent features in a dataset\nprevent the learning of other less frequent but equally informative features.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 17:58:49 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 13:55:46 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 22:06:39 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Tachet", "Remi", ""], ["Pezeshki", "Mohammad", ""], ["Shabanian", "Samira", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1809.06858", "submitter": "Di He", "authors": "Chengyue Gong, Di He, Xu Tan, Tao Qin, Liwei Wang, Tie-Yan Liu", "title": "FRAGE: Frequency-Agnostic Word Representation", "comments": "To appear in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous word representation (aka word embedding) is a basic building block\nin many neural network-based models used in natural language processing tasks.\nAlthough it is widely accepted that words with similar semantics should be\nclose to each other in the embedding space, we find that word embeddings\nlearned in several tasks are biased towards word frequency: the embeddings of\nhigh-frequency and low-frequency words lie in different subregions of the\nembedding space, and the embedding of a rare word and a popular word can be far\nfrom each other even if they are semantically similar. This makes learned word\nembeddings ineffective, especially for rare words, and consequently limits the\nperformance of these neural network models. In this paper, we develop a neat,\nsimple yet effective way to learn \\emph{FRequency-AGnostic word Embedding}\n(FRAGE) using adversarial training. We conducted comprehensive studies on ten\ndatasets across four natural language processing tasks, including word\nsimilarity, language modeling, machine translation and text classification.\nResults show that with FRAGE, we achieve higher performance than the baselines\nin all tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 13:31:22 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 04:28:27 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Gong", "Chengyue", ""], ["He", "Di", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1809.06913", "submitter": "Markus Sch\\\"oberl", "authors": "Markus Sch\\\"oberl, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis", "title": "Predictive Collective Variable Discovery with Deep Bayesian Models", "comments": null, "journal-ref": "J. Chem. Phys. 150, 024109 (2019)", "doi": "10.1063/1.5058063", "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending spatio-temporal scale limitations of models for complex atomistic\nsystems considered in biochemistry and materials science necessitates the\ndevelopment of enhanced sampling methods. The potential acceleration in\nexploring the configurational space by enhanced sampling methods depends on the\nchoice of collective variables (CVs). In this work, we formulate the discovery\nof CVs as a Bayesian inference problem and consider the CVs as hidden\ngenerators of the full-atomistic trajectory. The ability to generate samples of\nthe fine-scale atomistic configurations using limited training data allows us\nto compute estimates of observables as well as our probabilistic confidence on\nthem. The methodology is based on emerging methodological advances in machine\nlearning and variational inference. The discovered CVs are related to\nphysicochemical properties which are essential for understanding mechanisms\nespecially in unexplored complex systems. We provide a quantitative assessment\nof the CVs in terms of their predictive ability for alanine dipeptide (ALA-2)\nand ALA-15 peptide.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 20:11:22 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 21:27:02 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Sch\u00f6berl", "Markus", ""], ["Zabaras", "Nicholas", ""], ["Koutsourelakis", "Phaedon-Stelios", ""]]}, {"id": "1809.06937", "submitter": "Hannah Li", "authors": "Ramesh Johari, Vijay Kamble, Anilesh K. Krishnaswamy, Hannah Li", "title": "Exploration vs. Exploitation in Team Formation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An online labor platform faces an online learning problem in matching workers\nwith jobs and using the performance on these jobs to create better future\nmatches. This learning problem is complicated by the rise of complex tasks on\nthese platforms, such as web development and product design, that require a\nteam of workers to complete. The success of a job is now a function of the\nskills and contributions of all workers involved, which may be unknown to both\nthe platform and the client who posted the job. These team matchings result in\na structured correlation between what is known about the individuals and this\ninformation can be utilized to create better future matches. We analyze two\nnatural settings where the performance of a team is dictated by its strongest\nand its weakest member, respectively. We find that both problems pose an\nexploration-exploitation tradeoff between learning the performance of untested\nteams and repeating previously tested teams that resulted in a good\nperformance. We establish fundamental regret bounds and design near-optimal\nalgorithms that uncover several insights into these tradeoffs.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 21:15:45 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 22:58:12 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Johari", "Ramesh", ""], ["Kamble", "Vijay", ""], ["Krishnaswamy", "Anilesh K.", ""], ["Li", "Hannah", ""]]}, {"id": "1809.06958", "submitter": "Patrick Rebeschini", "authors": "Dominic Richards and Patrick Rebeschini", "title": "Graph-Dependent Implicit Regularisation for Distributed Stochastic\n  Subgradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose graph-dependent implicit regularisation strategies for distributed\nstochastic subgradient descent (Distributed SGD) for convex problems in\nmulti-agent learning. Under the standard assumptions of convexity, Lipschitz\ncontinuity, and smoothness, we establish statistical learning rates that\nretain, up to logarithmic terms, centralised statistical guarantees through\nimplicit regularisation (step size tuning and early stopping) with appropriate\ndependence on the graph topology. Our approach avoids the need for explicit\nregularisation in decentralised learning problems, such as adding constraints\nto the empirical risk minimisation rule. Particularly for distributed methods,\nthe use of implicit regularisation allows the algorithm to remain simple,\nwithout projections or dual methods. To prove our results, we establish\ngraph-independent generalisation bounds for Distributed SGD that match the\ncentralised setting (using algorithmic stability), and we establish\ngraph-dependent optimisation bounds that are of independent interest. We\npresent numerical experiments to show that the qualitative nature of the upper\nbounds we derive can be representative of real behaviours.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 22:51:32 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Richards", "Dominic", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "1809.06963", "submitter": "Yichong Xu", "authors": "Yichong Xu, Xiaodong Liu, Yelong Shen, Jingjing Liu and Jianfeng Gao", "title": "Multi-task Learning with Sample Re-weighting for Machine Reading\n  Comprehension", "comments": "North American Chapter of the Association for Computational\n  Linguistics (NAACL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-task learning framework to learn a joint Machine Reading\nComprehension (MRC) model that can be applied to a wide range of MRC tasks in\ndifferent domains. Inspired by recent ideas of data selection in machine\ntranslation, we develop a novel sample re-weighting scheme to assign\nsample-specific weights to the loss. Empirical study shows that our approach\ncan be applied to many existing MRC models. Combined with contextual\nrepresentations from pre-trained language models (such as ELMo), we achieve new\nstate-of-the-art results on a set of MRC benchmark datasets. We release our\ncode at https://github.com/xycforgithub/MultiTask-MRC.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 23:44:03 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 06:42:32 GMT"}, {"version": "v3", "created": "Sun, 31 Mar 2019 20:51:34 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Xu", "Yichong", ""], ["Liu", "Xiaodong", ""], ["Shen", "Yelong", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1809.06970", "submitter": "Shuochao Yao", "authors": "Shuochao Yao, Yiran Zhao, Huajie Shao, Shengzhong Liu, Dongxin Liu, Lu\n  Su, Tarek Abdelzaher", "title": "FastDeepIoT: Towards Understanding and Optimizing Neural Network\n  Execution Time on Mobile and Embedded Devices", "comments": "Accepted by SenSys '18", "journal-ref": null, "doi": "10.1145/3274783.3274840", "report-no": null, "categories": "cs.LG cs.NI cs.PF cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks show great potential as solutions to many sensing\napplication problems, but their excessive resource demand slows down execution\ntime, pausing a serious impediment to deployment on low-end devices. To address\nthis challenge, recent literature focused on compressing neural network size to\nimprove performance. We show that changing neural network size does not\nproportionally affect performance attributes of interest, such as execution\ntime. Rather, extreme run-time nonlinearities exist over the network\nconfiguration space. Hence, we propose a novel framework, called FastDeepIoT,\nthat uncovers the non-linear relation between neural network structure and\nexecution time, then exploits that understanding to find network configurations\nthat significantly improve the trade-off between execution time and accuracy on\nmobile and embedded devices. FastDeepIoT makes two key contributions. First,\nFastDeepIoT automatically learns an accurate and highly interpretable execution\ntime model for deep neural networks on the target device. This is done without\nprior knowledge of either the hardware specifications or the detailed\nimplementation of the used deep learning library. Second, FastDeepIoT informs a\ncompression algorithm how to minimize execution time on the profiled device\nwithout impacting accuracy. We evaluate FastDeepIoT using three different\nsensing-related tasks on two mobile devices: Nexus 5 and Galaxy Nexus.\nFastDeepIoT further reduces the neural network execution time by $48\\%$ to\n$78\\%$ and energy consumption by $37\\%$ to $69\\%$ compared with the\nstate-of-the-art compression algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 00:43:26 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Yao", "Shuochao", ""], ["Zhao", "Yiran", ""], ["Shao", "Huajie", ""], ["Liu", "Shengzhong", ""], ["Liu", "Dongxin", ""], ["Su", "Lu", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "1809.06987", "submitter": "Colin White", "authors": "Maria-Florina Balcan, Travis Dick, Colin White", "title": "Data-Driven Clustering via Parameterized Lloyd's Families", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for clustering points in metric spaces is a long-studied area of\nresearch. Clustering has seen a multitude of work both theoretically, in\nunderstanding the approximation guarantees possible for many objective\nfunctions such as k-median and k-means clustering, and experimentally, in\nfinding the fastest algorithms and seeding procedures for Lloyd's algorithm.\nThe performance of a given clustering algorithm depends on the specific\napplication at hand, and this may not be known up front. For example, a\n\"typical instance\" may vary depending on the application, and different\nclustering heuristics perform differently depending on the instance.\n  In this paper, we define an infinite family of algorithms generalizing\nLloyd's algorithm, with one parameter controlling the initialization procedure,\nand another parameter controlling the local search procedure. This family of\nalgorithms includes the celebrated k-means++ algorithm, as well as the classic\nfarthest-first traversal algorithm. We design efficient learning algorithms\nwhich receive samples from an application-specific distribution over clustering\ninstances and learn a near-optimal clustering algorithm from the class. We show\nthe best parameters vary significantly across datasets such as MNIST, CIFAR,\nand mixtures of Gaussians. Our learned algorithms never perform worse than\nk-means++, and on some datasets we see significant improvements.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 02:36:25 GMT"}, {"version": "v2", "created": "Sun, 6 Jan 2019 03:09:42 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 06:44:07 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Dick", "Travis", ""], ["White", "Colin", ""]]}, {"id": "1809.06992", "submitter": "Md Fayeem Bin Aziz", "authors": "Fayeem Aziz, Aaron S. W. Wong, James S. Welsh and Stephan K. Chalup", "title": "Aligning Manifolds of Double Pendulum Dynamics Under the Influence of\n  Noise", "comments": "The final version will appear in ICONIP 2018. A DOI identifier to the\n  final version will be added to the preprint, as soon as it is available", "journal-ref": null, "doi": "10.1007/978-3-030-04239-4_7", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents the results of a series of simulation experiments that\nevaluate and compare four different manifold alignment methods under the\ninfluence of noise. The data was created by simulating the dynamics of two\nslightly different double pendulums in three-dimensional space. The method of\nsemi-supervised feature-level manifold alignment using global distance resulted\nin the most convincing visualisations. However, the semi-supervised\nfeature-level local alignment methods resulted in smaller alignment errors.\nThese local alignment methods were also more robust to noise and faster than\nthe other methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 03:13:22 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 04:06:59 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Aziz", "Fayeem", ""], ["Wong", "Aaron S. W.", ""], ["Welsh", "James S.", ""], ["Chalup", "Stephan K.", ""]]}, {"id": "1809.06995", "submitter": "Alexander Brown", "authors": "Alexander Brown and Marek Petrik", "title": "Interpretable Reinforcement Learning with Ensemble Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to use boosted regression trees as a way to compute\nhuman-interpretable solutions to reinforcement learning problems. Boosting\ncombines several regression trees to improve their accuracy without\nsignificantly reducing their inherent interpretability. Prior work has focused\nindependently on reinforcement learning and on interpretable machine learning,\nbut there has been little progress in interpretable reinforcement learning. Our\nexperimental results show that boosted regression trees compute solutions that\nare both interpretable and match the quality of leading reinforcement learning\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 03:23:35 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Brown", "Alexander", ""], ["Petrik", "Marek", ""]]}, {"id": "1809.07004", "submitter": "Jeannette Bohg", "authors": "Hamza Merzic and Miroslav Bogdanovic and Daniel Kappler and Ludovic\n  Righetti and Jeannette Bohg", "title": "Leveraging Contact Forces for Learning to Grasp", "comments": "7 pages, 5 figures, Submitted to ICRA'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grasping objects under uncertainty remains an open problem in robotics\nresearch. This uncertainty is often due to noisy or partial observations of the\nobject pose or shape. To enable a robot to react appropriately to unforeseen\neffects, it is crucial that it continuously takes sensor feedback into account.\nWhile visual feedback is important for inferring a grasp pose and reaching for\nan object, contact feedback offers valuable information during manipulation and\ngrasp acquisition. In this paper, we use model-free deep reinforcement learning\nto synthesize control policies that exploit contact sensing to generate robust\ngrasping under uncertainty. We demonstrate our approach on a multi-fingered\nhand that exhibits more complex finger coordination than the commonly used\ntwo-fingered grippers. We conduct extensive experiments in order to assess the\nperformance of the learned policies, with and without contact sensing. While it\nis possible to learn grasping policies without contact sensing, our results\nsuggest that contact feedback allows for a significant improvement of grasping\nrobustness under object pose uncertainty and for objects with a complex shape.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 03:55:54 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Merzic", "Hamza", ""], ["Bogdanovic", "Miroslav", ""], ["Kappler", "Daniel", ""], ["Righetti", "Ludovic", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1809.07006", "submitter": "Andrew Skabar", "authors": "Andrew Skabar", "title": "Using Eigencentrality to Estimate Joint, Conditional and Marginal\n  Probabilities from Mixed-Variable Data: Method and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to estimate joint, conditional and marginal probability\ndistributions over some set of variables is of great utility for many common\nmachine learning tasks. However, estimating these distributions can be\nchallenging, particularly in the case of data containing a mix of discrete and\ncontinuous variables. This paper presents a non-parametric method for\nestimating these distributions directly from a dataset. The data are first\nrepresented as a graph consisting of object nodes and attribute value nodes.\nDepending on the distribution to be estimated, an appropriate eigenvector\nequation is then constructed. This equation is then solved to find the\ncorresponding stationary distribution of the graph, from which the required\ndistributions can then be estimated and sampled from. The paper demonstrates\nhow the method can be applied to many common machine learning tasks including\nclassification, regression, missing value imputation, outlier detection, random\nvector generation, and clustering.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 04:01:55 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Skabar", "Andrew", ""]]}, {"id": "1809.07011", "submitter": "Nontawat Charoenphakdee", "authors": "Nontawat Charoenphakdee and Masashi Sugiyama", "title": "Positive-Unlabeled Classification under Class Prior Shift and Asymmetric\n  Error", "comments": "Fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bottlenecks of binary classification from positive and unlabeled data (PU\nclassification) are the requirements that given unlabeled patterns are drawn\nfrom the test marginal distribution, and the penalty of the false positive\nerror is identical to the false negative error. However, such requirements are\noften not fulfilled in practice. In this paper, we generalize PU classification\nto the class prior shift and asymmetric error scenarios. Based on the analysis\nof the Bayes optimal classifier, we show that given a test class prior, PU\nclassification under class prior shift is equivalent to PU classification with\nasymmetric error. Then, we propose two different frameworks to handle these\nproblems, namely, a risk minimization framework and density ratio estimation\nframework. Finally, we demonstrate the effectiveness of the proposed frameworks\nand compare both frameworks through experiments using benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 04:29:03 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 14:56:14 GMT"}, {"version": "v3", "created": "Wed, 17 Oct 2018 03:14:42 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2020 10:26:23 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Charoenphakdee", "Nontawat", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1809.07016", "submitter": "Chong Xiang", "authors": "Chong Xiang, Charles R. Qi, Bo Li", "title": "Generating 3D Adversarial Point Clouds", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are known to be vulnerable to adversarial examples which\nare carefully crafted instances to cause the models to make wrong predictions.\nWhile adversarial examples for 2D images and CNNs have been extensively\nstudied, less attention has been paid to 3D data such as point clouds. Given\nmany safety-critical 3D applications such as autonomous driving, it is\nimportant to study how adversarial point clouds could affect current deep 3D\nmodels. In this work, we propose several novel algorithms to craft adversarial\npoint clouds against PointNet, a widely used deep neural network for point\ncloud processing. Our algorithms work in two ways: adversarial point\nperturbation and adversarial point generation. For point perturbation, we shift\nexisting points negligibly. For point generation, we generate either a set of\nindependent and scattered points or a small number (1-3) of point clusters with\nmeaningful shapes such as balls and airplanes which could be hidden in the\nhuman psyche. In addition, we formulate six perturbation measurement metrics\ntailored to the attacks in point clouds and conduct extensive experiments to\nevaluate the proposed algorithms on the ModelNet40 3D shape classification\ndataset. Overall, our attack algorithms achieve a success rate higher than 99%\nfor all targeted attacks\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 05:01:06 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 13:48:49 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 09:36:18 GMT"}, {"version": "v4", "created": "Fri, 12 Jul 2019 12:35:10 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Xiang", "Chong", ""], ["Qi", "Charles R.", ""], ["Li", "Bo", ""]]}, {"id": "1809.07023", "submitter": "Zijun Zhang", "authors": "Zijun Zhang, Yining Zhang, Zongpeng Li", "title": "Removing the Feature Correlation Effect of Multiplicative Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplicative noise, including dropout, is widely used to regularize deep\nneural networks (DNNs), and is shown to be effective in a wide range of\narchitectures and tasks. From an information perspective, we consider injecting\nmultiplicative noise into a DNN as training the network to solve the task with\nnoisy information pathways, which leads to the observation that multiplicative\nnoise tends to increase the correlation between features, so as to increase the\nsignal-to-noise ratio of information pathways. However, high feature\ncorrelation is undesirable, as it increases redundancy in representations. In\nthis work, we propose non-correlating multiplicative noise (NCMN), which\nexploits batch normalization to remove the correlation effect in a simple yet\neffective way. We show that NCMN significantly improves the performance of\nstandard multiplicative noise on image classification tasks, providing a better\nalternative to dropout for batch-normalized networks. Additionally, we present\na unified view of NCMN and shake-shake regularization, which explains the\nperformance gain of the latter.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 06:23:46 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Zhang", "Zijun", ""], ["Zhang", "Yining", ""], ["Li", "Zongpeng", ""]]}, {"id": "1809.07048", "submitter": "Jose Carballo", "authors": "Jose A. Carballo, Javier Bonilla, Manuel Berenguel, Jes\\'us\n  Fern\\'andez-Reche, Gin\\'es Garc\\'ia", "title": "New approach for solar tracking systems based on computer vision, low\n  cost hardware and deep learning", "comments": "12 pages, 10 figures,", "journal-ref": "Carballo, J. A., Bonilla, J., Berenguel, M., Fernandez-Reche, J.,\n  & Garcia, G. (2018). New approach for solar tracking systems based on\n  computer vision, low cost hardware and deep learning. Renewable Energy", "doi": "10.1016/j.renene.2018.08.101", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a new approach for Sun tracking systems is presented. Due to\nthe current system limitations regarding costs and operational problems, a new\napproach based on low cost, computer vision open hardware and deep learning has\nbeen developed. The preliminary tests carried out successfully in Plataforma\nsolar de Almeria (PSA), reveal the great potential and show the new approach as\na good alternative to traditional systems. The proposed approach can provide\nkey variables for the Sun tracking system control like cloud movements\nprediction, block and shadow detection, atmospheric attenuation or measures of\nconcentrated solar radiation, which can improve the control strategies of the\nsystem and therefore the system performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 08:09:04 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Carballo", "Jose A.", ""], ["Bonilla", "Javier", ""], ["Berenguel", "Manuel", ""], ["Fern\u00e1ndez-Reche", "Jes\u00fas", ""], ["Garc\u00eda", "Gin\u00e9s", ""]]}, {"id": "1809.07066", "submitter": "Vishal Sunder", "authors": "Vishal Sunder, Lovekesh Vig, Arnab Chatterjee, Gautam Shroff", "title": "Prosocial or Selfish? Agents with different behaviors for Contract\n  Negotiation using Reinforcement Learning", "comments": "Proceedings of the 11th International Workshop on Automated\n  Negotiations (held in conjunction with IJCAI 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an effective technique for training deep learning agents capable\nof negotiating on a set of clauses in a contract agreement using a simple\ncommunication protocol. We use Multi Agent Reinforcement Learning to train both\nagents simultaneously as they negotiate with each other in the training\nenvironment. We also model selfish and prosocial behavior to varying degrees in\nthese agents. Empirical evidence is provided showing consistency in agent\nbehaviors. We further train a meta agent with a mixture of behaviors by\nlearning an ensemble of different models using reinforcement learning. Finally,\nto ascertain the deployability of the negotiating agents, we conducted\nexperiments pitting the trained agents against human players. Results\ndemonstrate that the agents are able to hold their own against human players,\noften emerging as winners in the negotiation. Our experiments demonstrate that\nthe meta agent is able to reasonably emulate human behavior.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 08:46:34 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Sunder", "Vishal", ""], ["Vig", "Lovekesh", ""], ["Chatterjee", "Arnab", ""], ["Shroff", "Gautam", ""]]}, {"id": "1809.07069", "submitter": "Roland S. Zimmermann", "authors": "Roland S. Zimmermann and Julien N. Siems", "title": "Faster Training of Mask R-CNN by Focusing on Instance Boundaries", "comments": "9 pages, 7 figures, 5 tables", "journal-ref": null, "doi": "10.1016/j.cviu.2019.102795", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an auxiliary task to Mask R-CNN, an instance segmentation network,\nwhich leads to faster training of the mask head. Our addition to Mask R-CNN is\na new prediction head, the Edge Agreement Head, which is inspired by the way\nhuman annotators perform instance segmentation. Human annotators copy the\ncontour of an object instance and only indirectly the occupied instance area.\nHence, the edges of instance masks are particularly useful as they characterize\nthe instance well. The Edge Agreement Head therefore encourages predicted masks\nto have similar image gradients to the ground-truth mask using edge detection\nfilters. We provide a detailed survey of loss combinations and show\nimprovements on the MS COCO Mask metrics compared to using no additional loss.\nOur approach marginally increases the model size and adds no additional\ntrainable model variables. While the computational costs are increased\nslightly, the increment is negligible considering the high computational cost\nof the Mask R-CNN architecture. As the additional network head is only relevant\nduring training, inference speed remains unchanged compared to Mask R-CNN. In a\ndefault Mask R-CNN setup, we achieve a training speed-up and a relative overall\nimprovement of 8.1% on the MS COCO metrics compared to the baseline.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 08:54:18 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 15:55:43 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 19:57:57 GMT"}, {"version": "v4", "created": "Sat, 10 Aug 2019 08:55:37 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Zimmermann", "Roland S.", ""], ["Siems", "Julien N.", ""]]}, {"id": "1809.07082", "submitter": "Matthias Lenga", "authors": "Matthias Lenga, Tobias Klinder, Christian B\\\"urger, Jens von Berg,\n  Astrid Franz, Cristian Lorenz", "title": "Deep Learning Based Rib Centerline Extraction and Labeling", "comments": "This paper was accepted for presentation at the MICCAI MSKI 2018\n  Workshop", "journal-ref": null, "doi": "10.1007/978-3-030-11166-3_9", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated extraction and labeling of rib centerlines is a typically needed\nprerequisite for more advanced assisted reading tools that help the radiologist\nto efficiently inspect all 24 ribs in a CT volume. In this paper, we combine a\ndeep learning-based rib detection with a dedicated centerline extraction\nalgorithm applied to the detection result for the purpose of fast, robust and\naccurate rib centerline extraction and labeling from CT volumes. More\nspecifically, we first apply a fully convolutional neural network (FCNN) to\ngenerate a probability map for detecting the first rib pair, the twelfth rib\npair, and the collection of all intermediate ribs. In a second stage, a newly\ndesigned centerline extraction algorithm is applied to this multi-label\nprobability map. Finally, the distinct detection of first and twelfth rib\nseparately, allows to derive individual rib labels by simple sorting and\ncounting the detected centerlines. We applied our method to CT volumes from 116\npatients which included a variety of different challenges and achieved a\ncenterline accuracy of 0.787 mm with respect to manual centerline annotations.\n  This article is a preprint version of: Lenga M., Klinder T., B\\\"urger C., von\nBerg J., Franz A., Lorenz C. (2019) Deep Learning Based Rib Centerline\nExtraction and Labeling. In: Vrtovec T., Yao J., Zheng G., Pozo J. (eds)\nComputational Methods and Clinical Applications in Musculoskeletal Imaging.\nMSKI 2018. Lecture Notes in Computer Science, vol 11404. Springer, Cham\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 09:09:23 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 20:56:28 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Lenga", "Matthias", ""], ["Klinder", "Tobias", ""], ["B\u00fcrger", "Christian", ""], ["von Berg", "Jens", ""], ["Franz", "Astrid", ""], ["Lorenz", "Cristian", ""]]}, {"id": "1809.07091", "submitter": "Andres C Rodriguez", "authors": "Andres C. Rodriguez and Jan D. Wegner", "title": "Counting the uncountable: deep semantic density estimation from Space", "comments": "Accepted in GCPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method to count objects of specific categories that are\nsignificantly smaller than the ground sampling distance of a satellite image.\nThis task is hard due to the cluttered nature of scenes where different object\ncategories occur. Target objects can be partially occluded, vary in appearance\nwithin the same class and look alike to different categories. Since traditional\nobject detection is infeasible due to the small size of objects with respect to\nthe pixel size, we cast object counting as a density estimation problem. To\ndistinguish objects of different classes, our approach combines density\nestimation with semantic segmentation in an end-to-end learnable convolutional\nneural network (CNN). Experiments show that deep semantic density estimation\ncan robustly count objects of various classes in cluttered scenes. Experiments\nalso suggest that we need specific CNN architectures in remote sensing instead\nof blindly applying existing ones from computer vision.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 09:29:35 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 07:15:02 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Rodriguez", "Andres C.", ""], ["Wegner", "Jan D.", ""]]}, {"id": "1809.07098", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas, Hirotaka Takano, Junichi Murata", "title": "Novelty-organizing team of classifiers in noisy and dynamic environments", "comments": null, "journal-ref": "2015 IEEE Congress on Evolutionary Computation (CEC)", "doi": "10.1109/CEC.2015.7257254", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, the environment is constantly changing with the input\nvariables under the effect of noise. However, few algorithms were shown to be\nable to work under those circumstances. Here, Novelty-Organizing Team of\nClassifiers (NOTC) is applied to the continuous action mountain car as well as\ntwo variations of it: a noisy mountain car and an unstable weather mountain\ncar. These problems take respectively noise and change of problem dynamics into\naccount. Moreover, NOTC is compared with NeuroEvolution of Augmenting\nTopologies (NEAT) in these problems, revealing a trade-off between the\napproaches. While NOTC achieves the best performance in all of the problems,\nNEAT needs less trials to converge. It is demonstrated that NOTC achieves\nbetter performance because of its division of the input space (creating easier\nproblems). Unfortunately, this division of input space also requires a bit of\ntime to bootstrap.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 09:38:20 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Takano", "Hirotaka", ""], ["Murata", "Junichi", ""]]}, {"id": "1809.07102", "submitter": "Kirubin Pillay", "authors": "Kirubin Pillay and Maarten De Vos", "title": "A unifying Bayesian approach for preterm brain-age prediction that\n  models EEG sleep transitions over age", "comments": "5 pages, 2 figures. Submitted for Neural Information Processing\n  (NIPS) conference workshop on Machine Learning for Health (ML4H), Long Beach,\n  CA, USA, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preterm newborns undergo various stresses that may materialize as learning\nproblems at school-age. Sleep staging of the Electroencephalogram (EEG),\nfollowed by prediction of their brain-age from these sleep states can quantify\ndeviations from normal brain development early (when compared to the known\nage). Current automation of this approach relies on explicit sleep state\nclassification, optimizing algorithms using clinician visually labelled sleep\nstages, which remains a subjective gold-standard. Such models fail to perform\nconsistently over a wide age range and impacts the subsequent brain-age\nestimates that could prevent identification of subtler developmental\ndeviations. We introduce a Bayesian Network utilizing multiple Gaussian Mixture\nModels, as a novel, unified approach for directly estimating brain-age,\nsimultaneously modelling for both age and sleep dependencies on the EEG, to\nimprove the accuracy of prediction over a wider age range.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 09:52:53 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Pillay", "Kirubin", ""], ["De Vos", "Maarten", ""]]}, {"id": "1809.07109", "submitter": "Young-Jin Park", "authors": "Young-Jin Park, and Han-Lim Choi", "title": "InfoSSM: Interpretable Unsupervised Learning of Nonparametric\n  State-Space Model for Multi-modal Dynamics", "comments": "Submitted to AIAA Intelligent Systems Student Paper Competition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of system identification is to learn about underlying physics\ndynamics behind the time-series data. To model the probabilistic and\nnonparametric dynamics model, Gaussian process (GP) have been widely used; GP\ncan estimate the uncertainty of prediction and avoid over-fitting. Traditional\nGPSSMs, however, are based on Gaussian transition model, thus often have\ndifficulty in describing a more complex transition model, e.g. aircraft\nmotions. To resolve the challenge, this paper proposes a framework using\nmultiple GP transition models which is capable of describing multi-modal\ndynamics. Furthermore, we extend the model to the information-theoretic\nframework, the so-called InfoSSM, by introducing a mutual information\nregularizer helping the model to learn interpretable and distinguishable\nmultiple dynamics models. Two illustrative numerical experiments in simple\nDubins vehicle and high-fidelity flight simulator are presented to demonstrate\nthe performance and interpretability of the proposed model. Finally, this paper\nintroduces a framework using InfoSSM with Bayesian filtering for air traffic\ncontrol tracking.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 10:16:00 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 10:05:23 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Park", "Young-Jin", ""], ["Choi", "Han-Lim", ""]]}, {"id": "1809.07122", "submitter": "Shuxin Zheng", "authors": "Shuxin Zheng, Qi Meng, Huishuai Zhang, Wei Chen, Nenghai Yu, Tie-Yan\n  Liu", "title": "Capacity Control of ReLU Neural Networks by Basis-path Norm", "comments": null, "journal-ref": "AAAI 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, path norm was proposed as a new capacity measure for neural\nnetworks with Rectified Linear Unit (ReLU) activation function, which takes the\nrescaling-invariant property of ReLU into account. It has been shown that the\ngeneralization error bound in terms of the path norm explains the empirical\ngeneralization behaviors of the ReLU neural networks better than that of other\ncapacity measures. Moreover, optimization algorithms which take path norm as\nthe regularization term to the loss function, like Path-SGD, have been shown to\nachieve better generalization performance. However, the path norm counts the\nvalues of all paths, and hence the capacity measure based on path norm could be\nimproperly influenced by the dependency among different paths. It is also known\nthat each path of a ReLU network can be represented by a small group of\nlinearly independent basis paths with multiplication and division operation,\nwhich indicates that the generalization behavior of the network only depends on\nonly a few basis paths. Motivated by this, we propose a new norm\n\\emph{Basis-path Norm} based on a group of linearly independent paths to\nmeasure the capacity of neural networks more accurately. We establish a\ngeneralization error bound based on this basis path norm, and show it explains\nthe generalization behaviors of ReLU networks more accurately than previous\ncapacity measures via extensive experiments. In addition, we develop\noptimization algorithms which minimize the empirical risk regularized by the\nbasis-path norm. Our experiments on benchmark datasets demonstrate that the\nproposed regularization method achieves clearly better performance on the test\nset than the previous regularization approaches.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 11:08:31 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Zheng", "Shuxin", ""], ["Meng", "Qi", ""], ["Zhang", "Huishuai", ""], ["Chen", "Wei", ""], ["Yu", "Nenghai", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1809.07180", "submitter": "Patrick Johnstone", "authors": "Patrick R. Johnstone and Jonathan Eckstein", "title": "Projective Splitting with Forward Steps only Requires Continuity", "comments": "15 pages. arXiv admin note: text overlap with arXiv:1803.07043", "journal-ref": "Optim. Lett. 14, 229-247 (2020)", "doi": "10.1007/s11590-019-01509-7", "report-no": null, "categories": "math.OC cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent innovation in projective splitting algorithms for monotone operator\ninclusions has been the development of a procedure using two forward steps\ninstead of the customary proximal steps for operators that are Lipschitz\ncontinuous. This paper shows that the Lipschitz assumption is unnecessary when\nthe forward steps are performed in finite-dimensional spaces: a backtracking\nlinesearch yields a convergent algorithm for operators that are merely\ncontinuous with full domain.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 18:11:28 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Johnstone", "Patrick R.", ""], ["Eckstein", "Jonathan", ""]]}, {"id": "1809.07192", "submitter": "Yizheng Liao", "authors": "Yizheng Liao, Yang Weng, Guangyi Liu, Zhongyang Zhao, Chin-woo Tan,\n  Ram Rajagopal", "title": "Unbalanced Multi-Phase Distribution Grid Topology Estimation and Bus\n  Phase Identification", "comments": "17 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is an increasing need for monitoring and controlling uncertainties\nbrought by distributed energy resources in distribution grids. For such goal,\naccurate multi-phase topology is the basis for correlating measurements in\nunbalanced distribution networks. Unfortunately, such topology knowledge is\noften unavailable due to limited investment, especially for \\revv{low-voltage}\ndistribution grids. Also, the bus phase labeling information is inaccurate due\nto human errors or outdated records. For this challenge, this paper utilizes\nsmart meter data for an information-theoretic approach to learn the topology of\ndistribution grids. Specifically, multi-phase unbalanced systems are converted\ninto symmetrical components, namely positive, negative, and zero sequences.\nThen, this paper proves that the Chow-Liu algorithm finds the topology by\nutilizing power flow equations and the conditional independence relationships\nimplied by the radial multi-phase structure of distribution grids with the\npresence of incorrect bus phase labels. At last, by utilizing Carson's\nequation, this paper proves that the bus phase connection can be correctly\nidentified using voltage measurements. For validation, IEEE systems are\nsimulated using three real data sets. The simulation results demonstrate that\nthe algorithm is highly accurate for finding multi-phase topology even with\nstrong load unbalancing condition and DERs. This ensures close monitoring and\ncontrolling DERs in distribution grids.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 05:22:49 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 05:00:44 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 07:05:35 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Liao", "Yizheng", ""], ["Weng", "Yang", ""], ["Liu", "Guangyi", ""], ["Zhao", "Zhongyang", ""], ["Tan", "Chin-woo", ""], ["Rajagopal", "Ram", ""]]}, {"id": "1809.07196", "submitter": "Elliot J. Crowley", "authors": "Jack Turner, Jos\\'e Cano, Valentin Radu, Elliot J. Crowley, Michael\n  O'Boyle, Amos Storkey", "title": "Characterising Across-Stack Optimisations for Deep Convolutional Neural\n  Networks", "comments": "IISWC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) are extremely computationally demanding,\npresenting a large barrier to their deployment on resource-constrained devices.\nSince such systems are where some of their most useful applications lie (e.g.\nobstacle detection for mobile robots, vision-based medical assistive\ntechnology), significant bodies of work from both machine learning and systems\ncommunities have attempted to provide optimisations that will make CNNs\navailable to edge devices. In this paper we unify the two viewpoints in a Deep\nLearning Inference Stack and take an across-stack approach by implementing and\nevaluating the most common neural network compression techniques (weight\npruning, channel pruning, and quantisation) and optimising their parallel\nexecution with a range of programming approaches (OpenMP, OpenCL) and hardware\narchitectures (CPU, GPU). We provide comprehensive Pareto curves to instruct\ntrade-offs under constraints of accuracy, execution time, and memory space.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 13:52:49 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Turner", "Jack", ""], ["Cano", "Jos\u00e9", ""], ["Radu", "Valentin", ""], ["Crowley", "Elliot J.", ""], ["O'Boyle", "Michael", ""], ["Storkey", "Amos", ""]]}, {"id": "1809.07222", "submitter": "Sreejith Kallummil", "authors": "Sreejith Kallummil and Sheetal Kalyani", "title": "Noise Statistics Oblivious GARD For Robust Regression With Sparse\n  Outliers", "comments": "16 pages, 24 figures", "journal-ref": null, "doi": "10.1109/TSP.2018.2883025", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear regression models contaminated by Gaussian noise (inlier) and possibly\nunbounded sparse outliers are common in many signal processing applications.\nSparse recovery inspired robust regression (SRIRR) techniques are shown to\ndeliver high quality estimation performance in such regression models.\nUnfortunately, most SRIRR techniques assume \\textit{a priori} knowledge of\nnoise statistics like inlier noise variance or outlier statistics like number\nof outliers. Both inlier and outlier noise statistics are rarely known\n\\textit{a priori} and this limits the efficient operation of many SRIRR\nalgorithms. This article proposes a novel noise statistics oblivious algorithm\ncalled residual ratio thresholding GARD (RRT-GARD) for robust regression in the\npresence of sparse outliers. RRT-GARD is developed by modifying the recently\nproposed noise statistics dependent greedy algorithm for robust de-noising\n(GARD). Both finite sample and asymptotic analytical results indicate that\nRRT-GARD performs nearly similar to GARD with \\textit{a priori} knowledge of\nnoise statistics. Numerical simulations in real and synthetic data sets also\npoint to the highly competitive performance of RRT-GARD.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 14:36:11 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Kallummil", "Sreejith", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1809.07257", "submitter": "Oliver Nina", "authors": "Oliver Nina and Washington Garcia and Scott Clouse and Alper Yilmaz", "title": "MTLE: A Multitask Learning Encoder of Visual Feature Representations for\n  Video and Movie Description", "comments": "This is a pre-print version of our soon to be released paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning visual feature representations for video analysis is a daunting task\nthat requires a large amount of training samples and a proper generalization\nframework. Many of the current state of the art methods for video captioning\nand movie description rely on simple encoding mechanisms through recurrent\nneural networks to encode temporal visual information extracted from video\ndata. In this paper, we introduce a novel multitask encoder-decoder framework\nfor automatic semantic description and captioning of video sequences. In\ncontrast to current approaches, our method relies on distinct decoders that\ntrain a visual encoder in a multitask fashion. Our system does not depend\nsolely on multiple labels and allows for a lack of training data working even\nwith datasets where only one single annotation is viable per video. Our method\nshows improved performance over current state of the art methods in several\nmetrics on multi-caption and single-caption datasets. To the best of our\nknowledge, our method is the first method to use a multitask approach for\nencoding video features. Our method demonstrates its robustness on the Large\nScale Movie Description Challenge (LSMDC) 2017 where our method won the movie\ndescription task and its results were ranked among other competitors as the\nmost helpful for the visually impaired.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 15:50:18 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Nina", "Oliver", ""], ["Garcia", "Washington", ""], ["Clouse", "Scott", ""], ["Yilmaz", "Alper", ""]]}, {"id": "1809.07258", "submitter": "Guillaume Gautier", "authors": "Guillaume Gautier, Guillermo Polito, R\\'emi Bardenet, Michal Valko", "title": "DPPy: Sampling DPPs with Python", "comments": "Code at http://github.com/guilgautier/DPPy/ Documentation at\n  http://dppy.readthedocs.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) are specific probability distributions\nover clouds of points that are used as models and computational tools across\nphysics, probability, statistics, and more recently machine learning. Sampling\nfrom DPPs is a challenge and therefore we present DPPy, a Python toolbox that\ngathers known exact and approximate sampling algorithms for both finite and\ncontinuous DPPs. The project is hosted on GitHub and equipped with an extensive\ndocumentation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 15:53:00 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 16:58:41 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Gautier", "Guillaume", ""], ["Polito", "Guillermo", ""], ["Bardenet", "R\u00e9mi", ""], ["Valko", "Michal", ""]]}, {"id": "1809.07260", "submitter": "Santu Rana", "authors": "Pratibha Vellanki, Santu Rana, Sunil Gupta, David Rubin de Celis Leal,\n  Alessandra Sutti, Murray Height, Svetha Venkatesh", "title": "Bayesian functional optimisation with shape prior", "comments": "Submitted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world experiments are expensive, and thus it is important to reach a\ntarget in minimum number of experiments. Experimental processes often involve\ncontrol variables that changes over time. Such problems can be formulated as a\nfunctional optimisation problem. We develop a novel Bayesian optimisation\nframework for such functional optimisation of expensive black-box processes. We\nrepresent the control function using Bernstein polynomial basis and optimise in\nthe coefficient space. We derive the theory and practice required to\ndynamically adjust the order of the polynomial degree, and show how prior\ninformation about shape can be integrated. We demonstrate the effectiveness of\nour approach for short polymer fibre design and optimising learning rate\nschedules for deep networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 16:00:24 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 00:24:26 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Vellanki", "Pratibha", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Leal", "David Rubin de Celis", ""], ["Sutti", "Alessandra", ""], ["Height", "Murray", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1809.07276", "submitter": "Romain Hennequin", "authors": "R\\'emi Delbouys and Romain Hennequin and Francesco Piccoli and Jimena\n  Royo-Letelier and Manuel Moussallam", "title": "Music Mood Detection Based On Audio And Lyrics With Deep Neural Net", "comments": "Published in ISMIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the task of multimodal music mood prediction based on the audio\nsignal and the lyrics of a track. We reproduce the implementation of\ntraditional feature engineering based approaches and propose a new model based\non deep learning. We compare the performance of both approaches on a database\ncontaining 18,000 tracks with associated valence and arousal values and show\nthat our approach outperforms classical models on the arousal detection task,\nand that both approaches perform equally on the valence prediction task. We\nalso compare the a posteriori fusion with fusion of modalities optimized\nsimultaneously with each unimodal model, and observe a significant improvement\nof valence prediction. We release part of our database for comparison purposes.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 16:16:57 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Delbouys", "R\u00e9mi", ""], ["Hennequin", "Romain", ""], ["Piccoli", "Francesco", ""], ["Royo-Letelier", "Jimena", ""], ["Moussallam", "Manuel", ""]]}, {"id": "1809.07282", "submitter": "Nikita Srivatsan", "authors": "Nikita Srivatsan, Zachary Wojtowicz, Taylor Berg-Kirkpatrick", "title": "Modeling Online Discourse with Coupled Distributed Topics", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep, globally normalized topic model that\nincorporates structural relationships connecting documents in socially\ngenerated corpora, such as online forums. Our model (1) captures discursive\ninteractions along observed reply links in addition to traditional topic\ninformation, and (2) incorporates latent distributed representations arranged\nin a deep architecture, which enables a GPU-based mean-field inference\nprocedure that scales efficiently to large data. We apply our model to a new\nsocial media dataset consisting of 13M comments mined from the popular internet\nforum Reddit, a domain that poses significant challenges to models that do not\naccount for relationships connecting user comments. We evaluate against\nexisting methods across multiple metrics including perplexity and metadata\nprediction, and qualitatively analyze the learned interaction patterns.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 16:21:12 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 17:47:25 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 05:21:13 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Srivatsan", "Nikita", ""], ["Wojtowicz", "Zachary", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1809.07294", "submitter": "Xin Yi", "authors": "Xin Yi, Ekta Walia, Paul Babyn", "title": "Generative Adversarial Network in Medical Imaging: A Review", "comments": "24 pages; v4; added missing references from before Jan 1st 2019;\n  accepted to MedIA", "journal-ref": null, "doi": "10.1016/j.media.2019.101552", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks have gained a lot of attention in the\ncomputer vision community due to their capability of data generation without\nexplicitly modelling the probability density function. The adversarial loss\nbrought by the discriminator provides a clever way of incorporating unlabeled\nsamples into training and imposing higher order consistency. This has proven to\nbe useful in many cases, such as domain adaptation, data augmentation, and\nimage-to-image translation. These properties have attracted researchers in the\nmedical imaging community, and we have seen rapid adoption in many traditional\nand novel applications, such as image reconstruction, segmentation, detection,\nclassification, and cross-modality synthesis. Based on our observations, this\ntrend will continue and we therefore conducted a review of recent advances in\nmedical imaging using the adversarial training scheme with the hope of\nbenefiting researchers interested in this technique.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 16:44:36 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 16:17:34 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 20:29:29 GMT"}, {"version": "v4", "created": "Wed, 4 Sep 2019 01:01:58 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Yi", "Xin", ""], ["Walia", "Ekta", ""], ["Babyn", "Paul", ""]]}, {"id": "1809.07310", "submitter": "Yann Guermeur", "authors": "Yann Guermeur", "title": "Combinatorial and Structural Results for gamma-Psi-dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with the generalization performance of margin\nmulti-category classifiers, when minimal learnability hypotheses are made. In\nthat context, the derivation of a guaranteed risk is based on the handling of\ncapacity measures belonging to three main families: Rademacher/Gaussian\ncomplexities, metric entropies and scale-sensitive combinatorial dimensions.\nThe scale-sensitive combinatorial dimensions dedicated to the classifiers of\nthis kind are the gamma-Psi-dimensions. We introduce the combinatorial and\nstructural results needed to involve them in the derivation of guaranteed risks\nand establish the corresponding upper bounds on the metric entropies and the\nRademacher complexity. Two major conclusions can be drawn: 1. the\ngamma-Psi-dimensions always bring an improvement compared to the use of the\nfat-shattering dimension of the class of margin functions; 2. thanks to their\ncapacity to take into account basic features of the classifier, they represent\na promising alternative to performing the transition from the multi-class case\nto the binary one with covering numbers.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 17:35:43 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 19:22:21 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 17:35:56 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Guermeur", "Yann", ""]]}, {"id": "1809.07321", "submitter": "Diyora Salimova", "authors": "Arnulf Jentzen, Diyora Salimova, Timo Welti", "title": "A proof that deep artificial neural networks overcome the curse of\n  dimensionality in the numerical approximation of Kolmogorov partial\n  differential equations with constant diffusion and nonlinear drift\n  coefficients", "comments": "48 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.AP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years deep artificial neural networks (DNNs) have been successfully\nemployed in numerical simulations for a multitude of computational problems\nincluding, for example, object and face recognition, natural language\nprocessing, fraud detection, computational advertisement, and numerical\napproximations of partial differential equations (PDEs). These numerical\nsimulations indicate that DNNs seem to possess the fundamental flexibility to\novercome the curse of dimensionality in the sense that the number of real\nparameters used to describe the DNN grows at most polynomially in both the\nreciprocal of the prescribed approximation accuracy $ \\varepsilon > 0 $ and the\ndimension $ d \\in \\mathbb{N}$ of the function which the DNN aims to approximate\nin such computational problems. There is also a large number of rigorous\nmathematical approximation results for artificial neural networks in the\nscientific literature but there are only a few special situations where results\nin the literature can rigorously justify the success of DNNs in\nhigh-dimensional function approximation. The key contribution of this paper is\nto reveal that DNNs do overcome the curse of dimensionality in the numerical\napproximation of Kolmogorov PDEs with constant diffusion and nonlinear drift\ncoefficients. We prove that the number of parameters used to describe the\nemployed DNN grows at most polynomially in both the PDE dimension $ d \\in\n\\mathbb{N}$ and the reciprocal of the prescribed approximation accuracy $\n\\varepsilon > 0 $. A crucial ingredient in our proof is the fact that the\nartificial neural network used to approximate the solution of the PDE is indeed\na deep artificial neural network with a large number of hidden layers.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 17:56:40 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 14:25:33 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Jentzen", "Arnulf", ""], ["Salimova", "Diyora", ""], ["Welti", "Timo", ""]]}, {"id": "1809.07347", "submitter": "Sanket Diwale", "authors": "Sanket Diwale and Colin Jones", "title": "A Generalized Representer Theorem for Hilbert Space - Valued Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The necessary and sufficient conditions for existence of a generalized\nrepresenter theorem are presented for learning Hilbert space-valued functions.\nRepresenter theorems involving explicit basis functions and Reproducing Kernels\nare a common occurrence in various machine learning algorithms like generalized\nleast squares, support vector machines, Gaussian process regression and kernel\nbased deep neural networks to name a few. Due to the more general structure of\nthe underlying variational problems, the theory is also relevant to other\napplication areas like optimal control, signal processing and decision making.\nWe present the generalized representer as a unified view for supervised and\nsemi-supervised learning methods, using the theory of linear operators and\nsubspace valued maps. The implications of the theorem are presented with\nexamples of multi input-multi output regression, kernel based deep neural\nnetworks, stochastic regression and sparsity learning problems as being special\ncases in this unified view.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 18:00:51 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Diwale", "Sanket", ""], ["Jones", "Colin", ""]]}, {"id": "1809.07402", "submitter": "Huan Wang", "authors": "Huan Wang, Nitish Shirish Keskar, Caiming Xiong, Richard Socher", "title": "Identifying Generalization Properties in Neural Networks", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While it has not yet been proven, empirical evidence suggests that model\ngeneralization is related to local properties of the optima which can be\ndescribed via the Hessian. We connect model generalization with the local\nproperty of a solution under the PAC-Bayes paradigm. In particular, we prove\nthat model generalization ability is related to the Hessian, the higher-order\n\"smoothness\" terms characterized by the Lipschitz constant of the Hessian, and\nthe scales of the parameters. Guided by the proof, we propose a metric to score\nthe generalization capability of the model, as well as an algorithm that\noptimizes the perturbed model accordingly.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 20:37:42 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Wang", "Huan", ""], ["Keskar", "Nitish Shirish", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1809.07405", "submitter": "Tom Hanika", "authors": "Bastian Sch\\\"afermeier and Tom Hanika and Gerd Stumme", "title": "Distances for WiFi Based Topological Indoor Mapping", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": "10.1145/3360774.3360780", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For localization and mapping of indoor environments through WiFi signals,\nlocations are often represented as likelihoods of the received signal strength\nindicator. In this work we compare various measures of distance between such\nlikelihoods in combination with different methods for estimation and\nrepresentation. In particular, we show that among the considered distance\nmeasures the Earth Mover's Distance seems the most beneficial for the\nlocalization task. Combined with kernel density estimation we were able to\nretain the topological structure of rooms in a real-world office scenario.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 20:45:59 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Sch\u00e4fermeier", "Bastian", ""], ["Hanika", "Tom", ""], ["Stumme", "Gerd", ""]]}, {"id": "1809.07412", "submitter": "Martin Butz", "authors": "Martin V. Butz and David Bilkey and Dania Humaidan and Alistair Knott\n  and Sebastian Otte", "title": "Learning, Planning, and Control in a Monolithic Neural Event Inference\n  Architecture", "comments": "This is the final revision submitted to the Neural Networks journal.\n  The revision mainly includes improvements in language, explanation, and\n  additional references and system relations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce REPRISE, a REtrospective and PRospective Inference SchEme, which\nlearns temporal event-predictive models of dynamical systems. REPRISE infers\nthe unobservable contextual event state and accompanying temporal predictive\nmodels that best explain the recently encountered sensorimotor experiences\nretrospectively. Meanwhile, it optimizes upcoming motor activities\nprospectively in a goal-directed manner. Here, REPRISE is implemented by a\nrecurrent neural network (RNN), which learns temporal forward models of the\nsensorimotor contingencies generated by different simulated dynamic vehicles.\nThe RNN is augmented with contextual neurons, which enable the encoding of\ndistinct, but related, sensorimotor dynamics as compact event codes. We show\nthat REPRISE concurrently learns to separate and approximate the encountered\nsensorimotor dynamics: it analyzes sensorimotor error signals adapting both\ninternal contextual neural activities and connection weight values. Moreover,\nwe show that REPRISE can exploit the learned model to induce goal-directed,\nmodel-predictive control, that is, approximate active inference: Given a goal\nstate, the system imagines a motor command sequence optimizing it with the\nprospective objective to minimize the distance to the goal. The RNN activities\nthus continuously imagine the upcoming future and reflect on the recent past,\noptimizing the predictive model, the hidden neural state activities, and the\nupcoming motor activities. As a result, event-predictive neural encodings\ndevelop, which allow the invocation of highly effective and adaptive\ngoal-directed sensorimotor control.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 21:25:13 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 14:30:59 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Butz", "Martin V.", ""], ["Bilkey", "David", ""], ["Humaidan", "Dania", ""], ["Knott", "Alistair", ""], ["Otte", "Sebastian", ""]]}, {"id": "1809.07424", "submitter": "Besmira Nushi", "authors": "Besmira Nushi, Ece Kamar, Eric Horvitz", "title": "Towards Accountable AI: Hybrid Human-Machine Analyses for Characterizing\n  System Failure", "comments": null, "journal-ref": "AAAI Conference on Human Computation and Crowdsourcing 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning systems move from computer-science laboratories into the\nopen world, their accountability becomes a high priority problem.\nAccountability requires deep understanding of system behavior and its failures.\nCurrent evaluation methods such as single-score error metrics and confusion\nmatrices provide aggregate views of system performance that hide important\nshortcomings. Understanding details about failures is important for identifying\npathways for refinement, communicating the reliability of systems in different\nsettings, and for specifying appropriate human oversight and engagement.\nCharacterization of failures and shortcomings is particularly complex for\nsystems composed of multiple machine learned components. For such systems,\nexisting evaluation methods have limited expressiveness in describing and\nexplaining the relationship among input content, the internal states of system\ncomponents, and final output quality. We present Pandora, a set of hybrid\nhuman-machine methods and tools for describing and explaining system failures.\nPandora leverages both human and system-generated observations to summarize\nconditions of system malfunction with respect to the input content and system\narchitecture. We share results of a case study with a machine learning pipeline\nfor image captioning that show how detailed performance views can be beneficial\nfor analysis and debugging.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 22:53:46 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Nushi", "Besmira", ""], ["Kamar", "Ece", ""], ["Horvitz", "Eric", ""]]}, {"id": "1809.07426", "submitter": "Jiaxi Tang", "authors": "Jiaxi Tang, Ke Wang", "title": "Personalized Top-N Sequential Recommendation via Convolutional Sequence\n  Embedding", "comments": "Accepted at WSDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Top-$N$ sequential recommendation models each user as a sequence of items\ninteracted in the past and aims to predict top-$N$ ranked items that a user\nwill likely interact in a `near future'. The order of interaction implies that\nsequential patterns play an important role where more recent items in a\nsequence have a larger impact on the next item. In this paper, we propose a\nConvolutional Sequence Embedding Recommendation Model (\\emph{Caser}) as a\nsolution to address this requirement. The idea is to embed a sequence of recent\nitems into an `image' in the time and latent spaces and learn sequential\npatterns as local features of the image using convolutional filters. This\napproach provides a unified and flexible network structure for capturing both\ngeneral preferences and sequential patterns. The experiments on public datasets\ndemonstrated that Caser consistently outperforms state-of-the-art sequential\nrecommendation methods on a variety of common evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 23:13:57 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Tang", "Jiaxi", ""], ["Wang", "Ke", ""]]}, {"id": "1809.07428", "submitter": "Jiaxi Tang", "authors": "Jiaxi Tang, Ke Wang", "title": "Ranking Distillation: Learning Compact Ranking Models With High\n  Performance for Recommender System", "comments": "Accepted at KDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel way to train ranking models, such as recommender systems,\nthat are both effective and efficient. Knowledge distillation (KD) was shown to\nbe successful in image recognition to achieve both effectiveness and\nefficiency. We propose a KD technique for learning to rank problems, called\n\\emph{ranking distillation (RD)}. Specifically, we train a smaller student\nmodel to learn to rank documents/items from both the training data and the\nsupervision of a larger teacher model. The student model achieves a similar\nranking performance to that of the large teacher model, but its smaller model\nsize makes the online inference more efficient. RD is flexible because it is\northogonal to the choices of ranking models for the teacher and student. We\naddress the challenges of RD for ranking problems. The experiments on public\ndata sets and state-of-the-art recommendation models showed that RD achieves\nits design purposes: the student model learnt with RD has a model size less\nthan half of the teacher model while achieving a ranking performance similar to\nthe teacher model and much better than the student model learnt without RD.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 23:25:24 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Tang", "Jiaxi", ""], ["Wang", "Ke", ""]]}, {"id": "1809.07435", "submitter": "Kristopher De Asis", "authors": "Kristopher De Asis, Brendan Bennett, Richard S. Sutton", "title": "Predicting Periodicity with Temporal Difference Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal difference (TD) learning is an important approach in reinforcement\nlearning, as it combines ideas from dynamic programming and Monte Carlo methods\nin a way that allows for online and incremental model-free learning. A key idea\nof TD learning is that it is learning predictive knowledge about the\nenvironment in the form of value functions, from which it can derive its\nbehavior to address long-term sequential decision making problems. The agent's\nhorizon of interest, that is, how immediate or long-term a TD learning agent\npredicts into the future, is adjusted through a discount rate parameter. In\nthis paper, we introduce an alternative view on the discount rate, with insight\nfrom digital signal processing, to include complex-valued discounting. Our\nresults show that setting the discount rate to appropriately chosen complex\nnumbers allows for online and incremental estimation of the Discrete Fourier\nTransform (DFT) of a signal of interest with TD learning. We thereby extend the\ntypes of knowledge representable by value functions, which we show are\nparticularly useful for identifying periodic effects in the reward sequence.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 00:07:27 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["De Asis", "Kristopher", ""], ["Bennett", "Brendan", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1809.07436", "submitter": "Chengsheng Mao", "authors": "Chengsheng Mao, Yiheng Pan, Zexian Zeng, Liang Yao, Yuan Luo", "title": "Deep Generative Classifiers for Thoracic Disease Diagnosis with Chest\n  X-ray Images", "comments": "BIBM 2018 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thoracic diseases are very serious health problems that plague a large number\nof people. Chest X-ray is currently one of the most popular methods to diagnose\nthoracic diseases, playing an important role in the healthcare workflow.\nHowever, reading the chest X-ray images and giving an accurate diagnosis remain\nchallenging tasks for expert radiologists. With the success of deep learning in\ncomputer vision, a growing number of deep neural network architectures were\napplied to chest X-ray image classification. However, most of the previous deep\nneural network classifiers were based on deterministic architectures which are\nusually very noise-sensitive and are likely to aggravate the overfitting issue.\nIn this paper, to make a deep architecture more robust to noise and to reduce\noverfitting, we propose using deep generative classifiers to automatically\ndiagnose thorax diseases from the chest X-ray images. Unlike the traditional\ndeterministic classifier, a deep generative classifier has a distribution\nmiddle layer in the deep neural network. A sampling layer then draws a random\nsample from the distribution layer and input it to the following layer for\nclassification. The classifier is generative because the class label is\ngenerated from samples of a related distribution. Through training the model\nwith a certain amount of randomness, the deep generative classifiers are\nexpected to be robust to noise and can reduce overfitting and then achieve good\nperformances. We implemented our deep generative classifiers based on a number\nof well-known deterministic neural network architectures, and tested our models\non the chest X-ray14 dataset. The results demonstrated the superiority of deep\ngenerative classifiers compared with the corresponding deep deterministic\nclassifiers.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 00:13:50 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 18:41:48 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Mao", "Chengsheng", ""], ["Pan", "Yiheng", ""], ["Zeng", "Zexian", ""], ["Yao", "Liang", ""], ["Luo", "Yuan", ""]]}, {"id": "1809.07454", "submitter": "Yi Luo", "authors": "Yi Luo, Nima Mesgarani", "title": "Conv-TasNet: Surpassing Ideal Time-Frequency Magnitude Masking for\n  Speech Separation", "comments": "Accepted by IEEE/ACM Transactions on Audio, Speech and Language\n  Processing. This version is the authors' version and may vary from the final\n  publication in details", "journal-ref": null, "doi": "10.1109/TASLP.2019.2915167", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Single-channel, speaker-independent speech separation methods have recently\nseen great progress. However, the accuracy, latency, and computational cost of\nsuch methods remain insufficient. The majority of the previous methods have\nformulated the separation problem through the time-frequency representation of\nthe mixed signal, which has several drawbacks, including the decoupling of the\nphase and magnitude of the signal, the suboptimality of time-frequency\nrepresentation for speech separation, and the long latency in calculating the\nspectrograms. To address these shortcomings, we propose a fully-convolutional\ntime-domain audio separation network (Conv-TasNet), a deep learning framework\nfor end-to-end time-domain speech separation. Conv-TasNet uses a linear encoder\nto generate a representation of the speech waveform optimized for separating\nindividual speakers. Speaker separation is achieved by applying a set of\nweighting functions (masks) to the encoder output. The modified encoder\nrepresentations are then inverted back to the waveforms using a linear decoder.\nThe masks are found using a temporal convolutional network (TCN) consisting of\nstacked 1-D dilated convolutional blocks, which allows the network to model the\nlong-term dependencies of the speech signal while maintaining a small model\nsize. The proposed Conv-TasNet system significantly outperforms previous\ntime-frequency masking methods in separating two- and three-speaker mixtures.\nAdditionally, Conv-TasNet surpasses several ideal time-frequency magnitude\nmasks in two-speaker speech separation as evaluated by both objective\ndistortion measures and subjective quality assessment by human listeners.\nFinally, Conv-TasNet has a significantly smaller model size and a shorter\nminimum latency, making it a suitable solution for both offline and real-time\nspeech separation applications.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 02:38:05 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 02:16:14 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 07:40:44 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Luo", "Yi", ""], ["Mesgarani", "Nima", ""]]}, {"id": "1809.07480", "submitter": "Vibhavari Dasagi", "authors": "Vibhavari Dasagi, Robert Lee, Serena Mou, Jake Bruce, Niko\n  S\\\"underhauf and J\\\"urgen Leitner", "title": "Sim-to-Real Transfer of Robot Learning with Variable Length Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current end-to-end deep Reinforcement Learning (RL) approaches require\njointly learning perception, decision-making and low-level control from very\nsparse reward signals and high-dimensional inputs, with little capability of\nincorporating prior knowledge. This results in prohibitively long training\ntimes for use on real-world robotic tasks. Existing algorithms capable of\nextracting task-level representations from high-dimensional inputs, e.g. object\ndetection, often produce outputs of varying lengths, restricting their use in\nRL methods due to the need for neural networks to have fixed length inputs. In\nthis work, we propose a framework that combines deep sets encoding, which\nallows for variable-length abstract representations, with modular RL that\nutilizes these representations, decoupling high-level decision making from\nlow-level control. We successfully demonstrate our approach on the robot\nmanipulation task of object sorting, showing that this method can learn\neffective policies within mere minutes of highly simplified simulation. The\nlearned policies can be directly deployed on a robot without further training,\nand generalize to variations of the task unseen during training.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 05:09:00 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 00:21:04 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Dasagi", "Vibhavari", ""], ["Lee", "Robert", ""], ["Mou", "Serena", ""], ["Bruce", "Jake", ""], ["S\u00fcnderhauf", "Niko", ""], ["Leitner", "J\u00fcrgen", ""]]}, {"id": "1809.07491", "submitter": "Changhao Chen", "authors": "Changhao Chen, Peijun Zhao, Chris Xiaoxuan Lu, Wei Wang, Andrew\n  Markham, Niki Trigoni", "title": "OxIOD: The Dataset for Deep Inertial Odometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in micro-electro-mechanical (MEMS) techniques enable inertial\nmeasurements units (IMUs) to be small, cheap, energy efficient, and widely used\nin smartphones, robots, and drones. Exploiting inertial data for accurate and\nreliable navigation and localization has attracted significant research and\nindustrial interest, as IMU measurements are completely ego-centric and\ngenerally environment agnostic. Recent studies have shown that the notorious\nissue of drift can be significantly alleviated by using deep neural networks\n(DNNs), e.g. IONet. However, the lack of sufficient labelled data for training\nand testing various architectures limits the proliferation of adopting DNNs in\nIMU-based tasks. In this paper, we propose and release the Oxford Inertial\nOdometry Dataset (OxIOD), a first-of-its-kind data collection for\ninertial-odometry research, with all sequences having ground-truth labels. Our\ndataset contains 158 sequences totalling more than 42 km in total distance,\nmuch larger than previous inertial datasets. Another notable feature of this\ndataset lies in its diversity, which can reflect the complex motions of\nphone-based IMUs in various everyday usage. The measurements were collected\nwith four different attachments (handheld, in the pocket, in the handbag and on\nthe trolley), four motion modes (halting, walking slowly, walking normally, and\nrunning), five different users, four types of off-the-shelf consumer phones,\nand large-scale localization from office buildings. Deep inertial tracking\nexperiments were conducted to show the effectiveness of our dataset in training\ndeep neural network models and evaluate learning-based and model-based\nalgorithms. The OxIOD Dataset is available at: http://deepio.cs.ox.ac.uk\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 06:48:37 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Chen", "Changhao", ""], ["Zhao", "Peijun", ""], ["Lu", "Chris Xiaoxuan", ""], ["Wang", "Wei", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1809.07499", "submitter": "Joseph K J", "authors": "K J Joseph and Vineeth N Balasubramanian", "title": "MASON: A Model AgnoStic ObjectNess Framework", "comments": "Accepted at AutoNUE Workshop, 15th European Conference on Computer\n  Vision (ECCV), September 2018, Munich, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a simple, yet very effective method to localize dominant\nforeground objects in an image, to pixel-level precision. The proposed method\n'MASON' (Model-AgnoStic ObjectNess) uses a deep convolutional network to\ngenerate category-independent and model-agnostic heat maps for any image. The\nnetwork is not explicitly trained for the task, and hence, can be used\noff-the-shelf in tandem with any other network or task. We show that this\nframework scales to a wide variety of images, and illustrate the effectiveness\nof MASON in three varied application contexts.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 07:08:38 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Joseph", "K J", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1809.07500", "submitter": "Simon Duque Anton", "authors": "Simon Duque Anton, Lia Ahrens, Daniel Fraunholz, Hans Dieter Schotten", "title": "Time is of the Essence: Machine Learning-based Intrusion Detection in\n  Industrial Time Series Data", "comments": "Extended version of a publication in the 2018 IEEE International\n  Conference on Data Mining Workshops (ICDMW)", "journal-ref": null, "doi": "10.1109/ICDMW.2018.00008", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Industrial Internet of Things drastically increases connectivity of\ndevices in industrial applications. In addition to the benefits in efficiency,\nscalability and ease of use, this creates novel attack surfaces. Historically,\nindustrial networks and protocols do not contain means of security, such as\nauthentication and encryption, that are made necessary by this development.\nThus, industrial IT-security is needed. In this work, emulated industrial\nnetwork data is transformed into a time series and analysed with three\ndifferent algorithms. The data contains labeled attacks, so the performance can\nbe evaluated. Matrix Profiles perform well with almost no parameterisation\nneeded. Seasonal Autoregressive Integrated Moving Average performs well in the\npresence of noise, requiring parameterisation effort. Long Short Term\nMemory-based neural networks perform mediocre while requiring a high training-\nand parameterisation effort.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 07:15:43 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Anton", "Simon Duque", ""], ["Ahrens", "Lia", ""], ["Fraunholz", "Daniel", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1809.07575", "submitter": "Gino Brunner", "authors": "Gino Brunner, Yuyi Wang, Roger Wattenhofer and Sumu Zhao", "title": "Symbolic Music Genre Transfer with CycleGAN", "comments": "Paper accepted at the 30th International Conference on Tools with\n  Artificial Intelligence, ICTAI 2018, Volos, Greece", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models such as Variational Autoencoders (VAEs) and Generative\nAdversarial Networks (GANs) have recently been applied to style and domain\ntransfer for images, and in the case of VAEs, music. GAN-based models employing\nseveral generators and some form of cycle consistency loss have been among the\nmost successful for image domain transfer. In this paper we apply such a model\nto symbolic music and show the feasibility of our approach for music genre\ntransfer. Evaluations using separate genre classifiers show that the style\ntransfer works well. In order to improve the fidelity of the transformed music,\nwe add additional discriminators that cause the generators to keep the\nstructure of the original music mostly intact, while still achieving strong\ngenre transfer. Visual and audible results further show the potential of our\napproach. To the best of our knowledge, this paper represents the first\napplication of GANs to symbolic music domain transfer.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 11:20:11 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Brunner", "Gino", ""], ["Wang", "Yuyi", ""], ["Wattenhofer", "Roger", ""], ["Zhao", "Sumu", ""]]}, {"id": "1809.07599", "submitter": "Jean-Baptiste Cordonnier", "authors": "Sebastian U. Stich, Jean-Baptiste Cordonnier and Martin Jaggi", "title": "Sparsified SGD with Memory", "comments": "to appear at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Huge scale machine learning problems are nowadays tackled by distributed\noptimization algorithms, i.e. algorithms that leverage the compute power of\nmany devices for training. The communication overhead is a key bottleneck that\nhinders perfect scalability. Various recent works proposed to use quantization\nor sparsification techniques to reduce the amount of data that needs to be\ncommunicated, for instance by only sending the most significant entries of the\nstochastic gradient (top-k sparsification). Whilst such schemes showed very\npromising performance in practice, they have eluded theoretical analysis so\nfar.\n  In this work we analyze Stochastic Gradient Descent (SGD) with\nk-sparsification or compression (for instance top-k or random-k) and show that\nthis scheme converges at the same rate as vanilla SGD when equipped with error\ncompensation (keeping track of accumulated errors in memory). That is,\ncommunication can be reduced by a factor of the dimension of the problem\n(sometimes even more) whilst still converging at the same rate. We present\nnumerical experiments to illustrate the theoretical findings and the better\nscalability for distributed applications.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 13:02:14 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 21:13:10 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Stich", "Sebastian U.", ""], ["Cordonnier", "Jean-Baptiste", ""], ["Jaggi", "Martin", ""]]}, {"id": "1809.07600", "submitter": "Gino Brunner", "authors": "Gino Brunner, Andres Konrad, Yuyi Wang, Roger Wattenhofer", "title": "MIDI-VAE: Modeling Dynamics and Instrumentation of Music with\n  Applications to Style Transfer", "comments": "Paper accepted at the 19th International Society for Music\n  Information Retrieval Conference, ISMIR 2018, Paris, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MIDI-VAE, a neural network model based on Variational\nAutoencoders that is capable of handling polyphonic music with multiple\ninstrument tracks, as well as modeling the dynamics of music by incorporating\nnote durations and velocities. We show that MIDI-VAE can perform style transfer\non symbolic music by automatically changing pitches, dynamics and instruments\nof a music piece from, e.g., a Classical to a Jazz style. We evaluate the\nefficacy of the style transfer by training separate style validation\nclassifiers. Our model can also interpolate between short pieces of music,\nproduce medleys and create mixtures of entire songs. The interpolations\nsmoothly change pitches, dynamics and instrumentation to create a harmonic\nbridge between two music pieces. To the best of our knowledge, this work\nrepresents the first successful attempt at applying neural style transfer to\ncomplete musical compositions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 13:02:30 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Brunner", "Gino", ""], ["Konrad", "Andres", ""], ["Wang", "Yuyi", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1809.07609", "submitter": "Xavier Warin", "authors": "Quentin Chan-Wai-Nam, Joseph Mikael, Xavier Warin", "title": "Machine Learning for semi linear PDEs", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent machine learning algorithms dedicated to solving semi-linear PDEs are\nimproved by using different neural network architectures and different\nparameterizations. These algorithms are compared to a new one that solves a\nfixed point problem by using deep learning techniques. This new algorithm\nappears to be competitive in terms of accuracy with the best existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 13:26:09 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 12:39:29 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Chan-Wai-Nam", "Quentin", ""], ["Mikael", "Joseph", ""], ["Warin", "Xavier", ""]]}, {"id": "1809.07688", "submitter": "Peiyuan Sun", "authors": "Peiyuan Suny, Jianxin Li, Yongyi Mao, Richong Zhang, Lihong Wang", "title": "Inferring Multiplex Diffusion Network via Multivariate Marked Hawkes\n  Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the diffusion in social network is an important task. However,\nthis task is challenging since (1) the network structure is usually hidden with\nonly observations of events like \"post\" or \"repost\" associated with each node,\nand (2) the interactions between nodes encompass multiple distinct patterns\nwhich in turn affect the diffusion patterns. For instance, social interactions\nseldom develop on a single channel, and multiple relationships can bind pairs\nof people due to their various common interests. Most previous work considers\nonly one of these two challenges which is apparently unrealistic. In this\npaper, we study the problem of \\emph{inferring multiplex network} in social\nnetworks. We propose the Multiplex Diffusion Model (MDM) which incorporates the\nmultivariate marked Hawkes process and topic model to infer the multiplex\nstructure of social network. A MCMC based algorithm is developed to infer the\nlatent multiplex structure and to estimate the node-related parameters. We\nevaluate our model based on both synthetic and real-world datasets. The results\nshow that our model is more effective in terms of uncovering the multiplex\nnetwork structure.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 02:56:39 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Suny", "Peiyuan", ""], ["Li", "Jianxin", ""], ["Mao", "Yongyi", ""], ["Zhang", "Richong", ""], ["Wang", "Lihong", ""]]}, {"id": "1809.07691", "submitter": "Yunpeng Zhao", "authors": "Yunpeng Zhao", "title": "A Survey on Theoretical Advances of Community Detection in Networks", "comments": "Wire Computational Statistics, 2017", "journal-ref": null, "doi": "10.1002/wics.1403", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world networks usually have community structure, that is, nodes are\ngrouped into densely connected communities. Community detection is one of the\nmost popular and best-studied research topics in network science and has\nattracted attention in many different fields, including computer science,\nstatistics, social sciences, among others. Numerous approaches for community\ndetection have been proposed in literature, from ad-hoc algorithms to\nsystematic model-based approaches. The large number of available methods leads\nto a fundamental question: whether a certain method can provide consistent\nestimates of community labels. The stochastic blockmodel (SBM) and its variants\nprovide a convenient framework for the study of such problems. This article is\na survey on the recent theoretical advances of community detection. The authors\nreview a number of community detection methods and their theoretical\nproperties, including graph cut methods, profile likelihoods, the\npseudo-likelihood method, the variational method, belief propagation, spectral\nclustering, and semidefinite relaxations of the SBM. The authors also briefly\ndiscuss other research topics in community detection such as robust community\ndetection, community detection with nodal covariates and model selection, as\nwell as suggest a few possible directions for future research.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 03:52:19 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Zhao", "Yunpeng", ""]]}, {"id": "1809.07695", "submitter": "Pedro Henrique da Costa Avelar", "authors": "Pedro H. C. Avelar and Henrique Lemos and Marcelo O. R. Prates and\n  Luis Lamb", "title": "Multitask Learning on Graph Neural Networks: Learning Multiple Graph\n  Centrality Measures with a Unified Network", "comments": "Published at ICANN2019. 10 pages, 3 Figures", "journal-ref": null, "doi": "10.1007/978-3-030-30493-5_63", "report-no": null, "categories": "cs.SI cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning to symbolic domains remains an active\nresearch endeavour. Graph neural networks (GNN), consisting of trained neural\nmodules which can be arranged in different topologies at run time, are sound\nalternatives to tackle relational problems which lend themselves to graph\nrepresentations. In this paper, we show that GNNs are capable of multitask\nlearning, which can be naturally enforced by training the model to refine a\nsingle set of multidimensional embeddings $\\in \\mathbb{R}^d$ and decode them\ninto multiple outputs by connecting MLPs at the end of the pipeline. We\ndemonstrate the multitask learning capability of the model in the relevant\nrelational problem of estimating network centrality measures, focusing\nprimarily on producing rankings based on these measures, i.e. is vertex $v_1$\nmore central than vertex $v_2$ given centrality $c$?. We then show that a GNN\ncan be trained to develop a \\emph{lingua franca} of vertex embeddings from\nwhich all relevant information about any of the trained centrality measures can\nbe decoded. The proposed model achieves $89\\%$ accuracy on a test dataset of\nrandom instances with up to 128 vertices and is shown to generalise to larger\nproblem sizes. The model is also shown to obtain reasonable accuracy on a\ndataset of real world instances with up to 4k vertices, vastly surpassing the\nsizes of the largest instances with which the model was trained ($n=128$).\nFinally, we believe that our contributions attest to the potential of GNNs in\nsymbolic domains in general and in relational learning in particular.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 12:01:37 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 13:04:48 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 17:56:26 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 18:39:30 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Avelar", "Pedro H. C.", ""], ["Lemos", "Henrique", ""], ["Prates", "Marcelo O. R.", ""], ["Lamb", "Luis", ""]]}, {"id": "1809.07697", "submitter": "Ryan Rossi", "authors": "John Boaz Lee, Ryan A. Rossi, Xiangnan Kong, Sungchul Kim, Eunyee Koh,\n  and Anup Rao", "title": "Higher-order Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the success of deep convolutional networks in various vision and\nspeech related tasks, researchers have started investigating generalizations of\nthe well-known technique for graph-structured data. A recently-proposed method\ncalled Graph Convolutional Networks has been able to achieve state-of-the-art\nresults in the task of node classification. However, since the proposed method\nrelies on localized first-order approximations of spectral graph convolutions,\nit is unable to capture higher-order interactions between nodes in the graph.\nIn this work, we propose a motif-based graph attention model, called Motif\nConvolutional Networks (MCNs), which generalizes past approaches by using\nweighted multi-hop motif adjacency matrices to capture higher-order\nneighborhoods. A novel attention mechanism is used to allow each individual\nnode to select the most relevant neighborhood to apply its filter. Experiments\nshow that our proposed method is able to achieve state-of-the-art results on\nthe semi-supervised node classification task.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 02:08:29 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Lee", "John Boaz", ""], ["Rossi", "Ryan A.", ""], ["Kong", "Xiangnan", ""], ["Kim", "Sungchul", ""], ["Koh", "Eunyee", ""], ["Rao", "Anup", ""]]}, {"id": "1809.07703", "submitter": "Dan Shiebler", "authors": "Dan Shiebler, Luca Belli, Jay Baxter, Hanchen Xiong, Abhishek Tayal", "title": "Fighting Redundancy and Model Decay with Embeddings", "comments": "Presented at the Common Model Infrastructure Workshop at KDD 2018\n  (link: https://cmi2018.sdsc.edu/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every day, hundreds of millions of new Tweets containing over 40 languages of\never-shifting vernacular flow through Twitter. Models that attempt to extract\ninsight from this firehose of information must face the torrential covariate\nshift that is endemic to the Twitter platform. While regularly-retrained\nalgorithms can maintain performance in the face of this shift, fixed model\nfeatures that fail to represent new trends and tokens can quickly become stale,\nresulting in performance degradation. To mitigate this problem we employ\nlearned features, or embedding models, that can efficiently represent the most\nrelevant aspects of a data distribution. Sharing these embedding models across\nteams can also reduce redundancy and multiplicatively increase cross-team\nmodeling productivity. In this paper, we detail the commoditized tools,\nalgorithms and pipelines that we have developed and are developing at Twitter\nto regularly generate high quality, up-to-date embeddings and share them\nbroadly across the company.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 15:58:13 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Shiebler", "Dan", ""], ["Belli", "Luca", ""], ["Baxter", "Jay", ""], ["Xiong", "Hanchen", ""], ["Tayal", "Abhishek", ""]]}, {"id": "1809.07706", "submitter": "Zheng-Hao Liu", "authors": "Mu Yang, Zheng-Hao Liu, Ze-Di Cheng, Jin-Shi Xu, Chuan-Feng Li and\n  Guang-Can Guo", "title": "Deep Hybrid Scattering Image Learning", "comments": "8 pages, 6 figures", "journal-ref": "J. Phys. D: Appl. Phys. 52 115105 (2019)", "doi": "10.1088/1361-6463/aafa3c", "report-no": null, "categories": "eess.IV cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-trained deep neural network is shown to gain capability of\nsimultaneously restoring two kinds of images, which are completely destroyed by\ntwo distinct scattering medias respectively. The network, based on the U-net\narchitecture, can be trained by blended dataset of speckles-reference images\npairs. We experimentally demonstrate the power of the network in reconstructing\nimages which are strongly diffused by glass diffuser or multi-mode fiber. The\nlearning model further shows good generalization ability to reconstruct images\nthat are distinguished from the training dataset. Our work facilitates the\nstudy of optical transmission and expands machine learning's application in\noptics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 12:28:40 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Yang", "Mu", ""], ["Liu", "Zheng-Hao", ""], ["Cheng", "Ze-Di", ""], ["Xu", "Jin-Shi", ""], ["Li", "Chuan-Feng", ""], ["Guo", "Guang-Can", ""]]}, {"id": "1809.07731", "submitter": "A. Rupam Mahmood", "authors": "A. Rupam Mahmood, Dmytro Korenkevych, Gautham Vasan, William Ma, James\n  Bergstra", "title": "Benchmarking Reinforcement Learning Algorithms on Real-World Robots", "comments": "Appears in Proceedings of the Second Conference on Robot Learning\n  (CoRL 2018). Companion video at https://youtu.be/ovDfhvjpQd8 and source code\n  at https://github.com/kindredresearch/SenseAct", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through many recent successes in simulation, model-free reinforcement\nlearning has emerged as a promising approach to solving continuous control\nrobotic tasks. The research community is now able to reproduce, analyze and\nbuild quickly on these results due to open source implementations of learning\nalgorithms and simulated benchmark tasks. To carry forward these successes to\nreal-world applications, it is crucial to withhold utilizing the unique\nadvantages of simulations that do not transfer to the real world and experiment\ndirectly with physical robots. However, reinforcement learning research with\nphysical robots faces substantial resistance due to the lack of benchmark tasks\nand supporting source code. In this work, we introduce several reinforcement\nlearning tasks with multiple commercially available robots that present varying\nlevels of learning difficulty, setup, and repeatability. On these tasks, we\ntest the learning performance of off-the-shelf implementations of four\nreinforcement learning algorithms and analyze sensitivity to their\nhyper-parameters to determine their readiness for applications in various\nreal-world tasks. Our results show that with a careful setup of the task\ninterface and computations, some of these implementations can be readily\napplicable to physical robots. We find that state-of-the-art learning\nalgorithms are highly sensitive to their hyper-parameters and their relative\nordering does not transfer across tasks, indicating the necessity of re-tuning\nthem for each task for best performance. On the other hand, the best\nhyper-parameter configuration from one task may often result in effective\nlearning on held-out tasks even with different robots, providing a reasonable\ndefault. We make the benchmark tasks publicly available to enhance\nreproducibility in real-world reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 16:46:04 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Mahmood", "A. Rupam", ""], ["Korenkevych", "Dmytro", ""], ["Vasan", "Gautham", ""], ["Ma", "William", ""], ["Bergstra", "James", ""]]}, {"id": "1809.07748", "submitter": "Shing Chan", "authors": "Shing Chan and Ahmed H. Elsheikh", "title": "Exemplar-based synthesis of geology using kernel discrepancies and\n  generative neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for synthesis of geological images based on an\nexemplar image. We synthesize new realizations such that the discrepancy in the\npatch distribution between the realizations and the exemplar image is\nminimized. Such discrepancy is quantified using a kernel method for two-sample\ntest called maximum mean discrepancy. To enable fast synthesis, we train a\ngenerative neural network in an offline phase to sample realizations\nefficiently during deployment, while also providing a parametrization of the\nsynthesis process. We assess the framework on a classical binary image\nrepresenting channelized subsurface reservoirs, finding that the method\nreproduces the visual patterns and spatial statistics (image histogram and\ntwo-point probability functions) of the exemplar image.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 17:33:20 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 09:31:45 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Chan", "Shing", ""], ["Elsheikh", "Ahmed H.", ""]]}, {"id": "1809.07751", "submitter": "Brian Lucena", "authors": "Brian Lucena", "title": "Spline-Based Probability Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many classification problems it is desirable to output well-calibrated\nprobabilities on the different classes. We propose a robust, non-parametric\nmethod of calibrating probabilities called SplineCalib that utilizes smoothing\nsplines to determine a calibration function. We demonstrate how applying\ncertain transformations as part of the calibration process can improve\nperformance on problems in deep learning and other domains where the scores\ntend to be \"overconfident\". We adapt the approach to multi-class problems and\nfind that better calibration can improve accuracy as well as log-loss by better\nresolving uncertain cases. Finally, we present a cross-validated approach to\ncalibration which conserves data. Significant improvements to log-loss and\naccuracy are shown on several different problems. We also introduce the\nml-insights python package which contains an implementation of the SplineCalib\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 17:36:24 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Lucena", "Brian", ""]]}, {"id": "1809.07763", "submitter": "Alicja Gosiewska", "authors": "Alicja Gosiewska, Przemyslaw Biecek", "title": "auditor: an R Package for Model-Agnostic Visual Validation and\n  Diagnostics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have spread to almost every area of life. They are\nsuccessfully applied in biology, medicine, finance, physics, and other fields.\nWith modern software it is easy to train even a~complex model that fits the\ntraining data and results in high accuracy on the test set. The problem arises\nwhen models fail confronted with real-world data.\n  This paper describes methodology and tools for model-agnostic audit.\nIntroduced techniques facilitate assessing and comparing the goodness of fit\nand performance of models. In~addition, they may be used for the analysis of\nthe similarity of residuals and for identification of~outliers and influential\nobservations. The examination is carried out by diagnostic scores and visual\nverification.\n  Presented methods were implemented in the auditor package for R. Due to\nflexible and~consistent grammar, it is simple to validate models of any\nclasses.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 19:14:46 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 06:28:36 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 18:01:43 GMT"}, {"version": "v4", "created": "Tue, 26 May 2020 15:15:19 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Gosiewska", "Alicja", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "1809.07802", "submitter": "Mateusz Malinowski", "authors": "Julien Perolat and Mateusz Malinowski and Bilal Piot and Olivier\n  Pietquin", "title": "Playing the Game of Universal Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning classifiers robust to universal adversarial\nperturbations. While prior work approaches this problem via robust\noptimization, adversarial training, or input transformation, we instead phrase\nit as a two-player zero-sum game. In this new formulation, both players\nsimultaneously play the same game, where one player chooses a classifier that\nminimizes a classification loss whilst the other player creates an adversarial\nperturbation that increases the same loss when applied to every sample in the\ntraining set. By observing that performing a classification (respectively\ncreating adversarial samples) is the best response to the other player, we\npropose a novel extension of a game-theoretic algorithm, namely fictitious\nplay, to the domain of training robust classifiers. Finally, we empirically\nshow the robustness and versatility of our approach in two defence scenarios\nwhere universal attacks are performed on several image classification datasets\n-- CIFAR10, CIFAR100 and ImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 18:48:36 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 20:16:45 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Perolat", "Julien", ""], ["Malinowski", "Mateusz", ""], ["Piot", "Bilal", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1809.07803", "submitter": "Axel Abels", "authors": "Axel Abels, Diederik M. Roijers, Tom Lenaerts, Ann Now\\'e, Denis\n  Steckelmacher", "title": "Dynamic Weights in Multi-Objective Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world decision problems are characterized by multiple conflicting\nobjectives which must be balanced based on their relative importance. In the\ndynamic weights setting the relative importance changes over time and\nspecialized algorithms that deal with such change, such as a tabular\nReinforcement Learning (RL) algorithm by Natarajan and Tadepalli (2005), are\nrequired. However, this earlier work is not feasible for RL settings that\nnecessitate the use of function approximators. We generalize across weight\nchanges and high-dimensional inputs by proposing a multi-objective Q-network\nwhose outputs are conditioned on the relative importance of objectives and we\nintroduce Diverse Experience Replay (DER) to counter the inherent\nnon-stationarity of the Dynamic Weights setting. We perform an extensive\nexperimental evaluation and compare our methods to adapted algorithms from Deep\nMulti-Task/Multi-Objective Reinforcement Learning and show that our proposed\nnetwork in combination with DER dominates these adapted algorithms across\nweight change scenarios and problem domains.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 18:52:15 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 14:51:55 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Abels", "Axel", ""], ["Roijers", "Diederik M.", ""], ["Lenaerts", "Tom", ""], ["Now\u00e9", "Ann", ""], ["Steckelmacher", "Denis", ""]]}, {"id": "1809.07806", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Deepta Rajan and Prasanna Sattigeri", "title": "Understanding Behavior of Clinical Models under Domain Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hypothesis that computational models can be reliable enough to be adopted\nin prognosis and patient care is revolutionizing healthcare. Deep learning, in\nparticular, has been a game changer in building predictive models, thus leading\nto community-wide data curation efforts. However, due to inherent variabilities\nin population characteristics and biological systems, these models are often\nbiased to the training datasets. This can be limiting when models are deployed\nin new environments, when there are systematic domain shifts not known a\npriori. In this paper, we propose to emulate a large class of domain shifts,\nthat can occur in clinical settings, with a given dataset, and argue that\nevaluating the behavior of predictive models in light of those shifts is an\neffective way to quantify their reliability. More specifically, we develop an\napproach for building realistic scenarios, based on analysis of \\textit{disease\nlandscapes} in multi-label classification. Using the openly available MIMIC-III\nEHR dataset for phenotyping, for the first time, our work sheds light into data\nregimes where deep clinical models can fail to generalize. This work emphasizes\nthe need for novel validation mechanisms driven by real-world domain shifts in\nAI for healthcare.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 19:03:14 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 01:39:12 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Rajan", "Deepta", ""], ["Sattigeri", "Prasanna", ""]]}, {"id": "1809.07823", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Alessandro Abate, Daniel Kroening", "title": "Logically-Constrained Neural Fitted Q-Iteration", "comments": "AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for efficient training of Q-functions for\ncontinuous-state Markov Decision Processes (MDPs) such that the traces of the\nresulting policies satisfy a given Linear Temporal Logic (LTL) property. LTL, a\nmodal logic, can express a wide range of time-dependent logical properties\n(including \"safety\") that are quite similar to patterns in natural language. We\nconvert the LTL property into a limit deterministic Buchi automaton and\nconstruct an on-the-fly synchronised product MDP. The control policy is then\nsynthesised by defining an adaptive reward function and by applying a modified\nneural fitted Q-iteration algorithm to the synchronised structure, assuming\nthat no prior knowledge is available from the original MDP. The proposed method\nis evaluated in a numerical study to test the quality of the generated control\npolicy and is compared with conventional methods for policy synthesis such as\nMDP abstraction (Voronoi quantizer) and approximate dynamic programming (fitted\nvalue iteration).\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 19:52:06 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 19:39:49 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 12:04:34 GMT"}, {"version": "v4", "created": "Thu, 14 Mar 2019 11:17:57 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""]]}, {"id": "1809.07824", "submitter": "Yair Lakretz", "authors": "Yair Lakretz, Gal Chechik, Evan-Gary Cohen, Alessandro Treves, Naama\n  Friedmann", "title": "Metric Learning for Phoneme Perception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric functions for phoneme perception capture the similarity structure\namong phonemes in a given language and therefore play a central role in\nphonology and psycho-linguistics. Various phenomena depend on phoneme\nsimilarity, such as spoken word recognition or serial recall from verbal\nworking memory. This study presents a new framework for learning a metric\nfunction for perceptual distances among pairs of phonemes. Previous studies\nhave proposed various metric functions, from simple measures counting the\nnumber of phonetic dimensions that two phonemes share (place-,\nmanner-of-articulation and voicing), to more sophisticated ones such as\nderiving perceptual distances based on the number of natural classes that both\nphonemes belong to. However, previous studies have manually constructed the\nmetric function, which may lead to unsatisfactory account of the empirical\ndata. This study presents a framework to derive the metric function from\nbehavioral data on phoneme perception using learning algorithms. We first show\nthat this approach outperforms previous metrics suggested in the literature in\npredicting perceptual distances among phoneme pairs. We then study several\nmetric functions derived by the learning algorithms and show how perceptual\nsaliencies of phonological features can be derived from them. For English, we\nshow that the derived perceptual saliencies are in accordance with a previously\ndescribed order among phonological features and show how the framework extends\nthe results to more features. Finally, we explore how the metric function and\nperceptual saliencies of phonological features may vary across languages. To\nthis end, we compare results based on two English datasets and a new dataset\nthat we have collected for Hebrew.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 19:53:33 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Lakretz", "Yair", ""], ["Chechik", "Gal", ""], ["Cohen", "Evan-Gary", ""], ["Treves", "Alessandro", ""], ["Friedmann", "Naama", ""]]}, {"id": "1809.07828", "submitter": "Qinghan Xue", "authors": "Qinghan Xue, Xiaoran Wang, Samuel Meehan, Jilong Kuang, Alex Gao, Mooi\n  Choo Chuah", "title": "Recurrent Neural Networks based Obesity Status Prediction Using Activity\n  Data", "comments": "8 pages, 6 figures, ICMLA 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obesity is a serious public health concern world-wide, which increases the\nrisk of many diseases, including hypertension, stroke, and type 2 diabetes. To\ntackle this problem, researchers across the health ecosystem are collecting\ndiverse types of data, which includes biomedical, behavioral and activity, and\nutilizing machine learning techniques to mine hidden patterns for obesity\nstatus improvement prediction. While existing machine learning methods such as\nRecurrent Neural Networks (RNNs) can provide exceptional results, it is\nchallenging to discover hidden patterns of the sequential data due to the\nirregular observation time instances. Meanwhile, the lack of understanding of\nwhy those learning models are effective also limits further improvements on\ntheir architectures. Thus, in this work, we develop a RNN based time-aware\narchitecture to tackle the challenging problem of handling irregular\nobservation times and relevant feature extractions from longitudinal patient\nrecords for obesity status improvement prediction. To improve the prediction\nperformance, we train our model using two data sources: (i) electronic medical\nrecords containing information regarding lab tests, diagnoses, and\ndemographics; (ii) continuous activity data collected from popular wearables.\nEvaluations of real-world data demonstrate that our proposed method can capture\nthe underlying structures in users' time sequences with irregularities, and\nachieve an accuracy of 77-86% in predicting the obesity status improvement.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 19:55:22 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Xue", "Qinghan", ""], ["Wang", "Xiaoran", ""], ["Meehan", "Samuel", ""], ["Kuang", "Jilong", ""], ["Gao", "Alex", ""], ["Chuah", "Mooi Choo", ""]]}, {"id": "1809.07830", "submitter": "Yize Chen", "authors": "Yize Chen, Hao Wang", "title": "IntelligentCrowd: Mobile Crowdsensing via Multi-Agent Reinforcement\n  Learning", "comments": "Accepted paper at 2020 IEEE Transactions on Emerging Topics in\n  Computational Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prosperity of smart mobile devices has made mobile crowdsensing (MCS) a\npromising paradigm for completing complex sensing and computation tasks. In the\npast, great efforts have been made on the design of incentive mechanisms and\ntask allocation strategies from MCS platform's perspective to motivate mobile\nusers' participation. However, in practice, MCS participants face many\nuncertainties coming from their sensing environment as well as other\nparticipants' strategies, and how do they interact with each other and make\nsensing decisions is not well understood. In this paper, we take MCS\nparticipants' perspective to derive an online sensing policy to maximize their\npayoffs via MCS participation. Specifically, we model the interactions of\nmobile users and sensing environments as a multi-agent Markov decision process.\nEach participant cannot observe others' decisions, but needs to decide her\neffort level in sensing tasks only based on local information, e.g., its own\nrecord of sensed signals' quality. To cope with the stochastic sensing\nenvironment, we develop an intelligent crowdsensing algorithm IntelligentCrowd\nby leveraging the power of multi-agent reinforcement learning (MARL). Our\nalgorithm leads to the optimal sensing policy for each user to maximize the\nexpected payoff against stochastic sensing environments, and can be implemented\nat individual participant's level in a distributed fashion. Numerical\nsimulations demonstrate that IntelligentCrowd significantly improves users'\npayoffs in sequential MCS tasks under various sensing dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 19:56:08 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 19:25:26 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 04:21:42 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Chen", "Yize", ""], ["Wang", "Hao", ""]]}, {"id": "1809.07857", "submitter": "Yiwen Han", "authors": "Xiaofei Wang, Yiwen Han, Chenyang Wang, Qiyang Zhao, Xu Chen, Min Chen", "title": "In-Edge AI: Intelligentizing Mobile Edge Computing, Caching and\n  Communication by Federated Learning", "comments": "This paper has been accepted by IEEE Network for publication", "journal-ref": "IEEE Network, 2019, 33(5): 156-165", "doi": "10.1109/MNET.2019.1800286", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, along with the rapid development of mobile communication\ntechnology, edge computing theory and techniques have been attracting more and\nmore attentions from global researchers and engineers, which can significantly\nbridge the capacity of cloud and requirement of devices by the network edges,\nand thus can accelerate the content deliveries and improve the quality of\nmobile services. In order to bring more intelligence to the edge systems,\ncompared to traditional optimization methodology, and driven by the current\ndeep learning techniques, we propose to integrate the Deep Reinforcement\nLearning techniques and Federated Learning framework with the mobile edge\nsystems, for optimizing the mobile edge computing, caching and communication.\nAnd thus, we design the \"In-Edge AI\" framework in order to intelligently\nutilize the collaboration among devices and edge nodes to exchange the learning\nparameters for a better training and inference of the models, and thus to carry\nout dynamic system-level optimization and application-level enhancement while\nreducing the unnecessary system communication load. \"In-Edge AI\" is evaluated\nand proved to have near-optimal performance but relatively low overhead of\nlearning, while the system is cognitive and adaptive to the mobile\ncommunication systems. Finally, we discuss several related challenges and\nopportunities for unveiling a promising upcoming future of \"In-Edge AI\".\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 05:27:42 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 02:49:13 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Wang", "Xiaofei", ""], ["Han", "Yiwen", ""], ["Wang", "Chenyang", ""], ["Zhao", "Qiyang", ""], ["Chen", "Xu", ""], ["Chen", "Min", ""]]}, {"id": "1809.07861", "submitter": "Avraam Tsantekidis", "authors": "Paraskevi Nousi, Avraam Tsantekidis, Nikolaos Passalis, Adamantios\n  Ntakaris, Juho Kanniainen, Anastasios Tefas, Moncef Gabbouj, Alexandros\n  Iosifidis", "title": "Machine Learning for Forecasting Mid Price Movement using Limit Order\n  Book Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting the movements of stock prices is one the most challenging\nproblems in financial markets analysis. In this paper, we use Machine Learning\n(ML) algorithms for the prediction of future price movements using limit order\nbook data. Two different sets of features are combined and evaluated:\nhandcrafted features based on the raw order book data and features extracted by\nML algorithms, resulting in feature vectors with highly variant\ndimensionalities. Three classifiers are evaluated using combinations of these\nsets of features on two different evaluation setups and three prediction\nscenarios. Even though the large scale and high frequency nature of the limit\norder book poses several challenges, the scope of the conducted experiments and\nthe significance of the experimental results indicate that Machine Learning\nhighly befits this task carving the path towards future research in this field.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 10:05:30 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 11:26:49 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Nousi", "Paraskevi", ""], ["Tsantekidis", "Avraam", ""], ["Passalis", "Nikolaos", ""], ["Ntakaris", "Adamantios", ""], ["Kanniainen", "Juho", ""], ["Tefas", "Anastasios", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1809.07904", "submitter": "Dmitriy Korchev", "authors": "Dmitriy Korchev, Aruna Jammalamadaka, and Rajan Bhattacharyya", "title": "Automatic Rule Learning for Autonomous Driving Using Semantic Memory", "comments": "8 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach for automatic rule learning applicable\nto an autonomous driving system using real driving data.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 01:02:48 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 20:08:42 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Korchev", "Dmitriy", ""], ["Jammalamadaka", "Aruna", ""], ["Bhattacharyya", "Rajan", ""]]}, {"id": "1809.07945", "submitter": "Kamel Alrashedy", "authors": "Kamel Alreshedy, Dhanush Dharmaretnam, Daniel M. German, Venkatesh\n  Srinivasan and T. Aaron Gulliver", "title": "SCC: Automatic Classification of Code Snippets", "comments": null, "journal-ref": "Working Conference on Source Code Analysis & Manipulation 2018", "doi": null, "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the programming language of a source code file has been\nconsidered in the research community; it has been shown that Machine Learning\n(ML) and Natural Language Processing (NLP) algorithms can be effective in\nidentifying the programming language of source code files. However, determining\nthe programming language of a code snippet or a few lines of source code is\nstill a challenging task. Online forums such as Stack Overflow and code\nrepositories such as GitHub contain a large number of code snippets. In this\npaper, we describe Source Code Classification (SCC), a classifier that can\nidentify the programming language of code snippets written in 21 different\nprogramming languages. A Multinomial Naive Bayes (MNB) classifier is employed\nwhich is trained using Stack Overflow posts. It is shown to achieve an accuracy\nof 75% which is higher than that with Programming Languages Identification (PLI\na proprietary online classifier of snippets) whose accuracy is only 55.5%. The\naverage score for precision, recall and the F1 score with the proposed tool are\n0.76, 0.75 and 0.75, respectively. In addition, it can distinguish between code\nsnippets from a family of programming languages such as C, C++ and C#, and can\nalso identify the programming language version such as C# 3.0, C# 4.0 and C#\n5.0.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 04:50:40 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Alreshedy", "Kamel", ""], ["Dharmaretnam", "Dhanush", ""], ["German", "Daniel M.", ""], ["Srinivasan", "Venkatesh", ""], ["Gulliver", "T. Aaron", ""]]}, {"id": "1809.07950", "submitter": "Wonjin Yoon", "authors": "Wonjin Yoon, Chan Ho So, Jinhyuk Lee, Jaewoo Kang", "title": "CollaboNet: collaboration of deep neural networks for biomedical named\n  entity recognition", "comments": "From DTMBio workshop at CIKM 2018, Turin, Italy. 22-26 October 2018", "journal-ref": "BMC Bioinformatics 2019, 20(Suppl 10):249", "doi": "10.1186/s12859-019-2813-6", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Finding biomedical named entities is one of the most essential\ntasks in biomedical text mining. Recently, deep learning-based approaches have\nbeen applied to biomedical named entity recognition (BioNER) and showed\npromising results. However, as deep learning approaches need an abundant amount\nof training data, a lack of data can hinder performance. BioNER datasets are\nscarce resources and each dataset covers only a small subset of entity types.\nFurthermore, many bio entities are polysemous, which is one of the major\nobstacles in named entity recognition. Results: To address the lack of data and\nthe entity type misclassification problem, we propose CollaboNet which utilizes\na combination of multiple NER models. In CollaboNet, models trained on a\ndifferent dataset are connected to each other so that a target model obtains\ninformation from other collaborator models to reduce false positives. Every\nmodel is an expert on their target entity type and takes turns serving as a\ntarget and a collaborator model during training time. The experimental results\nshow that CollaboNet can be used to greatly reduce the number of false\npositives and misclassified entities including polysemous words. CollaboNet\nachieved state-of-the-art performance in terms of precision, recall and F1\nscore. Conclusions: We demonstrated the benefits of combining multiple models\nfor BioNER. Our model has successfully reduced the number of misclassified\nentities and improved the performance by leveraging multiple datasets annotated\nfor different entity types. Given the state-of-the-art performance of our\nmodel, we believe that CollaboNet can improve the accuracy of downstream\nbiomedical text mining applications such as bio-entity relation extraction.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 05:48:54 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 16:34:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Yoon", "Wonjin", ""], ["So", "Chan Ho", ""], ["Lee", "Jinhyuk", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1809.07952", "submitter": "Yusuke Tanaka", "authors": "Yusuke Tanaka, Tomoharu Iwata, Toshiyuki Tanaka, Takeshi Kurashima,\n  Maya Okawa, Hiroyuki Toda", "title": "Refining Coarse-grained Spatial Data using Auxiliary Spatial Data Sets\n  with Various Granularities", "comments": "Appears in Proceedings of the Thirty-Third AAAI Conference on\n  Artificial Intelligence (AAAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic model for refining coarse-grained spatial data by\nutilizing auxiliary spatial data sets. Existing methods require that the\nspatial granularities of the auxiliary data sets are the same as the desired\ngranularity of target data. The proposed model can effectively make use of\nauxiliary data sets with various granularities by hierarchically incorporating\nGaussian processes. With the proposed model, a distribution for each auxiliary\ndata set on the continuous space is modeled using a Gaussian process, where the\nrepresentation of uncertainty considers the levels of granularity. The\nfine-grained target data are modeled by another Gaussian process that considers\nboth the spatial correlation and the auxiliary data sets with their\nuncertainty. We integrate the Gaussian process with a spatial aggregation\nprocess that transforms the fine-grained target data into the coarse-grained\ntarget data, by which we can infer the fine-grained target Gaussian process\nfrom the coarse-grained data. Our model is designed such that the inference of\nmodel parameters based on the exact marginal likelihood is possible, in which\nthe variables of fine-grained target and auxiliary data are analytically\nintegrated out. Our experiments on real-world spatial data sets demonstrate the\neffectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 05:54:18 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 00:11:57 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Tanaka", "Yusuke", ""], ["Iwata", "Tomoharu", ""], ["Tanaka", "Toshiyuki", ""], ["Kurashima", "Takeshi", ""], ["Okawa", "Maya", ""], ["Toda", "Hiroyuki", ""]]}, {"id": "1809.07954", "submitter": "Kamel Alrashedy", "authors": "Kamel Alreshedy, Dhanush Dharmaretnam, Daniel M. German, Venkatesh\n  Srinivasan and T. Aaron Gulliver", "title": "Predicting the Programming Language of Questions and Snippets of\n  StackOverflow Using Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stack Overflow is the most popular Q&A website among software developers. As\na platform for knowledge sharing and acquisition, the questions posted in Stack\nOverflow usually contain a code snippet. Stack Overflow relies on users to\nproperly tag the programming language of a question and it simply assumes that\nthe programming language of the snippets inside a question is the same as the\ntag of the question itself. In this paper, we propose a classifier to predict\nthe programming language of questions posted in Stack Overflow using Natural\nLanguage Processing (NLP) and Machine Learning (ML). The classifier achieves an\naccuracy of 91.1% in predicting the 24 most popular programming languages by\ncombining features from the title, body and the code snippets of the question.\nWe also propose a classifier that only uses the title and body of the question\nand has an accuracy of 81.1%. Finally, we propose a classifier of code snippets\nonly that achieves an accuracy of 77.7%. These results show that deploying\nMachine Learning techniques on the combination of text and the code snippets of\na question provides the best performance. These results demonstrate also that\nit is possible to identify the programming language of a snippet of few lines\nof source code. We visualize the feature space of two programming languages\nJava and SQL in order to identify some special properties of information inside\nthe questions in Stack Overflow corresponding to these languages.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 06:02:25 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Alreshedy", "Kamel", ""], ["Dharmaretnam", "Dhanush", ""], ["German", "Daniel M.", ""], ["Srinivasan", "Venkatesh", ""], ["Gulliver", "T. Aaron", ""]]}, {"id": "1809.08004", "submitter": "Francesco Tudisco", "authors": "Francesca Arrigo and Francesco Tudisco", "title": "Multi-Dimensional, Multilayer, Nonlinear and Dynamic HITS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG math.NA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a ranking model for temporal multi-dimensional weighted and\ndirected networks based on the Perron eigenvector of a multi-homogeneous\norder-preserving map. The model extends to the temporal multilayer setting the\nHITS algorithm and defines five centrality vectors: two for the nodes, two for\nthe layers, and one for the temporal stamps. Nonlinearity is introduced in the\nstandard HITS model in order to guarantee existence and uniqueness of these\ncentrality vectors for any network, without any requirement on its connectivity\nstructure. We introduce a globally convergent power iteration like algorithm\nfor the computation of the centrality vectors. Numerical experiments on\nreal-world networks are performed in order to assess the effectiveness of the\nproposed model and showcase the performance of the accompanying algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 09:27:59 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Arrigo", "Francesca", ""], ["Tudisco", "Francesco", ""]]}, {"id": "1809.08031", "submitter": "Silvia Makowski", "authors": "Silvia Makowski, Lena J\\\"ager, Ahmed Abdelwahab, Niels Landwehr,\n  Tobias Scheffer", "title": "A Discriminative Model for Identifying Readers and Assessing Text\n  Comprehension from Eye Movements", "comments": "Proceedings of the European Conference on Machine Learning, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of inferring readers' identities and estimating their\nlevel of text comprehension from observations of their eye movements during\nreading. We develop a generative model of individual gaze patterns (scanpaths)\nthat makes use of lexical features of the fixated words. Using this generative\nmodel, we derive a Fisher-score representation of eye-movement sequences. We\nstudy whether a Fisher-SVM with this Fisher kernel and several reference\nmethods are able to identify readers and estimate their level of text\ncomprehension based on eye-tracking data. While none of the methods are able to\nestimate text comprehension accurately, we find that the SVM with Fisher kernel\nexcels at identifying readers.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 10:46:21 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Makowski", "Silvia", ""], ["J\u00e4ger", "Lena", ""], ["Abdelwahab", "Ahmed", ""], ["Landwehr", "Niels", ""], ["Scheffer", "Tobias", ""]]}, {"id": "1809.08055", "submitter": "Sushrut Karmalkar", "authors": "Sushrut Karmalkar, Eric Price", "title": "Compressed Sensing with Adversarial Sparse Noise via L1 Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple and effective algorithm for the problem of \\emph{sparse\nrobust linear regression}. In this problem, one would like to estimate a sparse\nvector $w^* \\in \\mathbb{R}^n$ from linear measurements corrupted by sparse\nnoise that can arbitrarily change an adversarially chosen $\\eta$ fraction of\nmeasured responses $y$, as well as introduce bounded norm noise to the\nresponses. For Gaussian measurements, we show that a simple algorithm based on\nL1 regression can successfully estimate $w^*$ for any $\\eta < \\eta_0 \\approx\n0.239$, and that this threshold is tight for the algorithm. The number of\nmeasurements required by the algorithm is $O(k \\log \\frac{n}{k})$ for\n$k$-sparse estimation, which is within constant factors of the number needed\nwithout any sparse noise. Of the three properties we show---the ability to\nestimate sparse, as well as dense, $w^*$; the tolerance of a large constant\nfraction of outliers; and tolerance of adversarial rather than distributional\n(e.g., Gaussian) dense noise---to the best of our knowledge, no previous result\nachieved more than two.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 12:15:49 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 06:34:17 GMT"}, {"version": "v3", "created": "Fri, 9 Nov 2018 17:06:07 GMT"}, {"version": "v4", "created": "Sun, 6 Jan 2019 15:53:46 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Karmalkar", "Sushrut", ""], ["Price", "Eric", ""]]}, {"id": "1809.08067", "submitter": "Mostafa Tavassolipour", "authors": "Mostafa Tavassolipour, Seyed Abolfazl Motahari, and Mohammad-Taghi\n  Manzuri Shalmani", "title": "Learning of Tree-Structured Gaussian Graphical Models on Distributed\n  Data under Communication Constraints", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2876325", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, learning of tree-structured Gaussian graphical models from\ndistributed data is addressed. In our model, samples are stored in a set of\ndistributed machines where each machine has access to only a subset of\nfeatures. A central machine is then responsible for learning the structure\nbased on received messages from the other nodes. We present a set of\ncommunication efficient strategies, which are theoretically proved to convey\nsufficient information for reliable learning of the structure. In particular,\nour analyses show that even if each machine sends only the signs of its local\ndata samples to the central node, the tree structure can still be recovered\nwith high accuracy. Our simulation results on both synthetic and real-world\ndatasets show that our strategies achieve a desired accuracy in inferring the\nunderlying structure, while spending a small budget on communication.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 12:49:27 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Tavassolipour", "Mostafa", ""], ["Motahari", "Seyed Abolfazl", ""], ["Shalmani", "Mohammad-Taghi Manzuri", ""]]}, {"id": "1809.08079", "submitter": "Fei Jiang", "authors": "Fei Jiang and Lei Zheng and Jin Xu and Philip S. Yu", "title": "FI-GRL: Fast Inductive Graph Representation Learning via Projection-Cost\n  Preservation", "comments": "ICDM 2018, Full Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning aims at transforming graph data into meaningful\nlow-dimensional vectors to facilitate the employment of machine learning and\ndata mining algorithms designed for general data. Most current graph\nrepresentation learning approaches are transductive, which means that they\nrequire all the nodes in the graph are known when learning graph\nrepresentations and these approaches cannot naturally generalize to unseen\nnodes. In this paper, we present a Fast Inductive Graph Representation Learning\nframework (FI-GRL) to learn nodes' low-dimensional representations. Our\napproach can obtain accurate representations for seen nodes with provable\ntheoretical guarantees and can easily generalize to unseen nodes. Specifically,\nin order to explicitly decouple nodes' relations expressed by the graph, we\ntransform nodes into a randomized subspace spanned by a random projection\nmatrix. This stage is guaranteed to preserve the projection-cost of the\nnormalized random walk matrix which is highly related to the normalized cut of\nthe graph. Then feature extraction is achieved by conducting singular value\ndecomposition on the obtained matrix sketch. By leveraging the property of\nprojection-cost preservation on the matrix sketch, the obtained representation\nresult is nearly optimal. To deal with unseen nodes, we utilize folding-in\ntechnique to learn their meaningful representations. Empirically, when the\namount of seen nodes are larger than that of unseen nodes, FI-GRL always\nachieves excellent results. Our algorithm is fast, simple to implement and\ntheoretically guaranteed. Extensive experiments on real datasets demonstrate\nthe superiority of our algorithm on both efficacy and efficiency over both\nmacroscopic level (clustering) and microscopic level (structural hole\ndetection) applications.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 14:06:00 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Jiang", "Fei", ""], ["Zheng", "Lei", ""], ["Xu", "Jin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1809.08085", "submitter": "Gonzalo N\\'apoles", "authors": "Gonzalo N\\'apoles, Frank Vanhoenshoven, Koen Vanhoof", "title": "Short-term Cognitive Networks, Flexible Reasoning and Nonsynaptic\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the machine learning literature dedicated to fully automated reasoning\nalgorithms is abundant, the number of methods enabling the inference process on\nthe basis of previously defined knowledge structures is scanter. Fuzzy\nCognitive Maps (FCMs) are neural networks that can be exploited towards this\ngoal because of their flexibility to handle external knowledge. However, FCMs\nsuffer from a number of issues that range from the limited prediction horizon\nto the absence of theoretically sound learning algorithms able to produce\naccurate predictions. In this paper, we propose a neural network system named\nShort-term Cognitive Networks that tackle some of these limitations. In our\nmodel weights are not constricted and may have a causal nature or not. As a\nsecond contribution, we present a nonsynaptic learning algorithm to improve the\nnetwork performance without modifying the previously defined weights. Moreover,\nwe derive a stop condition to prevent the learning algorithm from iterating\nwithout decreasing the simulation error.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:02:30 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["N\u00e1poles", "Gonzalo", ""], ["Vanhoenshoven", "Frank", ""], ["Vanhoof", "Koen", ""]]}, {"id": "1809.08092", "submitter": "Yongli Zhu", "authors": "Yongli Zhu, Songtao Lu, Renchang Dai, Guangyi Liu, Zhiwei Wang", "title": "Power Market Price Forecasting via Deep Learning", "comments": "This manuscript has been accepted by the incoming conference IECON\n  2018 at Washington DC, USA, Oct. 21-23, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A study on power market price forecasting by deep learning is presented. As\none of the most successful deep learning frameworks, the LSTM (Long short-term\nmemory) neural network is utilized. The hourly prices data from the New England\nand PJM day-ahead markets are used in this study. First, a LSTM network is\nformulated and trained. Then the raw input and output data are preprocessed by\nunit scaling, and the trained network is tested on the real price data under\ndifferent input lengths, forecasting horizons and data sizes. Its performance\nis also compared with other existing methods. The forecasted results\ndemonstrate that, the LSTM deep neural network can outperform the others under\ndifferent application settings in this problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 19:00:18 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 13:49:04 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Zhu", "Yongli", ""], ["Lu", "Songtao", ""], ["Dai", "Renchang", ""], ["Liu", "Guangyi", ""], ["Wang", "Zhiwei", ""]]}, {"id": "1809.08097", "submitter": "Amar Prakash Azad", "authors": "Amar Prakash Azad, Dinesh Garg, Priyanka Agrawal, Arun Kumar", "title": "Deep Domain Adaptation under Deep Label Scarcity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal behind Domain Adaptation (DA) is to leverage the labeled examples\nfrom a source domain so as to infer an accurate model in a target domain where\nlabels are not available or in scarce at the best. A state-of-the-art approach\nfor the DA is due to (Ganin et al. 2016), known as DANN, where they attempt to\ninduce a common representation of source and target domains via adversarial\ntraining. This approach requires a large number of labeled examples from the\nsource domain to be able to infer a good model for the target domain. However,\nin many situations obtaining labels in the source domain is expensive which\nresults in deteriorated performance of DANN and limits its applicability in\nsuch scenarios. In this paper, we propose a novel approach to overcome this\nlimitation. In our work, we first establish that DANN reduces the original DA\nproblem into a semi-supervised learning problem over the space of common\nrepresentation. Next, we propose a learning approach, namely TransDANN, that\namalgamates adversarial learning and transductive learning to mitigate the\ndetrimental impact of limited source labels and yields improved performance.\nExperimental results (both on text and images) show a significant boost in the\nperformance of TransDANN over DANN under such scenarios. We also provide\ntheoretical justification for the performance boost.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 12:32:47 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Azad", "Amar Prakash", ""], ["Garg", "Dinesh", ""], ["Agrawal", "Priyanka", ""], ["Kumar", "Arun", ""]]}, {"id": "1809.08098", "submitter": "Shiqi Wang", "authors": "Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, Suman Jana", "title": "Efficient Formal Safety Analysis of Neural Networks", "comments": "Accepted to NIPS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly deployed in real-world safety-critical\ndomains such as autonomous driving, aircraft collision avoidance, and malware\ndetection. However, these networks have been shown to often mispredict on\ninputs with minor adversarial or even accidental perturbations. Consequences of\nsuch errors can be disastrous and even potentially fatal as shown by the recent\nTesla autopilot crash. Thus, there is an urgent need for formal analysis\nsystems that can rigorously check neural networks for violations of different\nsafety properties such as robustness against adversarial perturbations within a\ncertain $L$-norm of a given image. An effective safety analysis system for a\nneural network must be able to either ensure that a safety property is\nsatisfied by the network or find a counterexample, i.e., an input for which the\nnetwork will violate the property. Unfortunately, most existing techniques for\nperforming such analysis struggle to scale beyond very small networks and the\nones that can scale to larger networks suffer from high false positives and\ncannot produce concrete counterexamples in case of a property violation. In\nthis paper, we present a new efficient approach for rigorously checking\ndifferent safety properties of neural networks that significantly outperforms\nexisting approaches by multiple orders of magnitude. Our approach can check\ndifferent safety properties and find concrete counterexamples for networks that\nare 10$\\times$ larger than the ones supported by existing analysis techniques.\nWe believe that our approach to estimating tight output bounds of a network for\na given input range can also help improve the explainability of neural networks\nand guide the training process of more robust neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 20:21:28 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 02:29:30 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 22:30:38 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Wang", "Shiqi", ""], ["Pei", "Kexin", ""], ["Whitehouse", "Justin", ""], ["Yang", "Junfeng", ""], ["Jana", "Suman", ""]]}, {"id": "1809.08106", "submitter": "Chengsheng Mao", "authors": "Chengsheng Mao, Liang Yao, Yuan Luo", "title": "Distribution Networks for Open Set Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In open set learning, a model must be able to generalize to novel classes\nwhen it encounters a sample that does not belong to any of the classes it has\nseen before. Open set learning poses a realistic learning scenario that is\nreceiving growing attention. Existing studies on open set learning mainly\nfocused on detecting novel classes, but few studies tried to model them for\ndifferentiating novel classes. In this paper, we recognize that novel classes\nshould be different from each other, and propose distribution networks for open\nset learning that can model different novel classes based on probability\ndistributions. We hypothesize that, through a certain mapping, samples from\ndifferent classes with the same classification criterion should follow\ndifferent probability distributions from the same distribution family. A deep\nneural network is learned to map the samples in the original feature space to a\nlatent space where the distributions of known classes can be jointly learned\nwith the network. We additionally propose a distribution parameter transfer and\nupdating strategy for novel class modeling when a novel class is detected in\nthe latent space. By novel class modeling, the detected novel classes can serve\nas known classes to the subsequent classification. Our experimental results on\nimage datasets MNIST and CIFAR10 show that the distribution networks can detect\nnovel classes accurately, and model them well for the subsequent classification\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 00:06:56 GMT"}, {"version": "v2", "created": "Sat, 24 Nov 2018 01:13:44 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Mao", "Chengsheng", ""], ["Yao", "Liang", ""], ["Luo", "Yuan", ""]]}, {"id": "1809.08113", "submitter": "Yong Zhang", "authors": "Yong Zhang, Yu Zhang, Zhao Zhang, Jie Bao, Yunpeng Song", "title": "Human activity recognition based on time series analysis using U-Net", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional human activity recognition (HAR) based on time series adopts\nsliding window analysis method. This method faces the multi-class window\nproblem which mistakenly labels different classes of sampling points within a\nwindow as a class. In this paper, a HAR algorithm based on U-Net is proposed to\nperform activity labeling and prediction at each sampling point. The activity\ndata of the triaxial accelerometer is mapped into an image with the single\npixel column and multi-channel which is input into the U-Net network for\ntraining and recognition. Our proposal can complete the pixel-level gesture\nrecognition function. The method does not need manual feature extraction and\ncan effectively identify short-term behaviors in long-term activity sequences.\nWe collected the Sanitation dataset and tested the proposed scheme with four\nopen data sets. The experimental results show that compared with Support Vector\nMachine (SVM), k-Nearest Neighbor (kNN), Decision Tree(DT), Quadratic\nDiscriminant Analysis (QDA), Convolutional Neural Network (CNN) and Fully\nConvolutional Networks (FCN) methods, our proposal has the highest accuracy and\nF1-socre in each dataset, and has stable performance and high robustness. At\nthe same time, after the U-Net has finished training, our proposal can achieve\nfast enough recognition speed.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 07:16:33 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Zhang", "Yong", ""], ["Zhang", "Yu", ""], ["Zhang", "Zhao", ""], ["Bao", "Jie", ""], ["Song", "Yunpeng", ""]]}, {"id": "1809.08151", "submitter": "Etienne Boursier", "authors": "Etienne Boursier and Vianney Perchet", "title": "SIC-MMAB: Synchronisation Involves Communication in Multiplayer\n  Multi-Armed Bandits", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by cognitive radio networks, we consider the stochastic multiplayer\nmulti-armed bandit problem, where several players pull arms simultaneously and\ncollisions occur if one of them is pulled by several players at the same stage.\nWe present a decentralized algorithm that achieves the same performance as a\ncentralized one, contradicting the existing lower bounds for that problem. This\nis possible by \"hacking\" the standard model by constructing a communication\nprotocol between players that deliberately enforces collisions, allowing them\nto share their information at a negligible cost. This motivates the\nintroduction of a more appropriate dynamic setting without sensing, where\nsimilar communication protocols are no longer possible. However, we show that\nthe logarithmic growth of the regret is still achievable for this model with a\nnew algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 14:43:46 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 10:30:41 GMT"}, {"version": "v3", "created": "Sat, 1 Jun 2019 09:28:36 GMT"}, {"version": "v4", "created": "Tue, 19 Nov 2019 09:51:23 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Boursier", "Etienne", ""], ["Perchet", "Vianney", ""]]}, {"id": "1809.08159", "submitter": "Keiichi Kisamori", "authors": "Keiichi Kisamori, Motonobu Kanagawa, Keisuke Yamazaki", "title": "Simulator Calibration under Covariate Shift with Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel calibration method for computer simulators, dealing with\nthe problem of covariate shift. Covariate shift is the situation where input\ndistributions for training and test are different, and ubiquitous in\napplications of simulations. Our approach is based on Bayesian inference with\nkernel mean embedding of distributions, and on the use of an\nimportance-weighted reproducing kernel for covariate shift adaptation. We\nprovide a theoretical analysis for the proposed method, including a novel\ntheoretical result for conditional mean embedding, as well as empirical\ninvestigations suggesting its effectiveness in practice. The experiments\ninclude calibration of a widely used simulator for industrial manufacturing\nprocesses, where we also demonstrate how the proposed method may be useful for\nsensitivity analysis of model parameters.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 14:51:39 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 06:24:52 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 12:28:43 GMT"}, {"version": "v4", "created": "Thu, 19 Mar 2020 03:18:24 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Kisamori", "Keiichi", ""], ["Kanagawa", "Motonobu", ""], ["Yamazaki", "Keisuke", ""]]}, {"id": "1809.08196", "submitter": "Xiongfeng Yan", "authors": "Xiongfeng Yan and Tinghua Ai", "title": "Analysis of Irregular Spatial Data with Machine Learning: Classification\n  of Building Patterns with a Graph Convolutional Neural Network", "comments": "7 pages, 6 figures, GIScience 2018", "journal-ref": null, "doi": "10.4230/LIPIcs.GIScience.2018.69", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods such as convolutional neural networks (CNNs) are\nbecoming an integral part of scientific research in many disciplines, spatial\nvector data often fail to be analyzed using these powerful learning methods\nbecause of its irregularities. With the aid of graph Fourier transform and\nconvolution theorem, it is possible to convert the convolution as a point-wise\nproduct in Fourier domain and construct a learning architecture of CNN on graph\nfor the analysis task of irregular spatial data. In this study, we used the\nclassification task of building patterns as a case study to test this method,\nand experiments showed that this method has achieved outstanding results in\nidentifying regular and irregular patterns, and has significantly improved in\ncomparing with other methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 16:37:24 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Yan", "Xiongfeng", ""], ["Ai", "Tinghua", ""]]}, {"id": "1809.08198", "submitter": "Huda Nassar", "authors": "Huda Nassar, Georgios Kollias, Ananth Grama, David F. Gleich", "title": "Low rank methods for multiple network alignment", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple network alignment is the problem of identifying similar and related\nregions in a given set of networks. While there are a large number of effective\ntechniques for pairwise problems with two networks that scale in terms of\nedges, these cannot be readily extended to align multiple networks as the\ncomputational complexity will tend to grow exponentially with the number of\nnetworks.In this paper we introduce a new multiple network alignment algorithm\nand framework that is effective at aligning thousands of networks with\nthousands of nodes. The key enabling technique of our algorithm is identifying\nan exact and easy to compute low-rank tensor structure inside of a principled\nheuristic procedure for pairwise network alignment called IsoRank. This can be\ncombined with a new algorithm for $k$-dimensional matching problems on low-rank\ntensors to produce the alignment. We demonstrate results on synthetic and\nreal-world problems that show our technique (i) is as good or better in terms\nof quality as existing methods, when they work on small problems, while running\nconsiderably faster and (ii) is able to scale to aligning a number of networks\nunreachable by current methods. We show in this paper that our method is the\nrealistic choice for aligning multiple networks when no prior information is\npresent.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 16:38:36 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Nassar", "Huda", ""], ["Kollias", "Georgios", ""], ["Grama", "Ananth", ""], ["Gleich", "David F.", ""]]}, {"id": "1809.08336", "submitter": "Konstantina Christakopoulou", "authors": "Konstantina Christakopoulou, Arindam Banerjee", "title": "Adversarial Recommendation: Attack of the Learned Fake Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can machine learning models for recommendation be easily fooled? While the\nquestion has been answered for hand-engineered fake user profiles, it has not\nbeen explored for machine learned adversarial attacks. This paper attempts to\nclose this gap.\n  We propose a framework for generating fake user profiles which, when\nincorporated in the training of a recommendation system, can achieve an\nadversarial intent, while remaining indistinguishable from real user profiles.\nWe formulate this procedure as a repeated general-sum game between two players:\nan oblivious recommendation system $R$ and an adversarial fake user generator\n$A$ with two goals: (G1) the rating distribution of the fake users needs to be\nclose to the real users, and (G2) some objective $f_A$ encoding the attack\nintent, such as targeting the top-K recommendation quality of $R$ for a subset\nof users, needs to be optimized. We propose a learning framework to achieve\nboth goals, and offer extensive experiments considering multiple types of\nattacks highlighting the vulnerability of recommendation systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 23:00:39 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Christakopoulou", "Konstantina", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1809.08343", "submitter": "Nicholas Mattei", "authors": "Ritesh Noothigattu, Djallel Bouneffouf, Nicholas Mattei, Rachita\n  Chandra, Piyush Madan, Kush Varshney, Murray Campbell, Moninder Singh,\n  Francesca Rossi", "title": "Interpretable Multi-Objective Reinforcement Learning through Policy\n  Orchestration", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous cyber-physical agents and systems play an increasingly large role\nin our lives. To ensure that agents behave in ways aligned with the values of\nthe societies in which they operate, we must develop techniques that allow\nthese agents to not only maximize their reward in an environment, but also to\nlearn and follow the implicit constraints of society. These constraints and\nnorms can come from any number of sources including regulations, business\nprocess guidelines, laws, ethical principles, social norms, and moral values.\nWe detail a novel approach that uses inverse reinforcement learning to learn a\nset of unspecified constraints from demonstrations of the task, and\nreinforcement learning to learn to maximize the environment rewards. More\nprecisely, we assume that an agent can observe traces of behavior of members of\nthe society but has no access to the explicit set of constraints that give rise\nto the observed behavior. Inverse reinforcement learning is used to learn such\nconstraints, that are then combined with a possibly orthogonal value function\nthrough the use of a contextual bandit-based orchestrator that picks a\ncontextually-appropriate choice between the two policies (constraint-based and\nenvironment reward-based) when taking actions. The contextual bandit\norchestrator allows the agent to mix policies in novel ways, taking the best\nactions from either a reward maximizing or constrained policy. In addition, the\norchestrator is transparent on which policy is being employed at each time\nstep. We test our algorithms using a Pac-Man domain and show that the agent is\nable to learn to act optimally, act within the demonstrated constraints, and\nmix these two functions in complex ways.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 23:38:17 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Noothigattu", "Ritesh", ""], ["Bouneffouf", "Djallel", ""], ["Mattei", "Nicholas", ""], ["Chandra", "Rachita", ""], ["Madan", "Piyush", ""], ["Varshney", "Kush", ""], ["Campbell", "Murray", ""], ["Singh", "Moninder", ""], ["Rossi", "Francesca", ""]]}, {"id": "1809.08346", "submitter": "Amir Erfan Eshratifar", "authors": "Amir Erfan Eshratifar, Mohammad Saeed Abrishami, David Eigen, Massoud\n  Pedram", "title": "A Meta-Learning Approach for Custom Model Training", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer-learning and meta-learning are two effective methods to apply\nknowledge learned from large data sources to new tasks. In few-class, few-shot\ntarget task settings (i.e. when there are only a few classes and training\nexamples available in the target task), meta-learning approaches that optimize\nfor future task learning have outperformed the typical transfer approach of\ninitializing model weights from a pre-trained starting point. But as we\nexperimentally show, meta-learning algorithms that work well in the few-class\nsetting do not generalize well in many-shot and many-class cases. In this\npaper, we propose a joint training approach that combines both\ntransfer-learning and meta-learning. Benefiting from the advantages of each,\nour method obtains improved generalization performance on unseen target tasks\nin both few- and many-class and few- and many-shot scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 23:47:34 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 04:32:50 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Eshratifar", "Amir Erfan", ""], ["Abrishami", "Mohammad Saeed", ""], ["Eigen", "David", ""], ["Pedram", "Massoud", ""]]}, {"id": "1809.08350", "submitter": "Nicholas Mattei", "authors": "Andrea Loreggia, Nicholas Mattei, Francesca Rossi, K. Brent Venable", "title": "CPMetric: Deep Siamese Networks for Learning Distances Between\n  Structured Preferences", "comments": null, "journal-ref": "Artificial Intelligence. IJCAI 2019 International Workshops. IJCAI\n  2019. Lecture Notes in Computer Science, vol 12158. Springer, Cham", "doi": "10.1007/978-3-030-56150-5_11", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preference are central to decision making by both machines and humans.\nRepresenting, learning, and reasoning with preferences is an important area of\nstudy both within computer science and across the sciences. When working with\npreferences it is necessary to understand and compute the distance between sets\nof objects, e.g., the preferences of a user and a the descriptions of objects\nto be recommended. We present CPDist, a novel neural network to address the\nproblem of learning to measure the distance between structured preference\nrepresentations. We use the popular CP-net formalism to represent preferences\nand then leverage deep neural networks to learn a recently proposed metric\nfunction that is computationally hard to compute directly. CPDist is a novel\nmetric learning approach based on the use of deep siamese networks which learn\nthe Kendal Tau distance between partial orders that are induced by compact\npreference representations. We find that CPDist is able to learn the distance\nfunction with high accuracy and outperform existing approximation algorithms on\nboth the regression and classification task using less computation time.\nPerformance remains good even when CPDist is trained with only a small number\nof samples compared to the dimension of the solution space, indicating the\nnetwork generalizes well.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 23:56:53 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 19:47:20 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Loreggia", "Andrea", ""], ["Mattei", "Nicholas", ""], ["Rossi", "Francesca", ""], ["Venable", "K. Brent", ""]]}, {"id": "1809.08352", "submitter": "Tom B Brown", "authors": "Tom B. Brown, Nicholas Carlini, Chiyuan Zhang, Catherine Olsson, Paul\n  Christiano, Ian Goodfellow", "title": "Unrestricted Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a two-player contest for evaluating the safety and robustness of\nmachine learning systems, with a large prize pool. Unlike most prior work in ML\nrobustness, which studies norm-constrained adversaries, we shift our focus to\nunconstrained adversaries. Defenders submit machine learning models, and try to\nachieve high accuracy and coverage on non-adversarial data while making no\nconfident mistakes on adversarial inputs. Attackers try to subvert defenses by\nfinding arbitrary unambiguous inputs where the model assigns an incorrect label\nwith high confidence. We propose a simple unambiguous dataset (\"bird-or-\nbicycle\") to use as part of this contest. We hope this contest will help to\nmore comprehensively evaluate the worst-case adversarial risk of machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 00:16:18 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Brown", "Tom B.", ""], ["Carlini", "Nicholas", ""], ["Zhang", "Chiyuan", ""], ["Olsson", "Catherine", ""], ["Christiano", "Paul", ""], ["Goodfellow", "Ian", ""]]}, {"id": "1809.08353", "submitter": "Vassilis N. Ioannidis", "authors": "Vassilis N. Ioannidis, Ahmed S. Zamzam, Georgios B. Giannakis, and\n  Nicholas D. Sidiropoulos", "title": "Coupled Graphs and Tensor Factorization for Recommender Systems and\n  Community Detection", "comments": "This paper is submitted to the IEEE Transactions on Knowledge and\n  Data Engineering. A preliminary version of this work was accepted for\n  presentation in the special track of GlobalSIP on Tensor Methods for Signal\n  Processing and Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint analysis of data from multiple information repositories facilitates\nuncovering the underlying structure in heterogeneous datasets. Single and\ncoupled matrix-tensor factorization (CMTF) has been widely used in this context\nfor imputation-based recommendation from ratings, social network, and other\nuser-item data. When this side information is in the form of item-item\ncorrelation matrices or graphs, existing CMTF algorithms may fall short.\nAlleviating current limitations, we introduce a novel model coined coupled\ngraph-tensor factorization (CGTF) that judiciously accounts for graph-related\nside information. The CGTF model has the potential to overcome practical\nchallenges, such as missing slabs from the tensor and/or missing rows/columns\nfrom the correlation matrices. A novel alternating direction method of\nmultipliers (ADMM) is also developed that recovers the nonnegative factors of\nCGTF. Our algorithm enjoys closed-form updates that result in reduced\ncomputational complexity and allow for convergence claims. A novel direction is\nfurther explored by employing the interpretable factors to detect graph\ncommunities having the tensor as side information. The resulting community\ndetection approach is successful even when some links in the graphs are\nmissing. Results with real data sets corroborate the merits of the proposed\nmethods relative to state-of-the-art competing factorization techniques in\nproviding recommendations and detecting communities.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 00:25:20 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 17:22:27 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Ioannidis", "Vassilis N.", ""], ["Zamzam", "Ahmed S.", ""], ["Giannakis", "Georgios B.", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1809.08360", "submitter": "Xiuqing Wei", "authors": "Haiqing Wei, Gang Huang, Xiuqing Wei, Yanlong Sun, Hongbin Wang", "title": "Comment on \"All-optical machine learning using diffractive deep neural\n  networks\"", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lin et al. (Reports, 7 September 2018, p. 1004) reported a remarkable\nproposal that employs a passive, strictly linear optical setup to perform\npattern classifications. But interpreting the multilayer diffractive setup as a\ndeep neural network and advocating it as an all-optical deep learning framework\nare not well justified and represent a mischaracterization of the system by\noverlooking its defining characteristics of perfect linearity and strict\npassivity.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 01:06:16 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 04:52:11 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Wei", "Haiqing", ""], ["Huang", "Gang", ""], ["Wei", "Xiuqing", ""], ["Sun", "Yanlong", ""], ["Wang", "Hongbin", ""]]}, {"id": "1809.08377", "submitter": "Reza Katebi", "authors": "Reza Katebi, Yadi Zhou, Ryan Chornock and Razvan Bunescu", "title": "Galaxy morphology prediction using capsule networks", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": "10.1093/mnras/stz915", "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding morphological types of galaxies is a key parameter for studying\ntheir formation and evolution. Neural networks that have been used previously\nfor galaxy morphology classification have some disadvantages, such as not being\ninvariant under rotation. In this work, we studied the performance of Capsule\nNetwork, a recently introduced neural network architecture that is rotationally\ninvariant and spatially aware, on the task of galaxy morphology classification.\nWe designed two evaluation scenarios based on the answers from the question\ntree in the Galaxy Zoo project. In the first scenario, we used Capsule Network\nfor regression and predicted probabilities for all of the questions. In the\nsecond scenario, we chose the answer to the first morphology question that had\nthe highest user agreement as the class of the object and trained a Capsule\nNetwork classifier, where we also reconstructed galaxy images. We achieved\npromising results in both of these scenarios. Automated approaches such as the\none introduced here will greatly decrease the workload of astronomers and will\nplay a critical role in the upcoming large sky surveys.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 03:41:05 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Katebi", "Reza", ""], ["Zhou", "Yadi", ""], ["Chornock", "Ryan", ""], ["Bunescu", "Razvan", ""]]}, {"id": "1809.08397", "submitter": "Zongliang Zhang", "authors": "Zongliang Zhang, Hongbin Zeng, Jonathan Li, Yiping Chen, Chenhui Yang,\n  Cheng Wang", "title": "Geometric Multi-Model Fitting by Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the geometric multi-model fitting from noisy,\nunstructured point set data (e.g., laser scanned point clouds). We formulate\nmulti-model fitting problem as a sequential decision making process. We then\nuse a deep reinforcement learning algorithm to learn the optimal decisions\ntowards the best fitting result. In this paper, we have compared our method\nagainst the state-of-the-art on simulated data. The results demonstrated that\nour approach significantly reduced the number of fitting iterations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 07:13:05 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2018 12:47:47 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Zhang", "Zongliang", ""], ["Zeng", "Hongbin", ""], ["Li", "Jonathan", ""], ["Chen", "Yiping", ""], ["Yang", "Chenhui", ""], ["Wang", "Cheng", ""]]}, {"id": "1809.08400", "submitter": "Kenan Cui", "authors": "Kenan Cui and Xu Chen and Jiangchao Yao and Ya Zhang", "title": "Variational Collaborative Learning for User Probabilistic Representation", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) has been successfully employed by many modern\nrecommender systems. Conventional CF-based methods use the user-item\ninteraction data as the sole information source to recommend items to users.\nHowever, CF-based methods are known for suffering from cold start problems and\ndata sparsity problems. Hybrid models that utilize auxiliary information on top\nof interaction data have increasingly gained attention. A few \"collaborative\nlearning\"-based models, which tightly bridges two heterogeneous learners\nthrough mutual regularization, are recently proposed for the hybrid\nrecommendation. However, the \"collaboration\" in the existing methods are\nactually asynchronous due to the alternative optimization of the two learners.\nLeveraging the recent advances in variational autoencoder~(VAE), we here\npropose a model consisting of two streams of mutual linked VAEs, named\nvariational collaborative model (VCM). Unlike the mutual regularization used in\nprevious works where two learners are optimized asynchronously, VCM enables a\nsynchronous collaborative learning mechanism. Besides, the two stream VAEs\nsetup allows VCM to fully leverages the Bayesian probabilistic representations\nin collaborative learning. Extensive experiments on three real-life datasets\nhave shown that VCM outperforms several state-of-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 07:38:30 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Cui", "Kenan", ""], ["Chen", "Xu", ""], ["Yao", "Jiangchao", ""], ["Zhang", "Ya", ""]]}, {"id": "1809.08406", "submitter": "Armen Allahverdyan", "authors": "Rongrong Xie, Shengfeng Deng, Weibing Deng and Armen E. Allahverdyan", "title": "Active image restoration", "comments": "17 pages, 6 figures", "journal-ref": "Phys. Rev. E 98, 052108 (2018)", "doi": "10.1103/PhysRevE.98.052108", "report-no": null, "categories": "cond-mat.stat-mech cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study active restoration of noise-corrupted images generated via the Gibbs\nprobability of an Ising ferromagnet in external magnetic field. Ferromagnetism\naccounts for the prior expectation of data smoothness, i.e. a positive\ncorrelation between neighbouring pixels (Ising spins), while the magnetic field\nrefers to the bias. The restoration is actively supervised by requesting the\ntrue values of certain pixels after a noisy observation. This additional\ninformation improves restoration of other pixels. The optimal strategy of\nactive inference is not known for realistic (two-dimensional) images. We\ndetermine this strategy for the mean-field version of the model and show that\nit amounts to supervising the values of spins (pixels) that do not agree with\nthe sign of the average magnetization. The strategy leads to a transparent\nanalytical expression for the minimal Bayesian risk, and shows that there is a\nmaximal number of pixels beyond of which the supervision is useless. We show\nnumerically that this strategy applies for two-dimensional images away from the\ncritical regime. Within this regime the strategy is outperformed by its local\n(adaptive) version, which supervises pixels that do not agree with their\nBayesian estimate. We show on transparent examples how active supervising can\nbe essential in recovering noise-corrupted images and advocate for a wider\nusage of active methods in image restoration.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 08:32:43 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Xie", "Rongrong", ""], ["Deng", "Shengfeng", ""], ["Deng", "Weibing", ""], ["Allahverdyan", "Armen E.", ""]]}, {"id": "1809.08410", "submitter": "Kuan Tung", "authors": "Kuan Tung, Po-Kang Liu, Yu-Chuan Chuang, Sheng-Hui Wang, An-Yeu Wu", "title": "Entropy-Assisted Multi-Modal Emotion Recognition Framework Based on\n  Physiological Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the result of the growing importance of the Human Computer Interface\nsystem, understanding human's emotion states has become a consequential ability\nfor the computer. This paper aims to improve the performance of emotion\nrecognition by conducting the complexity analysis of physiological signals.\nBased on AMIGOS dataset, we extracted several entropy-domain features such as\nRefined Composite Multi-Scale Entropy (RCMSE), Refined Composite Multi-Scale\nPermutation Entropy (RCMPE) from ECG and GSR signals, and Multivariate\nMulti-Scale Entropy (MMSE), Multivariate Multi-Scale Permutation Entropy (MMPE)\nfrom EEG, respectively. The statistical results show that RCMSE in GSR has a\ndominating performance in arousal, while RCMPE in GSR would be the excellent\nfeature in valence. Furthermore, we selected XGBoost model to predict emotion\nand get 68% accuracy in arousal and 84% in valence.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 08:45:15 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Tung", "Kuan", ""], ["Liu", "Po-Kang", ""], ["Chuang", "Yu-Chuan", ""], ["Wang", "Sheng-Hui", ""], ["Wu", "An-Yeu", ""]]}, {"id": "1809.08417", "submitter": "Md. Abu Bakr Siddique", "authors": "Md. Abu Bakr Siddique, Rezoana Bente Arif, Mohammad Mahmudur Rahman\n  Khan, Zahidun Ashrafi", "title": "Implementation of Fuzzy C-Means and Possibilistic C-Means Clustering\n  Algorithms, Cluster Tendency Analysis and Cluster Validation", "comments": "8 pages, 13 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, several two-dimensional clustering scenarios are given. In\nthose scenarios, soft partitioning clustering algorithms (Fuzzy C-means (FCM)\nand Possibilistic c-means (PCM)) are applied. Afterward, VAT is used to\ninvestigate the clustering tendency visually, and then in order of checking\ncluster validation, three types of indices (e.g., PC, DI, and DBI) were used.\nAfter observing the clustering algorithms, it was evident that each of them has\nits limitations; however, PCM is more robust to noise than FCM as in case of\nFCM a noise point has to be considered as a member of any of the cluster.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 09:45:05 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 03:22:09 GMT"}, {"version": "v3", "created": "Sun, 12 May 2019 06:10:21 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Siddique", "Md. Abu Bakr", ""], ["Arif", "Rezoana Bente", ""], ["Khan", "Mohammad Mahmudur Rahman", ""], ["Ashrafi", "Zahidun", ""]]}, {"id": "1809.08443", "submitter": "Stephan Bialonski", "authors": "Justus T. C. Schwabedal, Daniel Sippel, Moritz D. Brandt, Stephan\n  Bialonski", "title": "Automated Classification of Sleep Stages and EEG Artifacts in Mice with\n  Deep Learning", "comments": "7 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep scoring is a necessary and time-consuming task in sleep studies. In\nanimal models (such as mice) or in humans, automating this tedious process\npromises to facilitate long-term studies and to promote sleep biology as a\ndata-driven field. We introduce a deep neural network model that is able to\npredict different states of consciousness (Wake, Non-REM, REM) in mice from EEG\nand EMG recordings with excellent scoring results for out-of-sample data.\nPredictions are made on epochs of 4 seconds length, and epochs are classified\nas artifact-free or not. The model architecture draws on recent advances in\ndeep learning and in convolutional neural networks research. In contrast to\nprevious approaches towards automated sleep scoring, our model does not rely on\nmanually defined features of the data but learns predictive features\nautomatically. We expect deep learning models like ours to become widely\napplied in different fields, automating many repetitive cognitive tasks that\nwere previously difficult to tackle.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 15:02:02 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Schwabedal", "Justus T. C.", ""], ["Sippel", "Daniel", ""], ["Brandt", "Moritz D.", ""], ["Bialonski", "Stephan", ""]]}, {"id": "1809.08458", "submitter": "Yihui He", "authors": "Huasong Zhong, Xianggen Liu, Yihui He, Yuchun Ma", "title": "Shift-based Primitives for Efficient Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a collection of three shift-based primitives for building\nefficient compact CNN-based networks. These three primitives (channel shift,\naddress shift, shortcut shift) can reduce the inference time on GPU while\nmaintains the prediction accuracy. These shift-based primitives only moves the\npointer but avoids memory copy, thus very fast. For example, the channel shift\noperation is 12.7x faster compared to channel shuffle in ShuffleNet but\nachieves the same accuracy. The address shift and channel shift can be merged\ninto the point-wise group convolution and invokes only a single kernel call,\ntaking little time to perform spatial convolution and channel shift. Shortcut\nshift requires no time to realize residual connection through allocating space\nin advance. We blend these shift-based primitives with point-wise group\nconvolution and built two inference-efficient CNN architectures named\nAddressNet and Enhanced AddressNet. Experiments on CIFAR100 and ImageNet\ndatasets show that our models are faster and achieve comparable or better\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 17:43:28 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 02:59:32 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Zhong", "Huasong", ""], ["Liu", "Xianggen", ""], ["He", "Yihui", ""], ["Ma", "Yuchun", ""]]}, {"id": "1809.08510", "submitter": "Armen Aghajanyan", "authors": "Armen Aghajanyan, Xia Song, Saurabh Tiwary", "title": "Towards Language Agnostic Universal Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a bilingual student learns to solve word problems in math, we expect the\nstudent to be able to solve these problem in both languages the student is\nfluent in,even if the math lessons were only taught in one language. However,\ncurrent representations in machine learning are language dependent. In this\nwork, we present a method to decouple the language from the problem by learning\nlanguage agnostic representations and therefore allowing training a model in\none language and applying to a different one in a zero shot fashion. We learn\nthese representations by taking inspiration from linguistics and formalizing\nUniversal Grammar as an optimization process (Chomsky, 2014; Montague, 1970).\nWe demonstrate the capabilities of these representations by showing that the\nmodels trained on a single language using language agnostic representations\nachieve very similar accuracies in other languages.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 01:55:46 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Aghajanyan", "Armen", ""], ["Song", "Xia", ""], ["Tiwary", "Saurabh", ""]]}, {"id": "1809.08516", "submitter": "Bao Wang", "authors": "Bao Wang, Alex T. Lin, Wei Zhu, Penghang Yin, Andrea L. Bertozzi,\n  Stanley J. Osher", "title": "Adversarial Defense via Data Dependent Activation Function and Total\n  Variation Minimization", "comments": "17 pages, 6 figures", "journal-ref": "Inverse Problems and Imaging, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve the robustness of Deep Neural Net (DNN) to adversarial attacks by\nusing an interpolating function as the output activation. This data-dependent\nactivation remarkably improves both the generalization and robustness of DNN.\nIn the CIFAR10 benchmark, we raise the robust accuracy of the adversarially\ntrained ResNet20 from $\\sim 46\\%$ to $\\sim 69\\%$ under the state-of-the-art\nIterative Fast Gradient Sign Method (IFGSM) based adversarial attack. When we\ncombine this data-dependent activation with total variation minimization on\nadversarial images and training data augmentation, we achieve an improvement in\nrobust accuracy by 38.9$\\%$ for ResNet56 under the strongest IFGSM attack.\nFurthermore, We provide an intuitive explanation of our defense by analyzing\nthe geometry of the feature space.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 02:33:31 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 17:54:21 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 07:05:16 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Wang", "Bao", ""], ["Lin", "Alex T.", ""], ["Zhu", "Wei", ""], ["Yin", "Penghang", ""], ["Bertozzi", "Andrea L.", ""], ["Osher", "Stanley J.", ""]]}, {"id": "1809.08530", "submitter": "Jason Lee", "authors": "Sham Kakade and Jason D. Lee", "title": "Provably Correct Automatic Subdifferentiation for Qualified Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cheap Gradient Principle (Griewank 2008) --- the computational cost of\ncomputing the gradient of a scalar-valued function is nearly the same (often\nwithin a factor of $5$) as that of simply computing the function itself --- is\nof central importance in optimization; it allows us to quickly obtain (high\ndimensional) gradients of scalar loss functions which are subsequently used in\nblack box gradient-based optimization procedures. The current state of affairs\nis markedly different with regards to computing subderivatives: widely used ML\nlibraries, including TensorFlow and PyTorch, do not correctly compute\n(generalized) subderivatives even on simple examples. This work considers the\nquestion: is there a Cheap Subgradient Principle? Our main result shows that,\nunder certain restrictions on our library of nonsmooth functions (standard in\nnonlinear programming), provably correct generalized subderivatives can be\ncomputed at a computational cost that is within a (dimension-free) factor of\n$6$ of the cost of computing the scalar function itself.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 04:22:22 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 06:09:08 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Kakade", "Sham", ""], ["Lee", "Jason D.", ""]]}, {"id": "1809.08541", "submitter": "Jianzhe Lin", "authors": "Jianzhe Lin, Qi Wang, Rabab Ward, Z. Jane Wang", "title": "DT-LET: Deep Transfer Learning by Exploring where to Transfer", "comments": "Conference paper submitted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous transfer learning methods based on deep network assume the knowledge\nshould be transferred between the same hidden layers of the source domain and\nthe target domains. This assumption doesn't always hold true, especially when\nthe data from the two domains are heterogeneous with different resolutions. In\nsuch case, the most suitable numbers of layers for the source domain data and\nthe target domain data would differ. As a result, the high level knowledge from\nthe source domain would be transferred to the wrong layer of target domain.\nBased on this observation, \"where to transfer\" proposed in this paper should be\na novel research frontier. We propose a new mathematic model named DT-LET to\nsolve this heterogeneous transfer learning problem. In order to select the best\nmatching of layers to transfer knowledge, we define specific loss function to\nestimate the corresponding relationship between high-level features of data in\nthe source domain and the target domain. To verify this proposed cross-layer\nmodel, experiments for two cross-domain recognition/classification tasks are\nconducted, and the achieved superior results demonstrate the necessity of layer\ncorrespondence searching.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 06:06:01 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Lin", "Jianzhe", ""], ["Wang", "Qi", ""], ["Ward", "Rabab", ""], ["Wang", "Z. Jane", ""]]}, {"id": "1809.08560", "submitter": "Shoubo Hu", "authors": "Shoubo Hu, Zhitang Chen, Laiwan Chan", "title": "A Kernel Embedding-based Approach for Nonstationary Causal Model\n  Inference", "comments": "Published at Neural Computation", "journal-ref": "Neural computation, 30(5), 1394-1425, 2018", "doi": "10.1162/neco_a_01064", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although nonstationary data are more common in the real world, most existing\ncausal discovery methods do not take nonstationarity into consideration. In\nthis letter, we propose a kernel embedding-based approach, ENCI, for\nnonstationary causal model inference where data are collected from multiple\ndomains with varying distributions. In ENCI, we transform the complicated\nrelation of a cause-effect pair into a linear model of variables of which\nobservations correspond to the kernel embeddings of the cause-and-effect\ndistributions in different domains. In this way, we are able to estimate the\ncausal direction by exploiting the causal asymmetry of the transformed linear\nmodel. Furthermore, we extend ENCI to causal graph discovery for multiple\nvariables by transforming the relations among them into a linear nongaussian\nacyclic model. We show that by exploiting the nonstationarity of distributions,\nboth cause-effect pairs and two kinds of causal graphs are identifiable under\nmild conditions. Experiments on synthetic and real-world data are conducted to\njustify the efficacy of ENCI over major existing methods.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 09:28:46 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Hu", "Shoubo", ""], ["Chen", "Zhitang", ""], ["Chan", "Laiwan", ""]]}, {"id": "1809.08567", "submitter": "Jordi De La Torre", "authors": "Jordi de la Torre, Aida Valls, Domenec Puig, Pere Romero-Aroca", "title": "Identification and Visualization of the Underlying Independent Causes of\n  the Diagnostic of Diabetic Retinopathy made by a Deep Learning Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability is a key factor in the design of automatic classifiers for\nmedical diagnosis. Deep learning models have been proven to be a very effective\nclassification algorithm when trained in a supervised way with enough data. The\nmain concern is the difficulty of inferring rationale interpretations from\nthem. Different attempts have been done in last years in order to convert deep\nlearning classifiers from high confidence statistical black box machines into\nself-explanatory models. In this paper we go forward into the generation of\nexplanations by identifying the independent causes that use a deep learning\nmodel for classifying an image into a certain class. We use a combination of\nIndependent Component Analysis with a Score Visualization technique. In this\npaper we study the medical problem of classifying an eye fundus image into 5\nlevels of Diabetic Retinopathy. We conclude that only 3 independent components\nare enough for the differentiation and correct classification between the 5\ndisease standard classes. We propose a method for visualizing them and\ndetecting lesions from the generated visual maps.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 09:51:12 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["de la Torre", "Jordi", ""], ["Valls", "Aida", ""], ["Puig", "Domenec", ""], ["Romero-Aroca", "Pere", ""]]}, {"id": "1809.08568", "submitter": "Shoubo Hu", "authors": "Shoubo Hu, Zhitang Chen, Vahid Partovi Nia, Laiwan Chan, Yanhui Geng", "title": "Causal Inference and Mechanism Clustering of A Mixture of Additive Noise\n  Models", "comments": "Published at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inference of the causal relationship between a pair of observed variables\nis a fundamental problem in science, and most existing approaches are based on\none single causal model. In practice, however, observations are often collected\nfrom multiple sources with heterogeneous causal models due to certain\nuncontrollable factors, which renders causal analysis results obtained by a\nsingle model skeptical. In this paper, we generalize the Additive Noise Model\n(ANM) to a mixture model, which consists of a finite number of ANMs, and\nprovide the condition of its causal identifiability. To conduct model\nestimation, we propose Gaussian Process Partially Observable Model (GPPOM), and\nincorporate independence enforcement into it to learn latent parameter\nassociated with each observation. Causal inference and clustering according to\nthe underlying generating mechanisms of the mixture model are addressed in this\nwork. Experiments on synthetic and real data demonstrate the effectiveness of\nour proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 09:57:14 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 18:11:35 GMT"}, {"version": "v3", "created": "Sun, 11 Nov 2018 13:04:29 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Hu", "Shoubo", ""], ["Chen", "Zhitang", ""], ["Nia", "Vahid Partovi", ""], ["Chan", "Laiwan", ""], ["Geng", "Yanhui", ""]]}, {"id": "1809.08587", "submitter": "Ohad Shamir", "authors": "Ohad Shamir", "title": "Exponential Convergence Time of Gradient Descent for One-Dimensional\n  Deep Linear Neural Networks", "comments": "Comparison to previous version: Fixed a bug in lemma 1 part 3 (does\n  not affect any other part of the paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the dynamics of gradient descent on objective functions of the form\n$f(\\prod_{i=1}^{k} w_i)$ (with respect to scalar parameters $w_1,\\ldots,w_k$),\nwhich arise in the context of training depth-$k$ linear neural networks. We\nprove that for standard random initializations, and under mild assumptions on\n$f$, the number of iterations required for convergence scales exponentially\nwith the depth $k$. We also show empirically that this phenomenon can occur in\nhigher dimensions, where each $w_i$ is a matrix. This highlights a potential\nobstacle in understanding the convergence of gradient-based methods for deep\nlinear neural networks, where $k$ is large.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 12:32:45 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 08:37:45 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 08:31:56 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 07:23:22 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Shamir", "Ohad", ""]]}, {"id": "1809.08590", "submitter": "Kaiyu Chen", "authors": "Kaiyu Chen, Yihan Dong, Xipeng Qiu, Zitian Chen", "title": "Neural Arithmetic Expression Calculator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a pure neural solver for arithmetic expression\ncalculation (AEC) problem. Previous work utilizes the powerful capabilities of\ndeep neural networks and attempts to build an end-to-end model to solve this\nproblem. However, most of these methods can only deal with the additive\noperations. It is still a challenging problem to solve the complex expression\ncalculation problem, which includes the adding, subtracting, multiplying,\ndividing and bracketing operations. In this work, we regard the arithmetic\nexpression calculation as a hierarchical reinforcement learning problem. An\narithmetic operation is decomposed into a series of sub-tasks, and each\nsub-task is dealt with by a skill module. The skill module could be a basic\nmodule performing elementary operations, or interactive module performing\ncomplex operations by invoking other skill models. With curriculum learning,\nour model can deal with a complex arithmetic expression calculation with the\ndeep hierarchical structure of skill models. Experiments show that our model\nsignificantly outperforms the previous models for arithmetic expression\ncalculation.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 13:05:28 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Chen", "Kaiyu", ""], ["Dong", "Yihan", ""], ["Qiu", "Xipeng", ""], ["Chen", "Zitian", ""]]}, {"id": "1809.08613", "submitter": "Namiko Saito", "authors": "Namiko Saito, Kitae Kim, Shingo Murata, Tetsuya Ogata and Shigeki\n  Sugano", "title": "Detecting Features of Tools, Objects, and Actions from Effects in a\n  Robot using Deep Learning", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a tool-use model that can detect the features of tools, target\nobjects, and actions from the provided effects of object manipulation. We\nconstruct a model that enables robots to manipulate objects with tools, using\ninfant learning as a concept. To realize this, we train sensory-motor data\nrecorded during a tool-use task performed by a robot with deep learning.\nExperiments include four factors: (1) tools, (2) objects, (3) actions, and (4)\neffects, which the model considers simultaneously. For evaluation, the robot\ngenerates predicted images and motions given information of the effects of\nusing unknown tools and objects. We confirm that the robot is capable of\ndetecting features of tools, objects, and actions by learning the effects and\nexecuting the task.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 15:24:21 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Saito", "Namiko", ""], ["Kim", "Kitae", ""], ["Murata", "Shingo", ""], ["Ogata", "Tetsuya", ""], ["Sugano", "Shigeki", ""]]}, {"id": "1809.08625", "submitter": "Chengxi Ye", "authors": "Chengxi Ye, Anton Mitrokhin, Cornelia Ferm\\\"uller, James A. Yorke,\n  Yiannis Aloimonos", "title": "Unsupervised Learning of Dense Optical Flow, Depth and Egomotion from\n  Sparse Event Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a lightweight, unsupervised learning pipeline for\n\\textit{dense} depth, optical flow and egomotion estimation from sparse event\noutput of the Dynamic Vision Sensor (DVS). To tackle this low level vision\ntask, we use a novel encoder-decoder neural network architecture - ECN.\n  Our work is the first monocular pipeline that generates dense depth and\noptical flow from sparse event data only. The network works in self-supervised\nmode and has just 150k parameters. We evaluate our pipeline on the MVSEC self\ndriving dataset and present results for depth, optical flow and and egomotion\nestimation. Due to the lightweight design, the inference part of the network\nruns at 250 FPS on a single GPU, making the pipeline ready for realtime\nrobotics applications. Our experiments demonstrate significant improvements\nupon previous works that used deep learning on event data, as well as the\nability of our pipeline to perform well during both day and night.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 16:27:58 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 18:17:25 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Ye", "Chengxi", ""], ["Mitrokhin", "Anton", ""], ["Ferm\u00fcller", "Cornelia", ""], ["Yorke", "James A.", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "1809.08626", "submitter": "Arash Mahyari", "authors": "Arash Golibagh Mahyari, Thomas Locker", "title": "Domain Adaptation for Robot Predictive Maintenance Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial robots play an increasingly important role in a growing number of\nfields. For example, robotics is used to increase productivity while reducing\ncosts in various aspects of manufacturing. Since robots are often set up in\nproduction lines, the breakdown of a single robot has a negative impact on the\nentire process, in the worst case bringing the whole line to a halt until the\nissue is resolved, leading to substantial financial losses due to the\nunforeseen downtime. Therefore, predictive maintenance systems based on the\ninternal signals of robots have gained attention as an essential component of\nrobotics service offerings. The main shortcoming of existing predictive\nmaintenance algorithms is that the extracted features typically differ\nsignificantly from the learnt model when the operation of the robot changes,\nincurring false alarms. In order to mitigate this problem, predictive\nmaintenance algorithms require the model to be retrained with normal data of\nthe new operation. In this paper, we propose a novel solution based on transfer\nlearning to pass the knowledge of the trained model from one operation to\nanother in order to prevent the need for retraining and to eliminate such false\nalarms. The deployment of the proposed unsupervised transfer learning algorithm\non real-world datasets demonstrates that the algorithm can not only distinguish\nbetween operation and mechanical condition change, it further yields a sharper\ndeviation from the trained model in case of a mechanical condition change and\nthus detects mechanical issues with higher confidence.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 16:29:29 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 15:44:18 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 19:37:38 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Mahyari", "Arash Golibagh", ""], ["Locker", "Thomas", ""]]}, {"id": "1809.08657", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Peter Richt\\'arik", "title": "Accelerated Gossip via Stochastic Heavy Ball Method", "comments": "8 pages, 5 Figures, 56th Annual Allerton Conference on Communication,\n  Control, and Computing, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG cs.NA cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show how the stochastic heavy ball method (SHB) -- a popular\nmethod for solving stochastic convex and non-convex optimization problems\n--operates as a randomized gossip algorithm. In particular, we focus on two\nspecial cases of SHB: the Randomized Kaczmarz method with momentum and its\nblock variant. Building upon a recent framework for the design and analysis of\nrandomized gossip algorithms, [Loizou Richtarik, 2016] we interpret the\ndistributed nature of the proposed methods. We present novel protocols for\nsolving the average consensus problem where in each step all nodes of the\nnetwork update their values but only a subset of them exchange their private\nvalues. Numerical experiments on popular wireless sensor networks showing the\nbenefits of our protocols are also presented.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 18:51:01 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1809.08660", "submitter": "Vahid Moosavi", "authors": "Lukas Fuhrimann, Vahid Moosavi, Patrick Ole Ohlbrock, Pierluigi\n  Dacunto", "title": "Data-Driven Design: Exploring new Structural Forms using Machine\n  Learning and Graphic Statics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this research is to introduce a novel structural design process\nthat allows architects and engineers to extend their typical design space\nhorizon and thereby promoting the idea of creativity in structural design. The\ntheoretical base of this work builds on the combination of structural\nform-finding and state-of-the-art machine learning algorithms. In the first\nstep of the process, Combinatorial Equilibrium Modelling (CEM) is used to\ngenerate a large variety of spatial networks in equilibrium for given input\nparameters. In the second step, these networks are clustered and represented in\na form-map through the implementation of a Self Organizing Map (SOM) algorithm.\nIn the third step, the solution space is interpreted with the help of a Uniform\nManifold Approximation and Projection algorithm (UMAP). This allows gaining\nimportant insights in the structure of the solution space. A specific case\nstudy is used to illustrate how the infinite equilibrium states of a given\ntopology can be defined and represented by clusters. Furthermore, three\nclasses, related to the non-linear interaction between the input parameters and\nthe form space, are verified and a statement about the entire manifold of the\nsolution space of the case study is made. To conclude, this work presents an\ninnovative approach on how the manifold of a solution space can be grasped with\na minimum amount of data and how to operate within the manifold in order to\nincrease the diversity of solutions.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 19:00:40 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Fuhrimann", "Lukas", ""], ["Moosavi", "Vahid", ""], ["Ohlbrock", "Patrick Ole", ""], ["Dacunto", "Pierluigi", ""]]}, {"id": "1809.08696", "submitter": "Zeljko Kereta", "authors": "Ernesto de Vito and Zeljko Kereta and Valeria Naumova", "title": "Unsupervised parameter selection for denoising with the elastic net", "comments": "27 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in regularisation theory, the issue of parameter\nselection still remains a challenge for most applications. In a recent work the\nframework of statistical learning was used to approximate the optimal Tikhonov\nregularisation parameter from noisy data. In this work, we improve their\nresults and extend the analysis to the elastic net regularisation, providing\nexplicit error bounds on the accuracy of the approximated parameter and the\ncorresponding regularisation solution in a simplified case. Furthermore, in the\ngeneral case we design a data-driven, automated algorithm for the computation\nof an approximate regularisation parameter. Our analysis combines statistical\nlearning theory with insights from regularisation theory. We compare our\napproach with state-of-the-art parameter selection criteria and illustrate its\nsuperiority in terms of accuracy and computational time on simulated and real\ndata sets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 23:31:17 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 08:52:04 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 14:56:15 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["de Vito", "Ernesto", ""], ["Kereta", "Zeljko", ""], ["Naumova", "Valeria", ""]]}, {"id": "1809.08700", "submitter": "Ritesh Noothigattu", "authors": "Maria-Florina Balcan, Travis Dick, Ritesh Noothigattu and Ariel D.\n  Procaccia", "title": "Envy-Free Classification", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, 2019, pp.\n  1240-1250", "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classic fair division problems such as cake cutting and rent division,\nenvy-freeness requires that each individual (weakly) prefer his allocation to\nanyone else's. On a conceptual level, we argue that envy-freeness also provides\na compelling notion of fairness for classification tasks. Our technical focus\nis the generalizability of envy-free classification, i.e., understanding\nwhether a classifier that is envy free on a sample would be almost envy free\nwith respect to the underlying distribution with high probability. Our main\nresult establishes that a small sample is sufficient to achieve such\nguarantees, when the classifier in question is a mixture of deterministic\nclassifiers that belong to a family of low Natarajan dimension.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 23:59:20 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 05:35:16 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Dick", "Travis", ""], ["Noothigattu", "Ritesh", ""], ["Procaccia", "Ariel D.", ""]]}, {"id": "1809.08705", "submitter": "Babak Barazandeh", "authors": "Babak Barazandeh, Meisam Razaviyayn", "title": "On the Behavior of the Expectation-Maximization Algorithm for Mixture\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite mixture models are among the most popular statistical models used in\ndifferent data science disciplines. Despite their broad applicability,\ninference under these models typically leads to computationally challenging\nnon-convex problems. While the Expectation-Maximization (EM) algorithm is the\nmost popular approach for solving these non-convex problems, the behavior of\nthis algorithm is not well understood. In this work, we focus on the case of\nmixture of Laplacian (or Gaussian) distribution. We start by analyzing a simple\nequally weighted mixture of two single dimensional Laplacian distributions and\nshow that every local optimum of the population maximum likelihood estimation\nproblem is globally optimal. Then, we prove that the EM algorithm converges to\nthe ground truth parameters almost surely with random initialization. Our\nresult extends the existing results for Gaussian distribution to Laplacian\ndistribution. Then we numerically study the behavior of mixture models with\nmore than two components. Motivated by our extensive numerical experiments, we\npropose a novel stochastic method for estimating the mean of components of a\nmixture model. Our numerical experiments show that our algorithm outperforms\nthe Naive EM algorithm in almost all scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 00:12:28 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Barazandeh", "Babak", ""], ["Razaviyayn", "Meisam", ""]]}, {"id": "1809.08706", "submitter": "Pin-Yu Chen", "authors": "Pin-Yu Chen, Bhanukiran Vinzamuri, Sijia Liu", "title": "Is Ordered Weighted $\\ell_1$ Regularized Regression Robust to\n  Adversarial Perturbation? A Case Study on OSCAR", "comments": "Accepted to IEEE GlobalSIP 2018. Pin-Yu Chen and Bhanukiran Vinzamuri\n  contribute equally to this work; v2 fixes missing citation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many state-of-the-art machine learning models such as deep neural networks\nhave recently shown to be vulnerable to adversarial perturbations, especially\nin classification tasks. Motivated by adversarial machine learning, in this\npaper we investigate the robustness of sparse regression models with strongly\ncorrelated covariates to adversarially designed measurement noises.\nSpecifically, we consider the family of ordered weighted $\\ell_1$ (OWL)\nregularized regression methods and study the case of OSCAR (octagonal shrinkage\nclustering algorithm for regression) in the adversarial setting. Under a\nnorm-bounded threat model, we formulate the process of finding a maximally\ndisruptive noise for OWL-regularized regression as an optimization problem and\nillustrate the steps towards finding such a noise in the case of OSCAR.\nExperimental results demonstrate that the regression performance of grouping\nstrongly correlated features can be severely degraded under our adversarial\nsetting, even when the noise budget is significantly smaller than the\nground-truth signals.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 00:20:03 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 03:50:41 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Chen", "Pin-Yu", ""], ["Vinzamuri", "Bhanukiran", ""], ["Liu", "Sijia", ""]]}, {"id": "1809.08707", "submitter": "Yaohua Sun", "authors": "Yaohua Sun, Mugen Peng, Yangcheng Zhou, Yuzhe Huang, Shiwen Mao", "title": "Application of Machine Learning in Wireless Networks: Key Techniques and\n  Open Issues", "comments": "34 pages,8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a key technique for enabling artificial intelligence, machine learning\n(ML) is capable of solving complex problems without explicit programming.\nMotivated by its successful applications to many practical tasks like image\nrecognition, both industry and the research community have advocated the\napplications of ML in wireless communication. This paper comprehensively\nsurveys the recent advances of the applications of ML in wireless\ncommunication, which are classified as: resource management in the MAC layer,\nnetworking and mobility management in the network layer, and localization in\nthe application layer. The applications in resource management further include\npower control, spectrum management, backhaul management, cache management,\nbeamformer design and computation resource management, while ML based\nnetworking focuses on the applications in clustering, base station switching\ncontrol, user association and routing. Moreover, literatures in each aspect is\norganized according to the adopted ML techniques. In addition, several\nconditions for applying ML to wireless communication are identified to help\nreaders decide whether to use ML and which kind of ML techniques to use, and\ntraditional approaches are also summarized together with their performance\ncomparison with ML based approaches, based on which the motivations of surveyed\nliteratures to adopt ML are clarified. Given the extensiveness of the research\narea, challenges and unresolved issues are presented to facilitate future\nstudies, where ML based network slicing, infrastructure update to support ML\nbased paradigms, open data sets and platforms for researchers, theoretical\nguidance for ML implementation and so on are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 00:25:49 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 03:33:12 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Sun", "Yaohua", ""], ["Peng", "Mugen", ""], ["Zhou", "Yangcheng", ""], ["Huang", "Yuzhe", ""], ["Mao", "Shiwen", ""]]}, {"id": "1809.08717", "submitter": "Alexander Stec", "authors": "Alexander Stec, Diego Klabjan, Jean Utke", "title": "Unified recurrent neural network for many feature types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are time series that are amenable to recurrent neural network (RNN)\nsolutions when treated as sequences, but some series, e.g. asynchronous time\nseries, provide a richer variation of feature types than current RNN cells take\ninto account. In order to address such situations, we introduce a unified RNN\nthat handles five different feature types, each in a different manner. Our RNN\nframework separates sequential features into two groups dependent on their\nfrequency, which we call sparse and dense features, and which affect cell\nupdates differently. Further, we also incorporate time features at the\nsequential level that relate to the time between specified events in the\nsequence and are used to modify the cell's memory state. We also include two\ntypes of static (whole sequence level) features, one related to time and one\nnot, which are combined with the encoder output. The experiments show that the\nmodeling framework proposed does increase performance compared to standard\ncells.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 01:37:26 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Stec", "Alexander", ""], ["Klabjan", "Diego", ""], ["Utke", "Jean", ""]]}, {"id": "1809.08738", "submitter": "Mikhail Yurochkin", "authors": "Mikhail Yurochkin, Zhiwei Fan, Aritra Guha, Paraschos Koutris and\n  XuanLong Nguyen", "title": "Scalable inference of topic evolution via models for latent geometric\n  structures", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop new models and algorithms for learning the temporal dynamics of\nthe topic polytopes and related geometric objects that arise in topic model\nbased inference. Our model is nonparametric Bayesian and the corresponding\ninference algorithm is able to discover new topics as the time progresses. By\nexploiting the connection between the modeling of topic polytope evolution,\nBeta-Bernoulli process and the Hungarian matching algorithm, our method is\nshown to be several orders of magnitude faster than existing topic modeling\napproaches, as demonstrated by experiments working with several million\ndocuments in under two dozens of minutes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 03:23:07 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 23:59:08 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 03:49:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Yurochkin", "Mikhail", ""], ["Fan", "Zhiwei", ""], ["Guha", "Aritra", ""], ["Koutris", "Paraschos", ""], ["Nguyen", "XuanLong", ""]]}, {"id": "1809.08771", "submitter": "{\\L}ukasz Kidzi\\'nski", "authors": "{\\L}ukasz Kidzi\\'nski, Trevor Hastie", "title": "Longitudinal data analysis using matrix completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In clinical practice and biomedical research, measurements are often\ncollected sparsely and irregularly in time while the data acquisition is\nexpensive and inconvenient. Examples include measurements of spine bone mineral\ndensity, cancer growth through mammography or biopsy, a progression of defect\nof vision, or assessment of gait in patients with neurological disorders. Since\nthe data collection is often costly and inconvenient, estimation of progression\nfrom sparse observations is of great interest for practitioners.\n  From the statistical standpoint, such data is often analyzed in the context\nof a mixed-effect model where time is treated as both random and fixed effect.\nAlternatively, researchers analyze Gaussian processes or functional data where\nobservations are assumed to be drawn from a certain distribution of processes.\nThese models are flexible but rely on probabilistic assumptions and require\nvery careful implementation.\n  In this study, we propose an alternative elementary framework for analyzing\nlongitudinal data, relying on matrix completion. Our method yields point\nestimates of progression curves by iterative application of the SVD. Our\nframework covers multivariate longitudinal data, regression and can be easily\nextended to other settings.\n  We apply our methods to understand trends of progression of motor impairment\nin children with Cerebral Palsy. Our model approximates individual progression\ncurves and explains 30% of the variability. Low-rank representation of\nprogression trends enables discovering that subtypes of Cerebral Palsy exhibit\ndifferent progression trends.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 06:18:13 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Kidzi\u0144ski", "\u0141ukasz", ""], ["Hastie", "Trevor", ""]]}, {"id": "1809.08782", "submitter": "Xiao Yan", "authors": "Xiao Yan, Jinfeng Li, Xinyan Dai, Hongzhi Chen, James Cheng", "title": "Norm-Ranging LSH for Maximum Inner Product Search", "comments": "NIPS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neyshabur and Srebro proposed Simple-LSH, which is the state-of-the-art\nhashing method for maximum inner product search (MIPS) with performance\nguarantee. We found that the performance of Simple-LSH, in both theory and\npractice, suffers from long tails in the 2-norm distribution of real datasets.\nWe propose Norm-ranging LSH, which addresses the excessive normalization\nproblem caused by long tails in Simple-LSH by partitioning a dataset into\nmultiple sub-datasets and building a hash index for each sub-dataset\nindependently. We prove that Norm-ranging LSH has lower query time complexity\nthan Simple-LSH. We also show that the idea of partitioning the dataset can\nimprove other hashing based methods for MIPS. To support efficient query\nprocessing on the hash indexes of the sub-datasets, a novel similarity metric\nis formulated. Experiments show that Norm-ranging LSH achieves an order of\nmagnitude speedup over Simple-LSH for the same recall, thus significantly\nbenefiting applications that involve MIPS.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 07:20:45 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 06:29:44 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Yan", "Xiao", ""], ["Li", "Jinfeng", ""], ["Dai", "Xinyan", ""], ["Chen", "Hongzhi", ""], ["Cheng", "James", ""]]}, {"id": "1809.08783", "submitter": "Bodhibrata Mukhopadhyay", "authors": "Bodhibrata Mukhopadhyay, Sahil Anchal, Subrat Kar", "title": "Person Identification using Seismic Signals generated from Footfalls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Footfall based biometric system is perhaps the only person identification\ntechnique which does not hinder the natural movement of an individual. This is\na clear edge over all other biometric systems which require a formidable amount\nof human intervention and encroach upon an individual's privacy to some extent\nor the other. This paper presents a Fog computing architecture for implementing\nfootfall based biometric system using widespread geographically distributed\ngeophones (vibration sensor). Results were stored in an Internet of Things\n(IoT) cloud. We have tested our biometric system on an indigenous database\n(created by us) containing 46000 footfall events from 8 individuals and\nachieved an accuracy of 73%, 90% and 95% in case of 1, 5 and 10 footsteps per\nsample. We also proposed a basis pursuit based data compression technique DS8BP\nfor wireless transmission of footfall events to the Fog. DS8BP compresses the\noriginal footfall events (sampled at 8 kHz) by a factor of 108 and also acts as\na smoothing filter. These experimental results depict the high viability of our\ntechnique in the realm of person identification and access control systems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 07:35:05 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Mukhopadhyay", "Bodhibrata", ""], ["Anchal", "Sahil", ""], ["Kar", "Subrat", ""]]}, {"id": "1809.08799", "submitter": "Christian Reisswig", "authors": "Anoop Raveendra Katti, Christian Reisswig, Cordula Guder, Sebastian\n  Brarda, Steffen Bickel, Johannes H\\\"ohne, Jean Baptiste Faddoul", "title": "Chargrid: Towards Understanding 2D Documents", "comments": "To be published at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel type of text representation that preserves the 2D layout\nof a document. This is achieved by encoding each document page as a\ntwo-dimensional grid of characters. Based on this representation, we present a\ngeneric document understanding pipeline for structured documents. This pipeline\nmakes use of a fully convolutional encoder-decoder network that predicts a\nsegmentation mask and bounding boxes. We demonstrate its capabilities on an\ninformation extraction task from invoices and show that it significantly\noutperforms approaches based on sequential text or document images.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 08:37:02 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Katti", "Anoop Raveendra", ""], ["Reisswig", "Christian", ""], ["Guder", "Cordula", ""], ["Brarda", "Sebastian", ""], ["Bickel", "Steffen", ""], ["H\u00f6hne", "Johannes", ""], ["Faddoul", "Jean Baptiste", ""]]}, {"id": "1809.08820", "submitter": "Hugh Salimbeni", "authors": "Hugh Salimbeni, Ching-An Cheng, Byron Boots, Marc Deisenroth", "title": "Orthogonally Decoupled Variational Gaussian Processes", "comments": "Appearing NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) provide a powerful non-parametric framework for\nreasoning over functions. Despite appealing theory, its superlinear\ncomputational and memory complexities have presented a long-standing challenge.\nState-of-the-art sparse variational inference methods trade modeling accuracy\nagainst complexity. However, the complexities of these methods still scale\nsuperlinearly in the number of basis functions, implying that that sparse GP\nmethods are able to learn from large datasets only when a small model is used.\nRecently, a decoupled approach was proposed that removes the unnecessary\ncoupling between the complexities of modeling the mean and the covariance\nfunctions of a GP. It achieves a linear complexity in the number of mean\nparameters, so an expressive posterior mean function can be modeled. While\npromising, this approach suffers from optimization difficulties due to\nill-conditioning and non-convexity. In this work, we propose an alternative\ndecoupled parametrization. It adopts an orthogonal basis in the mean function\nto model the residues that cannot be learned by the standard coupled approach.\nTherefore, our method extends, rather than replaces, the coupled approach to\nachieve strictly better performance. This construction admits a straightforward\nnatural gradient update rule, so the structure of the information manifold that\nis lost during decoupling can be leveraged to speed up learning. Empirically,\nour algorithm demonstrates significantly faster convergence in multiple\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 09:52:42 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 09:43:18 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 16:26:28 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Salimbeni", "Hugh", ""], ["Cheng", "Ching-An", ""], ["Boots", "Byron", ""], ["Deisenroth", "Marc", ""]]}, {"id": "1809.08826", "submitter": "Lyan Verwimp", "authors": "Lyan Verwimp, Joris Pelemans, Hugo Van hamme, Patrick Wambacq", "title": "Information-Weighted Neural Cache Language Models for ASR", "comments": "Accepted for publication at SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural cache language models (LMs) extend the idea of regular cache language\nmodels by making the cache probability dependent on the similarity between the\ncurrent context and the context of the words in the cache. We make an extensive\ncomparison of 'regular' cache models with neural cache models, both in terms of\nperplexity and WER after rescoring first-pass ASR results. Furthermore, we\npropose two extensions to this neural cache model that make use of the content\nvalue/information weight of the word: firstly, combining the cache probability\nand LM probability with an information-weighted interpolation and secondly,\nselectively adding only content words to the cache. We obtain a 29.9%/32.1%\n(validation/test set) relative improvement in perplexity with respect to a\nbaseline LSTM LM on the WikiText-2 dataset, outperforming previous work on\nneural cache LMs. Additionally, we observe significant WER reductions with\nrespect to the baseline model on the WSJ ASR task.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 10:07:27 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Verwimp", "Lyan", ""], ["Pelemans", "Joris", ""], ["Van hamme", "Hugo", ""], ["Wambacq", "Patrick", ""]]}, {"id": "1809.08830", "submitter": "Soroosh Shafieezadeh-Abadeh", "authors": "Soroosh Shafieezadeh-Abadeh, Viet Anh Nguyen, Daniel Kuhn, Peyman\n  Mohajerin Esfahani", "title": "Wasserstein Distributionally Robust Kalman Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a distributionally robust mean square error estimation problem over\na nonconvex Wasserstein ambiguity set containing only normal distributions. We\nshow that the optimal estimator and the least favorable distribution form a\nNash equilibrium. Despite the non-convex nature of the ambiguity set, we prove\nthat the estimation problem is equivalent to a tractable convex program. We\nfurther devise a Frank-Wolfe algorithm for this convex program whose\ndirection-searching subproblem can be solved in a quasi-closed form. Using\nthese ingredients, we introduce a distributionally robust Kalman filter that\nhedges against model risk.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 10:22:03 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 14:31:59 GMT"}, {"version": "v3", "created": "Mon, 1 Oct 2018 14:49:46 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shafieezadeh-Abadeh", "Soroosh", ""], ["Nguyen", "Viet Anh", ""], ["Kuhn", "Daniel", ""], ["Esfahani", "Peyman Mohajerin", ""]]}, {"id": "1809.08835", "submitter": "Sven Kreiss", "authors": "Changan Chen, Yuejiang Liu, Sven Kreiss, Alexandre Alahi", "title": "Crowd-Robot Interaction: Crowd-aware Robot Navigation with\n  Attention-based Deep Reinforcement Learning", "comments": "Accepted at ICRA2019. Copyright may be transferred without notice,\n  after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobility in an effective and socially-compliant manner is an essential yet\nchallenging task for robots operating in crowded spaces. Recent works have\nshown the power of deep reinforcement learning techniques to learn socially\ncooperative policies. However, their cooperation ability deteriorates as the\ncrowd grows since they typically relax the problem as a one-way Human-Robot\ninteraction problem. In this work, we want to go beyond first-order Human-Robot\ninteraction and more explicitly model Crowd-Robot Interaction (CRI). We propose\nto (i) rethink pairwise interactions with a self-attention mechanism, and (ii)\njointly model Human-Robot as well as Human-Human interactions in the deep\nreinforcement learning framework. Our model captures the Human-Human\ninteractions occurring in dense crowds that indirectly affects the robot's\nanticipation capability. Our proposed attentive pooling mechanism learns the\ncollective importance of neighboring humans with respect to their future\nstates. Various experiments demonstrate that our model can anticipate human\ndynamics and navigate in crowds with time efficiency, outperforming\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 10:54:03 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 16:59:22 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Chen", "Changan", ""], ["Liu", "Yuejiang", ""], ["Kreiss", "Sven", ""], ["Alahi", "Alexandre", ""]]}, {"id": "1809.08846", "submitter": "Pratik Dubal", "authors": "Rishabh Iyer, Pratik Dubal, Kunal Dargan, Suraj Kothawade, Rohan\n  Mahadev and Vishal Kaushal", "title": "Vis-DSS: An Open-Source toolkit for Visual Data Selection and\n  Summarization", "comments": "Vis-DSS is available at https://github.com/rishabhk108/vis-dss", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing amounts of visual data being created in the form of videos\nand images, visual data selection and summarization are becoming ever\nincreasing problems. We present Vis-DSS, an open-source toolkit for Visual Data\nSelection and Summarization. Vis-DSS implements a framework of models for\nsummarization and data subset selection using submodular functions, which are\nbecoming increasingly popular today for these problems. We present several\nclasses of models, capturing notions of diversity, coverage, representation and\nimportance, along with optimization/inference and learning algorithms. Vis-DSS\nis the first open source toolkit for several Data selection and summarization\ntasks including Image Collection Summarization, Video Summarization, Training\nData selection for Classification and Diversified Active Learning. We\ndemonstrate state-of-the art performance on all these tasks, and also show how\nwe can scale to large problems. Vis-DSS allows easy integration for\napplications to be built on it, also can serve as a general skeleton that can\nbe extended to several use cases, including video and image sharing platforms\nfor creating GIFs, image montage creation, or as a component to surveillance\nsystems and we demonstrate this by providing a graphical user-interface (GUI)\ndesktop app built over Qt framework. Vis-DSS is available at\nhttps://github.com/rishabhk108/vis-dss\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 11:15:14 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Iyer", "Rishabh", ""], ["Dubal", "Pratik", ""], ["Dargan", "Kunal", ""], ["Kothawade", "Suraj", ""], ["Mahadev", "Rohan", ""], ["Kaushal", "Vishal", ""]]}, {"id": "1809.08848", "submitter": "Piotr Warcho{\\l}", "authors": "Wojciech Tarnowski, Piotr Warcho{\\l}, Stanis{\\l}aw Jastrz\\k{e}bski,\n  Jacek Tabor, Maciej A. Nowak", "title": "Dynamical Isometry is Achieved in Residual Networks in a Universal Way\n  for any Activation Function", "comments": null, "journal-ref": "AISTATS 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that in residual neural networks (ResNets) dynamical isometry\nis achievable irrespectively of the activation function used. We do that by\nderiving, with the help of Free Probability and Random Matrix Theories, a\nuniversal formula for the spectral density of the input-output Jacobian at\ninitialization, in the large network width and depth limit. The resulting\nsingular value spectrum depends on a single parameter, which we calculate for a\nvariety of popular activation functions, by analyzing the signal propagation in\nthe artificial neural network. We corroborate our results with numerical\nsimulations of both random matrices and ResNets applied to the CIFAR-10\nclassification problem. Moreover, we study the consequence of this universal\nbehavior for the initial and late phases of the learning processes. We conclude\nby drawing attention to the simple fact, that initialization acts as a\nconfounding factor between the choice of activation function and the rate of\nlearning. We propose that in ResNets this can be resolved based on our results,\nby ensuring the same level of dynamical isometry at initialization.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 11:20:50 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 17:17:27 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 15:43:56 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Tarnowski", "Wojciech", ""], ["Warcho\u0142", "Piotr", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["Tabor", "Jacek", ""], ["Nowak", "Maciej A.", ""]]}, {"id": "1809.08854", "submitter": "Suraj Kothawade", "authors": "Vishal Kaushal, Sandeep Subramanian, Suraj Kothawade, Rishabh Iyer and\n  Ganesh Ramakrishnan", "title": "A Framework towards Domain Specific Video Summarization", "comments": "Accepted to WACV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the light of exponentially increasing video content, video summarization\nhas attracted a lot of attention recently due to its ability to optimize time\nand storage. Characteristics of a good summary of a video depend on the\nparticular domain under question. We propose a novel framework for domain\nspecific video summarization. Given a video of a particular domain, our system\ncan produce a summary based on what is important for that domain in addition to\npossessing other desired characteristics like representativeness, coverage,\ndiversity etc. as suitable to that domain. Past related work has focused either\non using supervised approaches for ranking the snippets to produce summary or\non using unsupervised approaches of generating the summary as a subset of\nsnippets with the above characteristics. We look at the joint problem of\nlearning domain specific importance of segments as well as the desired summary\ncharacteristic for that domain. Our studies show that the more efficient way of\nincorporating domain specific relevances into a summary is by obtaining ratings\nof shots as opposed to binary inclusion/exclusion information. We also argue\nthat ratings can be seen as unified representation of all possible ground truth\nsummaries of a video, taking us one step closer in dealing with challenges\nassociated with multiple ground truth summaries of a video. We also propose a\nnovel evaluation measure which is more naturally suited in assessing the\nquality of video summary for the task at hand than F1 like measures. It\nleverages the ratings information and is richer in appropriately modeling\ndesirable and undesirable characteristics of a summary. Lastly, we release a\ngold standard dataset for furthering research in domain specific video\nsummarization, which to our knowledge is the first dataset with long videos\nacross several domains with rating annotations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 11:36:53 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 08:54:33 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Kaushal", "Vishal", ""], ["Subramanian", "Sandeep", ""], ["Kothawade", "Suraj", ""], ["Iyer", "Rishabh", ""], ["Ramakrishnan", "Ganesh", ""]]}, {"id": "1809.08881", "submitter": "Dario Mantegazza", "authors": "Dario Mantegazza, J\\'er\\^ome Guzzi, Luca M. Gambardella and Alessandro\n  Giusti", "title": "Vision-based Control of a Quadrotor in User Proximity: Mediated vs\n  End-to-End Learning Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of controlling a quadrotor to hover in front of a freely\nmoving user, using input data from an onboard camera. On this specific task we\ncompare two widespread learning paradigms: a mediated approach, which learns an\nhigh-level state from the input and then uses it for deriving control signals;\nand an end-to-end approach, which skips high-level state estimation altogether.\nWe show that despite their fundamental difference, both approaches yield\nequivalent performance on this task. We finally qualitatively analyze the\nbehavior of a quadrotor implementing such approaches.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 12:49:38 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 15:02:06 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Mantegazza", "Dario", ""], ["Guzzi", "J\u00e9r\u00f4me", ""], ["Gambardella", "Luca M.", ""], ["Giusti", "Alessandro", ""]]}, {"id": "1809.08899", "submitter": "Christopher Ormerod", "authors": "Christopher M. Ormerod and Amy E. Harris", "title": "Neural network approach to classifying alarming student responses to\n  online assessment", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated scoring engines are increasingly being used to score the free-form\ntext responses that students give to questions. Such engines are not designed\nto appropriately deal with responses that a human reader would find alarming\nsuch as those that indicate an intention to self-harm or harm others, responses\nthat allude to drug abuse or sexual abuse or any response that would elicit\nconcern for the student writing the response. Our neural network models have\nbeen designed to help identify these anomalous responses from a large\ncollection of typical responses that students give. The responses identified by\nthe neural network can be assessed for urgency, severity, and validity more\nquickly by a team of reviewers than otherwise possible. Given the anomalous\nnature of these types of responses, our goal is to maximize the chance of\nflagging these responses for review given the constraint that only a fixed\npercentage of responses can viably be assessed by a team of reviewers.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 14:29:22 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Ormerod", "Christopher M.", ""], ["Harris", "Amy E.", ""]]}, {"id": "1809.08911", "submitter": "Xiao Chen", "authors": "Xiao Chen, Peter Kairouz, Ram Rajagopal", "title": "Understanding Compressive Adversarial Privacy", "comments": null, "journal-ref": "2018 IEEE Conference on Decision and Control (CDC)", "doi": "10.1109/CDC.2018.8619455", "report-no": null, "categories": "cs.LG cs.CY cs.SY eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Designing a data sharing mechanism without sacrificing too much privacy can\nbe considered as a game between data holders and malicious attackers. This\npaper describes a compressive adversarial privacy framework that captures the\ntrade-off between the data privacy and utility. We characterize the optimal\ndata releasing mechanism through convex optimization when assuming that both\nthe data holder and attacker can only modify the data using linear\ntransformations. We then build a more realistic data releasing mechanism that\ncan rely on a nonlinear compression model while the attacker uses a neural\nnetwork. We demonstrate in a series of empirical applications that this\nframework, consisting of compressive adversarial privacy, can preserve\nsensitive information.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 07:39:50 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 04:18:23 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Chen", "Xiao", ""], ["Kairouz", "Peter", ""], ["Rajagopal", "Ram", ""]]}, {"id": "1809.08922", "submitter": "Moin Nadeem", "authors": "Moin Nadeem, Dustin Stansbury, Shane Mooney", "title": "Context-Aware Systems for Sequential Item Recommendation", "comments": null, "journal-ref": null, "doi": "10.1109/ICDMW.2018.00056", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quizlet is the most popular online learning tool in the United States, and is\nused by over 2/3 of high school students, and 1/2 of college students. With\nmore than 95% of Quizlet users reporting improved grades as a result, the\nplatform has become the de-facto tool used in millions of classrooms. In this\npaper, we explore the task of recommending suitable content for a student to\nstudy, given their prior interests, as well as what their peers are studying.\nWe propose a novel approach, i.e. Neural Educational Recommendation Engine\n(NERE), to recommend educational content by leveraging student behaviors rather\nthan ratings. We have found that this approach better captures social factors\nthat are more aligned with learning. NERE is based on a recurrent neural\nnetwork that includes collaborative and content-based approaches for\nrecommendation, and takes into account any particular student's speed, mastery,\nand experience to recommend the appropriate task. We train NERE by jointly\nlearning the user embeddings and content embeddings, and attempt to predict the\ncontent embedding for the final timestamp. We also develop a confidence\nestimator for our neural network, which is a crucial requirement for\nproductionizing this model. We apply NERE to Quizlet's proprietary dataset, and\npresent our results. We achieved an R^2 score of 0.81 in the content embedding\nspace, and a recall score of 54% on our 100 nearest neighbors. This vastly\nexceeds the recall@100 score of 12% that a standard matrix-factorization\napproach provides. We conclude with a discussion on how NERE will be deployed,\nand position our work as one of the first educational recommender systems for\nthe K-12 space.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 03:48:52 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 21:30:12 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Nadeem", "Moin", ""], ["Stansbury", "Dustin", ""], ["Mooney", "Shane", ""]]}, {"id": "1809.08923", "submitter": "Yue Wang", "authors": "Yue Wang, Qi Meng, Wei Cheng, Yuting Liug, Zhi-Ming Ma, Tie-Yan Liu", "title": "Target Transfer Q-Learning and Its Convergence Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning is one of the most popular methods in Reinforcement Learning (RL).\nTransfer Learning aims to utilize the learned knowledge from source tasks to\nhelp new tasks to improve the sample complexity of the new tasks. Considering\nthat data collection in RL is both more time and cost consuming and Q-learning\nconverges slowly comparing to supervised learning, different kinds of transfer\nRL algorithms are designed. However, most of them are heuristic with no\ntheoretical guarantee of the convergence rate. Therefore, it is important for\nus to clearly understand when and how will transfer learning help RL method and\nprovide the theoretical guarantee for the improvement of the sample complexity.\nIn this paper, we propose to transfer the Q-function learned in the source task\nto the target of the Q-learning in the new task when certain safe conditions\nare satisfied. We call this new transfer Q-learning method target transfer\nQ-Learning. The safe conditions are necessary to avoid the harm to the new\ntasks and thus ensure the convergence of the algorithm. We study the\nconvergence rate of the target transfer Q-learning. We prove that if the two\ntasks are similar with respect to the MDPs, the optimal Q-functions in the\nsource and new RL tasks are similar which means the error of the transferred\ntarget Q-function in new MDP is small. Also, the convergence rate analysis\nshows that the target transfer Q-Learning will converge faster than Q-learning\nif the error of the transferred target Q-function is smaller than the current\nQ-function in the new task. Based on our theoretical results, we design the\nsafe condition as the Bellman error of the transferred target Q-function is\nless than the current Q-function. Our experiments are consistent with our\ntheoretical founding and verified the effectiveness of our proposed target\ntransfer Q-learning method.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 05:31:26 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Wang", "Yue", ""], ["Meng", "Qi", ""], ["Cheng", "Wei", ""], ["Liug", "Yuting", ""], ["Ma", "Zhi-Ming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1809.08925", "submitter": "Tu-Hoa Pham", "authors": "Tu-Hoa Pham, Giovanni De Magistris, Don Joven Agravante, Subhajit\n  Chaudhury, Asim Munawar, Ryuki Tachibana", "title": "Constrained Exploration and Recovery from Experience Shaping", "comments": "Code: https://github.com/IBM/constrained-rl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reinforcement learning under safety requirements,\nin which an agent is trained to complete a given task, typically formalized as\nthe maximization of a reward signal over time, while concurrently avoiding\nundesirable actions or states, associated to lower rewards, or penalties. The\nconstruction and balancing of different reward components can be difficult in\nthe presence of multiple objectives, yet is crucial for producing a satisfying\npolicy. For example, in reaching a target while avoiding obstacles, low\ncollision penalties can lead to reckless movements while high penalties can\ndiscourage exploration. To circumvent this limitation, we examine the effect of\npast actions in terms of safety to estimate which are acceptable or should be\navoided in the future. We then actively reshape the action space of the agent\nduring reinforcement learning, so that reward-driven exploration is constrained\nwithin safety limits. We propose an algorithm enabling the learning of such\nsafety constraints in parallel with reinforcement learning and demonstrate its\neffectiveness in terms of both task completion and training time.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 06:11:11 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Pham", "Tu-Hoa", ""], ["De Magistris", "Giovanni", ""], ["Agravante", "Don Joven", ""], ["Chaudhury", "Subhajit", ""], ["Munawar", "Asim", ""], ["Tachibana", "Ryuki", ""]]}, {"id": "1809.08926", "submitter": "Yue Wang", "authors": "Yue Wang, Wei Chen, Yuting Liu, Zhi-Ming Ma, Tie-Yan Liu", "title": "Finite Sample Analysis of the GTD Policy Evaluation Algorithms in Markov\n  Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL) , one of the key components is policy\nevaluation, which aims to estimate the value function (i.e., expected long-term\naccumulated reward) of a policy. With a good policy evaluation method, the RL\nalgorithms will estimate the value function more accurately and find a better\npolicy. When the state space is large or continuous \\emph{Gradient-based\nTemporal Difference(GTD)} policy evaluation algorithms with linear function\napproximation are widely used. Considering that the collection of the\nevaluation data is both time and reward consuming, a clear understanding of the\nfinite sample performance of the policy evaluation algorithms is very important\nto reinforcement learning. Under the assumption that data are i.i.d. generated,\nprevious work provided the finite sample analysis of the GTD algorithms with\nconstant step size by converting them into convex-concave saddle point\nproblems. However, it is well-known that, the data are generated from Markov\nprocesses rather than i.i.d. in RL problems.. In this paper, in the realistic\nMarkov setting, we derive the finite sample bounds for the general\nconvex-concave saddle point problems, and hence for the GTD algorithms. We have\nthe following discussions based on our bounds. (1) With variants of step size,\nGTD algorithms converge. (2) The convergence rate is determined by the step\nsize, with the mixing time of the Markov process as the coefficient. The faster\nthe Markov processes mix, the faster the convergence. (3) We explain that the\nexperience replay trick is effective by improving the mixing property of the\nMarkov process. To the best of our knowledge, our analysis is the first to\nprovide finite sample bounds for the GTD algorithms in Markov setting.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 06:09:21 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Wang", "Yue", ""], ["Chen", "Wei", ""], ["Liu", "Yuting", ""], ["Ma", "Zhi-Ming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1809.08986", "submitter": "Pin-Yu Chen", "authors": "Chia-Yi Hsu, Pei-Hsuan Lu, Pin-Yu Chen, Chia-Mu Yu", "title": "On The Utility of Conditional Generation Based Mutual Information for\n  Characterizing Adversarial Subspaces", "comments": "Accepted to IEEE GlobalSIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have found that deep learning systems are vulnerable to\nadversarial examples; e.g., visually unrecognizable adversarial images can\neasily be crafted to result in misclassification. The robustness of neural\nnetworks has been studied extensively in the context of adversary detection,\nwhich compares a metric that exhibits strong discriminate power between natural\nand adversarial examples. In this paper, we propose to characterize the\nadversarial subspaces through the lens of mutual information (MI) approximated\nby conditional generation methods. We use MI as an information-theoretic metric\nto strengthen existing defenses and improve the performance of adversary\ndetection. Experimental results on MagNet defense demonstrate that our proposed\nMI detector can strengthen its robustness against powerful adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 15:05:01 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Hsu", "Chia-Yi", ""], ["Lu", "Pei-Hsuan", ""], ["Chen", "Pin-Yu", ""], ["Yu", "Chia-Mu", ""]]}, {"id": "1809.08999", "submitter": "Ali Dabouei", "authors": "Ali Dabouei, Sobhan Soleymani, Jeremy Dawson, Nasser M. Nasrabadi", "title": "Fast Geometrically-Perturbed Adversarial Faces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art performance of deep learning algorithms has led to a\nconsiderable increase in the utilization of machine learning in\nsecurity-sensitive and critical applications. However, it has recently been\nshown that a small and carefully crafted perturbation in the input space can\ncompletely fool a deep model. In this study, we explore the extent to which\nface recognition systems are vulnerable to geometrically-perturbed adversarial\nfaces. We propose a fast landmark manipulation method for generating\nadversarial faces, which is approximately 200 times faster than the previous\ngeometric attacks and obtains 99.86% success rate on the state-of-the-art face\nrecognition models. To further force the generated samples to be natural, we\nintroduce a second attack constrained on the semantic structure of the face\nwhich has the half speed of the first attack with the success rate of 99.96%.\nBoth attacks are extremely robust against the state-of-the-art defense methods\nwith the success rate of equal or greater than 53.59%. Code is available at\nhttps://github.com/alldbi/FLM\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 15:26:13 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 17:20:54 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Dabouei", "Ali", ""], ["Soleymani", "Sobhan", ""], ["Dawson", "Jeremy", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "1809.09003", "submitter": "Ting Yu Mu", "authors": "Ting-Yu Mu, Ala Al-Fuqaha, Khaled Shuaib, Farag M. Sallabi, Junaid\n  Qadir", "title": "SDN Flow Entry Management Using Reinforcement Learning", "comments": "19 pages, 11 figures, published on ACM Transactions on Autonomous and\n  Adaptive Systems (TAAS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern information technology services largely depend on cloud\ninfrastructures to provide their services. These cloud infrastructures are\nbuilt on top of datacenter networks (DCNs) constructed with high-speed links,\nfast switching gear, and redundancy to offer better flexibility and resiliency.\nIn this environment, network traffic includes long-lived (elephant) and\nshort-lived (mice) flows with partitioned and aggregated traffic patterns.\nAlthough SDN-based approaches can efficiently allocate networking resources for\nsuch flows, the overhead due to network reconfiguration can be significant.\nWith limited capacity of Ternary Content-Addressable Memory (TCAM) deployed in\nan OpenFlow enabled switch, it is crucial to determine which forwarding rules\nshould remain in the flow table, and which rules should be processed by the SDN\ncontroller in case of a table-miss on the SDN switch. This is needed in order\nto obtain the flow entries that satisfy the goal of reducing the long-term\ncontrol plane overhead introduced between the controller and the switches. To\nachieve this goal, we propose a machine learning technique that utilizes two\nvariations of reinforcement learning (RL) algorithms-the first of which is\ntraditional reinforcement learning algorithm based while the other is deep\nreinforcement learning based. Emulation results using the RL algorithm show\naround 60% improvement in reducing the long-term control plane overhead, and\naround 14% improvement in the table-hit ratio compared to the Multiple Bloom\nFilters (MBF) method given a fixed size flow table of 4KB.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 15:29:06 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Mu", "Ting-Yu", ""], ["Al-Fuqaha", "Ala", ""], ["Shuaib", "Khaled", ""], ["Sallabi", "Farag M.", ""], ["Qadir", "Junaid", ""]]}, {"id": "1809.09030", "submitter": "Golnoosh Farnadi", "authors": "Golnoosh Farnadi and Pigi Kouki and Spencer K. Thompson and Sriram\n  Srinivasan and Lise Getoor", "title": "A Fairness-aware Hybrid Recommender System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recommender systems are used in variety of domains affecting people's lives.\nThis has raised concerns about possible biases and discrimination that such\nsystems might exacerbate. There are two primary kinds of biases inherent in\nrecommender systems: observation bias and bias stemming from imbalanced data.\nObservation bias exists due to a feedback loop which causes the model to learn\nto only predict recommendations similar to previous ones. Imbalance in data\noccurs when systematic societal, historical, or other ambient bias is present\nin the data. In this paper, we address both biases by proposing a hybrid\nfairness-aware recommender system. Our model provides efficient and accurate\nrecommendations by incorporating multiple user-user and item-item similarity\nmeasures, content, and demographic information, while addressing recommendation\nbiases. We implement our model using a powerful and expressive probabilistic\nprogramming language called probabilistic soft logic. We experimentally\nevaluate our approach on a popular movie recommendation dataset, showing that\nour proposed model can provide more accurate and fairer recommendations,\ncompared to a state-of-the art fair recommender system.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 00:30:52 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Farnadi", "Golnoosh", ""], ["Kouki", "Pigi", ""], ["Thompson", "Spencer K.", ""], ["Srinivasan", "Sriram", ""], ["Getoor", "Lise", ""]]}, {"id": "1809.09035", "submitter": "Mohammad Shojafar", "authors": "Deepa K, Radhamani G, Vinod P, Mohammad Shojafar, Neeraj Kumar, Mauro\n  Conti", "title": "FeatureAnalytics: An approach to derive relevant attributes for\n  analyzing Android Malware", "comments": "26 pages, 6 figures, 9 tables, Journal Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ever increasing number of Android malware, has always been a concern for\ncybersecurity professionals. Even though plenty of anti-malware solutions\nexist, a rational and pragmatic approach for the same is rare and has to be\ninspected further. In this paper, we propose a novel two-set feature selection\napproach based on Rough Set and Statistical Test named as RSST to extract\nrelevant system calls. To address the problem of higher dimensional attribute\nset, we derived suboptimal system call space by applying the proposed feature\nselection method to maximize the separability between malware and benign\nsamples. Comprehensive experiments conducted on a dataset consisting of 3500\nsamples with 30 RSST derived essential system calls resulted in an accuracy of\n99.9%, Area Under Curve (AUC) of 1.0, with 1% False Positive Rate (FPR).\nHowever, other feature selectors (Information Gain, CFsSubsetEval, ChiSquare,\nFreqSel and Symmetric Uncertainty) used in the domain of malware analysis\nresulted in the accuracy of 95.5% with 8.5% FPR. Besides, empirical analysis of\nRSST derived system calls outperform other attributes such as permissions,\nopcodes, API, methods, call graphs, Droidbox attributes and network traces.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 15:08:36 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["K", "Deepa", ""], ["G", "Radhamani", ""], ["P", "Vinod", ""], ["Shojafar", "Mohammad", ""], ["Kumar", "Neeraj", ""], ["Conti", "Mauro", ""]]}, {"id": "1809.09060", "submitter": "Isidro Cortes-Ciriano PhD", "authors": "Isidro Cortes-Ciriano and Andreas Bender", "title": "Deep Confidence: A Computationally Efficient Framework for Calculating\n  Reliable Errors for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jcim.8b00542", "report-no": null, "categories": "cs.LG cs.AI q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning architectures have proved versatile in a number of drug\ndiscovery applications, including the modelling of in vitro compound activity.\nWhile controlling for prediction confidence is essential to increase the trust,\ninterpretability and usefulness of virtual screening models in drug discovery,\ntechniques to estimate the reliability of the predictions generated with deep\nlearning networks remain largely underexplored. Here, we present Deep\nConfidence, a framework to compute valid and efficient confidence intervals for\nindividual predictions using the deep learning technique Snapshot Ensembling\nand conformal prediction. Specifically, Deep Confidence generates an ensemble\nof deep neural networks by recording the network parameters throughout the\nlocal minima visited during the optimization phase of a single neural network.\nThis approach serves to derive a set of base learners (i.e., snapshots) with\ncomparable predictive power on average, that will however generate slightly\ndifferent predictions for a given instance. The variability across base\nlearners and the validation residuals are in turn harnessed to compute\nconfidence intervals using the conformal prediction framework. Using a set of\n24 diverse IC50 data sets from ChEMBL 23, we show that Snapshot Ensembles\nperform on par with Random Forest (RF) and ensembles of independently trained\ndeep neural networks. In addition, we find that the confidence regions\npredicted using the Deep Confidence framework span a narrower set of values.\nOverall, Deep Confidence represents a highly versatile error prediction\nframework that can be applied to any deep learning-based application at no\nextra computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 17:08:08 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Cortes-Ciriano", "Isidro", ""], ["Bender", "Andreas", ""]]}, {"id": "1809.09081", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Andri Ashfahani, Yew Soon Ong, Savitha Ramasamy\n  and Edwin Lughofer", "title": "Autonomous Deep Learning: Incremental Learning of Denoising Autoencoder\n  for Evolving Data Streams", "comments": "have been submitted to AAAI 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generative learning phase of Autoencoder (AE) and its successor Denosing\nAutoencoder (DAE) enhances the flexibility of data stream method in exploiting\nunlabelled samples. Nonetheless, the feasibility of DAE for data stream\nanalytic deserves in-depth study because it characterizes a fixed network\ncapacity which cannot adapt to rapidly changing environments. An automated\nconstruction of a denoising autoeconder, namely deep evolving denoising\nautoencoder (DEVDAN), is proposed in this paper. DEVDAN features an open\nstructure both in the generative phase and in the discriminative phase where\ninput features can be automatically added and discarded on the fly. A network\nsignificance (NS) method is formulated in this paper and is derived from the\nbias-variance concept. This method is capable of estimating the statistical\ncontribution of the network structure and its hidden units which precursors an\nideal state to add or prune input features. Furthermore, DEVDAN is free of the\nproblem- specific threshold and works fully in the single-pass learning\nfashion. The efficacy of DEVDAN is numerically validated using nine\nnon-stationary data stream problems simulated under the prequential\ntest-then-train protocol where DEVDAN is capable of delivering an improvement\nof classification accuracy to recently published online learning works while\nhaving flexibility in the automatic extraction of robust input features and in\nadapting to rapidly changing environments.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 17:49:09 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Ashfahani", "Andri", ""], ["Ong", "Yew Soon", ""], ["Ramasamy", "Savitha", ""], ["Lughofer", "Edwin", ""]]}, {"id": "1809.09087", "submitter": "Ke Li", "authors": "Ke Li and Jitendra Malik", "title": "Implicit Maximum Likelihood Estimation", "comments": "21 pages, 4 figures. In the interest of promoting discussion, we make\n  the reviews available at\n  https://people.eecs.berkeley.edu/~ke.li/papers/imle_reviews.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit probabilistic models are models defined naturally in terms of a\nsampling procedure and often induces a likelihood function that cannot be\nexpressed explicitly. We develop a simple method for estimating parameters in\nimplicit models that does not require knowledge of the form of the likelihood\nfunction or any derived quantities, but can be shown to be equivalent to\nmaximizing likelihood under some conditions. Our result holds in the\nnon-asymptotic parametric setting, where both the capacity of the model and the\nnumber of data examples are finite. We also demonstrate encouraging\nexperimental results.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 17:57:25 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 17:56:37 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Li", "Ke", ""], ["Malik", "Jitendra", ""]]}, {"id": "1809.09095", "submitter": "Yang Yu", "authors": "Zhen-Jia Pang, Ruo-Ze Liu, Zhou-Yu Meng, Yi Zhang, Yang Yu, Tong Lu", "title": "On Reinforcement Learning for Full-length Game of StarCraft", "comments": "Appeared in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  StarCraft II poses a grand challenge for reinforcement learning. The main\ndifficulties of it include huge state and action space and a long-time horizon.\nIn this paper, we investigate a hierarchical reinforcement learning approach\nfor StarCraft II. The hierarchy involves two levels of abstraction. One is the\nmacro-action automatically extracted from expert's trajectories, which reduces\nthe action space in an order of magnitude yet remains effective. The other is a\ntwo-layer hierarchical architecture which is modular and easy to scale,\nenabling a curriculum transferring from simpler tasks to more complex tasks.\nThe reinforcement training algorithm for this architecture is also\ninvestigated. On a 64x64 map and using restrictive units, we achieve a winning\nrate of more than 99\\% against the difficulty level-1 built-in AI. Through the\ncurriculum transfer learning algorithm and a mixture of combat model, we can\nachieve over 93\\% winning rate of Protoss against the most difficult\nnon-cheating built-in AI (level-7) of Terran, training within two days using a\nsingle machine with only 48 CPU cores and 8 K40 GPUs. It also shows strong\ngeneralization performance, when tested against never seen opponents including\ncheating levels built-in AI and all levels of Zerg and Protoss built-in AI. We\nhope this study could shed some light on the future research of large-scale\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 15:48:28 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 18:00:54 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Pang", "Zhen-Jia", ""], ["Liu", "Ruo-Ze", ""], ["Meng", "Zhou-Yu", ""], ["Zhang", "Yi", ""], ["Yu", "Yang", ""], ["Lu", "Tong", ""]]}, {"id": "1809.09096", "submitter": "Davide Bacciu", "authors": "Davide Bacciu and Antonio Bruno", "title": "Text Summarization as Tree Transduction by Top-Down TreeLSTM", "comments": "To appear in IEEE SCCI Deep Learning 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extractive compression is a challenging natural language processing problem.\nThis work contributes by formulating neural extractive compression as a parse\ntree transduction problem, rather than a sequence transduction task. Motivated\nby this, we introduce a deep neural model for learning\nstructure-to-substructure tree transductions by extending the standard Long\nShort-Term Memory, considering the parent-child relationships in the structural\nrecursion. The proposed model can achieve state of the art performance on\nsentence compression benchmarks, both in terms of accuracy and compression\nrate.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 11:00:57 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Bacciu", "Davide", ""], ["Bruno", "Antonio", ""]]}, {"id": "1809.09143", "submitter": "Kexin Huang", "authors": "Kexin Huang, Rodrigo Nogueira", "title": "EpiRL: A Reinforcement Learning Agent to Facilitate Epistasis Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epistasis (gene-gene interaction) is crucial to predicting genetic disease.\nOur work tackles the computational challenges faced by previous works in\nepistasis detection by modeling it as a one-step Markov Decision Process where\nthe state is genome data, the actions are the interacted genes, and the reward\nis an interaction measurement for the selected actions. A reinforcement\nlearning agent using policy gradient method then learns to discover a set of\nhighly interacted genes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 18:10:17 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Huang", "Kexin", ""], ["Nogueira", "Rodrigo", ""]]}, {"id": "1809.09147", "submitter": "Akshat Agarwal", "authors": "Akshat Agarwal, Abhinau Kumar V, Kyle Dunovan, Erik Peterson, Timothy\n  Verstynen, Katia Sycara", "title": "Better Safe than Sorry: Evidence Accumulation Allows for Safe\n  Reinforcement Learning", "comments": "8 pages, 3 figures. Code available at\n  https://github.com/agakshat/evidence-accumulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, agents often have to operate in situations with incomplete\ninformation, limited sensing capabilities, and inherently stochastic\nenvironments, making individual observations incomplete and unreliable.\nMoreover, in many situations it is preferable to delay a decision rather than\nrun the risk of making a bad decision. In such situations it is necessary to\naggregate information before taking an action; however, most state of the art\nreinforcement learning (RL) algorithms are biased towards taking actions\n\\textit{at every time step}, even if the agent is not particularly confident in\nits chosen action. This lack of caution can lead the agent to make critical\nmistakes, regardless of prior experience and acclimation to the environment.\nMotivated by theories of dynamic resolution of uncertainty during decision\nmaking in biological brains, we propose a simple accumulator module which\naccumulates evidence in favor of each possible decision, encodes uncertainty as\na dynamic competition between actions, and acts on the environment only when it\nis sufficiently confident in the chosen action. The agent makes no decision by\ndefault, and the burden of proof to make a decision falls on the policy to\naccrue evidence strongly in favor of a single decision. Our results show that\nthis accumulator module achieves near-optimal performance on a simple guessing\ngame, far outperforming deep recurrent networks using traditional, forced\naction selection policies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 18:13:01 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Agarwal", "Akshat", ""], ["Kumar", "Abhinau", "V"], ["Dunovan", "Kyle", ""], ["Peterson", "Erik", ""], ["Verstynen", "Timothy", ""], ["Sycara", "Katia", ""]]}, {"id": "1809.09165", "submitter": "Vitaly Feldman", "authors": "Amit Daniely and Vitaly Feldman", "title": "Locally Private Learning without Interaction Requires Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning under the constraint of local differential privacy\n(LDP). For many learning problems known efficient algorithms in this model\nrequire many rounds of communication between the server and the clients holding\nthe data points. Yet multi-round protocols are prohibitively slow in practice\ndue to network latency and, as a result, currently deployed large-scale systems\nare limited to a single round. Despite significant research interest, very\nlittle is known about which learning problems can be solved by such\nnon-interactive systems. The only lower bound we are aware of is for PAC\nlearning an artificial class of functions with respect to a uniform\ndistribution (Kasiviswanathan et al. 2011).\n  We show that the margin complexity of a class of Boolean functions is a lower\nbound on the complexity of any non-interactive LDP algorithm for\ndistribution-independent PAC learning of the class. In particular, the classes\nof linear separators and decision lists require exponential number of samples\nto learn non-interactively even though they can be learned in polynomial time\nby an interactive LDP algorithm. This gives the first example of a natural\nproblem that is significantly harder to solve without interaction and also\nresolves an open problem of Kasiviswanathan et al. (2011). We complement this\nlower bound with a new efficient learning algorithm whose complexity is\npolynomial in the margin complexity of the class. Our algorithm is\nnon-interactive on labeled samples but still needs interactive access to\nunlabeled samples. All of our results also apply to the statistical query model\nand any model in which the number of bits communicated about each data point is\nconstrained.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 18:57:36 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 02:35:29 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 06:20:12 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Daniely", "Amit", ""], ["Feldman", "Vitaly", ""]]}, {"id": "1809.09170", "submitter": "Kailiang Wu", "authors": "Kailiang Wu, Dongbin Xiu", "title": "Numerical Aspects for Approximating Governing Equations Using Data", "comments": "26 pages, 17 figures", "journal-ref": "Journal of Computational Physics, 384, 200-221, 2019", "doi": "10.1016/j.jcp.2019.01.030", "report-no": null, "categories": "math.NA cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present effective numerical algorithms for locally recovering unknown\ngoverning differential equations from measurement data. We employ a set of\nstandard basis functions, e.g., polynomials, to approximate the governing\nequation with high accuracy. Upon recasting the problem into a function\napproximation problem, we discuss several important aspects for accurate\napproximation. Most notably, we discuss the importance of using a large number\nof short bursts of trajectory data, rather than using data from a single long\ntrajectory. Several options for the numerical algorithms to perform accurate\napproximation are then presented, along with an error estimate of the final\nequation approximation. We then present an extensive set of numerical examples\nof both linear and nonlinear systems to demonstrate the properties and\neffectiveness of our equation recovery algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 19:11:32 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wu", "Kailiang", ""], ["Xiu", "Dongbin", ""]]}, {"id": "1809.09215", "submitter": "Tavpritesh Sethi", "authors": "Tavpritesh Sethi, Anant Mittal, Shubham Maheshwari, Samarth Chugh", "title": "Learning to Address Health Inequality in the United States with a\n  Bayesian Decision Network", "comments": "8 pages, 4 figures, 1 table (excluding the supplementary material),\n  accepted for publication in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Life-expectancy is a complex outcome driven by genetic, socio-demographic,\nenvironmental and geographic factors. Increasing socio-economic and health\ndisparities in the United States are propagating the longevity-gap, making it a\ncause for concern. Earlier studies have probed individual factors but an\nintegrated picture to reveal quantifiable actions has been missing. There is a\ngrowing concern about a further widening of healthcare inequality caused by\nArtificial Intelligence (AI) due to differential access to AI-driven services.\nHence, it is imperative to explore and exploit the potential of AI for\nilluminating biases and enabling transparent policy decisions for positive\nsocial and health impact. In this work, we reveal actionable interventions for\ndecreasing the longevity-gap in the United States by analyzing a County-level\ndata resource containing healthcare, socio-economic, behavioral, education and\ndemographic features. We learn an ensemble-averaged structure, draw inferences\nusing the joint probability distribution and extend it to a Bayesian Decision\nNetwork for identifying policy actions. We draw quantitative estimates for the\nimpact of diversity, preventive-care quality and stable-families within the\nunified framework of our decision network. Finally, we make this analysis and\ndashboard available as an interactive web-application for enabling users and\npolicy-makers to validate our reported findings and to explore the impact of\nones beyond reported in this work.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 00:24:06 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 04:20:50 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Sethi", "Tavpritesh", ""], ["Mittal", "Anant", ""], ["Maheshwari", "Shubham", ""], ["Chugh", "Samarth", ""]]}, {"id": "1809.09219", "submitter": "Xiaolin Huang", "authors": "Fan He, Xiaolin Huang, Yipeng Liu, Ming Yan", "title": "Fast Signal Recovery from Saturated Measurements by Linear Loss and\n  Nonconvex Penalties", "comments": null, "journal-ref": "IEEE Signal Processing Letters, 25 (2018) 1374-1378", "doi": "10.1109/LSP.2018.2860242", "report-no": null, "categories": "cs.IT cs.LG math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign information is the key to overcoming the inevitable saturation error in\ncompressive sensing systems, which causes information loss and results in bias.\nFor sparse signal recovery from saturation, we propose to use a linear loss to\nimprove the effectiveness from existing methods that utilize hard\nconstraints/hinge loss for sign consistency. Due to the use of linear loss, an\nanalytical solution in the update progress is obtained, and some nonconvex\npenalties are applicable, e.g., the minimax concave penalty, the $\\ell_0$ norm,\nand the sorted $\\ell_1$ norm. Theoretical analysis reveals that the estimation\nerror can still be bounded. Generally, with linear loss and nonconvex\npenalties, the recovery performance is significantly improved, and the\ncomputational time is largely saved, which is verified by the numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 01:05:43 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["He", "Fan", ""], ["Huang", "Xiaolin", ""], ["Liu", "Yipeng", ""], ["Yan", "Ming", ""]]}, {"id": "1809.09244", "submitter": "Michele Covell", "authors": "Shumeet Baluja and David Marwood and Michele Covell and Nick Johnston", "title": "No Multiplication? No Floating Point? No Problem! Training Networks for\n  Efficient Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For successful deployment of deep neural networks on\nhighly--resource-constrained devices (hearing aids, earbuds, wearables), we\nmust simplify the types of operations and the memory/power resources used\nduring inference. Completely avoiding inference-time floating-point operations\nis one of the simplest ways to design networks for these highly-constrained\nenvironments. By discretizing both our in-network non-linearities and our\nnetwork weights, we can move to simple, compact networks without floating point\noperations, without multiplications, and avoid all non-linear function\ncomputations. Our approach allows us to explore the spectrum of possible\nnetworks, ranging from fully continuous versions down to networks with bi-level\nweights and activations. Our results show that discretization can be done\nwithout loss of performance and that we can train a network that will\nsuccessfully operate without floating-point, without multiplication, and with\nless RAM on both regression tasks (auto encoding) and multi-class\nclassification tasks (ImageNet). The memory needed to deploy our discretized\nnetworks is less than one third of the equivalent architecture that does use\nfloating-point operations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 22:29:24 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 16:11:32 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Baluja", "Shumeet", ""], ["Marwood", "David", ""], ["Covell", "Michele", ""], ["Johnston", "Nick", ""]]}, {"id": "1809.09245", "submitter": "John Henry Hinnefeld", "authors": "J. Henry Hinnefeld, Peter Cooman, Nat Mammo, Rupert Deese", "title": "Evaluating Fairness Metrics in the Presence of Dataset Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven algorithms play a large role in decision making across a variety\nof industries. Increasingly, these algorithms are being used to make decisions\nthat have significant ramifications for people's social and economic\nwell-being, e.g. in sentencing, loan approval, and policing. Amid the\nproliferation of such systems there is a growing concern about their potential\ndiscriminatory impact. In particular, machine learning systems which are\ntrained on biased data have the potential to learn and perpetuate those biases.\nA central challenge for practitioners is thus to determine whether their models\ndisplay discriminatory bias. Here we present a case study in which we frame the\nissue of bias detection as a causal inference problem with observational data.\nWe enumerate two main causes of bias, sampling bias and label bias, and we\ninvestigate the abilities of six different fairness metrics to detect each bias\ntype. Based on these investigations, we propose a set of best practice\nguidelines to select the fairness metric that is most likely to detect bias if\nit is present. Additionally, we aim to identify the conditions in which certain\nfairness metrics may fail to detect bias and instead give practitioners a false\nbelief that their biased model is making fair decisions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 22:32:05 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Hinnefeld", "J. Henry", ""], ["Cooman", "Peter", ""], ["Mammo", "Nat", ""], ["Deese", "Rupert", ""]]}, {"id": "1809.09258", "submitter": "Yi Zhou", "authors": "Guanghui Lan, Yi Zhou", "title": "Asynchronous decentralized accelerated stochastic gradient descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce an asynchronous decentralized accelerated\nstochastic gradient descent type of method for decentralized stochastic\noptimization, considering communication and synchronization are the major\nbottlenecks. We establish $\\mathcal{O}(1/\\epsilon)$ (resp.,\n$\\mathcal{O}(1/\\sqrt{\\epsilon})$) communication complexity and\n$\\mathcal{O}(1/\\epsilon^2)$ (resp., $\\mathcal{O}(1/\\epsilon)$) sampling\ncomplexity for solving general convex (resp., strongly convex) problems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 23:40:29 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Lan", "Guanghui", ""], ["Zhou", "Yi", ""]]}, {"id": "1809.09260", "submitter": "Jeffrey McKinstry", "authors": "Jeffrey L Mckinstry, Davis R. Barch, Deepika Bablani, Michael V.\n  Debole, Steven K. Esser, Jeffrey A. Kusnitz, John V. Arthur, Dharmendra S.\n  Modha", "title": "Low Precision Policy Distillation with Application to Low-Power,\n  Real-time Sensation-Cognition-Action Loop with Neuromorphic Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low precision networks in the reinforcement learning (RL) setting are\nrelatively unexplored because of the limitations of binary activations for\nfunction approximation. Here, in the discrete action ATARI domain, we\ndemonstrate, for the first time, that low precision policy distillation from a\nhigh precision network provides a principled, practical way to train an RL\nagent. As an application, on 10 different ATARI games, we demonstrate real-time\nend-to-end game playing on low-power neuromorphic hardware by converting a\nsequence of game frames into discrete actions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 00:03:33 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Mckinstry", "Jeffrey L", ""], ["Barch", "Davis R.", ""], ["Bablani", "Deepika", ""], ["Debole", "Michael V.", ""], ["Esser", "Steven K.", ""], ["Kusnitz", "Jeffrey A.", ""], ["Arthur", "John V.", ""], ["Modha", "Dharmendra S.", ""]]}, {"id": "1809.09261", "submitter": "Aleksandra Faust", "authors": "Aleksandra Faust, James B. Aimone, Conrad D. James and Lydia Tapia", "title": "Resilient Computing with Reinforcement Learning on a Dynamical System:\n  Case Study in Sorting", "comments": "11 pages, accepted to CDC 2018. Here with additional evaluations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots and autonomous agents often complete goal-based tasks with limited\nresources, relying on imperfect models and sensor measurements. In particular,\nreinforcement learning (RL) and feedback control can be used to help a robot\nachieve a goal. Taking advantage of this body of work, this paper formulates\ngeneral computation as a feedback-control problem, which allows the agent to\nautonomously overcome some limitations of standard procedural language\nprogramming: resilience to errors and early program termination. Our\nformulation considers computation to be trajectory generation in the program's\nvariable space. The computing then becomes a sequential decision making\nproblem, solved with reinforcement learning (RL), and analyzed with Lyapunov\nstability theory to assess the agent's resilience and progression to the goal.\nWe do this through a case study on a quintessential computer science problem,\narray sorting. Evaluations show that our RL sorting agent makes steady progress\nto an asymptotically stable goal, is resilient to faulty components, and\nperforms less array manipulations than traditional Quicksort and Bubble sort.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 00:07:20 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Faust", "Aleksandra", ""], ["Aimone", "James B.", ""], ["James", "Conrad D.", ""], ["Tapia", "Lydia", ""]]}, {"id": "1809.09262", "submitter": "Luca de Alfaro", "authors": "Luca de Alfaro", "title": "Neural Networks with Structural Resistance to Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial attacks to machine-learning classifiers, small perturbations\nare added to input that is correctly classified. The perturbations yield\nadversarial examples, which are virtually indistinguishable from the\nunperturbed input, and yet are misclassified. In standard neural networks used\nfor deep learning, attackers can craft adversarial examples from most input to\ncause a misclassification of their choice.\n  We introduce a new type of network units, called RBFI units, whose non-linear\nstructure makes them inherently resistant to adversarial attacks. On\npermutation-invariant MNIST, in absence of adversarial attacks, networks using\nRBFI units match the performance of networks using sigmoid units, and are\nslightly below the accuracy of networks with ReLU units. When subjected to\nadversarial attacks, networks with RBFI units retain accuracies above 90% for\nattacks that degrade the accuracy of networks with ReLU or sigmoid units to\nbelow 2%. RBFI networks trained with regular input are superior in their\nresistance to adversarial attacks even to ReLU and sigmoid networks trained\nwith the help of adversarial examples.\n  The non-linear structure of RBFI units makes them difficult to train using\nstandard gradient descent. We show that networks of RBFI units can be\nefficiently trained to high accuracies using pseudogradients, computed using\nfunctions especially crafted to facilitate learning instead of their true\nderivatives. We show that the use of pseudogradients makes training deep RBFI\nnetworks practical, and we compare several structural alternatives of RBFI\nnetworks for their accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 00:08:10 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["de Alfaro", "Luca", ""]]}, {"id": "1809.09266", "submitter": "Ioannis Schizas", "authors": "Ioannis D. Schizas", "title": "Graph filtering for data reduction and reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach is put forth that utilizes data similarity, quantified on a\ngraph, to improve upon the reconstruction performance of principal component\nanalysis. The tasks of data dimensionality reduction and reconstruction are\nformulated as graph filtering operations, that enable the exploitation of data\nnode connectivity in a graph via the adjacency matrix. The unknown reducing and\nreconstruction filters are determined by optimizing a mean-square error cost\nthat entails the data, as well as their graph adjacency matrix. Working in the\ngraph spectral domain enables the derivation of simple gradient descent\nrecursions used to update the matrix filter taps. Numerical tests in real image\ndatasets demonstrate the better reconstruction performance of the novel method\nover standard principal component analysis.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 00:20:40 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Schizas", "Ioannis D.", ""]]}, {"id": "1809.09307", "submitter": "Daeyoung Choi", "authors": "Daeyoung Choi and Wonjong Rhee", "title": "Utilizing Class Information for Deep Network Representation Shaping", "comments": "Published in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical characteristics of deep network representations, such as sparsity\nand correlation, are known to be relevant to the performance and\ninterpretability of deep learning. When a statistical characteristic is\ndesired, often an adequate regularizer can be designed and applied during the\ntraining phase. Typically, such a regularizer aims to manipulate a statistical\ncharacteristic over all classes together. For classification tasks, however, it\nmight be advantageous to enforce the desired characteristic per class such that\ndifferent classes can be better distinguished. Motivated by the idea, we design\ntwo class-wise regularizers that explicitly utilize class information:\nclass-wise Covariance Regularizer (cw-CR) and class-wise Variance Regularizer\n(cw-VR). cw-CR targets to reduce the covariance of representations calculated\nfrom the same class samples for encouraging feature independence. cw-VR is\nsimilar, but variance instead of covariance is targeted to improve feature\ncompactness. For the sake of completeness, their counterparts without using\nclass information, Covariance Regularizer (CR) and Variance Regularizer (VR),\nare considered together. The four regularizers are conceptually simple and\ncomputationally very efficient, and the visualization shows that the\nregularizers indeed perform distinct representation shaping. In terms of\nclassification performance, significant improvements over the baseline and\nL1/L2 weight regularization methods were found for 21 out of 22 tasks over\npopular benchmark datasets. In particular, cw-VR achieved the best performance\nfor 13 tasks including ResNet-32/110.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 03:50:59 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 03:58:50 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Choi", "Daeyoung", ""], ["Rhee", "Wonjong", ""]]}, {"id": "1809.09310", "submitter": "Daniel Fremont", "authors": "Daniel J. Fremont, Tommaso Dreossi, Shromona Ghosh, Xiangyu Yue,\n  Alberto L. Sangiovanni-Vincentelli, Sanjit A. Seshia", "title": "Scenic: A Language for Scenario Specification and Scene Generation", "comments": "41 pages, 36 figures. Full version of a PLDI 2019 paper (extending UC\n  Berkeley EECS Department Tech Report No. UCB/EECS-2018-8)", "journal-ref": null, "doi": "10.1145/3314221.3314633", "report-no": null, "categories": "cs.PL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new probabilistic programming language for the design and\nanalysis of perception systems, especially those based on machine learning.\nSpecifically, we consider the problems of training a perception system to\nhandle rare events, testing its performance under different conditions, and\ndebugging failures. We show how a probabilistic programming language can help\naddress these problems by specifying distributions encoding interesting types\nof inputs and sampling these to generate specialized training and test sets.\nMore generally, such languages can be used for cyber-physical systems and\nrobotics to write environment models, an essential prerequisite to any formal\nanalysis. In this paper, we focus on systems like autonomous cars and robots,\nwhose environment is a \"scene\", a configuration of physical objects and agents.\nWe design a domain-specific language, Scenic, for describing \"scenarios\" that\nare distributions over scenes. As a probabilistic programming language, Scenic\nallows assigning distributions to features of the scene, as well as\ndeclaratively imposing hard and soft constraints over the scene. We develop\nspecialized techniques for sampling from the resulting distribution, taking\nadvantage of the structure provided by Scenic's domain-specific syntax.\nFinally, we apply Scenic in a case study on a convolutional neural network\ndesigned to detect cars in road images, improving its performance beyond that\nachieved by state-of-the-art synthetic data generation methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 03:57:00 GMT"}, {"version": "v2", "created": "Fri, 21 Jun 2019 01:12:24 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Fremont", "Daniel J.", ""], ["Dreossi", "Tommaso", ""], ["Ghosh", "Shromona", ""], ["Yue", "Xiangyu", ""], ["Sangiovanni-Vincentelli", "Alberto L.", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1809.09318", "submitter": "Vikas Dhiman", "authors": "Vikas Dhiman, Shurjo Banerjee, Jeffrey M. Siskind and Jason J. Corso", "title": "Floyd-Warshall Reinforcement Learning: Learning from Past Experiences to\n  Reach New Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider mutli-goal tasks that involve static environments and dynamic goals.\nExamples of such tasks, such as goal-directed navigation and pick-and-place in\nrobotics, abound. Two types of Reinforcement Learning (RL) algorithms are used\nfor such tasks: model-free or model-based. Each of these approaches has\nlimitations. Model-free RL struggles to transfer learned information when the\ngoal location changes, but achieves high asymptotic accuracy in single goal\ntasks. Model-based RL can transfer learned information to new goal locations by\nretaining the explicitly learned state-dynamics, but is limited by the fact\nthat small errors in modelling these dynamics accumulate over long-term\nplanning. In this work, we improve upon the limitations of model-free RL in\nmulti-goal domains. We do this by adapting the Floyd-Warshall algorithm for RL\nand call the adaptation Floyd-Warshall RL (FWRL). The proposed algorithm learns\na goal-conditioned action-value function by constraining the value of the\noptimal path between any two states to be greater than or equal to the value of\npaths via intermediary states. Experimentally, we show that FWRL is more\nsample-efficient and learns higher reward strategies in multi-goal tasks as\ncompared to Q-learning, model-based RL and other relevant baselines in a\ntabular domain.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 05:09:32 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 20:23:32 GMT"}, {"version": "v3", "created": "Thu, 4 Oct 2018 18:33:20 GMT"}, {"version": "v4", "created": "Fri, 4 Jan 2019 20:53:40 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Dhiman", "Vikas", ""], ["Banerjee", "Shurjo", ""], ["Siskind", "Jeffrey M.", ""], ["Corso", "Jason J.", ""]]}, {"id": "1809.09326", "submitter": "Pablo Navarrete Michelini", "authors": "Pablo Navarrete Michelini, Hanwen Liu and Dan Zhu", "title": "Multigrid Backprojection Super-Resolution and Deep Filter Visualization", "comments": "Spotlight paper in the Thirty-Third AAAI Conference on Artificial\n  Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel deep-learning architecture for image upscaling by large\nfactors (e.g. 4x, 8x) based on examples of pristine high-resolution images. Our\ntarget is to reconstruct high-resolution images from their downscale versions.\nThe proposed system performs a multi-level progressive upscaling, starting from\nsmall factors (2x) and updating for higher factors (4x and 8x). The system is\nrecursive as it repeats the same procedure at each level. It is also residual\nsince we use the network to update the outputs of a classic upscaler. The\nnetwork residuals are improved by Iterative Back-Projections (IBP) computed in\nthe features of a convolutional network. To work in multiple levels we extend\nthe standard back-projection algorithm using a recursion analogous to\nMulti-Grid algorithms commonly used as solvers of large systems of linear\nequations. We finally show how the network can be interpreted as a standard\nupsampling-and-filter upscaler with a space-variant filter that adapts to the\ngeometry. This approach allows us to visualize how the network learns to\nupscale. Finally, our system reaches state of the art quality for models with\nrelatively few number of parameters.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 05:36:51 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 15:37:28 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 02:04:15 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Michelini", "Pablo Navarrete", ""], ["Liu", "Hanwen", ""], ["Zhu", "Dan", ""]]}, {"id": "1809.09331", "submitter": "Hamidreza Alvari", "authors": "Hamidreza Alvari, Elham Shaabani, and Paulo Shakarian", "title": "Early Identification of Pathogenic Social Media Accounts", "comments": "IEEE Intelligence and Security Informatics (ISI) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathogenic Social Media (PSM) accounts such as terrorist supporters exploit\nlarge communities of supporters for conducting attacks on social media. Early\ndetection of these accounts is crucial as they are high likely to be key users\nin making a harmful message \"viral\". In this paper, we make the first attempt\non utilizing causal inference to identify PSMs within a short time frame around\ntheir activity. We propose a time-decay causality metric and incorporate it\ninto a causal community detection-based algorithm. The proposed algorithm is\napplied to groups of accounts sharing similar causality features and is\nfollowed by a classification algorithm to classify accounts as PSM or not.\nUnlike existing techniques that take significant time to collect information\nsuch as network, cascade path, or content, our scheme relies solely on action\nlog of users. Results on a real-world dataset from Twitter demonstrate\neffectiveness and efficiency of our approach. We achieved precision of 0.84 for\ndetecting PSMs only based on their first 10 days of activity; the misclassified\naccounts were then detected 10 days later.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 06:10:51 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 04:11:21 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Alvari", "Hamidreza", ""], ["Shaabani", "Elham", ""], ["Shakarian", "Paulo", ""]]}, {"id": "1809.09332", "submitter": "Hongyao Tang", "authors": "Hongyao Tang, Jianye Hao, Tangjie Lv, Yingfeng Chen, Zongzhang Zhang,\n  Hangtian Jia, Chunxu Ren, Yan Zheng, Zhaopeng Meng, Changjie Fan, Li Wang", "title": "Hierarchical Deep Multiagent Reinforcement Learning with Temporal\n  Abstraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent reinforcement learning (MARL) is commonly considered to suffer\nfrom non-stationary environments and exponentially increasing policy space. It\nwould be even more challenging when rewards are sparse and delayed over long\ntrajectories. In this paper, we study hierarchical deep MARL in cooperative\nmultiagent problems with sparse and delayed reward. With temporal abstraction,\nwe decompose the problem into a hierarchy of different time scales and\ninvestigate how agents can learn high-level coordination based on the\nindependent skills learned at the low level. Three hierarchical deep MARL\narchitectures are proposed to learn hierarchical policies under different MARL\nparadigms. Besides, we propose a new experience replay mechanism to alleviate\nthe issue of the sparse transitions at the high level of abstraction and the\nnon-stationarity of multiagent learning. We empirically demonstrate the\neffectiveness of our approaches in two domains with extremely sparse feedback:\n(1) a variety of Multiagent Trash Collection tasks, and (2) a challenging\nonline mobile game, i.e., Fever Basketball Defense.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 06:19:22 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 11:00:01 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Tang", "Hongyao", ""], ["Hao", "Jianye", ""], ["Lv", "Tangjie", ""], ["Chen", "Yingfeng", ""], ["Zhang", "Zongzhang", ""], ["Jia", "Hangtian", ""], ["Ren", "Chunxu", ""], ["Zheng", "Yan", ""], ["Meng", "Zhaopeng", ""], ["Fan", "Changjie", ""], ["Wang", "Li", ""]]}, {"id": "1809.09349", "submitter": "Stefano Spigler", "authors": "Mario Geiger, Stefano Spigler, St\\'ephane d'Ascoli, Levent Sagun,\n  Marco Baity-Jesi, Giulio Biroli and Matthieu Wyart", "title": "The jamming transition as a paradigm to understand the loss landscape of\n  deep neural networks", "comments": null, "journal-ref": "Phys. Rev. E 100, 012115 (2019)", "doi": "10.1103/PhysRevE.100.012115", "report-no": null, "categories": "cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been immensely successful at a variety of tasks, ranging\nfrom classification to AI. Learning corresponds to fitting training data, which\nis implemented by descending a very high-dimensional loss function.\nUnderstanding under which conditions neural networks do not get stuck in poor\nminima of the loss, and how the landscape of that loss evolves as depth is\nincreased remains a challenge. Here we predict, and test empirically, an\nanalogy between this landscape and the energy landscape of repulsive ellipses.\nWe argue that in FC networks a phase transition delimits the over- and\nunder-parametrized regimes where fitting can or cannot be achieved. In the\nvicinity of this transition, properties of the curvature of the minima of the\nloss are critical. This transition shares direct similarities with the jamming\ntransition by which particles form a disordered solid as the density is\nincreased, which also occurs in certain classes of computational optimization\nand learning problems such as the perceptron. Our analysis gives a simple\nexplanation as to why poor minima of the loss cannot be encountered in the\noverparametrized regime, and puts forward the surprising result that the\nability of fully connected networks to fit random data is independent of their\ndepth. Our observations suggests that this independence also holds for real\ndata. We also study a quantity $\\Delta$ which characterizes how well\n($\\Delta<0$) or badly ($\\Delta>0$) a datum is learned. At the critical point it\nis power-law distributed, $P_+(\\Delta)\\sim\\Delta^\\theta$ for $\\Delta>0$ and\n$P_-(\\Delta)\\sim(-\\Delta)^{-\\gamma}$ for $\\Delta<0$, with $\\theta\\approx0.3$\nand $\\gamma\\approx0.2$. This observation suggests that near the transition the\nloss landscape has a hierarchical structure and that the learning dynamics is\nprone to avalanche-like dynamics, with abrupt changes in the set of patterns\nthat are learned.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 07:15:27 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 17:25:37 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 09:23:42 GMT"}, {"version": "v4", "created": "Mon, 17 Jun 2019 08:20:27 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Geiger", "Mario", ""], ["Spigler", "Stefano", ""], ["d'Ascoli", "St\u00e9phane", ""], ["Sagun", "Levent", ""], ["Baity-Jesi", "Marco", ""], ["Biroli", "Giulio", ""], ["Wyart", "Matthieu", ""]]}, {"id": "1809.09350", "submitter": "Chaobing Song", "authors": "Chaobing Song, Ji Liu, Han Liu, Yong Jiang, Tong Zhang", "title": "Fully Implicit Online Learning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized online learning is widely used in machine learning applications.\nIn online learning, performing exact minimization ($i.e.,$ implicit update) is\nknown to be beneficial to the numerical stability and structure of solution. In\nthis paper we study a class of regularized online algorithms without\nlinearizing the loss function or the regularizer, which we call \\emph{fully\nimplicit online learning} (FIOL). We show that for arbitrary Bregman\ndivergence, FIOL has the $O(\\sqrt{T})$ regret for general convex setting and\n$O(\\log T)$ regret for strongly convex setting, and the regret has an one-step\nimprovement effect because it avoids the approximation error of linearization.\nThen we propose efficient algorithms to solve the subproblem of FIOL. We show\nthat even if the solution of the subproblem has no closed form, it can be\nsolved with complexity comparable to the linearized online algoritms.\nExperiments validate the proposed approaches.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 07:16:17 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 15:47:11 GMT"}, {"version": "v3", "created": "Wed, 6 Feb 2019 19:35:42 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Song", "Chaobing", ""], ["Liu", "Ji", ""], ["Liu", "Han", ""], ["Jiang", "Yong", ""], ["Zhang", "Tong", ""]]}, {"id": "1809.09367", "submitter": "Edgar Steiger", "authors": "Edgar Steiger, Martin Vingron", "title": "Sparse-Group Bayesian Feature Selection Using Expectation Propagation\n  for Signal Recovery and Network Reconstruction", "comments": "44 pages, 15 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian method for feature selection in the presence of\ngrouping information with sparsity on the between- and within group level.\nInstead of using a stochastic algorithm for parameter inference, we employ\nexpectation propagation, which is a deterministic and fast algorithm. Available\nmethods for feature selection in the presence of grouping information have a\nnumber of short-comings: on one hand, lasso methods, while being fast,\nunderestimate the regression coefficients and do not make good use of the\ngrouping information, and on the other hand, Bayesian approaches, while\naccurate in parameter estimation, often rely on the stochastic and slow Gibbs\nsampling procedure to recover the parameters, rendering them infeasible e.g.\nfor gene network reconstruction. Our approach of a Bayesian sparse-group\nframework with expectation propagation enables us to not only recover accurate\nparameter estimates in signal recovery problems, but also makes it possible to\napply this Bayesian framework to large-scale network reconstruction problems.\nThe presented method is generic but in terms of application we focus on gene\nregulatory networks. We show on simulated and experimental data that the method\nconstitutes a good choice for network reconstruction regarding the number of\ncorrectly selected features, prediction on new data and reasonable computing\ntime.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 09:08:26 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Steiger", "Edgar", ""], ["Vingron", "Martin", ""]]}, {"id": "1809.09369", "submitter": "Antonin Raffin", "authors": "Antonin Raffin and Ashley Hill and Ren\\'e Traor\\'e and Timoth\\'ee\n  Lesort and Natalia D\\'iaz-Rodr\\'iguez and David Filliat", "title": "S-RL Toolbox: Environments, Datasets and Evaluation Metrics for State\n  Representation Learning", "comments": "Github repo: https://github.com/araffin/robotics-rl-srl\n  Documentation: https://s-rl-toolbox.readthedocs.io/en/latest/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State representation learning aims at learning compact representations from\nraw observations in robotics and control applications. Approaches used for this\nobjective are auto-encoders, learning forward models, inverse dynamics or\nlearning using generic priors on the state characteristics. However, the\ndiversity in applications and methods makes the field lack standard evaluation\ndatasets, metrics and tasks. This paper provides a set of environments, data\ngenerators, robotic control tasks, metrics and tools to facilitate iterative\nstate representation learning and evaluation in reinforcement learning\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 09:11:49 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 09:40:45 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Raffin", "Antonin", ""], ["Hill", "Ashley", ""], ["Traor\u00e9", "Ren\u00e9", ""], ["Lesort", "Timoth\u00e9e", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Filliat", "David", ""]]}, {"id": "1809.09399", "submitter": "Sergey Sukhov", "authors": "Mikhail Iu. Leontev, Viktoriia Islenteva, Sergey V. Sukhov", "title": "Non-Iterative Knowledge Fusion in Deep Convolutional Neural Networks", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": "10.1007/s11063-019-10074-0", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporation of a new knowledge into neural networks with simultaneous\npreservation of the previous one is known to be a nontrivial problem. This\nproblem becomes even more complex when new knowledge is contained not in new\ntraining examples, but inside the parameters (connection weights) of another\nneural network. Here we propose and test two methods allowing combining the\nknowledge contained in separate networks. One method is based on a simple\noperation of summation of weights of constituent neural networks. Another\nmethod assumes incorporation of a new knowledge by modification of weights\nnonessential for the preservation of already stored information. We show that\nwith these methods the knowledge from one network can be transferred into\nanother one non-iteratively without requiring training sessions. The fused\nnetwork operates efficiently, performing classification far better than a\nchance level. The efficiency of the methods is quantified on several publicly\navailable data sets in classification tasks both for shallow and deep neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 10:29:18 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Leontev", "Mikhail Iu.", ""], ["Islenteva", "Viktoriia", ""], ["Sukhov", "Sergey V.", ""]]}, {"id": "1809.09401", "submitter": "Yifan Feng", "authors": "Yifan Feng, Haoxuan You, Zizhao Zhang, Rongrong Ji, Yue Gao", "title": "Hypergraph Neural Networks", "comments": "Accepted in AAAI'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a hypergraph neural networks (HGNN) framework for\ndata representation learning, which can encode high-order data correlation in a\nhypergraph structure. Confronting the challenges of learning representation for\ncomplex data in real practice, we propose to incorporate such data structure in\na hypergraph, which is more flexible on data modeling, especially when dealing\nwith complex data. In this method, a hyperedge convolution operation is\ndesigned to handle the data correlation during representation learning. In this\nway, traditional hypergraph learning procedure can be conducted using hyperedge\nconvolution operations efficiently. HGNN is able to learn the hidden layer\nrepresentation considering the high-order data structure, which is a general\nframework considering the complex data correlations. We have conducted\nexperiments on citation network classification and visual object recognition\ntasks and compared HGNN with graph convolutional networks and other traditional\nmethods. Experimental results demonstrate that the proposed HGNN method\noutperforms recent state-of-the-art methods. We can also reveal from the\nresults that the proposed HGNN is superior when dealing with multi-modal data\ncompared with existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 10:42:28 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 03:13:42 GMT"}, {"version": "v3", "created": "Sat, 23 Feb 2019 02:48:42 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Feng", "Yifan", ""], ["You", "Haoxuan", ""], ["Zhang", "Zizhao", ""], ["Ji", "Rongrong", ""], ["Gao", "Yue", ""]]}, {"id": "1809.09420", "submitter": "Matthew Guzdial", "authors": "Matthew Guzdial, Nicholas Liao and Mark Riedl", "title": "Co-Creative Level Design via Machine Learning", "comments": "7 pages, 2 figures, Fifth Experimental AI in Games Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural Level Generation via Machine Learning (PLGML), the study of\ngenerating game levels with machine learning, has received a large amount of\nrecent academic attention. For certain measures these approaches have shown\nsuccess at replicating the quality of existing game levels. However, it is\nunclear the extent to which they might benefit human designers. In this paper\nwe present a framework for co-creative level design with a PLGML agent. In\nsupport of this framework we present results from a user study and results from\na comparative study of PLGML approaches.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 11:56:52 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Guzdial", "Matthew", ""], ["Liao", "Nicholas", ""], ["Riedl", "Mark", ""]]}, {"id": "1809.09445", "submitter": "Yousra El-Bachir", "authors": "Yousra El-Bachir and Anthony C. Davison", "title": "Fast Automatic Smoothing for Generalized Additive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple generalized additive models (GAMs) are a type of distributional\nregression wherein parameters of probability distributions depend on predictors\nthrough smooth functions, with selection of the degree of smoothness via $L_2$\nregularization. Multiple GAMs allow finer statistical inference by\nincorporating explanatory information in any or all of the parameters of the\ndistribution. Owing to their nonlinearity, flexibility and interpretability,\nGAMs are widely used, but reliable and fast methods for automatic smoothing in\nlarge datasets are still lacking, despite recent advances. We develop a general\nmethodology for automatically learning the optimal degree of $L_2$\nregularization for multiple GAMs using an empirical Bayes approach. The smooth\nfunctions are penalized by different amounts, which are learned simultaneously\nby maximization of a marginal likelihood through an approximate\nexpectation-maximization algorithm that involves a double Laplace approximation\nat the E-step, and leads to an efficient M-step. Empirical analysis shows that\nthe resulting algorithm is numerically stable, faster than all existing methods\nand achieves state-of-the-art accuracy. For illustration, we apply it to an\nimportant and challenging problem in the analysis of extremal data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 12:59:01 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["El-Bachir", "Yousra", ""], ["Davison", "Anthony C.", ""]]}, {"id": "1809.09446", "submitter": "Jacques Wainer", "authors": "Jacques Wainer and Gavin Cawley", "title": "Nested cross-validation when selecting classifiers is overzealous for\n  most practical applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When selecting a classification algorithm to be applied to a particular\nproblem, one has to simultaneously select the best algorithm for that dataset\n\\emph{and} the best set of hyperparameters for the chosen model. The usual\napproach is to apply a nested cross-validation procedure; hyperparameter\nselection is performed in the inner cross-validation, while the outer\ncross-validation computes an unbiased estimate of the expected accuracy of the\nalgorithm \\emph{with cross-validation based hyperparameter tuning}. The\nalternative approach, which we shall call `flat cross-validation', uses a\nsingle cross-validation step both to select the optimal hyperparameter values\nand to provide an estimate of the expected accuracy of the algorithm, that\nwhile biased may nevertheless still be used to select the best learning\nalgorithm. We tested both procedures using 12 different algorithms on 115 real\nlife binary datasets and conclude that using the less computationally expensive\nflat cross-validation procedure will generally result in the selection of an\nalgorithm that is, for all practical purposes, of similar quality to that\nselected via nested cross-validation, provided the learning algorithms have\nrelatively few hyperparameters to be optimised.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 12:59:05 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Wainer", "Jacques", ""], ["Cawley", "Gavin", ""]]}, {"id": "1809.09449", "submitter": "Panayotis Mertikopoulos", "authors": "Immanuel M. Bomze and Panayotis Mertikopoulos and Werner Schachinger\n  and Mathias Staudigl", "title": "Hessian barrier algorithms for linearly constrained optimization\n  problems", "comments": "27 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an interior-point method for linearly constrained\noptimization problems (possibly nonconvex). The method - which we call the\nHessian barrier algorithm (HBA) - combines a forward Euler discretization of\nHessian Riemannian gradient flows with an Armijo backtracking step-size policy.\nIn this way, HBA can be seen as an alternative to mirror descent (MD), and\ncontains as special cases the affine scaling algorithm, regularized Newton\nprocesses, and several other iterative solution methods. Our main result is\nthat, modulo a non-degeneracy condition, the algorithm converges to the\nproblem's set of critical points; hence, in the convex case, the algorithm\nconverges globally to the problem's minimum set. In the case of linearly\nconstrained quadratic programs (not necessarily convex), we also show that the\nmethod's convergence rate is $\\mathcal{O}(1/k^\\rho)$ for some $\\rho\\in(0,1]$\nthat depends only on the choice of kernel function (i.e., not on the problem's\nprimitives). These theoretical results are validated by numerical experiments\nin standard non-convex test functions and large-scale traffic assignment\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 13:01:11 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 14:46:45 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Bomze", "Immanuel M.", ""], ["Mertikopoulos", "Panayotis", ""], ["Schachinger", "Werner", ""], ["Staudigl", "Mathias", ""]]}, {"id": "1809.09501", "submitter": "Matthieu Geist", "authors": "Matthieu Geist and Bruno Scherrer", "title": "Anderson Acceleration for Reinforcement Learning", "comments": "European Workshop on Reinforcement Learning (EWRL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anderson acceleration is an old and simple method for accelerating the\ncomputation of a fixed point. However, as far as we know and quite\nsurprisingly, it has never been applied to dynamic programming or reinforcement\nlearning. In this paper, we explain briefly what Anderson acceleration is and\nhow it can be applied to value iteration, this being supported by preliminary\nexperiments showing a significant speed up of convergence, that we critically\ndiscuss. We also discuss how this idea could be applied more generally to\n(deep) reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 14:04:25 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Geist", "Matthieu", ""], ["Scherrer", "Bruno", ""]]}, {"id": "1809.09505", "submitter": "Jonathan Huggins", "authors": "Jonathan H. Huggins, Trevor Campbell, Miko{\\l}aj Kasprzak, Tamara\n  Broderick", "title": "Practical bounds on the error of Bayesian posterior approximations: A\n  nonasymptotic approach", "comments": "22 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference typically requires the computation of an approximation to\nthe posterior distribution. An important requirement for an approximate\nBayesian inference algorithm is to output high-accuracy posterior mean and\nuncertainty estimates. Classical Monte Carlo methods, particularly Markov Chain\nMonte Carlo, remain the gold standard for approximate Bayesian inference\nbecause they have a robust finite-sample theory and reliable convergence\ndiagnostics. However, alternative methods, which are more scalable or apply to\nproblems where Markov Chain Monte Carlo cannot be used, lack the same\nfinite-data approximation theory and tools for evaluating their accuracy. In\nthis work, we develop a flexible new approach to bounding the error of mean and\nuncertainty estimates of scalable inference algorithms. Our strategy is to\ncontrol the estimation errors in terms of Wasserstein distance, then bound the\nWasserstein distance via a generalized notion of Fisher distance. Unlike\ncomputing the Wasserstein distance, which requires access to the normalized\nposterior distribution, the Fisher distance is tractable to compute because it\nrequires access only to the gradient of the log posterior density. We\ndemonstrate the usefulness of our Fisher distance approach by deriving bounds\non the Wasserstein error of the Laplace approximation and Hilbert coresets. We\nanticipate that our approach will be applicable to many other approximate\ninference methods such as the integrated Laplace approximation, variational\ninference, and approximate Bayesian computation\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 14:11:32 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 21:33:00 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Huggins", "Jonathan H.", ""], ["Campbell", "Trevor", ""], ["Kasprzak", "Miko\u0142aj", ""], ["Broderick", "Tamara", ""]]}, {"id": "1809.09529", "submitter": "Kaoutar Ben Ahmed", "authors": "Kaoutar Ben Ahmed, Ahmad Babaeian Jelodar", "title": "Fine-Tuning VGG Neural Network For Fine-grained State Recognition of\n  Food Images", "comments": "5 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State recognition of food images can be considered as one of the promising\napplications of object recognition and fine-grained image classification in\ncomputer vision. In this paper, evidence is provided for the power of\nconvolutional neural network (CNN) for food state recognition, even with a\nsmall data set. In this study, we fine-tuned a CNN initially trained on a large\nnatural image recognition dataset (Imagenet ILSVRC) and transferred the learned\nfeature representations to the food state recognition task. A small-scale\ndataset consisting of 5978 images of seven categories was constructed and\nannotated manually. Data augmentation was applied to increase the size of the\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 22:38:33 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Ahmed", "Kaoutar Ben", ""], ["Jelodar", "Ahmad Babaeian", ""]]}, {"id": "1809.09533", "submitter": "Faik Boray Tek", "authors": "F. Boray Tek", "title": "An Adaptive Locally Connected Neuron Model: Focusing Neuron", "comments": "45 pages, a national patent filed, submitted to Turkish Patent\n  Office, No: -2017/17601, Date: 09.11.2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new artificial neuron model capable of learning its\nreceptive field in the topological domain of inputs. The model provides\nadaptive and differentiable local connectivity (plasticity) applicable to any\ndomain. It requires no other tool than the backpropagation algorithm to learn\nits parameters which control the receptive field locations and apertures. This\nresearch explores whether this ability makes the neuron focus on informative\ninputs and yields any advantage over fully connected neurons. The experiments\ninclude tests of focusing neuron networks of one or two hidden layers on\nsynthetic and well-known image recognition data sets. The results demonstrated\nthat the focusing neurons can move their receptive fields towards more\ninformative inputs. In the simple two-hidden layer networks, the focusing\nlayers outperformed the dense layers in the classification of the 2D spatial\ndata sets. Moreover, the focusing networks performed better than the dense\nnetworks even when 70$\\%$ of the weights were pruned. The tests on\nconvolutional networks revealed that using focusing layers instead of dense\nlayers for the classification of convolutional features may work better in some\ndata sets.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 09:15:32 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 13:29:37 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 11:11:40 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Tek", "F. Boray", ""]]}, {"id": "1809.09558", "submitter": "Evangelos Boukas Prof", "authors": "Jordi Spranger, Roxana Buzatoiu, Athanasios Polydoros, Lazaros\n  Nalpantidis and Evangelos Boukas", "title": "Human-Machine Interface for Remote Training of Robot Tasks", "comments": "Accepted in IEEE International Conference on Imaging Systems and\n  Techniques - IST2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regardless of their industrial or research application, the streamlining of\nrobot operations is limited by the proximity of experienced users to the actual\nhardware. Be it massive open online robotics courses, crowd-sourcing of robot\ntask training, or remote research on massive robot farms for machine learning,\nthe need to create an apt remote Human-Machine Interface is quite prevalent.\nThe paper at hand proposes a novel solution to the programming/training of\nremote robots employing an intuitive and accurate user-interface which offers\nall the benefits of working with real robots without imposing delays and\ninefficiency. The system includes: a vision-based 3D hand detection and gesture\nrecognition subsystem, a simulated digital twin of a robot as visual feedback,\nand the \"remote\" robot learning/executing trajectories using dynamic motion\nprimitives. Our results indicate that the system is a promising solution to the\nproblem of remote training of robot tasks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 15:44:35 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Spranger", "Jordi", ""], ["Buzatoiu", "Roxana", ""], ["Polydoros", "Athanasios", ""], ["Nalpantidis", "Lazaros", ""], ["Boukas", "Evangelos", ""]]}, {"id": "1809.09569", "submitter": "Bart van Merri\\\"enboer", "authors": "Bart van Merri\\\"enboer, Dan Moldovan and Alexander B Wiltschko", "title": "Tangent: Automatic differentiation using source-code transformation for\n  dynamically typed array programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need to efficiently calculate first- and higher-order derivatives of\nincreasingly complex models expressed in Python has stressed or exceeded the\ncapabilities of available tools. In this work, we explore techniques from the\nfield of automatic differentiation (AD) that can give researchers expressive\npower, performance and strong usability. These include source-code\ntransformation (SCT), flexible gradient surgery, efficient in-place array\noperations, higher-order derivatives as well as mixing of forward and reverse\nmode AD. We implement and demonstrate these ideas in the Tangent software\nlibrary for Python, the first AD framework for a dynamic language that uses\nSCT.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 16:08:37 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 14:13:37 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["van Merri\u00ebnboer", "Bart", ""], ["Moldovan", "Dan", ""], ["Wiltschko", "Alexander B", ""]]}, {"id": "1809.09573", "submitter": "Yuxin Chen", "authors": "Yuejie Chi, Yue M. Lu, Yuxin Chen", "title": "Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview", "comments": "Invited overview article", "journal-ref": "IEEE Transactions on Signal Processing, vol. 67, no. 20, pp.\n  5239-5269, October 2019", "doi": "10.1109/TSP.2019.2937282", "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substantial progress has been made recently on developing provably accurate\nand efficient algorithms for low-rank matrix factorization via nonconvex\noptimization. While conventional wisdom often takes a dim view of nonconvex\noptimization algorithms due to their susceptibility to spurious local minima,\nsimple iterative methods such as gradient descent have been remarkably\nsuccessful in practice. The theoretical footings, however, had been largely\nlacking until recently.\n  In this tutorial-style overview, we highlight the important role of\nstatistical models in enabling efficient nonconvex optimization with\nperformance guarantees. We review two contrasting approaches: (1) two-stage\nalgorithms, which consist of a tailored initialization step followed by\nsuccessive refinement; and (2) global landscape analysis and\ninitialization-free algorithms. Several canonical matrix factorization problems\nare discussed, including but not limited to matrix sensing, phase retrieval,\nmatrix completion, blind deconvolution, robust principal component analysis,\nphase synchronization, and joint alignment. Special care is taken to illustrate\nthe key technical insights underlying their analyses. This article serves as a\ntestament that the integrated consideration of optimization and statistics\nleads to fruitful research findings.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 16:21:07 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 22:56:03 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 17:00:59 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Chi", "Yuejie", ""], ["Lu", "Yue M.", ""], ["Chen", "Yuxin", ""]]}, {"id": "1809.09574", "submitter": "Jaehoon Koo", "authors": "Jaehoon Koo, Diego Klabjan, Jean Utke", "title": "Combined convolutional and recurrent neural networks for hierarchical\n  classification of images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models based on CNNs are predominantly used in image\nclassification tasks. Such approaches, assuming independence of object\ncategories, normally use a CNN as a feature learner and apply a flat classifier\non top of it. Object classes in many settings have hierarchical relations, and\nclassifiers exploiting these relations should perform better. We propose\nhierarchical classification models combining a CNN to extract hierarchical\nrepresentations of images, and an RNN or sequence-to-sequence model to capture\na hierarchical tree of classes. In addition, we apply residual learning to the\nRNN part in oder to facilitate training our compound model and improve\ngeneralization of the model. Experimental results on a real world proprietary\ndataset of images show that our hierarchical networks perform better than\nstate-of-the-art CNNs.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 16:23:45 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 22:47:07 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 17:32:54 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Koo", "Jaehoon", ""], ["Klabjan", "Diego", ""], ["Utke", "Jean", ""]]}, {"id": "1809.09582", "submitter": "Negin Golrezaei", "authors": "Santiago Balseiro, Negin Golrezaei, Mohammad Mahdian, Vahab Mirrokni,\n  Jon Schneider", "title": "Contextual Bandits with Cross-learning", "comments": "48 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classical contextual bandits problem, in each round $t$, a learner\nobserves some context $c$, chooses some action $a$ to perform, and receives\nsome reward $r_{a,t}(c)$. We consider the variant of this problem where in\naddition to receiving the reward $r_{a,t}(c)$, the learner also learns the\nvalues of $r_{a,t}(c')$ for all other contexts $c'$; i.e., the rewards that\nwould have been achieved by performing that action under different contexts.\nThis variant arises in several strategic settings, such as learning how to bid\nin non-truthful repeated auctions (in this setting the context is the decision\nmaker's private valuation for each auction). We call this problem the\ncontextual bandits problem with cross-learning. The best algorithms for the\nclassical contextual bandits problem achieve $\\tilde{O}(\\sqrt{CKT})$ regret\nagainst all stationary policies, where $C$ is the number of contexts, $K$ the\nnumber of actions, and $T$ the number of rounds. We demonstrate algorithms for\nthe contextual bandits problem with cross-learning that remove the dependence\non $C$ and achieve regret $O(\\sqrt{KT})$ (when contexts are stochastic with\nknown distribution), $\\tilde{O}(K^{1/3}T^{2/3})$ (when contexts are stochastic\nwith unknown distribution), and $\\tilde{O}(\\sqrt{KT})$ (when contexts are\nadversarial but rewards are stochastic).\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 16:40:44 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 23:04:28 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Balseiro", "Santiago", ""], ["Golrezaei", "Negin", ""], ["Mahdian", "Mohammad", ""], ["Mirrokni", "Vahab", ""], ["Schneider", "Jon", ""]]}, {"id": "1809.09620", "submitter": "Shujaat Khan Engr", "authors": "Shujaat Khan, Imran Naseem, Roberto Togneri, and Mohammed Bennamoun", "title": "RAFP-Pred: Robust Prediction of Antifreeze Proteins using Localized\n  Analysis of n-Peptide Compositions", "comments": "7 pages, 2 figures", "journal-ref": "\"RAFP-Pred: Robust Prediction of Antifreeze Proteins Using\n  Localized Analysis of n-Peptide Compositions,\" in IEEE/ACM Transactions on\n  Computational Biology and Bioinformatics, vol. 15, no. 1, pp. 244-250, 1\n  Jan.-Feb. 2018", "doi": "10.1109/TCBB.2016.2617337", "report-no": null, "categories": "q-bio.BM cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In extreme cold weather, living organisms produce Antifreeze Proteins (AFPs)\nto counter the otherwise lethal intracellular formation of ice. Structures and\nsequences of various AFPs exhibit a high degree of heterogeneity, consequently\nthe prediction of the AFPs is considered to be a challenging task. In this\nresearch, we propose to handle this arduous manifold learning task using the\nnotion of localized processing. In particular an AFP sequence is segmented into\ntwo sub-segments each of which is analyzed for amino acid and di-peptide\ncompositions. We propose to use only the most significant features using the\nconcept of information gain (IG) followed by a random forest classification\napproach. The proposed RAFP-Pred achieved an excellent performance on a number\nof standard datasets. We report a high Youden's index\n(sensitivity+specificity-1) value of 0.75 on the standard independent test data\nset outperforming the AFP-PseAAC, AFP\\_PSSM, AFP-Pred and iAFP by a margin of\n0.05, 0.06, 0.14 and 0.68 respectively. The verification rate on the UniProKB\ndataset is found to be 83.19\\% which is substantially superior to the 57.18\\%\nreported for the iAFP method.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 05:51:29 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Khan", "Shujaat", ""], ["Naseem", "Imran", ""], ["Togneri", "Roberto", ""], ["Bennamoun", "Mohammed", ""]]}, {"id": "1809.09621", "submitter": "Ilya Trofimov", "authors": "Ilya Trofimov", "title": "Inferring Complementary Products from Baskets and Browsing Sessions", "comments": "Workshop on Intelligent Recommender Systems by Knowledge Transfer and\n  Learning (RecSysKTL'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complementary products recommendation is an important problem in e-commerce.\nSuch recommendations increase the average order price and the number of\nproducts in baskets. Complementary products are typically inferred from basket\ndata. In this study, we propose the BB2vec model. The BB2vec model learns\nvector representations of products by analyzing jointly two types of data -\nBaskets and Browsing sessions (visiting web pages of products). These vector\nrepresentations are used for making complementary products recommendation. The\nproposed model alleviates the cold start problem by delivering better\nrecommendations for products having few or no purchases. We show that the\nBB2vec model has better performance than other models which use only basket\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 08:38:05 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Trofimov", "Ilya", ""]]}, {"id": "1809.09645", "submitter": "Kyongsik Yun", "authors": "Kyongsik Yun, Alexander Huyen, and Thomas Lu", "title": "Deep Neural Networks for Pattern Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of pattern recognition research, the method of using deep neural\nnetworks based on improved computing hardware recently attracted attention\nbecause of their superior accuracy compared to conventional methods. Deep\nneural networks simulate the human visual system and achieve human equivalent\naccuracy in image classification, object detection, and segmentation. This\nchapter introduces the basic structure of deep neural networks that simulate\nhuman neural networks. Then we identify the operational processes and\napplications of conditional generative adversarial networks, which are being\nactively researched based on the bottom-up and top-down mechanisms, the most\nimportant functions of the human visual perception process. Finally, recent\ndevelopments in training strategies for effective learning of complex deep\nneural networks are addressed.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 18:23:49 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Yun", "Kyongsik", ""], ["Huyen", "Alexander", ""], ["Lu", "Thomas", ""]]}, {"id": "1809.09703", "submitter": "Klaus Broelemann", "authors": "Klaus Broelemann and Gjergji Kasneci", "title": "A Gradient-Based Split Criterion for Highly Accurate and Transparent\n  Model Trees", "comments": null, "journal-ref": "Proceedings of the Twenty-Eighth International Joint Conference on\n  Artificial Intelligence, {IJCAI} 2019", "doi": "10.24963/ijcai.2019/281", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms aim at minimizing the number of false decisions\nand increasing the accuracy of predictions. However, the high predictive power\nof advanced algorithms comes at the costs of transparency. State-of-the-art\nmethods, such as neural networks and ensemble methods, often result in highly\ncomplex models that offer little transparency.\n  We propose shallow model trees as a way to combine simple and highly\ntransparent predictive models for higher predictive power without losing the\ntransparency of the original models. We present a novel split criterion for\nmodel trees that allows for significantly higher predictive power than\nstate-of-the-art model trees while maintaining the same level of simplicity.\nThis novel approach finds split points which allow the underlying simple models\nto make better predictions on the corresponding data. In addition, we introduce\nmultiple mechanisms to increase the transparency of the resulting trees.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 20:22:40 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 09:03:55 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Broelemann", "Klaus", ""], ["Kasneci", "Gjergji", ""]]}, {"id": "1809.09745", "submitter": "Nitish Nag", "authors": "Nitish Nag, Vaibhav Pandey, Aishwarya Manjunath, Avinash Vaka, Ramesh\n  Jain", "title": "Surface Type Estimation from GPS Tracked Bicycle Activities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road conditions affect both machine and human powered modes of\ntransportation. In the case of human powered transportation, poor road\nconditions increase the work for the individual to travel. Previous estimates\nfor these parameters have used computationally expensive analysis of satellite\nimages. In this work, we use a computationally inexpensive and simple method by\nusing only GPS data from a human powered cyclist. By estimating if the road\ntaken by the user has high or low variations in their directional vector, we\nclassify if the user is on a paved road or on an unpaved trail. In order to do\nthis, three methods were adopted, changes in frequency of the direction of\nslope in a given path segment, fitting segments of the path, and finding the\nfirst derivative and the number of points of zero crossings of each segment.\nMachine learning models such as support vector machines, K-nearest neighbors,\nand decision trees were used for the classification of the path. We show in our\nmethods, the decision trees performed the best with an accuracy of 86\\%.\nEstimation of the type of surface can be used for many applications such as\nunderstanding rolling resistance for power estimation estimation or building\nexercise recommendation systems by user profiling as described in detail in the\npaper.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 22:24:12 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Nag", "Nitish", ""], ["Pandey", "Vaibhav", ""], ["Manjunath", "Aishwarya", ""], ["Vaka", "Avinash", ""], ["Jain", "Ramesh", ""]]}, {"id": "1809.09755", "submitter": "James Murphy", "authors": "James Murphy, Yuanyuan Pao, Albert Yuen", "title": "Map matching when the map is wrong: Efficient vehicle tracking on- and\n  off-road for map learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sequence of possibly sparse and noisy GPS traces and a map of the\nroad network, map matching algorithms can infer the most accurate trajectory on\nthe road network. However, if the road network is wrong (for example due to\nmissing or incorrectly mapped roads, missing parking lots, misdirected turn\nrestrictions or misdirected one-way streets) standard map matching algorithms\nfail to reconstruct the correct trajectory.\n  In this paper, an algorithm to tracking vehicles able to move both on and off\nthe known road network is formulated. It efficiently unifies existing hidden\nMarkov model (HMM) approaches for map matching and standard free-space tracking\nmethods (e.g. Kalman smoothing) in a principled way. The algorithm is a form of\ninteracting multiple model (IMM) filter subject to an additional assumption on\nthe type of model interaction permitted, termed here as semi-interacting\nmultiple model (sIMM) filter. A forward filter (suitable for real-time\ntracking) and backward MAP sampling step (suitable for MAP trajectory inference\nand map matching) are described. The framework set out here is agnostic to the\nspecific tracking models used, and makes clear how to replace these components\nwith others of a similar type. In addition to avoiding generating misleading\nmap matching trajectories, this algorithm can be applied to learn map features\nby detecting unmapped or incorrectly mapped roads and parking lots, incorrectly\nmapped turn restrictions and road directions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 23:17:06 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 23:02:21 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Murphy", "James", ""], ["Pao", "Yuanyuan", ""], ["Yuen", "Albert", ""]]}, {"id": "1809.09813", "submitter": "Rabindra Lamsal", "authors": "Rabindra Lamsal, Ayesha Choudhary", "title": "Predicting Outcome of Indian Premier League (IPL) Matches Using Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cricket, especially the Twenty20 format, has maximum uncertainty, where a\nsingle over can completely change the momentum of the game. With millions of\npeople following the Indian Premier League (IPL), developing a model for\npredicting the outcome of its matches is a real-world problem. A cricket match\ndepends upon various factors, and in this work, the factors which significantly\ninfluence the outcome of a Twenty20 cricket match are identified. Each player's\nperformance in the field is considered to find out the overall weight (relative\nstrength) of the teams. A multivariate regression based solution is proposed to\ncalculate points for each player in the league and the overall weight of a team\nis computed based on the past performance of the players who have appeared most\nfor the team. Finally, a dataset is modeled based on the identified seven\nfactors which influence the outcome of an IPL match. Six machine learning\nmodels were trained and used for predicting the outcome of each 2018 IPL match,\n15 minutes before the gameplay, immediately after the toss. Three of the\ntrained models were seen to be correctly predicting more than 40 matches, with\nMultilayer Perceptron outperforming all other models with an impressive\naccuracy of 71.66%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 05:26:14 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 05:04:01 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 07:09:17 GMT"}, {"version": "v4", "created": "Tue, 25 Jun 2019 05:22:58 GMT"}, {"version": "v5", "created": "Mon, 21 Sep 2020 17:14:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lamsal", "Rabindra", ""], ["Choudhary", "Ayesha", ""]]}, {"id": "1809.09853", "submitter": "Liu Liu", "authors": "Liu Liu, Xuanqing Liu, Cho-Jui Hsieh, Dacheng Tao", "title": "Stochastic Second-order Methods for Non-convex Optimization with Inexact\n  Hessian and Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust region and cubic regularization methods have demonstrated good\nperformance in small scale non-convex optimization, showing the ability to\nescape from saddle points. Each iteration of these methods involves computation\nof gradient, Hessian and function value in order to obtain the search direction\nand adjust the radius or cubic regularization parameter. However, exactly\ncomputing those quantities are too expensive in large-scale problems such as\ntraining deep networks. In this paper, we study a family of stochastic trust\nregion and cubic regularization methods when gradient, Hessian and function\nvalues are computed inexactly, and show the iteration complexity to achieve\n$\\epsilon$-approximate second-order optimality is in the same order with\nprevious work for which gradient and function values are computed exactly. The\nmild conditions on inexactness can be achieved in finite-sum minimization using\nrandom sampling. We show the algorithm performs well on training convolutional\nneural networks compared with previous second-order methods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 08:59:09 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Liu", "Liu", ""], ["Liu", "Xuanqing", ""], ["Hsieh", "Cho-Jui", ""], ["Tao", "Dacheng", ""]]}, {"id": "1809.09864", "submitter": "Pablo Sanchez Perez", "authors": "Pablo S\\'anchez and Alejandro Bellog\\'in", "title": "A novel approach for venue recommendation using cross-domain techniques", "comments": "Accepted at the Workshop on Intelligent Recommender Systems by\n  Knowledge Transfer and Learning co-located with the 12th ACM Conference on\n  Recommender Systems (RecSys 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the next venue to be visited by a user in a specific city is an\ninteresting, but challenging, problem. Different techniques have been proposed,\ncombining collaborative, content, social, and geographical signals; however it\nis not trivial to decide which tech- nique works best, since this may depend on\nthe data density or the amount of activity logged for each user or item. At the\nsame time, cross-domain strategies have been exploited in the recommender\nsystems literature when dealing with (very) sparse situations, such as those\ninherently arising when recommendations are produced based on information from\na single city.\n  In this paper, we address the problem of venue recommendation from a novel\nperspective: applying cross-domain recommenda- tion techniques considering each\ncity as a different domain. We perform an experimental comparison of several\nrecommendation techniques in a temporal split under two conditions:\nsingle-domain (only information from the target city is considered) and cross-\ndomain (information from many other cities is incorporated into the\nrecommendation algorithm). For the latter, we have explored two strategies to\ntransfer knowledge from one domain to another: testing the target city and\ntraining a model with information of the k cities with more ratings or only\nusing the k closest cities.\n  Our results show that, in general, applying cross-domain by proximity\nincreases the performance of the majority of the recom- menders in terms of\nrelevance. This is the first work, to the best of our knowledge, where so many\ndomains (eight) are combined in the tourism context where a temporal split is\nused, and thus we expect these results could provide readers with an overall\npicture of what can be achieved in a real-world environment.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 09:31:11 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["S\u00e1nchez", "Pablo", ""], ["Bellog\u00edn", "Alejandro", ""]]}, {"id": "1809.09875", "submitter": "Clemens-Alexander Brust", "authors": "Clemens-Alexander Brust, Christoph K\\\"ading, Joachim Denzler", "title": "Active Learning for Deep Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The great success that deep models have achieved in the past is mainly owed\nto large amounts of labeled training data. However, the acquisition of labeled\ndata for new tasks aside from existing benchmarks is both challenging and\ncostly. Active learning can make the process of labeling new data more\nefficient by selecting unlabeled samples which, when labeled, are expected to\nimprove the model the most. In this paper, we combine a novel method of active\nlearning for object detection with an incremental learning scheme to enable\ncontinuous exploration of new unlabeled datasets. We propose a set of\nuncertainty-based active learning metrics suitable for most object detectors.\nFurthermore, we present an approach to leverage class imbalances during sample\nselection. All methods are evaluated systematically in a continuous exploration\ncontext on the PASCAL VOC 2012 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 09:47:42 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Brust", "Clemens-Alexander", ""], ["K\u00e4ding", "Christoph", ""], ["Denzler", "Joachim", ""]]}, {"id": "1809.09879", "submitter": "Dieter Mitsche", "authors": "Josep Diaz, Colin McDiarmid, Dieter Mitsche", "title": "Learning random points from geometric graphs or orderings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that there is a family of $n$ random points $X_v$ for $v \\in V$,\nindependently and uniformly distributed in the square\n$\\left[-\\sqrt{n}/2,\\sqrt{n}/2\\right]^2$ of area $n$. We do not see these\npoints, but learn about them in one of the following two ways.\n  Suppose first that we are given the corresponding random geometric graph $G$,\nwhere distinct vertices $u$ and $v$ are adjacent when the Euclidean distance\n$d_E(X_u,X_v)$ is at most $r$. If the threshold distance $r$ satisfies\n$n^{3/14} \\ll r \\ll n^{1/2}$, then the following holds with high probability.\nGiven the graph $G$ (without any geometric information), in polynomial time we\ncan approximately reconstruct the hidden embedding, in the sense that, `up to\nsymmetries', for each vertex $v$ we find a point within distance about $r$ of\n$X_v$; that is, we find an embedding with `displacement' at most about $r$.\n  Now suppose that, instead of being given the graph $G$, we are given, for\neach vertex $v$, the ordering of the other vertices by increasing Euclidean\ndistance from $v$. Then, with high probability, in polynomial time we can find\nan embedding with the much smaller displacement error $O(\\sqrt{\\log n})$.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 09:55:03 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 21:47:50 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Diaz", "Josep", ""], ["McDiarmid", "Colin", ""], ["Mitsche", "Dieter", ""]]}, {"id": "1809.09910", "submitter": "Fanghui Liu", "authors": "Fanghui Liu, Lei Shi, Xiaolin Huang, Jie Yang, and Johan A.K. Suykens", "title": "Generalization Properties of hyper-RKHS and its Applications", "comments": "38 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper generalizes regularized regression problems in a hyper-reproducing\nkernel Hilbert space (hyper-RKHS), illustrates its utility for kernel learning\nand out-of-sample extensions, and proves asymptotic convergence results for the\nintroduced regression models in an approximation theory view. Algorithmically,\nwe consider two regularized regression models with bivariate forms in this\nspace, including kernel ridge regression (KRR) and support vector regression\n(SVR) endowed with hyper-RKHS, and further combine divide-and-conquer with\nNystr\\\"{o}m approximation for scalability in large sample cases. This framework\nis general: the underlying kernel is learned from a broad class, and can be\npositive definite or not, which adapts to various requirements in kernel\nlearning. Theoretically, we study the convergence behavior of regularized\nregression algorithms in hyper-RKHS and derive the learning rates, which goes\nbeyond the classical analysis on RKHS due to the non-trivial independence of\npairwise samples and the characterisation of hyper-RKHS. Experimentally,\nresults on several benchmarks suggest that the employed framework is able to\nlearn a general kernel function form an arbitrary similarity matrix, and thus\nachieves a satisfactory performance on classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 11:11:09 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 16:38:52 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 18:37:13 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Liu", "Fanghui", ""], ["Shi", "Lei", ""], ["Huang", "Xiaolin", ""], ["Yang", "Jie", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1809.09924", "submitter": "Bj\\\"orn Barz", "authors": "Bj\\\"orn Barz, Joachim Denzler", "title": "Hierarchy-based Image Embeddings for Semantic Image Retrieval", "comments": "Accepted at WACV 2019. Source code:\n  https://github.com/cvjena/semantic-embeddings", "journal-ref": "2019 IEEE Winter Conference on Applications of Computer Vision\n  (WACV), Waikoloa Village, HI, USA, 2019, pp. 638-647", "doi": "10.1109/WACV.2019.00073", "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks trained for classification have been found to learn\npowerful image representations, which are also often used for other tasks such\nas comparing images w.r.t. their visual similarity. However, visual similarity\ndoes not imply semantic similarity. In order to learn semantically\ndiscriminative features, we propose to map images onto class embeddings whose\npair-wise dot products correspond to a measure of semantic similarity between\nclasses. Such an embedding does not only improve image retrieval results, but\ncould also facilitate integrating semantics for other tasks, e.g., novelty\ndetection or few-shot learning. We introduce a deterministic algorithm for\ncomputing the class centroids directly based on prior world-knowledge encoded\nin a hierarchy of classes such as WordNet. Experiments on CIFAR-100, NABirds,\nand ImageNet show that our learned semantic image embeddings improve the\nsemantic consistency of image retrieval results by a large margin.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 11:58:19 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 14:03:18 GMT"}, {"version": "v3", "created": "Wed, 21 Nov 2018 11:55:13 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2019 15:13:18 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Barz", "Bj\u00f6rn", ""], ["Denzler", "Joachim", ""]]}, {"id": "1809.09925", "submitter": "Yawei Luo", "authors": "Yawei Luo, Tao Guan, Junqing Yu, Ping Liu, Yi Yang", "title": "Every Node Counts: Self-Ensembling Graph Convolutional Networks for\n  Semi-Supervised Learning", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional network (GCN) provides a powerful means for graph-based\nsemi-supervised tasks. However, as a localized first-order approximation of\nspectral graph convolution, the classic GCN can not take full advantage of\nunlabeled data, especially when the unlabeled node is far from labeled ones. To\ncapitalize on the information from unlabeled nodes to boost the training for\nGCN, we propose a novel framework named Self-Ensembling GCN (SEGCN), which\nmarries GCN with Mean Teacher - another powerful model in semi-supervised\nlearning. SEGCN contains a student model and a teacher model. As a student, it\nnot only learns to correctly classify the labeled nodes, but also tries to be\nconsistent with the teacher on unlabeled nodes in more challenging situations,\nsuch as a high dropout rate and graph collapse. As a teacher, it averages the\nstudent model weights and generates more accurate predictions to lead the\nstudent. In such a mutual-promoting process, both labeled and unlabeled samples\ncan be fully utilized for backpropagating effective gradients to train GCN. In\nthree article classification tasks, i.e. Citeseer, Cora and Pubmed, we validate\nthat the proposed method matches the state of the arts in the classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 11:59:00 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Luo", "Yawei", ""], ["Guan", "Tao", ""], ["Yu", "Junqing", ""], ["Liu", "Ping", ""], ["Yang", "Yi", ""]]}, {"id": "1809.09953", "submitter": "Max Farrell", "authors": "Max H. Farrell and Tengyuan Liang and Sanjog Misra", "title": "Deep Neural Networks for Estimation and Inference", "comments": null, "journal-ref": "Econometrica, vol 89, no 1, 181-213, 2021", "doi": "10.3982/ECTA16901", "report-no": null, "categories": "econ.EM cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study deep neural networks and their use in semiparametric inference. We\nestablish novel rates of convergence for deep feedforward neural nets. Our new\nrates are sufficiently fast (in some cases minimax optimal) to allow us to\nestablish valid second-step inference after first-step estimation with deep\nlearning, a result also new to the literature. Our estimation rates and\nsemiparametric inference results handle the current standard architecture:\nfully connected feedforward neural networks (multi-layer perceptrons), with the\nnow-common rectified linear unit activation function and a depth explicitly\ndiverging with the sample size. We discuss other architectures as well,\nincluding fixed-width, very deep networks. We establish nonasymptotic bounds\nfor these deep nets for a general class of nonparametric regression-type loss\nfunctions, which includes as special cases least squares, logistic regression,\nand other generalized linear models. We then apply our theory to develop\nsemiparametric inference, focusing on causal parameters for concreteness, such\nas treatment effects, expected welfare, and decomposition effects. Inference in\nmany other semiparametric contexts can be readily obtained. We demonstrate the\neffectiveness of deep learning with a Monte Carlo analysis and an empirical\napplication to direct mail marketing.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 13:04:23 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 00:03:51 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 14:23:32 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Farrell", "Max H.", ""], ["Liang", "Tengyuan", ""], ["Misra", "Sanjog", ""]]}, {"id": "1809.09968", "submitter": "Juncheng Shen", "authors": "Juncheng Shen, Juzheng Liu, Yiran Chen and Hai Li", "title": "Towards Efficient and Secure Delivery of Data for Training and Inference\n  with Privacy-Preserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy recently emerges as a severe concern in deep learning, that is,\nsensitive data must be prohibited from being shared with the third party during\ndeep neural network development. In this paper, we propose Morphed Learning\n(MoLe), an efficient and secure scheme to deliver deep learning data. MoLe has\ntwo main components: data morphing and Augmented Convolutional (Aug-Conv)\nlayer. Data morphing allows data providers to send morphed data without privacy\ninformation, while Aug-Conv layer helps deep learning developers to apply their\nnetworks on the morphed data without performance penalty. MoLe provides\nstronger security while introducing lower overhead compared to GAZELLE (USENIX\nSecurity 2018), which is another method with no performance penalty on the\nneural network. When using MoLe for VGG-16 network on CIFAR dataset, the\ncomputational overhead is only 9% and the data transmission overhead is 5.12%.\nAs a comparison, GAZELLE has computational overhead of 10,000 times and data\ntransmission overhead of 421,000 times. In this setting, the attack success\nrate of adversary is 7.9 x 10^{-90} for MoLe and 2.9 x 10^{-30} for GAZELLE,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 07:37:10 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 11:53:00 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 14:54:08 GMT"}, {"version": "v4", "created": "Thu, 9 May 2019 06:18:18 GMT"}, {"version": "v5", "created": "Sun, 7 Jul 2019 06:58:29 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Shen", "Juncheng", ""], ["Liu", "Juzheng", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1809.09994", "submitter": "Alican B\\\"uy\\\"uk\\c{c}ak{\\i}r", "authors": "Alican B\\\"uy\\\"uk\\c{c}ak{\\i}r, Hamed Bonab, Fazli Can", "title": "A Novel Online Stacked Ensemble for Multi-Label Stream Classification", "comments": "10 pages, 4 figures. To be appeared in ACM CIKM 2018, in Torino,\n  Italy", "journal-ref": null, "doi": "10.1145/3269206.3271774", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As data streams become more prevalent, the necessity for online algorithms\nthat mine this transient and dynamic data becomes clearer. Multi-label data\nstream classification is a supervised learning problem where each instance in\nthe data stream is classified into one or more pre-defined sets of labels. Many\nmethods have been proposed to tackle this problem, including but not limited to\nensemble-based methods. Some of these ensemble-based methods are specifically\ndesigned to work with certain multi-label base classifiers; some others employ\nonline bagging schemes to build their ensembles. In this study, we introduce a\nnovel online and dynamically-weighted stacked ensemble for multi-label\nclassification, called GOOWE-ML, that utilizes spatial modeling to assign\noptimal weights to its component classifiers. Our model can be used with any\nexisting incremental multi-label classification algorithm as its base\nclassifier. We conduct experiments with 4 GOOWE-ML-based multi-label ensembles\nand 7 baseline models on 7 real-world datasets from diverse areas of interest.\nOur experiments show that GOOWE-ML ensembles yield consistently better results\nin terms of predictive performance in almost all of the datasets, with respect\nto the other prominent ensemble models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 13:40:50 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["B\u00fcy\u00fck\u00e7ak\u0131r", "Alican", ""], ["Bonab", "Hamed", ""], ["Can", "Fazli", ""]]}, {"id": "1809.10007", "submitter": "Nicolas Anastassacos", "authors": "Nicolas Anastassacos, Mirco Musolesi", "title": "Learning through Probing: a decentralized reinforcement learning\n  architecture for social dilemmas", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning has received significant interest in\nrecent years notably due to the advancements made in deep reinforcement\nlearning which have allowed for the developments of new architectures and\nlearning algorithms. Using social dilemmas as the training ground, we present a\nnovel learning architecture, Learning through Probing (LTP), where agents\nutilize a probing mechanism to incorporate how their opponent's behavior\nchanges when an agent takes an action. We use distinct training phases and\nadjust rewards according to the overall outcome of the experiences accounting\nfor changes to the opponents behavior. We introduce a parameter eta to\ndetermine the significance of these future changes to opponent behavior. When\napplied to the Iterated Prisoner's Dilemma (IPD), LTP agents demonstrate that\nthey can learn to cooperate with each other, achieving higher average\ncumulative rewards than other reinforcement learning methods while also\nmaintaining good performance in playing against static agents that are present\nin Axelrod tournaments. We compare this method with traditional reinforcement\nlearning algorithms and agent-tracking techniques to highlight key differences\nand potential applications. We also draw attention to the differences between\nsolving games and societal-like interactions and analyze the training of\nQ-learning agents in makeshift societies. This is to emphasize how cooperation\nmay emerge in societies and demonstrate this using environments where\ninteractions with opponents are determined through a random encounter format of\nthe IPD.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 14:10:13 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 13:49:32 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Anastassacos", "Nicolas", ""], ["Musolesi", "Mirco", ""]]}, {"id": "1809.10012", "submitter": "Louis Dressel", "authors": "Louis Dressel, Mykel J. Kochenderfer", "title": "Using Neural Networks to Generate Information Maps for Mobile Sensors", "comments": "Accepted to the 2018 IEEE Conference on Decision and Control (CDC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Target localization is a critical task for mobile sensors and has many\napplications. However, generating informative trajectories for these sensors is\na challenging research problem. A common method uses information maps that\nestimate the value of taking measurements from any point in the sensor state\nspace. These information maps are used to generate trajectories; for example, a\ntrajectory might be designed so its distribution of measurements matches the\ndistribution of the information map. Regardless of the trajectory generation\nmethod, generating information maps as new observations are made is critical.\nHowever, it can be challenging to compute these maps in real-time. We propose\nusing convolutional neural networks to generate information maps from a target\nestimate and sensor model in real-time. Simulations show that maps are\naccurately rendered while offering orders of magnitude reduction in computation\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 14:15:27 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Dressel", "Louis", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1809.10020", "submitter": "Romana Markovic", "authors": "Romana Markovic, J\\'er\\^ome Frisch, Christoph van Treeck", "title": "Learning short-term past as predictor of human behavior in commercial\n  buildings", "comments": "Preprint submitted to Energy and Buildings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the question of identifying the time-window in\nshort-term past from which the information regarding the future occupant's\nwindow opening actions and resulting window states in buildings can be\npredicted. The addressed sequence duration was in the range between 30 and 240\ntime-steps of indoor climate data, where the applied temporal discretization\nwas one minute. For that purpose, a deep neural network is trained to predict\nthe window states, where the input sequence duration is handled as an\nadditional hyperparameter. Eventually, the relationship between the prediction\naccuracy and the time-lag of the predicted window state in future is analyzed.\nThe results pointed out, that the optimal predictive performance was achieved\nfor the case where 60 time-steps of the indoor climate data were used as input.\nAdditionally, the results showed that very long sequences (120-240 time-steps)\ncould be addressed efficiently, given the right hyperprameters. Hence, the use\nof the memory over previous hours of high-resolution indoor climate data did\nnot improve the predictive performance, when compared to the case where 30/60\nminutes indoor sequences were used. The analysis of the prediction accuracy in\nthe form of F1 score for the different time-lag of future window states dropped\nfrom 0.51 to 0.27, when shifting the prediction target from 10 to 60 minutes in\nfuture.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 11:31:49 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Markovic", "Romana", ""], ["Frisch", "J\u00e9r\u00f4me", ""], ["van Treeck", "Christoph", ""]]}, {"id": "1809.10025", "submitter": "Evan Cater", "authors": "Sam Saarinen, Evan Cater, Michael Littman", "title": "Personalized Education at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tailoring the presentation of information to the needs of individual students\nleads to massive gains in student outcomes~\\cite{bloom19842}. This finding is\nlikely due to the fact that different students learn differently, perhaps as a\nresult of variation in ability, interest or other\nfactors~\\cite{schiefele1992interest}. Adapting presentations to the educational\nneeds of an individual has traditionally been the domain of experts, making it\nexpensive and logistically challenging to do at scale, and also leading to\ninequity in educational outcomes. Increased course sizes and large MOOC\nenrollments provide an unprecedented access to student data. We propose that\nemerging technologies in reinforcement learning (RL), as well as\nsemi-supervised learning, natural language processing, and computer vision are\ncritical to leveraging this data to provide personalized education at scale.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 19:40:25 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Saarinen", "Sam", ""], ["Cater", "Evan", ""], ["Littman", "Michael", ""]]}, {"id": "1809.10049", "submitter": "Rohan Varma A", "authors": "Rohan Varma, Jelena Kova\\v{c}evi\\'c", "title": "Sampling Theory for Graph Signals on Product Graphs", "comments": "Accepted to GlobalSIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we extend the sampling theory on graphs by constructing a\nframework that exploits the structure in product graphs for efficient sampling\nand recovery of bandlimited graph signals that lie on them. Product graphs are\ngraphs that are composed from smaller graph atoms; we motivate how this model\nis a flexible and useful way to model richer classes of data that can be\nmulti-modal in nature. Previous works have established a sampling theory on\ngraphs for bandlimited signals. Importantly, the framework achieves significant\nsavings in both sample complexity and computational complexity\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 15:08:08 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Varma", "Rohan", ""], ["Kova\u010devi\u0107", "Jelena", ""]]}, {"id": "1809.10073", "submitter": "Amir Emad Marvasti", "authors": "Amir Emad Marvasti, Ehsan Emad Marvasti, George Atia, Hassan Foroosh", "title": "Rediscovering Deep Neural Networks Through Finite-State Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new way of thinking about deep neural networks, in which the\nlinear and non-linear components of the network are naturally derived and\njustified in terms of principles in probability theory. In particular, the\nmodels constructed in our framework assign probabilities to uncertain\nrealizations, leading to Kullback-Leibler Divergence (KLD) as the linear layer.\nIn our model construction, we also arrive at a structure similar to ReLU\nactivation supported with Bayes' theorem. The non-linearities in our framework\nare normalization layers with ReLU and Sigmoid as element-wise approximations.\nAdditionally, the pooling function is derived as a marginalization of spatial\nrandom variables according to the mechanics of the framework. As such, Max\nPooling is an approximation to the aforementioned marginalization process.\nSince our models are comprised of finite state distributions (FSD) as variables\nand parameters, exact computation of information-theoretic quantities such as\nentropy and KLD is possible, thereby providing more objective measures to\nanalyze networks. Unlike existing designs that rely on heuristics, the proposed\nframework restricts subjective interpretations of CNNs and sheds light on the\nfunctionality of neural networks from a completely new perspective.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 15:46:53 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 19:29:42 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Marvasti", "Amir Emad", ""], ["Marvasti", "Ehsan Emad", ""], ["Atia", "George", ""], ["Foroosh", "Hassan", ""]]}, {"id": "1809.10083", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Yue Wu, Wael AbdAlmageed, Premkumar Natarajan", "title": "Unsupervised Adversarial Invariance", "comments": "To appear in Proceedings of NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data representations that contain all the information about target variables\nbut are invariant to nuisance factors benefit supervised learning algorithms by\npreventing them from learning associations between these factors and the\ntargets, thus reducing overfitting. We present a novel unsupervised invariance\ninduction framework for neural networks that learns a split representation of\ndata through competitive training between the prediction task and a\nreconstruction task coupled with disentanglement, without needing any labeled\ninformation about nuisance factors or domain knowledge. We describe an\nadversarial instantiation of this framework and provide analysis of its\nworking. Our unsupervised model outperforms state-of-the-art methods, which are\nsupervised, at inducing invariance to inherent nuisance factors, effectively\nusing synthetic data augmentation to learn invariance, and domain adaptation.\nOur method can be applied to any prediction task, eg., binary/multi-class\nclassification or regression, without loss of generality.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 15:55:22 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Jaiswal", "Ayush", ""], ["Wu", "Yue", ""], ["AbdAlmageed", "Wael", ""], ["Natarajan", "Premkumar", ""]]}, {"id": "1809.10093", "submitter": "Pooya Abolghasemi", "authors": "Pooya Abolghasemi, Amir Mazaheri, Mubarak Shah and Ladislau B\\\"ol\\\"oni", "title": "Pay attention! - Robustifying a Deep Visuomotor Policy through\n  Task-Focused Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent studies have demonstrated the promise of deep visuomotor\npolicies for robot manipulator control. Despite impressive progress, these\nsystems are known to be vulnerable to physical disturbances, such as accidental\nor adversarial bumps that make them drop the manipulated object. They also tend\nto be distracted by visual disturbances such as objects moving in the robot's\nfield of view, even if the disturbance does not physically prevent the\nexecution of the task. In this paper, we propose an approach for augmenting a\ndeep visuomotor policy trained through demonstrations with Task Focused visual\nAttention (TFA). The manipulation task is specified with a natural language\ntext such as `move the red bowl to the left'. This allows the visual attention\ncomponent to concentrate on the current object that the robot needs to\nmanipulate. We show that even in benign environments, the TFA allows the policy\nto consistently outperform a variant with no attention mechanism. More\nimportantly, the new policy is significantly more robust: it regularly recovers\nfrom severe physical disturbances (such as bumps causing it to drop the object)\nfrom which the baseline policy, i.e. with no visual attention, almost never\nrecovers. In addition, we show that the proposed policy performs correctly in\nthe presence of a wide class of visual disturbances, exhibiting a behavior\nreminiscent of human selective visual attention experiments. Our proposed\napproach consists of a VAE-GAN network which encodes the visual input and feeds\nit to a Motor network that moves the robot joints. Also, our approach benefits\nfrom a teacher network for the TFA that leverages textual input command to\nrobustify the visual encoder against various types of disturbances.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 16:06:34 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 23:54:47 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Abolghasemi", "Pooya", ""], ["Mazaheri", "Amir", ""], ["Shah", "Mubarak", ""], ["B\u00f6l\u00f6ni", "Ladislau", ""]]}, {"id": "1809.10120", "submitter": "Yannick Le Cacheux", "authors": "Yannick Le Cacheux, Herv\\'e Le Borgne, Michel Crucianu", "title": "From Classical to Generalized Zero-Shot Learning: a Simple Adaptation\n  Process", "comments": null, "journal-ref": "Proceedings of the 25th International Conference on MultiMedia\n  Modeling (2019), 465-477", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning (ZSL) is concerned with the recognition of previously\nunseen classes. It relies on additional semantic knowledge for which a mapping\ncan be learned with training examples of seen classes. While classical ZSL\nconsiders the recognition performance on unseen classes only, generalized\nzero-shot learning (GZSL) aims at maximizing performance on both seen and\nunseen classes. In this paper, we propose a new process for training and\nevaluation in the GZSL setting; this process addresses the gap in performance\nbetween samples from unseen and seen classes by penalizing the latter, and\nenables to select hyper-parameters well-suited to the GZSL task. It can be\napplied to any existing ZSL approach and leads to a significant performance\nboost: the experimental evaluation shows that GZSL performance, averaged over\neight state-of-the-art methods, is improved from 28.5 to 42.2 on CUB and from\n28.2 to 57.1 on AwA2.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 17:04:42 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Cacheux", "Yannick Le", ""], ["Borgne", "Herv\u00e9 Le", ""], ["Crucianu", "Michel", ""]]}, {"id": "1809.10121", "submitter": "Sarah Dean", "authors": "Sarah Dean, Stephen Tu, Nikolai Matni, Benjamin Recht", "title": "Safely Learning to Control the Constrained Linear Quadratic Regulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the constrained linear quadratic regulator with unknown dynamics,\naddressing the tension between safety and exploration in data-driven control\ntechniques. We present a framework which allows for system identification\nthrough persistent excitation, while maintaining safety by guaranteeing the\nsatisfaction of state and input constraints. This framework involves a novel\nmethod for synthesizing robust constraint-satisfying feedback controllers,\nleveraging newly developed tools from system level synthesis. We connect\nstatistical results with cost sub-optimality bounds to give non-asymptotic\nguarantees on both estimation and controller performance.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 17:04:59 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 12:48:09 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Dean", "Sarah", ""], ["Tu", "Stephen", ""], ["Matni", "Nikolai", ""], ["Recht", "Benjamin", ""]]}, {"id": "1809.10124", "submitter": "Aleksandra Faust", "authors": "Hao-Tien Lewis Chiang, Aleksandra Faust, Marek Fiser, Anthony Francis", "title": "Learning Navigation Behaviors End-to-End with AutoRL", "comments": "Accepted to RA-L/ICRA 2019. Chiang and Faust contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We learn end-to-end point-to-point and path-following navigation behaviors\nthat avoid moving obstacles. These policies receive noisy lidar observations\nand output robot linear and angular velocities. The policies are trained in\nsmall, static environments with AutoRL, an evolutionary automation layer around\nReinforcement Learning (RL) that searches for a deep RL reward and neural\nnetwork architecture with large-scale hyper-parameter optimization. AutoRL\nfirst finds a reward that maximizes task completion, and then finds a neural\nnetwork architecture that maximizes the cumulative of the found reward.\nEmpirical evaluations, both in simulation and on-robot, show that AutoRL\npolicies do not suffer from the catastrophic forgetfulness that plagues many\nother deep reinforcement learning algorithms, generalize to new environments\nand moving obstacles, are robust to sensor, actuator, and localization noise,\nand can serve as robust building blocks for larger navigation tasks. Our\npath-following and point-to-point policies are respectively 23% and 26% more\nsuccessful than comparison methods across new environments. Video at:\nhttps://youtu.be/0UwkjpUEcbI\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 17:09:56 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 23:31:47 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Chiang", "Hao-Tien Lewis", ""], ["Faust", "Aleksandra", ""], ["Fiser", "Marek", ""], ["Francis", "Anthony", ""]]}, {"id": "1809.10139", "submitter": "Soudabeh Barghi", "authors": "Soudabeh Barghi, Lalet Scaria, Ali Salari, Tristan Glatard", "title": "Predicting computational reproducibility of data analysis pipelines in\n  large population studies using collaborative filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the computational reproducibility of data analysis pipelines has\nbecome a critical issue. It is, however, a cumbersome process for analyses that\ninvolve data from large populations of subjects, due to their computational and\nstorage requirements. We present a method to predict the computational\nreproducibility of data analysis pipelines in large population studies. We\nformulate the problem as a collaborative filtering process, with constraints on\nthe construction of the training set. We propose 6 different strategies to\nbuild the training set, which we evaluate on 2 datasets, a synthetic one\nmodeling a population with a growing number of subject types, and a real one\nobtained with neuroinformatics pipelines. Results show that one sampling\nmethod, \"Random File Numbers (Uniform)\" is able to predict computational\nreproducibility with a good accuracy. We also analyze the relevance of\nincluding file and subject biases in the collaborative filtering model. We\nconclude that the proposed method is able to speedup reproducibility\nevaluations substantially, with a reduced accuracy loss.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 20:24:46 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Barghi", "Soudabeh", ""], ["Scaria", "Lalet", ""], ["Salari", "Ali", ""], ["Glatard", "Tristan", ""]]}, {"id": "1809.10141", "submitter": "Maxime Petit", "authors": "Maxime Petit (imagine), Amaury Depierre (imagine), Xiaofang Wang\n  (imagine), Emmanuel Dellandr\\'ea (LIRIS), Liming Chen (imagine)", "title": "Developmental Bayesian Optimization of Black-Box with Visual\n  Similarity-Based Transfer Learning", "comments": null, "journal-ref": "IEEE International Conference on Development and Learning and\n  Epigenetic Robotics (ICDL-EpiRob), Sep 2018, Tokyo, Japan. 2018", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a developmental framework based on a long-term memory and\nreasoning mechanisms (Vision Similarity and Bayesian Optimisation). This\narchitecture allows a robot to optimize autonomously hyper-parameters that need\nto be tuned from any action and/or vision module, treated as a black-box. The\nlearning can take advantage of past experiences (stored in the episodic and\nprocedural memories) in order to warm-start the exploration using a set of\nhyper-parameters previously optimized from objects similar to the new unknown\none (stored in a semantic memory). As example, the system has been used to\noptimized 9 continuous hyper-parameters of a professional software (Kamido)\nboth in simulation and with a real robot (industrial robotic arm Fanuc) with a\ntotal of 13 different objects. The robot is able to find a good object-specific\noptimization in 68 (simulation) or 40 (real) trials. In simulation, we\ndemonstrate the benefit of the transfer learning based on visual similarity, as\nopposed to an amnesic learning (i.e. learning from scratch all the time).\nMoreover, with the real robot, we show that the method consistently outperforms\nthe manual optimization from an expert with less than 2 hours of training time\nto achieve more than 88% of success.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 09:06:38 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 07:56:02 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 12:09:03 GMT"}, {"version": "v4", "created": "Tue, 16 Oct 2018 10:02:02 GMT"}, {"version": "v5", "created": "Wed, 17 Oct 2018 08:26:10 GMT"}, {"version": "v6", "created": "Thu, 18 Oct 2018 06:30:25 GMT"}, {"version": "v7", "created": "Fri, 19 Oct 2018 06:26:33 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Petit", "Maxime", "", "imagine"], ["Depierre", "Amaury", "", "imagine"], ["Wang", "Xiaofang", "", "imagine"], ["Dellandr\u00e9a", "Emmanuel", "", "LIRIS"], ["Chen", "Liming", "", "imagine"]]}, {"id": "1809.10168", "submitter": "Viet Hung Tran", "authors": "Viet Hung Tran and Wenwu Wang", "title": "Bayesian inference for PCA and MUSIC algorithms with unknown number of\n  sources", "comments": "IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is a popular method for projecting data\nonto uncorrelated components in lower dimension, although the optimal number of\ncomponents is not specified. Likewise, multiple signal classification (MUSIC)\nalgorithm is a popular PCA-based method for estimating directions of arrival\n(DOAs) of sinusoidal sources, yet it requires the number of sources to be known\na priori. The accurate estimation of the number of sources is hence a crucial\nissue for performance of these algorithms. In this paper, we will show that\nboth PCA and MUSIC actually return the exact joint maximum-a-posteriori (MAP)\nestimate for uncorrelated steering vectors, although they can only compute this\nMAP estimate approximately in correlated case. We then use Bayesian method to,\nfor the first time, compute the MAP estimate for the number of sources in PCA\nand MUSIC algorithms. Intuitively, this MAP estimate corresponds to the highest\nprobability that signal-plus-noise's variance still dominates projected noise's\nvariance on signal subspace. In simulations of overlapping multi-tone sources\nfor linear sensor array, our exact MAP estimate is far superior to the\nasymptotic Akaike information criterion (AIC), which is a popular method for\nestimating the number of components in PCA and MUSIC algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 18:08:25 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Tran", "Viet Hung", ""], ["Wang", "Wenwu", ""]]}, {"id": "1809.10170", "submitter": "Jiyuan Zhang", "authors": "Jiyuan Zhang, Franz Franchetti, Tze Meng Low", "title": "High Performance Zero-Memory Overhead Direct Convolutions", "comments": "the 35th International Conference on Machine Learning(ICML 2018),\n  camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of convolution layers in deep neural networks typically rely\non high performance routines that trade space for time by using additional\nmemory (either for packing purposes or required as part of the algorithm) to\nimprove performance. The problems with such an approach are two-fold. First,\nthese routines incur additional memory overhead which reduces the overall size\nof the network that can fit on embedded devices with limited memory capacity.\nSecond, these high performance routines were not optimized for performing\nconvolution, which means that the performance obtained is usually less than\nconventionally expected. In this paper, we demonstrate that direct convolution,\nwhen implemented correctly, eliminates all memory overhead, and yields\nperformance that is between 10% to 400% times better than existing high\nperformance implementations of convolution layers on conventional and embedded\nCPU architectures. We also show that a high performance direct convolution\nexhibits better scaling performance, i.e. suffers less performance drop, when\nincreasing the number of threads.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 00:48:12 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Zhang", "Jiyuan", ""], ["Franchetti", "Franz", ""], ["Low", "Tze Meng", ""]]}, {"id": "1809.10188", "submitter": "Linfeng Zhang", "authors": "Linfeng Zhang, Weinan E, Lei Wang", "title": "Monge-Amp\\`ere Flow for Generative Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep generative model, named Monge-Amp\\`ere flow, which builds\non continuous-time gradient flow arising from the Monge-Amp\\`ere equation in\noptimal transport theory. The generative map from the latent space to the data\nspace follows a dynamical system, where a learnable potential function guides a\ncompressible fluid to flow towards the target density distribution. Training of\nthe model amounts to solving an optimal control problem. The Monge-Amp\\`ere\nflow has tractable likelihoods and supports efficient sampling and inference.\nOne can easily impose symmetry constraints in the generative model by designing\nsuitable scalar potential functions. We apply the approach to unsupervised\ndensity estimation of the MNIST dataset and variational calculation of the\ntwo-dimensional Ising model at the critical point. This approach brings\ninsights and techniques from Monge-Amp\\`ere equation, optimal transport, and\nfluid dynamics into reversible flow-based generative models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 18:53:51 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Zhang", "Linfeng", ""], ["E", "Weinan", ""], ["Wang", "Lei", ""]]}, {"id": "1809.10190", "submitter": "Suraj Kothawade", "authors": "Suraj Kothawade, Kunjan Mhaske, Sahil Sharma, Furkhan Shaikh", "title": "Content Based Image Retrieval from AWiFS Images Repository of IRS\n  Resourcesat-2 Satellite Based on Water Bodies and Burnt Areas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satellite Remote Sensing Technology is becoming a major milestone in the\nprediction of weather anomalies, natural disasters as well as finding\nalternative resources in proximity using multiple multi-spectral sensors\nemitting electromagnetic waves at distinct wavelengths. Hence, it is imperative\nto extract water bodies and burnt areas from orthorectified tiles and\ncorrespondingly rank them using similarity measures. Different objects in all\nthe spheres of the earth have the inherent capability of absorbing\nelectromagnetic waves of distant wavelengths. This creates various unique masks\nin terms of reflectance on the receptor. We propose Dynamic Semantic\nSegmentation (DSS) algorithms that utilized the mentioned capability to extract\nand rank Advanced Wide Field Sensor (AWiFS) images according to various\nfeatures. This system stores data intelligently in the form of a sparse feature\nvector which drastically mitigates the computational and spatial costs incurred\nfor further analysis. The compressed source image is divided into chunks and\nstored in the database for quicker retrieval. This work is intended to utilize\nreadily available and cost effective resources like AWiFS dataset instead of\ndepending on advanced technologies like Moderate Resolution Imaging\nSpectroradiometer (MODIS) for data which is scarce.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 18:58:24 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Kothawade", "Suraj", ""], ["Mhaske", "Kunjan", ""], ["Sharma", "Sahil", ""], ["Shaikh", "Furkhan", ""]]}, {"id": "1809.10200", "submitter": "Edouard Oyallon", "authors": "Edouard Oyallon and Eugene Belilovsky and Sergey Zagoruyko and Michal\n  Valko", "title": "Compressing the Input for CNNs with the First-Order Scattering Transform", "comments": null, "journal-ref": "ECCV 2018", "doi": "10.1007/978-3-030-01240-3_19", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the first-order scattering transform as a candidate for reducing the\nsignal processed by a convolutional neural network (CNN). We show theoretical\nand empirical evidence that in the case of natural images and sufficiently\nsmall translation invariance, this transform preserves most of the signal\ninformation needed for classification while substantially reducing the spatial\nresolution and total signal size. We demonstrate that cascading a CNN with this\nrepresentation performs on par with ImageNet classification models, commonly\nused in downstream tasks, such as the ResNet-50. We subsequently apply our\ntrained hybrid ImageNet model as a base model on a detection system, which has\ntypically larger image inputs. On Pascal VOC and COCO detection tasks we\ndemonstrate improvements in the inference speed and training memory consumption\ncompared to models trained directly on the input image.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 10:14:46 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Oyallon", "Edouard", ""], ["Belilovsky", "Eugene", ""], ["Zagoruyko", "Sergey", ""], ["Valko", "Michal", ""]]}, {"id": "1809.10203", "submitter": "Defeng Chen", "authors": "Han Kang, Defeng Chen", "title": "Multi-Scale Fully Convolutional Network for Cardiac Left Ventricle\n  Segmentation", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The morphological structure of left ventricle segmented from cardiac magnetic\nresonance images can be used to calculate key clinical parameters, and it is of\ngreat significance to the accurate and efficient diagnosis of cardiovascular\ndiseases. Compared with traditional methods, the segmentation algorithms based\non fully convolutional neural network greatly improve the accuracy of semantic\nsegmentation. For the problem of left ventricular segmentation, a new fully\nconvolutional neural network structure named MS-FCN is proposed in this paper.\nThe MS-FCN network employs a multi-scale pooling module to ensure that the\nnetwork maximises the feature extraction ability and uses a dense connectivity\ndecoder to refine the boundaries of the object. Based on the Sunnybrook cine-MR\ndataset provided by the MICCAI 2009 challenge, numerical experiments\ndemonstrate that our proposed model has obtained state-of-the-art segmentation\nresults: the Dice score of our method reaches 0.93 on the endocardium, and 0.96\non the epicardium.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 08:13:05 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Kang", "Han", ""], ["Chen", "Defeng", ""]]}, {"id": "1809.10210", "submitter": "Cun Mu", "authors": "Guang Yang and Cun Mu", "title": "A Machine Learning Approach to Shipping Box Design", "comments": "Accepted by 2019 Intelligent Systems Conference (A shorter version of\n  the paper is presented at the 13th INFORMS Workshop on Data Mining and\n  Decision Analytics)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having the right assortment of shipping boxes in the fulfillment warehouse to\npack and ship customer's online orders is an indispensable and integral part of\nnowadays eCommerce business, as it will not only help maintain a profitable\nbusiness but also create great experiences for customers. However, it is an\nextremely challenging operations task to strategically select the best\ncombination of tens of box sizes from thousands of feasible ones to be\nresponsible for hundreds of thousands of orders daily placed on millions of\ninventory products. In this paper, we present a machine learning approach to\ntackle the task by formulating the box design problem prescriptively as a\ngeneralized version of weighted $k$-medoids clustering problem, where the\nparameters are estimated through a variety of descriptive analytics. We test\nthis machine learning approach on fulfillment data collected from Walmart U.S.\neCommerce, and our approach is shown to be capable of improving the box\nutilization rate by more than $10\\%$.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 19:48:45 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 08:41:26 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 19:41:14 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Yang", "Guang", ""], ["Mu", "Cun", ""]]}, {"id": "1809.10224", "submitter": "Quan Geng", "authors": "Quan Geng, Wei Ding, Ruiqi Guo, and Sanjiv Kumar", "title": "Optimal Noise-Adding Mechanism in Additive Differential Privacy", "comments": "10 pages, 5 figures. Accepted by the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the optimal $(0, \\delta)$-differentially private query-output\nindependent noise-adding mechanism for single real-valued query function under\na general cost-minimization framework. Under a mild technical condition, we\nshow that the optimal noise probability distribution is a uniform distribution\nwith a probability mass at the origin. We explicitly derive the optimal noise\ndistribution for general $\\ell^p$ cost functions, including $\\ell^1$ (for noise\nmagnitude) and $\\ell^2$ (for noise power) cost functions, and show that the\nprobability concentration on the origin occurs when $\\delta > \\frac{p}{p+1}$.\nOur result demonstrates an improvement over the existing Gaussian mechanisms by\na factor of two and three for $(0,\\delta)$-differential privacy in the high\nprivacy regime in the context of minimizing the noise magnitude and noise\npower, and the gain is more pronounced in the low privacy regime. Our result is\nconsistent with the existing result for $(0,\\delta)$-differential privacy in\nthe discrete setting, and identifies a probability concentration phenomenon in\nthe continuous setting.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 20:41:01 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 16:06:17 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Geng", "Quan", ""], ["Ding", "Wei", ""], ["Guo", "Ruiqi", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1809.10229", "submitter": "Gabriel Dahia", "authors": "Gabriel Dahia, Maur\\'icio Pamplona Segundo", "title": "Automatic Dataset Annotation to Learn CNN Pore Description for\n  Fingerprint Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-resolution fingerprint recognition often relies on sophisticated\nmatching algorithms based on hand-crafted keypoint descriptors, with pores\nbeing the most common keypoint choice. Our method is the opposite of the\nprevalent approach: we use instead a simple matching algorithm based on robust\nlocal pore descriptors that are learned from the data using a CNN. In order to\ntrain this CNN in a fully supervised manner, we describe how the automatic\nalignment of fingerprint images can be used to obtain the required training\nannotations, which are otherwise missing in all publicly available datasets.\nThis improves the state-of-the-art recognition results for both partial and\nfull fingerprints in a public benchmark. To confirm that the observed\nimprovement is due to the adoption of learned descriptors, we conduct an\nablation study using the most successful pore descriptors previously used in\nthe literature. All our code is available at\nhttps://github.com/gdahia/high-res-fingerprint-recognition\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 20:50:23 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 00:08:54 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 20:49:37 GMT"}, {"version": "v4", "created": "Thu, 22 Nov 2018 13:13:02 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Dahia", "Gabriel", ""], ["Segundo", "Maur\u00edcio Pamplona", ""]]}, {"id": "1809.10231", "submitter": "Ren\\'e Corbet", "authors": "Ren\\'e Corbet, Ulderico Fugacci, Michael Kerber, Claudia Landi, Bei\n  Wang", "title": "A Kernel for Multi-Parameter Persistent Homology", "comments": "24 pages, 5 figures", "journal-ref": "Computers & Graphics (2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.CG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological data analysis and its main method, persistent homology, provide a\ntoolkit for computing topological information of high-dimensional and noisy\ndata sets. Kernels for one-parameter persistent homology have been established\nto connect persistent homology with machine learning techniques. We contribute\na kernel construction for multi-parameter persistence by integrating a\none-parameter kernel weighted along straight lines. We prove that our kernel is\nstable and efficiently computable, which establishes a theoretical connection\nbetween topological data analysis and machine learning for multivariate data\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 21:00:58 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 11:28:45 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Corbet", "Ren\u00e9", ""], ["Fugacci", "Ulderico", ""], ["Kerber", "Michael", ""], ["Landi", "Claudia", ""], ["Wang", "Bei", ""]]}, {"id": "1809.10232", "submitter": "Xi-Lin Li", "authors": "Xi-Lin Li", "title": "Preconditioner on Matrix Lie Group for SGD", "comments": "to appear on ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two types of preconditioners and preconditioned stochastic gradient\ndescent (SGD) methods in a unified framework. We call the first one the Newton\ntype due to its close relationship to the Newton method, and the second one the\nFisher type as its preconditioner is closely related to the inverse of Fisher\ninformation matrix. Both preconditioners can be derived from one framework, and\nefficiently estimated on any matrix Lie groups designated by the user using\nnatural or relative gradient descent minimizing certain preconditioner\nestimation criteria. Many existing preconditioners and methods, e.g., RMSProp,\nAdam, KFAC, equilibrated SGD, batch normalization, etc., are special cases of\nor closely related to either the Newton type or the Fisher type ones.\nExperimental results on relatively large scale machine learning problems are\nreported for performance study.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 21:04:23 GMT"}, {"version": "v2", "created": "Tue, 25 Dec 2018 00:10:24 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Li", "Xi-Lin", ""]]}, {"id": "1809.10237", "submitter": "Jiachen Li", "authors": "Jiachen Li, Wei Zhan and Masayoshi Tomizuka", "title": "Generic Vehicle Tracking Framework Capable of Handling Occlusions Based\n  on Modified Mixture Particle Filter", "comments": "Presented in 2018 IEEE Intelligent Vehicles Symposium (IV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and robust tracking of surrounding road participants plays an\nimportant role in autonomous driving. However, there is usually no prior\nknowledge of the number of tracking targets due to object emergence, object\ndisappearance and false alarms. To overcome this challenge, we propose a\ngeneric vehicle tracking framework based on modified mixture particle filter,\nwhich can make the number of tracking targets adaptive to real-time\nobservations and track all the vehicles within sensor range simultaneously in a\nuniform architecture without explicit data association. Each object corresponds\nto a mixture component whose distribution is non-parametric and approximated by\nparticle hypotheses. Most tracking approaches employ vehicle kinematic models\nas the prediction model. However, it is hard for these models to make proper\npredictions when sensor measurements are lost or become low quality due to\npartial or complete occlusions. Moreover, these models are incapable of\nforecasting sudden maneuvers. To address these problems, we propose to\nincorporate learning-based behavioral models instead of pure vehicle kinematic\nmodels to realize prediction in the prior update of recursive Bayesian state\nestimation. Two typical driving scenarios including lane keeping and lane\nchange are demonstrated to verify the effectiveness and accuracy of the\nproposed framework as well as the advantages of employing learning-based\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 05:27:47 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Li", "Jiachen", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1809.10238", "submitter": "Joseph K J", "authors": "K J Joseph, Arghya Pal, Sailaja Rajanala, Vineeth N Balasubramanian", "title": "C4Synth: Cross-Caption Cycle-Consistent Text-to-Image Synthesis", "comments": "To appear in the proceedings of IEEE Winter Conference on\n  Applications of Computer Vision, WACV-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generating an image from its description is a challenging task worth solving\nbecause of its numerous practical applications ranging from image editing to\nvirtual reality. All existing methods use one single caption to generate a\nplausible image. A single caption by itself, can be limited, and may not be\nable to capture the variety of concepts and behavior that may be present in the\nimage. We propose two deep generative models that generate an image by making\nuse of multiple captions describing it. This is achieved by ensuring\n'Cross-Caption Cycle Consistency' between the multiple captions and the\ngenerated image(s). We report quantitative and qualitative results on the\nstandard Caltech-UCSD Birds (CUB) and Oxford-102 Flowers datasets to validate\nthe efficacy of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 07:18:57 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Joseph", "K J", ""], ["Pal", "Arghya", ""], ["Rajanala", "Sailaja", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1809.10239", "submitter": "Berta Besc\\'os Torcal", "authors": "Berta Bescos, Jos\\'e Neira, Roland Siegwart, Cesar Cadena", "title": "Empty Cities: Image Inpainting for a Dynamic-Object-Invariant Space", "comments": "Accepted for Publication at IEEE International Conference on Robotics\n  and Automation (ICRA) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we present an end-to-end deep learning framework to turn images\nthat show dynamic content, such as vehicles or pedestrians, into realistic\nstatic frames. This objective encounters two main challenges: detecting all the\ndynamic objects, and inpainting the static occluded background with plausible\nimagery. The second problem is approached with a conditional generative\nadversarial model that, taking as input the original dynamic image and its\ndynamic/static binary mask, is capable of generating the final static image.\nThe former challenge is addressed by the use of a convolutional network that\nlearns a multi-class semantic segmentation of the image.\n  These generated images can be used for applications such as augmented reality\nor vision-based robot localization purposes. To validate our approach, we show\nboth qualitative and quantitative comparisons against other state-of-the-art\ninpainting methods by removing the dynamic objects and hallucinating the static\nstructure behind them. Furthermore, to demonstrate the potential of our\nresults, we carry out pilot experiments that show the benefits of our proposal\nfor visual place recognition.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 08:13:52 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 09:36:18 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Bescos", "Berta", ""], ["Neira", "Jos\u00e9", ""], ["Siegwart", "Roland", ""], ["Cadena", "Cesar", ""]]}, {"id": "1809.10240", "submitter": "Guanghua Xiao", "authors": "Shidan Wang, Tao Wang, Lin Yang, Faliu Yi, Xin Luo, Yikun Yang, Adi\n  Gazdar, Junya Fujimoto, Ignacio I. Wistuba, Bo Yao, ShinYi Lin, Yang Xie,\n  Yousheng Mao, Guanghua Xiao", "title": "ConvPath: A Software Tool for Lung Adenocarcinoma Digital Pathological\n  Image Analysis Aided by Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial distributions of different types of cells could reveal a cancer\ncell growth pattern, its relationships with the tumor microenvironment and the\nimmune response of the body, all of which represent key hallmarks of cancer.\nHowever, manually recognizing and localizing all the cells in pathology slides\nare almost impossible. In this study, we developed an automated cell type\nclassification pipeline, ConvPath, which includes nuclei segmentation,\nconvolutional neural network-based tumor, stromal and lymphocytes\nclassification, and extraction of tumor microenvironment related features for\nlung cancer pathology images. The overall classification accuracy is 92.9% and\n90.1% in training and independent testing datasets, respectively. By\nidentifying cells and classifying cell types, this pipeline can convert a\npathology image into a spatial map of tumor, stromal and lymphocyte cells. From\nthis spatial map, we can extracted features that characterize the tumor\nmicro-environment. Based on these features, we developed an image feature-based\nprognostic model and validated the model in two independent cohorts. The\npredicted risk group serves as an independent prognostic factor, after\nadjusting for clinical variables that include age, gender, smoking status, and\nstage.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 13:31:51 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Wang", "Shidan", ""], ["Wang", "Tao", ""], ["Yang", "Lin", ""], ["Yi", "Faliu", ""], ["Luo", "Xin", ""], ["Yang", "Yikun", ""], ["Gazdar", "Adi", ""], ["Fujimoto", "Junya", ""], ["Wistuba", "Ignacio I.", ""], ["Yao", "Bo", ""], ["Lin", "ShinYi", ""], ["Xie", "Yang", ""], ["Mao", "Yousheng", ""], ["Xiao", "Guanghua", ""]]}, {"id": "1809.10241", "submitter": "Shanshan Wang", "authors": "Jingxu Xu, Cheng Li, Yongjin Zhou, Lisha Mou, Hairong Zheng, and\n  Shanshan Wang", "title": "Classifying Mammographic Breast Density by Residual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mammographic breast density, a parameter used to describe the proportion of\nbreast tissue fibrosis, is widely adopted as an evaluation characteristic of\nthe likelihood of breast cancer incidence. In this study, we present a\nradiomics approach based on residual learning for the classification of\nmammographic breast densities. Our method possesses several encouraging\nproperties such as being almost fully automatic, possessing big model capacity\nand flexibility. It can obtain outstanding classification results without the\nnecessity of result compensation using mammographs taken from different views.\nThe proposed method was instantiated with the INbreast dataset and\nclassification accuracies of 92.6% and 96.8% were obtained for the four BI-RADS\n(Breast Imaging and Reporting Data System) category task and the two BI-RADS\ncategory task,respectively. The superior performances achieved compared to the\nexisting state-of-the-art methods along with its encouraging properties\nindicate that our method has a great potential to be applied as a\ncomputer-aided diagnosis tool.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 06:29:50 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Xu", "Jingxu", ""], ["Li", "Cheng", ""], ["Zhou", "Yongjin", ""], ["Mou", "Lisha", ""], ["Zheng", "Hairong", ""], ["Wang", "Shanshan", ""]]}, {"id": "1809.10242", "submitter": "Zhujun Xiao", "authors": "Zhujun Xiao, Yanzi Zhu, Yuxin Chen, Ben Y. Zhao, Junchen Jiang, Haitao\n  Zheng", "title": "Addressing Training Bias via Automated Image Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Build accurate DNN models requires training on large labeled, context\nspecific datasets, especially those matching the target scenario. We believe\nadvances in wireless localization, working in unison with cameras, can produce\nautomated annotation of targets on images and videos captured in the wild.\nUsing pedestrian and vehicle detection as examples, we demonstrate the\nfeasibility, benefits, and challenges of an automatic image annotation system.\nOur work calls for new technical development on passive localization, mobile\ndata analytics, and error-resilient ML models, as well as design issues in user\nprivacy policies.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 19:47:01 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 12:09:25 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Xiao", "Zhujun", ""], ["Zhu", "Yanzi", ""], ["Chen", "Yuxin", ""], ["Zhao", "Ben Y.", ""], ["Jiang", "Junchen", ""], ["Zheng", "Haitao", ""]]}, {"id": "1809.10243", "submitter": "Navid Alemi Koohbanani", "authors": "Mostafa Jahanifar, Neda Zamani Tajeddin, Navid Alemi Koohbanani, Ali\n  Gooya, and Nasir Rajpoot", "title": "Segmentation of Skin Lesions and their Attributes Using Multi-Scale\n  Convolutional Neural Networks and Domain Specific Augmentations", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided diagnosis systems for classification of different type of skin\nlesions have been an active field of research in recent decades. It has been\nshown that introducing lesions and their attributes masks into lesion\nclassification pipeline can greatly improve the performance. In this paper, we\npropose a framework by incorporating transfer learning for segmenting lesions\nand their attributes based on the convolutional neural networks. The proposed\nframework is based on the encoder-decoder architecture which utilizes a variety\nof pre-trained networks in the encoding path and generates the prediction map\nby combining multi-scale information in decoding path using a pyramid pooling\nmanner. To address the lack of training data and increase the proposed model\ngeneralization, an extensive set of novel domain-specific augmentation routines\nhave been applied to simulate the real variations in dermoscopy images.\nFinally, by performing broad experiments on three different data sets obtained\nfrom International Skin Imaging Collaboration archive (ISIC2016, ISIC2017, and\nISIC2018 challenges data sets), we show that the proposed method outperforms\nother state-of-the-art approaches for ISIC2016 and ISIC2017 segmentation task\nand achieved the first rank on the leader-board of ISIC2018 attribute detection\ntask.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 18:01:14 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 02:16:00 GMT"}, {"version": "v3", "created": "Fri, 29 Mar 2019 09:12:34 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Jahanifar", "Mostafa", ""], ["Tajeddin", "Neda Zamani", ""], ["Koohbanani", "Navid Alemi", ""], ["Gooya", "Ali", ""], ["Rajpoot", "Nasir", ""]]}, {"id": "1809.10252", "submitter": "Ahmed Qureshi", "authors": "Ahmed H. Qureshi and Michael C. Yip", "title": "Deeply Informed Neural Sampling for Robot Motion Planning", "comments": "2018 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling-based Motion Planners (SMPs) have become increasingly popular as\nthey provide collision-free path solutions regardless of obstacle geometry in a\ngiven environment. However, their computational complexity increases\nsignificantly with the dimensionality of the motion planning problem. Adaptive\nsampling is one of the ways to speed up SMPs by sampling a particular region of\na configuration space that is more likely to contain an optimal path solution.\nAlthough there are a wide variety of algorithms for adaptive sampling, they\nrely on hand-crafted heuristics; furthermore, their performance decreases\nsignificantly in high-dimensional spaces. In this paper, we present a neural\nnetwork-based adaptive sampler for motion planning called Deep Sampling-based\nMotion Planner (DeepSMP). DeepSMP generates samples for SMPs and enhances their\noverall speed significantly while exhibiting efficient scalability to\nhigher-dimensional problems. DeepSMP's neural architecture comprises of a\nContractive AutoEncoder which encodes given workspaces directly from a raw\npoint cloud data, and a Dropout-based stochastic deep feedforward neural\nnetwork which takes the workspace encoding, start and goal configuration, and\niteratively generates feasible samples for SMPs to compute end-to-end\ncollision-free optimal paths. DeepSMP is not only consistently computationally\nefficient in all tested environments but has also shown remarkable\ngeneralization to completely unseen environments. We evaluate DeepSMP on\nmultiple planning problems including planning of a point-mass robot,\nrigid-body, 6-link robotic manipulator in various 2D and 3D environments. The\nresults show that on average our method is at least 7 times faster in\npoint-mass and rigid-body case and about 28 times faster in 6-link robot case\nthan the existing state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 22:14:55 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Qureshi", "Ahmed H.", ""], ["Yip", "Michael C.", ""]]}, {"id": "1809.10253", "submitter": "Ryan Julian", "authors": "Ryan Julian, Eric Heiden, Zhanpeng He, Hejia Zhang, Stefan Schaal,\n  Joseph J. Lim, Gaurav Sukhatme, Karol Hausman", "title": "Scaling simulation-to-real transfer by learning composable robot skills", "comments": "Presented at ISER 2018. See\n  https://www.youtube.com/watch?v=Syr2RQTHqTs for supplemental video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel solution to the problem of simulation-to-real transfer,\nwhich builds on recent advances in robot skill decomposition. Rather than\nfocusing on minimizing the simulation-reality gap, we learn a set of diverse\npolicies that are parameterized in a way that makes them easily reusable. This\ndiversity and parameterization of low-level skills allows us to find a\ntransferable policy that is able to use combinations and variations of\ndifferent skills to solve more complex, high-level tasks. In particular, we\nfirst use simulation to jointly learn a policy for a set of low-level skills,\nand a \"skill embedding\" parameterization which can be used to compose them.\nLater, we learn high-level policies which actuate the low-level policies via\nthis skill embedding parameterization. The high-level policies encode how and\nwhen to reuse the low-level skills together to achieve specific high-level\ntasks. Importantly, our method learns to control a real robot in joint-space to\nachieve these high-level tasks with little or no on-robot time, despite the\nfact that the low-level policies may not be perfectly transferable from\nsimulation to real, and that the low-level skills were not trained on any\nexamples of high-level tasks. We illustrate the principles of our method using\ninformative simulation experiments. We then verify its usefulness for real\nrobotics problems by learning, transferring, and composing free-space and\ncontact motion skills on a Sawyer robot using only joint-space control. We\nexperiment with several techniques for composing pre-learned skills, and find\nthat our method allows us to use both learning-based approaches and efficient\nsearch-based planning to achieve high-level tasks using only pre-learned\nskills.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 22:21:02 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 00:37:06 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 21:42:51 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Julian", "Ryan", ""], ["Heiden", "Eric", ""], ["He", "Zhanpeng", ""], ["Zhang", "Hejia", ""], ["Schaal", "Stefan", ""], ["Lim", "Joseph J.", ""], ["Sukhatme", "Gaurav", ""], ["Hausman", "Karol", ""]]}, {"id": "1809.10271", "submitter": "Chi Zhang", "authors": "Chi Zhang, Thang Nguyen, Shagan Sah, Raymond Ptucha, Alexander Loui,\n  Carl Salvaggio", "title": "Batch-normalized Recurrent Highway Networks", "comments": "5 pages, 3 figures, Published in 2017 IEEE International Conference\n  on Image Processing (ICIP)", "journal-ref": null, "doi": "10.1109/ICIP.2017.8296359", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradient control plays an important role in feed-forward networks applied to\nvarious computer vision tasks. Previous work has shown that Recurrent Highway\nNetworks minimize the problem of vanishing or exploding gradients. They achieve\nthis by setting the eigenvalues of the temporal Jacobian to 1 across the time\nsteps. In this work, batch normalized recurrent highway networks are proposed\nto control the gradient flow in an improved way for network convergence.\nSpecifically, the introduced model can be formed by batch normalizing the\ninputs at each recurrence loop. The proposed model is tested on an image\ncaptioning task using MSCOCO dataset. Experimental results indicate that the\nbatch normalized recurrent highway networks converge faster and performs better\ncompared with the traditional LSTM and RHN based models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 23:56:24 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Zhang", "Chi", ""], ["Nguyen", "Thang", ""], ["Sah", "Shagan", ""], ["Ptucha", "Raymond", ""], ["Loui", "Alexander", ""], ["Salvaggio", "Carl", ""]]}, {"id": "1809.10274", "submitter": "Chi Zhang", "authors": "Shagan Sah, Dheeraj Peri, Ameya Shringi, Chi Zhang, Miguel Dominguez,\n  Andreas Savakis, Ray Ptucha", "title": "Semantically Invariant Text-to-Image Generation", "comments": "5 papers, 5 figures, Published in 2018 25th IEEE International\n  Conference on Image Processing (ICIP)", "journal-ref": null, "doi": "10.1109/ICIP.2018.8451656", "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image captioning has demonstrated models that are capable of generating\nplausible text given input images or videos. Further, recent work in image\ngeneration has shown significant improvements in image quality when text is\nused as a prior. Our work ties these concepts together by creating an\narchitecture that can enable bidirectional generation of images and text. We\ncall this network Multi-Modal Vector Representation (MMVR). Along with MMVR, we\npropose two improvements to the text conditioned image generation. Firstly, a\nn-gram metric based cost function is introduced that generalizes the caption\nwith respect to the image. Secondly, multiple semantically similar sentences\nare shown to help in generating better images. Qualitative and quantitative\nevaluations demonstrate that MMVR improves upon existing text conditioned image\ngeneration results by over 20%, while integrating visual and text modalities.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 00:11:25 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Sah", "Shagan", ""], ["Peri", "Dheeraj", ""], ["Shringi", "Ameya", ""], ["Zhang", "Chi", ""], ["Dominguez", "Miguel", ""], ["Savakis", "Andreas", ""], ["Ptucha", "Ray", ""]]}, {"id": "1809.10282", "submitter": "Raphael Tang", "authors": "Raphael Tang, Jimmy Lin", "title": "Adaptive Pruning of Neural Language Models for Mobile Devices", "comments": "10 pages, 3 figures, 2 tables, submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models (NLMs) exist in an accuracy-efficiency tradeoff space\nwhere better perplexity typically comes at the cost of greater computation\ncomplexity. In a software keyboard application on mobile devices, this\ntranslates into higher power consumption and shorter battery life. This paper\nrepresents the first attempt, to our knowledge, in exploring\naccuracy-efficiency tradeoffs for NLMs. Building on quasi-recurrent neural\nnetworks (QRNNs), we apply pruning techniques to provide a \"knob\" to select\ndifferent operating points. In addition, we propose a simple technique to\nrecover some perplexity using a negligible amount of memory. Our empirical\nevaluations consider both perplexity as well as energy consumption on a\nRaspberry Pi, where we demonstrate which methods provide the best\nperplexity-power consumption operating point. At one operating point, one of\nthe techniques is able to provide energy savings of 40% over the state of the\nart with only a 17% relative increase in perplexity.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 00:41:16 GMT"}], "update_date": "2018-09-30", "authors_parsed": [["Tang", "Raphael", ""], ["Lin", "Jimmy", ""]]}, {"id": "1809.10283", "submitter": "Christopher Iliffe Sprague", "authors": "Christopher Iliffe Sprague, Petter \\\"Ogren", "title": "Adding Neural Network Controllers to Behavior Trees without Destroying\n  Performance Guarantees", "comments": "Submitted to IEEE Transactions on Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how Behavior Trees that have performance guarantees,\nin terms of safety and goal convergence, can be extended with components that\nwere designed using machine learning, without destroying those performance\nguarantees.\n  Machine learning approaches such as reinforcement learning or learning from\ndemonstration can be very appealing to AI designers that want efficient and\nrealistic behaviors in their agents. However, those algorithms seldom provide\nguarantees for solving the given task in all different situations while keeping\nthe agent safe. Instead, such guarantees are often easier to find for manually\ndesigned model based approaches. In this paper we exploit the modularity of\nBehavior trees to extend a given design with an efficient, but possibly\nunreliable, machine learning component in a way that preserves the guarantees.\nThe approach is illustrated with an inverted pendulum example.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 12:23:19 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 11:36:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Sprague", "Christopher Iliffe", ""], ["\u00d6gren", "Petter", ""]]}, {"id": "1809.10284", "submitter": "Kevin Schlegel", "authors": "Kevin Schlegel", "title": "When is there a Representer Theorem? Reflexive Banach spaces", "comments": "25 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:1709.00084, arXiv:1804.09605", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general regularised interpolation problem for learning a\nparameter vector from data. The well known representer theorem says that under\ncertain conditions on the regulariser there exists a solution in the linear\nspan of the data points. This is at the core of kernel methods in machine\nlearning as it makes the problem computationally tractable. Most literature\ndeals only with sufficient conditions for representer theorems in Hilbert\nspaces. We prove necessary and sufficient conditions for the existence of\nrepresenter theorems in reflexive Banach spaces and illustrate why in a sense\nreflexivity is the minimal requirement on the function space. We further show\nthat if the learning relies on the linear representer theorem, then the\nsolution is independent of the regulariser and in fact determined by the\nfunction space alone. This in particular shows the value of generalising\nHilbert space learning theory to Banach spaces.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 12:56:09 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 16:12:31 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Schlegel", "Kevin", ""]]}, {"id": "1809.10288", "submitter": "Kou Tanaka", "authors": "Kou Tanaka, Takuhiro Kaneko, Nobukatsu Hojo, Hirokazu Kameoka", "title": "WaveCycleGAN: Synthetic-to-natural speech waveform conversion using\n  cycle-consistent adversarial networks", "comments": "SLT2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a learning-based filter that allows us to directly modify a\nsynthetic speech waveform into a natural speech waveform. Speech-processing\nsystems using a vocoder framework such as statistical parametric speech\nsynthesis and voice conversion are convenient especially for a limited number\nof data because it is possible to represent and process interpretable acoustic\nfeatures over a compact space, such as the fundamental frequency (F0) and\nmel-cepstrum. However, a well-known problem that leads to the quality\ndegradation of generated speech is an over-smoothing effect that eliminates\nsome detailed structure of generated/converted acoustic features. To address\nthis issue, we propose a synthetic-to-natural speech waveform conversion\ntechnique that uses cycle-consistent adversarial networks and which does not\nrequire any explicit assumption about speech waveform in adversarial learning.\nIn contrast to current techniques, since our modification is performed at the\nwaveform level, we expect that the proposed method will also make it possible\nto generate `vocoder-less' sounding speech even if the input speech is\nsynthesized using a vocoder framework. The experimental results demonstrate\nthat our proposed method can 1) alleviate the over-smoothing effect of the\nacoustic features despite the direct modification method used for the waveform\nand 2) greatly improve the naturalness of the generated speech sounds.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 13:03:43 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 18:25:11 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Tanaka", "Kou", ""], ["Kaneko", "Takuhiro", ""], ["Hojo", "Nobukatsu", ""], ["Kameoka", "Hirokazu", ""]]}, {"id": "1809.10312", "submitter": "Chi Zhang", "authors": "Shagan Sah, Chi Zhang, Thang Nguyen, Dheeraj Kumar Peri, Ameya\n  Shringi, Raymond Ptucha", "title": "Vector Learning for Cross Domain Representations", "comments": "5 pages, 7 figures, published in 2017 IEEE Applied Imagery Pattern\n  Recognition Workshop (AIPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, generative adversarial networks have gained a lot of popularity for\nimage generation tasks. However, such models are associated with complex\nlearning mechanisms and demand very large relevant datasets. This work borrows\nconcepts from image and video captioning models to form an image generative\nframework. The model is trained in a similar fashion as recurrent captioning\nmodel and uses the learned weights for image generation. This is done in an\ninverse direction, where the input is a caption and the output is an image. The\nvector representation of the sentence and frames are extracted from an\nencoder-decoder model which is initially trained on similar sentence and image\npairs. Our model conditions image generation on a natural language caption. We\nleverage a sequence-to-sequence model to generate synthetic captions that have\nthe same meaning for having a robust image generation. One key advantage of our\nmethod is that the traditional image captioning datasets can be used for\nsynthetic sentence paraphrases. Results indicate that images generated through\nmultiple captions are better at capturing the semantic meaning of the family of\ncaptions.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 02:08:06 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Sah", "Shagan", ""], ["Zhang", "Chi", ""], ["Nguyen", "Thang", ""], ["Peri", "Dheeraj Kumar", ""], ["Shringi", "Ameya", ""], ["Ptucha", "Raymond", ""]]}, {"id": "1809.10315", "submitter": "Jingfeng Zhang", "authors": "Jingfeng Zhang, Laura Wynter", "title": "Smooth Inter-layer Propagation of Stabilized Neural Networks for\n  Classification", "comments": "Revised Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has studied the reasons for the remarkable performance of deep\nneural networks in image classification. We examine batch normalization on the\none hand and the dynamical systems view of residual networks on the other hand.\nOur goal is in understanding the notions of stability and smoothness of the\ninter-layer propagation of ResNets so as to explain when they contribute to\nsignificantly enhanced performance. We postulate that such stability is of\nimportance for the trained ResNet to transfer.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 02:23:00 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 03:25:06 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zhang", "Jingfeng", ""], ["Wynter", "Laura", ""]]}, {"id": "1809.10326", "submitter": "Yunhao Tang", "authors": "Yunhao Tang, Shipra Agrawal", "title": "Boosting Trust Region Policy Optimization by Normalizing Flows Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to improve trust region policy search with normalizing flows\npolicy. We illustrate that when the trust region is constructed by KL\ndivergence constraints, normalizing flows policy generates samples far from the\n'center' of the previous policy iterate, which potentially enables better\nexploration and helps avoid bad local optima. Through extensive comparisons, we\nshow that the normalizing flows policy significantly improves upon baseline\narchitectures especially on high-dimensional tasks with complex dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 03:19:53 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 19:22:48 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 14:28:17 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Tang", "Yunhao", ""], ["Agrawal", "Shipra", ""]]}, {"id": "1809.10330", "submitter": "Matias Quiroz", "authors": "Ming Xu, Matias Quiroz, Robert Kohn, Scott A. Sisson", "title": "Variance reduction properties of the reparameterization trick", "comments": "Accepted for publication by AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reparameterization trick is widely used in variational inference as it\nyields more accurate estimates of the gradient of the variational objective\nthan alternative approaches such as the score function method. Although there\nis overwhelming empirical evidence in the literature showing its success, there\nis relatively little research exploring why the reparameterization trick is so\neffective. We explore this under the idealized assumptions that the variational\napproximation is a mean-field Gaussian density and that the log of the joint\ndensity of the model parameters and the data is a quadratic function that\ndepends on the variational mean. From this, we show that the marginal variances\nof the reparameterization gradient estimator are smaller than those of the\nscore function gradient estimator. We apply the result of our idealized\nanalysis to real-world examples.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 03:33:20 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 04:35:12 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 05:20:23 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Xu", "Ming", ""], ["Quiroz", "Matias", ""], ["Kohn", "Robert", ""], ["Sisson", "Scott A.", ""]]}, {"id": "1809.10333", "submitter": "Teresa Brooks", "authors": "Teresa Nicole Brooks", "title": "Using Autoencoders To Learn Interesting Features For Detecting\n  Surveillance Aircraft", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores using a Long short-term memory (LSTM) based sequence\nautoencoder to learn interesting features for detecting surveillance aircraft\nusing ADS-B flight data. An aircraft periodically broadcasts ADS-B (Automatic\nDependent Surveillance - Broadcast) data to ground receivers. The ability of\nLSTM networks to model varying length time series data and remember\ndependencies that span across events makes it an ideal candidate for\nimplementing a sequence autoencoder for ADS-B data because of its possible\nvariable length time series, irregular sampling and dependencies that span\nacross events.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 03:35:00 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Brooks", "Teresa Nicole", ""]]}, {"id": "1809.10336", "submitter": "Tao Ma", "authors": "Tao Ma", "title": "Multi-task Learning for Financial Forecasting", "comments": "The methods and results of this paper have been proved to be wrong.\n  So we want to withdraw it to keep others from following the wrong results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial forecasting is challenging and attractive in machine learning.\nThere are many classic solutions, as well as many deep learning based methods,\nproposed to deal with it yielding encouraging performance. Stock time series\nforecasting is the most representative problem in financial forecasting. Due to\nthe strong connections among stocks, the information valuable for forecasting\nis not only included in individual stocks, but also included in the stocks\nrelated to them. However, most previous works focus on one single stock, which\neasily ignore the valuable information in others. To leverage more information,\nin this paper, we propose a jointly forecasting approach to process multiple\ntime series of related stocks simultaneously, using multi-task learning\nframework. Compared to the previous works, we use multiple networks to forecast\nmultiple related stocks, using the shared and private information of them\nsimultaneously through multi-task learning. Moreover, we propose an attention\nmethod learning an optimized weighted combination of shared and private\ninformation based on the idea of Capital Asset Pricing Model (CAPM) to help\nforecast. Experimental results on various data show improved forecasting\nperformance over baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 04:03:03 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2018 14:25:41 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 09:19:22 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Ma", "Tao", ""]]}, {"id": "1809.10341", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, William Fedus, William L. Hamilton, Pietro\n  Li\\`o, Yoshua Bengio, R Devon Hjelm", "title": "Deep Graph Infomax", "comments": "To appear at ICLR 2019. 17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG cs.SI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Deep Graph Infomax (DGI), a general approach for learning node\nrepresentations within graph-structured data in an unsupervised manner. DGI\nrelies on maximizing mutual information between patch representations and\ncorresponding high-level summaries of graphs---both derived using established\ngraph convolutional network architectures. The learnt patch representations\nsummarize subgraphs centered around nodes of interest, and can thus be reused\nfor downstream node-wise learning tasks. In contrast to most prior approaches\nto unsupervised learning with GCNs, DGI does not rely on random walk\nobjectives, and is readily applicable to both transductive and inductive\nlearning setups. We demonstrate competitive performance on a variety of node\nclassification benchmarks, which at times even exceeds the performance of\nsupervised learning.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 04:53:24 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 15:44:59 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Fedus", "William", ""], ["Hamilton", "William L.", ""], ["Li\u00f2", "Pietro", ""], ["Bengio", "Yoshua", ""], ["Hjelm", "R Devon", ""]]}, {"id": "1809.10374", "submitter": "Andrew Lampinen", "authors": "Andrew K. Lampinen, Surya Ganguli", "title": "An analytic theory of generalization dynamics and transfer learning in\n  deep linear networks", "comments": "ICLR 2019, 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much attention has been devoted recently to the generalization puzzle in deep\nlearning: large, deep networks can generalize well, but existing theories\nbounding generalization error are exceedingly loose, and thus cannot explain\nthis striking performance. Furthermore, a major hope is that knowledge may\ntransfer across tasks, so that multi-task learning can improve generalization\non individual tasks. However we lack analytic theories that can quantitatively\npredict how the degree of knowledge transfer depends on the relationship\nbetween the tasks. We develop an analytic theory of the nonlinear dynamics of\ngeneralization in deep linear networks, both within and across tasks. In\nparticular, our theory provides analytic solutions to the training and testing\nerror of deep networks as a function of training time, number of examples,\nnetwork size and initialization, and the task structure and SNR. Our theory\nreveals that deep networks progressively learn the most important task\nstructure first, so that generalization error at the early stopping time\nprimarily depends on task structure and is independent of network size. This\nsuggests any tight bound on generalization error must take into account task\nstructure, and explains observations about real data being learned faster than\nrandom data. Intriguingly our theory also reveals the existence of a learning\nalgorithm that proveably out-performs neural network training through gradient\ndescent. Finally, for transfer learning, our theory reveals that knowledge\ntransfer depends sensitively, but computably, on the SNRs and input feature\nalignments of pairs of tasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 06:47:58 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 22:16:58 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Lampinen", "Andrew K.", ""], ["Ganguli", "Surya", ""]]}, {"id": "1809.10388", "submitter": "Kleanthis Malialis", "authors": "Kleanthis Malialis, Christos G. Panayiotou, Marios M. Polycarpou", "title": "Queue-based Resampling for Online Class Imbalance Learning", "comments": "Keywords: online learning, class imbalance, concept drift,\n  resampling, neural networks, data streams. In: 2018 International Conference\n  on Artificial Neural Networks (ICANN)", "journal-ref": "Proceedings of the International Conference on Artificial Neural\n  Networks (ICANN), 2018", "doi": "10.1007/978-3-030-01418-6_49", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online class imbalance learning constitutes a new problem and an emerging\nresearch topic that focusses on the challenges of online learning under class\nimbalance and concept drift. Class imbalance deals with data streams that have\nvery skewed distributions while concept drift deals with changes in the class\nimbalance status. Little work exists that addresses these challenges and in\nthis paper we introduce queue-based resampling, a novel algorithm that\nsuccessfully addresses the co-existence of class imbalance and concept drift.\nThe central idea of the proposed resampling algorithm is to selectively include\nin the training set a subset of the examples that appeared in the past. Results\non two popular benchmark datasets demonstrate the effectiveness of queue-based\nresampling over state-of-the-art methods in terms of learning speed and\nquality.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 07:59:33 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 11:25:24 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Malialis", "Kleanthis", ""], ["Panayiotou", "Christos G.", ""], ["Polycarpou", "Marios M.", ""]]}, {"id": "1809.10460", "submitter": "Yutian Chen", "authors": "Yutian Chen, Yannis Assael, Brendan Shillingford, David Budden, Scott\n  Reed, Heiga Zen, Quan Wang, Luis C. Cobo, Andrew Trask, Ben Laurie, Caglar\n  Gulcehre, A\\\"aron van den Oord, Oriol Vinyals, Nando de Freitas", "title": "Sample Efficient Adaptive Text-to-Speech", "comments": "Accepted by ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a meta-learning approach for adaptive text-to-speech (TTS) with\nfew data. During training, we learn a multi-speaker model using a shared\nconditional WaveNet core and independent learned embeddings for each speaker.\nThe aim of training is not to produce a neural network with fixed weights,\nwhich is then deployed as a TTS system. Instead, the aim is to produce a\nnetwork that requires few data at deployment time to rapidly adapt to new\nspeakers. We introduce and benchmark three strategies: (i) learning the speaker\nembedding while keeping the WaveNet core fixed, (ii) fine-tuning the entire\narchitecture with stochastic gradient descent, and (iii) predicting the speaker\nembedding with a trained neural network encoder. The experiments show that\nthese approaches are successful at adapting the multi-speaker neural network to\nnew speakers, obtaining state-of-the-art results in both sample naturalness and\nvoice similarity with merely a few minutes of audio data from new speakers.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 11:31:19 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 15:23:54 GMT"}, {"version": "v3", "created": "Wed, 16 Jan 2019 22:30:22 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Chen", "Yutian", ""], ["Assael", "Yannis", ""], ["Shillingford", "Brendan", ""], ["Budden", "David", ""], ["Reed", "Scott", ""], ["Zen", "Heiga", ""], ["Wang", "Quan", ""], ["Cobo", "Luis C.", ""], ["Trask", "Andrew", ""], ["Laurie", "Ben", ""], ["Gulcehre", "Caglar", ""], ["Oord", "A\u00e4ron van den", ""], ["Vinyals", "Oriol", ""], ["de Freitas", "Nando", ""]]}, {"id": "1809.10463", "submitter": "Joseph Bethge", "authors": "Joseph Bethge, Haojin Yang, Christian Bartz, Christoph Meinel", "title": "Learning to Train a Binary Neural Network", "comments": "Code: https://github.com/Jopyth/BMXNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have achieved astonishing results in different\napplication areas. Various methods which allow us to use these models on mobile\nand embedded devices have been proposed. Especially binary neural networks seem\nto be a promising approach for these devices with low computational power.\nHowever, understanding binary neural networks and training accurate models for\npractical applications remains a challenge. In our work, we focus on increasing\nour understanding of the training process and making it accessible to everyone.\nWe publish our code and models based on BMXNet for everyone to use. Within this\nframework, we systematically evaluated different network architectures and\nhyperparameters to provide useful insights on how to train a binary neural\nnetwork. Further, we present how we improved accuracy by increasing the number\nof connections in the network.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 11:40:03 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Bethge", "Joseph", ""], ["Yang", "Haojin", ""], ["Bartz", "Christian", ""], ["Meinel", "Christoph", ""]]}, {"id": "1809.10477", "submitter": "Dan Garber", "authors": "Dan Garber, Atara Kaplan", "title": "Fast Stochastic Algorithms for Low-rank and Nonsmooth Matrix Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composite convex optimization problems which include both a nonsmooth term\nand a low-rank promoting term have important applications in machine learning\nand signal processing, such as when one wishes to recover an unknown matrix\nthat is simultaneously low-rank and sparse. However, such problems are highly\nchallenging to solve in large-scale: the low-rank promoting term prohibits\nefficient implementations of proximal methods for composite optimization and\neven simple subgradient methods. On the other hand, methods which are tailored\nfor low-rank optimization, such as conditional gradient-type methods, which are\noften applied to a smooth approximation of the nonsmooth objective, are slow\nsince their runtime scales with both the large Lipshitz parameter of the\nsmoothed gradient vector and with $1/\\epsilon$. In this paper we develop\nefficient algorithms for \\textit{stochastic} optimization of a strongly-convex\nobjective which includes both a nonsmooth term and a low-rank promoting term.\nIn particular, to the best of our knowledge, we present the first algorithm\nthat enjoys all following critical properties for large-scale problems: i)\n(nearly) optimal sample complexity, ii) each iteration requires only a single\n\\textit{low-rank} SVD computation, and iii) overall number of thin-SVD\ncomputations scales only with $\\log{1/\\epsilon}$ (as opposed to\n$\\textrm{poly}(1/\\epsilon)$ in previous methods). We also give an algorithm for\nthe closely-related finite-sum setting. At the heart of our results lie a novel\ncombination of a variance-reduction technique and the use of a\n\\textit{weak-proximal oracle} which is key to obtaining all above three\nproperties simultaneously.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 12:11:56 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Garber", "Dan", ""], ["Kaplan", "Atara", ""]]}, {"id": "1809.10482", "submitter": "David Gaudrie", "authors": "David Gaudrie and Rodolphe Le Riche and Victor Picheny and Benoit\n  Enaux and Vincent Herbert", "title": "Budgeted Multi-Objective Optimization with a Focus on the Central Part\n  of the Pareto Front -- Extended Version", "comments": "Submission pre-print, extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing nonlinear systems involving expensive computer experiments with\nregard to conflicting objectives is a common challenge. When the number of\nexperiments is severely restricted and/or when the number of objectives\nincreases, uncovering the whole set of Pareto optimal solutions is out of\nreach, even for surrogate-based approaches: the proposed solutions are\nsub-optimal or do not cover the front well. As non-compromising optimal\nsolutions have usually little point in applications, this work restricts the\nsearch to solutions that are close to the Pareto front center. The article\nstarts by characterizing this center, which is defined for any type of front.\nNext, a Bayesian multi-objective optimization method for directing the search\ntowards it is proposed. Targeting a subset of the Pareto front allows an\nimproved optimality of the solutions and a better coverage of this zone, which\nis our main concern. A criterion for detecting convergence to the center is\ndescribed. If the criterion is triggered, a widened central part of the Pareto\nfront is targeted such that sufficiently accurate convergence to it is\nforecasted within the remaining budget. Numerical experiments show how the\nresulting algorithm, C-EHI, better locates the central part of the Pareto front\nwhen compared to state-of-the-art Bayesian algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 12:22:04 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 16:36:47 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 07:23:58 GMT"}, {"version": "v4", "created": "Mon, 15 Jul 2019 16:22:06 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Gaudrie", "David", ""], ["Riche", "Rodolphe Le", ""], ["Picheny", "Victor", ""], ["Enaux", "Benoit", ""], ["Herbert", "Vincent", ""]]}, {"id": "1809.10491", "submitter": "Dan Garber", "authors": "Dan Garber", "title": "On the Regret Minimization of Nonconvex Online Gradient Ascent for\n  Online PCA", "comments": "added logarithmic regret bounds, more related work, fixed some small\n  errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the problem of Online Principal Component Analysis\nin the regret minimization framework. For this problem, all existing regret\nminimization algorithms for the fully-adversarial setting are based on a\npositive semidefinite convex relaxation, and hence require quadratic memory and\nSVD computation (either thin of full) on each iteration, which amounts to at\nleast quadratic runtime per iteration. This is in stark contrast to a\ncorresponding stochastic i.i.d. variant of the problem, which was studied\nextensively lately, and admits very efficient gradient ascent algorithms that\nwork directly on the natural non-convex formulation of the problem, and hence\nrequire only linear memory and linear runtime per iteration. This raises the\nquestion: can non-convex online gradient ascent algorithms be shown to minimize\nregret in online adversarial settings? In this paper we take a step forward\ntowards answering this question. We introduce an\n\\textit{adversarially-perturbed spiked-covariance model} in which, each data\npoint is assumed to follow a fixed stochastic distribution with a non-zero\nspectral gap in the covariance matrix, but is then perturbed with some\nadversarial vector. This model is a natural extension of a well studied\nstandard stochastic setting that allows for non-stationary (adversarial)\npatterns to arise in the data and hence, might serve as a significantly better\napproximation for real-world data-streams. We show that in an interesting\nregime of parameters, when the non-convex online gradient ascent algorithm is\ninitialized with a \"warm-start\" vector, it provably minimizes the regret with\nhigh probability. We further discuss the possibility of computing such a\n\"warm-start\" vector, and also the use of regularization to obtain fast regret\nrates. Our theoretical findings are supported by empirical experiments on both\nsynthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 12:35:17 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 15:43:08 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Garber", "Dan", ""]]}, {"id": "1809.10504", "submitter": "Alexander Ecker", "authors": "Alexander S. Ecker, Fabian H. Sinz, Emmanouil Froudarakis, Paul G.\n  Fahey, Santiago A. Cadena, Edgar Y. Walker, Erick Cobos, Jacob Reimer,\n  Andreas S. Tolias, Matthias Bethge", "title": "A rotation-equivariant convolutional neural network model of primary\n  visual cortex", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical models describe primary visual cortex (V1) as a filter bank of\norientation-selective linear-nonlinear (LN) or energy models, but these models\nfail to predict neural responses to natural stimuli accurately. Recent work\nshows that models based on convolutional neural networks (CNNs) lead to much\nmore accurate predictions, but it remains unclear which features are extracted\nby V1 neurons beyond orientation selectivity and phase invariance. Here we work\ntowards systematically studying V1 computations by categorizing neurons into\ngroups that perform similar computations. We present a framework to identify\ncommon features independent of individual neurons' orientation selectivity by\nusing a rotation-equivariant convolutional neural network, which automatically\nextracts every feature at multiple different orientations. We fit this model to\nresponses of a population of 6000 neurons to natural images recorded in mouse\nprimary visual cortex using two-photon imaging. We show that our\nrotation-equivariant network not only outperforms a regular CNN with the same\nnumber of feature maps, but also reveals a number of common features shared by\nmany V1 neurons, which deviate from the typical textbook idea of V1 as a bank\nof Gabor filters. Our findings are a first step towards a powerful new tool to\nstudy the nonlinear computations in V1.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 13:16:37 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Ecker", "Alexander S.", ""], ["Sinz", "Fabian H.", ""], ["Froudarakis", "Emmanouil", ""], ["Fahey", "Paul G.", ""], ["Cadena", "Santiago A.", ""], ["Walker", "Edgar Y.", ""], ["Cobos", "Erick", ""], ["Reimer", "Jacob", ""], ["Tolias", "Andreas S.", ""], ["Bethge", "Matthias", ""]]}, {"id": "1809.10505", "submitter": "Nikola Konstantinov", "authors": "Dan Alistarh, Torsten Hoefler, Mikael Johansson, Sarit Khirirat,\n  Nikola Konstantinov, C\\'edric Renggli", "title": "The Convergence of Sparsified Gradient Methods", "comments": "NIPS 2018 - Advances in Neural Information Processing Systems;\n  Authors in alphabetic order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed training of massive machine learning models, in particular deep\nneural networks, via Stochastic Gradient Descent (SGD) is becoming commonplace.\nSeveral families of communication-reduction methods, such as quantization,\nlarge-batch methods, and gradient sparsification, have been proposed. To date,\ngradient sparsification methods - where each node sorts gradients by magnitude,\nand only communicates a subset of the components, accumulating the rest locally\n- are known to yield some of the largest practical gains. Such methods can\nreduce the amount of communication per step by up to three orders of magnitude,\nwhile preserving model accuracy. Yet, this family of methods currently has no\ntheoretical justification.\n  This is the question we address in this paper. We prove that, under analytic\nassumptions, sparsifying gradients by magnitude with local error correction\nprovides convergence guarantees, for both convex and non-convex smooth\nobjectives, for data-parallel SGD. The main insight is that sparsification\nmethods implicitly maintain bounds on the maximum impact of stale updates,\nthanks to selection by magnitude. Our analysis and empirical validation also\nreveal that these methods do require analytical conditions to converge well,\njustifying existing heuristics.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 13:23:35 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Alistarh", "Dan", ""], ["Hoefler", "Torsten", ""], ["Johansson", "Mikael", ""], ["Khirirat", "Sarit", ""], ["Konstantinov", "Nikola", ""], ["Renggli", "C\u00e9dric", ""]]}, {"id": "1809.10522", "submitter": "Narendra Nath Joshi", "authors": "Mary Arpita Pyreddy, Varshini Ramaseshan, Narendra Nath Joshi, Zhuyun\n  Dai, Chenyan Xiong, Jamie Callan, Zhiyuan Liu", "title": "Consistency and Variation in Kernel Neural Ranking Model", "comments": "4 pages, 4 figures, 2 tables", "journal-ref": "Mary Arpita Pyreddy et al. 2018. Consistency and Variation in\n  Kernel Neural Ranking Model. In The 41st International ACM SIGIR Conference\n  on Research & Development in Information Retrieval (SIGIR '18). ACM, New\n  York, NY, USA, 961-964", "doi": "10.1145/3209978.3210107", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the consistency of the kernel-based neural ranking model\nK-NRM, a recent state-of-the-art neural IR model, which is important for\nreproducible research and deployment in the industry. We find that K-NRM has\nlow variance on relevance-based metrics across experimental trials. In spite of\nthis low variance in overall performance, different trials produce different\ndocument rankings for individual queries. The main source of variance in our\nexperiments was found to be different latent matching patterns captured by\nK-NRM. In the IR-customized word embeddings learned by K-NRM, the\nquery-document word pairs follow two different matching patterns that are\nequally effective, but align word pairs differently in the embedding space. The\ndifferent latent matching patterns enable a simple yet effective approach to\nconstruct ensemble rankers, which improve K-NRM's effectiveness and\ngeneralization abilities.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 14:01:19 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Pyreddy", "Mary Arpita", ""], ["Ramaseshan", "Varshini", ""], ["Joshi", "Narendra Nath", ""], ["Dai", "Zhuyun", ""], ["Xiong", "Chenyan", ""], ["Callan", "Jamie", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1809.10565", "submitter": "Yu Zhao", "authors": "Yu Zhao, Zhenhui Shi, Jingyang Zhang, Dong Chen, Lixu Gu", "title": "A novel active learning framework for classification: using weighted\n  rank aggregation to achieve multiple query criteria", "comments": "34 pages, 21 figures, 11 tables,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple query criteria active learning (MQCAL) methods have a higher\npotential performance than conventional active learning methods in which only\none criterion is deployed for sample selection. A central issue related to\nMQCAL methods concerns the development of an integration criteria strategy\n(ICS) that makes full use of all criteria. The conventional ICS adopted in\nrelevant research all facilitate the desired effects, but several limitations\nstill must be addressed. For instance, some of the strategies are not\nsufficiently scalable during the design process, and the number and type of\ncriteria involved are dictated. Thus, it is challenging for the user to\nintegrate other criteria into the original process unless modifications are\nmade to the algorithm. Other strategies are too dependent on empirical\nparameters, which can only be acquired by experience or cross-validation and\nthus lack generality; additionally, these strategies are counter to the\nintention of active learning, as samples need to be labeled in the validation\nset before the active learning process can begin. To address these limitations,\nwe propose a novel MQCAL method for classification tasks that employs a third\nstrategy via weighted rank aggregation. The proposed method serves as a\nheuristic means to select high-value samples of high scalability and generality\nand is implemented through a three-step process: (1) the transformation of the\nsample selection to sample ranking and scoring, (2) the computation of the\nself-adaptive weights of each criterion, and (3) the weighted aggregation of\neach sample rank list. Ultimately, the sample at the top of the aggregated\nranking list is the most comprehensively valuable and must be labeled. Several\nexperiments generating 257 wins, 194 ties and 49 losses against other\nstate-of-the-art MQCALs are conducted to verify that the proposed method can\nachieve superior results.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 15:12:54 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Zhao", "Yu", ""], ["Shi", "Zhenhui", ""], ["Zhang", "Jingyang", ""], ["Chen", "Dong", ""], ["Gu", "Lixu", ""]]}, {"id": "1809.10606", "submitter": "Dian Wu", "authors": "Dian Wu, Lei Wang, Pan Zhang", "title": "Solving Statistical Mechanics Using Variational Autoregressive Networks", "comments": null, "journal-ref": "Phys. Rev. Lett. 122, 080602 (2019), Github:\n  https://github.com/wdphy16/stat-mech-van", "doi": "10.1103/PhysRevLett.122.080602", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for solving statistical mechanics of systems\nwith finite size. The approach extends the celebrated variational mean-field\napproaches using autoregressive neural networks, which support direct sampling\nand exact calculation of normalized probability of configurations. It computes\nvariational free energy, estimates physical quantities such as entropy,\nmagnetizations and correlations, and generates uncorrelated samples all at\nonce. Training of the network employs the policy gradient approach in\nreinforcement learning, which unbiasedly estimates the gradient of variational\nparameters. We apply our approach to several classic systems, including 2D\nIsing models, the Hopfield model, the Sherrington-Kirkpatrick model, and the\ninverse Ising model, for demonstrating its advantages over existing variational\nmean-field methods. Our approach sheds light on solving statistical physics\nproblems using modern deep generative neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 16:18:23 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 14:52:39 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Wu", "Dian", ""], ["Wang", "Lei", ""], ["Zhang", "Pan", ""]]}, {"id": "1809.10610", "submitter": "Sahaj Garg", "authors": "Sahaj Garg, Vincent Perot, Nicole Limtiaco, Ankur Taly, Ed H. Chi,\n  Alex Beutel", "title": "Counterfactual Fairness in Text Classification through Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study counterfactual fairness in text classification, which\nasks the question: How would the prediction change if the sensitive attribute\nreferenced in the example were different? Toxicity classifiers demonstrate a\ncounterfactual fairness issue by predicting that \"Some people are gay\" is toxic\nwhile \"Some people are straight\" is nontoxic. We offer a metric, counterfactual\ntoken fairness (CTF), for measuring this particular form of fairness in text\nclassifiers, and describe its relationship with group fairness. Further, we\noffer three approaches, blindness, counterfactual augmentation, and\ncounterfactual logit pairing (CLP), for optimizing counterfactual token\nfairness during training, bridging the robustness and fairness literature.\nEmpirically, we find that blindness and CLP address counterfactual token\nfairness. The methods do not harm classifier performance, and have varying\ntradeoffs with group fairness. These approaches, both for measurement and\noptimization, provide a new path forward for addressing fairness concerns in\ntext classification.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 16:21:39 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 19:09:40 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Garg", "Sahaj", ""], ["Perot", "Vincent", ""], ["Limtiaco", "Nicole", ""], ["Taly", "Ankur", ""], ["Chi", "Ed H.", ""], ["Beutel", "Alex", ""]]}, {"id": "1809.10611", "submitter": "David Fridovich-Keil", "authors": "Esther Rolf, David Fridovich-Keil, Max Simchowitz, Benjamin Recht,\n  Claire Tomlin", "title": "A Successive-Elimination Approach to Adaptive Robotic Sensing", "comments": null, "journal-ref": "IEEE Transactions on Robotics Research, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an adaptive source seeking problem, in which a mobile robot must\nidentify the strongest emitter(s) of a signal in an environment with background\nemissions. Background signals may be highly heterogeneous and can mislead\nalgorithms that are based on receding horizon control. We propose AdaSearch, a\ngeneral algorithm for adaptive source seeking in the face of heterogeneous\nbackground noise. AdaSearch combines global trajectory planning with principled\nconfidence intervals in order to concentrate measurements in promising regions\nwhile guaranteeing sufficient coverage of the entire area. Theoretical analysis\nshows that AdaSearch confers gains over a uniform sampling strategy when the\ndistribution of background signals is highly variable. Simulation experiments\ndemonstrate that when applied to the problem of radioactive source seeking,\nAdaSearch outperforms both uniform sampling and a receding time horizon\ninformation-maximization approach based on the current literature. We also\ndemonstrate AdaSearch in hardware, providing further evidence of its potential\nfor real-time implementation.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 16:23:15 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 04:51:10 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 22:48:29 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Rolf", "Esther", ""], ["Fridovich-Keil", "David", ""], ["Simchowitz", "Max", ""], ["Recht", "Benjamin", ""], ["Tomlin", "Claire", ""]]}, {"id": "1809.10635", "submitter": "Gido van de Ven", "authors": "Gido M. van de Ven, Andreas S. Tolias", "title": "Generative replay with feedback connections as a general strategy for\n  continual learning", "comments": "17 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major obstacle to developing artificial intelligence applications capable\nof true lifelong learning is that artificial neural networks quickly or\ncatastrophically forget previously learned tasks when trained on a new one.\nNumerous methods for alleviating catastrophic forgetting are currently being\nproposed, but differences in evaluation protocols make it difficult to directly\ncompare their performance. To enable more meaningful comparisons, here we\nidentified three distinct scenarios for continual learning based on whether\ntask identity is known and, if it is not, whether it needs to be inferred.\nPerforming the split and permuted MNIST task protocols according to each of\nthese scenarios, we found that regularization-based approaches (e.g., elastic\nweight consolidation) failed when task identity needed to be inferred. In\ncontrast, generative replay combined with distillation (i.e., using class\nprobabilities as \"soft targets\") achieved superior performance in all three\nscenarios. Addressing the issue of efficiency, we reduced the computational\ncost of generative replay by integrating the generative model into the main\nmodel by equipping it with generative feedback or backward connections. This\nReplay-through-Feedback approach substantially shortened training time with no\nor negligible loss in performance. We believe this to be an important first\nstep towards making the powerful technique of generative replay scalable to\nreal-world continual learning applications.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 16:55:58 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 09:20:24 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["van de Ven", "Gido M.", ""], ["Tolias", "Andreas S.", ""]]}, {"id": "1809.10636", "submitter": "Anoop Toffy", "authors": "Chae Young Lee, Anoop Toffy, Gue Jun Jung, Woo-Jin Han", "title": "Conditional WaveGAN", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative models are successfully used for image synthesis in the recent\nyears. But when it comes to other modalities like audio, text etc little\nprogress has been made. Recent works focus on generating audio from a\ngenerative model in an unsupervised setting. We explore the possibility of\nusing generative models conditioned on class labels. Concatenation based\nconditioning and conditional scaling were explored in this work with various\nhyper-parameter tuning methods. In this paper we introduce Conditional WaveGANs\n(cWaveGAN). Find our implementation at https://github.com/acheketa/cwavegan\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 16:56:23 GMT"}], "update_date": "2018-09-30", "authors_parsed": [["Lee", "Chae Young", ""], ["Toffy", "Anoop", ""], ["Jung", "Gue Jun", ""], ["Han", "Woo-Jin", ""]]}, {"id": "1809.10658", "submitter": "Rodrigo Nogueira", "authors": "Rodrigo Nogueira, Jannis Bulian, Massimiliano Ciaramita", "title": "Learning to Coordinate Multiple Reinforcement Learning Agents for\n  Diverse Query Reformulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to efficiently learn diverse strategies in reinforcement\nlearning for query reformulation in the tasks of document retrieval and\nquestion answering. In the proposed framework an agent consists of multiple\nspecialized sub-agents and a meta-agent that learns to aggregate the answers\nfrom sub-agents to produce a final answer. Sub-agents are trained on disjoint\npartitions of the training data, while the meta-agent is trained on the full\ntraining set. Our method makes learning faster, because it is highly\nparallelizable, and has better generalization performance than strong\nbaselines, such as an ensemble of agents trained on the full data. We show that\nthe improved performance is due to the increased diversity of reformulation\nstrategies.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 17:35:57 GMT"}, {"version": "v2", "created": "Tue, 25 Dec 2018 19:14:55 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Nogueira", "Rodrigo", ""], ["Bulian", "Jannis", ""], ["Ciaramita", "Massimiliano", ""]]}, {"id": "1809.10678", "submitter": "Linara Adilova", "authors": "Linara Adilova, Nathalie Paul, and Peter Schlicht", "title": "Introducing Noise in Decentralized Training of Neural Networks", "comments": "13 pages", "journal-ref": "ECML PKDD 2018, Workshop DMLE", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that injecting noise into the neural network weights during\nthe training process leads to a better generalization of the resulting model.\nNoise injection in the distributed setup is a straightforward technique and it\nrepresents a promising approach to improve the locally trained models. We\ninvestigate the effects of noise injection into the neural networks during a\ndecentralized training process. We show both theoretically and empirically that\nnoise injection has no positive effect in expectation on linear models, though.\nHowever for non-linear neural networks we empirically show that noise injection\nsubstantially improves model quality helping to reach a generalization ability\nof a local model close to the serial baseline.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 09:45:38 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Adilova", "Linara", ""], ["Paul", "Nathalie", ""], ["Schlicht", "Peter", ""]]}, {"id": "1809.10679", "submitter": "Nasrin Sadeghianpourhamami", "authors": "Nasrin Sadeghianpourhamami, Johannes Deleu, Chris Develder", "title": "Definition and evaluation of model-free coordination of electrical\n  vehicle charging with reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initial DR studies mainly adopt model predictive control and thus require\naccurate models of the control problem (e.g., a customer behavior model), which\nare to a large extent uncertain for the EV scenario. Hence, model-free\napproaches, especially based on reinforcement learning (RL) are an attractive\nalternative. In this paper, we propose a new Markov decision process (MDP)\nformulation in the RL framework, to jointly coordinate a set of EV charging\nstations. State-of-the-art algorithms either focus on a single EV, or perform\nthe control of an aggregate of EVs in multiple steps (e.g., aggregate load\ndecisions in one step, then a step translating the aggregate decision to\nindividual connected EVs). On the contrary, we propose an RL approach to\njointly control the whole set of EVs at once. We contribute a new MDP\nformulation, with a scalable state representation that is independent of the\nnumber of EV charging stations. Further, we use a batch reinforcement learning\nalgorithm, i.e., an instance of fitted Q-iteration, to learn the optimal\ncharging policy. We analyze its performance using simulation experiments based\non a real-world EV charging data. More specifically, we (i) explore the various\nsettings in training the RL policy (e.g., duration of the period with training\ndata), (ii) compare its performance to an oracle all-knowing benchmark (which\nprovides an upper bound for performance, relying on information that is not\navailable or at least imperfect in practice), (iii) analyze performance over\ntime, over the course of a full year to evaluate possible performance\nfluctuations (e.g, across different seasons), and (iv) demonstrate the\ngeneralization capacity of a learned control policy to larger sets of charging\nstations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 10:34:41 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 19:00:36 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Sadeghianpourhamami", "Nasrin", ""], ["Deleu", "Johannes", ""], ["Develder", "Chris", ""]]}, {"id": "1809.10680", "submitter": "Guoqing Chao", "authors": "Guoqing Chao, Chengsheng Mao, Fei Wang, Yuan Zhao, Yuan Luo", "title": "Supervised Nonnegative Matrix Factorization to Predict ICU Mortality\n  Risk", "comments": "7 Pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ICU mortality risk prediction is a tough yet important task. On one hand, due\nto the complex temporal data collected, it is difficult to identify the\neffective features and interpret them easily; on the other hand, good\nprediction can help clinicians take timely actions to prevent the mortality.\nThese correspond to the interpretability and accuracy problems. Most existing\nmethods lack of the interpretability, but recently Subgraph Augmented\nNonnegative Matrix Factorization (SANMF) has been successfully applied to time\nseries data to provide a path to interpret the features well. Therefore, we\nadopted this approach as the backbone to analyze the patient data. One\nlimitation of the raw SANMF method is its poor prediction ability due to its\nunsupervised nature. To deal with this problem, we proposed a supervised SANMF\nalgorithm by integrating the logistic regression loss function into the NMF\nframework and solved it with an alternating optimization procedure. We used the\nsimulation data to verify the effectiveness of this method, and then we applied\nit to ICU mortality risk prediction and demonstrated its superiority over other\nconventional supervised NMF methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 13:15:18 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 02:47:21 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Chao", "Guoqing", ""], ["Mao", "Chengsheng", ""], ["Wang", "Fei", ""], ["Zhao", "Yuan", ""], ["Luo", "Yuan", ""]]}, {"id": "1809.10699", "submitter": "Yuval Litvak", "authors": "Yuval Litvak, Armin Biess, Aharon Bar-Hillel", "title": "Learning Pose Estimation for High-Precision Robotic Assembly Using\n  Simulated Depth Images", "comments": "8 pages, 5 figures. This work has been accepted to the International\n  Conference on Robotics and Automation (ICRA 2019). For associated video, see\n  https://youtu.be/uMvq2-Tg-9g", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of industrial robotic assembly tasks today require fixed initial\nconditions for successful assembly. These constraints induce high production\ncosts and low adaptability to new tasks. In this work we aim towards flexible\nand adaptable robotic assembly by using 3D CAD models for all parts to be\nassembled. We focus on a generic assembly task - the Siemens Innovation\nChallenge - in which a robot needs to assemble a gear-like mechanism with high\nprecision into an operating system. To obtain the millimeter-accuracy required\nfor this task and industrial settings alike, we use a depth camera mounted near\nthe robot end-effector. We present a high-accuracy two-stage pose estimation\nprocedure based on deep convolutional neural networks, which includes\ndetection, pose estimation, refinement, and handling of near- and full\nsymmetries of parts. The networks are trained on simulated depth images with\nmeans to ensure successful transfer to the real robot. We obtain an average\npose estimation error of 2.16 millimeters and 0.64 degree leading to 91%\nsuccess rate for robotic assembly of randomly distributed parts. To the best of\nour knowledge, this is the first time that the Siemens Innovation Challenge is\nfully addressed, with all the parts assembled with high success rates.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 18:02:24 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 12:57:02 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Litvak", "Yuval", ""], ["Biess", "Armin", ""], ["Bar-Hillel", "Aharon", ""]]}, {"id": "1809.10711", "submitter": "Pablo Navarrete Michelini", "authors": "Pablo Navarrete Michelini, Dan Zhu, and Hanwen Liu", "title": "Multi-Scale Recursive and Perception-Distortion Controllable Image\n  Super-Resolution", "comments": "In ECCV 2018 Workshops. Won 2nd place in Region 3 of PIRM-SR\n  Challenge 2018. Code and models are available at\n  https://github.com/pnavarre/pirm-sr-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe our solution for the PIRM Super-Resolution Challenge 2018 where\nwe achieved the 2nd best perceptual quality for average RMSE<=16, 5th best for\nRMSE<=12.5, and 7th best for RMSE<=11.5. We modify a recently proposed\nMulti-Grid Back-Projection (MGBP) architecture to work as a generative system\nwith an input parameter that can control the amount of artificial details in\nthe output. We propose a discriminator for adversarial training with the\nfollowing novel properties: it is multi-scale that resembles a progressive-GAN;\nit is recursive that balances the architecture of the generator; and it\nincludes a new layer to capture significant statistics of natural images.\nFinally, we propose a training strategy that avoids conflicts between\nreconstruction and perceptual losses. Our configuration uses only 281k\nparameters and upscales each image of the competition in 0.2s in average.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 18:26:09 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 03:07:47 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Michelini", "Pablo Navarrete", ""], ["Zhu", "Dan", ""], ["Liu", "Hanwen", ""]]}, {"id": "1809.10717", "submitter": "Chitta Ranjan", "authors": "Chitta Ranjan, Mahendranath Reddy, Markku Mustonen, Kamran Paynabar,\n  and Karim Pourak", "title": "Dataset: Rare Event Classification in Multivariate Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A real-world dataset is provided from a pulp-and-paper manufacturing\nindustry. The dataset comes from a multivariate time series process. The data\ncontains a rare event of paper break that commonly occurs in the industry. The\ndata contains sensor readings at regular time-intervals (x's) and the event\nlabel (y). The primary purpose of the data is thought to be building a\nclassification model for early prediction of the rare event. However, it can\nalso be used for multivariate time series data exploration and building other\nsupervised and unsupervised models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 18:38:45 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 16:46:42 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 20:26:23 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 21:11:41 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ranjan", "Chitta", ""], ["Reddy", "Mahendranath", ""], ["Mustonen", "Markku", ""], ["Paynabar", "Kamran", ""], ["Pourak", "Karim", ""]]}, {"id": "1809.10732", "submitter": "Nemanja Djuric", "authors": "Henggang Cui, Vladan Radosavljevic, Fang-Chieh Chou, Tsung-Han Lin,\n  Thi Nguyen, Tzu-Kuo Huang, Jeff Schneider, Nemanja Djuric", "title": "Multimodal Trajectory Predictions for Autonomous Driving using Deep\n  Convolutional Networks", "comments": "Accepted for publication at IEEE International Conference on Robotics\n  and Automation (ICRA) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving presents one of the largest problems that the robotics and\nartificial intelligence communities are facing at the moment, both in terms of\ndifficulty and potential societal impact. Self-driving vehicles (SDVs) are\nexpected to prevent road accidents and save millions of lives while improving\nthe livelihood and life quality of many more. However, despite large interest\nand a number of industry players working in the autonomous domain, there still\nremains more to be done in order to develop a system capable of operating at a\nlevel comparable to best human drivers. One reason for this is high uncertainty\nof traffic behavior and large number of situations that an SDV may encounter on\nthe roads, making it very difficult to create a fully generalizable system. To\nensure safe and efficient operations, an autonomous vehicle is required to\naccount for this uncertainty and to anticipate a multitude of possible\nbehaviors of traffic actors in its surrounding. We address this critical\nproblem and present a method to predict multiple possible trajectories of\nactors while also estimating their probabilities. The method encodes each\nactor's surrounding context into a raster image, used as input by deep\nconvolutional networks to automatically derive relevant features for the task.\nFollowing extensive offline evaluation and comparison to state-of-the-art\nbaselines, the method was successfully tested on SDVs in closed-course tests.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 04:07:13 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 14:07:02 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Cui", "Henggang", ""], ["Radosavljevic", "Vladan", ""], ["Chou", "Fang-Chieh", ""], ["Lin", "Tsung-Han", ""], ["Nguyen", "Thi", ""], ["Huang", "Tzu-Kuo", ""], ["Schneider", "Jeff", ""], ["Djuric", "Nemanja", ""]]}, {"id": "1809.10749", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen, Mahesh Chandra Mukkamala, Matthias Hein", "title": "On the loss landscape of a class of deep neural networks with no bad\n  local valleys", "comments": "Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify a class of over-parameterized deep neural networks with standard\nactivation functions and cross-entropy loss which provably have no bad local\nvalley, in the sense that from any point in parameter space there exists a\ncontinuous path on which the cross-entropy loss is non-increasing and gets\narbitrarily close to zero. This implies that these networks have no sub-optimal\nstrict local minima.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 20:09:59 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 00:58:29 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Nguyen", "Quynh", ""], ["Mukkamala", "Mahesh Chandra", ""], ["Hein", "Matthias", ""]]}, {"id": "1809.10756", "submitter": "Jan-Willem Van De Meent", "authors": "Jan-Willem van de Meent and Brooks Paige and Hongseok Yang and Frank\n  Wood", "title": "An Introduction to Probabilistic Programming", "comments": "Under review at Foundations and Trends in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document is designed to be a first-year graduate-level introduction to\nprobabilistic programming. It not only provides a thorough background for\nanyone wishing to use a probabilistic programming system, but also introduces\nthe techniques needed to design and build these systems. It is aimed at people\nwho have an undergraduate-level understanding of either or, ideally, both\nprobabilistic machine learning and programming languages.\n  We start with a discussion of model-based reasoning and explain why\nconditioning as a foundational computation is central to the fields of\nprobabilistic machine learning and artificial intelligence. We then introduce a\nsimple first-order probabilistic programming language (PPL) whose programs\ndefine static-computation-graph, finite-variable-cardinality models. In the\ncontext of this restricted PPL we introduce fundamental inference algorithms\nand describe how they can be implemented in the context of models denoted by\nprobabilistic programs.\n  In the second part of this document, we introduce a higher-order\nprobabilistic programming language, with a functionality analogous to that of\nestablished programming languages. This affords the opportunity to define\nmodels with dynamic computation graphs, at the cost of requiring inference\nmethods that generate samples by repeatedly executing the program. Foundational\ninference algorithms for this kind of probabilistic programming language are\nexplained in the context of an interface between program executions and an\ninference controller.\n  This document closes with a chapter on advanced topics which we believe to\nbe, at the time of writing, interesting directions for probabilistic\nprogramming research; directions that point towards a tight integration with\ndeep neural network research and the development of systems for next-generation\nartificial intelligence applications.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 20:44:23 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["van de Meent", "Jan-Willem", ""], ["Paige", "Brooks", ""], ["Yang", "Hongseok", ""], ["Wood", "Frank", ""]]}, {"id": "1809.10780", "submitter": "Daniel C. Castro", "authors": "Daniel C. Castro, Jeremy Tan, Bernhard Kainz, Ender Konukoglu, Ben\n  Glocker", "title": "Morpho-MNIST: Quantitative Assessment and Diagnostics for Representation\n  Learning", "comments": "The published version of this article can be found at\n  http://jmlr.org/papers/v20/19-033.html", "journal-ref": "Journal of Machine Learning Research 20 (2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Revealing latent structure in data is an active field of research, having\nintroduced exciting technologies such as variational autoencoders and\nadversarial networks, and is essential to push machine learning towards\nunsupervised knowledge discovery. However, a major challenge is the lack of\nsuitable benchmarks for an objective and quantitative evaluation of learned\nrepresentations. To address this issue we introduce Morpho-MNIST, a framework\nthat aims to answer: \"to what extent has my model learned to represent specific\nfactors of variation in the data?\" We extend the popular MNIST dataset by\nadding a morphometric analysis enabling quantitative comparison of trained\nmodels, identification of the roles of latent variables, and characterisation\nof sample diversity. We further propose a set of quantifiable perturbations to\nassess the performance of unsupervised and supervised methods on challenging\ntasks such as outlier detection and domain adaptation. Data and code are\navailable at https://github.com/dccastro/Morpho-MNIST.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 22:05:03 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 19:46:33 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 16:40:21 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Castro", "Daniel C.", ""], ["Tan", "Jeremy", ""], ["Kainz", "Bernhard", ""], ["Konukoglu", "Ender", ""], ["Glocker", "Ben", ""]]}, {"id": "1809.10782", "submitter": "Dylan Cashman", "authors": "Dylan Cashman (1), Shah Rukh Humayoun (1), Florian Heimerl (2),\n  Kendall Park (2), Subhajit Das (3), John Thompson (3), Bahador Saket (3),\n  Abigail Mosca (1), John Stasko (3), Alex Endert (3), Michael Gleicher (2),\n  Remco Chang (1) ((1) Tufts University, (2) University of Wisconsin - Madison,\n  (3) Georgia Tech)", "title": "A User-based Visual Analytics Workflow for Exploratory Model Analysis", "comments": null, "journal-ref": "Computer Graphics Forum 38(3) 2019, The Eurographics Association\n  and John Wiley & Sons Ltd", "doi": "10.1111/cgf.13681", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many visual analytics systems allow users to interact with machine learning\nmodels towards the goals of data exploration and insight generation on a given\ndataset. However, in some situations, insights may be less important than the\nproduction of an accurate predictive model for future use. In that case, users\nare more interested in generating of diverse and robust predictive models,\nverifying their performance on holdout data, and selecting the most suitable\nmodel for their usage scenario. In this paper, we consider the concept of\nExploratory Model Analysis (EMA), which is defined as the process of\ndiscovering and selecting relevant models that can be used to make predictions\non a data source. We delineate the differences between EMA and the well-known\nterm exploratory data analysis in terms of the desired outcome of the analytic\nprocess: insights into the data or a set of deployable models. The\ncontributions of this work are a visual analytics system workflow for EMA, a\nuser study, and two use cases validating the effectiveness of the workflow. We\nfound that our system workflow enabled users to generate complex models, to\nassess them for various qualities, and to select the most relevant model for\ntheir task.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 22:18:51 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 17:15:16 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 16:08:41 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Cashman", "Dylan", ""], ["Humayoun", "Shah Rukh", ""], ["Heimerl", "Florian", ""], ["Park", "Kendall", ""], ["Das", "Subhajit", ""], ["Thompson", "John", ""], ["Saket", "Bahador", ""], ["Mosca", "Abigail", ""], ["Stasko", "John", ""], ["Endert", "Alex", ""], ["Gleicher", "Michael", ""], ["Chang", "Remco", ""]]}, {"id": "1809.10784", "submitter": "Timur Takhtaganov", "authors": "Timur Takhtaganov and Juliane M\\\"uller", "title": "Adaptive Gaussian process surrogates for Bayesian inference", "comments": "38 pages, submitted to the SIAM/ASA Journal on Uncertainty\n  Quantification", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an adaptive approach to the construction of Gaussian process\nsurrogates for Bayesian inference with expensive-to-evaluate forward models.\nOur method relies on the fully Bayesian approach to training Gaussian process\nmodels and utilizes the expected improvement idea from Bayesian global\noptimization. We adaptively construct training designs by maximizing the\nexpected improvement in fit of the Gaussian process model to the noisy\nobservational data. Numerical experiments on model problems with synthetic data\ndemonstrate the effectiveness of the obtained adaptive designs compared to the\nfixed non-adaptive designs in terms of accurate posterior estimation at a\nfraction of the cost of inference with forward models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 22:24:05 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Takhtaganov", "Timur", ""], ["M\u00fcller", "Juliane", ""]]}, {"id": "1809.10787", "submitter": "Digvijay Boob", "authors": "Digvijay Boob, Santanu S. Dey, Guanghui Lan", "title": "Complexity of Training ReLU Neural Network", "comments": "Hardness proof has been simplified. Accepted for publication at\n  Discrete Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore some basic questions on the complexity of training\nneural networks with ReLU activation function. We show that it is NP-hard to\ntrain a two-hidden layer feedforward ReLU neural network. If dimension of the\ninput data and the network topology is fixed, then we show that there exists a\npolynomial time algorithm for the same training problem. We also show that if\nsufficient over-parameterization is provided in the first hidden layer of ReLU\nneural network, then there is a polynomial time algorithm which finds weights\nsuch that output of the over-parameterized ReLU neural network matches with the\noutput of the given data.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 22:32:50 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 21:12:55 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Boob", "Digvijay", ""], ["Dey", "Santanu S.", ""], ["Lan", "Guanghui", ""]]}, {"id": "1809.10788", "submitter": "Jonathan Juett", "authors": "Jonathan Juett and Benjamin Kuipers", "title": "Learning and Acting in Peripersonal Space: Moving, Reaching, and\n  Grasping", "comments": "35 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The young infant explores its body, its sensorimotor system, and the\nimmediately accessible parts of its environment, over the course of a few\nmonths creating a model of peripersonal space useful for reaching and grasping\nobjects around it. Drawing on constraints from the empirical literature on\ninfant behavior, we present a preliminary computational model of this learning\nprocess, implemented and evaluated on a physical robot. The learning agent\nexplores the relationship between the configuration space of the arm, sensing\njoint angles through proprioception, and its visual perceptions of the hand and\ngrippers. The resulting knowledge is represented as the peripersonal space\n(PPS) graph, where nodes represent states of the arm, edges represent safe\nmovements, and paths represent safe trajectories from one pose to another. In\nour model, the learning process is driven by intrinsic motivation. When\nrepeatedly performing an action, the agent learns the typical result, but also\ndetects unusual outcomes, and is motivated to learn how to make those unusual\nresults reliable. Arm motions typically leave the static background unchanged,\nbut occasionally bump an object, changing its static position. The reach action\nis learned as a reliable way to bump and move an object in the environment.\nSimilarly, once a reliable reach action is learned, it typically makes a\nquasi-static change in the environment, moving an object from one static\nposition to another. The unusual outcome is that the object is accidentally\ngrasped (thanks to the innate Palmar reflex), and thereafter moves dynamically\nwith the hand. Learning to make grasps reliable is more complex than for\nreaches, but we demonstrate significant progress. Our current results are steps\ntoward autonomous sensorimotor learning of motion, reaching, and grasping in\nperipersonal space, based on unguided exploration and intrinsic motivation.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 22:39:45 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Juett", "Jonathan", ""], ["Kuipers", "Benjamin", ""]]}, {"id": "1809.10789", "submitter": "Mark Collier", "authors": "Mark Collier and Joeran Beel", "title": "An Empirical Comparison of Syllabuses for Curriculum Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syllabuses for curriculum learning have been developed on an ad-hoc, per task\nbasis and little is known about the relative performance of different\nsyllabuses. We identify a number of syllabuses used in the literature. We\ncompare the identified syllabuses based on their effect on the speed of\nlearning and generalization ability of a LSTM network on three sequential\nlearning tasks. We find that the choice of syllabus has limited effect on the\ngeneralization ability of a trained network. In terms of speed of learning our\nresults demonstrate that the best syllabus is task dependent but that a\nrecently proposed automated curriculum learning approach - Predictive Gain,\nperforms very competitively against all identified hand-crafted syllabuses. The\nbest performing hand-crafted syllabus which we term Look Back and Forward\ncombines a syllabus which steps through tasks in the order of their difficulty\nwith a uniform distribution over all tasks. Our experimental results provide an\nempirical basis for the choice of syllabus on a new problem that could benefit\nfrom curriculum learning. Additionally, insights derived from our results shed\nlight on how to successfully design new syllabuses.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 22:44:33 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 18:48:16 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Collier", "Mark", ""], ["Beel", "Joeran", ""]]}, {"id": "1809.10791", "submitter": "Razieh Nabi", "authors": "Razieh Nabi, Phyllis Kanki, Ilya Shpitser", "title": "Estimation of Personalized Effects Associated With Causal Pathways", "comments": null, "journal-ref": "In Proceedings of the Thirty Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI), 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of personalized decision making is to map a unit's characteristics\nto an action tailored to maximize the expected outcome for that unit. Obtaining\nhigh-quality mappings of this type is the goal of the dynamic regime\nliterature. In healthcare settings, optimizing policies with respect to a\nparticular causal pathway may be of interest as well. For example, we may wish\nto maximize the chemical effect of a drug given data from an observational\nstudy where the chemical effect of the drug on the outcome is entangled with\nthe indirect effect mediated by differential adherence. In such cases, we may\nwish to optimize the direct effect of a drug, while keeping the indirect effect\nto that of some reference treatment. [16] shows how to combine mediation\nanalysis and dynamic treatment regime ideas to defines policies associated with\ncausal pathways and counterfactual responses to these policies. In this paper,\nwe derive a variety of methods for learning high quality policies of this type\nfrom data, in a causal model corresponding to a longitudinal setting of\npractical importance. We illustrate our methods via a dataset of HIV patients\nundergoing therapy, gathered in the Nigerian PEPFAR program.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 22:49:29 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Nabi", "Razieh", ""], ["Kanki", "Phyllis", ""], ["Shpitser", "Ilya", ""]]}, {"id": "1809.10794", "submitter": "Manuele Leonelli", "authors": "Christiane Goergen, Manuele Leonelli", "title": "Model-Preserving Sensitivity Analysis for Families of Gaussian\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of probability distributions inferred using machine-learning\nalgorithms heavily depends on data availability and quality. In practical\napplications it is therefore fundamental to investigate the robustness of a\nstatistical model to misspecification of some of its underlying probabilities.\nIn the context of graphical models, investigations of robustness fall under the\nnotion of sensitivity analyses. These analyses consist in varying some of the\nmodel's probabilities or parameters and then assessing how far apart the\noriginal and the varied distributions are. However, for Gaussian graphical\nmodels, such variations usually make the original graph an incoherent\nrepresentation of the model's conditional independence structure. Here we\ndevelop an approach to sensitivity analysis which guarantees the original graph\nremains valid after any probability variation and we quantify the effect of\nsuch variations using different measures. To achieve this we take advantage of\nalgebraic techniques to both concisely represent conditional independence and\nto provide a straightforward way of checking the validity of such\nrelationships. Our methods are demonstrated to be robust and comparable to\nstandard ones, which break the conditional independence structure of the model,\nusing an artificial example and a medical real-world application.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 23:12:15 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Goergen", "Christiane", ""], ["Leonelli", "Manuele", ""]]}, {"id": "1809.10804", "submitter": "Ivan Girardi", "authors": "Ivan Girardi, Pengfei Ji, An-phi Nguyen, Nora Hollenstein, Adam\n  Ivankay, Lorenz Kuhn, Chiara Marchiori and Ce Zhang", "title": "Patient Risk Assessment and Warning Symptom Detection Using Deep\n  Attention-Based Neural Networks", "comments": "10 pages, 2 figures, EMNLP workshop LOUHI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an operational component of a real-world patient triage system.\nGiven a specific patient presentation, the system is able to assess the level\nof medical urgency and issue the most appropriate recommendation in terms of\nbest point of care and time to treat. We use an attention-based convolutional\nneural network architecture trained on 600,000 doctor notes in German. We\ncompare two approaches, one that uses the full text of the medical notes and\none that uses only a selected list of medical entities extracted from the text.\nThese approaches achieve 79% and 66% precision, respectively, but on a\nconfidence threshold of 0.6, precision increases to 85% and 75%, respectively.\nIn addition, a method to detect warning symptoms is implemented to render the\nclassification task transparent from a medical perspective. The method is based\non the learning of attention scores and a method of automatic validation using\nthe same data.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 00:14:10 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Girardi", "Ivan", ""], ["Ji", "Pengfei", ""], ["Nguyen", "An-phi", ""], ["Hollenstein", "Nora", ""], ["Ivankay", "Adam", ""], ["Kuhn", "Lorenz", ""], ["Marchiori", "Chiara", ""], ["Zhang", "Ce", ""]]}, {"id": "1809.10816", "submitter": "Zhe Li", "authors": "Yezheng Liu, Zhe Li, Chong Zhou, Yuanchun Jiang, Jianshan Sun, Meng\n  Wang and Xiangnan He", "title": "Generative Adversarial Active Learning for Unsupervised Outlier\n  Detection", "comments": "TKDE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is an important topic in machine learning and has been used\nin a wide range of applications. In this paper, we approach outlier detection\nas a binary-classification issue by sampling potential outliers from a uniform\nreference distribution. However, due to the sparsity of data in\nhigh-dimensional space, a limited number of potential outliers may fail to\nprovide sufficient information to assist the classifier in describing a\nboundary that can separate outliers from normal data effectively. To address\nthis, we propose a novel Single-Objective Generative Adversarial Active\nLearning (SO-GAAL) method for outlier detection, which can directly generate\ninformative potential outliers based on the mini-max game between a generator\nand a discriminator. Moreover, to prevent the generator from falling into the\nmode collapsing problem, the stop node of training should be determined when\nSO-GAAL is able to provide sufficient information. But without any prior\ninformation, it is extremely difficult for SO-GAAL. Therefore, we expand the\nnetwork structure of SO-GAAL from a single generator to multiple generators\nwith different objectives (MO-GAAL), which can generate a reasonable reference\ndistribution for the whole dataset. We empirically compare the proposed\napproach with several state-of-the-art outlier detection methods on both\nsynthetic and real-world datasets. The results show that MO-GAAL outperforms\nits competitors in the majority of cases, especially for datasets with various\ncluster types or high irrelevant variable ratio.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 01:41:59 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 01:58:16 GMT"}, {"version": "v3", "created": "Thu, 14 Mar 2019 13:44:52 GMT"}, {"version": "v4", "created": "Mon, 18 Mar 2019 02:15:27 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Liu", "Yezheng", ""], ["Li", "Zhe", ""], ["Zhou", "Chong", ""], ["Jiang", "Yuanchun", ""], ["Sun", "Jianshan", ""], ["Wang", "Meng", ""], ["He", "Xiangnan", ""]]}, {"id": "1809.10818", "submitter": "Wenbo Wang", "authors": "Wenbo Wang and Xingye Qiao", "title": "Learning Confidence Sets using Support Vector Machines", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of confidence-set learning in the binary classification setting is\nto construct two sets, each with a specific probability guarantee to cover a\nclass. An observation outside the overlap of the two sets is deemed to be from\none of the two classes, while the overlap is an ambiguity region which could\nbelong to either class. Instead of plug-in approaches, we propose a support\nvector classifier to construct confidence sets in a flexible manner.\nTheoretically, we show that the proposed learner can control the non-coverage\nrates and minimize the ambiguity with high probability. Efficient algorithms\nare developed and numerical studies illustrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 01:47:54 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Wang", "Wenbo", ""], ["Qiao", "Xingye", ""]]}, {"id": "1809.10827", "submitter": "Ji Oon Lee", "authors": "Hye Won Chung and Ji Oon Lee", "title": "Weak detection in the spiked Wigner model", "comments": "45 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the weak detection problem in a rank-one spiked Wigner data\nmatrix where the signal-to-noise ratio is small so that reliable detection is\nimpossible. We propose a hypothesis test on the presence of the signal by\nutilizing the linear spectral statistics of the data matrix. The test is\ndata-driven and does not require prior knowledge about the distribution of the\nsignal or the noise. When the noise is Gaussian, the proposed test is optimal\nin the sense that its error matches that of the likelihood ratio test, which\nminimizes the sum of the Type-I and Type-II errors. If the density of the noise\nis known and non-Gaussian, the error of the test can be lowered by applying an\nentrywise transformation to the data matrix. We establish a central limit\ntheorem for the linear spectral statistics of general rank-one spiked Wigner\nmatrices as an intermediate step.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 02:30:27 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 07:44:17 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 02:53:52 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Chung", "Hye Won", ""], ["Lee", "Ji Oon", ""]]}, {"id": "1809.10829", "submitter": "Yuandong Tian", "authors": "Yuandong Tian", "title": "A theoretical framework for deep locally connected ReLU network", "comments": "Submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding theoretical properties of deep and locally connected nonlinear\nnetwork, such as deep convolutional neural network (DCNN), is still a hard\nproblem despite its empirical success. In this paper, we propose a novel\ntheoretical framework for such networks with ReLU nonlinearity. The framework\nexplicitly formulates data distribution, favors disentangled representations\nand is compatible with common regularization techniques such as Batch Norm. The\nframework is built upon teacher-student setting, by expanding the student\nforward/backward propagation onto the teacher's computational graph. The\nresulting model does not impose unrealistic assumptions (e.g., Gaussian inputs,\nindependence of activation, etc). Our framework could help facilitate\ntheoretical analysis of many practical issues, e.g. overfitting,\ngeneralization, disentangled representations in deep networks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 02:37:35 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Tian", "Yuandong", ""]]}, {"id": "1809.10835", "submitter": "Dung Thai", "authors": "Dung Thai, Sree Harsha Ramesh, Shikhar Murty, Luke Vilnis, Andrew\n  McCallum", "title": "Embedded-State Latent Conditional Random Fields for Sequence Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex textual information extraction tasks are often posed as sequence\nlabeling or \\emph{shallow parsing}, where fields are extracted using local\nlabels made consistent through probabilistic inference in a graphical model\nwith constrained transitions. Recently, it has become common to locally\nparametrize these models using rich features extracted by recurrent neural\nnetworks (such as LSTM), while enforcing consistent outputs through a simple\nlinear-chain model, representing Markovian dependencies between successive\nlabels. However, the simple graphical model structure belies the often complex\nnon-local constraints between output labels. For example, many fields, such as\na first name, can only occur a fixed number of times, or in the presence of\nother fields. While RNNs have provided increasingly powerful context-aware\nlocal features for sequence tagging, they have yet to be integrated with a\nglobal graphical model of similar expressivity in the output distribution. Our\nmodel goes beyond the linear chain CRF to incorporate multiple hidden states\nper output label, but parametrizes their transitions parsimoniously with\nlow-rank log-potential scoring matrices, effectively learning an embedding\nspace for hidden states. This augmented latent space of inference variables\ncomplements the rich feature representation of the RNN, and allows exact global\ninference obeying complex, learned non-local output constraints. We experiment\nwith several datasets and show that the model outperforms baseline CRF+RNN\nmodels when global output constraints are necessary at inference-time, and\nexplore the interpretable latent structure.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 03:06:31 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Thai", "Dung", ""], ["Ramesh", "Sree Harsha", ""], ["Murty", "Shikhar", ""], ["Vilnis", "Luke", ""], ["McCallum", "Andrew", ""]]}, {"id": "1809.10842", "submitter": "Yi Wu", "authors": "Yi Wu, Yuxin Wu, Aviv Tamar, Stuart Russell, Georgia Gkioxari,\n  Yuandong Tian", "title": "Learning and Planning with a Semantic Model", "comments": "submitted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building deep reinforcement learning agents that can generalize and adapt to\nunseen environments remains a fundamental challenge for AI. This paper\ndescribes progresses on this challenge in the context of man-made environments,\nwhich are visually diverse but contain intrinsic semantic regularities. We\npropose a hybrid model-based and model-free approach, LEArning and Planning\nwith Semantics (LEAPS), consisting of a multi-target sub-policy that acts on\nvisual inputs, and a Bayesian model over semantic structures. When placed in an\nunseen environment, the agent plans with the semantic model to make high-level\ndecisions, proposes the next sub-target for the sub-policy to execute, and\nupdates the semantic model based on new observations. We perform experiments in\nvisual navigation tasks using House3D, a 3D environment that contains diverse\nhuman-designed indoor scenes with real-world objects. LEAPS outperforms strong\nbaselines that do not explicitly plan using the semantic content.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 03:30:37 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Wu", "Yi", ""], ["Wu", "Yuxin", ""], ["Tamar", "Aviv", ""], ["Russell", "Stuart", ""], ["Gkioxari", "Georgia", ""], ["Tian", "Yuandong", ""]]}, {"id": "1809.10847", "submitter": "T.S. Jayram", "authors": "T.S. Jayram and Tomasz Kornuta and Ryan L. McAvoy and Ahmet S. Ozcan", "title": "Using Multi-task and Transfer Learning to Solve Working Memory Tasks", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new architecture called Memory-Augmented Encoder-Solver (MAES)\nthat enables transfer learning to solve complex working memory tasks adapted\nfrom cognitive psychology. It uses dual recurrent neural network controllers,\ninside the encoder and solver, respectively, that interface with a shared\nmemory module and is completely differentiable. We study different types of\nencoders in a systematic manner and demonstrate a unique advantage of\nmulti-task learning in obtaining the best possible encoder. We show by\nextensive experimentation that the trained MAES models achieve task-size\ngeneralization, i.e., they are capable of handling sequential inputs 50 times\nlonger than seen during training, with appropriately large memory modules. We\ndemonstrate that the performance achieved by MAES far outperforms existing and\nwell-known models such as the LSTM, NTM and DNC on the entire suite of tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 04:01:06 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Jayram", "T. S.", ""], ["Kornuta", "Tomasz", ""], ["McAvoy", "Ryan L.", ""], ["Ozcan", "Ahmet S.", ""]]}, {"id": "1809.10851", "submitter": "Dongmian Zou", "authors": "Dongmian Zou, Gilad Lerman", "title": "Encoding Robust Representation for Graph Generation", "comments": "9 pages, 7 figures, 6 tables", "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN),\n  Budapest, Hungary, 2019, pp. 1-9", "doi": "10.1109/IJCNN.2019.8851705", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative networks have made it possible to generate meaningful signals such\nas images and texts from simple noise. Recently, generative methods based on\nGAN and VAE were developed for graphs and graph signals. However, the\nmathematical properties of these methods are unclear, and training good\ngenerative models is difficult. This work proposes a graph generation model\nthat uses a recent adaptation of Mallat's scattering transform to graphs. The\nproposed model is naturally composed of an encoder and a decoder. The encoder\nis a Gaussianized graph scattering transform, which is robust to signal and\ngraph manipulation. The decoder is a simple fully connected network that is\nadapted to specific tasks, such as link prediction, signal generation on graphs\nand full graph and signal generation. The training of our proposed system is\nefficient since it is only applied to the decoder and the hardware requirements\nare moderate. Numerical results demonstrate state-of-the-art performance of the\nproposed system for both link prediction and graph and signal generation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 04:11:18 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 23:52:51 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Zou", "Dongmian", ""], ["Lerman", "Gilad", ""]]}, {"id": "1809.10855", "submitter": "Stephen Tu", "authors": "Stephen Tu and Ross Boczar and Benjamin Recht", "title": "Minimax Lower Bounds for $\\mathcal{H}_\\infty$-Norm Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating the $\\mathcal{H}_\\infty$-norm of an LTI system from\nnoisy input/output measurements has attracted recent attention as an\nalternative to parameter identification for bounding unmodeled dynamics in\nrobust control. In this paper, we study lower bounds for\n$\\mathcal{H}_\\infty$-norm estimation under a query model where at each\niteration the algorithm chooses a bounded input signal and receives the\nresponse of the chosen signal corrupted by white noise. We prove that when the\nunderlying system is an FIR filter, $\\mathcal{H}_\\infty$-norm estimation is no\nmore efficient than model identification for passive sampling. For active\nsampling, we show that norm estimation is at most a factor of $\\log{r}$ more\nsample efficient than model identification, where $r$ is the length of the\nfilter. We complement our theoretical results with experiments which\ndemonstrate that a simple non-adaptive estimator of the norm is competitive\nwith state-of-the-art adaptive norm estimation algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 04:47:09 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Tu", "Stephen", ""], ["Boczar", "Ross", ""], ["Recht", "Benjamin", ""]]}, {"id": "1809.10858", "submitter": "Chulhee Yun", "authors": "Chulhee Yun, Suvrit Sra, Ali Jadbabaie", "title": "Efficiently testing local optimality and escaping saddles for ReLU\n  networks", "comments": "23 pages, appeared at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a theoretical algorithm for checking local optimality and escaping\nsaddles at nondifferentiable points of empirical risks of two-layer ReLU\nnetworks. Our algorithm receives any parameter value and returns: local\nminimum, second-order stationary point, or a strict descent direction. The\npresence of $M$ data points on the nondifferentiability of the ReLU divides the\nparameter space into at most $2^M$ regions, which makes analysis difficult. By\nexploiting polyhedral geometry, we reduce the total computation down to one\nconvex quadratic program (QP) for each hidden node, $O(M)$ (in)equality tests,\nand one (or a few) nonconvex QP. For the last QP, we show that our specific\nproblem can be solved efficiently, in spite of nonconvexity. In the benign\ncase, we solve one equality constrained QP, and we prove that projected\ngradient descent solves it exponentially fast. In the bad case, we have to\nsolve a few more inequality constrained QPs, but we prove that the time\ncomplexity is exponential only in the number of inequality constraints. Our\nexperiments show that either benign case or bad case with very few inequality\nconstraints occurs, implying that our algorithm is efficient in most cases.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 04:53:03 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 00:22:12 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Yun", "Chulhee", ""], ["Sra", "Suvrit", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1809.10862", "submitter": "Zhiling Guo", "authors": "Zhiling Guo, Hiroaki Shengoku, Guangming Wu, Qi Chen, Wei Yuan,\n  Xiaodan Shi, Xiaowei Shao, Yongwei Xu, Ryosuke Shibasaki", "title": "Semantic Segmentation for Urban Planning Maps based on U-Net", "comments": "4 pages, 3 figures, conference, International Geoscience and Remote\n  Sensing Symposium (IGARSS 2018), Jul 2018, Valencia, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic digitizing of paper maps is a significant and challenging task\nfor both academia and industry. As an important procedure of map digitizing,\nthe semantic segmentation section mainly relies on manual visual interpretation\nwith low efficiency. In this study, we select urban planning maps as a\nrepresentative sample and investigate the feasibility of utilizing U-shape\nfully convolutional based architecture to perform end-to-end map semantic\nsegmentation. The experimental results obtained from the test area in Shibuya\ndistrict, Tokyo, demonstrate that our proposed method could achieve a very high\nJaccard similarity coefficient of 93.63% and an overall accuracy of 99.36%. For\nimplementation on GPGPU and cuDNN, the required processing time for the whole\nShibuya district can be less than three minutes. The results indicate the\nproposed method can serve as a viable tool for urban planning map semantic\nsegmentation task with high accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 05:32:45 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 03:00:11 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Guo", "Zhiling", ""], ["Shengoku", "Hiroaki", ""], ["Wu", "Guangming", ""], ["Chen", "Qi", ""], ["Yuan", "Wei", ""], ["Shi", "Xiaodan", ""], ["Shao", "Xiaowei", ""], ["Xu", "Yongwei", ""], ["Shibasaki", "Ryosuke", ""]]}, {"id": "1809.10875", "submitter": "Zhuolin Yang", "authors": "Zhuolin Yang, Bo Li, Pin-Yu Chen, Dawn Song", "title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have highlighted adversarial examples as a ubiquitous threat\nto different neural network models and many downstream applications.\nNonetheless, as unique data properties have inspired distinct and powerful\nlearning principles, this paper aims to explore their potentials towards\nmitigating adversarial inputs. In particular, our results reveal the importance\nof using the temporal dependency in audio data to gain discriminate power\nagainst adversarial examples. Tested on the automatic speech recognition (ASR)\ntasks and three recent audio adversarial attacks, we find that (i) input\ntransformation developed from image adversarial defense provides limited\nrobustness improvement and is subtle to advanced attacks; (ii) temporal\ndependency can be exploited to gain discriminative power against audio\nadversarial examples and is resistant to adaptive attacks considered in our\nexperiments. Our results not only show promising means of improving the\nrobustness of ASR systems, but also offer novel insights in exploiting\ndomain-specific data properties to mitigate negative effects of adversarial\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 06:39:42 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 15:21:37 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Yang", "Zhuolin", ""], ["Li", "Bo", ""], ["Chen", "Pin-Yu", ""], ["Song", "Dawn", ""]]}, {"id": "1809.10877", "submitter": "Seonguk Seo", "authors": "Seonguk Seo, Paul Hongsuck Seo, Bohyung Han", "title": "Learning for Single-Shot Confidence Calibration in Deep Neural Networks\n  through Stochastic Inferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generic framework to calibrate accuracy and confidence of a\nprediction in deep neural networks through stochastic inferences. We interpret\nstochastic regularization using a Bayesian model, and analyze the relation\nbetween predictive uncertainty of networks and variance of the prediction\nscores obtained by stochastic inferences for a single example. Our empirical\nstudy shows that the accuracy and the score of a prediction are highly\ncorrelated with the variance of multiple stochastic inferences given by\nstochastic depth or dropout. Motivated by this observation, we design a novel\nvariance-weighted confidence-integrated loss function that is composed of two\ncross-entropy loss terms with respect to ground-truth and uniform distribution,\nwhich are balanced by variance of stochastic prediction scores. The proposed\nloss function enables us to learn deep neural networks that predict confidence\ncalibrated scores using a single inference. Our algorithm presents outstanding\nconfidence calibration performance and improves classification accuracy when\ncombined with two popular stochastic regularization techniques---stochastic\ndepth and dropout---in multiple models and datasets; it alleviates\noverconfidence issue in deep neural networks significantly by training networks\nto achieve prediction accuracy proportional to confidence of prediction.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 06:43:26 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 07:37:17 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 07:05:15 GMT"}, {"version": "v4", "created": "Tue, 27 Nov 2018 04:20:29 GMT"}, {"version": "v5", "created": "Wed, 24 Apr 2019 17:20:34 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Seo", "Seonguk", ""], ["Seo", "Paul Hongsuck", ""], ["Han", "Bohyung", ""]]}, {"id": "1809.10889", "submitter": "Zheyi Pan", "authors": "Zheyi Pan, Yuxuan Liang, Junbo Zhang, Xiuwen Yi, Yong Yu and Yu Zheng", "title": "HyperST-Net: Hypernetworks for Spatio-Temporal Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal (ST) data, which represent multiple time series data\ncorresponding to different spatial locations, are ubiquitous in real-world\ndynamic systems, such as air quality readings. Forecasting over ST data is of\ngreat importance but challenging as it is affected by many complex factors,\nincluding spatial characteristics, temporal characteristics and the intrinsic\ncausality between them. In this paper, we propose a general framework\n(HyperST-Net) based on hypernetworks for deep ST models. More specifically, it\nconsists of three major modules: a spatial module, a temporal module and a\ndeduction module. Among them, the deduction module derives the parameter\nweights of the temporal module from the spatial characteristics, which are\nextracted by the spatial module. Then, we design a general form of HyperST\nlayer as well as different forms for several basic layers in neural networks,\nincluding the dense layer (HyperST-Dense) and the convolutional layer\n(HyperST-Conv). Experiments on three types of real-world tasks demonstrate that\nthe predictive models integrated with our framework achieve significant\nimprovements, and outperform the state-of-the-art baselines as well.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 07:29:21 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Pan", "Zheyi", ""], ["Liang", "Yuxuan", ""], ["Zhang", "Junbo", ""], ["Yi", "Xiuwen", ""], ["Yu", "Yong", ""], ["Zheng", "Yu", ""]]}, {"id": "1809.10932", "submitter": "Huy Phan", "authors": "Huy Phan, Fernando Andreotti, Navin Cooray, Oliver Y. Ch\\'en, Maarten\n  De Vos", "title": "SeqSleepNet: End-to-End Hierarchical Recurrent Neural Network for\n  Sequence-to-Sequence Automatic Sleep Staging", "comments": "This article has been published in IEEE Transactions on Neural\n  Systems and Rehabilitation Engineering", "journal-ref": null, "doi": "10.1109/TNSRE.2019.2896659", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic sleep staging has been often treated as a simple classification\nproblem that aims at determining the label of individual target polysomnography\n(PSG) epochs one at a time. In this work, we tackle the task as a\nsequence-to-sequence classification problem that receives a sequence of\nmultiple epochs as input and classifies all of their labels at once. For this\npurpose, we propose a hierarchical recurrent neural network named SeqSleepNet.\nAt the epoch processing level, the network consists of a filterbank layer\ntailored to learn frequency-domain filters for preprocessing and an\nattention-based recurrent layer designed for short-term sequential modelling.\nAt the sequence processing level, a recurrent layer placed on top of the\nlearned epoch-wise features for long-term modelling of sequential epochs. The\nclassification is then carried out on the output vectors at every time step of\nthe top recurrent layer to produce the sequence of output labels. Despite being\nhierarchical, we present a strategy to train the network in an end-to-end\nfashion. We show that the proposed network outperforms state-of-the-art\napproaches, achieving an overall accuracy, macro F1-score, and Cohen's kappa of\n87.1%, 83.3%, and 0.815 on a publicly available dataset with 200 subjects.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 09:37:48 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 08:17:21 GMT"}, {"version": "v3", "created": "Sat, 2 Feb 2019 01:46:14 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Phan", "Huy", ""], ["Andreotti", "Fernando", ""], ["Cooray", "Navin", ""], ["Ch\u00e9n", "Oliver Y.", ""], ["De Vos", "Maarten", ""]]}, {"id": "1809.10941", "submitter": "Samir Suweis Dr.", "authors": "Alberto Testolin, Michele Piccolini, Samir Suweis", "title": "Deep learning systems as complex networks", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the availability of large scale digital datasets and massive\namounts of computational power, deep learning algorithms can learn\nrepresentations of data by exploiting multiple levels of abstraction. These\nmachine learning methods have greatly improved the state-of-the-art in many\nchallenging cognitive tasks, such as visual object recognition, speech\nprocessing, natural language understanding and automatic translation. In\nparticular, one class of deep learning models, known as deep belief networks,\ncan discover intricate statistical structure in large data sets in a completely\nunsupervised fashion, by learning a generative model of the data using\nHebbian-like learning mechanisms. Although these self-organizing systems can be\nconveniently formalized within the framework of statistical mechanics, their\ninternal functioning remains opaque, because their emergent dynamics cannot be\nsolved analytically. In this article we propose to study deep belief networks\nusing techniques commonly employed in the study of complex networks, in order\nto gain some insights into the structural and functional properties of the\ncomputational graph resulting from the learning process.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 10:06:36 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Testolin", "Alberto", ""], ["Piccolini", "Michele", ""], ["Suweis", "Samir", ""]]}, {"id": "1809.10959", "submitter": "Juan Juli\\'an Merelo-Guerv\\'os Pr.", "authors": "Rub\\'en H. Garc\\'ia-Ortega, Juan J. Merelo-Guerv\\'os, Pablo Garc\\'ia\n  S\\'anchez, Gad Pitaru", "title": "Overview of PicTropes, a film trope dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": "GeNeura 2018-09-2", "categories": "cs.CY cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  From the database DBTropes.org, we have created a dataset of films and the\ntropes that they use, which we have called PicTropes. In this report we provide\nthe descriptive analysis and a further discussion on the dataset PicTropes: The\nextracted features will help us decide the best values for a future\nrecommendation system and content generator, whereas the analysis of the\ndistribution functions that fit the best will help us interpret the relation\nbetween the films and the tropes that were found inside them. Additionally, we\nprovide rankings of the top-25 tropes and films, which will help us discuss and\nformulate questions to guide future extensions of the PicTropes dataset.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 11:00:20 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 10:45:10 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Garc\u00eda-Ortega", "Rub\u00e9n H.", ""], ["Merelo-Guerv\u00f3s", "Juan J.", ""], ["S\u00e1nchez", "Pablo Garc\u00eda", ""], ["Pitaru", "Gad", ""]]}, {"id": "1809.10962", "submitter": "Xiaofeng Cao", "authors": "Xiaofeng Cao, Ivor W. Tsang, Xiaofeng Xu, Guandong Xu", "title": "Target-Independent Active Learning via Distribution-Splitting", "comments": "This paper has been withdrawn. The first author quitted the PhD study\n  from AAI, University of Technology Sydney. The manuscript stopped updating", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce the label complexity in Agnostic Active Learning (A^2 algorithm),\nvolume-splitting splits the hypothesis edges to reduce the Vapnik-Chervonenkis\n(VC) dimension in version space. However, the effectiveness of volume-splitting\ncritically depends on the initial hypothesis and this problem is also known as\ntarget-dependent label complexity gap. This paper attempts to minimize this gap\nby introducing a novel notion of number density which provides a more natural\nand direct way to describe the hypothesis distribution than volume. By\ndiscovering the connections between hypothesis and input distribution, we map\nthe volume of version space into the number density and propose a\ntarget-independent distribution-splitting strategy with the following\nadvantages: 1) provide theoretical guarantees on reducing label complexity and\nerror rate as volume-splitting; 2) break the curse of initial hypothesis; 3)\nprovide model guidance for a target-independent AL algorithm in real AL tasks.\nWith these guarantees, for AL application, we then split the input distribution\ninto more near-optimal spheres and develop an application algorithm called\nDistribution-based A^2 (DA^2). Experiments further verify the effectiveness of\nthe halving and querying abilities of DA^2. Contributions of this paper are as\nfollows.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 11:07:03 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 23:52:32 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Cao", "Xiaofeng", ""], ["Tsang", "Ivor W.", ""], ["Xu", "Xiaofeng", ""], ["Xu", "Guandong", ""]]}, {"id": "1809.10979", "submitter": "Stephan Spiegel Dr.", "authors": "Stephan Spiegel, Fabian Mueller, Dorothea Weismann, John Bird", "title": "Cost-Sensitive Learning for Predictive Maintenance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In predictive maintenance, model performance is usually assessed by means of\nprecision, recall, and F1-score. However, employing the model with best\nperformance, e.g. highest F1-score, does not necessarily result in minimum\nmaintenance cost, but can instead lead to additional expenses. Thus, we propose\nto perform model selection based on the economic costs associated with the\nparticular maintenance application. We show that cost-sensitive learning for\npredictive maintenance can result in significant cost reduction and fault\ntolerant policies, since it allows to incorporate various business constraints\nand requirements.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 12:08:51 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Spiegel", "Stephan", ""], ["Mueller", "Fabian", ""], ["Weismann", "Dorothea", ""], ["Bird", "John", ""]]}, {"id": "1809.11003", "submitter": "Hongyu Liu", "authors": "Jinhong Li, Hongyu Liu, Wing-Yan Tsui and Xianchao Wang", "title": "An inverse scattering approach for geometric body generation: a machine\n  learning perspective", "comments": "22pages, comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are concerned with the 2D and 3D geometric shape generation\nby prescribing a set of characteristic values of a specific geometric body. One\nof the major motivations of our study is the 3D human body generation in\nvarious applications. We develop a novel method that can generate the desired\nbody with customized characteristic values. The proposed method follows a\nmachine-learning flavour that generates the inferred geometric body with the\ninput characteristic parameters from a training dataset. One of the critical\ningredients and novelties of our method is the borrowing of inverse scattering\ntechniques in the theory of wave propagation to the body generation. This is\ndone by establishing a delicate one-to-one correspondence between a geometric\nbody and the far-field pattern of a source scattering problem governed by the\nHelmholtz system. It in turn enables us to establish a one-to-one\ncorrespondence between the geometric body space and the function space defined\nby the far-field patterns. Hence, the far-field patterns can act as the shape\ngenerators. The shape generation with prescribed characteristic parameters is\nachieved by first manipulating the shape generators and then reconstructing the\ncorresponding geometric body from the obtained shape generator by a stable\nmultiple-frequency Fourier method. Our method is easy to implement and produces\nmore efficient and stable body generations. We provide both theoretical\nanalysis and extensive numerical experiments for the proposed method. The study\nis the first attempt to introduce inverse scattering approaches in combination\nwith machine learning to the geometric body generation and it opens up many\nopportunities for further developments.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 12:48:57 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Li", "Jinhong", ""], ["Liu", "Hongyu", ""], ["Tsui", "Wing-Yan", ""], ["Wang", "Xianchao", ""]]}, {"id": "1809.11008", "submitter": "Bo Han", "authors": "Bo Han, Gang Niu, Xingrui Yu, Quanming Yao, Miao Xu, Ivor Tsang,\n  Masashi Sugiyama", "title": "SIGUA: Forgetting May Make Learning with Noisy Labels More Robust", "comments": "ICML 2020 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given data with noisy labels, over-parameterized deep networks can gradually\nmemorize the data, and fit everything in the end. Although equipped with\ncorrections for noisy labels, many learning methods in this area still suffer\noverfitting due to undesired memorization. In this paper, to relieve this\nissue, we propose stochastic integrated gradient underweighted ascent (SIGUA):\nin a mini-batch, we adopt gradient descent on good data as usual, and\nlearning-rate-reduced gradient ascent on bad data; the proposal is a versatile\napproach where data goodness or badness is w.r.t. desired or undesired\nmemorization given a base learning method. Technically, SIGUA pulls\noptimization back for generalization when their goals conflict with each other;\nphilosophically, SIGUA shows forgetting undesired memorization can reinforce\ndesired memorization. Experiments demonstrate that SIGUA successfully\nrobustifies two typical base learning methods, so that their performance is\noften significantly improved.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 13:08:54 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 13:05:16 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 03:19:31 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Han", "Bo", ""], ["Niu", "Gang", ""], ["Yu", "Xingrui", ""], ["Yao", "Quanming", ""], ["Xu", "Miao", ""], ["Tsang", "Ivor", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1809.11017", "submitter": "Peifeng Wang", "authors": "Peifeng Wang, Shuangyin Li, Rong pan", "title": "Incorporating GAN for Negative Sampling in Knowledge Representation\n  Learning", "comments": "Accepted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge representation learning aims at modeling knowledge graph by\nencoding entities and relations into a low dimensional space. Most of the\ntraditional works for knowledge embedding need negative sampling to minimize a\nmargin-based ranking loss. However, those works construct negative samples\nthrough a random mode, by which the samples are often too trivial to fit the\nmodel efficiently. In this paper, we propose a novel knowledge representation\nlearning framework based on Generative Adversarial Networks (GAN). In this\nGAN-based framework, we take advantage of a generator to obtain high-quality\nnegative samples. Meanwhile, the discriminator in GAN learns the embeddings of\nthe entities and relations in knowledge graph. Thus, we can incorporate the\nproposed GAN-based framework into various traditional models to improve the\nability of knowledge representation learning. Experimental results show that\nour proposed GAN-based framework outperforms baselines on triplets\nclassification and link prediction tasks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 04:37:24 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Wang", "Peifeng", ""], ["Li", "Shuangyin", ""], ["pan", "Rong", ""]]}, {"id": "1809.11029", "submitter": "Ziwei Zhang", "authors": "Ziwei Zhang", "title": "A Note on Spectral Clustering and SVD of Graph Data", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering and Singular Value Decomposition (SVD) are both widely\nused technique for analyzing graph data. In this note, I will present their\nconnections using simple linear algebra, aiming to provide some in-depth\nunderstanding for future research.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 06:16:15 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Zhang", "Ziwei", ""]]}, {"id": "1809.11033", "submitter": "Ilja Kuzborskij", "authors": "Ilja Kuzborskij, Leonardo Cella, Nicol\\`o Cesa-Bianchi", "title": "Efficient Linear Bandits through Matrix Sketching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that two popular linear contextual bandit algorithms, OFUL and\nThompson Sampling, can be made efficient using Frequent Directions, a\ndeterministic online sketching technique. More precisely, we show that a sketch\nof size $m$ allows a $\\mathcal{O}(md)$ update time for both algorithms, as\nopposed to $\\Omega(d^2)$ required by their non-sketched versions in general\n(where $d$ is the dimension of context vectors). This computational speedup is\naccompanied by regret bounds of order $(1+\\varepsilon_m)^{3/2}d\\sqrt{T}$ for\nOFUL and of order $\\big((1+\\varepsilon_m)d\\big)^{3/2}\\sqrt{T}$ for Thompson\nSampling, where $\\varepsilon_m$ is bounded by the sum of the tail eigenvalues\nnot covered by the sketch. In particular, when the selected contexts span a\nsubspace of dimension at most $m$, our algorithms have a regret bound matching\nthat of their slower, non-sketched counterparts. Experiments on real-world\ndatasets corroborate our theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 14:00:05 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 21:39:50 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Kuzborskij", "Ilja", ""], ["Cella", "Leonardo", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""]]}, {"id": "1809.11044", "submitter": "Andrea Tacchetti", "authors": "Andrea Tacchetti, H. Francis Song, Pedro A. M. Mediano, Vinicius\n  Zambaldi, Neil C. Rabinowitz, Thore Graepel, Matthew Botvinick, Peter W.\n  Battaglia", "title": "Relational Forward Models for Multi-Agent Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavioral dynamics of multi-agent systems have a rich and orderly\nstructure, which can be leveraged to understand these systems, and to improve\nhow artificial agents learn to operate in them. Here we introduce Relational\nForward Models (RFM) for multi-agent learning, networks that can learn to make\naccurate predictions of agents' future behavior in multi-agent environments.\nBecause these models operate on the discrete entities and relations present in\nthe environment, they produce interpretable intermediate representations which\noffer insights into what drives agents' behavior, and what events mediate the\nintensity and valence of social interactions. Furthermore, we show that\nembedding RFM modules inside agents results in faster learning systems compared\nto non-augmented baselines. As more and more of the autonomous systems we\ndevelop and interact with become multi-agent in nature, developing richer\nanalysis tools for characterizing how and why agents make decisions is\nincreasingly necessary. Moreover, developing artificial agents that quickly and\nsafely learn to coordinate with one another, and with humans in shared\nenvironments, is crucial.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 14:10:39 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Tacchetti", "Andrea", ""], ["Song", "H. Francis", ""], ["Mediano", "Pedro A. M.", ""], ["Zambaldi", "Vinicius", ""], ["Rabinowitz", "Neil C.", ""], ["Graepel", "Thore", ""], ["Botvinick", "Matthew", ""], ["Battaglia", "Peter W.", ""]]}, {"id": "1809.11084", "submitter": "Saravanan Thirumuruganathan", "authors": "Saravanan Thirumuruganathan, Shameem A Puthiya Parambath, Mourad\n  Ouzzani, Nan Tang, Shafiq Joty", "title": "Reuse and Adaptation for Entity Resolution through Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity resolution (ER) is one of the fundamental problems in data\nintegration, where machine learning (ML) based classifiers often provide the\nstate-of-the-art results. Considerable human effort goes into feature\nengineering and training data creation. In this paper, we investigate a new\nproblem: Given a dataset D_T for ER with limited or no training data, is it\npossible to train a good ML classifier on D_T by reusing and adapting the\ntraining data of dataset D_S from same or related domain? Our major\ncontributions include (1) a distributed representation based approach to encode\neach tuple from diverse datasets into a standard feature space; (2)\nidentification of common scenarios where the reuse of training data can be\nbeneficial; and (3) five algorithms for handling each of the aforementioned\nscenarios. We have performed comprehensive experiments on 12 datasets from 5\ndifferent domains (publications, movies, songs, restaurants, and books). Our\nexperiments show that our algorithms provide significant benefits such as\nproviding superior performance for a fixed training data size.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:26:17 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Thirumuruganathan", "Saravanan", ""], ["Parambath", "Shameem A Puthiya", ""], ["Ouzzani", "Mourad", ""], ["Tang", "Nan", ""], ["Joty", "Shafiq", ""]]}, {"id": "1809.11086", "submitter": "Arash Ardakani", "authors": "Arash Ardakani, Zhengyun Ji, Sean C. Smithson, Brett H. Meyer, Warren\n  J. Gross", "title": "Learning Recurrent Binary/Ternary Weights", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have shown excellent performance in\nprocessing sequence data. However, they are both complex and memory intensive\ndue to their recursive nature. These limitations make RNNs difficult to embed\non mobile devices requiring real-time processes with limited hardware\nresources. To address the above issues, we introduce a method that can learn\nbinary and ternary weights during the training phase to facilitate hardware\nimplementations of RNNs. As a result, using this approach replaces all\nmultiply-accumulate operations by simple accumulations, bringing significant\nbenefits to custom hardware in terms of silicon area and power consumption. On\nthe software side, we evaluate the performance (in terms of accuracy) of our\nmethod using long short-term memories (LSTMs) on various sequential models\nincluding sequence classification and language modeling. We demonstrate that\nour method achieves competitive results on the aforementioned tasks while using\nbinary/ternary weights during the runtime. On the hardware side, we present\ncustom hardware for accelerating the recurrent computations of LSTMs with\nbinary/ternary weights. Ultimately, we show that LSTMs with binary/ternary\nweights can achieve up to 12x memory saving and 10x inference speedup compared\nto the full-precision implementation on an ASIC platform.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:27:29 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 19:14:18 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Ardakani", "Arash", ""], ["Ji", "Zhengyun", ""], ["Smithson", "Sean C.", ""], ["Meyer", "Brett H.", ""], ["Gross", "Warren J.", ""]]}, {"id": "1809.11087", "submitter": "T.S. Jayram", "authors": "T.S. Jayram and Younes Bouhadjar and Ryan L. McAvoy and Tomasz Kornuta\n  and Alexis Asseman and Kamil Rocki and Ahmet S. Ozcan", "title": "Learning to Remember, Forget and Ignore using Attention Control in\n  Memory", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical neural networks with external memory do not effectively separate\ncapacity for episodic and working memory as is required for reasoning in\nhumans. Applying knowledge gained from psychological studies, we designed a new\nmodel called Differentiable Working Memory (DWM) in order to specifically\nemulate human working memory. As it shows the same functional characteristics\nas working memory, it robustly learns psychology inspired tasks and converges\nfaster than comparable state-of-the-art models. Moreover, the DWM model\nsuccessfully generalizes to sequences two orders of magnitude longer than the\nones used in training. Our in-depth analysis shows that the behavior of DWM is\ninterpretable and that it learns to have fine control over memory, allowing it\nto retain, ignore or forget information based on its relevance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:30:54 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Jayram", "T. S.", ""], ["Bouhadjar", "Younes", ""], ["McAvoy", "Ryan L.", ""], ["Kornuta", "Tomasz", ""], ["Asseman", "Alexis", ""], ["Rocki", "Kamil", ""], ["Ozcan", "Ahmet S.", ""]]}, {"id": "1809.11092", "submitter": "Stefan Klus", "authors": "Stefan Klus, Andreas Bittracher, Ingmar Schuster, Christof Sch\\\"utte", "title": "A kernel-based approach to molecular conformation analysis", "comments": null, "journal-ref": "Journal of Chemical Physics 149, 244109, 2018", "doi": "10.1063/1.5063533", "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel machine learning approach to understanding conformation\ndynamics of biomolecules. The approach combines kernel-based techniques that\nare popular in the machine learning community with transfer operator theory for\nanalyzing dynamical systems in order to identify conformation dynamics based on\nmolecular dynamics simulation data. We show that many of the prominent methods\nlike Markov State Models, EDMD, and TICA can be regarded as special cases of\nthis approach and that new efficient algorithms can be constructed based on\nthis derivation. The results of these new powerful methods will be illustrated\nwith several examples, in particular the alanine dipeptide and the protein\nNTL9.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:36:11 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 14:35:26 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Klus", "Stefan", ""], ["Bittracher", "Andreas", ""], ["Schuster", "Ingmar", ""], ["Sch\u00fctte", "Christof", ""]]}, {"id": "1809.11096", "submitter": "Andrew Brock", "authors": "Andrew Brock, Jeff Donahue, Karen Simonyan", "title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent progress in generative image modeling, successfully generating\nhigh-resolution, diverse samples from complex datasets such as ImageNet remains\nan elusive goal. To this end, we train Generative Adversarial Networks at the\nlargest scale yet attempted, and study the instabilities specific to such\nscale. We find that applying orthogonal regularization to the generator renders\nit amenable to a simple \"truncation trick,\" allowing fine control over the\ntrade-off between sample fidelity and variety by reducing the variance of the\nGenerator's input. Our modifications lead to models which set the new state of\nthe art in class-conditional image synthesis. When trained on ImageNet at\n128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of\n166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previous\nbest IS of 52.52 and FID of 18.6.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:38:49 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 21:32:06 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Brock", "Andrew", ""], ["Donahue", "Jeff", ""], ["Simonyan", "Karen", ""]]}, {"id": "1809.11115", "submitter": "Thomas Bonald", "authors": "Thomas Bonald, Alexandre Hollocou, Marc Lelarge", "title": "Weighted Spectral Embedding of Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel spectral embedding of graphs that incorporates weights\nassigned to the nodes, quantifying their relative importance. This spectral\nembedding is based on the first eigenvectors of some properly normalized\nversion of the Laplacian. We prove that these eigenvectors correspond to the\nconfigurations of lowest energy of an equivalent physical system, either\nmechanical or electrical, in which the weight of each node can be interpreted\nas its mass or its capacitance, respectively. Experiments on a real dataset\nillustrate the impact of weighting on the embedding.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 16:05:03 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 15:15:11 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Bonald", "Thomas", ""], ["Hollocou", "Alexandre", ""], ["Lelarge", "Marc", ""]]}, {"id": "1809.11142", "submitter": "Chao Ma", "authors": "Chao Ma, Sebastian Tschiatschek, Konstantina Palla, Jos\\'e Miguel\n  Hern\\'andez-Lobato, Sebastian Nowozin, Cheng Zhang", "title": "EDDI: Efficient Dynamic Discovery of High-Value Information with Partial\n  VAE", "comments": "icml 2019 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-life decision-making situations allow further relevant information\nto be acquired at a specific cost, for example, in assessing the health status\nof a patient we may decide to take additional measurements such as diagnostic\ntests or imaging scans before making a final assessment. Acquiring more\nrelevant information enables better decision making, but may be costly. How can\nwe trade off the desire to make good decisions by acquiring further information\nwith the cost of performing that acquisition? To this end, we propose a\nprincipled framework, named EDDI (Efficient Dynamic Discovery of high-value\nInformation), based on the theory of Bayesian experimental design. In EDDI, we\npropose a novel partial variational autoencoder (Partial VAE) to predict\nmissing data entries problematically given any subset of the observed ones, and\ncombine it with an acquisition function that maximizes expected information\ngain on a set of target variables. We show cost reduction at the same decision\nquality and improved decision quality at the same cost in multiple machine\nlearning benchmarks and two real-world health-care applications.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 16:55:26 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 21:29:10 GMT"}, {"version": "v3", "created": "Fri, 12 Oct 2018 13:28:18 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 21:49:25 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ma", "Chao", ""], ["Tschiatschek", "Sebastian", ""], ["Palla", "Konstantina", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Nowozin", "Sebastian", ""], ["Zhang", "Cheng", ""]]}, {"id": "1809.11160", "submitter": "Tom Hanika", "authors": "Maximilian Felde and Tom Hanika", "title": "Formal Context Generation using Dirichlet Distributions", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": "10.1007/978-3-030-23182-8_5", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest an improved way to randomly generate formal contexts based on\nDirichlet distributions. For this purpose we investigate the predominant way to\ngenerate formal contexts, a coin-tossing model, recapitulate some of its\nshortcomings and examine its stochastic model. Building up on this we propose\nour Dirichlet model and develop an algorithm employing this idea. By comparing\nour generation model to a coin-tossing model we show that our approach is a\nsignificant improvement with respect to the variety of contexts generated.\nFinally, we outline a possible application in null model generation for formal\ncontexts.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 17:48:15 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Felde", "Maximilian", ""], ["Hanika", "Tom", ""]]}, {"id": "1809.11165", "submitter": "Geoff Pleiss", "authors": "Jacob R. Gardner, Geoff Pleiss, David Bindel, Kilian Q. Weinberger,\n  Andrew Gordon Wilson", "title": "GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU\n  Acceleration", "comments": "NeurIPS 2018. Most recent version includes additional details on\n  preconditioned BBMM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite advances in scalable models, the inference tools used for Gaussian\nprocesses (GPs) have yet to fully capitalize on developments in computing\nhardware. We present an efficient and general approach to GP inference based on\nBlackbox Matrix-Matrix multiplication (BBMM). BBMM inference uses a modified\nbatched version of the conjugate gradients algorithm to derive all terms for\ntraining and inference in a single call. BBMM reduces the asymptotic complexity\nof exact GP inference from $O(n^3)$ to $O(n^2)$. Adapting this algorithm to\nscalable approximations and complex GP models simply requires a routine for\nefficient matrix-matrix multiplication with the kernel and its derivative. In\naddition, BBMM uses a specialized preconditioner to substantially speed up\nconvergence. In experiments we show that BBMM effectively uses GPU hardware to\ndramatically accelerate both exact GP inference and scalable approximations.\nAdditionally, we provide GPyTorch, a software platform for scalable GP\ninference via BBMM, built on PyTorch.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 17:55:16 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 17:52:57 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 17:30:59 GMT"}, {"version": "v4", "created": "Wed, 28 Nov 2018 13:32:35 GMT"}, {"version": "v5", "created": "Fri, 11 Jan 2019 03:20:19 GMT"}, {"version": "v6", "created": "Tue, 29 Jun 2021 18:58:41 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Gardner", "Jacob R.", ""], ["Pleiss", "Geoff", ""], ["Bindel", "David", ""], ["Weinberger", "Kilian Q.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1809.11169", "submitter": "Yunzhu Li", "authors": "Yunzhu Li, Jiajun Wu, Jun-Yan Zhu, Joshua B. Tenenbaum, Antonio\n  Torralba, Russ Tedrake", "title": "Propagation Networks for Model-Based Control Under Partial Observation", "comments": "Accepted to ICRA 2019. Project Page: http://propnet.csail.mit.edu\n  Video: https://youtu.be/ZAxHXegkz48", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasing interest in learning dynamics simulators for\nmodel-based control. Compared with off-the-shelf physics engines, a learnable\nsimulator can quickly adapt to unseen objects, scenes, and tasks. However,\nexisting models like interaction networks only work for fully observable\nsystems; they also only consider pairwise interactions within a single time\nstep, both restricting their use in practical systems. We introduce Propagation\nNetworks (PropNet), a differentiable, learnable dynamics model that handles\npartially observable scenarios and enables instantaneous propagation of signals\nbeyond pairwise interactions. Experiments show that our propagation networks\nnot only outperform current learnable physics engines in forward simulation,\nbut also achieve superior performance on various control tasks. Compared with\nexisting model-free deep reinforcement learning algorithms, model-based control\nwith propagation networks is more accurate, efficient, and generalizable to\nnew, partially observable scenes and tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 17:58:10 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 02:20:25 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Li", "Yunzhu", ""], ["Wu", "Jiajun", ""], ["Zhu", "Jun-Yan", ""], ["Tenenbaum", "Joshua B.", ""], ["Torralba", "Antonio", ""], ["Tedrake", "Russ", ""]]}]