[{"id": "1105.0382", "submitter": "Raphael Pelossof", "authors": "Raphael Pelossof and Zhiliang Ying", "title": "Rapid Learning with Stochastic Focus of Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to stop the evaluation of a decision making process when\nthe result of the full evaluation is obvious. This trait is highly desirable\nfor online margin-based machine learning algorithms where a classifier\ntraditionally evaluates all the features for every example. We observe that\nsome examples are easier to classify than others, a phenomenon which is\ncharacterized by the event when most of the features agree on the class of an\nexample. By stopping the feature evaluation when encountering an easy to\nclassify example, the learning algorithm can achieve substantial gains in\ncomputation. Our method provides a natural attention mechanism for learning\nalgorithms. By modifying Pegasos, a margin-based online learning algorithm, to\ninclude our attentive method we lower the number of attributes computed from\n$n$ to an average of $O(\\sqrt{n})$ features without loss in prediction\naccuracy. We demonstrate the effectiveness of Attentive Pegasos on MNIST data.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 17:10:49 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Pelossof", "Raphael", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1105.0471", "submitter": "Masayuki Karasuyama", "authors": "Masayuki Karasuyama and Ichiro Takeuchi", "title": "Suboptimal Solution Path Algorithm for Support Vector Machine", "comments": "A shorter version of this paper is submitted to ICML 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a suboptimal solution path algorithm for the Support Vector\nMachine. The solution path algorithm is an effective tool for solving a\nsequence of a parametrized optimization problems in machine learning. The path\nof the solutions provided by this algorithm are very accurate and they satisfy\nthe optimality conditions more strictly than other SVM optimization algorithms.\nIn many machine learning application, however, this strict optimality is often\nunnecessary, and it adversely affects the computational efficiency. Our\nalgorithm can generate the path of suboptimal solutions within an arbitrary\nuser-specified tolerance level. It allows us to control the trade-off between\nthe accuracy of the solution and the computational cost. Moreover, We also show\nthat our suboptimal solutions can be interpreted as the solution of a\n\\emph{perturbed optimization problem} from the original one. We provide some\ntheoretical analyses of our algorithm based on this novel interpretation. The\nexperimental results also demonstrate the effectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 03:14:14 GMT"}], "update_date": "2011-05-04", "authors_parsed": [["Karasuyama", "Masayuki", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "1105.0540", "submitter": "Samory Kpotufe", "authors": "Samory Kpotufe, Ulrike von Luxburg", "title": "Pruning nearest neighbor cluster trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbor (k-NN) graphs are widely used in machine learning and data\nmining applications, and our aim is to better understand what they reveal about\nthe cluster structure of the unknown underlying distribution of points.\nMoreover, is it possible to identify spurious structures that might arise due\nto sampling variability?\n  Our first contribution is a statistical analysis that reveals how certain\nsubgraphs of a k-NN graph form a consistent estimator of the cluster tree of\nthe underlying distribution of points. Our second and perhaps most important\ncontribution is the following finite sample guarantee. We carefully work out\nthe tradeoff between aggressive and conservative pruning and are able to\nguarantee the removal of all spurious cluster structures at all levels of the\ntree while at the same time guaranteeing the recovery of salient clusters. This\nis the first such finite sample result in the context of clustering.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 10:34:25 GMT"}, {"version": "v2", "created": "Thu, 5 May 2011 14:13:49 GMT"}], "update_date": "2011-05-06", "authors_parsed": [["Kpotufe", "Samory", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1105.0857", "submitter": "Ruslan Salakhutdinov", "authors": "Dean Foster and Sham Kakade and Ruslan Salakhutdinov", "title": "Domain Adaptation: Overfitting and Small Sample Statistics", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the prevalent problem when a test distribution differs from the\ntraining distribution. We consider a setting where our training set consists of\na small number of sample domains, but where we have many samples in each\ndomain. Our goal is to generalize to a new domain. For example, we may want to\nlearn a similarity function using only certain classes of objects, but we\ndesire that this similarity function be applicable to object classes not\npresent in our training sample (e.g. we might seek to learn that \"dogs are\nsimilar to dogs\" even though images of dogs were absent from our training set).\nOur theoretical analysis shows that we can select many more features than\ndomains while avoiding overfitting by utilizing data-dependent variance\nproperties. We present a greedy feature selection algorithm based on using\nT-statistics. Our experiments validate this theory showing that our T-statistic\nbased greedy feature selection is more robust at avoiding overfitting than the\nclassical greedy procedure.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2011 15:50:44 GMT"}], "update_date": "2011-05-05", "authors_parsed": [["Foster", "Dean", ""], ["Kakade", "Sham", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1105.0972", "submitter": "Zhixiang Eddie Xu", "authors": "Zhixiang Eddie Xu, Kilian Q. Weinberger, Fei Sha", "title": "Rapid Feature Learning with Stacked Linear Denoisers", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate unsupervised pre-training of deep architectures as feature\ngenerators for \"shallow\" classifiers. Stacked Denoising Autoencoders (SdA),\nwhen used as feature pre-processing tools for SVM classification, can lead to\nsignificant improvements in accuracy - however, at the price of a substantial\nincrease in computational cost. In this paper we create a simple algorithm\nwhich mimics the layer by layer training of SdAs. However, in contrast to SdAs,\nour algorithm requires no training through gradient descent as the parameters\ncan be computed in closed-form. It can be implemented in less than 20 lines of\nMATLABTMand reduces the computation time from several hours to mere seconds. We\nshow that our feature transformation reliably improves the results of SVM\nclassification significantly on all our data sets - often outperforming SdAs\nand even deep neural networks in three out of four deep learning benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 04:02:35 GMT"}], "update_date": "2012-08-17", "authors_parsed": [["Xu", "Zhixiang Eddie", ""], ["Weinberger", "Kilian Q.", ""], ["Sha", "Fei", ""]]}, {"id": "1105.1033", "submitter": "Omer Tamuz", "authors": "Omer Tamuz, Ce Liu, Serge Belongie, Ohad Shamir, Adam Tauman Kalai", "title": "Adaptively Learning the Crowd Kernel", "comments": "9 pages, 7 figures, Accepted to the 28th International Conference on\n  Machine Learning (ICML), 2011", "journal-ref": "The 28th International Conference on Machine Learning, 2011", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an algorithm that, given n objects, learns a similarity matrix\nover all n^2 pairs, from crowdsourced data alone. The algorithm samples\nresponses to adaptively chosen triplet-based relative-similarity queries. Each\nquery has the form \"is object 'a' more similar to 'b' or to 'c'?\" and is chosen\nto be maximally informative given the preceding responses. The output is an\nembedding of the objects into Euclidean space (like MDS); we refer to this as\nthe \"crowd kernel.\" SVMs reveal that the crowd kernel captures prominent and\nsubtle features across a number of domains, such as \"is striped\" among neckties\nand \"vowel vs. consonant\" among letters.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 11:03:03 GMT"}, {"version": "v2", "created": "Sat, 25 Jun 2011 21:54:08 GMT"}], "update_date": "2013-07-19", "authors_parsed": [["Tamuz", "Omer", ""], ["Liu", "Ce", ""], ["Belongie", "Serge", ""], ["Shamir", "Ohad", ""], ["Kalai", "Adam Tauman", ""]]}, {"id": "1105.1178", "submitter": "Daniel Tarlow", "authors": "Daniel Tarlow, Inmar E. Givoni, Richard S. Zemel, Brendan J. Frey", "title": "Interpreting Graph Cuts as a Max-Product Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The maximum a posteriori (MAP) configuration of binary variable models with\nsubmodular graph-structured energy functions can be found efficiently and\nexactly by graph cuts. Max-product belief propagation (MP) has been shown to be\nsuboptimal on this class of energy functions by a canonical counterexample\nwhere MP converges to a suboptimal fixed point (Kulesza & Pereira, 2008).\n  In this work, we show that under a particular scheduling and damping scheme,\nMP is equivalent to graph cuts, and thus optimal. We explain the apparent\ncontradiction by showing that with proper scheduling and damping, MP always\nconverges to an optimal fixed point. Thus, the canonical counterexample only\nshows the suboptimality of MP with a particular suboptimal choice of schedule\nand damping. With proper choices, MP is optimal.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 21:24:37 GMT"}], "update_date": "2012-02-19", "authors_parsed": [["Tarlow", "Daniel", ""], ["Givoni", "Inmar E.", ""], ["Zemel", "Richard S.", ""], ["Frey", "Brendan J.", ""]]}, {"id": "1105.1951", "submitter": "Wolfgang Konen K", "authors": "Wolfgang Konen", "title": "Self-configuration from a Machine-Learning Perspective", "comments": "12 pages, 5 figures, Dagstuhl seminar 11181 \"Organic Computing -\n  Design of Self-Organizing Systems\", May 2011", "journal-ref": null, "doi": null, "report-no": "DPA-11181", "categories": "nlin.AO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of machine learning is to provide solutions which are trained by\ndata or by experience coming from the environment. Many training algorithms\nexist and some brilliant successes were achieved. But even in structured\nenvironments for machine learning (e.g. data mining or board games), most\napplications beyond the level of toy problems need careful hand-tuning or human\ningenuity (i.e. detection of interesting patterns) or both. We discuss several\naspects how self-configuration can help to alleviate these problems. One aspect\nis the self-configuration by tuning of algorithms, where recent advances have\nbeen made in the area of SPO (Sequen- tial Parameter Optimization). Another\naspect is the self-configuration by pattern detection or feature construction.\nForming multiple features (e.g. random boolean functions) and using algorithms\n(e.g. random forests) which easily digest many fea- tures can largely increase\nlearning speed. However, a full-fledged theory of feature construction is not\nyet available and forms a current barrier in machine learning. We discuss\nseveral ideas for systematic inclusion of feature construction. This may lead\nto partly self-configuring machine learning solutions which show robustness,\nflexibility, and fast learning in potentially changing environments.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 14:01:41 GMT"}, {"version": "v2", "created": "Mon, 5 Sep 2011 11:54:46 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Konen", "Wolfgang", ""]]}, {"id": "1105.2054", "submitter": "Alexander Grubb", "authors": "Alexander Grubb and J. Andrew Bagnell", "title": "Generalized Boosting Algorithms for Convex Optimization", "comments": "Extended version of paper presented at the International Conference\n  on Machine Learning, 2011. 9 pages + appendix with proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a popular way to derive powerful learners from simpler hypothesis\nclasses. Following previous work (Mason et al., 1999; Friedman, 2000) on\ngeneral boosting frameworks, we analyze gradient-based descent algorithms for\nboosting with respect to any convex objective and introduce a new measure of\nweak learner performance into this setting which generalizes existing work. We\npresent the weak to strong learning guarantees for the existing gradient\nboosting work for strongly-smooth, strongly-convex objectives under this new\nmeasure of performance, and also demonstrate that this work fails for\nnon-smooth objectives. To address this issue, we present new algorithms which\nextend this boosting approach to arbitrary convex loss functions and give\ncorresponding weak to strong convergence results. In addition, we demonstrate\nexperimental results that support our analysis and demonstrate the need for the\nnew algorithms we present.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 21:02:58 GMT"}, {"version": "v2", "created": "Tue, 14 Feb 2012 06:33:18 GMT"}], "update_date": "2012-02-15", "authors_parsed": [["Grubb", "Alexander", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1105.2176", "submitter": "Tansu Alpcan", "authors": "Tansu Alpcan", "title": "A Framework for Optimization under Limited Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real world problems, optimization decisions have to be made with\nlimited information. The decision maker may have no a priori or posteriori data\nabout the often nonconvex objective function except from on a limited number of\npoints that are obtained over time through costly observations. This paper\npresents an optimization framework that takes into account the information\ncollection (observation), estimation (regression), and optimization\n(maximization) aspects in a holistic and structured manner. Explicitly\nquantifying the information acquired at each optimization step using the\nentropy measure from information theory, the (nonconvex) objective function to\nbe optimized (maximized) is modeled and estimated by adopting a Bayesian\napproach and using Gaussian processes as a state-of-the-art regression method.\nThe resulting iterative scheme allows the decision maker to solve the problem\nby expressing preferences for each aspect quantitatively and concurrently.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2011 13:03:13 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Alpcan", "Tansu", ""]]}, {"id": "1105.2211", "submitter": "Tansu Alpcan", "authors": "Tansu Alpcan", "title": "Dual Control with Active Learning using Gaussian Process Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real world problems, control decisions have to be made with limited\ninformation. The controller may have no a priori (or even posteriori) data on\nthe nonlinear system, except from a limited number of points that are obtained\nover time. This is either due to high cost of observation or the highly\nnon-stationary nature of the system. The resulting conflict between information\ncollection (identification, exploration) and control (optimization,\nexploitation) necessitates an active learning approach for iteratively\nselecting the control actions which concurrently provide the data points for\nsystem identification. This paper presents a dual control approach where the\ninformation acquired at each control step is quantified using the entropy\nmeasure from information theory and serves as the training input to a\nstate-of-the-art Gaussian process regression (Bayesian learning) method. The\nexplicit quantification of the information obtained from each data point allows\nfor iterative optimization of both identification and control objectives. The\napproach developed is illustrated with two examples: control of logistic map as\na chaotic system and position control of a cart with inverted pendulum.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2011 14:45:25 GMT"}], "update_date": "2011-05-12", "authors_parsed": [["Alpcan", "Tansu", ""]]}, {"id": "1105.2274", "submitter": "Hua Ouyang", "authors": "Hua Ouyang, Alexander Gray", "title": "Data-Distributed Weighted Majority and Online Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the question of the extent to which online\nlearning can benefit from distributed computing. We focus on the setting in\nwhich $N$ agents online-learn cooperatively, where each agent only has access\nto its own data. We propose a generic data-distributed online learning\nmeta-algorithm. We then introduce the Distributed Weighted Majority and\nDistributed Online Mirror Descent algorithms, as special cases. We show, using\nboth theoretical analysis and experiments, that compared to a single agent:\ngiven the same computation time, these distributed algorithms achieve smaller\ngeneralization errors; and given the same generalization errors, they can be\n$N$ times faster.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2011 18:59:13 GMT"}], "update_date": "2019-08-17", "authors_parsed": [["Ouyang", "Hua", ""], ["Gray", "Alexander", ""]]}, {"id": "1105.2416", "submitter": "Yevgeny Seldin", "authors": "Yevgeny Seldin and Fran\\c{c}ois Laviolette and John Shawe-Taylor and\n  Jan Peters and Peter Auer", "title": "PAC-Bayesian Analysis of Martingales and Multiarmed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two alternative ways to apply PAC-Bayesian analysis to sequences\nof dependent random variables. The first is based on a new lemma that enables\nto bound expectations of convex functions of certain dependent random variables\nby expectations of the same functions of independent Bernoulli random\nvariables. This lemma provides an alternative tool to Hoeffding-Azuma\ninequality to bound concentration of martingale values. Our second approach is\nbased on integration of Hoeffding-Azuma inequality with PAC-Bayesian analysis.\nWe also introduce a way to apply PAC-Bayesian analysis in situation of limited\nfeedback. We combine the new tools to derive PAC-Bayesian generalization and\nregret bounds for the multiarmed bandit problem. Although our regret bound is\nnot yet as tight as state-of-the-art regret bounds based on other\nwell-established techniques, our results significantly expand the range of\npotential applications of PAC-Bayesian analysis and introduce a new analysis\ntool to reinforcement learning and many other fields, where martingales and\nlimited feedback are encountered.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 10:40:19 GMT"}, {"version": "v2", "created": "Thu, 19 May 2011 17:04:35 GMT"}], "update_date": "2011-05-20", "authors_parsed": [["Seldin", "Yevgeny", ""], ["Laviolette", "Fran\u00e7ois", ""], ["Shawe-Taylor", "John", ""], ["Peters", "Jan", ""], ["Auer", "Peter", ""]]}, {"id": "1105.2550", "submitter": "Dotan Di Castro", "authors": "Dotan Di Castro, Claudio Gentile, and Shie Mannor", "title": "A Maximal Large Deviation Inequality for Sub-Gaussian Variables", "comments": "This paper has been withdrawn by the authors due to a crucial error\n  in the last sentence of the proof of Theorem 1: \"we can take the infimum of\n  the r.h.s. over s, which yields (1).\" This statement is only true if a single\n  value of s yields the supremum of (\\epsilon_i s - \\rho_i(s)) simultaneously\n  for every i", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note we prove a maximal concentration lemma for sub-Gaussian\nrandom variables stating that for independent sub-Gaussian random variables we\nhave \\[P<(\\max_{1\\le i\\le N}S_{i}>\\epsilon>)\n\\le\\exp<(-\\frac{1}{N^2}\\sum_{i=1}^{N}\\frac{\\epsilon^{2}}{2\\sigma_{i}^{2}}>), \\]\nwhere $S_i$ is the sum of $i$ zero mean independent sub-Gaussian random\nvariables and $\\sigma_i$ is the variance of the $i$th random variable.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 19:29:21 GMT"}, {"version": "v2", "created": "Mon, 16 May 2011 19:03:34 GMT"}, {"version": "v3", "created": "Mon, 25 Jul 2011 13:01:20 GMT"}], "update_date": "2011-07-26", "authors_parsed": [["Di Castro", "Dotan", ""], ["Gentile", "Claudio", ""], ["Mannor", "Shie", ""]]}, {"id": "1105.2651", "submitter": "Nathan Keller", "authors": "Nathan Keller, Elchanan Mossel, and Tomer Schlank", "title": "A Note on the Entropy/Influence Conjecture", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The entropy/influence conjecture, raised by Friedgut and Kalai in 1996, seeks\nto relate two different measures of concentration of the Fourier coefficients\nof a Boolean function. Roughly saying, it claims that if the Fourier spectrum\nis \"smeared out\", then the Fourier coefficients are concentrated on \"high\"\nlevels. In this note we generalize the conjecture to biased product measures on\nthe discrete cube, and prove a variant of the conjecture for functions with an\nextremely low Fourier weight on the \"high\" levels.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 08:32:09 GMT"}], "update_date": "2011-05-16", "authors_parsed": [["Keller", "Nathan", ""], ["Mossel", "Elchanan", ""], ["Schlank", "Tomer", ""]]}, {"id": "1105.2868", "submitter": "Vincent Etter", "authors": "Etter Vincent", "title": "Semantic Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first present our work in machine translation, during which we used\naligned sentences to train a neural network to embed n-grams of different\nlanguages into an $d$-dimensional space, such that n-grams that are the\ntranslation of each other are close with respect to some metric. Good n-grams\nto n-grams translation results were achieved, but full sentences translation is\nstill problematic. We realized that learning semantics of sentences and\ndocuments was the key for solving a lot of natural language processing\nproblems, and thus moved to the second part of our work: sentence compression.\nWe introduce a flexible neural network architecture for learning embeddings of\nwords and sentences that extract their semantics, propose an efficient\nimplementation in the Torch framework and present embedding results comparable\nto the ones obtained with classical neural language models, while being more\npowerful.\n", "versions": [{"version": "v1", "created": "Sat, 14 May 2011 07:13:25 GMT"}], "update_date": "2011-05-17", "authors_parsed": [["Vincent", "Etter", ""]]}, {"id": "1105.2943", "submitter": "Rui Wang", "authors": "Rui Wang, Ke Tang", "title": "Feature Selection for MAUC-Oriented Classification Systems", "comments": "A journal length paper", "journal-ref": null, "doi": "10.1016/j.neucom.2012.01.013", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is an important pre-processing step for many pattern\nclassification tasks. Traditionally, feature selection methods are designed to\nobtain a feature subset that can lead to high classification accuracy. However,\nclassification accuracy has recently been shown to be an inappropriate\nperformance metric of classification systems in many cases. Instead, the Area\nUnder the receiver operating characteristic Curve (AUC) and its multi-class\nextension, MAUC, have been proved to be better alternatives. Hence, the target\nof classification system design is gradually shifting from seeking a system\nwith the maximum classification accuracy to obtaining a system with the maximum\nAUC/MAUC. Previous investigations have shown that traditional feature selection\nmethods need to be modified to cope with this new objective. These methods most\noften are restricted to binary classification problems only. In this study, a\nfilter feature selection method, namely MAUC Decomposition based Feature\nSelection (MDFS), is proposed for multi-class classification problems. To the\nbest of our knowledge, MDFS is the first method specifically designed to select\nfeatures for building classification systems with maximum MAUC. Extensive\nempirical results demonstrate the advantage of MDFS over several compared\nfeature selection methods.\n", "versions": [{"version": "v1", "created": "Sun, 15 May 2011 12:35:56 GMT"}], "update_date": "2012-05-03", "authors_parsed": [["Wang", "Rui", ""], ["Tang", "Ke", ""]]}, {"id": "1105.3259", "submitter": "Frank Nielsen", "authors": "Frank Nielsen and Richard Nock", "title": "On R\\'enyi and Tsallis entropies and divergences for exponential\n  families", "comments": "7 pages", "journal-ref": "Journal of Physics A: Mathematical and Theoretical, Volume 45\n  Number 3, 2012", "doi": "10.1088/1751-8113/45/3/032003", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many common probability distributions in statistics like the Gaussian,\nmultinomial, Beta or Gamma distributions can be studied under the unified\nframework of exponential families. In this paper, we prove that both R\\'enyi\nand Tsallis divergences of distributions belonging to the same exponential\nfamily admit a generic closed form expression. Furthermore, we show that\nR\\'enyi and Tsallis entropies can also be calculated in closed-form for\nsub-families including the Gaussian or exponential distributions, among others.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2011 02:05:32 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Nielsen", "Frank", ""], ["Nock", "Richard", ""]]}, {"id": "1105.3931", "submitter": "Xueyuan Zhou", "authors": "Xueyuan Zhou and Mikhail Belkin", "title": "Behavior of Graph Laplacians on Manifolds with Boundary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In manifold learning, algorithms based on graph Laplacians constructed from\ndata have received considerable attention both in practical applications and\ntheoretical analysis. In particular, the convergence of graph Laplacians\nobtained from sampled data to certain continuous operators has become an active\nresearch topic recently. Most of the existing work has been done under the\nassumption that the data is sampled from a manifold without boundary or that\nthe functions of interests are evaluated at a point away from the boundary.\nHowever, the question of boundary behavior is of considerable practical and\ntheoretical interest. In this paper we provide an analysis of the behavior of\ngraph Laplacians at a point near or on the boundary, discuss their convergence\nrates and their implications and provide some numerical results. It turns out\nthat while points near the boundary occupy only a small part of the total\nvolume of a manifold, the behavior of graph Laplacian there has different\nscaling properties from its behavior elsewhere on the manifold, with global\neffects on the whole manifold, an observation with potentially important\nimplications for the general problem of learning on manifolds.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2011 16:54:39 GMT"}], "update_date": "2011-05-23", "authors_parsed": [["Zhou", "Xueyuan", ""], ["Belkin", "Mikhail", ""]]}, {"id": "1105.4042", "submitter": "Sebastien Gerchinovitz", "authors": "S\\'ebastien Gerchinovitz (DMA, CLASSIC), Jia Yuan Yu", "title": "Adaptive and optimal online linear regression on $\\ell^1$-balls", "comments": null, "journal-ref": "Theoretical Computer Science, Elsevier, 2014, 519, pp.4-28", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online linear regression on individual sequences.\nThe goal in this paper is for the forecaster to output sequential predictions\nwhich are, after $T$ time rounds, almost as good as the ones output by the best\nlinear predictor in a given $\\ell^1$-ball in $\\\\R^d$. We consider both the\ncases where the dimension~$d$ is small and large relative to the time horizon\n$T$. We first present regret bounds with optimal dependencies on $d$, $T$, and\non the sizes $U$, $X$ and $Y$ of the $\\ell^1$-ball, the input data and the\nobservations. The minimax regret is shown to exhibit a regime transition around\nthe point $d = \\sqrt{T} U X / (2 Y)$. Furthermore, we present efficient\nalgorithms that are adaptive, \\ie, that do not require the knowledge of $U$,\n$X$, $Y$, and $T$, but still achieve nearly optimal regret bounds.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2011 09:14:03 GMT"}, {"version": "v2", "created": "Wed, 25 May 2011 07:54:09 GMT"}, {"version": "v3", "created": "Mon, 23 Jan 2012 19:32:08 GMT"}, {"version": "v4", "created": "Wed, 16 Jan 2019 13:01:19 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Gerchinovitz", "S\u00e9bastien", "", "DMA, CLASSIC"], ["Yu", "Jia Yuan", ""]]}, {"id": "1105.4272", "submitter": "Vladimir Vyugin", "authors": "Vladimir Trunov and Vladimir V'yugin", "title": "Calibration with Changing Checking Rules and Its Application to\n  Short-Term Trading", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a natural learning process in which a financial trader without a\nrisk receives a gain in case when Stock Market is inefficient. In this process,\nthe trader rationally choose his gambles using a prediction made by a\nrandomized calibrated algorithm. Our strategy is based on Dawid's notion of\ncalibration with more general changing checking rules and on some modification\nof Kakade and Foster's randomized algorithm for computing calibrated forecasts.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2011 17:28:12 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Trunov", "Vladimir", ""], ["V'yugin", "Vladimir", ""]]}, {"id": "1105.4385", "submitter": "Ping Li", "authors": "Ping Li and Joshua Moore and Christian Konig", "title": "b-Bit Minwise Hashing for Large-Scale Linear SVM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to (seamlessly) integrate b-bit minwise hashing\nwith linear SVM to substantially improve the training (and testing) efficiency\nusing much smaller memory, with essentially no loss of accuracy. Theoretically,\nwe prove that the resemblance matrix, the minwise hashing matrix, and the b-bit\nminwise hashing matrix are all positive definite matrices (kernels).\nInterestingly, our proof for the positive definiteness of the b-bit minwise\nhashing kernel naturally suggests a simple strategy to integrate b-bit hashing\nwith linear SVM. Our technique is particularly useful when the data can not fit\nin memory, which is an increasingly critical issue in large-scale machine\nlearning. Our preliminary experimental results on a publicly available webspam\ndataset (350K samples and 16 million dimensions) verified the effectiveness of\nour algorithm. For example, the training time was reduced to merely a few\nseconds. In addition, our technique can be easily extended to many other linear\nand nonlinear machine learning applications such as logistic regression.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 01:56:24 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Li", "Ping", ""], ["Moore", "Joshua", ""], ["Konig", "Christian", ""]]}, {"id": "1105.4585", "submitter": "Yevgeny Seldin", "authors": "Yevgeny Seldin, Nicol\\`o Cesa-Bianchi, Fran\\c{c}ois Laviolette, Peter\n  Auer, John Shawe-Taylor, Jan Peters", "title": "PAC-Bayesian Analysis of the Exploration-Exploitation Trade-off", "comments": "On-line Trading of Exploration and Exploitation 2 - ICML-2011\n  workshop. http://explo.cs.ucl.ac.uk/workshop/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a coherent framework for integrative simultaneous analysis of the\nexploration-exploitation and model order selection trade-offs. We improve over\nour preceding results on the same subject (Seldin et al., 2011) by combining\nPAC-Bayesian analysis with Bernstein-type inequality for martingales. Such a\ncombination is also of independent interest for studies of multiple\nsimultaneously evolving martingales.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 19:10:03 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Seldin", "Yevgeny", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""], ["Laviolette", "Fran\u00e7ois", ""], ["Auer", "Peter", ""], ["Shawe-Taylor", "John", ""], ["Peters", "Jan", ""]]}, {"id": "1105.4618", "submitter": "Haoyang (Hubert) Duan", "authors": "Hubert Haoyang Duan", "title": "Bounding the Fat Shattering Dimension of a Composition Function Class\n  Built Using a Continuous Logic Connective", "comments": "Winter 2011 Honours research project done under the supervision of\n  Dr. Vladimir Pestov at the University of Ottawa; 35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We begin this report by describing the Probably Approximately Correct (PAC)\nmodel for learning a concept class, consisting of subsets of a domain, and a\nfunction class, consisting of functions from the domain to the unit interval.\nTwo combinatorial parameters, the Vapnik-Chervonenkis (VC) dimension and its\ngeneralization, the Fat Shattering dimension of scale e, are explained and a\nfew examples of their calculations are given with proofs. We then explain\nSauer's Lemma, which involves the VC dimension and is used to prove the\nequivalence of a concept class being distribution-free PAC learnable and it\nhaving finite VC dimension.\n  As the main new result of our research, we explore the construction of a new\nfunction class, obtained by forming compositions with a continuous logic\nconnective, a uniformly continuous function from the unit hypercube to the unit\ninterval, from a collection of function classes. Vidyasagar had proved that\nsuch a composition function class has finite Fat Shattering dimension of all\nscales if the classes in the original collection do; however, no estimates of\nthe dimension were known. Using results by Mendelson-Vershynin and Talagrand,\nwe bound the Fat Shattering dimension of scale e of this new function class in\nterms of the Fat Shattering dimensions of the collection's classes.\n  We conclude this report by providing a few open questions and future research\ntopics involving the PAC learning model.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 20:04:16 GMT"}], "update_date": "2011-05-25", "authors_parsed": [["Duan", "Hubert Haoyang", ""]]}, {"id": "1105.4701", "submitter": "Stephen Voinea", "authors": "Tomaso Poggio, Stephen Voinea, Lorenzo Rosasco", "title": "Online Learning, Stability, and Stochastic Gradient Descent", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In batch learning, stability together with existence and uniqueness of the\nsolution corresponds to well-posedness of Empirical Risk Minimization (ERM)\nmethods; recently, it was proved that CV_loo stability is necessary and\nsufficient for generalization and consistency of ERM. In this note, we\nintroduce CV_on stability, which plays a similar note in online learning. We\nshow that stochastic gradient descent (SDG) with the usual hypotheses is CVon\nstable and we then discuss the implications of CV_on stability for convergence\nof SGD.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2011 07:58:30 GMT"}, {"version": "v2", "created": "Wed, 25 May 2011 01:47:15 GMT"}, {"version": "v3", "created": "Thu, 8 Sep 2011 04:14:53 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Poggio", "Tomaso", ""], ["Voinea", "Stephen", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1105.4995", "submitter": "Gilles Stoltz", "authors": "Shie Mannor (EE-Technion), Vianney Perchet (CMLA), Gilles Stoltz (DMA,\n  GREGH, INRIA Paris - Rocquencourt)", "title": "Robust approachability and regret minimization in games with partial\n  monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approachability has become a standard tool in analyzing earning algorithms in\nthe adversarial online learning setup. We develop a variant of approachability\nfor games where there is ambiguity in the obtained reward that belongs to a\nset, rather than being a single vector. Using this variant we tackle the\nproblem of approachability in games with partial monitoring and develop simple\nand efficient algorithms (i.e., with constant per-step complexity) for this\nsetup. We finally consider external regret and internal regret in repeated\ngames with partial monitoring and derive regret-minimizing strategies based on\napproachability theory.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2011 11:19:05 GMT"}, {"version": "v2", "created": "Tue, 30 Aug 2011 06:15:04 GMT"}, {"version": "v3", "created": "Wed, 15 Feb 2012 14:38:47 GMT"}], "update_date": "2012-02-17", "authors_parsed": [["Mannor", "Shie", "", "EE-Technion"], ["Perchet", "Vianney", "", "CMLA"], ["Stoltz", "Gilles", "", "DMA,\n  GREGH, INRIA Paris - Rocquencourt"]]}, {"id": "1105.5196", "submitter": "Jason  Weston", "authors": "Jason Weston, Samy Bengio, Philippe Hamel", "title": "Large-Scale Music Annotation and Retrieval: Learning to Rank in Joint\n  Semantic Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music prediction tasks range from predicting tags given a song or clip of\naudio, predicting the name of the artist, or predicting related songs given a\nsong, clip, artist name or tag. That is, we are interested in every semantic\nrelationship between the different musical concepts in our database. In\nrealistically sized databases, the number of songs is measured in the hundreds\nof thousands or more, and the number of artists in the tens of thousands or\nmore, providing a considerable challenge to standard machine learning\ntechniques. In this work, we propose a method that scales to such datasets\nwhich attempts to capture the semantic similarities between the database items\nby modeling audio, artist names, and tags in a single low-dimensional semantic\nspace. This choice of space is learnt by optimizing the set of prediction tasks\nof interest jointly using multi-task learning. Our method both outperforms\nbaseline methods and, in comparison to them, is faster and consumes less\nmemory. We then demonstrate how our method learns an interpretable model, where\nthe semantic space captures well the similarities of interest.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2011 03:41:47 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Weston", "Jason", ""], ["Bengio", "Samy", ""], ["Hamel", "Philippe", ""]]}, {"id": "1105.5379", "submitter": "Danny Bickson", "authors": "Joseph K. Bradley, Aapo Kyrola, Danny Bickson and Carlos Guestrin", "title": "Parallel Coordinate Descent for L1-Regularized Loss Minimization", "comments": null, "journal-ref": "In the 28th International Conference on Machine Learning, July\n  2011, Washington, USA", "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Shotgun, a parallel coordinate descent algorithm for minimizing\nL1-regularized losses. Though coordinate descent seems inherently sequential,\nwe prove convergence bounds for Shotgun which predict linear speedups, up to a\nproblem-dependent limit. We present a comprehensive empirical study of Shotgun\nfor Lasso and sparse logistic regression. Our theoretical predictions on the\npotential for parallelism closely match behavior on real data. Shotgun\noutperforms other published solvers on a range of large problems, proving to be\none of the most scalable algorithms for L1.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2011 19:19:30 GMT"}], "update_date": "2011-05-27", "authors_parsed": [["Bradley", "Joseph K.", ""], ["Kyrola", "Aapo", ""], ["Bickson", "Danny", ""], ["Guestrin", "Carlos", ""]]}, {"id": "1105.5464", "submitter": "W. W. Cohen", "authors": "W. W. Cohen, R. E. Schapire, Y. Singer", "title": "Learning to Order Things", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 10, pages\n  243-270, 1999", "doi": "10.1613/jair.587", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many applications in which it is desirable to order rather than\nclassify instances. Here we consider the problem of learning how to order\ninstances given feedback in the form of preference judgments, i.e., statements\nto the effect that one instance should be ranked ahead of another. We outline a\ntwo-stage approach in which one first learns by conventional means a binary\npreference function indicating whether it is advisable to rank one instance\nbefore another. Here we consider an on-line algorithm for learning preference\nfunctions that is based on Freund and Schapire's 'Hedge' algorithm. In the\nsecond stage, new instances are ordered so as to maximize agreement with the\nlearned preference function. We show that the problem of finding the ordering\nthat agrees best with a learned preference function is NP-complete.\nNevertheless, we describe simple greedy algorithms that are guaranteed to find\na good approximation. Finally, we show how metasearch can be formulated as an\nordering problem, and present experimental results on learning a combination of\n'search experts', each of which is a domain-specific query expansion strategy\nfor a web search engine.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2011 01:54:11 GMT"}], "update_date": "2011-05-30", "authors_parsed": [["Cohen", "W. W.", ""], ["Schapire", "R. E.", ""], ["Singer", "Y.", ""]]}, {"id": "1105.5592", "submitter": "Danny Bickson", "authors": "Le Song, Arthur Gretton, Danny Bickson, Yucheng Low, Carlos Guestrin", "title": "Kernel Belief Propagation", "comments": null, "journal-ref": "In the Fourteenth International Conference on Artificial\n  Intelligence and Statistics April 11-13, 2011 Ft. Lauderdale, FL, USA", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparametric generalization of belief propagation, Kernel\nBelief Propagation (KBP), for pairwise Markov random fields. Messages are\nrepresented as functions in a reproducing kernel Hilbert space (RKHS), and\nmessage updates are simple linear operations in the RKHS. KBP makes none of the\nassumptions commonly required in classical BP algorithms: the variables need\nnot arise from a finite domain or a Gaussian distribution, nor must their\nrelations take any particular parametric form. Rather, the relations between\nvariables are represented implicitly, and are learned nonparametrically from\ntraining data. KBP has the advantage that it may be used on any domain where\nkernels are defined (Rd, strings, groups), even where explicit parametric\nmodels are not known, or closed form expressions for the BP updates do not\nexist. The computational cost of message updates in KBP is polynomial in the\ntraining data size. We also propose a constant time approximate message update\nprocedure by representing messages using a small number of basis functions. In\nexperiments, we apply KBP to image denoising, depth prediction from still\nimages, and protein configuration prediction: KBP is faster than competing\nclassical and nonparametric approaches (by orders of magnitude, in some cases),\nwhile providing significantly more accurate results.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2011 15:56:11 GMT"}], "update_date": "2011-05-30", "authors_parsed": [["Song", "Le", ""], ["Gretton", "Arthur", ""], ["Bickson", "Danny", ""], ["Low", "Yucheng", ""], ["Guestrin", "Carlos", ""]]}, {"id": "1105.5721", "submitter": "Marcus Hutter", "authors": "Samuel Rathmanner and Marcus Hutter", "title": "A Philosophical Treatise of Universal Induction", "comments": "72 pages, 2 figures, 1 table, LaTeX", "journal-ref": "Entropy, 13:6 (2011) pages 1076-1136", "doi": "10.3390/e13061076", "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding inductive reasoning is a problem that has engaged mankind for\nthousands of years. This problem is relevant to a wide range of fields and is\nintegral to the philosophy of science. It has been tackled by many great minds\nranging from philosophers to scientists to mathematicians, and more recently\ncomputer scientists. In this article we argue the case for Solomonoff\nInduction, a formal inductive framework which combines algorithmic information\ntheory with the Bayesian framework. Although it achieves excellent theoretical\nresults and is based on solid philosophical foundations, the requisite\ntechnical knowledge necessary for understanding this framework has caused it to\nremain largely unknown and unappreciated in the wider scientific community. The\nmain contribution of this article is to convey Solomonoff induction and its\nrelated concepts in a generally accessible form with the aim of bridging this\ncurrent technical gap. In the process we examine the major historical\ncontributions that have led to the formulation of Solomonoff Induction as well\nas criticisms of Solomonoff and induction in general. In particular we examine\nhow Solomonoff induction addresses many issues that have plagued other\ninductive systems, such as the black ravens paradox and the confirmation\nproblem, and compare this approach with other recent approaches.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2011 15:07:16 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Rathmanner", "Samuel", ""], ["Hutter", "Marcus", ""]]}, {"id": "1105.5887", "submitter": "Francois Orieux", "authors": "F. Orieux, and O. F\\'eron, and J.-F. Giovannelli", "title": "Efficient sampling of high-dimensional Gaussian fields: the\n  non-stationary / non-sparse case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to the problem of sampling Gaussian fields in high\ndimension. Solutions exist for two specific structures of inverse covariance :\nsparse and circulant. The proposed approach is valid in a more general case and\nespecially as it emerges in inverse problems. It relies on a\nperturbation-optimization principle: adequate stochastic perturbation of a\ncriterion and optimization of the perturbed criterion. It is shown that the\ncriterion minimizer is a sample of the target density. The motivation in\ninverse problems is related to general (non-convolutive) linear observation\nmodels and their resolution in a Bayesian framework implemented through\nsampling algorithms when existing samplers are not feasible. It finds a direct\napplication in myopic and/or unsupervised inversion as well as in some\nnon-Gaussian inversion. An illustration focused on hyperparameter estimation\nfor super-resolution problems assesses the effectiveness of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 07:31:01 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Orieux", "F.", ""], ["F\u00e9ron", "O.", ""], ["Giovannelli", "J. -F.", ""]]}, {"id": "1105.6041", "submitter": "Constantinos Panagiotakopoulos", "authors": "Constantinos Panagiotakopoulos and Petroula Tsampouka", "title": "The Perceptron with Dynamic Margin", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical perceptron rule provides a varying upper bound on the maximum\nmargin, namely the length of the current weight vector divided by the total\nnumber of updates up to that time. Requiring that the perceptron updates its\ninternal state whenever the normalized margin of a pattern is found not to\nexceed a certain fraction of this dynamic upper bound we construct a new\napproximate maximum margin classifier called the perceptron with dynamic margin\n(PDM). We demonstrate that PDM converges in a finite number of steps and derive\nan upper bound on them. We also compare experimentally PDM with other\nperceptron-like algorithms and support vector machines on hard margin tasks\ninvolving linear kernels which are equivalent to 2-norm soft margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 17:02:09 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Panagiotakopoulos", "Constantinos", ""], ["Tsampouka", "Petroula", ""]]}]