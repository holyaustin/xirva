[{"id": "1802.00002", "submitter": "Abhishek Dubey", "authors": "Fangzhou sun and Abhishek Dubey and Jules White", "title": "DxNAT - Deep Neural Networks for Explaining Non-Recurring Traffic\n  Congestion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-recurring traffic congestion is caused by temporary disruptions, such as\naccidents, sports games, adverse weather, etc. We use data related to real-time\ntraffic speed, jam factors (a traffic congestion indicator), and events\ncollected over a year from Nashville, TN to train a multi-layered deep neural\nnetwork. The traffic dataset contains over 900 million data records. The\nnetwork is thereafter used to classify the real-time data and identify\nanomalous operations. Compared with traditional approaches of using statistical\nor machine learning techniques, our model reaches an accuracy of 98.73 percent\nwhen identifying traffic congestion caused by football games. Our approach\nfirst encodes the traffic across a region as a scaled image. After that the\nimage data from different timestamps is fused with event- and time-related\ndata. Then a crossover operator is used as a data augmentation method to\ngenerate training datasets with more balanced classes. Finally, we use the\nreceiver operating characteristic (ROC) analysis to tune the sensitivity of the\nclassifier. We present the analysis of the training time and the inference time\nseparately.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 23:18:11 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["sun", "Fangzhou", ""], ["Dubey", "Abhishek", ""], ["White", "Jules", ""]]}, {"id": "1802.00003", "submitter": "Babajide Ayinde", "authors": "Babajide O. Ayinde and Jacek M. Zurada", "title": "Deep Learning of Nonnegativity-Constrained Autoencoders for Enhanced\n  Understanding of Data", "comments": "IEEE Trans. on Neural Networks and Learning Systems, September 2018,\n  Vol. 29, Issue 9, Pg. 3969 - 3979", "journal-ref": "IEEE Trans. on Neural Networks and Learning Systems, September\n  2018, Vol. 29, Issue 9, Pg. 3969 - 3979", "doi": "10.1109/TNNLS.2017.2747861", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised feature extractors are known to perform an efficient and\ndiscriminative representation of data. Insight into the mappings they perform\nand human ability to understand them, however, remain very limited. This is\nespecially prominent when multilayer deep learning architectures are used. This\npaper demonstrates how to remove these bottlenecks within the architecture of\nNonnegativity Constrained Autoencoder (NCSAE). It is shown that by using both\nL1 and L2 regularization that induce nonnegativity of weights, most of the\nweights in the network become constrained to be nonnegative thereby resulting\ninto a more understandable structure with minute deterioration in\nclassification accuracy. Also, this proposed approach extracts features that\nare more sparse and produces additional output layer sparsification. The method\nis analyzed for accuracy and feature interpretation on the MNIST data, the NORB\nnormalized uniform object data, and the Reuters text categorization dataset.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 02:32:40 GMT"}, {"version": "v2", "created": "Sat, 3 Feb 2018 18:25:16 GMT"}, {"version": "v3", "created": "Tue, 25 Dec 2018 09:16:35 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Ayinde", "Babajide O.", ""], ["Zurada", "Jacek M.", ""]]}, {"id": "1802.00027", "submitter": "Natarajan Subrmanyma", "authors": "Varun Ranganathan and S. Natarajan", "title": "A New Backpropagation Algorithm without Gradient Descent", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation algorithm, which had been originally introduced in the\n1970s, is the workhorse of learning in neural networks. This backpropagation\nalgorithm makes use of the famous machine learning algorithm known as Gradient\nDescent, which is a first-order iterative optimization algorithm for finding\nthe minimum of a function. To find a local minimum of a function using gradient\ndescent, one takes steps proportional to the negative of the gradient (or of\nthe approximate gradient) of the function at the current point. In this paper,\nwe develop an alternative to the backpropagation without the use of the\nGradient Descent Algorithm, but instead we are going to devise a new algorithm\nto find the error in the weights and biases of an artificial neuron using\nMoore-Penrose Pseudo Inverse. The numerical studies and the experiments\nperformed on various datasets are used to verify the working of this\nalternative algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 05:33:26 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Ranganathan", "Varun", ""], ["Natarajan", "S.", ""]]}, {"id": "1802.00030", "submitter": "Marcio Nicolau", "authors": "M\\'arcio Nicolau, M\\'arcia Barrocas Moreira Pimentel, Casiane Salete\n  Tibola, Jos\\'e Mauricio Cunha Fernandes, Willingthon Pavan", "title": "Fusarium Damaged Kernels Detection Using Transfer Learning on Deep\n  Neural Network Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work shows the application of transfer learning for a pre-trained\ndeep neural network (DNN), using a small image dataset ($\\approx$ 12,000) on a\nsingle workstation with enabled NVIDIA GPU card that takes up to 1 hour to\ncomplete the training task and archive an overall average accuracy of $94.7\\%$.\nThe DNN presents a $20\\%$ score of misclassification for an external test\ndataset. The accuracy of the proposed methodology is equivalent to ones using\nHSI methodology $(81\\%-91\\%)$ used for the same task, but with the advantage of\nbeing independent on special equipment to classify wheat kernel for FHB\nsymptoms.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 19:31:25 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Nicolau", "M\u00e1rcio", ""], ["Pimentel", "M\u00e1rcia Barrocas Moreira", ""], ["Tibola", "Casiane Salete", ""], ["Fernandes", "Jos\u00e9 Mauricio Cunha", ""], ["Pavan", "Willingthon", ""]]}, {"id": "1802.00043", "submitter": "Fredrik Hallgren", "authors": "Fredrik Hallgren and Paul Northrop", "title": "Incremental kernel PCA and the Nystr\\\"om method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental versions of batch algorithms are often desired, for increased\ntime efficiency in the streaming data setting, or increased memory efficiency\nin general. In this paper we present a novel algorithm for incremental kernel\nPCA, based on rank one updates to the eigendecomposition of the kernel matrix,\nwhich is more computationally efficient than comparable existing algorithms. We\nextend our algorithm to incremental calculation of the Nystr\\\"om approximation\nto the kernel matrix, the first such algorithm proposed. Incremental\ncalculation of the Nystr\\\"om approximation leads to further gains in memory\nefficiency, and allows for empirical evaluation of when a subset of sufficient\nsize has been obtained.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 19:57:26 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Hallgren", "Fredrik", ""], ["Northrop", "Paul", ""]]}, {"id": "1802.00047", "submitter": "Rui Zhang", "authors": "Alexander Shapiro, Yao Xie, Rui Zhang", "title": "Matrix completion with deterministic pattern - a geometric perspective", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2885494", "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the matrix completion problem with a deterministic pattern of\nobserved entries. In this setting, we aim to answer the question: under what\ncondition there will be (at least locally) unique solution to the matrix\ncompletion problem, i.e., the underlying true matrix is identifiable. We answer\nthe question from a certain point of view and outline a geometric perspective.\nWe give an algebraically verifiable sufficient condition, which we call the\nwell-posedness condition, for the local uniqueness of MRMC solutions. We argue\nthat this condition is necessary for local stability of MRMC solutions, and we\nshow that the condition is generic using the characteristic rank. We also argue\nthat the low-rank approximation approaches are more stable than MRMC and\nfurther propose a sequential statistical testing procedure to determine the\n\"true\" rank from observed entries. Finally, we provide numerical examples aimed\nat verifying validity of the presented theory.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 20:03:07 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 02:29:26 GMT"}, {"version": "v3", "created": "Fri, 16 Feb 2018 03:25:36 GMT"}, {"version": "v4", "created": "Wed, 29 Aug 2018 19:03:53 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Shapiro", "Alexander", ""], ["Xie", "Yao", ""], ["Zhang", "Rui", ""]]}, {"id": "1802.00069", "submitter": "Maxwell Henderson", "authors": "Maxwell Henderson, John Novak, and Tristan Cook", "title": "Leveraging Adiabatic Quantum Computation for Election Forecasting", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": "10.7566/JPSJ.88.061009", "report-no": null, "categories": "quant-ph cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate, reliable sampling from fully-connected graphs with arbitrary\ncorrelations is a difficult problem. Such sampling requires knowledge of the\nprobabilities of observing every possible state of a graph. As graph size\ngrows, the number of model states becomes intractably large and efficient\ncomputation requires full sampling be replaced with heuristics and algorithms\nthat are only approximations of full sampling. This work investigates the\npotential impact of adiabatic quantum computation for sampling purposes,\nbuilding on recent successes training Boltzmann machines using a quantum\ndevice. We investigate the use case of quantum computation to train Boltzmann\nmachines for predicting the 2016 Presidential election.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 16:26:19 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Henderson", "Maxwell", ""], ["Novak", "John", ""], ["Cook", "Tristan", ""]]}, {"id": "1802.00086", "submitter": "Amartya Sanyal", "authors": "Amartya Sanyal, Pawan Kumar, Purushottam Kar, Sanjay Chawla, Fabrizio\n  Sebastiani", "title": "Optimizing Non-decomposable Measures with Deep Networks", "comments": null, "journal-ref": null, "doi": "10.1007/s10994-018-5736-y", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a class of algorithms capable of directly training deep neural\nnetworks with respect to large families of task-specific performance measures\nsuch as the F-measure and the Kullback-Leibler divergence that are structured\nand non-decomposable. This presents a departure from standard deep learning\ntechniques that typically use squared or cross-entropy loss functions (that are\ndecomposable) to train neural networks. We demonstrate that directly training\nwith task-specific loss functions yields much faster and more stable\nconvergence across problems and datasets. Our proposed algorithms and\nimplementations have several novel features including (i) convergence to first\norder stationary points despite optimizing complex objective functions; (ii)\nuse of fewer training samples to achieve a desired level of convergence, (iii)\na substantial reduction in training time, and (iv) a seamless integration of\nour implementation into existing symbolic gradient frameworks. We implement our\ntechniques on a variety of deep architectures including multi-layer perceptrons\nand recurrent neural networks and show that on a variety of benchmark and real\ndata sets, our algorithms outperform traditional approaches to training deep\nnetworks, as well as some recent approaches to task-specific training of neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 22:14:09 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Sanyal", "Amartya", ""], ["Kumar", "Pawan", ""], ["Kar", "Purushottam", ""], ["Chawla", "Sanjay", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1802.00123", "submitter": "Feng Li", "authors": "Feng Li, Yan Liu, Khidir Shaib Mohamed, Wei Wu", "title": "A Modified Sigma-Pi-Sigma Neural Network with Adaptive Choice of\n  Multinomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sigma-Pi-Sigma neural networks (SPSNNs) as a kind of high-order neural\nnetworks can provide more powerful mapping capability than the traditional\nfeedforward neural networks (Sigma-Sigma neural networks). In the existing\nliterature, in order to reduce the number of the Pi nodes in the Pi layer, a\nspecial multinomial P_s is used in SPSNNs. Each monomial in P_s is linear with\nrespect to each particular variable sigma_i when the other variables are taken\nas constants. Therefore, the monomials like sigma_i^n or sigma_i^n sigma_j with\nn>1 are not included. This choice may be somehow intuitive, but is not\nnecessarily the best. We propose in this paper a modified Sigma-Pi-Sigma neural\nnetwork (MSPSNN) with an adaptive approach to find a better multinomial for a\ngiven problem. To elaborate, we start from a complete multinomial with a given\norder. Then we employ a regularization technique in the learning process for\nthe given problem to reduce the number of monomials used in the multinomial,\nand end up with a new SPSNN involving the same number of monomials (= the\nnumber of nodes in the Pi-layer) as in P_s. Numerical experiments on some\nbenchmark problems show that our MSPSNN behaves better than the traditional\nSPSNN with P_s.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 01:55:11 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Li", "Feng", ""], ["Liu", "Yan", ""], ["Mohamed", "Khidir Shaib", ""], ["Wu", "Wei", ""]]}, {"id": "1802.00124", "submitter": "Jianbo Ye", "authors": "Jianbo Ye, Xin Lu, Zhe Lin, James Z. Wang", "title": "Rethinking the Smaller-Norm-Less-Informative Assumption in Channel\n  Pruning of Convolution Layers", "comments": "accepted to ICLR 2018, 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model pruning has become a useful technique that improves the computational\nefficiency of deep learning, making it possible to deploy solutions in\nresource-limited scenarios. A widely-used practice in relevant work assumes\nthat a smaller-norm parameter or feature plays a less informative role at the\ninference time. In this paper, we propose a channel pruning technique for\naccelerating the computations of deep convolutional neural networks (CNNs) that\ndoes not critically rely on this assumption. Instead, it focuses on direct\nsimplification of the channel-to-channel computation graph of a CNN without the\nneed of performing a computationally difficult and not-always-useful task of\nmaking high-dimensional tensors of CNN structured sparse. Our approach takes\ntwo stages: first to adopt an end-to- end stochastic training method that\neventually forces the outputs of some channels to be constant, and then to\nprune those constant channels from the original neural network by adjusting the\nbiases of their impacting layers such that the resulting compact model can be\nquickly fine-tuned. Our approach is mathematically appealing from an\noptimization perspective and easy to reproduce. We experimented our approach\nthrough several image learning benchmarks and demonstrate its interesting\naspects and competitive performance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 01:58:22 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 19:58:54 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Ye", "Jianbo", ""], ["Lu", "Xin", ""], ["Lin", "Zhe", ""], ["Wang", "James Z.", ""]]}, {"id": "1802.00130", "submitter": "Yu-Hsiang Lin", "authors": "Chien-Chih Wang, Kent Loong Tan, Chun-Ting Chen, Yu-Hsiang Lin, S.\n  Sathiya Keerthi, Dhruv Mahajan, S. Sundararajan, Chih-Jen Lin", "title": "Distributed Newton Methods for Deep Neural Networks", "comments": "Supplementary materials and experimental code are available at\n  https://www.csie.ntu.edu.tw/~cjlin/papers/dnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning involves a difficult non-convex optimization problem with a\nlarge number of weights between any two adjacent layers of a deep structure. To\nhandle large data sets or complicated networks, distributed training is needed,\nbut the calculation of function, gradient, and Hessian is expensive. In\nparticular, the communication and the synchronization cost may become a\nbottleneck. In this paper, we focus on situations where the model is\ndistributedly stored, and propose a novel distributed Newton method for\ntraining deep neural networks. By variable and feature-wise data partitions,\nand some careful designs, we are able to explicitly use the Jacobian matrix for\nmatrix-vector products in the Newton method. Some techniques are incorporated\nto reduce the running time as well as the memory consumption. First, to reduce\nthe communication cost, we propose a diagonalization method such that an\napproximate Newton direction can be obtained without communication between\nmachines. Second, we consider subsampled Gauss-Newton matrices for reducing the\nrunning time as well as the communication cost. Third, to reduce the\nsynchronization cost, we terminate the process of finding an approximate Newton\ndirection even though some nodes have not finished their tasks. Details of some\nimplementation issues in distributed environments are thoroughly investigated.\nExperiments demonstrate that the proposed method is effective for the\ndistributed training of deep neural networks. In compared with stochastic\ngradient methods, it is more robust and may give better test accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 02:44:56 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Wang", "Chien-Chih", ""], ["Tan", "Kent Loong", ""], ["Chen", "Chun-Ting", ""], ["Lin", "Yu-Hsiang", ""], ["Keerthi", "S. Sathiya", ""], ["Mahajan", "Dhruv", ""], ["Sundararajan", "S.", ""], ["Lin", "Chih-Jen", ""]]}, {"id": "1802.00150", "submitter": "Chen Xu", "authors": "Chen Xu, Jianqiang Yao, Zhouchen Lin, Wenwu Ou, Yuanbin Cao, Zhirong\n  Wang, Hongbin Zha", "title": "Alternating Multi-bit Quantization for Recurrent Neural Networks", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have achieved excellent performance in many\napplications. However, on portable devices with limited resources, the models\nare often too large to deploy. For applications on the server with large scale\nconcurrent requests, the latency during inference can also be very critical for\ncostly computing resources. In this work, we address these problems by\nquantizing the network, both weights and activations, into multiple binary\ncodes {-1,+1}. We formulate the quantization as an optimization problem. Under\nthe key observation that once the quantization coefficients are fixed the\nbinary codes can be derived efficiently by binary search tree, alternating\nminimization is then applied. We test the quantization for two well-known RNNs,\ni.e., long short term memory (LSTM) and gated recurrent unit (GRU), on the\nlanguage models. Compared with the full-precision counter part, by 2-bit\nquantization we can achieve ~16x memory saving and ~6x real inference\nacceleration on CPUs, with only a reasonable loss in the accuracy. By 3-bit\nquantization, we can achieve almost no loss in the accuracy or even surpass the\noriginal model, with ~10.5x memory saving and ~3x real inference acceleration.\nBoth results beat the exiting quantization works with large margins. We extend\nour alternating quantization to image classification tasks. In both RNNs and\nfeedforward neural networks, the method also achieves excellent performance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 04:06:39 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Xu", "Chen", ""], ["Yao", "Jianqiang", ""], ["Lin", "Zhouchen", ""], ["Ou", "Wenwu", ""], ["Cao", "Yuanbin", ""], ["Wang", "Zhirong", ""], ["Zha", "Hongbin", ""]]}, {"id": "1802.00154", "submitter": "Shehroz Khan", "authors": "Shehroz S. Khan, Amir Ahmad, Alex Mihailidis", "title": "Bootstrapping and Multiple Imputation Ensemble Approaches for Missing\n  Data", "comments": "16 Pages, 15 Tables, 4 Figures", "journal-ref": "Journal of Intelligent & Fuzzy Systems, 2019", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presence of missing values in a dataset can adversely affect the performance\nof a classifier. Single and Multiple Imputation are normally performed to fill\nin the missing values. In this paper, we present several variants of combining\nsingle and multiple imputation with bootstrapping to create ensembles that can\nmodel uncertainty and diversity in the data, and that are robust to high\nmissingness in the data. We present three ensemble strategies: bootstrapping on\nincomplete data followed by (i) single imputation and (ii) multiple imputation,\nand (iii) multiple imputation ensemble without bootstrapping. We perform an\nextensive evaluation of the performance of the these ensemble strategies on 8\ndatasets by varying the missingness ratio. Our results show that bootstrapping\nfollowed by multiple imputation using expectation maximization is the most\nrobust method even at high missingness ratio (up to 30%). For small missingness\nratio (up to 10%) most of the ensemble methods perform quivalently but better\nthan single imputation. Kappa-error plots suggest that accurate classifiers\nwith reasonable diversity is the reason for this behaviour. A consistent\nobservation in all the datasets suggests that for small missingness (up to\n10%), bootstrapping on incomplete data without any imputation produces\nequivalent results to other ensemble methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 05:05:46 GMT"}, {"version": "v2", "created": "Sun, 4 Feb 2018 03:41:36 GMT"}, {"version": "v3", "created": "Tue, 6 Feb 2018 01:32:38 GMT"}, {"version": "v4", "created": "Sun, 11 Nov 2018 06:25:07 GMT"}, {"version": "v5", "created": "Tue, 15 Oct 2019 17:52:05 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Khan", "Shehroz S.", ""], ["Ahmad", "Amir", ""], ["Mihailidis", "Alex", ""]]}, {"id": "1802.00168", "submitter": "Bao Wang", "authors": "Bao Wang, Xiyang Luo, Zhen Li, Wei Zhu, Zuoqiang Shi and Stanley J.\n  Osher", "title": "Deep Neural Nets with Interpolating Function as Output Activation", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We replace the output layer of deep neural nets, typically the softmax\nfunction, by a novel interpolating function. And we propose end-to-end training\nand testing algorithms for this new architecture. Compared to classical neural\nnets with softmax function as output activation, the surrogate with\ninterpolating function as output activation combines advantages of both deep\nand manifold learning. The new framework demonstrates the following major\nadvantages: First, it is better applicable to the case with insufficient\ntraining data. Second, it significantly improves the generalization accuracy on\na wide variety of networks. The algorithm is implemented in PyTorch, and code\nwill be made publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 06:25:39 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 17:38:08 GMT"}, {"version": "v3", "created": "Sun, 17 Jun 2018 00:56:50 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Wang", "Bao", ""], ["Luo", "Xiyang", ""], ["Li", "Zhen", ""], ["Zhu", "Wei", ""], ["Shi", "Zuoqiang", ""], ["Osher", "Stanley J.", ""]]}, {"id": "1802.00174", "submitter": "Badong Chen", "authors": "Zhengda Qin, Badong Chen, Nanning Zheng and Jose C. Principe", "title": "Augmented Space Linear Model", "comments": "5 pages and 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear model uses the space defined by the input to project the target or\ndesired signal and find the optimal set of model parameters. When the problem\nis nonlinear, the adaption requires nonlinear models for good performance, but\nit becomes slower and more cumbersome. In this paper, we propose a linear model\ncalled Augmented Space Linear Model (ASLM), which uses the full joint space of\ninput and desired signal as the projection space and approaches the performance\nof nonlinear models. This new algorithm takes advantage of the linear solution,\nand corrects the estimate for the current testing phase input with the error\nassigned to the input space neighborhood in the training phase. This algorithm\ncan solve the nonlinear problem with the computational efficiency of linear\nmethods, which can be regarded as a trade off between accuracy and\ncomputational complexity. Making full use of the training data, the proposed\naugmented space model may provide a new way to improve many modeling tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 07:03:57 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 08:39:13 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Qin", "Zhengda", ""], ["Chen", "Badong", ""], ["Zheng", "Nanning", ""], ["Principe", "Jose C.", ""]]}, {"id": "1802.00187", "submitter": "\\c{C}a\\u{g}lar Aytekin", "authors": "Caglar Aytekin, Xingyang Ni, Francesco Cricri, Emre Aksu", "title": "Clustering and Unsupervised Anomaly Detection with L2 Normalized Deep\n  Auto-Encoder Representations", "comments": "Submitted to IJCNN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is essential to many tasks in pattern recognition and computer\nvision. With the advent of deep learning, there is an increasing interest in\nlearning deep unsupervised representations for clustering analysis. Many works\non this domain rely on variants of auto-encoders and use the encoder outputs as\nrepresentations/features for clustering. In this paper, we show that an l2\nnormalization constraint on these representations during auto-encoder training,\nmakes the representations more separable and compact in the Euclidean space\nafter training. This greatly improves the clustering accuracy when k-means\nclustering is employed on the representations. We also propose a clustering\nbased unsupervised anomaly detection method using l2 normalized deep\nauto-encoder representations. We show the effect of l2 normalization on anomaly\ndetection accuracy. We further show that the proposed anomaly detection method\ngreatly improves accuracy compared to previously proposed deep methods such as\nreconstruction error based anomaly detection.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 08:10:50 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Aytekin", "Caglar", ""], ["Ni", "Xingyang", ""], ["Cricri", "Francesco", ""], ["Aksu", "Emre", ""]]}, {"id": "1802.00212", "submitter": "Pak Lun Kevin Ding", "authors": "Yikang Li, Pak Lun Kevin Ding, Baoxin Li", "title": "Training Neural Networks by Using Power Linear Units (PoLUs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce \"Power Linear Unit\" (PoLU) which increases the\nnonlinearity capacity of a neural network and thus helps improving its\nperformance. PoLU adopts several advantages of previously proposed activation\nfunctions. First, the output of PoLU for positive inputs is designed to be\nidentity to avoid the gradient vanishing problem. Second, PoLU has a non-zero\noutput for negative inputs such that the output mean of the units is close to\nzero, hence reducing the bias shift effect. Thirdly, there is a saturation on\nthe negative part of PoLU, which makes it more noise-robust for negative\ninputs. Furthermore, we prove that PoLU is able to map more portions of every\nlayer's input to the same space by using the power function and thus increases\nthe number of response regions of the neural network. We use image\nclassification for comparing our proposed activation function with others. In\nthe experiments, MNIST, CIFAR-10, CIFAR-100, Street View House Numbers (SVHN)\nand ImageNet are used as benchmark datasets. The neural networks we implemented\ninclude widely-used ELU-Network, ResNet-50, and VGG16, plus a couple of shallow\nnetworks. Experimental results show that our proposed activation function\noutperforms other state-of-the-art models with most networks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 09:38:06 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Li", "Yikang", ""], ["Ding", "Pak Lun Kevin", ""], ["Li", "Baoxin", ""]]}, {"id": "1802.00233", "submitter": "Nader Bshouty", "authors": "Nader H. Bshouty and Waseem Makhoul", "title": "On Polynomial time Constructions of Minimum Height Decision Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a polynomial time algorithms that for an input\n$A\\subseteq {B_m}$ outputs a decision tree for $A$ of minimum depth. This\nproblem has many applications that include, to name a few, computer vision,\ngroup testing, exact learning from membership queries and game theory.\n  Arkin et al. and Moshkov gave a polynomial time $(\\ln |A|)$- approximation\nalgorithm (for the depth). The result of Dinur and Steurer for set cover\nimplies that this problem cannot be approximated with ratio $(1-o(1))\\cdot \\ln\n|A|$, unless P=NP. Moskov the combinatorial measure of extended teaching\ndimension of $A$, $ETD(A)$. He showed that $ETD(A)$ is a lower bound for the\ndepth of the decision tree for $A$ and then gave an {\\it exponential time}\n$ETD(A)/\\log(ETD(A))$-approximation algorithm.\n  In this paper we further study the $ETD(A)$ measure and a new combinatorial\nmeasure, $DEN(A)$, that we call the density of the set $A$. We show that\n$DEN(A)\\le ETD(A)+1$. We then give two results. The first result is that the\nlower bound $ETD(A)$ of Moshkov for the depth of the decision tree for $A$ is\ngreater than the bounds that are obtained by the classical technique used in\nthe literature. The second result is a polynomial time $(\\ln 2)\nDEN(A)$-approximation (and therefore $(\\ln 2) ETD(A)$-approximation) algorithm\nfor the depth of the decision tree of $A$. We also show that a better\napproximation ratio implies P=NP.\n  We then apply the above results to learning the class of disjunctions of\npredicates from membership queries. We show that the $ETD$ of this class is\nbounded from above by the degree $d$ of its Hasse diagram. We then show that\nMoshkov algorithm can be run in polynomial time and is $(d/\\log\nd)$-approximation algorithm. This gives optimal algorithms when the degree is\nconstant. For example, learning axis parallel rays over constant dimension\nspace.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 10:38:30 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Bshouty", "Nader H.", ""], ["Makhoul", "Waseem", ""]]}, {"id": "1802.00255", "submitter": "Yuya Yoshikawa", "authors": "Yuya Yoshikawa, Yusaku Imai", "title": "A Nonparametric Delayed Feedback Model for Conversion Rate Prediction", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting conversion rates (CVRs) in display advertising (e.g., predicting\nthe proportion of users who purchase an item (i.e., a conversion) after its\ncorresponding ad is clicked) is important when measuring the effects of ads\nshown to users and to understanding the interests of the users. There is\ngenerally a time delay (i.e., so-called {\\it delayed feedback}) between the ad\nclick and conversion. Owing to the delayed feedback, samples that are converted\nafter an observation period may be treated as negative. To overcome this\ndrawback, CVR prediction assuming that the time delay follows an exponential\ndistribution has been proposed. In practice, however, there is no guarantee\nthat the delay is generated from the exponential distribution, and the best\ndistribution with which to represent the delay depends on the data. In this\npaper, we propose a nonparametric delayed feedback model for CVR prediction\nthat represents the distribution of the time delay without assuming a\nparametric distribution, such as an exponential or Weibull distribution.\nBecause the distribution of the time delay is modeled depending on the content\nof an ad and the features of a user, various shapes of the distribution can be\nrepresented potentially. In experiments, we show that the proposed model can\ncapture the distribution for the time delay on a synthetic dataset, even when\nthe distribution is complicated. Moreover, on a real dataset, we show that the\nproposed model outperforms the existing method that assumes an exponential\ndistribution for the time delay in terms of conversion rate prediction.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 12:01:23 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Yoshikawa", "Yuya", ""], ["Imai", "Yusaku", ""]]}, {"id": "1802.00265", "submitter": "Lei Tai", "authors": "Jingwei Zhang, Lei Tai, Peng Yun, Yufeng Xiong, Ming Liu, Joschka\n  Boedecker, Wolfram Burgard", "title": "VR-Goggles for Robots: Real-to-sim Domain Adaptation for Visual Control", "comments": "IEEE RA-L 2019 to appear. The first two authors contributed equally.\n  Video and supplement file are available on the project\n  page(https://goo.gl/KcvmRm)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with the reality gap from a novel perspective,\ntargeting transferring Deep Reinforcement Learning (DRL) policies learned in\nsimulated environments to the real-world domain for visual control tasks.\nInstead of adopting the common solutions to the problem by increasing the\nvisual fidelity of synthetic images output from simulators during the training\nphase, we seek to tackle the problem by translating the real-world image\nstreams back to the synthetic domain during the deployment phase, to make the\nrobot feel at home. We propose this as a lightweight, flexible, and efficient\nsolution for visual control, as 1) no extra transfer steps are required during\nthe expensive training of DRL agents in simulation; 2) the trained DRL agents\nwill not be constrained to being deployable in only one specific real-world\nenvironment; 3) the policy training and the transfer operations are decoupled,\nand can be conducted in parallel. Besides this, we propose a simple yet\neffective shift loss that is agnostic to the downstream task, to constrain the\nconsistency between subsequent frames which is important for consistent policy\noutputs. We validate the shift loss for artistic style transfer for videos and\ndomain adaptation, and validate our visual control approach in indoor and\noutdoor robotics experiments.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 12:42:02 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 04:26:35 GMT"}, {"version": "v3", "created": "Wed, 12 Sep 2018 02:22:47 GMT"}, {"version": "v4", "created": "Wed, 16 Jan 2019 09:04:06 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Zhang", "Jingwei", ""], ["Tai", "Lei", ""], ["Yun", "Peng", ""], ["Xiong", "Yufeng", ""], ["Liu", "Ming", ""], ["Boedecker", "Joschka", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1802.00308", "submitter": "Subhrajit Roy", "authors": "Subhrajit Roy, Isabell Kiral-Kornek, and Stefan Harrer", "title": "ChronoNet: A Deep Recurrent Neural Network for Abnormal EEG\n  Identification", "comments": "8 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-related disorders such as epilepsy can be diagnosed by analyzing\nelectroencephalograms (EEG). However, manual analysis of EEG data requires\nhighly trained clinicians, and is a procedure that is known to have relatively\nlow inter-rater agreement (IRA). Moreover, the volume of the data and the rate\nat which new data becomes available make manual interpretation a\ntime-consuming, resource-hungry, and expensive process. In contrast, automated\nanalysis of EEG data offers the potential to improve the quality of patient\ncare by shortening the time to diagnosis and reducing manual error. In this\npaper, we focus on one of the first steps in interpreting an EEG session -\nidentifying whether the brain activity is abnormal or normal. To solve this\ntask, we propose a novel recurrent neural network (RNN) architecture termed\nChronoNet which is inspired by recent developments from the field of image\nclassification and designed to work efficiently with EEG data. ChronoNet is\nformed by stacking multiple 1D convolution layers followed by deep gated\nrecurrent unit (GRU) layers where each 1D convolution layer uses multiple\nfilters of exponentially varying lengths and the stacked GRU layers are densely\nconnected in a feed-forward manner. We used the recently released TUH Abnormal\nEEG Corpus dataset for evaluating the performance of ChronoNet. Unlike previous\nstudies using this dataset, ChronoNet directly takes time-series EEG as input\nand learns meaningful representations of brain activity patterns. ChronoNet\noutperforms the previously reported best results by 7.79% thereby setting a new\nbenchmark for this dataset. Furthermore, we demonstrate the domain-independent\nnature of ChronoNet by successfully applying it to classify speech commands.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 05:47:02 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 00:46:07 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Roy", "Subhrajit", ""], ["Kiral-Kornek", "Isabell", ""], ["Harrer", "Stefan", ""]]}, {"id": "1802.00324", "submitter": "Nhien-An Le-Khac", "authors": "Nga Nguyen Thi, Van Loi Cao, Nhien-An Le-Khac", "title": "One-class Collective Anomaly Detection based on Long Short-Term Memory\n  Recurrent Neural Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1703.09752", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection for computer network systems has been becoming one of the\nmost critical tasks for network administrators today. It has an important role\nfor organizations, governments and our society due to the valuable resources\nhosted on computer networks. Traditional misuse detection strategies are unable\nto detect new and unknown intrusion types. In contrast, anomaly detection in\nnetwork security aims to distinguish between illegal or malicious events and\nnormal behavior of network systems. Anomaly detection can be considered as a\nclassification problem where it builds models of normal network behavior, of\nwhich it uses to detect new patterns that significantly deviate from the model.\nMost of the current approaches on anomaly detection is based on the learning of\nnormal behavior and anomalous actions. They do not include memory that is they\ndo not take into account previous events classify new ones. In this paper, we\npropose a one class collective anomaly detection model based on neural network\nlearning. Normally a Long Short Term Memory Recurrent Neural Network (LSTM RNN)\nis trained only on normal data, and it is capable of predicting several time\nsteps ahead of an input. In our approach, a LSTM RNN is trained on normal time\nseries data before performing a prediction for each time step. Instead of\nconsidering each time-step separately, the observation of prediction errors\nfrom a certain number of time-steps is now proposed as a new idea for detecting\ncollective anomalies. The prediction errors of a certain number of the latest\ntime-steps above a threshold will indicate a collective anomaly. The model is\nevaluated on a time series version of the KDD 1999 dataset. The experiments\ndemonstrate that the proposed model is capable to detect collective anomaly\nefficiently\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 10:38:07 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Thi", "Nga Nguyen", ""], ["Cao", "Van Loi", ""], ["Le-Khac", "Nhien-An", ""]]}, {"id": "1802.00332", "submitter": "Jingchu Liu", "authors": "Jingchu Liu, Pengfei Hou, Lisen Mu, Yinan Yu, Chang Huang", "title": "Elements of Effective Deep Reinforcement Learning towards Tactical\n  Driving Decision Making", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactical driving decision making is crucial for autonomous driving systems\nand has attracted considerable interest in recent years. In this paper, we\npropose several practical components that can speed up deep reinforcement\nlearning algorithms towards tactical decision making tasks: 1) non-uniform\naction skipping as a more stable alternative to action-repetition frame\nskipping, 2) a counter-based penalty for lanes on which ego vehicle has less\nright-of-road, and 3) heuristic inference-time action masking for apparently\nundesirable actions. We evaluate the proposed components in a realistic driving\nsimulator and compare them with several baselines. Results show that the\nproposed scheme provides superior performance in terms of safety, efficiency,\nand comfort.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 15:13:10 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Liu", "Jingchu", ""], ["Hou", "Pengfei", ""], ["Mu", "Lisen", ""], ["Yu", "Yinan", ""], ["Huang", "Chang", ""]]}, {"id": "1802.00382", "submitter": "Amitabha Karmakar", "authors": "Amitabha Karmakar", "title": "Classifying medical notes into standard disease codes using Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the automatic classification of patient discharge notes into\nstandard disease labels. We find that Convolutional Neural Networks with\nAttention outperform previous algorithms used in this task, and suggest further\nareas for improvement.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 16:46:00 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Karmakar", "Amitabha", ""]]}, {"id": "1802.00411", "submitter": "Bo Yang", "authors": "Bo Yang, Stefano Rosa, Andrew Markham, Niki Trigoni, Hongkai Wen", "title": "Dense 3D Object Reconstruction from a Single Depth View", "comments": "TPAMI 2018. Code and data are available at:\n  https://github.com/Yang7879/3D-RecGAN-extended. This article extends from\n  arXiv:1708.07969", "journal-ref": null, "doi": "10.1109/TPAMI.2018.2868195", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach, 3D-RecGAN++, which reconstructs\nthe complete 3D structure of a given object from a single arbitrary depth view\nusing generative adversarial networks. Unlike existing work which typically\nrequires multiple views of the same object or class labels to recover the full\n3D geometry, the proposed 3D-RecGAN++ only takes the voxel grid representation\nof a depth view of the object as input, and is able to generate the complete 3D\noccupancy grid with a high resolution of 256^3 by recovering the\noccluded/missing regions. The key idea is to combine the generative\ncapabilities of autoencoders and the conditional Generative Adversarial\nNetworks (GAN) framework, to infer accurate and fine-grained 3D structures of\nobjects in high-dimensional voxel space. Extensive experiments on large\nsynthetic datasets and real-world Kinect datasets show that the proposed\n3D-RecGAN++ significantly outperforms the state of the art in single view 3D\nobject reconstruction, and is able to reconstruct unseen types of objects.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 17:39:15 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 23:54:05 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Yang", "Bo", ""], ["Rosa", "Stefano", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""], ["Wen", "Hongkai", ""]]}, {"id": "1802.00420", "submitter": "Anish Athalye", "authors": "Anish Athalye, Nicholas Carlini, David Wagner", "title": "Obfuscated Gradients Give a False Sense of Security: Circumventing\n  Defenses to Adversarial Examples", "comments": "ICML 2018. Source code at\n  https://github.com/anishathalye/obfuscated-gradients", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify obfuscated gradients, a kind of gradient masking, as a phenomenon\nthat leads to a false sense of security in defenses against adversarial\nexamples. While defenses that cause obfuscated gradients appear to defeat\niterative optimization-based attacks, we find defenses relying on this effect\ncan be circumvented. We describe characteristic behaviors of defenses\nexhibiting the effect, and for each of the three types of obfuscated gradients\nwe discover, we develop attack techniques to overcome it. In a case study,\nexamining non-certified white-box-secure defenses at ICLR 2018, we find\nobfuscated gradients are a common occurrence, with 7 of 9 defenses relying on\nobfuscated gradients. Our new attacks successfully circumvent 6 completely, and\n1 partially, in the original threat model each paper considers.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 18:20:05 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 16:32:56 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 16:37:42 GMT"}, {"version": "v4", "created": "Tue, 31 Jul 2018 00:09:56 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Athalye", "Anish", ""], ["Carlini", "Nicholas", ""], ["Wagner", "David", ""]]}, {"id": "1802.00459", "submitter": "Peilin Zhong", "authors": "Wei Hu, Zhao Song, Lin F. Yang, Peilin Zhong", "title": "Nearly Optimal Dynamic $k$-Means Clustering for High-Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the $k$-means clustering problem in the dynamic streaming\nsetting, where points from a discrete Euclidean space $\\{1, 2, \\ldots,\n\\Delta\\}^d$ can be dynamically inserted to or deleted from the dataset. For\nthis problem, we provide a one-pass coreset construction algorithm using space\n$\\tilde{O}(k\\cdot \\mathrm{poly}(d, \\log\\Delta))$, where $k$ is the target\nnumber of centers. To our knowledge, this is the first dynamic geometric data\nstream algorithm for $k$-means using space polynomial in dimension and nearly\noptimal (linear) in $k$.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 19:07:51 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 18:47:20 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Hu", "Wei", ""], ["Song", "Zhao", ""], ["Yang", "Lin F.", ""], ["Zhong", "Peilin", ""]]}, {"id": "1802.00518", "submitter": "Anna Ma", "authors": "Saiprasad Ravishankar, Anna Ma, Deanna Needell", "title": "Analysis of Fast Alternating Minimization for Structured Dictionary\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods exploiting sparsity have been popular in imaging and signal\nprocessing applications including compression, denoising, and imaging inverse\nproblems. Data-driven approaches such as dictionary learning and transform\nlearning enable one to discover complex image features from datasets and\nprovide promising performance over analytical models. Alternating minimization\nalgorithms have been particularly popular in dictionary or transform learning.\nIn this work, we study the properties of alternating minimization for\nstructured (unitary) sparsifying operator learning. While the algorithm\nconverges to the stationary points of the non-convex problem in general, we\nprove rapid local linear convergence to the underlying generative model under\nmild assumptions. Our experiments show that the unitary operator learning\nalgorithm is robust to initialization.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 23:49:46 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Ravishankar", "Saiprasad", ""], ["Ma", "Anna", ""], ["Needell", "Deanna", ""]]}, {"id": "1802.00530", "submitter": "Phillip Alexander Jang", "authors": "Phillip A. Jang, Andrew E. Loeb, Matthew B. Davidow, Andrew Gordon\n  Wilson", "title": "Scalable L\\'evy Process Priors for Spectral Kernel Learning", "comments": "Appears in Advances in Neural Information Processing Systems 30\n  (NIPS), 2017", "journal-ref": "Advances in Neural Information Processing Systems 30 (NIPS), 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are rich distributions over functions, with generalization\nproperties determined by a kernel function. When used for long-range\nextrapolation, predictions are particularly sensitive to the choice of kernel\nparameters. It is therefore critical to account for kernel uncertainty in our\npredictive distributions. We propose a distribution over kernels formed by\nmodelling a spectral mixture density with a L\\'evy process. The resulting\ndistribution has support for all stationary covariances--including the popular\nRBF, periodic, and Mat\\'ern kernels--combined with inductive biases which\nenable automatic and data efficient learning, long-range extrapolation, and\nstate of the art predictive performance. The proposed model also presents an\napproach to spectral regularization, as the L\\'evy process introduces a\nsparsity-inducing prior over mixture components, allowing automatic selection\nover model order and pruning of extraneous components. We exploit the algebraic\nstructure of the proposed process for $\\mathcal{O}(n)$ training and\n$\\mathcal{O}(1)$ predictions. We perform extrapolations having reasonable\nuncertainty estimates on several benchmarks, show that the proposed model can\nrecover flexible ground truth covariances and that it is robust to errors in\ninitialization.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 01:40:46 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Jang", "Phillip A.", ""], ["Loeb", "Andrew E.", ""], ["Davidow", "Matthew B.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1802.00541", "submitter": "Brian Ruttenberg", "authors": "Michael Harradon, Jeff Druce, Brian Ruttenberg", "title": "Causal Learning and Explanation of Deep Neural Networks via Autoencoded\n  Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are complex and opaque. As they enter application in a\nvariety of important and safety critical domains, users seek methods to explain\ntheir output predictions. We develop an approach to explaining deep neural\nnetworks by constructing causal models on salient concepts contained in a CNN.\nWe develop methods to extract salient concepts throughout a target network by\nusing autoencoders trained to extract human-understandable representations of\nnetwork activations. We then build a bayesian causal model using these\nextracted concepts as variables in order to explain image classification.\nFinally, we use this causal model to identify and visualize features with\nsignificant causal influence on final classification.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 02:24:24 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Harradon", "Michael", ""], ["Druce", "Jeff", ""], ["Ruttenberg", "Brian", ""]]}, {"id": "1802.00543", "submitter": "Marinka Zitnik", "authors": "Marinka Zitnik, Monica Agrawal, Jure Leskovec", "title": "Modeling polypharmacy side effects with graph convolutional networks", "comments": "Presented at ISMB 2018", "journal-ref": "Bioinformatics, 34:13, 457-466, 2018", "doi": "10.1093/bioinformatics/bty294", "report-no": null, "categories": "cs.LG q-bio.MN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of drug combinations, termed polypharmacy, is common to treat\npatients with complex diseases and co-existing conditions. However, a major\nconsequence of polypharmacy is a much higher risk of adverse side effects for\nthe patient. Polypharmacy side effects emerge because of drug-drug\ninteractions, in which activity of one drug may change if taken with another\ndrug. The knowledge of drug interactions is limited because these complex\nrelationships are rare, and are usually not observed in relatively small\nclinical testing. Discovering polypharmacy side effects thus remains an\nimportant challenge with significant implications for patient mortality. Here,\nwe present Decagon, an approach for modeling polypharmacy side effects. The\napproach constructs a multimodal graph of protein-protein interactions,\ndrug-protein target interactions, and the polypharmacy side effects, which are\nrepresented as drug-drug interactions, where each side effect is an edge of a\ndifferent type. Decagon is developed specifically to handle such multimodal\ngraphs with a large number of edge types. Our approach develops a new graph\nconvolutional neural network for multirelational link prediction in multimodal\nnetworks. Decagon predicts the exact side effect, if any, through which a given\ndrug combination manifests clinically. Decagon accurately predicts polypharmacy\nside effects, outperforming baselines by up to 69%. We find that it\nautomatically learns representations of side effects indicative of\nco-occurrence of polypharmacy in patients. Furthermore, Decagon models\nparticularly well side effects with a strong molecular basis, while on\npredominantly non-molecular side effects, it achieves good performance because\nof effective sharing of model parameters across edge types. Decagon creates\nopportunities to use large pharmacogenomic and patient data to flag and\nprioritize side effects for follow-up analysis.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 02:43:29 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 21:39:44 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Zitnik", "Marinka", ""], ["Agrawal", "Monica", ""], ["Leskovec", "Jure", ""]]}, {"id": "1802.00560", "submitter": "Xuan Liu", "authors": "Xuan Liu, Xiaoguang Wang, Stan Matwin", "title": "Interpretable Deep Convolutional Neural Networks via Meta-learning", "comments": "9 pages, 9 figures, 2018 International Joint Conference on Neural\n  Networks, in press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model interpretability is a requirement in many applications in which crucial\ndecisions are made by users relying on a model's outputs. The recent movement\nfor \"algorithmic fairness\" also stipulates explainability, and therefore\ninterpretability of learning models. And yet the most successful contemporary\nMachine Learning approaches, the Deep Neural Networks, produce models that are\nhighly non-interpretable. We attempt to address this challenge by proposing a\ntechnique called CNN-INTE to interpret deep Convolutional Neural Networks (CNN)\nvia meta-learning. In this work, we interpret a specific hidden layer of the\ndeep CNN model on the MNIST image dataset. We use a clustering algorithm in a\ntwo-level structure to find the meta-level training data and Random Forest as\nbase learning algorithms to generate the meta-level test data. The\ninterpretation results are displayed visually via diagrams, which clearly\nindicates how a specific test instance is classified. Our method achieves\nglobal interpretation for all the test instances without sacrificing the\naccuracy obtained by the original deep CNN model. This means our model is\nfaithful to the deep CNN model, which leads to reliable interpretations.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 05:09:10 GMT"}, {"version": "v2", "created": "Sun, 19 Aug 2018 03:20:07 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Liu", "Xuan", ""], ["Wang", "Xiaoguang", ""], ["Matwin", "Stan", ""]]}, {"id": "1802.00662", "submitter": "Thai Hung Le", "authors": "Hung Le, Truyen Tran and Svetha Venkatesh", "title": "Dual Memory Neural Computer for Asynchronous Two-view Sequential\n  Learning", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the core tasks in multi-view learning is to capture relations among\nviews. For sequential data, the relations not only span across views, but also\nextend throughout the view length to form long-term intra-view and inter-view\ninteractions. In this paper, we present a new memory augmented neural network\nmodel that aims to model these complex interactions between two asynchronous\nsequential views. Our model uses two encoders for reading from and writing to\ntwo external memories for encoding input views. The intra-view interactions and\nthe long-term dependencies are captured by the use of memories during this\nencoding process. There are two modes of memory accessing in our system:\nlate-fusion and early-fusion, corresponding to late and early inter-view\ninteractions. In the late-fusion mode, the two memories are separated,\ncontaining only view-specific contents. In the early-fusion mode, the two\nmemories share the same addressing space, allowing cross-memory accessing. In\nboth cases, the knowledge from the memories will be combined by a decoder to\nmake predictions over the output space. The resulting dual memory neural\ncomputer is demonstrated on a comprehensive set of experiments, including a\nsynthetic task of summing two sequences and the tasks of drug prescription and\ndisease progression in healthcare. The results demonstrate competitive\nperformance over both traditional algorithms and deep learning methods designed\nfor multi-view problems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 12:32:29 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 03:19:38 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Le", "Hung", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1802.00673", "submitter": "Florian Schmidt", "authors": "Florian Schmidt and Mathias Niepert and Felipe Huici", "title": "Representation Learning for Resource Usage Prediction", "comments": "3 pages, 2 figures, SysML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating a model of a computer system that can be used for tasks such as\npredicting future resource usage and detecting anomalies is a challenging\nproblem. Most current systems rely on heuristics and overly simplistic\nassumptions about the workloads and system statistics. These heuristics are\ntypically a one-size-fits-all solution so as to be applicable in a wide range\nof applications and systems environments.\n  With this paper, we present our ongoing work of integrating systems telemetry\nranging from standard resource usage statistics to kernel and library calls of\napplications into a machine learning model. Intuitively, such a ML model\napproximates, at any point in time, the state of a system and allows us to\nsolve tasks such as resource usage prediction and anomaly detection. To achieve\nthis goal, we leverage readily-available information that does not require any\nchanges to the applications run on the system. We train recurrent neural\nnetworks to learn a model of the system under consideration. As a proof of\nconcept, we train models specifically to predict future resource usage of\nrunning applications.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 13:21:13 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Schmidt", "Florian", ""], ["Niepert", "Mathias", ""], ["Huici", "Felipe", ""]]}, {"id": "1802.00680", "submitter": "William Wilkinson", "authors": "William J. Wilkinson, Joshua D. Reiss, Dan Stowell", "title": "A Generative Model for Natural Sounds Based on Latent Force Modelling", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in analysis of subband amplitude envelopes of natural sounds\nhave resulted in convincing synthesis, showing subband amplitudes to be a\ncrucial component of perception. Probabilistic latent variable analysis is\nparticularly revealing, but existing approaches don't incorporate prior\nknowledge about the physical behaviour of amplitude envelopes, such as\nexponential decay and feedback. We use latent force modelling, a probabilistic\nlearning paradigm that incorporates physical knowledge into Gaussian process\nregression, to model correlation across spectral subband envelopes. We augment\nthe standard latent force model approach by explicitly modelling correlations\nover multiple time steps. Incorporating this prior knowledge strengthens the\ninterpretation of the latent functions as the source that generated the signal.\nWe examine this interpretation via an experiment which shows that sounds\ngenerated by sampling from our probabilistic model are perceived to be more\nrealistic than those generated by similar models based on nonnegative matrix\nfactorisation, even in cases where our model is outperformed from a\nreconstruction error perspective.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 13:34:46 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 16:03:38 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Wilkinson", "William J.", ""], ["Reiss", "Joshua D.", ""], ["Stowell", "Dan", ""]]}, {"id": "1802.00688", "submitter": "Malika Bendechache", "authors": "Malika Bendechache, Nhien-An Le-Khac and M-Tahar Kechadi", "title": "Hierarchical Aggregation Approach for Distributed clustering of spatial\n  datasets", "comments": "6 pages. arXiv admin note: substantial text overlap with\n  arXiv:1704.03421", "journal-ref": null, "doi": "10.1109/ICDMW.2016.0158", "report-no": null, "categories": "cs.DB cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new approach of distributed clustering for\nspatial datasets, based on an innovative and efficient aggregation technique.\nThis distributed approach consists of two phases: 1) local clustering phase,\nwhere each node performs a clustering on its local data, 2) aggregation phase,\nwhere the local clusters are aggregated to produce global clusters. This\napproach is characterised by the fact that the local clusters are represented\nin a simple and efficient way. And The aggregation phase is designed in such a\nway that the final clusters are compact and accurate while the overall process\nis efficient in both response time and memory allocation. We evaluated the\napproach with different datasets and compared it to well-known clustering\ntechniques. The experimental results show that our approach is very promising\nand outperforms all those algorithms\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 12:50:59 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Bendechache", "Malika", ""], ["Le-Khac", "Nhien-An", ""], ["Kechadi", "M-Tahar", ""]]}, {"id": "1802.00748", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio", "title": "Short-term Memory of Deep RNN", "comments": "This is a pre-print (pre-review) version of the paper accepted for\n  presentation at the 26th European Symposium on Artificial Neural Networks,\n  Computational Intelligence and Machine Learning (ESANN), Bruges (Belgium),\n  25-27 April 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extension of deep learning towards temporal data processing is gaining an\nincreasing research interest. In this paper we investigate the properties of\nstate dynamics developed in successive levels of deep recurrent neural networks\n(RNNs) in terms of short-term memory abilities. Our results reveal interesting\ninsights that shed light on the nature of layering as a factor of RNN design.\nNoticeably, higher layers in a hierarchically organized RNN architecture\nresults to be inherently biased towards longer memory spans even prior to\ntraining of the recurrent connections. Moreover, in the context of Reservoir\nComputing framework, our analysis also points out the benefit of a layered\nrecurrent organization as an efficient approach to improve the memory skills of\nreservoir models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 16:14:59 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Gallicchio", "Claudio", ""]]}, {"id": "1802.00810", "submitter": "Tianwei Yue", "authors": "Tianwei Yue, Haohan Wang", "title": "Deep Learning for Genomics: A Concise Overview", "comments": "Invited chapter for Springer Book: Handbook of Deep Learning\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in genomic research such as high-throughput sequencing\ntechniques have driven modern genomic studies into \"big data\" disciplines. This\ndata explosion is constantly challenging conventional methods used in genomics.\nIn parallel with the urgent demand for robust algorithms, deep learning has\nsucceeded in a variety of fields such as vision, speech, and text processing.\nYet genomics entails unique challenges to deep learning since we are expecting\nfrom deep learning a superhuman intelligence that explores beyond our knowledge\nto interpret the genome. A powerful deep learning model should rely on\ninsightful utilization of task-specific knowledge. In this paper, we briefly\ndiscuss the strengths of different deep learning models from a genomic\nperspective so as to fit each particular task with a proper deep architecture,\nand remark on practical considerations of developing modern deep learning\narchitectures for genomics. We also provide a concise review of deep learning\napplications in various aspects of genomic research, as well as pointing out\npotential opportunities and obstacles for future genomics applications.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 12:50:25 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 15:23:01 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Yue", "Tianwei", ""], ["Wang", "Haohan", ""]]}, {"id": "1802.00822", "submitter": "Ruizhe Cai", "authors": "Ruizhe Cai, Ao Ren, Ning Liu, Caiwen Ding, Luhao Wang, Xuehai Qian,\n  Massoud Pedram, Yanzhi Wang", "title": "VIBNN: Hardware Acceleration of Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3173162.3173212", "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Neural Networks (BNNs) have been proposed to address the problem of\nmodel uncertainty in training and inference. By introducing weights associated\nwith conditioned probability distributions, BNNs are capable of resolving the\noverfitting issue commonly seen in conventional neural networks and allow for\nsmall-data training, through the variational inference process. Frequent usage\nof Gaussian random variables in this process requires a properly optimized\nGaussian Random Number Generator (GRNG). The high hardware cost of conventional\nGRNG makes the hardware implementation of BNNs challenging.\n  In this paper, we propose VIBNN, an FPGA-based hardware accelerator design\nfor variational inference on BNNs. We explore the design space for massive\namount of Gaussian variable sampling tasks in BNNs. Specifically, we introduce\ntwo high performance Gaussian (pseudo) random number generators: the RAM-based\nLinear Feedback Gaussian Random Number Generator (RLF-GRNG), which is inspired\nby the properties of binomial distribution and linear feedback logics; and the\nBayesian Neural Network-oriented Wallace Gaussian Random Number Generator. To\nachieve high scalability and efficient memory access, we propose a deep\npipelined accelerator architecture with fast execution and good hardware\nutilization. Experimental results demonstrate that the proposed VIBNN\nimplementations on an FPGA can achieve throughput of 321,543.4 Images/s and\nenergy efficiency upto 52,694.8 Images/J while maintaining similar accuracy as\nits software counterpart.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 19:26:59 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Cai", "Ruizhe", ""], ["Ren", "Ao", ""], ["Liu", "Ning", ""], ["Ding", "Caiwen", ""], ["Wang", "Luhao", ""], ["Qian", "Xuehai", ""], ["Pedram", "Massoud", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1802.00844", "submitter": "Amir Rosenfeld", "authors": "Amir Rosenfeld, John K. Tsotsos", "title": "Intriguing Properties of Randomly Weighted Networks: Generalizing While\n  Learning Next to Nothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks results in strong learned representations that\nshow good generalization capabilities. In most cases, training involves\niterative modification of all weights inside the network via back-propagation.\nIn Extreme Learning Machines, it has been suggested to set the first layer of a\nnetwork to fixed random values instead of learning it. In this paper, we\npropose to take this approach a step further and fix almost all layers of a\ndeep convolutional neural network, allowing only a small portion of the weights\nto be learned. As our experiments show, fixing even the majority of the\nparameters of the network often results in performance which is on par with the\nperformance of learning all of them. The implications of this intriguing\nproperty of deep neural networks are discussed and we suggest ways to harness\nit to create more robust representations.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 20:53:31 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Rosenfeld", "Amir", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1802.00850", "submitter": "Rohit  Tripathy", "authors": "Rohit Tripathy and Ilias Bilionis", "title": "Deep UQ: Learning deep neural network surrogate models for high\n  dimensional uncertainty quantification", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2018.08.036", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art computer codes for simulating real physical systems are\noften characterized by a vast number of input parameters. Performing\nuncertainty quantification (UQ) tasks with Monte Carlo (MC) methods is almost\nalways infeasible because of the need to perform hundreds of thousands or even\nmillions of forward model evaluations in order to obtain convergent statistics.\nOne, thus, tries to construct a cheap-to-evaluate surrogate model to replace\nthe forward model solver. For systems with large numbers of input parameters,\none has to deal with the curse of dimensionality - the exponential increase in\nthe volume of the input space, as the number of parameters increases linearly.\nIn this work, we demonstrate the use of deep neural networks (DNN) to construct\nsurrogate models for numerical simulators. We parameterize the structure of the\nDNN in a manner that lends the DNN surrogate the interpretation of recovering a\nlow dimensional nonlinear manifold. The model response is a parameterized\nnonlinear function of the low dimensional projections of the input. We think of\nthis low dimensional manifold as a nonlinear generalization of the notion of\nthe active subspace. Our approach is demonstrated with a problem on uncertainty\npropagation in a stochastic elliptic partial differential equation (SPDE) with\nuncertain diffusion coefficient. We deviate from traditional formulations of\nthe SPDE problem by not imposing a specific covariance structure on the random\ndiffusion coefficient. Instead, we attempt to solve a more challenging problem\nof learning a map between an arbitrary snapshot of the diffusion field and the\nresponse.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 21:20:17 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Tripathy", "Rohit", ""], ["Bilionis", "Ilias", ""]]}, {"id": "1802.00868", "submitter": "Yize Chen", "authors": "Yize Chen, Pan Li, Baosen Zhang", "title": "Bayesian Renewables Scenario Generation via Deep Generative Networks", "comments": "Paper accepted to Annual Conference on Information Sciences and\n  Systems (CISS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to generate renewable scenarios using Bayesian\nprobabilities by implementing the Bayesian generative adversarial\nnetwork~(Bayesian GAN), which is a variant of generative adversarial networks\nbased on two interconnected deep neural networks. By using a Bayesian\nformulation, generators can be constructed and trained to produce scenarios\nthat capture different salient modes in the data, allowing for better diversity\nand more accurate representation of the underlying physical process. Compared\nto conventional statistical models that are often hard to scale or sample from,\nthis method is model-free and can generate samples extremely efficiently. For\nvalidation, we use wind and solar times-series data from NREL integration data\nsets to train the Bayesian GAN. We demonstrate that proposed method is able to\ngenerate clusters of wind scenarios with different variance and mean value, and\nis able to distinguish and generate wind and solar scenarios simultaneously\neven if the historical data are intentionally mixed.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 22:24:17 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Chen", "Yize", ""], ["Li", "Pan", ""], ["Zhang", "Baosen", ""]]}, {"id": "1802.00891", "submitter": "Rui Xia", "authors": "Huihui He, Rui Xia", "title": "Joint Binary Neural Network for Multi-label Learning with Applications\n  to Emotion Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the deep learning techniques have achieved success in multi-label\nclassification due to its automatic representation learning ability and the\nend-to-end learning framework. Existing deep neural networks in multi-label\nclassification can be divided into two kinds: binary relevance neural network\n(BRNN) and threshold dependent neural network (TDNN). However, the former needs\nto train a set of isolate binary networks which ignore dependencies between\nlabels and have heavy computational load, while the latter needs an additional\nthreshold function mechanism to transform the multi-class probabilities to\nmulti-label outputs. In this paper, we propose a joint binary neural network\n(JBNN), to address these shortcomings. In JBNN, the representation of the text\nis fed to a set of logistic functions instead of a softmax function, and the\nmultiple binary classifications are carried out synchronously in one neural\nnetwork framework. Moreover, the relations between labels are captured via\ntraining on a joint binary cross entropy (JBCE) loss. To better meet\nmulti-label emotion classification, we further proposed to incorporate the\nprior label relations into the JBCE loss. The experimental results on the\nbenchmark dataset show that our model performs significantly better than the\nstate-of-the-art multi-label emotion classification methods, in both\nclassification performance and computational efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 01:42:32 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["He", "Huihui", ""], ["Xia", "Rui", ""]]}, {"id": "1802.00899", "submitter": "Sergio Valcarcel Macua", "authors": "Sergio Valcarcel Macua, Javier Zazo, Santiago Zazo", "title": "Learning Parametric Closed-Loop Policies for Markov Potential Games", "comments": "Presented at ICLR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent systems where agents interact among themselves and with a\nstochastic environment can be formalized as stochastic games. We study a\nsubclass named Markov potential games (MPGs) that appear often in economic and\nengineering applications when the agents share a common resource. We consider\nMPGs with continuous state-action variables, coupled constraints and nonconvex\nrewards. Previous analysis followed a variational approach that is only valid\nfor very simple cases (convex rewards, invertible dynamics, and no coupled\nconstraints); or considered deterministic dynamics and provided open-loop (OL)\nanalysis, studying strategies that consist in predefined action sequences,\nwhich are not optimal for stochastic environments. We present a closed-loop\n(CL) analysis for MPGs and consider parametric policies that depend on the\ncurrent state. We provide easily verifiable, sufficient and necessary\nconditions for a stochastic game to be an MPG, even for complex parametric\nfunctions (e.g., deep neural networks); and show that a closed-loop Nash\nequilibrium (NE) can be found (or at least approximated) by solving a related\noptimal control problem (OCP). This is useful since solving an OCP--which is a\nsingle-objective problem--is usually much simpler than solving the original set\nof coupled OCPs that form the game--which is a multiobjective control problem.\nThis is a considerable improvement over the previously standard approach for\nthe CL analysis of MPGs, which gives no approximate solution if no NE belongs\nto the chosen parametric family, and which is practical only for simple\nparametric forms. We illustrate the theoretical contributions with an example\nby applying our approach to a noncooperative communications engineering game.\nWe then solve the game with a deep reinforcement learning algorithm that learns\npolicies that closely approximates an exact variational NE of the game.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 02:56:54 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 11:23:55 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Macua", "Sergio Valcarcel", ""], ["Zazo", "Javier", ""], ["Zazo", "Santiago", ""]]}, {"id": "1802.00910", "submitter": "Ziqi Liu", "authors": "Ziqi Liu, Chaochao Chen, Longfei Li, Jun Zhou, Xiaolong Li, Le Song,\n  Yuan Qi", "title": "GeniePath: Graph Neural Networks with Adaptive Receptive Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present, GeniePath, a scalable approach for learning adaptive receptive\nfields of neural networks defined on permutation invariant graph data. In\nGeniePath, we propose an adaptive path layer consists of two complementary\nfunctions designed for breadth and depth exploration respectively, where the\nformer learns the importance of different sized neighborhoods, while the latter\nextracts and filters signals aggregated from neighbors of different hops away.\nOur method works in both transductive and inductive settings, and extensive\nexperiments compared with competitive methods show that our approaches yield\nstate-of-the-art results on large graphs.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 04:36:41 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 12:38:30 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 08:57:53 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Liu", "Ziqi", ""], ["Chen", "Chaochao", ""], ["Li", "Longfei", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Song", "Le", ""], ["Qi", "Yuan", ""]]}, {"id": "1802.00912", "submitter": "Zongwei Zhou", "authors": "Zongwei Zhou, Jae Y. Shin, Suryakanth R. Gurudu, Michael B. Gotway,\n  Jianming Liang", "title": "Active, Continual Fine Tuning of Convolutional Neural Networks for\n  Reducing Annotation Efforts", "comments": null, "journal-ref": null, "doi": "10.1016/j.media.2021.101997", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The splendid success of convolutional neural networks (CNNs) in computer\nvision is largely attributable to the availability of massive annotated\ndatasets, such as ImageNet and Places. However, in medical imaging, it is\nchallenging to create such large annotated datasets, as annotating medical\nimages is not only tedious, laborious, and time consuming, but it also demands\ncostly, specialty-oriented skills, which are not easily accessible. To\ndramatically reduce annotation cost, this paper presents a novel method to\nnaturally integrate active learning and transfer learning (fine-tuning) into a\nsingle framework, which starts directly with a pre-trained CNN to seek \"worthy\"\nsamples for annotation and gradually enhances the (fine-tuned) CNN via\ncontinual fine-tuning. We have evaluated our method using three distinct\nmedical imaging applications, demonstrating that it can reduce annotation\nefforts by at least half compared with random selection.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 05:01:17 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 02:13:28 GMT"}, {"version": "v3", "created": "Sat, 23 May 2020 18:03:48 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 00:19:51 GMT"}, {"version": "v5", "created": "Sat, 10 Apr 2021 22:38:32 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhou", "Zongwei", ""], ["Shin", "Jae Y.", ""], ["Gurudu", "Suryakanth R.", ""], ["Gotway", "Michael B.", ""], ["Liang", "Jianming", ""]]}, {"id": "1802.00923", "submitter": "Paul Pu Liang", "authors": "Amir Zadeh, Paul Pu Liang, Soujanya Poria, Prateek Vij, Erik Cambria,\n  Louis-Philippe Morency", "title": "Multi-attention Recurrent Network for Human Communication Comprehension", "comments": "AAAI 2018 Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human face-to-face communication is a complex multimodal signal. We use words\n(language modality), gestures (vision modality) and changes in tone (acoustic\nmodality) to convey our intentions. Humans easily process and understand\nface-to-face communication, however, comprehending this form of communication\nremains a significant challenge for Artificial Intelligence (AI). AI must\nunderstand each modality and the interactions between them that shape human\ncommunication. In this paper, we present a novel neural architecture for\nunderstanding human communication called the Multi-attention Recurrent Network\n(MARN). The main strength of our model comes from discovering interactions\nbetween modalities through time using a neural component called the\nMulti-attention Block (MAB) and storing them in the hybrid memory of a\nrecurrent component called the Long-short Term Hybrid Memory (LSTHM). We\nperform extensive comparisons on six publicly available datasets for multimodal\nsentiment analysis, speaker trait recognition and emotion recognition. MARN\nshows state-of-the-art performance on all the datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 06:29:17 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Zadeh", "Amir", ""], ["Liang", "Paul Pu", ""], ["Poria", "Soujanya", ""], ["Vij", "Prateek", ""], ["Cambria", "Erik", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1802.00924", "submitter": "Paul Pu Liang", "authors": "Minghai Chen, Sen Wang, Paul Pu Liang, Tadas Baltru\\v{s}aitis, Amir\n  Zadeh, Louis-Philippe Morency", "title": "Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement\n  Learning", "comments": "ICMI 2017 Oral Presentation, Honorable Mention Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of video sharing websites such as YouTube and\nFacebook, multimodal sentiment analysis has received increasing attention from\nthe scientific community. Contrary to previous works in multimodal sentiment\nanalysis which focus on holistic information in speech segments such as bag of\nwords representations and average facial expression intensity, we develop a\nnovel deep architecture for multimodal sentiment analysis that performs\nmodality fusion at the word level. In this paper, we propose the Gated\nMultimodal Embedding LSTM with Temporal Attention (GME-LSTM(A)) model that is\ncomposed of 2 modules. The Gated Multimodal Embedding alleviates the\ndifficulties of fusion when there are noisy modalities. The LSTM with Temporal\nAttention performs word level fusion at a finer fusion resolution between input\nmodalities and attends to the most important time steps. As a result, the\nGME-LSTM(A) is able to better model the multimodal structure of speech through\ntime and perform better sentiment comprehension. We demonstrate the\neffectiveness of this approach on the publicly-available Multimodal Corpus of\nSentiment Intensity and Subjectivity Analysis (CMU-MOSI) dataset by achieving\nstate-of-the-art sentiment classification and regression results. Qualitative\nanalysis on our model emphasizes the importance of the Temporal Attention Layer\nin sentiment prediction because the additional acoustic and visual modalities\nare noisy. We also demonstrate the effectiveness of the Gated Multimodal\nEmbedding in selectively filtering these noisy modalities out. Our results and\nanalysis open new areas in the study of sentiment analysis in human\ncommunication and provide new models for multimodal fusion.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 06:30:09 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Chen", "Minghai", ""], ["Wang", "Sen", ""], ["Liang", "Paul Pu", ""], ["Baltru\u0161aitis", "Tadas", ""], ["Zadeh", "Amir", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1802.00927", "submitter": "Paul Pu Liang", "authors": "Amir Zadeh, Paul Pu Liang, Navonil Mazumder, Soujanya Poria, Erik\n  Cambria, Louis-Philippe Morency", "title": "Memory Fusion Network for Multi-view Sequential Learning", "comments": "AAAI 2018 Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view sequential learning is a fundamental problem in machine learning\ndealing with multi-view sequences. In a multi-view sequence, there exists two\nforms of interactions between different views: view-specific interactions and\ncross-view interactions. In this paper, we present a new neural architecture\nfor multi-view sequential learning called the Memory Fusion Network (MFN) that\nexplicitly accounts for both interactions in a neural architecture and\ncontinuously models them through time. The first component of the MFN is called\nthe System of LSTMs, where view-specific interactions are learned in isolation\nthrough assigning an LSTM function to each view. The cross-view interactions\nare then identified using a special attention mechanism called the Delta-memory\nAttention Network (DMAN) and summarized through time with a Multi-view Gated\nMemory. Through extensive experimentation, MFN is compared to various proposed\napproaches for multi-view sequential learning on multiple publicly available\nbenchmark datasets. MFN outperforms all the existing multi-view approaches.\nFurthermore, MFN outperforms all current state-of-the-art models, setting new\nstate-of-the-art results for these multi-view datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 06:37:46 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Zadeh", "Amir", ""], ["Liang", "Paul Pu", ""], ["Mazumder", "Navonil", ""], ["Poria", "Soujanya", ""], ["Cambria", "Erik", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1802.00930", "submitter": "Dheevatsa Mudigere", "authors": "Dipankar Das, Naveen Mellempudi, Dheevatsa Mudigere, Dhiraj Kalamkar,\n  Sasikanth Avancha, Kunal Banerjee, Srinivas Sridharan, Karthik Vaidyanathan,\n  Bharat Kaul, Evangelos Georganas, Alexander Heinecke, Pradeep Dubey, Jesus\n  Corbal, Nikita Shustrov, Roma Dubtsov, Evarist Fomenko, Vadim Pirogov", "title": "Mixed Precision Training of Convolutional Neural Networks using Integer\n  Operations", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art (SOTA) for mixed precision training is dominated by\nvariants of low precision floating point operations, and in particular, FP16\naccumulating into FP32 Micikevicius et al. (2017). On the other hand, while a\nlot of research has also happened in the domain of low and mixed-precision\nInteger training, these works either present results for non-SOTA networks (for\ninstance only AlexNet for ImageNet-1K), or relatively small datasets (like\nCIFAR-10). In this work, we train state-of-the-art visual understanding neural\nnetworks on the ImageNet-1K dataset, with Integer operations on General Purpose\n(GP) hardware. In particular, we focus on Integer Fused-Multiply-and-Accumulate\n(FMA) operations which take two pairs of INT16 operands and accumulate results\ninto an INT32 output.We propose a shared exponent representation of tensors and\ndevelop a Dynamic Fixed Point (DFP) scheme suitable for common neural network\noperations. The nuances of developing an efficient integer convolution kernel\nis examined, including methods to handle overflow of the INT32 accumulator. We\nimplement CNN training for ResNet-50, GoogLeNet-v1, VGG-16 and AlexNet; and\nthese networks achieve or exceed SOTA accuracy within the same number of\niterations as their FP32 counterparts without any change in hyper-parameters\nand with a 1.8X improvement in end-to-end training throughput. To the best of\nour knowledge these results represent the first INT16 training results on GP\nhardware for ImageNet-1K dataset using SOTA CNNs and achieve highest reported\naccuracy using half-precision\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 07:01:48 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 18:02:58 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Das", "Dipankar", ""], ["Mellempudi", "Naveen", ""], ["Mudigere", "Dheevatsa", ""], ["Kalamkar", "Dhiraj", ""], ["Avancha", "Sasikanth", ""], ["Banerjee", "Kunal", ""], ["Sridharan", "Srinivas", ""], ["Vaidyanathan", "Karthik", ""], ["Kaul", "Bharat", ""], ["Georganas", "Evangelos", ""], ["Heinecke", "Alexander", ""], ["Dubey", "Pradeep", ""], ["Corbal", "Jesus", ""], ["Shustrov", "Nikita", ""], ["Dubtsov", "Roma", ""], ["Fomenko", "Evarist", ""], ["Pirogov", "Vadim", ""]]}, {"id": "1802.00981", "submitter": "Baihan Lin", "authors": "Baihan Lin, Djallel Bouneffouf, Guillermo Cecchi, Irina Rish", "title": "Contextual Bandit with Adaptive Feature Extraction", "comments": "IEEE ICDMW 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an online decision making setting known as contextual bandit\nproblem, and propose an approach for improving contextual bandit performance by\nusing an adaptive feature extraction (representation learning) based on online\nclustering. Our approach starts with an off-line pre-training on unlabeled\nhistory of contexts (which can be exploited by our approach, but not by the\nstandard contextual bandit), followed by an online selection and adaptation of\nencoders. Specifically, given an input sample (context), the proposed approach\nselects the most appropriate encoding function to extract a feature vector\nwhich becomes an input for a contextual bandit, and updates both the bandit and\nthe encoding function based on the context and on the feedback (reward). Our\nexperiments on a variety of datasets, and both in stationary and non-stationary\nenvironments of several kinds demonstrate clear advantages of the proposed\nadaptive representation learning over the standard contextual bandit based on\n\"raw\" input contexts.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 14:44:51 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 19:30:15 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 01:28:57 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2020 15:32:13 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lin", "Baihan", ""], ["Bouneffouf", "Djallel", ""], ["Cecchi", "Guillermo", ""], ["Rish", "Irina", ""]]}, {"id": "1802.01029", "submitter": "Michael Veale", "authors": "Michael Veale, Max Van Kleek, Reuben Binns", "title": "Fairness and Accountability Design Needs for Algorithmic Support in\n  High-Stakes Public Sector Decision-Making", "comments": "14 pages, 0 figures, ACM Conference on Human Factors in Computing\n  Systems (CHI'18), April 21--26, Montreal, Canada", "journal-ref": "Proceedings of the 2018 CHI Conference on Human Factors in\n  Computing Systems (2018) 440", "doi": "10.1145/3173574.3174014", "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Calls for heightened consideration of fairness and accountability in\nalgorithmically-informed public decisions---like taxation, justice, and child\nprotection---are now commonplace. How might designers support such human\nvalues? We interviewed 27 public sector machine learning practitioners across 5\nOECD countries regarding challenges understanding and imbuing public values\ninto their work. The results suggest a disconnect between organisational and\ninstitutional realities, constraints and needs, and those addressed by current\nresearch into usable, transparent and 'discrimination-aware' machine\nlearning---absences likely to undermine practical initiatives unless addressed.\nWe see design opportunities in this disconnect, such as in supporting the\ntracking of concept drift in secondary data sources, and in building usable\ntransparency tools to identify risks and incorporate domain knowledge, aimed\nboth at managers and at the 'street-level bureaucrats' on the frontlines of\npublic service. We conclude by outlining ethical challenges and future\ndirections for collaboration in these high-stakes applications.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 20:57:13 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Veale", "Michael", ""], ["Van Kleek", "Max", ""], ["Binns", "Reuben", ""]]}, {"id": "1802.01034", "submitter": "Himani Arora", "authors": "Himani Arora, Rajath Kumar, Jason Krone, Chong Li", "title": "Multi-task Learning for Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reliable and effective multi-task learning is a prerequisite for the\ndevelopment of robotic agents that can quickly learn to accomplish related,\neveryday tasks. However, in the reinforcement learning domain, multi-task\nlearning has not exhibited the same level of success as in other domains, such\nas computer vision. In addition, most reinforcement learning research on\nmulti-task learning has been focused on discrete action spaces, which are not\nused for robotic control in the real-world. In this work, we apply multi-task\nlearning methods to continuous action spaces and benchmark their performance on\na series of simulated continuous control tasks. Most notably, we show that\nmulti-task learning outperforms our baselines and alternative knowledge sharing\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 21:20:03 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Arora", "Himani", ""], ["Kumar", "Rajath", ""], ["Krone", "Jason", ""], ["Li", "Chong", ""]]}, {"id": "1802.01059", "submitter": "Naveen Sai Madiraju", "authors": "Naveen Sai Madiraju, Seid M. Sadat, Dimitry Fisher, Homa Karimabadi", "title": "Deep Temporal Clustering : Fully Unsupervised Learning of Time-Domain\n  Features", "comments": "11 pages, 4 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning of time series data, also known as temporal clustering,\nis a challenging problem in machine learning. Here we propose a novel\nalgorithm, Deep Temporal Clustering (DTC), to naturally integrate\ndimensionality reduction and temporal clustering into a single end-to-end\nlearning framework, fully unsupervised. The algorithm utilizes an autoencoder\nfor temporal dimensionality reduction and a novel temporal clustering layer for\ncluster assignment. Then it jointly optimizes the clustering objective and the\ndimensionality reduction objec tive. Based on requirement and application, the\ntemporal clustering layer can be customized with any temporal similarity\nmetric. Several similarity metrics and state-of-the-art algorithms are\nconsidered and compared. To gain insight into temporal features that the\nnetwork has learned for its clustering, we apply a visualization method that\ngenerates a region of interest heatmap for the time series. The viability of\nthe algorithm is demonstrated using time series data from diverse domains,\nranging from earthquakes to spacecraft sensor data. In each case, we show that\nthe proposed algorithm outperforms traditional methods. The superior\nperformance is attributed to the fully integrated temporal dimensionality\nreduction and clustering criterion.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 02:18:25 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Madiraju", "Naveen Sai", ""], ["Sadat", "Seid M.", ""], ["Fisher", "Dimitry", ""], ["Karimabadi", "Homa", ""]]}, {"id": "1802.01071", "submitter": "Mohamed Ishmael Belghazi", "authors": "Mohamed Ishmael Belghazi, Sai Rajeswar, Olivier Mastropietro, Negar\n  Rostamzadeh, Jovana Mitrovic and Aaron Courville", "title": "Hierarchical Adversarially Learned Inference", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel hierarchical generative model with a simple Markovian\nstructure and a corresponding inference model. Both the generative and\ninference model are trained using the adversarial learning paradigm. We\ndemonstrate that the hierarchical structure supports the learning of\nprogressively more abstract representations as well as providing semantically\nmeaningful reconstructions with different levels of fidelity. Furthermore, we\nshow that minimizing the Jensen-Shanon divergence between the generative and\ninference network is enough to minimize the reconstruction error. The resulting\nsemantically meaningful hierarchical latent structure discovery is exemplified\non the CelebA dataset. There, we show that the features learned by our model in\nan unsupervised way outperform the best handcrafted features. Furthermore, the\nextracted features remain competitive when compared to several recent deep\nsupervised approaches on an attribute prediction task on CelebA. Finally, we\nleverage the model's inference network to achieve state-of-the-art performance\non a semi-supervised variant of the MNIST digit classification task.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 04:49:18 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Belghazi", "Mohamed Ishmael", ""], ["Rajeswar", "Sai", ""], ["Mastropietro", "Olivier", ""], ["Rostamzadeh", "Negar", ""], ["Mitrovic", "Jovana", ""], ["Courville", "Aaron", ""]]}, {"id": "1802.01096", "submitter": "Nathalia Moraes do Nascimento", "authors": "Nathalia Nascimento, Carlos Lucena, Paulo Alencar and Donald Cowan", "title": "Software Engineers vs. Machine Learning Algorithms: An Empirical Study\n  Assessing Performance and Reuse Tasks", "comments": "22 pages. To be submitted to IEEE Transactions on Software\n  Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.HC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several papers have recently contained reports on applying machine learning\n(ML) to the automation of software engineering (SE) tasks, such as project\nmanagement, modeling and development. However, there appear to be no approaches\ncomparing how software engineers fare against machine-learning algorithms as\napplied to specific software development tasks. Such a comparison is essential\nto gain insight into which tasks are better performed by humans and which by\nmachine learning and how cooperative work or human-in-the-loop processes can be\nimplemented more effectively. In this paper, we present an empirical study that\ncompares how software engineers and machine-learning algorithms perform and\nreuse tasks. The empirical study involves the synthesis of the control\nstructure of an autonomous streetlight application. Our approach consists of\nfour steps. First, we solved the problem using machine learning to determine\nspecific performance and reuse tasks. Second, we asked software engineers with\ndifferent domain knowledge levels to provide a solution to the same tasks.\nThird, we compared how software engineers fare against machine-learning\nalgorithms when accomplishing the performance and reuse tasks based on criteria\nsuch as energy consumption and safety. Finally, we analyzed the results to\nunderstand which tasks are better performed by either humans or algorithms so\nthat they can work together more effectively. Such an understanding and the\nresulting human-in-the-loop approaches, which take into account the strengths\nand weaknesses of humans and machine-learning algorithms, are fundamental not\nonly to provide a basis for cooperative work in support of software\nengineering, but also, in other areas.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 09:38:48 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 21:32:02 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Nascimento", "Nathalia", ""], ["Lucena", "Carlos", ""], ["Alencar", "Paulo", ""], ["Cowan", "Donald", ""]]}, {"id": "1802.01212", "submitter": "Jose Manuel Zorrilla Matilla", "authors": "Arushi Gupta, Jos\\'e Manuel Zorrilla Matilla, Daniel Hsu, Zolt\\'an\n  Haiman", "title": "Non-Gaussian information from weak lensing data via deep learning", "comments": "15 pages, 13 figures, accepted to PRD", "journal-ref": "Phys. Rev. D 97, 103515 (2018)", "doi": "10.1103/PhysRevD.97.103515", "report-no": null, "categories": "astro-ph.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weak lensing maps contain information beyond two-point statistics on small\nscales. Much recent work has tried to extract this information through a range\nof different observables or via nonlinear transformations of the lensing field.\nHere we train and apply a 2D convolutional neural network to simulated\nnoiseless lensing maps covering 96 different cosmological models over a range\nof {$\\Omega_m,\\sigma_8$}. Using the area of the confidence contour in the\n{$\\Omega_m,\\sigma_8$} plane as a figure-of-merit, derived from simulated\nconvergence maps smoothed on a scale of 1.0 arcmin, we show that the neural\nnetwork yields $\\approx 5 \\times$ tighter constraints than the power spectrum,\nand $\\approx 4 \\times$ tighter than the lensing peaks. Such gains illustrate\nthe extent to which weak lensing data encode cosmological information not\naccessible to the power spectrum or even other, non-Gaussian statistics such as\nlensing peaks.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 22:40:17 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 02:58:07 GMT"}, {"version": "v3", "created": "Tue, 1 May 2018 10:43:32 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Gupta", "Arushi", ""], ["Matilla", "Jos\u00e9 Manuel Zorrilla", ""], ["Hsu", "Daniel", ""], ["Haiman", "Zolt\u00e1n", ""]]}, {"id": "1802.01223", "submitter": "Samet Oymak", "authors": "Samet Oymak", "title": "Learning Compact Neural Networks with Regularization", "comments": "ICML 2018, 46 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proper regularization is critical for speeding up training, improving\ngeneralization performance, and learning compact models that are cost\nefficient. We propose and analyze regularized gradient descent algorithms for\nlearning shallow neural networks. Our framework is general and covers\nweight-sharing (convolutional networks), sparsity (network pruning), and\nlow-rank constraints among others. We first introduce covering dimension to\nquantify the complexity of the constraint set and provide insights on the\ngeneralization properties. Then, we show that proposed algorithms become\nwell-behaved and local linear convergence occurs once the amount of data\nexceeds the covering dimension. Overall, our results demonstrate that\nnear-optimal sample complexity is sufficient for efficient learning and\nillustrate how regularization can be beneficial to learn over-parameterized\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 00:22:26 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 23:28:22 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Oymak", "Samet", ""]]}, {"id": "1802.01239", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, Kun Zhang", "title": "Counting and Sampling from Markov Equivalent DAGs Using Clique Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A directed acyclic graph (DAG) is the most common graphical model for\nrepresenting causal relationships among a set of variables. When restricted to\nusing only observational data, the structure of the ground truth DAG is\nidentifiable only up to Markov equivalence, based on conditional independence\nrelations among the variables. Therefore, the number of DAGs equivalent to the\nground truth DAG is an indicator of the causal complexity of the underlying\nstructure--roughly speaking, it shows how many interventions or how much\nadditional information is further needed to recover the underlying DAG. In this\npaper, we propose a new technique for counting the number of DAGs in a Markov\nequivalence class. Our approach is based on the clique tree representation of\nchordal graphs. We show that in the case of bounded degree graphs, the proposed\nalgorithm is polynomial time. We further demonstrate that this technique can be\nutilized for uniform sampling from a Markov equivalence class, which provides a\nstochastic way to enumerate DAGs in the equivalence class and may be needed for\nfinding the best DAG or for causal inference given the equivalence class as\ninput. We also extend our counting and sampling method to the case where prior\nknowledge about the underlying DAG is available, and present applications of\nthis extension in causal experiment design and estimating the causal effect of\njoint interventions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 02:32:05 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 01:49:04 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Salehkaleybar", "Saber", ""], ["Kiyavash", "Negar", ""], ["Zhang", "Kun", ""]]}, {"id": "1802.01240", "submitter": "Rakesh Katuwal", "authors": "Rakesh Katuwal and P.N. Suganthan", "title": "Enhancing Multi-Class Classification of Random Forest using Random\n  Vector Functional Neural Network and Oblique Decision Surfaces", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both neural networks and decision trees are popular machine learning methods\nand are widely used to solve problems from diverse domains. These two\nclassifiers are commonly used base classifiers in an ensemble framework. In\nthis paper, we first present a new variant of oblique decision tree based on a\nlinear classifier, then construct an ensemble classifier based on the fusion of\na fast neural network, random vector functional link network and oblique\ndecision trees. Random Vector Functional Link Network has an elegant closed\nform solution with extremely short training time. The neural network partitions\neach training bag (obtained using bagging) at the root level into C subsets\nwhere C is the number of classes in the dataset and subsequently, C oblique\ndecision trees are trained on such partitions. The proposed method provides a\nrich insight into the data by grouping the confusing or hard to classify\nsamples for each class and thus, provides an opportunity to employ fine-grained\nclassification rule over the data. The performance of the ensemble classifier\nis evaluated on several multi-class datasets where it demonstrates a superior\nperformance compared to other state-of- the-art classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 02:42:39 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Katuwal", "Rakesh", ""], ["Suganthan", "P. N.", ""]]}, {"id": "1802.01284", "submitter": "Maya Kabkab", "authors": "Maya Kabkab, Pouya Samangouei, Rama Chellappa", "title": "Task-Aware Compressed Sensing with Generative Adversarial Networks", "comments": "Accepted for publication at the Thirty-Second AAAI Conference on\n  Artificial Intelligence (AAAI-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural network approaches have been widely adopted for\nmachine learning tasks, with applications in computer vision. More recently,\nunsupervised generative models based on neural networks have been successfully\napplied to model data distributions via low-dimensional latent spaces. In this\npaper, we use Generative Adversarial Networks (GANs) to impose structure in\ncompressed sensing problems, replacing the usual sparsity constraint. We\npropose to train the GANs in a task-aware fashion, specifically for\nreconstruction tasks. We also show that it is possible to train our model\nwithout using any (or much) non-compressed data. Finally, we show that the\nlatent space of the GAN carries discriminative information and can further be\nregularized to generate input features for general inference tasks. We\ndemonstrate the effectiveness of our method on a variety of reconstruction and\nclassification problems.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 06:56:55 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Kabkab", "Maya", ""], ["Samangouei", "Pouya", ""], ["Chellappa", "Rama", ""]]}, {"id": "1802.01379", "submitter": "Peilin Zhao", "authors": "Wenpeng Zhang, Xiao Lin, Peilin Zhao", "title": "Online Compact Convexified Factorization Machine", "comments": "11 pages, 2 figures, WWW2018 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization Machine (FM) is a supervised learning approach with a powerful\ncapability of feature engineering. It yields state-of-the-art performance in\nvarious batch learning tasks where all the training data is made available\nprior to the training. However, in real-world applications where the data\narrives sequentially in a streaming manner, the high cost of re-training with\nbatch learning algorithms has posed formidable challenges in the online\nlearning scenario. The initial challenge is that no prior formulations of FM\ncould fulfill the requirements in Online Convex Optimization (OCO) -- the\nparamount framework for online learning algorithm design. To address the\naforementioned challenge, we invent a new convexification scheme leading to a\nCompact Convexified FM (CCFM) that seamlessly meets the requirements in OCO.\nHowever for learning Compact Convexified FM (CCFM) in the online learning\nsetting, most existing algorithms suffer from expensive projection operations.\nTo address this subsequent challenge, we follow the general projection-free\nalgorithmic framework of Online Conditional Gradient and propose an Online\nCompact Convex Factorization Machine (OCCFM) algorithm that eschews the\nprojection operation with efficient linear optimization steps. In support of\nthe proposed OCCFM in terms of its theoretical foundation, we prove that the\ndeveloped algorithm achieves a sub-linear regret bound. To evaluate the\nempirical performance of OCCFM, we conduct extensive experiments on 6\nreal-world datasets for online recommendation and binary classification tasks.\nThe experimental results show that OCCFM outperforms the state-of-art online\nlearning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 13:24:56 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Zhang", "Wenpeng", ""], ["Lin", "Xiao", ""], ["Zhao", "Peilin", ""]]}, {"id": "1802.01396", "submitter": "Siyuan Ma", "authors": "Mikhail Belkin, Siyuan Ma, Soumik Mandal", "title": "To understand deep learning we need to understand kernel learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization performance of classifiers in deep learning has recently\nbecome a subject of intense study. Deep models, typically over-parametrized,\ntend to fit the training data exactly. Despite this \"overfitting\", they perform\nwell on test data, a phenomenon not yet fully understood.\n  The first point of our paper is that strong performance of overfitted\nclassifiers is not a unique feature of deep learning. Using six real-world and\ntwo synthetic datasets, we establish experimentally that kernel machines\ntrained to have zero classification or near zero regression error perform very\nwell on test data, even when the labels are corrupted with a high level of\nnoise. We proceed to give a lower bound on the norm of zero loss solutions for\nsmooth kernels, showing that they increase nearly exponentially with data size.\nWe point out that this is difficult to reconcile with the existing\ngeneralization bounds. Moreover, none of the bounds produce non-trivial results\nfor interpolating solutions.\n  Second, we show experimentally that (non-smooth) Laplacian kernels easily fit\nrandom labels, a finding that parallels results for ReLU neural networks. In\ncontrast, fitting noisy data requires many more epochs for smooth Gaussian\nkernels. Similar performance of overfitted Laplacian and Gaussian classifiers\non test, suggests that generalization is tied to the properties of the kernel\nfunction rather than the optimization process.\n  Certain key phenomena of deep learning are manifested similarly in kernel\nmethods in the modern \"overfitted\" regime. The combination of the experimental\nand theoretical results presented in this paper indicates a need for new\ntheoretical ideas for understanding properties of classical kernel methods. We\nargue that progress on understanding deep learning will be difficult until more\ntractable \"shallow\" kernel methods are better understood.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 14:14:28 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 18:19:04 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 21:25:54 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Belkin", "Mikhail", ""], ["Ma", "Siyuan", ""], ["Mandal", "Soumik", ""]]}, {"id": "1802.01414", "submitter": "Dong Liu", "authors": "Dong Liu and Chenyang Yang", "title": "A Learning-based Approach to Joint Content Caching and Recommendation at\n  Base Stations", "comments": "Accepted by IEEE GLOBECOM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation system is able to shape user demands, which can be used for\nboosting caching gain. In this paper, we jointly optimize content caching and\nrecommendation at base stations to maximize the caching gain meanwhile not\ncompromising the user preference. We first propose a model to capture the\nimpact of recommendation on user demands, which is controlled by a\nuser-specific psychological threshold. We then formulate a joint caching and\nrecommendation problem maximizing the successful offloading probability, which\nis a mixed integer programming problem. We develop a hierarchical iterative\nalgorithm to solve the problem when the threshold is known. Since the user\nthreshold is unknown in practice, we proceed to propose an $\\varepsilon$-greedy\nalgorithm to find the solution by learning the threshold via interactions with\nusers. Simulation results show that the proposed algorithms improve the\nsuccessful offloading probability compared with prior works with/without\nrecommendation. The $\\varepsilon$-greedy algorithm learns the user threshold\nquickly, and achieves more than $1-\\varepsilon$ of the performance obtained by\nthe algorithm with known threshold.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 01:54:58 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 06:57:11 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Liu", "Dong", ""], ["Yang", "Chenyang", ""]]}, {"id": "1802.01421", "submitter": "Carl-Johann Simon-Gabriel", "authors": "Carl-Johann Simon-Gabriel, Yann Ollivier, L\\'eon Bottou, Bernhard\n  Sch\\\"olkopf, David Lopez-Paz", "title": "First-order Adversarial Vulnerability of Neural Networks and Input\n  Dimension", "comments": "Paper previously called: \"Adversarial Vulnerability of Neural\n  Networks Increases with Input Dimension\". 9 pages main text and references,\n  11 pages appendix, 14 figures", "journal-ref": "Proceedings of ICML 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, neural networks were proven vulnerable to\nadversarial images: targeted but imperceptible image perturbations lead to\ndrastically different predictions. We show that adversarial vulnerability\nincreases with the gradients of the training objective when viewed as a\nfunction of the inputs. Surprisingly, vulnerability does not depend on network\ntopology: for many standard network architectures, we prove that at\ninitialization, the $\\ell_1$-norm of these gradients grows as the square root\nof the input dimension, leaving the networks increasingly vulnerable with\ngrowing image size. We empirically show that this dimension dependence persists\nafter either usual or robust training, but gets attenuated with higher\nregularization.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 14:36:44 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 13:26:43 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 19:01:10 GMT"}, {"version": "v4", "created": "Sun, 16 Jun 2019 20:55:06 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Simon-Gabriel", "Carl-Johann", ""], ["Ollivier", "Yann", ""], ["Bottou", "L\u00e9on", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1802.01433", "submitter": "Haonan Yu", "authors": "Haonan Yu, Haichao Zhang, Wei Xu", "title": "Interactive Grounded Language Acquisition and Generalization in a 2D\n  World", "comments": "ICLR 2018 (Figure 6 caption improved)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a virtual agent for learning language in a 2D maze-like world. The\nagent sees images of the surrounding environment, listens to a virtual teacher,\nand takes actions to receive rewards. It interactively learns the teacher's\nlanguage from scratch based on two language use cases: sentence-directed\nnavigation and question answering. It learns simultaneously the visual\nrepresentations of the world, the language, and the action control. By\ndisentangling language grounding from other computational routines and sharing\na concept detection function between language grounding and prediction, the\nagent reliably interpolates and extrapolates to interpret sentences that\ncontain new word combinations or new words missing from training sentences. The\nnew words are transferred from the answers of language prediction. Such a\nlanguage ability is trained and evaluated on a population of over 1.6 million\ndistinct sentences consisting of 119 object words, 8 color words, 9\nspatial-relation words, and 50 grammatical words. The proposed model\nsignificantly outperforms five comparison methods for interpreting zero-shot\nsentences. In addition, we demonstrate human-interpretable intermediate outputs\nof the model in the appendix.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 01:35:46 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 22:03:27 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2018 19:36:51 GMT"}, {"version": "v4", "created": "Mon, 13 Aug 2018 23:29:31 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Yu", "Haonan", ""], ["Zhang", "Haichao", ""], ["Xu", "Wei", ""]]}, {"id": "1802.01448", "submitter": "Deepak Vijaykeerthy", "authors": "Deepak Vijaykeerthy, Anshuman Suri, Sameep Mehta, Ponnurangam\n  Kumaraguru", "title": "Hardening Deep Neural Networks via Adversarial Model Cascades", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to malicious inputs crafted by an\nadversary to produce erroneous outputs. Works on securing neural networks\nagainst adversarial examples achieve high empirical robustness on simple\ndatasets such as MNIST. However, these techniques are inadequate when\nempirically tested on complex data sets such as CIFAR-10 and SVHN. Further,\nexisting techniques are designed to target specific attacks and fail to\ngeneralize across attacks. We propose the Adversarial Model Cascades (AMC) as a\nway to tackle the above inadequacies. Our approach trains a cascade of models\nsequentially where each model is optimized to be robust towards a mixture of\nmultiple attacks. Ultimately, it yields a single model which is secure against\na wide range of attacks; namely FGSM, Elastic, Virtual Adversarial\nPerturbations and Madry. On an average, AMC increases the model's empirical\nrobustness against various attacks simultaneously, by a significant margin (of\n6.225% for MNIST, 5.075% for SVHN and 2.65% for CIFAR10). At the same time, the\nmodel's performance on non-adversarial inputs is comparable to the\nstate-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 09:02:38 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 16:38:56 GMT"}, {"version": "v3", "created": "Mon, 12 Feb 2018 06:28:25 GMT"}, {"version": "v4", "created": "Sun, 4 Nov 2018 11:16:23 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Vijaykeerthy", "Deepak", ""], ["Suri", "Anshuman", ""], ["Mehta", "Sameep", ""], ["Kumaraguru", "Ponnurangam", ""]]}, {"id": "1802.01483", "submitter": "Xuhong Li", "authors": "Xuhong Li, Yves Grandvalet, Franck Davoine", "title": "Explicit Inductive Bias for Transfer Learning with Convolutional\n  Networks", "comments": "Accepted at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In inductive transfer learning, fine-tuning pre-trained convolutional\nnetworks substantially outperforms training from scratch. When using\nfine-tuning, the underlying assumption is that the pre-trained model extracts\ngeneric features, which are at least partially relevant for solving the target\ntask, but would be difficult to extract from the limited amount of data\navailable on the target task. However, besides the initialization with the\npre-trained model and the early stopping, there is no mechanism in fine-tuning\nfor retaining the features learned on the source task. In this paper, we\ninvestigate several regularization schemes that explicitly promote the\nsimilarity of the final solution with the initial model. We show the benefit of\nhaving an explicit inductive bias towards the initial model, and we eventually\nrecommend a simple $L^2$ penalty with the pre-trained model being a reference\nas the baseline of penalty for transfer learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 15:58:40 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 08:50:30 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Li", "Xuhong", ""], ["Grandvalet", "Yves", ""], ["Davoine", "Franck", ""]]}, {"id": "1802.01504", "submitter": "Wei Hu", "authors": "Simon S. Du, Wei Hu", "title": "Linear Convergence of the Primal-Dual Gradient Method for Convex-Concave\n  Saddle Point Problems without Strong Convexity", "comments": "Published in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the convex-concave saddle point problem $\\min_{x}\\max_{y}\nf(x)+y^\\top A x-g(y)$ where $f$ is smooth and convex and $g$ is smooth and\nstrongly convex. We prove that if the coupling matrix $A$ has full column rank,\nthe vanilla primal-dual gradient method can achieve linear convergence even if\n$f$ is not strongly convex. Our result generalizes previous work which either\nrequires $f$ and $g$ to be quadratic functions or requires proximal mappings\nfor both $f$ and $g$. We adopt a novel analysis technique that in each\niteration uses a \"ghost\" update as a reference, and show that the iterates in\nthe primal-dual gradient method converge to this \"ghost\" sequence. Using the\nsame technique we further give an analysis for the primal-dual stochastic\nvariance reduced gradient (SVRG) method for convex-concave saddle point\nproblems with a finite-sum structure.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 16:27:06 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2019 06:28:39 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Du", "Simon S.", ""], ["Hu", "Wei", ""]]}, {"id": "1802.01522", "submitter": "Soonam Lee", "authors": "Soonam Lee and Daekeun Kim", "title": "Background subtraction using the factored 3-way restricted Boltzmann\n  machines", "comments": "EECS545 (2011 Winter) class project report at the University of\n  Michigan. This is for archiving purpose", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a method for reconstructing the 3D model based on\ncontinuous sensory input. The robot can draw on extremely large data from the\nreal world using various sensors. However, the sensory inputs are usually too\nnoisy and high-dimensional data. It is very difficult and time consuming for\nrobot to process using such raw data when the robot tries to construct 3D\nmodel. Hence, there needs to be a method that can extract useful information\nfrom such sensory inputs. To address this problem our method utilizes the\nconcept of Object Semantic Hierarchy (OSH). Different from the previous work\nthat used this hierarchy framework, we extract the motion information using the\nDeep Belief Network technique instead of applying classical computer vision\napproaches. We have trained on two large sets of random dot images (10,000)\nwhich are translated and rotated, respectively, and have successfully extracted\nseveral bases that explain the translation and rotation motion. Based on this\ntranslation and rotation bases, background subtraction have become possible\nusing Object Semantic Hierarchy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 17:29:40 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Lee", "Soonam", ""], ["Kim", "Daekeun", ""]]}, {"id": "1802.01528", "submitter": "Terence Parr", "authors": "Terence Parr, Jeremy Howard", "title": "The Matrix Calculus You Need For Deep Learning", "comments": "PDF version of mobile/web friendly version\n  http://explained.ai/matrix-calculus/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an attempt to explain all the matrix calculus you need in order\nto understand the training of deep neural networks. We assume no math knowledge\nbeyond what you learned in calculus 1, and provide links to help you refresh\nthe necessary math where needed. Note that you do not need to understand this\nmaterial before you start learning to train and use deep learning in practice;\nrather, this material is for those who are already familiar with the basics of\nneural networks, and wish to deepen their understanding of the underlying math.\nDon't worry if you get stuck at some point along the way---just go back and\nreread the previous section, and try writing down and working through some\nexamples. And if you're still stuck, we're happy to answer your questions in\nthe Theory category at forums.fast.ai. Note: There is a reference section at\nthe end of the paper summarizing all the key matrix calculus rules and\nterminology discussed here. See related articles at http://explained.ai\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 17:37:59 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 17:35:28 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2018 17:36:34 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Parr", "Terence", ""], ["Howard", "Jeremy", ""]]}, {"id": "1802.01532", "submitter": "Blake Wulfe", "authors": "Blake Wulfe, Sunil Chintakindi, Sou-Cheng T. Choi, Rory\n  Hartong-Redden, Anuradha Kodali, Mykel J. Kochenderfer", "title": "Real-time Prediction of Intermediate-Horizon Automotive Collision Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced collision avoidance and driver hand-off systems can benefit from the\nability to accurately predict, in real time, the probability a vehicle will be\ninvolved in a collision within an intermediate horizon of 10 to 20 seconds. The\nrarity of collisions in real-world data poses a significant challenge to\ndeveloping this capability because, as we demonstrate empirically,\nintermediate-horizon risk prediction depends heavily on high-dimensional driver\nbehavioral features. As a result, a large amount of data is required to fit an\neffective predictive model. In this paper, we assess whether simulated data can\nhelp alleviate this issue. Focusing on highway driving, we present a three-step\napproach for generating data and fitting a predictive model capable of\nreal-time prediction. First, high-risk automotive scenes are generated using\nimportance sampling on a learned Bayesian network scene model. Second,\ncollision risk is estimated through Monte Carlo simulation. Third, a neural\nnetwork domain adaptation model is trained on real and simulated data to\naddress discrepancies between the two domains. Experiments indicate that\nsimulated data can mitigate issues resulting from collision rarity, thereby\nimproving risk prediction in real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 17:47:58 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Wulfe", "Blake", ""], ["Chintakindi", "Sunil", ""], ["Choi", "Sou-Cheng T.", ""], ["Hartong-Redden", "Rory", ""], ["Kodali", "Anuradha", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1802.01549", "submitter": "Zhezhi He", "authors": "Adnan Siraj Rakin, Zhezhi He, Boqing Gong, Deliang Fan", "title": "Blind Pre-Processing: A Robust Defense Method Against Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms and networks are vulnerable to perturbed inputs\nwhich is known as the adversarial attack. Many defense methodologies have been\ninvestigated to defend against such adversarial attack. In this work, we\npropose a novel methodology to defend the existing powerful attack model. We\nfor the first time introduce a new attacking scheme for the attacker and set a\npractical constraint for white box attack. Under this proposed attacking\nscheme, we present the best defense ever reported against some of the recent\nstrong attacks. It consists of a set of nonlinear function to process the input\ndata which will make it more robust over the adversarial attack. However, we\nmake this processing layer completely hidden from the attacker. Blind\npre-processing improves the white box attack accuracy of MNIST from 94.3\\% to\n98.7\\%. Even with increasing defense when others defenses completely fail,\nblind pre-processing remains one of the strongest ever reported. Another\nstrength of our defense is that it eliminates the need for adversarial training\nas it can significantly increase the MNIST accuracy without adversarial\ntraining as well. Additionally, blind pre-processing can also increase the\ninference accuracy in the face of a powerful attack on CIFAR-10 and SVHN data\nset as well without much sacrificing clean data accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 18:21:31 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 17:46:02 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Rakin", "Adnan Siraj", ""], ["He", "Zhezhi", ""], ["Gong", "Boqing", ""], ["Fan", "Deliang", ""]]}, {"id": "1802.01557", "submitter": "Chelsea Finn", "authors": "Tianhe Yu, Chelsea Finn, Annie Xie, Sudeep Dasari, Tianhao Zhang,\n  Pieter Abbeel, Sergey Levine", "title": "One-Shot Imitation from Observing Humans via Domain-Adaptive\n  Meta-Learning", "comments": "First two authors contributed equally. Video available at\n  https://sites.google.com/view/daml", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals are capable of learning a new behavior by observing others\nperform the skill just once. We consider the problem of allowing a robot to do\nthe same -- learning from a raw video pixels of a human, even when there is\nsubstantial domain shift in the perspective, environment, and embodiment\nbetween the robot and the observed human. Prior approaches to this problem have\nhand-specified how human and robot actions correspond and often relied on\nexplicit human pose detection systems. In this work, we present an approach for\none-shot learning from a video of a human by using human and robot\ndemonstration data from a variety of previous tasks to build up prior knowledge\nthrough meta-learning. Then, combining this prior knowledge and only a single\nvideo demonstration from a human, the robot can perform the task that the human\ndemonstrated. We show experiments on both a PR2 arm and a Sawyer arm,\ndemonstrating that after meta-learning, the robot can learn to place, push, and\npick-and-place new objects using just one video of a human performing the\nmanipulation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 18:36:19 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Yu", "Tianhe", ""], ["Finn", "Chelsea", ""], ["Xie", "Annie", ""], ["Dasari", "Sudeep", ""], ["Zhang", "Tianhao", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1802.01561", "submitter": "Lasse Espeholt", "authors": "Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Volodymir\n  Mnih, Tom Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, Shane\n  Legg, Koray Kavukcuoglu", "title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted\n  Actor-Learner Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we aim to solve a large collection of tasks using a single\nreinforcement learning agent with a single set of parameters. A key challenge\nis to handle the increased amount of data and extended training time. We have\ndeveloped a new distributed agent IMPALA (Importance Weighted Actor-Learner\nArchitecture) that not only uses resources more efficiently in single-machine\ntraining but also scales to thousands of machines without sacrificing data\nefficiency or resource utilisation. We achieve stable learning at high\nthroughput by combining decoupled acting and learning with a novel off-policy\ncorrection method called V-trace. We demonstrate the effectiveness of IMPALA\nfor multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from the\nDeepMind Lab environment (Beattie et al., 2016)) and Atari-57 (all available\nAtari games in Arcade Learning Environment (Bellemare et al., 2013a)). Our\nresults show that IMPALA is able to achieve better performance than previous\nagents with less data, and crucially exhibits positive transfer between tasks\nas a result of its multi-task approach.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 18:47:30 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 15:09:30 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 06:54:39 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Espeholt", "Lasse", ""], ["Soyer", "Hubert", ""], ["Munos", "Remi", ""], ["Simonyan", "Karen", ""], ["Mnih", "Volodymir", ""], ["Ward", "Tom", ""], ["Doron", "Yotam", ""], ["Firoiu", "Vlad", ""], ["Harley", "Tim", ""], ["Dunning", "Iain", ""], ["Legg", "Shane", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1802.01568", "submitter": "Lirong Yang", "authors": "Karim Said Barsim, Lirong Yang, Bin Yang", "title": "Selective Sampling and Mixture Models in Generative Adversarial Networks", "comments": "5pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a multi-generator extension to the adversarial\ntraining framework, in which the objective of each generator is to represent a\nunique component of a target mixture distribution. In the training phase, the\ngenerators cooperate to represent, as a mixture, the target distribution while\nmaintaining distinct manifolds. As opposed to traditional generative models,\ninference from a particular generator after training resembles selective\nsampling from a unique component in the target distribution. We demonstrate the\nfeasibility of the proposed architecture both analytically and with basic\nMulti-Layer Perceptron (MLP) models trained on the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 23:05:52 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Barsim", "Karim Said", ""], ["Yang", "Lirong", ""], ["Yang", "Bin", ""]]}, {"id": "1802.01569", "submitter": "Nicolas Masse", "authors": "Nicolas Y. Masse, Gregory D. Grant, David J. Freedman", "title": "Alleviating catastrophic forgetting using context-dependent gating and\n  synaptic stabilization", "comments": "Published in PNAS, https://www.pnas.org/content/115/44/E10467", "journal-ref": "Proceedings of the National Academy of Sciences, 115(44),\n  E10467-E10475", "doi": "10.1073/pnas.1803839115", "report-no": null, "categories": "cs.LG cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Humans and most animals can learn new tasks without forgetting old ones.\nHowever, training artificial neural networks (ANNs) on new tasks typically\ncause it to forget previously learned tasks. This phenomenon is the result of\n\"catastrophic forgetting\", in which training an ANN disrupts connection weights\nthat were important for solving previous tasks, degrading task performance.\nSeveral recent studies have proposed methods to stabilize connection weights of\nANNs that are deemed most important for solving a task, which helps alleviate\ncatastrophic forgetting. Here, drawing inspiration from algorithms that are\nbelieved to be implemented in vivo, we propose a complementary method: adding a\ncontext-dependent gating signal, such that only sparse, mostly non-overlapping\npatterns of units are active for any one task. This method is easy to\nimplement, requires little computational overhead, and allows ANNs to maintain\nhigh performance across large numbers of sequentially presented tasks when\ncombined with weight stabilization. This work provides another example of how\nneuroscience-inspired algorithms can benefit ANN design and capability.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 23:49:44 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 16:44:16 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Masse", "Nicolas Y.", ""], ["Grant", "Gregory D.", ""], ["Freedman", "David J.", ""]]}, {"id": "1802.01572", "submitter": "Federico Monti", "authors": "Federico Monti, Karl Otness, Michael M. Bronstein", "title": "MotifNet: a motif-based Graph Convolutional Network for directed graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning on graphs and in particular, graph convolutional neural\nnetworks, have recently attracted significant attention in the machine learning\ncommunity. Many of such techniques explore the analogy between the graph\nLaplacian eigenvectors and the classical Fourier basis, allowing to formulate\nthe convolution as a multiplication in the spectral domain. One of the key\ndrawback of spectral CNNs is their explicit assumption of an undirected graph,\nleading to a symmetric Laplacian matrix with orthogonal eigendecomposition. In\nthis work we propose MotifNet, a graph CNN capable of dealing with directed\ngraphs by exploiting local graph motifs. We present experimental evidence\nshowing the advantage of our approach on real data.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 03:07:20 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Monti", "Federico", ""], ["Otness", "Karl", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "1802.01616", "submitter": "Igor Fedorov", "authors": "Igor Fedorov, Bhaskar D. Rao", "title": "Re-Weighted Learning for Sparsifying Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the topic of sparsifying deep neural networks (DNN's).\nWhile DNN's are powerful models that achieve state-of-the-art performance on a\nlarge number of tasks, the large number of model parameters poses serious\nstorage and computational challenges. To combat these difficulties, a growing\nline of work focuses on pruning network weights without sacrificing\nperformance. We propose a general affine scaling transformation (AST) algorithm\nto sparsify DNN's. Our approach follows in the footsteps of popular sparse\nrecovery techniques, which have yet to be explored in the context of DNN's. We\ndescribe a principled framework for transforming densely connected DNN's into\nsparsely connected ones without sacrificing network performance. Unlike\nexisting methods, our approach is able to learn sparse connections at each\nlayer simultaneously, and achieves comparable pruning results on the\narchitecture tested.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 19:31:49 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Fedorov", "Igor", ""], ["Rao", "Bhaskar D.", ""]]}, {"id": "1802.01697", "submitter": "Yao-Yuan Yang", "authors": "Yao-Yuan Yang, Yi-An Lin, Hong-Min Chu and Hsuan-Tien Lin", "title": "Deep Learning with a Rethinking Structure for Multi-label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification (MLC) is an important class of machine learning\nproblems that come with a wide spectrum of applications, each demanding a\npossibly different evaluation criterion. When solving the MLC problems, we\ngenerally expect the learning algorithm to take the hidden correlation of the\nlabels into account to improve the prediction performance. Extracting the\nhidden correlation is generally a challenging task. In this work, we propose a\nnovel deep learning framework to better extract the hidden correlation with the\nhelp of the memory structure within recurrent neural networks. The memory\nstores the temporary guesses on the labels and effectively allows the framework\nto rethink about the goodness and correlation of the guesses before making the\nfinal prediction. Furthermore, the rethinking process makes it easy to adapt to\ndifferent evaluation criteria to match real-world application needs. In\nparticular, the framework can be trained in an end-to-end style with respect to\nany given MLC evaluation criteria. The end-to-end design can be seamlessly\ncombined with other deep learning techniques to conquer challenging MLC\nproblems like image tagging. Experimental results across many real-world data\nsets justify that the rethinking framework indeed improves MLC performance\nacross different evaluation criteria and leads to superior performance over\nstate-of-the-art MLC algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 21:27:59 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 07:27:59 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Yang", "Yao-Yuan", ""], ["Lin", "Yi-An", ""], ["Chu", "Hong-Min", ""], ["Lin", "Hsuan-Tien", ""]]}, {"id": "1802.01709", "submitter": "Zeyu You", "authors": "Zeyu You, Raviv Raich, Xiaoli Z. Fern, and Jinsub Kim", "title": "Weakly-supervised Dictionary Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2807422", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic modeling and inference framework for\ndiscriminative analysis dictionary learning under a weak supervision setting.\nDictionary learning approaches have been widely used for tasks such as\nlow-level signal denoising and restoration as well as high-level classification\ntasks, which can be applied to audio and image analysis. Synthesis dictionary\nlearning aims at jointly learning a dictionary and corresponding sparse\ncoefficients to provide accurate data representation. This approach is useful\nfor denoising and signal restoration, but may lead to sub-optimal\nclassification performance. By contrast, analysis dictionary learning provides\na transform that maps data to a sparse discriminative representation suitable\nfor classification. We consider the problem of analysis dictionary learning for\ntime-series data under a weak supervision setting in which signals are assigned\nwith a global label instead of an instantaneous label signal. We propose a\ndiscriminative probabilistic model that incorporates both label information and\nsparsity constraints on the underlying latent instantaneous label signal using\ncardinality control. We present the expectation maximization (EM) procedure for\nmaximum likelihood estimation (MLE) of the proposed model. To facilitate a\ncomputationally efficient E-step, we propose both a chain and a novel tree\ngraph reformulation of the graphical model. The performance of the proposed\nmodel is demonstrated on both synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 21:55:52 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["You", "Zeyu", ""], ["Raich", "Raviv", ""], ["Fern", "Xiaoli Z.", ""], ["Kim", "Jinsub", ""]]}, {"id": "1802.01737", "submitter": "Trevor Campbell", "authors": "Trevor Campbell, Tamara Broderick", "title": "Bayesian Coreset Construction via Greedy Iterative Geodesic Ascent", "comments": "Appearing in the 2018 International Conference on Machine Learning\n  (ICML). 13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coherent uncertainty quantification is a key strength of Bayesian methods.\nBut modern algorithms for approximate Bayesian posterior inference often\nsacrifice accurate posterior uncertainty estimation in the pursuit of\nscalability. This work shows that previous Bayesian coreset construction\nalgorithms---which build a small, weighted subset of the data that approximates\nthe full dataset---are no exception. We demonstrate that these algorithms scale\nthe coreset log-likelihood suboptimally, resulting in underestimated posterior\nuncertainty. To address this shortcoming, we develop greedy iterative geodesic\nascent (GIGA), a novel algorithm for Bayesian coreset construction that scales\nthe coreset log-likelihood optimally. GIGA provides geometric decay in\nposterior approximation error as a function of coreset size, and maintains the\nfast running time of its predecessors. The paper concludes with validation of\nGIGA on both synthetic and real datasets, demonstrating that it reduces\nposterior approximation error by orders of magnitude compared with previous\ncoreset constructions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 23:52:12 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 23:46:26 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Campbell", "Trevor", ""], ["Broderick", "Tamara", ""]]}, {"id": "1802.01744", "submitter": "Siddharth Reddy", "authors": "Siddharth Reddy, Anca D. Dragan, Sergey Levine", "title": "Shared Autonomy via Deep Reinforcement Learning", "comments": "Accepted to the Robotics: Science and Systems (RSS) 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In shared autonomy, user input is combined with semi-autonomous control to\nachieve a common goal. The goal is often unknown ex-ante, so prior work enables\nagents to infer the goal from user input and assist with the task. Such methods\ntend to assume some combination of knowledge of the dynamics of the\nenvironment, the user's policy given their goal, and the set of possible goals\nthe user might target, which limits their application to real-world scenarios.\nWe propose a deep reinforcement learning framework for model-free shared\nautonomy that lifts these assumptions. We use human-in-the-loop reinforcement\nlearning with neural network function approximation to learn an end-to-end\nmapping from environmental observation and user input to agent action values,\nwith task reward as the only form of supervision. This approach poses the\nchallenge of following user commands closely enough to provide the user with\nreal-time action feedback and thereby ensure high-quality user input, but also\ndeviating from the user's actions when they are suboptimal. We balance these\ntwo needs by discarding actions whose values fall below some threshold, then\nselecting the remaining action closest to the user's input. Controlled studies\nwith users (n = 12) and synthetic pilots playing a video game, and a pilot\nstudy with users (n = 4) flying a real quadrotor, demonstrate the ability of\nour algorithm to assist users with real-time control tasks in which the agent\ncannot directly access the user's private information through observations, but\nreceives a reward signal and user input that both depend on the user's intent.\nThe agent learns to assist the user without access to this private information,\nimplicitly inferring it from the user's input. This paper is a proof of concept\nthat illustrates the potential for deep reinforcement learning to enable\nflexible and practical assistive systems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 00:45:12 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 03:12:34 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Reddy", "Siddharth", ""], ["Dragan", "Anca D.", ""], ["Levine", "Sergey", ""]]}, {"id": "1802.01751", "submitter": "Wai Ming Tai", "authors": "Jeff M. Phillips, Wai Ming Tai", "title": "Near-Optimal Coresets of Kernel Density Estimates", "comments": "This paper is combined with arXiv:1710.04325", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct near-optimal coresets for kernel density estimates for points in\n$\\mathbb{R}^d$ when the kernel is positive definite. Specifically we show a\npolynomial time construction for a coreset of size $O(\\sqrt{d}/\\varepsilon\\cdot\n\\sqrt{\\log 1/\\varepsilon} )$, and we show a near-matching lower bound of size\n$\\Omega(\\min\\{\\sqrt{d}/\\varepsilon, 1/\\varepsilon^2\\})$. When $d\\geq\n1/\\varepsilon^2$, it is known that the size of coreset can be\n$O(1/\\varepsilon^2)$. The upper bound is a polynomial-in-$(1/\\varepsilon)$\nimprovement when $d \\in [3,1/\\varepsilon^2)$ and the lower bound is the first\nknown lower bound to depend on $d$ for this problem. Moreover, the upper bound\nrestriction that the kernel is positive definite is significant in that it\napplies to a wide-variety of kernels, specifically those most important for\nmachine learning. This includes kernels for information distances and the sinc\nkernel which can be negative.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 01:06:47 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 17:04:17 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 13:34:29 GMT"}, {"version": "v4", "created": "Fri, 29 Mar 2019 00:45:09 GMT"}, {"version": "v5", "created": "Thu, 11 Apr 2019 23:06:34 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Phillips", "Jeff M.", ""], ["Tai", "Wai Ming", ""]]}, {"id": "1802.01765", "submitter": "Xu Chen", "authors": "Xu Chen, Jiang Wang, Hao Ge", "title": "Training Generative Adversarial Networks via Primal-Dual Subgradient\n  Methods: A Lagrangian Perspective on GAN", "comments": "Accepted by Sixth International Conference on Learning\n  Representations (ICLR 2018). Xu Chen and Jiang Wang contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We relate the minimax game of generative adversarial networks (GANs) to\nfinding the saddle points of the Lagrangian function for a convex optimization\nproblem, where the discriminator outputs and the distribution of generator\noutputs play the roles of primal variables and dual variables, respectively.\nThis formulation shows the connection between the standard GAN training process\nand the primal-dual subgradient methods for convex optimization. The inherent\nconnection does not only provide a theoretical convergence proof for training\nGANs in the function space, but also inspires a novel objective function for\ntraining. The modified objective function forces the distribution of generator\noutputs to be updated along the direction according to the primal-dual\nsubgradient methods. A toy example shows that the proposed method is able to\nresolve mode collapse, which in this case cannot be avoided by the standard GAN\nor Wasserstein GAN. Experiments on both Gaussian mixture synthetic data and\nreal-world image datasets demonstrate the performance of the proposed method on\ngenerating diverse samples.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 02:31:43 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Chen", "Xu", ""], ["Wang", "Jiang", ""], ["Ge", "Hao", ""]]}, {"id": "1802.01772", "submitter": "Maxime Bouton", "authors": "Maxime Bouton, Kyle Julian, Alireza Nakhaei, Kikuo Fujimura, and Mykel\n  J. Kochenderfer", "title": "Decomposition Methods with Deep Corrections for Reinforcement Learning", "comments": null, "journal-ref": "Journal of Agents and Multi-Agent Systems (JAAMAS), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposition methods have been proposed to approximate solutions to large\nsequential decision making problems. In contexts where an agent interacts with\nmultiple entities, utility decomposition can be used to separate the global\nobjective into local tasks considering each individual entity independently. An\narbitrator is then responsible for combining the individual utilities and\nselecting an action in real time to solve the global problem. Although these\ntechniques can perform well empirically, they rely on strong assumptions of\nindependence between the local tasks and sacrifice the optimality of the global\nsolution. This paper proposes an approach that improves upon such approximate\nsolutions by learning a correction term represented by a neural network. We\ndemonstrate this approach on a fisheries management problem where multiple\nboats must coordinate to maximize their catch over time as well as on a\npedestrian avoidance problem for autonomous driving. In each problem,\ndecomposition methods can scale to multiple boats or pedestrians by using\nstrategies involving one entity. We verify empirically that the proposed\ncorrection method significantly improves the decomposition method and\noutperforms a policy trained on the full scale problem without utility\ndecomposition.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 03:02:22 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 19:54:27 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Bouton", "Maxime", ""], ["Julian", "Kyle", ""], ["Nakhaei", "Alireza", ""], ["Fujimura", "Kikuo", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1802.01808", "submitter": "Xiang Li", "authors": "Wenhai Wang, Xiang Li, Jian Yang, Tong Lu", "title": "Mixed Link Networks", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Basing on the analysis by revealing the equivalence of modern networks, we\nfind that both ResNet and DenseNet are essentially derived from the same \"dense\ntopology\", yet they only differ in the form of connection -- addition (dubbed\n\"inner link\") vs. concatenation (dubbed \"outer link\"). However, both two forms\nof connections have the superiority and insufficiency. To combine their\nadvantages and avoid certain limitations on representation learning, we present\na highly efficient and modularized Mixed Link Network (MixNet) which is\nequipped with flexible inner link and outer link modules. Consequently, ResNet,\nDenseNet and Dual Path Network (DPN) can be regarded as a special case of\nMixNet, respectively. Furthermore, we demonstrate that MixNets can achieve\nsuperior efficiency in parameter over the state-of-the-art architectures on\nmany competitive datasets like CIFAR-10/100, SVHN and ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 05:50:34 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Wang", "Wenhai", ""], ["Li", "Xiang", ""], ["Yang", "Jian", ""], ["Lu", "Tong", ""]]}, {"id": "1802.01812", "submitter": "Shuming Ma", "authors": "Junyang Lin, Shuming Ma, Qi Su, Xu Sun", "title": "Decoding-History-Based Adaptive Control of Attention for Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence model has proved successful in Neural\nMachine Translation (NMT). However, the attention without consideration of\ndecoding history, which includes the past information in the decoder and the\nattention mechanism, often causes much repetition. To address this problem, we\npropose the decoding-history-based Adaptive Control of Attention (ACA) for the\nNMT model. ACA learns to control the attention by keeping track of the decoding\nhistory and the current information with a memory vector, so that the model can\ntake the translated contents and the current information into consideration.\nExperiments on Chinese-English translation and the English-Vietnamese\ntranslation have demonstrated that our model significantly outperforms the\nstrong baselines. The analysis shows that our model is capable of generating\ntranslation with less repetition and higher accuracy. The code will be\navailable at https://github.com/lancopku\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 06:18:56 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Lin", "Junyang", ""], ["Ma", "Shuming", ""], ["Su", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "1802.01886", "submitter": "Weinan Zhang", "authors": "Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang,\n  Yong Yu", "title": "Texygen: A Benchmarking Platform for Text Generation Models", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Texygen, a benchmarking platform to support research on\nopen-domain text generation models. Texygen has not only implemented a majority\nof text generation models, but also covered a set of metrics that evaluate the\ndiversity, the quality and the consistency of the generated texts. The Texygen\nplatform could help standardize the research on text generation and facilitate\nthe sharing of fine-tuned open-source implementations among researchers for\ntheir work. As a consequence, this would help in improving the reproductivity\nand reliability of future research work in text generation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 11:30:32 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Zhu", "Yaoming", ""], ["Lu", "Sidi", ""], ["Zheng", "Lei", ""], ["Guo", "Jiaxian", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""], ["Yu", "Yong", ""]]}, {"id": "1802.01894", "submitter": "Boris Landa", "authors": "Boris Landa and Yoel Shkolnisky", "title": "The steerable graph Laplacian and its application to filtering image\n  data-sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, improvements in various image acquisition techniques gave\nrise to the need for adaptive processing methods, aimed particularly for large\ndatasets corrupted by noise and deformations. In this work, we consider\ndatasets of images sampled from a low-dimensional manifold (i.e. an\nimage-valued manifold), where the images can assume arbitrary planar rotations.\nTo derive an adaptive and rotation-invariant framework for processing such\ndatasets, we introduce a graph Laplacian (GL)-like operator over the dataset,\ntermed ${\\textit{steerable graph Laplacian}}$. Essentially, the steerable GL\nextends the standard GL by accounting for all (infinitely-many) planar\nrotations of all images. As it turns out, similarly to the standard GL, a\nproperly normalized steerable GL converges to the Laplace-Beltrami operator on\nthe low-dimensional manifold. However, the steerable GL admits an improved\nconvergence rate compared to the GL, where the improved convergence behaves as\nif the intrinsic dimension of the underlying manifold is lower by one.\nMoreover, it is shown that the steerable GL admits eigenfunctions of the form\nof Fourier modes (along the orbits of the images' rotations) multiplied by\neigenvectors of certain matrices, which can be computed efficiently by the FFT.\nFor image datasets corrupted by noise, we employ a subset of these\neigenfunctions to \"filter\" the dataset via a Fourier-like filtering scheme,\nessentially using all images and their rotations simultaneously. We demonstrate\nour filtering framework by de-noising simulated single-particle cryo-EM image\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 11:56:25 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 19:00:04 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Landa", "Boris", ""], ["Shkolnisky", "Yoel", ""]]}, {"id": "1802.01933", "submitter": "Riccardo Guidotti", "authors": "Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini,\n  Dino Pedreschi, Fosca Giannotti", "title": "A Survey Of Methods For Explaining Black Box Models", "comments": "This work is currently under review on an international journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years many accurate decision support systems have been\nconstructed as black boxes, that is as systems that hide their internal logic\nto the user. This lack of explanation constitutes both a practical and an\nethical issue. The literature reports many approaches aimed at overcoming this\ncrucial weakness sometimes at the cost of scarifying accuracy for\ninterpretability. The applications in which black box decision systems can be\nused are various, and each approach is typically developed to provide a\nsolution for a specific problem and, as a consequence, delineating explicitly\nor implicitly its own definition of interpretability and explanation. The aim\nof this paper is to provide a classification of the main problems addressed in\nthe literature with respect to the notion of explanation and the type of black\nbox system. Given a problem definition, a black box type, and a desired\nexplanation this survey should help the researcher to find the proposals more\nuseful for his own work. The proposed classification of approaches to open\nblack box models should also be useful for putting the many research open\nquestions in perspective.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 13:20:02 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 12:29:56 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 08:15:38 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Guidotti", "Riccardo", ""], ["Monreale", "Anna", ""], ["Ruggieri", "Salvatore", ""], ["Turini", "Franco", ""], ["Pedreschi", "Dino", ""], ["Giannotti", "Fosca", ""]]}, {"id": "1802.02032", "submitter": "Hui Su", "authors": "Xiaoyu Shen, Hui Su, Shuzi Niu and Vera Demberg", "title": "Improving Variational Encoder-Decoders in Dialogue Generation", "comments": "Accepted by AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational encoder-decoders (VEDs) have shown promising results in dialogue\ngeneration. However, the latent variable distributions are usually approximated\nby a much simpler model than the powerful RNN structure used for encoding and\ndecoding, yielding the KL-vanishing problem and inconsistent training\nobjective. In this paper, we separate the training step into two phases: The\nfirst phase learns to autoencode discrete texts into continuous embeddings,\nfrom which the second phase learns to generalize latent representations by\nreconstructing the encoded embedding. In this case, latent variables are\nsampled by transforming Gaussian noise through multi-layer perceptrons and are\ntrained with a separate VED model, which has the potential of realizing a much\nmore flexible distribution. We compare our model with current popular models\nand the experiment demonstrates substantial improvement in both metric-based\nand human evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 16:19:05 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Shen", "Xiaoyu", ""], ["Su", "Hui", ""], ["Niu", "Shuzi", ""], ["Demberg", "Vera", ""]]}, {"id": "1802.02046", "submitter": "Nariman Farsad", "authors": "Nariman Farsad and Andrea Goldsmith", "title": "Neural Network Detection of Data Sequences in Communication Systems", "comments": "Accepted for publication in IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2018.2868322", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider detection based on deep learning, and show it is possible to\ntrain detectors that perform well without any knowledge of the underlying\nchannel models. Moreover, when the channel model is known, we demonstrate that\nit is possible to train detectors that do not require channel state information\n(CSI). In particular, a technique we call a sliding bidirectional recurrent\nneural network (SBRNN) is proposed for detection where, after training, the\ndetector estimates the data in real-time as the signal stream arrives at the\nreceiver. We evaluate this algorithm, as well as other neural network (NN)\narchitectures, using the Poisson channel model, which is applicable to both\noptical and molecular communication systems. In addition, we also evaluate the\nperformance of this detection method applied to data sent over a molecular\ncommunication platform, where the channel model is difficult to model\nanalytically. We show that SBRNN is computationally efficient, and can perform\ndetection under various channel conditions without knowing the underlying\nchannel model. We also demonstrate that the bit error rate (BER) performance of\nthe proposed SBRNN detector is better than that of a Viterbi detector with\nimperfect CSI as well as that of other NN detectors that have been previously\nproposed. Finally, we show that the SBRNN can perform well in rapidly changing\nchannels, where the coherence time is on the order of a single symbol duration.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 01:22:21 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 19:38:39 GMT"}, {"version": "v3", "created": "Tue, 28 Aug 2018 02:09:13 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Farsad", "Nariman", ""], ["Goldsmith", "Andrea", ""]]}, {"id": "1802.02053", "submitter": "Marwa Hadj Salah", "authors": "Marwa Hadj Salah, Didier Schwab, Herv\\'e Blanchon and Mounir Zrigui", "title": "Syst\\`eme de traduction automatique statistique Anglais-Arabe", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation (MT) is the process of translating text written in a\nsource language into text in a target language. In this article, we present our\nEnglish-Arabic statistical machine translation system. First, we present the\ngeneral process for setting up a statistical machine translation system, then\nwe describe the tools as well as the different corpora we used to build our MT\nsystem. Our system was evaluated in terms of the BLUE score (24.51%)\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 16:36:44 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Salah", "Marwa Hadj", ""], ["Schwab", "Didier", ""], ["Blanchon", "Herv\u00e9", ""], ["Zrigui", "Mounir", ""]]}, {"id": "1802.02139", "submitter": "Karim Said Barsim", "authors": "Karim Said Barsim and Bin Yang", "title": "On the Feasibility of Generic Deep Disaggregation for Single-Load\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, and with the growing development of big energy datasets,\ndata-driven learning techniques began to represent a potential solution to the\nenergy disaggregation problem outperforming engineered and hand-crafted models.\nHowever, most proposed deep disaggregation models are load-dependent in the\nsense that either expert knowledge or a hyper-parameter optimization stage is\nrequired prior to training and deployment (normally for each load category)\neven upon acquisition and cleansing of aggregate and sub-metered data. In this\npaper, we present a feasibility study on the development of a generic\ndisaggregation model based on data-driven learning. Specifically, we present a\ngeneric deep disaggregation model capable of achieving state-of-art performance\nin load monitoring for a variety of load categories. The developed model is\nevaluated on the publicly available UK-DALE dataset with a moderately low\nsampling frequency and various domestic loads.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 20:59:36 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Barsim", "Karim Said", ""], ["Yang", "Bin", ""]]}, {"id": "1802.02147", "submitter": "Hanyuan Zhang", "authors": "Hanyuan Zhang, Hao Wu, Weiwei Sun, Baihua Zheng", "title": "DeepTravel: a Neural Network Based Travel Time Estimation Model with\n  Auxiliary Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the travel time of a path is of great importance to smart urban\nmobility. Existing approaches are either based on estimating the time cost of\neach road segment which are not able to capture many cross-segment complex\nfactors, or designed heuristically in a non-learning-based way which fail to\nutilize the existing abundant temporal labels of the data, i.e., the time stamp\nof each trajectory point. In this paper, we leverage on new development of deep\nneural networks and propose a novel auxiliary supervision model, namely\nDeepTravel, that can automatically and effectively extract different features,\nas well as make full use of the temporal labels of the trajectory data. We have\nconducted comprehensive experiments on real datasets to demonstrate the\nout-performance of DeepTravel over existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 16:08:06 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Zhang", "Hanyuan", ""], ["Wu", "Hao", ""], ["Sun", "Weiwei", ""], ["Zheng", "Baihua", ""]]}, {"id": "1802.02186", "submitter": "John Olafenwa", "authors": "John Olafenwa, Moses Olafenwa", "title": "FastNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inception and the Resnet family of Convolutional Neural Network\narchi-tectures have broken records in the past few years, but recent state of\nthe art models have also incurred very high computational cost in terms of\ntraining, inference and model size. Making the deployment of these models on\nEdge devices, impractical. In light of this, we present a new novel\narchitecture that is designed for high computational efficiency on both GPUs\nand CPUs, and is highly suited for deployment on Mobile Applications, Smart\nCameras, Iot devices and controllers as well as low cost drones. Our\narchitecture boasts competitive accuracies on standard Datasets even\nout-performing the original Resnet. We present below the motivation for this\nresearch, the architecture of the network, single test accuracies on CIFAR 10\nand CIFAR 100 , a detailed comparison with other well-known architectures and\nlink to an implementation in Keras.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 10:37:58 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Olafenwa", "John", ""], ["Olafenwa", "Moses", ""]]}, {"id": "1802.02195", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Djordje Miladinovic, Walter Karlen", "title": "Granger-causal Attentive Mixtures of Experts: Learning Important\n  Features with Neural Networks", "comments": "AAAI Conference on Artificial Intelligence 2019", "journal-ref": null, "doi": "10.1609/aaai.v33i01.33014846", "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge of the importance of input features towards decisions made by\nmachine-learning models is essential to increase our understanding of both the\nmodels and the underlying data. Here, we present a new approach to estimating\nfeature importance with neural networks based on the idea of distributing the\nfeatures of interest among experts in an attentive mixture of experts (AME).\nAMEs use attentive gating networks trained with a Granger-causal objective to\nlearn to jointly produce accurate predictions as well as estimates of feature\nimportance in a single model. Our experiments show (i) that the feature\nimportance estimates provided by AMEs compare favourably to those provided by\nstate-of-the-art methods, (ii) that AMEs are significantly faster at estimating\nfeature importance than existing methods, and (iii) that the associations\ndiscovered by AMEs are consistent with those reported by domain experts.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 20:21:30 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 11:18:22 GMT"}, {"version": "v3", "created": "Thu, 6 Sep 2018 12:49:54 GMT"}, {"version": "v4", "created": "Fri, 7 Sep 2018 12:15:56 GMT"}, {"version": "v5", "created": "Mon, 1 Oct 2018 12:36:39 GMT"}, {"version": "v6", "created": "Wed, 14 Nov 2018 23:57:14 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Schwab", "Patrick", ""], ["Miladinovic", "Djordje", ""], ["Karlen", "Walter", ""]]}, {"id": "1802.02203", "submitter": "Yang Hu Dr.", "authors": "Yang Hu, Guihua Wen, Huiqiang Liao, Changjun Wang, Dan Dai, Zhiwen Yu", "title": "Automatic construction of Chinese herbal prescription from tongue image\n  via CNNs and auxiliary latent therapy topics", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The tongue image provides important physical information of humans. It is of\ngreat importance for diagnoses and treatments in clinical medicine. Herbal\nprescriptions are simple, noninvasive and have low side effects. Thus, they are\nwidely applied in China. Studies on the automatic construction technology of\nherbal prescriptions based on tongue images have great significance for deep\nlearning to explore the relevance of tongue images for herbal prescriptions, it\ncan be applied to healthcare services in mobile medical systems. In order to\nadapt to the tongue image in a variety of photographic environments and\nconstruct herbal prescriptions, a neural network framework for prescription\nconstruction is designed. It includes single/double convolution channels and\nfully connected layers. Furthermore, it proposes the auxiliary therapy topic\nloss mechanism to model the therapy of Chinese doctors and alleviate the\ninterference of sparse output labels on the diversity of results. The\nexperiment use the real world tongue images and the corresponding prescriptions\nand the results can generate prescriptions that are close to the real samples,\nwhich verifies the feasibility of the proposed method for the automatic\nconstruction of herbal prescriptions from tongue images. Also, it provides a\nreference for automatic herbal prescription construction from more physical\ninformation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 08:21:04 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 05:43:28 GMT"}, {"version": "v3", "created": "Sat, 26 Jan 2019 08:39:35 GMT"}, {"version": "v4", "created": "Mon, 6 May 2019 09:37:56 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Hu", "Yang", ""], ["Wen", "Guihua", ""], ["Liao", "Huiqiang", ""], ["Wang", "Changjun", ""], ["Dai", "Dan", ""], ["Yu", "Zhiwen", ""]]}, {"id": "1802.02207", "submitter": "Jaro Zink", "authors": "Jaro Milan Zink", "title": "Automated dataset generation for image recognition using the example of\n  taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This master thesis addresses the subject of automatically generating a\ndataset for image recognition, which takes a lot of time when being done\nmanually. As the thesis was written with motivation from the context of the\nbiodiversity workgroup at the City University of Applied Sciences Bremen, the\nclassification of taxonomic entries was chosen as an exemplary use case. In\norder to automate the dataset creation, a prototype was conceptualized and\nimplemented after working out knowledge basics and analyzing requirements for\nit. It makes use of an pre-trained abstract artificial intelligence which is\nable to sort out images that do not contain the desired content. Subsequent to\nthe implementation and the automated dataset creation resulting from it, an\nevaluation was performed. Other, manually collected datasets were compared to\nthe one the prototype produced in means of specifications and accuracy. The\nresults were more than satisfactory and showed that automatically generating a\ndataset for image recognition is not only possible, but also might be a decent\nalternative to spending time and money in doing this task manually. At the very\nend of this work, an idea of how to use the principle of employing abstract\nartificial intelligences for step-by-step classification of deeper taxonomic\nlayers in a productive system is presented and discussed.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 19:30:04 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Zink", "Jaro Milan", ""]]}, {"id": "1802.02212", "submitter": "Eric Tramel", "authors": "Pierre Courtiol, Eric W. Tramel, Marc Sanselme, Gilles Wainrib", "title": "Classification and Disease Localization in Histopathology Using Only\n  Global Labels: A Weakly-Supervised Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of histopathology slides is a critical step for many diagnoses, and\nin particular in oncology where it defines the gold standard. In the case of\ndigital histopathological analysis, highly trained pathologists must review\nvast whole-slide-images of extreme digital resolution ($100,000^2$ pixels)\nacross multiple zoom levels in order to locate abnormal regions of cells, or in\nsome cases single cells, out of millions. The application of deep learning to\nthis problem is hampered not only by small sample sizes, as typical datasets\ncontain only a few hundred samples, but also by the generation of ground-truth\nlocalized annotations for training interpretable classification and\nsegmentation models. We propose a method for disease localization in the\ncontext of weakly supervised learning, where only image-level labels are\navailable during training. Even without pixel-level annotations, we are able to\ndemonstrate performance comparable with models trained with strong annotations\non the Camelyon-16 lymph node metastases detection challenge. We accomplish\nthis through the use of pre-trained deep convolutional networks, feature\nembedding, as well as learning via top instances and negative evidence, a\nmultiple instance learning technique from the field of semantic segmentation\nand object detection.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 15:21:14 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 16:25:47 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Courtiol", "Pierre", ""], ["Tramel", "Eric W.", ""], ["Sanselme", "Marc", ""], ["Wainrib", "Gilles", ""]]}, {"id": "1802.02240", "submitter": "Avinash Malik", "authors": "Avinash Malik, Tommy Peng, Mark Trew", "title": "A machine learning approach to reconstruction of heart surface\n  potentials from body surface potentials", "comments": "4 pages, 9 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invasive cardiac catheterisation is a common procedure that is carried out\nbefore surgical intervention. Yet, invasive cardiac diagnostics are full of\nrisks, especially for young children. Decades of research has been conducted on\nthe so called inverse problem of electrocardiography, which can be used to\nreconstruct Heart Surface Potentials (HSPs) from Body Surface Potentials\n(BSPs), for non-invasive diagnostics. State of the art solutions to the inverse\nproblem are unsatisfactory, since the inverse problem is known to be ill-posed.\nIn this paper we propose a novel approach to reconstructing HSPs from BSPs\nusing a Time-Delay Artificial Neural Network (TDANN). We first design the TDANN\narchitecture, and then develop an iterative search space algorithm to find the\nparameters of the TDANN, which results in the best overall HSP prediction. We\nuse real-world recorded BSPs and HSPs from individuals suffering from serious\ncardiac conditions to validate our TDANN. The results are encouraging, in that\ncoefficients obtained by correlating the predicted HSP with the recorded\npatient' HSP approach ideal values.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 22:36:46 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Malik", "Avinash", ""], ["Peng", "Tommy", ""], ["Trew", "Mark", ""]]}, {"id": "1802.02241", "submitter": "Yue Wu", "authors": "Yue Wu, Youzuo Lin, Zheng Zhou, Andrew Delorey", "title": "Seismic-Net: A Deep Densely Connected Neural Network to Detect Seismic\n  Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the risks of large-scale geologic carbon sequestration is the\npotential migration of fluids out of the storage formations. Accurate and fast\ndetection of this fluids migration is not only important but also challenging,\ndue to the large subsurface uncertainty and complex governing physics.\nTraditional leakage detection and monitoring techniques rely on geophysical\nobservations including seismic. However, the resulting accuracy of these\nmethods is limited because of indirect information they provide requiring\nexpert interpretation, therefore yielding in-accurate estimates of leakage\nrates and locations. In this work, we develop a novel machine-learning\ndetection package, named \"Seismic-Net\", which is based on the deep densely\nconnected neural network. To validate the performance of our proposed leakage\ndetection method, we employ our method to a natural analog site at Chimay\\'o,\nNew Mexico. The seismic events in the data sets are generated because of the\neruptions of geysers, which is due to the leakage of $\\mathrm{CO}_\\mathrm{2}$.\nIn particular, we demonstrate the efficacy of our Seismic-Net by formulating\nour detection problem as an event detection problem with time series data. A\nfixed-length window is slid throughout the time series data and we build a deep\ndensely connected network to classify each window to determine if a geyser\nevent is included. Through our numerical tests, we show that our model achieves\nprecision/recall as high as 0.889/0.923. Therefore, our Seismic-Net has a great\npotential for detection of $\\mathrm{CO}_\\mathrm{2}$ leakage.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 17:06:04 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Wu", "Yue", ""], ["Lin", "Youzuo", ""], ["Zhou", "Zheng", ""], ["Delorey", "Andrew", ""]]}, {"id": "1802.02271", "submitter": "Yoojin Choi", "authors": "Yoojin Choi, Mostafa El-Khamy, Jungwon Lee", "title": "Universal Deep Neural Network Compression", "comments": "NeurIPS 2018 Workshop on Compact Deep Neural Network Representation\n  with Industrial Applications (CDNNRIA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate lossy compression of deep neural networks\n(DNNs) by weight quantization and lossless source coding for memory-efficient\ndeployment. Whereas the previous work addressed non-universal scalar\nquantization and entropy coding of DNN weights, we for the first time introduce\nuniversal DNN compression by universal vector quantization and universal source\ncoding. In particular, we examine universal randomized lattice quantization of\nDNNs, which randomizes DNN weights by uniform random dithering before lattice\nquantization and can perform near-optimally on any source without relying on\nknowledge of its probability distribution. Moreover, we present a method of\nfine-tuning vector quantized DNNs to recover the performance loss after\nquantization. Our experimental results show that the proposed universal DNN\ncompression scheme compresses the 32-layer ResNet (trained on CIFAR-10) and the\nAlexNet (trained on ImageNet) with compression ratios of $47.1$ and $42.5$,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 00:39:56 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 01:33:44 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Choi", "Yoojin", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "1802.02277", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Lacra Pavel", "title": "From Game-theoretic Multi-agent Log Linear Learning to Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main focus of this paper is on enhancement of two types of game-theoretic\nlearning algorithms: log-linear learning and reinforcement learning. The\nstandard analysis of log-linear learning needs a highly structured environment,\ni.e. strong assumptions about the game from an implementation perspective. In\nthis paper, we introduce a variant of log-linear learning that provides\nasymptotic guarantees while relaxing the structural assumptions to include\nsynchronous updates and limitations in information available to the players. On\nthe other hand, model-free reinforcement learning is able to perform even under\nweaker assumptions on players' knowledge about the environment and other\nplayers' strategies. We propose a reinforcement algorithm that uses a\ndouble-aggregation scheme in order to deepen players' insight about the\nenvironment and constant learning step-size which achieves a higher convergence\nrate. Numerical experiments are conducted to verify each algorithm's robustness\nand performance.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 01:22:13 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 15:10:20 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Pavel", "Lacra", ""]]}, {"id": "1802.02290", "submitter": "Siyu Chen", "authors": "Siyu Chen and Danping Liao and Yuntao Qian", "title": "Spectral Image Visualization Using Generative Adversarial Networks", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral images captured by satellites and radio-telescopes are analyzed to\nobtain information about geological compositions distributions, distant asters\nas well as undersea terrain. Spectral images usually contain tens to hundreds\nof continuous narrow spectral bands and are widely used in various fields. But\nthe vast majority of those image signals are beyond the visible range, which\ncalls for special visualization technique. The visualizations of spectral\nimages shall convey as much information as possible from the original signal\nand facilitate image interpretation. However, most of the existing visualizatio\nmethods display spectral images in false colors, which contradict with human's\nexperience and expectation. In this paper, we present a novel visualization\ngenerative adversarial network (GAN) to display spectral images in natural\ncolors. To achieve our goal, we propose a loss function which consists of an\nadversarial loss and a structure loss. The adversarial loss pushes our solution\nto the natural image distribution using a discriminator network that is trained\nto differentiate between false-color images and natural-color images. We also\nuse a cycle loss as the structure constraint to guarantee structure\nconsistency. Experimental results show that our method is able to generate\nstructure-preserved and natural-looking visualizations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 02:23:47 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Chen", "Siyu", ""], ["Liao", "Danping", ""], ["Qian", "Yuntao", ""]]}, {"id": "1802.02312", "submitter": "Kevin Moran P", "authors": "Kevin Moran and Carlos Bernal-C\\'ardenas and Michael Curcio and\n  Richard Bonett and Denys Poshyvanyk", "title": "Machine Learning-Based Prototyping of Graphical User Interfaces for\n  Mobile Apps", "comments": "Accepted to IEEE Transactions on Software Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common practice for developers of user-facing software to transform a\nmock-up of a graphical user interface (GUI) into code. This process takes place\nboth at an application's inception and in an evolutionary context as GUI\nchanges keep pace with evolving features. Unfortunately, this practice is\nchallenging and time-consuming. In this paper, we present an approach that\nautomates this process by enabling accurate prototyping of GUIs via three\ntasks: detection, classification, and assembly. First, logical components of a\nGUI are detected from a mock-up artifact using either computer vision\ntechniques or mock-up metadata. Then, software repository mining, automated\ndynamic analysis, and deep convolutional neural networks are utilized to\naccurately classify GUI-components into domain-specific types (e.g.,\ntoggle-button). Finally, a data-driven, K-nearest-neighbors algorithm generates\na suitable hierarchical GUI structure from which a prototype application can be\nautomatically assembled. We implemented this approach for Android in a system\ncalled ReDraw. Our evaluation illustrates that ReDraw achieves an average\nGUI-component classification accuracy of 91% and assembles prototype\napplications that closely mirror target mock-ups in terms of visual affinity\nwhile exhibiting reasonable code structure. Interviews with industrial\npractitioners illustrate ReDraw's potential to improve real development\nworkflows.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 05:32:59 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 03:12:06 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Moran", "Kevin", ""], ["Bernal-C\u00e1rdenas", "Carlos", ""], ["Curcio", "Michael", ""], ["Bonett", "Richard", ""], ["Poshyvanyk", "Denys", ""]]}, {"id": "1802.02339", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Chenyou Fan and Mengdi Wang", "title": "Improved Oracle Complexity of Variance Reduced Methods for Nonsmooth\n  Convex Stochastic Composition Optimization", "comments": "We improve the current result and have a new version arXiv:1806.00458", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the nonsmooth convex composition optimization problem where the\nobjective is a composition of two finite-sum functions and analyze stochastic\ncompositional variance reduced gradient (SCVRG) methods for them. SCVRG and its\nvariants have recently drawn much attention given their edge over stochastic\ncompositional gradient descent (SCGD); but the theoretical analysis exclusively\nassumes strong convexity of the objective, which excludes several important\nexamples such as Lasso, logistic regression, principle component analysis and\ndeep neural nets. In contrast, we prove non-asymptotic incremental first-order\noracle (IFO) complexity of SCVRG or its novel variants for nonsmooth convex\ncomposition optimization and show that they are provably faster than SCGD and\ngradient descent. More specifically, our method achieves the total IFO\ncomplexity of $O\\left((m+n)\\log\\left(1/\\epsilon\\right)+1/\\epsilon^3\\right)$\nwhich improves that of $O\\left(1/\\epsilon^{3.5}\\right)$ and\n$O\\left((m+n)/\\sqrt{\\epsilon}\\right)$ obtained by SCGD and accelerated gradient\ndescent (AGD) respectively. Experimental results confirm that our methods\noutperform several existing methods, e.g., SCGD and AGD, on sparse\nmean-variance optimization problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 08:11:42 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 02:36:17 GMT"}, {"version": "v3", "created": "Fri, 9 Feb 2018 13:59:46 GMT"}, {"version": "v4", "created": "Wed, 18 Apr 2018 09:34:25 GMT"}, {"version": "v5", "created": "Wed, 25 Jul 2018 03:49:44 GMT"}, {"version": "v6", "created": "Sat, 19 Jan 2019 16:47:58 GMT"}, {"version": "v7", "created": "Tue, 30 Jul 2019 21:56:21 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Lin", "Tianyi", ""], ["Fan", "Chenyou", ""], ["Wang", "Mengdi", ""]]}, {"id": "1802.02436", "submitter": "Joshua Chacksfield", "authors": "Alexey Chaplygin and Joshua Chacksfield", "title": "Stochastic Deconvolutional Neural Network Ensemble Training on\n  Generative Pseudo-Adversarial Networks", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training of Generative Adversarial Networks is a difficult task mainly\ndue to the nature of the networks. One such issue is when the generator and\ndiscriminator start oscillating, rather than converging to a fixed point.\nAnother case can be when one agent becomes more adept than the other which\nresults in the decrease of the other agent's ability to learn, reducing the\nlearning capacity of the system as a whole. Additionally, there exists the\nproblem of Mode Collapse which involves the generators output collapsing to a\nsingle sample or a small set of similar samples. To train GANs a careful\nselection of the architecture that is used along with a variety of other\nmethods to improve training. Even when applying these methods there is low\nstability of training in relation to the parameters that are chosen. Stochastic\nensembling is suggested as a method for improving the stability while training\nGANs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 14:36:15 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Chaplygin", "Alexey", ""], ["Chacksfield", "Joshua", ""]]}, {"id": "1802.02498", "submitter": "Chicheng Zhang", "authors": "Chicheng Zhang, Eran A. Mukamel, Kamalika Chaudhuri", "title": "Spectral Learning of Binomial HMMs for DNA Methylation Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning parameters of Binomial Hidden Markov Models, which may\nbe used to model DNA methylation data. The standard algorithm for the problem\nis EM, which is computationally expensive for sequences of the scale of the\nmammalian genome. Recently developed spectral algorithms can learn parameters\nof latent variable models via tensor decomposition, and are highly efficient\nfor large data. However, these methods have only been applied to categorial\nHMMs, and the main challenge is how to extend them to Binomial HMMs while still\nretaining computational efficiency. We address this challenge by introducing a\nnew feature-map based approach that exploits specific properties of Binomial\nHMMs. We provide theoretical performance guarantees for our algorithm and\nevaluate it on real DNA methylation data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 16:00:05 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Zhang", "Chicheng", ""], ["Mukamel", "Eran A.", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1802.02500", "submitter": "Alexander New", "authors": "Alexander New, Curt Breneman, and Kristin P. Bennett", "title": "Cadre Modeling: Simultaneously Discovering Subpopulations and Predictive\n  Models", "comments": "8 pages, 6 figures", "journal-ref": "In 2018 International Joint Conference on Neural Networks (IJCNN),\n  Rio de Janeiro, Brazil, 2018", "doi": "10.1109/IJCNN.2018.8489618", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem in regression analysis of identifying subpopulations\nthat exhibit different patterns of response, where each subpopulation requires\na different underlying model. Unlike statistical cohorts, these subpopulations\nare not known a priori; thus, we refer to them as cadres. When the cadres and\ntheir associated models are interpretable, modeling leads to insights about the\nsubpopulations and their associations with the regression target. We introduce\na discriminative model that simultaneously learns cadre assignment and\ntarget-prediction rules. Sparsity-inducing priors are placed on the model\nparameters, under which independent feature selection is performed for both the\ncadre assignment and target-prediction processes. We learn models using\nadaptive step size stochastic gradient descent, and we assess cadre quality\nwith bootstrapped sample analysis. We present simulated results showing that,\nwhen the true clustering rule does not depend on the entire set of features,\nour method significantly outperforms methods that learn subpopulation-discovery\nand target-prediction rules separately. In a materials-by-design case study,\nour model provides state-of-the-art prediction of polymer glass transition\ntemperature. Importantly, the method identifies cadres of polymers that respond\ndifferently to structural perturbations, thus providing design insight for\ntargeting or avoiding specific transition temperature ranges. It identifies\nchemically meaningful cadres, each with interpretable models. Further\nexperimental results show that cadre methods have generalization that is\ncompetitive with linear and nonlinear regression models and can identify robust\nsubpopulations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 16:05:22 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 19:28:58 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["New", "Alexander", ""], ["Breneman", "Curt", ""], ["Bennett", "Kristin P.", ""]]}, {"id": "1802.02511", "submitter": "Avesh Singh", "authors": "Brandon Ballinger, Johnson Hsieh, Avesh Singh, Nimit Sohoni, Jack\n  Wang, Geoffrey H. Tison, Gregory M. Marcus, Jose M. Sanchez, Carol Maguire,\n  Jeffrey E. Olgin, Mark J. Pletcher", "title": "DeepHeart: Semi-Supervised Sequence Learning for Cardiovascular Risk\n  Prediction", "comments": "Presented at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train and validate a semi-supervised, multi-task LSTM on 57,675\nperson-weeks of data from off-the-shelf wearable heart rate sensors, showing\nhigh accuracy at detecting multiple medical conditions, including diabetes\n(0.8451), high cholesterol (0.7441), high blood pressure (0.8086), and sleep\napnea (0.8298). We compare two semi-supervised train- ing methods,\nsemi-supervised sequence learning and heuristic pretraining, and show they\noutperform hand-engineered biomarkers from the medical literature. We believe\nour work suggests a new approach to patient risk stratification based on\ncardiovascular risk scores derived from popular wearables such as Fitbit, Apple\nWatch, or Android Wear.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 16:31:50 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Ballinger", "Brandon", ""], ["Hsieh", "Johnson", ""], ["Singh", "Avesh", ""], ["Sohoni", "Nimit", ""], ["Wang", "Jack", ""], ["Tison", "Geoffrey H.", ""], ["Marcus", "Gregory M.", ""], ["Sanchez", "Jose M.", ""], ["Maguire", "Carol", ""], ["Olgin", "Jeffrey E.", ""], ["Pletcher", "Mark J.", ""]]}, {"id": "1802.02532", "submitter": "Thomas Corcoran", "authors": "Thomas Corcoran, Rafael Zamora-Resendiz, Xinlian Liu, Silvia Crivelli", "title": "A Spatial Mapping Algorithm with Applications in Deep Learning-Based\n  Structure Classification", "comments": "17 Pages, 4 figures, 7 tables. The first two authors contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Network (CNN)-based machine learning systems have made\nbreakthroughs in feature extraction and image recognition tasks in two\ndimensions (2D). Although there is significant ongoing work to apply CNN\ntechnology to domains involving complex 3D data, the success of such efforts\nhas been constrained, in part, by limitations in data representation\ntechniques. Most current approaches rely upon low-resolution 3D models,\nstrategic limitation of scope in the 3D space, or the application of lossy\nprojection techniques to allow for the use of 2D CNNs. To address this issue,\nwe present a mapping algorithm that converts 3D structures to 2D and 1D data\ngrids by mapping a traversal of a 3D space-filling curve to the traversal of\ncorresponding 2D and 1D curves. We explore the performance of 2D and 1D CNNs\ntrained on data encoded with our method versus comparable volumetric CNNs\noperating upon raw 3D data from a popular benchmarking dataset. Our experiments\ndemonstrate that both 2D and 1D representations of 3D data generated via our\nmethod preserve a significant proportion of the 3D data's features in forms\nlearnable by CNNs. Furthermore, we demonstrate that our method of encoding 3D\ndata into lower-dimensional representations allows for decreased CNN training\ntime cost, increased original 3D model rendering resolutions, and supports\nincreased numbers of data channels when compared to purely volumetric\napproaches. This demonstration is accomplished in the context of a structural\nbiology classification task wherein we train 3D, 2D, and 1D CNNs on examples of\ntwo homologous branches within the Ras protein family. The essential\ncontribution of this paper is the introduction of a dimensionality-reduction\nmethod that may ease the application of powerful deep learning tools to domains\ncharacterized by complex structural data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 17:18:33 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 20:38:14 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Corcoran", "Thomas", ""], ["Zamora-Resendiz", "Rafael", ""], ["Liu", "Xinlian", ""], ["Crivelli", "Silvia", ""]]}, {"id": "1802.02535", "submitter": "Hiva Ghanbari", "authors": "Hiva Ghanbari and Katya Scheinberg", "title": "Directly and Efficiently Optimizing Prediction Error and AUC of Linear\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predictive quality of machine learning models is typically measured in\nterms of their (approximate) expected prediction error or the so-called Area\nUnder the Curve (AUC) for a particular data distribution. However, when the\nmodels are constructed by the means of empirical risk minimization, surrogate\nfunctions such as the logistic loss are optimized instead. This is done because\nthe empirical approximations of the expected error and AUC functions are\nnonconvex and nonsmooth, and more importantly have zero derivative almost\neverywhere. In this work, we show that in the case of linear predictors, and\nunder the assumption that the data has normal distribution, the expected error\nand the expected AUC are not only smooth, but have closed form expressions,\nwhich depend on the first and second moments of the normal distribution. Hence,\nwe derive derivatives of these two functions and use these derivatives in an\noptimization algorithm to directly optimize the expected error and the AUC. In\nthe case of real data sets, the derivatives can be approximated using empirical\nmoments. We show that even when data is not normally distributed, computed\nderivatives are sufficiently useful to render an efficient optimization method\nand high quality solutions. Thus, we propose a gradient-based optimization\nmethod for direct optimization of the prediction error and AUC. Moreover, the\nper-iteration complexity of the proposed algorithm has no dependence on the\nsize of the data set, unlike those for optimizing logistic regression and all\nother well known empirical risk minimization problems.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 17:20:49 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Ghanbari", "Hiva", ""], ["Scheinberg", "Katya", ""]]}, {"id": "1802.02547", "submitter": "Surbhi Goel", "authors": "Surbhi Goel, Adam Klivans and Raghu Meka", "title": "Learning One Convolutional Layer with Overlapping Patches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first provably efficient algorithm for learning a one hidden\nlayer convolutional network with respect to a general class of (potentially\noverlapping) patches. Additionally, our algorithm requires only mild conditions\non the underlying distribution. We prove that our framework captures commonly\nused schemes from computer vision, including one-dimensional and\ntwo-dimensional \"patch and stride\" convolutions.\n  Our algorithm-- $Convotron$ -- is inspired by recent work applying isotonic\nregression to learning neural networks. Convotron uses a simple, iterative\nupdate rule that is stochastic in nature and tolerant to noise (requires only\nthat the conditional mean function is a one layer convolutional network, as\nopposed to the realizable setting). In contrast to gradient descent, Convotron\nrequires no special initialization or learning-rate tuning to converge to the\nglobal optimum.\n  We also point out that learning one hidden convolutional layer with respect\nto a Gaussian distribution and just $one$ disjoint patch $P$ (the other patches\nmay be arbitrary) is $easy$ in the following sense: Convotron can efficiently\nrecover the hidden weight vector by updating $only$ in the direction of $P$.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 17:41:25 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Goel", "Surbhi", ""], ["Klivans", "Adam", ""], ["Meka", "Raghu", ""]]}, {"id": "1802.02548", "submitter": "Sam Ganzfried", "authors": "Sheila Alemany, Jonathan Beltran, Adrian Perez, Sam Ganzfried", "title": "Predicting Hurricane Trajectories using a Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hurricanes are cyclones circulating about a defined center whose closed wind\nspeeds exceed 75 mph originating over tropical and subtropical waters. At\nlandfall, hurricanes can result in severe disasters. The accuracy of predicting\ntheir trajectory paths is critical to reduce economic loss and save human\nlives. Given the complexity and nonlinearity of weather data, a recurrent\nneural network (RNN) could be beneficial in modeling hurricane behavior. We\npropose the application of a fully connected RNN to predict the trajectory of\nhurricanes. We employed the RNN over a fine grid to reduce typical truncation\nerrors. We utilized their latitude, longitude, wind speed, and pressure\npublicly provided by the National Hurricane Center (NHC) to predict the\ntrajectory of a hurricane at 6-hour intervals. Results show that this proposed\ntechnique is competitive to methods currently employed by the NHC and can\npredict up to approximately 120 hours of hurricane path.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 08:17:58 GMT"}, {"version": "v2", "created": "Sat, 24 Mar 2018 08:59:55 GMT"}, {"version": "v3", "created": "Wed, 12 Sep 2018 07:30:52 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Alemany", "Sheila", ""], ["Beltran", "Jonathan", ""], ["Perez", "Adrian", ""], ["Ganzfried", "Sam", ""]]}, {"id": "1802.02550", "submitter": "Yoon Kim", "authors": "Yoon Kim, Sam Wiseman, Andrew C. Miller, David Sontag, Alexander M.\n  Rush", "title": "Semi-Amortized Variational Autoencoders", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amortized variational inference (AVI) replaces instance-specific local\ninference with a global inference network. While AVI has enabled efficient\ntraining of deep generative models such as variational autoencoders (VAE),\nrecent empirical work suggests that inference networks can produce suboptimal\nvariational parameters. We propose a hybrid approach, to use AVI to initialize\nthe variational parameters and run stochastic variational inference (SVI) to\nrefine them. Crucially, the local SVI procedure is itself differentiable, so\nthe inference network and generative model can be trained end-to-end with\ngradient-based optimization. This semi-amortized approach enables the use of\nrich generative models without experiencing the posterior-collapse phenomenon\ncommon in training VAEs for problems like text generation. Experiments show\nthis approach outperforms strong autoregressive and variational baselines on\nstandard text and image datasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 18:06:42 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 17:02:04 GMT"}, {"version": "v3", "created": "Mon, 12 Mar 2018 05:18:57 GMT"}, {"version": "v4", "created": "Mon, 26 Mar 2018 17:05:42 GMT"}, {"version": "v5", "created": "Thu, 24 May 2018 20:06:49 GMT"}, {"version": "v6", "created": "Fri, 8 Jun 2018 21:17:42 GMT"}, {"version": "v7", "created": "Mon, 23 Jul 2018 19:31:28 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Kim", "Yoon", ""], ["Wiseman", "Sam", ""], ["Miller", "Andrew C.", ""], ["Sontag", "David", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1802.02558", "submitter": "Richard Zhao", "authors": "Lucy Xia, Richard Zhao, Yanhui Wu and Xin Tong", "title": "Intentional Control of Type I Error over Unconscious Data Distortion: a\n  Neyman-Pearson Approach to Text Classification", "comments": null, "journal-ref": "Journal of the American Statistical Association, 2020", "doi": "10.1080/01621459.2020.1740711", "report-no": null, "categories": "stat.ME cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the challenges in classifying textual data obtained from\nopen online platforms, which are vulnerable to distortion. Most existing\nclassification methods minimize the overall classification error and may yield\nan undesirably large type I error (relevant textual messages are classified as\nirrelevant), particularly when available data exhibit an asymmetry between\nrelevant and irrelevant information. Data distortion exacerbates this situation\nand often leads to fallacious prediction. To deal with inestimable data\ndistortion, we propose the use of the Neyman-Pearson (NP) classification\nparadigm, which minimizes type II error under a user-specified type I error\nconstraint. Theoretically, we show that the NP oracle is unaffected by data\ndistortion when the class conditional distributions remain the same.\nEmpirically, we study a case of classifying posts about worker strikes obtained\nfrom a leading Chinese microblogging platform, which are frequently prone to\nextensive, unpredictable and inestimable censorship. We demonstrate that, even\nthough the training and test data are susceptible to different distortion and\ntherefore potentially follow different distributions, our proposed NP methods\ncontrol the type I error on test data at the targeted level. The methods and\nimplementation pipeline proposed in our case study are applicable to many other\nproblems involving data distortion.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 18:33:20 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 19:21:05 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 03:49:46 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Xia", "Lucy", ""], ["Zhao", "Richard", ""], ["Wu", "Yanhui", ""], ["Tong", "Xin", ""]]}, {"id": "1802.02565", "submitter": "Johannes Wagner", "authors": "Johannes Wagner, Tobias Baur, Yue Zhang, Michel F. Valstar, Bj\\\"orn\n  Schuller, Elisabeth Andr\\'e", "title": "Applying Cooperative Machine Learning to Speed Up the Annotation of\n  Social Signals in Large Multi-modal Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific disciplines, such as Behavioural Psychology, Anthropology and\nrecently Social Signal Processing are concerned with the systematic exploration\nof human behaviour. A typical work-flow includes the manual annotation (also\ncalled coding) of social signals in multi-modal corpora of considerable size.\nFor the involved annotators this defines an exhausting and time-consuming task.\nIn the article at hand we present a novel method and also provide the tools to\nspeed up the coding procedure. To this end, we suggest and evaluate the use of\nCooperative Machine Learning (CML) techniques to reduce manual labelling\nefforts by combining the power of computational capabilities and human\nintelligence. The proposed CML strategy starts with a small number of labelled\ninstances and concentrates on predicting local parts first. Afterwards, a\nsession-independent classification model is created to finish the remaining\nparts of the database. Confidence values are computed to guide the manual\ninspection and correction of the predictions. To bring the proposed approach\ninto application we introduce NOVA - an open-source tool for collaborative and\nmachine-aided annotations. In particular, it gives labellers immediate access\nto CML strategies and directly provides visual feedback on the results. Our\nexperiments show that the proposed method has the potential to significantly\nreduce human labelling efforts.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 18:47:49 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Wagner", "Johannes", ""], ["Baur", "Tobias", ""], ["Zhang", "Yue", ""], ["Valstar", "Michel F.", ""], ["Schuller", "Bj\u00f6rn", ""], ["Andr\u00e9", "Elisabeth", ""]]}, {"id": "1802.02568", "submitter": "Hamid Izadinia", "authors": "Hamid Izadinia, Pierre Garrigues", "title": "VISER: Visual Self-Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose the use of large set of unlabeled images as a source\nof regularization data for learning robust visual representation. Given a\nvisual model trained by a labeled dataset in a supervised fashion, we augment\nour training samples by incorporating large number of unlabeled data and train\na semi-supervised model. We demonstrate that our proposed learning approach\nleverages an abundance of unlabeled images and boosts the visual recognition\nperformance which alleviates the need to rely on large labeled datasets for\nlearning robust representation. To increment the number of image instances\nneeded to learn robust visual models in our approach, each labeled image\npropagates its label to its nearest unlabeled image instances. These retrieved\nunlabeled images serve as local perturbations of each labeled image to perform\nVisual Self-Regularization (VISER). To retrieve such visual self regularizers,\nwe compute the cosine similarity in a semantic space defined by the penultimate\nlayer in a fully convolutional neural network. We use the publicly available\nYahoo Flickr Creative Commons 100M dataset as the source of our unlabeled image\nset and propose a distributed approximate nearest neighbor algorithm to make\nretrieval practical at that scale. Using the labeled instances and their\nregularizer samples we show that we significantly improve object categorization\nand localization performance on the MS COCO and Visual Genome datasets where\nobjects appear in context.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 18:55:01 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Izadinia", "Hamid", ""], ["Garrigues", "Pierre", ""]]}, {"id": "1802.02617", "submitter": "Fady Medhat", "authors": "Fady Medhat, David Chesmore, John Robinson", "title": "Recognition of Acoustic Events Using Masked Conditional Neural Networks", "comments": "Restricted Boltzmann Machine, RBM, Conditional Restricted Boltzmann\n  Machine, CRBM, Conditional Neural Networks, CLNN, Masked Conditional Neural\n  Networks, MCLNN, Deep Neural Network, Environmental Sound Recognition, ESR", "journal-ref": "IEEE International Conference on Machine Learning and Applications\n  (ICMLA) Year: 2017 Pages: 199 - 206", "doi": "10.1109/ICMLA.2017.0-158", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic feature extraction using neural networks has accomplished\nremarkable success for images, but for sound recognition, these models are\nusually modified to fit the nature of the multi-dimensional temporal\nrepresentation of the audio signal in spectrograms. This may not efficiently\nharness the time-frequency representation of the signal. The ConditionaL Neural\nNetwork (CLNN) takes into consideration the interrelation between the temporal\nframes, and the Masked ConditionaL Neural Network (MCLNN) extends upon the CLNN\nby forcing a systematic sparseness over the network's weights using a binary\nmask. The masking allows the network to learn about frequency bands rather than\nbins, mimicking a filterbank used in signal transformations such as MFCC.\nAdditionally, the Mask is designed to consider various combinations of\nfeatures, which automates the feature hand-crafting process. We applied the\nMCLNN for the Environmental Sound Recognition problem using the Urbansound8k,\nYorNoise, ESC-10 and ESC-50 datasets. The MCLNN have achieved competitive\nperformance compared to state-of-the-art Convolutional Neural Networks and\nhand-crafted attempts.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 19:58:50 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 10:01:26 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Medhat", "Fady", ""], ["Chesmore", "David", ""], ["Robinson", "John", ""]]}, {"id": "1802.02638", "submitter": "Jonathan Ullman", "authors": "Jonathan Ullman", "title": "Tight Lower Bounds for Locally Differentially Private Selection", "comments": "The results in this paper have been subsumed by: Alexander Edmonds,\n  Aleksandar Nikolov, Jonathan Ullman. \"The Power of Factorization Mechanisms\n  in Local and Central Differential Privacy.\" STOC 2020 [arXiv:1911.08339].\n  Please cite that paper for the relevant results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a tight lower bound (up to constant factors) on the sample\ncomplexity of any non-interactive local differentially private protocol for\noptimizing a linear function over the simplex. This lower bound also implies a\ntight lower bound (again, up to constant factors) on the sample complexity of\nany non-interactive local differentially private protocol implementing the\nexponential mechanism. These results reveal that any local protocol for these\nproblems has exponentially worse dependence on the dimension than corresponding\nalgorithms in the central model. Previously, Kasiviswanathan et al. (FOCS 2008)\nproved an exponential separation between local and central model algorithms for\nPAC learning the class of parity functions. In contrast, our lower bound are\nquantitatively tight, apply to a simple and natural class of linear\noptimization problems, and our techniques are arguably simpler.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 21:17:53 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 13:55:37 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Ullman", "Jonathan", ""]]}, {"id": "1802.02643", "submitter": "Pavel Gurevich", "authors": "Pavel Gurevich, Hannes Stuke", "title": "Gradient conjugate priors and multi-layer neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with learning probability distributions of observed data by\nartificial neural networks. We suggest a so-called gradient conjugate prior\n(GCP) update appropriate for neural networks, which is a modification of the\nclassical Bayesian update for conjugate priors. We establish a connection\nbetween the gradient conjugate prior update and the maximization of the\nlog-likelihood of the predictive distribution. Unlike for the Bayesian neural\nnetworks, we use deterministic weights of neural networks, but rather assume\nthat the ground truth distribution is normal with unknown mean and variance and\nlearn by the neural networks the parameters of a prior (normal-gamma\ndistribution) for these unknown mean and variance. The update of the parameters\nis done, using the gradient that, at each step, directs towards minimizing the\nKullback--Leibler divergence from the prior to the posterior distribution (both\nbeing normal-gamma). We obtain a corresponding dynamical system for the prior's\nparameters and analyze its properties. In particular, we study the limiting\nbehavior of all the prior's parameters and show how it differs from the case of\nthe classical full Bayesian update. The results are validated on synthetic and\nreal world data sets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 21:29:52 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 14:27:07 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 09:20:22 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Gurevich", "Pavel", ""], ["Stuke", "Hannes", ""]]}, {"id": "1802.02664", "submitter": "Valentin Khrulkov", "authors": "Valentin Khrulkov and Ivan Oseledets", "title": "Geometry Score: A Method For Comparing Generative Adversarial Networks", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges in the research of generative adversarial\nnetworks (GANs) is assessing the quality of generated samples and detecting\nvarious levels of mode collapse. In this work, we construct a novel measure of\nperformance of a GAN by comparing geometrical properties of the underlying data\nmanifold and the generated one, which provides both qualitative and\nquantitative means for evaluation. Our algorithm can be applied to datasets of\nan arbitrary nature and is not limited to visual data. We test the obtained\nmetric on various real-life models and datasets and demonstrate that our method\nprovides new insights into properties of GANs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 22:44:37 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 21:00:36 GMT"}, {"version": "v3", "created": "Sat, 9 Jun 2018 14:44:41 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Khrulkov", "Valentin", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1802.02678", "submitter": "Charles Delahunt", "authors": "Charles B. Delahunt, Jeffrey A. Riffell, J. Nathan Kutz", "title": "Biological Mechanisms for Learning: A Computational Model of Olfactory\n  Learning in the Manduca sexta Moth, with Applications to Neural Nets", "comments": "35 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The insect olfactory system, which includes the antennal lobe (AL), mushroom\nbody (MB), and ancillary structures, is a relatively simple neural system\ncapable of learning. Its structural features, which are widespread in\nbiological neural systems, process olfactory stimuli through a cascade of\nnetworks where large dimension shifts occur from stage to stage and where\nsparsity and randomness play a critical role in coding. Learning is partly\nenabled by a neuromodulatory reward mechanism of octopamine stimulation of the\nAL, whose increased activity induces rewiring of the MB through Hebbian\nplasticity. Enforced sparsity in the MB focuses Hebbian growth on neurons that\nare the most important for the representation of the learned odor. Based upon\ncurrent biophysical knowledge, we have constructed an end-to-end computational\nmodel of the Manduca sexta moth olfactory system which includes the interaction\nof the AL and MB under octopamine stimulation. Our model is able to robustly\nlearn new odors, and our simulations of integrate-and-fire neurons match the\nstatistical features of in-vivo firing rate data. From a biological\nperspective, the model provides a valuable tool for examining the role of\nneuromodulators, like octopamine, in learning, and gives insight into critical\ninteractions between sparsity, Hebbian growth, and stimulation during learning.\nOur simulations also inform predictions about structural details of the\nolfactory system that are not currently well-characterized. From a machine\nlearning perspective, the model yields bio-inspired mechanisms that are\npotentially useful in constructing neural nets for rapid learning from very few\nsamples. These mechanisms include high-noise layers, sparse layers as noise\nfilters, and a biologically-plausible optimization method to train the network\nbased on octopamine stimulation, sparse layers, and Hebbian growth.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 00:16:31 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Delahunt", "Charles B.", ""], ["Riffell", "Jeffrey A.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1802.02696", "submitter": "Da Xiao", "authors": "Da Xiao, Jo-Yu Liao, Xingyuan Yuan", "title": "Improving the Universality and Learnability of Neural\n  Programmer-Interpreters with Combinator Abstraction", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To overcome the limitations of Neural Programmer-Interpreters (NPI) in its\nuniversality and learnability, we propose the incorporation of combinator\nabstraction into neural programing and a new NPI architecture to support this\nabstraction, which we call Combinatory Neural Programmer-Interpreter (CNPI).\nCombinator abstraction dramatically reduces the number and complexity of\nprograms that need to be interpreted by the core controller of CNPI, while\nstill allowing the CNPI to represent and interpret arbitrary complex programs\nby the collaboration of the core with the other components. We propose a small\nset of four combinators to capture the most pervasive programming patterns. Due\nto the finiteness and simplicity of this combinator set and the offloading of\nsome burden of interpretation from the core, we are able construct a CNPI that\nis universal with respect to the set of all combinatorizable programs, which is\nadequate for solving most algorithmic tasks. Moreover, besides supervised\ntraining on execution traces, CNPI can be trained by policy gradient\nreinforcement learning with appropriately designed curricula.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 03:08:34 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Xiao", "Da", ""], ["Liao", "Jo-Yu", ""], ["Yuan", "Xingyuan", ""]]}, {"id": "1802.02736", "submitter": "Jeehyeong Kim", "authors": "Jeehyeong Kim, Joohan Park, Jaewon Noh, and Sunghyun Cho", "title": "Autonomous Power Allocation based on Distributed Deep Learning for\n  Device-to-Device Communication Underlaying Cellular Network", "comments": "accepted in IEEE Access, 2169-3536", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3000350", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For Device-to-device (D2D) communication of Internet-of-Things (IoT) enabled\n5G system, there is a limit to allocating resources considering a complicated\ninterference between different links in a centralized manner. If D2D link is\ncontrolled by an enhanced node base station (eNB), and thus, remains a burden\non the eNB and it causes delayed latency. This paper proposes a fully\nautonomous power allocation method for IoT-D2D communication underlaying\ncellular networks using deep learning. In the proposed scheme, an IoT-D2D\ntransmitter decides the transmit power independently from an eNB and other\nIoT-D2D devices. In addition, the power set can be nearly optimized by deep\nlearning with distributed manner to achieve higher cell throughput. We present\na distributed deep learning architecture in which the devices are trained as a\ngroup but operate independently. The deep learning can attain near optimal cell\nthroughput while suppressing interference to eNB.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 08:06:39 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 00:23:06 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 14:42:16 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kim", "Jeehyeong", ""], ["Park", "Joohan", ""], ["Noh", "Jaewon", ""], ["Cho", "Sunghyun", ""]]}, {"id": "1802.02745", "submitter": "Reuben Feinman", "authors": "Reuben Feinman, Brenden M. Lake", "title": "Learning Inductive Biases with Simple Neural Networks", "comments": "Published in Proceedings of the 40th Annual Meeting of the Cognitive\n  Science Society, July 2018", "journal-ref": "Feinman, R. and Lake, B.M. (2018). Learning inductive biases with\n  simple neural networks. In Proceedings of the 40th Annual Meeting of the\n  Cognitive Science Society", "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People use rich prior knowledge about the world in order to efficiently learn\nnew concepts. These priors - also known as \"inductive biases\" - pertain to the\nspace of internal models considered by a learner, and they help the learner\nmake inferences that go beyond the observed data. A recent study found that\ndeep neural networks optimized for object recognition develop the shape bias\n(Ritter et al., 2017), an inductive bias possessed by children that plays an\nimportant role in early word learning. However, these networks use\nunrealistically large quantities of training data, and the conditions required\nfor these biases to develop are not well understood. Moreover, it is unclear\nhow the learning dynamics of these networks relate to developmental processes\nin childhood. We investigate the development and influence of the shape bias in\nneural networks using controlled datasets of abstract patterns and synthetic\nimages, allowing us to systematically vary the quantity and form of the\nexperience provided to the learning algorithms. We find that simple neural\nnetworks develop a shape bias after seeing as few as 3 examples of 4 object\ncategories. The development of these biases predicts the onset of vocabulary\nacceleration in our networks, consistent with the developmental process in\nchildren.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 08:25:51 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 18:01:21 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Feinman", "Reuben", ""], ["Lake", "Brenden M.", ""]]}, {"id": "1802.02798", "submitter": "Sean Rowan", "authors": "Sean Rowan", "title": "Transductive Adversarial Networks (TAN)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transductive Adversarial Networks (TAN) is a novel domain-adaptation machine\nlearning framework that is designed for learning a conditional probability\ndistribution on unlabelled input data in a target domain, while also only\nhaving access to: (1) easily obtained labelled data from a related source\ndomain, which may have a different conditional probability distribution than\nthe target domain, and (2) a marginalised prior distribution on the labels for\nthe target domain. TAN leverages a fully adversarial training procedure and a\nunique generator/encoder architecture which approximates the transductive\ncombination of the available source- and target-domain data. A benefit of TAN\nis that it allows the distance between the source- and target-domain\nlabel-vector marginal probability distributions to be greater than 0 (i.e.\ndifferent tasks across the source and target domains) whereas other\ndomain-adaptation algorithms require this distance to equal 0 (i.e. a single\ntask across the source and target domains). TAN can, however, still handle the\nlatter case and is a more generalised approach to this case. Another benefit of\nTAN is that due to being a fully adversarial algorithm, it has the potential to\naccurately approximate highly complex distributions. Theoretical analysis\ndemonstrates the viability of the TAN framework.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 10:44:53 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Rowan", "Sean", ""]]}, {"id": "1802.02840", "submitter": "Shuohui Li", "authors": "Shuo-Hui Li and Lei Wang", "title": "Neural Network Renormalization Group", "comments": "Main text: 4.5 pages, 4 figures. Supplement: 3 pages. Github link:\n  https://github.com/li012589/NeuralRG", "journal-ref": "Phys. Rev. Lett. 121, 260601 (2018)", "doi": "10.1103/PhysRevLett.121.260601", "report-no": null, "categories": "cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a variational renormalization group (RG) approach using a deep\ngenerative model based on normalizing flows. The model performs hierarchical\nchange-of-variables transformations from the physical space to a latent space\nwith reduced mutual information. Conversely, the neural net directly maps\nindependent Gaussian noises to physical configurations following the inverse RG\nflow. The model has an exact and tractable likelihood, which allows unbiased\ntraining and direct access to the renormalized energy function of the latent\nvariables. To train the model, we employ probability density distillation for\nthe bare energy function of the physical problem, in which the training loss\nprovides a variational upper bound of the physical free energy. We demonstrate\npractical usage of the approach by identifying mutually independent collective\nvariables of the Ising model and performing accelerated hybrid Monte Carlo\nsampling in the latent space. Lastly, we comment on the connection of the\npresent approach to the wavelet formulation of RG and the modern pursuit of\ninformation preserving RG.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 13:16:01 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 09:17:25 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 13:48:25 GMT"}, {"version": "v4", "created": "Wed, 19 Dec 2018 04:14:43 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Li", "Shuo-Hui", ""], ["Wang", "Lei", ""]]}, {"id": "1802.02871", "submitter": "Doyen Sahoo", "authors": "Steven C.H. Hoi, Doyen Sahoo, Jing Lu, Peilin Zhao", "title": "Online Learning: A Comprehensive Survey", "comments": "100 pages, ~400 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning represents an important family of machine learning\nalgorithms, in which a learner attempts to resolve an online prediction (or any\ntype of decision-making) task by learning a model/hypothesis from a sequence of\ndata instances one at a time. The goal of online learning is to ensure that the\nonline learner would make a sequence of accurate predictions (or correct\ndecisions) given the knowledge of correct answers to previous prediction or\nlearning tasks and possibly additional information. This is in contrast to many\ntraditional batch learning or offline machine learning algorithms that are\noften designed to train a model in batch from a given collection of training\ndata instances. This survey aims to provide a comprehensive survey of the\nonline machine learning literatures through a systematic review of basic ideas\nand key principles and a proper categorization of different algorithms and\ntechniques. Generally speaking, according to the learning type and the forms of\nfeedback information, the existing online learning works can be classified into\nthree major categories: (i) supervised online learning where full feedback\ninformation is always available, (ii) online learning with limited feedback,\nand (iii) unsupervised online learning where there is no feedback available.\nDue to space limitation, the survey will be mainly focused on the first\ncategory, but also briefly cover some basics of the other two categories.\nFinally, we also discuss some open issues and attempt to shed light on\npotential future research directions in this field.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 14:18:23 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 06:22:23 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Hoi", "Steven C. H.", ""], ["Sahoo", "Doyen", ""], ["Lu", "Jing", ""], ["Zhao", "Peilin", ""]]}, {"id": "1802.02907", "submitter": "Rui Zhang", "authors": "Rui Zhang and Quanyan Zhu", "title": "A Game-Theoretic Approach to Design Secure and Resilient Distributed\n  Support Vector Machines", "comments": "arXiv admin note: text overlap with arXiv:1710.04677", "journal-ref": null, "doi": "10.1109/TNNLS.2018.2802721", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Support Vector Machines (DSVM) have been developed to solve\nlarge-scale classification problems in networked systems with a large number of\nsensors and control units. However, the systems become more vulnerable as\ndetection and defense are increasingly difficult and expensive. This work aims\nto develop secure and resilient DSVM algorithms under adversarial environments\nin which an attacker can manipulate the training data to achieve his objective.\nWe establish a game-theoretic framework to capture the conflicting interests\nbetween an adversary and a set of distributed data processing units. The Nash\nequilibrium of the game allows predicting the outcome of learning algorithms in\nadversarial environments, and enhancing the resilience of the machine learning\nthrough dynamic distributed learning algorithms. We prove that the convergence\nof the distributed algorithm is guaranteed without assumptions on the training\ndata or network topologies. Numerical experiments are conducted to corroborate\nthe results. We show that network topology plays an important role in the\nsecurity of DSVM. Networks with fewer nodes and higher average degrees are more\nsecure. Moreover, a balanced network is found to be less vulnerable to attacks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 18:06:48 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Zhang", "Rui", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1802.02920", "submitter": "Anru Zhang", "authors": "Anru Zhang and Mengdi Wang", "title": "Spectral State Compression of Markov Processes", "comments": "to appear in IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Model reduction of Markov processes is a basic problem in modeling\nstate-transition systems. Motivated by the state aggregation approach rooted in\ncontrol theory, we study the statistical state compression of a discrete-state\nMarkov chain from empirical trajectories. Through the lens of spectral\ndecomposition, we study the rank and features of Markov processes, as well as\nproperties like representability, aggregability, and lumpability. We develop\nspectral methods for estimating the transition matrix of a low-rank Markov\nmodel, estimating the leading subspace spanned by Markov features, and\nrecovering latent structures like state aggregation and lumpable partition of\nthe state space. We prove statistical upper bounds for the estimation errors\nand nearly matching minimax lower bounds. Numerical studies are performed on\nsynthetic data and a dataset of New York City taxi trips.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 15:28:46 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 03:34:14 GMT"}, {"version": "v3", "created": "Sun, 24 Nov 2019 03:08:25 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zhang", "Anru", ""], ["Wang", "Mengdi", ""]]}, {"id": "1802.02952", "submitter": "Shoaib Ahmed Siddiqui", "authors": "Shoaib Ahmed Siddiqui, Dominik Mercier, Mohsin Munir, Andreas Dengel,\n  Sheraz Ahmed", "title": "TSViz: Demystification of Deep Learning Models for Time-Series Analysis", "comments": "7 Pages (6 + 1 for references), 7 figures", "journal-ref": "IEEE Access 2019 PP(99):1-1", "doi": "10.1109/ACCESS.2019.2912823", "report-no": "ACCESS.2019.2912823", "categories": "cs.LG cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a novel framework for demystification of convolutional\ndeep learning models for time-series analysis. This is a step towards making\ninformed/explainable decisions in the domain of time-series, powered by deep\nlearning. There have been numerous efforts to increase the interpretability of\nimage-centric deep neural network models, where the learned features are more\nintuitive to visualize. Visualization in time-series domain is much more\ncomplicated as there is no direct interpretation of the filters and inputs as\ncompared to the image modality. In addition, little or no concentration has\nbeen devoted for the development of such tools in the domain of time-series in\nthe past. TSViz provides possibilities to explore and analyze a network from\ndifferent dimensions at different levels of abstraction which includes\nidentification of parts of the input that were responsible for a prediction\n(including per filter saliency), importance of different filters present in the\nnetwork for a particular prediction, notion of diversity present in the network\nthrough filter clustering, understanding of the main sources of variation\nlearnt by the network through inverse optimization, and analysis of the\nnetwork's robustness against adversarial noise. As a sanity check for the\ncomputed influence values, we demonstrate results regarding pruning of neural\nnetworks based on the computed influence information. These representations\nallow to understand the network features so that the acceptability of deep\nnetworks for time-series data can be enhanced. This is extremely important in\ndomains like finance, industry 4.0, self-driving cars, health-care,\ncounter-terrorism etc., where reasons for reaching a particular prediction are\nequally important as the prediction itself. We assess the proposed framework\nfor interpretability with a set of desirable properties essential for any\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 16:29:49 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 23:22:53 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 07:53:44 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Siddiqui", "Shoaib Ahmed", ""], ["Mercier", "Dominik", ""], ["Munir", "Mohsin", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "1802.02961", "submitter": "Daniel Recoskie", "authors": "Daniel Recoskie and Richard Mann", "title": "Learning Sparse Wavelet Representations", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a method for learning wavelet filters directly from\ndata. We accomplish this by framing the discrete wavelet transform as a\nmodified convolutional neural network. We introduce an autoencoder wavelet\ntransform network that is trained using gradient descent. We show that the\nmodel is capable of learning structured wavelet filters from synthetic and real\ndata. The learned wavelets are shown to be similar to traditional wavelets that\nare derived using Fourier methods. Our method is simple to implement and easily\nincorporated into neural network architectures. A major advantage to our model\nis that we can learn from raw audio data.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 16:49:00 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Recoskie", "Daniel", ""], ["Mann", "Richard", ""]]}, {"id": "1802.02988", "submitter": "Damek Davis", "authors": "Damek Davis, Dmitriy Drusvyatskiy", "title": "Stochastic subgradient method converges at the rate $O(k^{-1/4})$ on\n  weakly convex functions", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the proximal stochastic subgradient method, applied to a weakly\nconvex problem, drives the gradient of the Moreau envelope to zero at the rate\n$O(k^{-1/4})$. As a consequence, we resolve an open question on the convergence\nrate of the proximal stochastic gradient method for minimizing the sum of a\nsmooth nonconvex function and a convex proximable function.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 18:03:12 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 21:16:39 GMT"}, {"version": "v3", "created": "Mon, 19 Feb 2018 23:21:25 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Davis", "Damek", ""], ["Drusvyatskiy", "Dmitriy", ""]]}, {"id": "1802.03001", "submitter": "Shin Matsushima", "authors": "Shin Matsushima", "title": "Statistical Learnability of Generalized Additive Models based on Total\n  Variation Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generalized additive model (GAM, Hastie and Tibshirani (1987)) is a\nnonparametric model by the sum of univariate functions with respect to each\nexplanatory variable, i.e., $f({\\mathbf x}) = \\sum f_j(x_j)$, where\n$x_j\\in\\mathbb{R}$ is $j$-th component of a sample ${\\mathbf x}\\in\n\\mathbb{R}^p$. In this paper, we introduce the total variation (TV) of a\nfunction as a measure of the complexity of functions in $L^1_{\\rm\nc}(\\mathbb{R})$-space. Our analysis shows that a GAM based on TV-regularization\nexhibits a Rademacher complexity of $O(\\sqrt{\\frac{\\log p}{m}})$, which is\ntight in terms of both $m$ and $p$ in the agnostic case of the classification\nproblem. In result, we obtain generalization error bounds for finite samples\naccording to work by Bartlett and Mandelson (2002).\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 18:36:28 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 18:18:23 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Matsushima", "Shin", ""]]}, {"id": "1802.03006", "submitter": "Lars Buesing", "authors": "Lars Buesing, Theophane Weber, Sebastien Racaniere, S. M. Ali Eslami,\n  Danilo Rezende, David P. Reichert, Fabio Viola, Frederic Besse, Karol Gregor,\n  Demis Hassabis, Daan Wierstra", "title": "Learning and Querying Fast Generative Models for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in model-based reinforcement learning (RL) is to synthesize\ncomputationally efficient and accurate environment models. We show that\ncarefully designed generative models that learn and operate on compact state\nrepresentations, so-called state-space models, substantially reduce the\ncomputational costs for predicting outcomes of sequences of actions. Extensive\nexperiments establish that state-space models accurately capture the dynamics\nof Atari games from the Arcade Learning Environment from raw pixels. The\ncomputational speed-up of state-space models while maintaining high accuracy\nmakes their application in RL feasible: We demonstrate that agents which query\nthese models for decision making outperform strong model-free baselines on the\ngame MSPACMAN, demonstrating the potential of using learned environment models\nfor planning.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 18:54:44 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Buesing", "Lars", ""], ["Weber", "Theophane", ""], ["Racaniere", "Sebastien", ""], ["Eslami", "S. M. Ali", ""], ["Rezende", "Danilo", ""], ["Reichert", "David P.", ""], ["Viola", "Fabio", ""], ["Besse", "Frederic", ""], ["Gregor", "Karol", ""], ["Hassabis", "Demis", ""], ["Wierstra", "Daan", ""]]}, {"id": "1802.03010", "submitter": "M. Sevi Baltaoglu", "authors": "Sevi Baltaoglu, Lang Tong, and Qing Zhao", "title": "Algorithmic Bidding for Virtual Trading in Electricity Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimal bidding for virtual trading in\ntwo-settlement electricity markets. A virtual trader aims to arbitrage on the\ndifferences between day-ahead and real-time market prices; both prices,\nhowever, are random and unknown to market participants. An online learning\nalgorithm is proposed to maximize the cumulative payoff over a finite number of\ntrading sessions by allocating the trader's budget among his bids for K options\nin each session. It is shown that the proposed algorithm converges, with an\nalmost optimal convergence rate, to the global optimal corresponding to the\ncase when the underlying price distribution is known. The proposed algorithm is\nalso generalized for trading strategies with a risk measure. By using both\ncumulative payoff and Sharpe ratio as performance metrics, evaluations were\nperformed based on historical data spanning ten year period of NYISO and PJM\nmarkets. It was shown that the proposed strategy outperforms standard\nbenchmarks and the S&P 500 index over the same period.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 20:22:44 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 23:43:11 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Baltaoglu", "Sevi", ""], ["Tong", "Lang", ""], ["Zhao", "Qing", ""]]}, {"id": "1802.03039", "submitter": "Akisato Kimura", "authors": "Akisato Kimura, Zoubin Ghahramani, Koh Takeuchi, Tomoharu Iwata,\n  Naonori Ueda", "title": "Few-shot learning of neural networks from scratch by pseudo example\n  optimization", "comments": "14 pages, 2 figures, will be presented at BMVC2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple but effective method for training neural\nnetworks with a limited amount of training data. Our approach inherits the idea\nof knowledge distillation that transfers knowledge from a deep or wide\nreference model to a shallow or narrow target model. The proposed method\nemploys this idea to mimic predictions of reference estimators that are more\nrobust against overfitting than the network we want to train. Different from\nalmost all the previous work for knowledge distillation that requires a large\namount of labeled training data, the proposed method requires only a small\namount of training data. Instead, we introduce pseudo training examples that\nare optimized as a part of model parameters. Experimental results for several\nbenchmark datasets demonstrate that the proposed method outperformed all the\nother baselines, such as naive training of the target model and standard\nknowledge distillation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 20:28:01 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 15:00:17 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2018 15:13:58 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Kimura", "Akisato", ""], ["Ghahramani", "Zoubin", ""], ["Takeuchi", "Koh", ""], ["Iwata", "Tomoharu", ""], ["Ueda", "Naonori", ""]]}, {"id": "1802.03041", "submitter": "Luis Mu\\~noz-Gonz\\'alez", "authors": "Andrea Paudice, Luis Mu\\~noz-Gonz\\'alez, Andras Gyorgy, Emil C. Lupu", "title": "Detection of Adversarial Training Examples in Poisoning Attacks through\n  Anomaly Detection", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has become an important component for many systems and\napplications including computer vision, spam filtering, malware and network\nintrusion detection, among others. Despite the capabilities of machine learning\nalgorithms to extract valuable information from data and produce accurate\npredictions, it has been shown that these algorithms are vulnerable to attacks.\nData poisoning is one of the most relevant security threats against machine\nlearning systems, where attackers can subvert the learning process by injecting\nmalicious samples in the training data. Recent work in adversarial machine\nlearning has shown that the so-called optimal attack strategies can\nsuccessfully poison linear classifiers, degrading the performance of the system\ndramatically after compromising a small fraction of the training dataset. In\nthis paper we propose a defence mechanism to mitigate the effect of these\noptimal poisoning attacks based on outlier detection. We show empirically that\nthe adversarial examples generated by these attack strategies are quite\ndifferent from genuine points, as no detectability constrains are considered to\ncraft the attack. Hence, they can be detected with an appropriate pre-filtering\nof the training dataset.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 20:34:19 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Paudice", "Andrea", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Gyorgy", "Andras", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1802.03043", "submitter": "Minhui Zou", "authors": "Minhui Zou, Yang Shi, Chengliang Wang, Fangyu Li, WenZhan Song and Yu\n  Wang", "title": "PoTrojan: powerful neural-level trojan designs in deep learning models", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity of deep learning (DL), artificial intelligence (AI) has\nbeen applied in many areas of human life. Neural network or artificial neural\nnetwork (NN), the main technique behind DL, has been extensively studied to\nfacilitate computer vision and natural language recognition. However, the more\nwe rely on information technology, the more vulnerable we are. That is,\nmalicious NNs could bring huge threat in the so-called coming AI era. In this\npaper, for the first time in the literature, we propose a novel approach to\ndesign and insert powerful neural-level trojans or PoTrojan in pre-trained NN\nmodels. Most of the time, PoTrojans remain inactive, not affecting the normal\nfunctions of their host NN models. PoTrojans could only be triggered in very\nrare conditions. Once activated, however, the PoTrojans could cause the host NN\nmodels to malfunction, either falsely predicting or classifying, which is a\nsignificant threat to human society of the AI era. We would explain the\nprinciples of PoTrojans and the easiness of designing and inserting them in\npre-trained deep learning models. PoTrojans doesn't modify the existing\narchitecture or parameters of the pre-trained models, without re-training.\nHence, the proposed method is very efficient.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 20:44:41 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 04:17:13 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Zou", "Minhui", ""], ["Shi", "Yang", ""], ["Wang", "Chengliang", ""], ["Li", "Fangyu", ""], ["Song", "WenZhan", ""], ["Wang", "Yu", ""]]}, {"id": "1802.03050", "submitter": "Ravi Ganti", "authors": "Ravi Ganti, Matyas Sustik, Quoc Tran and Brian Seaman", "title": "Thompson Sampling for Dynamic Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply active learning algorithms for dynamic pricing in a\nprominent e-commerce website. Dynamic pricing involves changing the price of\nitems on a regular basis, and uses the feedback from the pricing decisions to\nupdate prices of the items. Most popular approaches to dynamic pricing use a\npassive learning approach, where the algorithm uses historical data to learn\nvarious parameters of the pricing problem, and uses the updated parameters to\ngenerate a new set of prices. We show that one can use active learning\nalgorithms such as Thompson sampling to more efficiently learn the underlying\nparameters in a pricing problem. We apply our algorithms to a real e-commerce\nsystem and show that the algorithms indeed improve revenue compared to pricing\nalgorithms that use passive learning.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 21:17:28 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Ganti", "Ravi", ""], ["Sustik", "Matyas", ""], ["Tran", "Quoc", ""], ["Seaman", "Brian", ""]]}, {"id": "1802.03063", "submitter": "Ozsel Kilinc", "authors": "Ozsel Kilinc, Ismail Uysal", "title": "Learning Latent Representations in Neural Networks for Clustering\n  through Pseudo Supervision and Graph-based Activity Regularization", "comments": "To appear in proceedings of the International Conference on Learning\n  Representations 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel unsupervised clustering approach exploiting\nthe hidden information that is indirectly introduced through a pseudo\nclassification objective. Specifically, we randomly assign a pseudo\nparent-class label to each observation which is then modified by applying the\ndomain specific transformation associated with the assigned label. Generated\npseudo observation-label pairs are subsequently used to train a neural network\nwith Auto-clustering Output Layer (ACOL) that introduces multiple softmax nodes\nfor each pseudo parent-class. Due to the unsupervised objective based on\nGraph-based Activity Regularization (GAR) terms, softmax duplicates of each\nparent-class are specialized as the hidden information captured through the\nhelp of domain specific transformations is propagated during training.\nUltimately we obtain a k-means friendly latent representation. Furthermore, we\ndemonstrate how the chosen transformation type impacts performance and helps\npropagate the latent information that is useful in revealing unknown clusters.\nOur results show state-of-the-art performance for unsupervised clustering tasks\non MNIST, SVHN and USPS datasets, with the highest accuracies reported to date\nin the literature.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 22:13:59 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Kilinc", "Ozsel", ""], ["Uysal", "Ismail", ""]]}, {"id": "1802.03133", "submitter": "Liang Lin", "authors": "Guangrun Wang and Jiefeng Peng and Ping Luo and Xinjiang Wang and\n  Liang Lin", "title": "Batch Kalman Normalization: Towards Training Deep Neural Networks with\n  Micro-Batches", "comments": "We presented how to improve and accelerate the training of DNNs,\n  particularly under the context of micro-batches. (Submitted to IJCAI 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an indispensable component, Batch Normalization (BN) has successfully\nimproved the training of deep neural networks (DNNs) with mini-batches, by\nnormalizing the distribution of the internal representation for each hidden\nlayer. However, the effectiveness of BN would diminish with scenario of\nmicro-batch (e.g., less than 10 samples in a mini-batch), since the estimated\nstatistics in a mini-batch are not reliable with insufficient samples. In this\npaper, we present a novel normalization method, called Batch Kalman\nNormalization (BKN), for improving and accelerating the training of DNNs,\nparticularly under the context of micro-batches. Specifically, unlike the\nexisting solutions treating each hidden layer as an isolated system, BKN treats\nall the layers in a network as a whole system, and estimates the statistics of\na certain layer by considering the distributions of all its preceding layers,\nmimicking the merits of Kalman Filtering. BKN has two appealing properties.\nFirst, it enables more stable training and faster convergence compared to\nprevious works. Second, training DNNs using BKN performs substantially better\nthan those using BN and its variants, especially when very small mini-batches\nare presented. On the image classification benchmark of ImageNet, using BKN\npowered networks we improve upon the best-published model-zoo results: reaching\n74.0% top-1 val accuracy for InceptionV2. More importantly, using BKN achieves\nthe comparable accuracy with extremely smaller batch size, such as 64 times\nsmaller on CIFAR-10/100 and 8 times smaller on ImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 05:19:16 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 02:01:50 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Wang", "Guangrun", ""], ["Peng", "Jiefeng", ""], ["Luo", "Ping", ""], ["Wang", "Xinjiang", ""], ["Lin", "Liang", ""]]}, {"id": "1802.03144", "submitter": "Christian Walder Dr", "authors": "Christian J. Walder and Dongwoo Kim", "title": "Neural Dynamic Programming for Musical Self Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural sequence model designed specifically for symbolic music.\nThe model is based on a learned edit distance mechanism which generalises a\nclassic recursion from computer sci- ence, leading to a neural dynamic program.\nRe- peated motifs are detected by learning the transfor- mations between them.\nWe represent the arising computational dependencies using a novel data\nstructure, the edit tree; this perspective suggests natural approximations\nwhich afford the scaling up of our otherwise cubic time algorithm. We\ndemonstrate our model on real and synthetic data; in all cases it out-performs\na strong stacked long short-term memory benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 06:37:05 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 10:19:36 GMT"}, {"version": "v3", "created": "Wed, 29 Aug 2018 02:21:07 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Walder", "Christian J.", ""], ["Kim", "Dongwoo", ""]]}, {"id": "1802.03145", "submitter": "Qinxue Meng", "authors": "Qinxue Meng, Daniel Catchpoole, David Skillicorn, Paul J. Kennedy", "title": "Relational Autoencoder for Feature Extraction", "comments": "IJCNN-2017", "journal-ref": "2017 International Joint Conference on Neural Networks (IJCNN),\n  Anchorage, AK, 2017, pp. 364-371", "doi": "10.1109/IJCNN.2017.7965877", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction becomes increasingly important as data grows high\ndimensional. Autoencoder as a neural network based feature extraction method\nachieves great success in generating abstract features of high dimensional\ndata. However, it fails to consider the relationships of data samples which may\naffect experimental results of using original and new features. In this paper,\nwe propose a Relation Autoencoder model considering both data features and\ntheir relationships. We also extend it to work with other major autoencoder\nmodels including Sparse Autoencoder, Denoising Autoencoder and Variational\nAutoencoder. The proposed relational autoencoder models are evaluated on a set\nof benchmark datasets and the experimental results show that considering data\nrelationships can generate more robust features which achieve lower\nconstruction loss and then lower error rate in further classification compared\nto the other variants of autoencoders.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 06:42:38 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Meng", "Qinxue", ""], ["Catchpoole", "Daniel", ""], ["Skillicorn", "David", ""], ["Kennedy", "Paul J.", ""]]}, {"id": "1802.03151", "submitter": "Seyed Ali Osia", "authors": "Seyed Ali Osia, Ali Taheri, Ali Shahin Shamsabadi, Kleomenis Katevas,\n  Hamed Haddadi, Hamid R. Rabiee", "title": "Deep Private-Feature Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and evaluate Deep Private-Feature Extractor (DPFE), a deep model\nwhich is trained and evaluated based on information theoretic constraints.\nUsing the selective exchange of information between a user's device and a\nservice provider, DPFE enables the user to prevent certain sensitive\ninformation from being shared with a service provider, while allowing them to\nextract approved information using their model. We introduce and utilize the\nlog-rank privacy, a novel measure to assess the effectiveness of DPFE in\nremoving sensitive information and compare different models based on their\naccuracy-privacy tradeoff. We then implement and evaluate the performance of\nDPFE on smartphones to understand its complexity, resource demands, and\nefficiency tradeoffs. Our results on benchmark image datasets demonstrate that\nunder moderate resource utilization, DPFE can achieve high accuracy for primary\ntasks while preserving the privacy of sensitive features.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 07:12:29 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 16:32:47 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Osia", "Seyed Ali", ""], ["Taheri", "Ali", ""], ["Shamsabadi", "Ali Shahin", ""], ["Katevas", "Kleomenis", ""], ["Haddadi", "Hamed", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "1802.03162", "submitter": "Hung Le", "authors": "Hung Le, Quang Pham, Doyen Sahoo, Steven C.H. Hoi", "title": "URLNet: Learning a URL Representation with Deep Learning for Malicious\n  URL Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious URLs host unsolicited content and are used to perpetrate\ncybercrimes. It is imperative to detect them in a timely manner. Traditionally,\nthis is done through the usage of blacklists, which cannot be exhaustive, and\ncannot detect newly generated malicious URLs. To address this, recent years\nhave witnessed several efforts to perform Malicious URL Detection using Machine\nLearning. The most popular and scalable approaches use lexical properties of\nthe URL string by extracting Bag-of-words like features, followed by applying\nmachine learning models such as SVMs. There are also other features designed by\nexperts to improve the prediction performance of the model. These approaches\nsuffer from several limitations: (i) Inability to effectively capture semantic\nmeaning and sequential patterns in URL strings; (ii) Requiring substantial\nmanual feature engineering; and (iii) Inability to handle unseen features and\ngeneralize to test data. To address these challenges, we propose URLNet, an\nend-to-end deep learning framework to learn a nonlinear URL embedding for\nMalicious URL Detection directly from the URL. Specifically, we apply\nConvolutional Neural Networks to both characters and words of the URL String to\nlearn the URL embedding in a jointly optimized framework. This approach allows\nthe model to capture several types of semantic information, which was not\npossible by the existing models. We also propose advanced word-embeddings to\nsolve the problem of too many rare words observed in this task. We conduct\nextensive experiments on a large-scale dataset and show a significant\nperformance gain over existing methods. We also conduct ablation studies to\nevaluate the performance of various components of URLNet.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 08:07:13 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 03:42:49 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Le", "Hung", ""], ["Pham", "Quang", ""], ["Sahoo", "Doyen", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "1802.03170", "submitter": "Xiang Li", "authors": "Shuo Chen, Chen Gong, Jian Yang, Xiang Li, Yang Wei, Jun Li", "title": "Adversarial Metric Learning", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decades, intensive efforts have been put to design various loss\nfunctions and metric forms for metric learning problem. These improvements have\nshown promising results when the test data is similar to the training data.\nHowever, the trained models often fail to produce reliable distances on the\nambiguous test pairs due to the distribution bias between training set and test\nset. To address this problem, the Adversarial Metric Learning (AML) is proposed\nin this paper, which automatically generates adversarial pairs to remedy the\ndistribution bias and facilitate robust metric learning. Specifically, AML\nconsists of two adversarial stages, i.e. confusion and distinguishment. In\nconfusion stage, the ambiguous but critical adversarial data pairs are\nadaptively generated to mislead the learned metric. In distinguishment stage, a\nmetric is exhaustively learned to try its best to distinguish both the\nadversarial pairs and the original training pairs. Thanks to the challenges\nposed by the confusion stage in such competing process, the AML model is able\nto grasp plentiful difficult knowledge that has not been contained by the\noriginal training pairs, so the discriminability of AML can be significantly\nimproved. The entire model is formulated into optimization framework, of which\nthe global convergence is theoretically proved. The experimental results on toy\ndata and practical datasets clearly demonstrate the superiority of AML to the\nrepresentative state-of-the-art metric learning methodologies.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 08:43:57 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Chen", "Shuo", ""], ["Gong", "Chen", ""], ["Yang", "Jian", ""], ["Li", "Xiang", ""], ["Wei", "Yang", ""], ["Li", "Jun", ""]]}, {"id": "1802.03171", "submitter": "Long Yang", "authors": "Long Yang, Minhao Shi, Qian Zheng, Wenjia Meng, Gang Pan", "title": "A Unified Approach for Multi-step Temporal-Difference Learning with\n  Eligibility Traces in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a new multi-step temporal learning algorithm, called $Q(\\sigma)$,\nunifies $n$-step Tree-Backup (when $\\sigma=0$) and $n$-step Sarsa (when\n$\\sigma=1$) by introducing a sampling parameter $\\sigma$. However, similar to\nother multi-step temporal-difference learning algorithms, $Q(\\sigma)$ needs\nmuch memory consumption and computation time. Eligibility trace is an important\nmechanism to transform the off-line updates into efficient on-line ones which\nconsume less memory and computation time. In this paper, we further develop the\noriginal $Q(\\sigma)$, combine it with eligibility traces and propose a new\nalgorithm, called $Q(\\sigma ,\\lambda)$, in which $\\lambda$ is trace-decay\nparameter. This idea unifies Sarsa$(\\lambda)$ (when $\\sigma =1$) and\n$Q^{\\pi}(\\lambda)$ (when $\\sigma =0$). Furthermore, we give an upper error\nbound of $Q(\\sigma ,\\lambda)$ policy evaluation algorithm. We prove that\n$Q(\\sigma,\\lambda)$ control algorithm can converge to the optimal value\nfunction exponentially. We also empirically compare it with conventional\ntemporal-difference learning methods. Results show that, with an intermediate\nvalue of $\\sigma$, $Q(\\sigma ,\\lambda)$ creates a mixture of the existing\nalgorithms that can learn the optimal value significantly faster than the\nextreme end ($\\sigma=0$, or $1$).\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 08:46:21 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Yang", "Long", ""], ["Shi", "Minhao", ""], ["Zheng", "Qian", ""], ["Meng", "Wenjia", ""], ["Pan", "Gang", ""]]}, {"id": "1802.03184", "submitter": "Dongwoo Kim", "authors": "Dongwoo Kim, Christian Walder", "title": "Self-Bounded Prediction Suffix Tree via Approximate String Matching", "comments": "Proceedings of the 35th International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction suffix trees (PST) provide an effective tool for sequence\nmodelling and prediction. Current prediction techniques for PSTs rely on exact\nmatching between the suffix of the current sequence and the previously observed\nsequence. We present a provably correct algorithm for learning a PST with\napproximate suffix matching by relaxing the exact matching condition. We then\npresent a self-bounded enhancement of our algorithm where the depth of suffix\ntree grows automatically in response to the model performance on a training\nsequence. Through experiments on synthetic datasets as well as three real-world\ndatasets, we show that the approximate matching PST results in better\npredictive performance than the other variants of PST.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 09:52:35 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 03:58:01 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Kim", "Dongwoo", ""], ["Walder", "Christian", ""]]}, {"id": "1802.03203", "submitter": "J\\'er\\'emy Emile Cohen", "authors": "Jeremy Emile Cohen, Rodrigo Cabral Farias, Bertrand Rivet", "title": "Curve Registered Coupled Low Rank Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extension of the canonical polyadic (CP) tensor model where one\nof the latent factors is allowed to vary through data slices in a constrained\nway. The components of the latent factors, which we want to retrieve from data,\ncan vary from one slice to another up to a diffeomorphism. We suppose that the\ndiffeomorphisms are also unknown, thus merging curve registration and tensor\ndecomposition in one model, which we call registered CP. We present an\nalgorithm to retrieve both the latent factors and the diffeomorphism, which is\nassumed to be in a parametrized form. At the end of the paper, we show\nsimulation results comparing registered CP with other models from the\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 11:08:00 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Cohen", "Jeremy Emile", ""], ["Farias", "Rodrigo Cabral", ""], ["Rivet", "Bertrand", ""]]}, {"id": "1802.03212", "submitter": "Louis Falissard", "authors": "Louis Falissard, Guy Fagherazzi, Newton Howard and Bruno Falissard", "title": "Deep clustering of longitudinal data", "comments": "28 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are a family of computational models that have led to a\ndramatical improvement of the state of the art in several domains such as\nimage, voice or text analysis. These methods provide a framework to model\ncomplex, non-linear interactions in large datasets, and are naturally suited to\nthe analysis of hierarchical data such as, for instance, longitudinal data with\nthe use of recurrent neural networks. In the other hand, cohort studies have\nbecome a tool of importance in the research field of epidemiology. In such\nstudies, variables are measured repeatedly over time, to allow the practitioner\nto study their temporal evolution as trajectories, and, as such, as\nlongitudinal data. This paper investigates the application of the advanced\nmodelling techniques provided by the deep learning framework in the analysis of\nthe longitudinal data provided by cohort studies. Methods: A method for\nvisualizing and clustering longitudinal dataset is proposed, and compared to\nother widely used approaches to the problem on both real and simulated\ndatasets. Results: The proposed method is shown to be coherent with the\npreexisting procedures on simple tasks, and to outperform them on more complex\ntasks such as the partitioning of longitudinal datasets into non-spherical\nclusters. Conclusion: Deep artificial neural networks can be used to visualize\nlongitudinal data in a low dimensional manifold that is much simpler to\ninterpret than traditional longitudinal plots are. Consequently, practitioners\nshould start considering the use of deep artificial neural networks for the\nanalysis of their longitudinal data in studies to come.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 11:44:21 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Falissard", "Louis", ""], ["Fagherazzi", "Guy", ""], ["Howard", "Newton", ""], ["Falissard", "Bruno", ""]]}, {"id": "1802.03236", "submitter": "Daniel J Mankowitz", "authors": "Daniel J. Mankowitz, Timothy A. Mann, Pierre-Luc Bacon, Doina Precup\n  and Shie Mannor", "title": "Learning Robust Options", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust reinforcement learning aims to produce policies that have strong\nguarantees even in the face of environments/transition models whose parameters\nhave strong uncertainty. Existing work uses value-based methods and the usual\nprimitive action setting. In this paper, we propose robust methods for learning\ntemporally abstract actions, in the framework of options. We present a Robust\nOptions Policy Iteration (ROPI) algorithm with convergence guarantees, which\nlearns options that are robust to model uncertainty. We utilize ROPI to learn\nrobust options with the Robust Options Deep Q Network (RO-DQN) that solves\nmultiple tasks and mitigates model misspecification due to model uncertainty.\nWe present experimental results which suggest that policy iteration with linear\nfeatures may have an inherent form of robustness when using coarse feature\nrepresentations. In addition, we present experimental results which demonstrate\nthat robustness helps policy iteration implemented on top of deep neural\nnetworks to generalize over a much broader range of dynamics than non-robust\npolicy iteration.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 12:52:06 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Mankowitz", "Daniel J.", ""], ["Mann", "Timothy A.", ""], ["Bacon", "Pierre-Luc", ""], ["Precup", "Doina", ""], ["Mannor", "Shie", ""]]}, {"id": "1802.03239", "submitter": "Avi Rosenfeld", "authors": "Avi Rosenfeld and Ron Illuz and Dovid Gottesman and Mark Last", "title": "Using Discretization for Extending the Set of Predictive Features", "comments": "14 pages", "journal-ref": "EURASIP Journal on Advances in Signal Processing 2018:7", "doi": "10.1186/s13634-018-0528-x", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, attribute discretization is typically performed by replacing the\noriginal set of continuous features with a transposed set of discrete ones.\nThis paper provides support for a new idea that discretized features should\noften be used in addition to existing features and as such, datasets should be\nextended, and not replaced, by discretization. We also claim that\ndiscretization algorithms should be developed with the explicit purpose of\nenriching a non-discretized dataset with discretized values. We present such an\nalgorithm, D-MIAT, a supervised algorithm that discretizes data based on\nMinority Interesting Attribute Thresholds. D-MIAT only generates new features\nwhen strong indications exist for one of the target values needing to be\nlearned and thus is intended to be used in addition to the original data. We\npresent extensive empirical results demonstrating the success of using D-MIAT\non $ 28 $ benchmark datasets. We also demonstrate that $ 10 $ other\ndiscretization algorithms can also be used to generate features that yield\nimproved performance when used in combination with the original non-discretized\ndata. Our results show that the best predictive performance is attained using a\ncombination of the original dataset with added features from a \"standard\"\nsupervised discretization algorithm and D-MIAT.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 13:00:44 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Rosenfeld", "Avi", ""], ["Illuz", "Ron", ""], ["Gottesman", "Dovid", ""], ["Last", "Mark", ""]]}, {"id": "1802.03268", "submitter": "Hieu Pham", "authors": "Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, Jeff Dean", "title": "Efficient Neural Architecture Search via Parameter Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Efficient Neural Architecture Search (ENAS), a fast and\ninexpensive approach for automatic model design. In ENAS, a controller learns\nto discover neural network architectures by searching for an optimal subgraph\nwithin a large computational graph. The controller is trained with policy\ngradient to select a subgraph that maximizes the expected reward on the\nvalidation set. Meanwhile the model corresponding to the selected subgraph is\ntrained to minimize a canonical cross entropy loss. Thanks to parameter sharing\nbetween child models, ENAS is fast: it delivers strong empirical performances\nusing much fewer GPU-hours than all existing automatic model design approaches,\nand notably, 1000x less expensive than standard Neural Architecture Search. On\nthe Penn Treebank dataset, ENAS discovers a novel architecture that achieves a\ntest perplexity of 55.8, establishing a new state-of-the-art among all methods\nwithout post-training processing. On the CIFAR-10 dataset, ENAS designs novel\narchitectures that achieve a test error of 2.89%, which is on par with NASNet\n(Zoph et al., 2018), whose test error is 2.65%.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 14:14:37 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 03:34:00 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Pham", "Hieu", ""], ["Guan", "Melody Y.", ""], ["Zoph", "Barret", ""], ["Le", "Quoc V.", ""], ["Dean", "Jeff", ""]]}, {"id": "1802.03284", "submitter": "Feihu Huang", "authors": "Feihu Huang and Songcan Chen", "title": "Mini-Batch Stochastic ADMMs for Nonconvex Nonsmooth Optimization", "comments": "We have fixed some errors in the proofs. arXiv admin note: text\n  overlap with arXiv:1610.02758", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the large rising of complex data, the nonconvex models such as nonconvex\nloss function and nonconvex regularizer are widely used in machine learning and\npattern recognition. In this paper, we propose a class of mini-batch stochastic\nADMMs (alternating direction method of multipliers) for solving large-scale\nnonconvex nonsmooth problems. We prove that, given an appropriate mini-batch\nsize, the mini-batch stochastic ADMM without variance reduction (VR) technique\nis convergent and reaches a convergence rate of $O(1/T)$ to obtain a stationary\npoint of the nonconvex optimization, where $T$ denotes the number of\niterations. Moreover, we extend the mini-batch stochastic gradient method to\nboth the nonconvex SVRG-ADMM and SAGA-ADMM proposed in our initial manuscript\n\\cite{huang2016stochastic}, and prove these mini-batch stochastic ADMMs also\nreaches the convergence rate of $O(1/T)$ without condition on the mini-batch\nsize. In particular, we provide a specific parameter selection for step size\n$\\eta$ of stochastic gradients and penalty parameter $\\rho$ of augmented\nLagrangian function. Finally, extensive experimental results on both simulated\nand real-world data demonstrate the effectiveness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 02:48:22 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 04:54:31 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 02:45:42 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Huang", "Feihu", ""], ["Chen", "Songcan", ""]]}, {"id": "1802.03300", "submitter": "Johan Segers", "authors": "Simon Guillotte, Fran\\c{c}ois Perron, Johan Segers", "title": "Bayesian inference for bivariate ranks", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recommender system based on ranks is proposed, where an expert's ranking of\na set of objects and a user's ranking of a subset of those objects are combined\nto make a prediction of the user's ranking of all objects. The rankings are\nassumed to be induced by latent continuous variables corresponding to the\ngrades assigned by the expert and the user to the objects. The dependence\nbetween the expert and user grades is modelled by a copula in some parametric\nfamily. Given a prior distribution on the copula parameter, the user's complete\nranking is predicted by the mode of the posterior predictive distribution of\nthe user's complete ranking conditional on the expert's complete and the user's\nincomplete rankings. Various Markov chain Monte-Carlo algorithms are proposed\nto approximate the predictive distribution or only its mode. The predictive\ndistribution can be obtained exactly for the Farlie-Gumbel-Morgenstern copula\nfamily, providing a benchmark for the approximation accuracy of the algorithms.\nThe method is applied to the MovieLens 100k dataset with a Gaussian copula\nmodelling dependence between the expert's and user's grades.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 15:10:14 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Guillotte", "Simon", ""], ["Perron", "Fran\u00e7ois", ""], ["Segers", "Johan", ""]]}, {"id": "1802.03308", "submitter": "Frieder Stolzenburg", "authors": "Frieder Stolzenburg, Sandra Litz, Olivia Michael, Oliver Obst", "title": "The Power of Linear Recurrent Neural Networks", "comments": "34 pages, 13 figures, 2 tables, revised implementation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are a powerful means to cope with time series. We\nshow how linear, i.e., linearly activated recurrent neural networks (LRNNs) can\napproximate any time-dependent function f(t) given by a number of function\nvalues. The approximation can effectively be learned by simply solving a linear\nequation system; no backpropagation or similar methods are needed. Furthermore,\nthe size of an LRNN can be reduced significantly in one step, after inspecting\nthe eigenvalues of the network transition matrix, by taking only the most\nrelevant components. Therefore, in contrast to others, we do not only learn\nnetwork weights but also the network architecture. LRNNs have interesting\nproperties: They end up in ellipse trajectories in the long run and allow the\nprediction of further values and compact representations of functions. We\ndemonstrate this by several experiments, among them multiple superimposed\noscillators (MSO), robotic soccer, and predicting stock prices. LRNNs\noutperform the previous state-of-the-art for the MSO task with a minimal number\nof units.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 15:35:41 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 06:28:35 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 11:51:16 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 14:17:57 GMT"}, {"version": "v5", "created": "Tue, 4 May 2021 11:34:37 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Stolzenburg", "Frieder", ""], ["Litz", "Sandra", ""], ["Michael", "Olivia", ""], ["Obst", "Oliver", ""]]}, {"id": "1802.03334", "submitter": "Muhammad Osama", "authors": "Muhammad Osama, Dave Zachariah, Thomas B. Sch\\\"on", "title": "Learning Localized Spatio-Temporal Models From Streaming Data", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of predicting spatio-temporal processes with temporal\npatterns that vary across spatial regions, when data is obtained as a stream.\nThat is, when the training dataset is augmented sequentially. Specifically, we\ndevelop a localized spatio-temporal covariance model of the process that can\ncapture spatially varying temporal periodicities in the data. We then apply a\ncovariance-fitting methodology to learn the model parameters which yields a\npredictor that can be updated sequentially with each new data point. The\nproposed method is evaluated using both synthetic and real climate data which\ndemonstrate its ability to accurately predict data missing in spatial regions\nover time.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 16:36:23 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 15:00:01 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Osama", "Muhammad", ""], ["Zachariah", "Dave", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1802.03337", "submitter": "Di Wang", "authors": "Di Wang and Jinhui Xu", "title": "Large Scale Constrained Linear Regression Revisited: Faster Algorithms\n  via Preconditioning", "comments": "Appear in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the large-scale constrained linear regression\nproblem and propose faster methods based on some recent developments in\nsketching and optimization. Our algorithms combine (accelerated) mini-batch SGD\nwith a new method called two-step preconditioning to achieve an approximate\nsolution with a time complexity lower than that of the state-of-the-art\ntechniques for the low precision case. Our idea can also be extended to the\nhigh precision case, which gives an alternative implementation to the Iterative\nHessian Sketch (IHS) method with significantly improved time complexity.\nExperiments on benchmark and synthetic datasets suggest that our methods indeed\noutperform existing ones considerably in both the low and high precision cases.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 16:39:26 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Wang", "Di", ""], ["Xu", "Jinhui", ""]]}, {"id": "1802.03358", "submitter": "Yu-Jhe Li", "authors": "Yun-Chun Chen, Yu-Jhe Li, Aragorn Tseng, and Tsungnan Lin", "title": "Deep Learning for Malicious Flow Detection", "comments": "7 pages, 5 figures, 2017 IEEE 28th Annual International Symposium on\n  Personal, Indoor, and Mobile Radio Communications (PIMRC) (IEEE PIMRC 2017\n  Track 1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber security has grown up to be a hot issue in recent years. How to\nidentify potential malware becomes a challenging task. To tackle this\nchallenge, we adopt deep learning approaches and perform flow detection on real\ndata. However, real data often encounters an issue of imbalanced data\ndistribution which will lead to a gradient dilution issue. When training a\nneural network, this problem will not only result in a bias toward the majority\nclass but show the inability to learn from the minority classes. In this paper,\nwe propose an end-to-end trainable Tree-Shaped Deep Neural Network (TSDNN)\nwhich classifies the data in a layer-wise manner. To better learn from the\nminority classes, we propose a Quantity Dependent Backpropagation (QDBP)\nalgorithm which incorporates the knowledge of the disparity between classes. We\nevaluate our method on an imbalanced data set. Experimental result demonstrates\nthat our approach outperforms the state-of-the-art methods and justifies that\nthe proposed method is able to overcome the difficulty of imbalanced learning.\nWe also conduct a partial flow experiment which shows the feasibility of\nreal-time detection and a zero-shot learning experiment which justifies the\ngeneralization capability of deep learning in cyber security.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 17:16:02 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Chen", "Yun-Chun", ""], ["Li", "Yu-Jhe", ""], ["Tseng", "Aragorn", ""], ["Lin", "Tsungnan", ""]]}, {"id": "1802.03360", "submitter": "Vadim Smolyakov", "authors": "Vadim Smolyakov", "title": "Information Planning for Text Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information planning enables faster learning with fewer training examples. It\nis particularly applicable when training examples are costly to obtain. This\nwork examines the advantages of information planning for text data by focusing\non three supervised models: Naive Bayes, supervised LDA and deep neural\nnetworks. We show that planning based on entropy and mutual information\noutperforms random selection baseline and therefore accelerates learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 17:25:43 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 19:22:30 GMT"}, {"version": "v3", "created": "Wed, 21 Mar 2018 14:45:32 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Smolyakov", "Vadim", ""]]}, {"id": "1802.03386", "submitter": "Sebastien Bubeck", "authors": "Zeyuan Allen-Zhu, S\\'ebastien Bubeck, Yuanzhi Li", "title": "Make the Minority Great Again: First-Order Regret Bound for Contextual\n  Bandits", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret bounds in online learning compare the player's performance to $L^*$,\nthe optimal performance in hindsight with a fixed strategy. Typically such\nbounds scale with the square root of the time horizon $T$. The more refined\nconcept of first-order regret bound replaces this with a scaling $\\sqrt{L^*}$,\nwhich may be much smaller than $\\sqrt{T}$. It is well known that minor variants\nof standard algorithms satisfy first-order regret bounds in the full\ninformation and multi-armed bandit settings. In a COLT 2017 open problem,\nAgarwal, Krishnamurthy, Langford, Luo, and Schapire raised the issue that\nexisting techniques do not seem sufficient to obtain first-order regret bounds\nfor the contextual bandit problem. In the present paper, we resolve this open\nproblem by presenting a new strategy based on augmenting the policy space.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 18:47:21 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Bubeck", "S\u00e9bastien", ""], ["Li", "Yuanzhi", ""]]}, {"id": "1802.03390", "submitter": "Junkyung Kim", "authors": "Matthew Ricci, Junkyung Kim, Thomas Serre", "title": "Same-different problems strain convolutional neural networks", "comments": "6 Pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robust and efficient recognition of visual relations in images is a\nhallmark of biological vision. We argue that, despite recent progress in visual\nrecognition, modern machine vision algorithms are severely limited in their\nability to learn visual relations. Through controlled experiments, we\ndemonstrate that visual-relation problems strain convolutional neural networks\n(CNNs). The networks eventually break altogether when rote memorization becomes\nimpossible, as when intra-class variability exceeds network capacity. Motivated\nby the comparable success of biological vision, we argue that feedback\nmechanisms including attention and perceptual grouping may be the key\ncomputational components underlying abstract visual reasoning.\\\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 18:55:34 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 22:29:20 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 17:00:23 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Ricci", "Matthew", ""], ["Kim", "Junkyung", ""], ["Serre", "Thomas", ""]]}, {"id": "1802.03396", "submitter": "Bryan Gregory", "authors": "Bryan Gregory", "title": "Predicting Customer Churn: Extreme Gradient Boosting with Temporal Data", "comments": "WSDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting customer churn using large scale time-series data is a\ncommon problem facing many business domains. The creation of model features\nacross various time windows for training and testing can be particularly\nchallenging due to temporal issues common to time-series data. In this paper,\nwe will explore the application of extreme gradient boosting (XGBoost) on a\ncustomer dataset with a wide-variety of temporal features in order to create a\nhighly-accurate customer churn model. In particular, we describe an effective\nmethod for handling temporally sensitive feature engineering. The proposed\nmodel was submitted in the WSDM Cup 2018 Churn Challenge and achieved\nfirst-place out of 575 teams.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 17:24:27 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Gregory", "Bryan", ""]]}, {"id": "1802.03418", "submitter": "C\\'edric Beaulac", "authors": "C\\'edric Beaulac and Jeffrey S. Rosenthal", "title": "Predicting University Students' Academic Success and Major using Random\n  Forests", "comments": null, "journal-ref": "Research in Higher Education 2019", "doi": "10.1007/s11162-019-09546-y", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, a large data set containing every course taken by every\nundergraduate student in a major university in Canada over 10 years is\nanalysed. Modern machine learning algorithms can use large data sets to build\nuseful tools for the data provider, in this case, the university. In this\narticle, two classifiers are constructed using random forests. To begin, the\nfirst two semesters of courses completed by a student are used to predict if\nthey will obtain an undergraduate degree. Secondly, for the students that\ncompleted a program, their major is predicted using once again the first few\ncourses they have registered to. A classification tree is an intuitive and\npowerful classifier and building a random forest of trees improves this\nclassifier. Random forests also allow for reliable variable importance\nmeasurements. These measures explain what variables are useful to the\nclassifiers and can be used to better understand what is statistically related\nto the students' situation. The results are two accurate classifiers and a\nvariable importance analysis that provides useful information to university\nadministrations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 19:19:17 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 17:10:21 GMT"}, {"version": "v3", "created": "Sat, 12 Jan 2019 16:13:33 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Beaulac", "C\u00e9dric", ""], ["Rosenthal", "Jeffrey S.", ""]]}, {"id": "1802.03426", "submitter": "Leland McInnes", "authors": "Leland McInnes, John Healy and James Melville", "title": "UMAP: Uniform Manifold Approximation and Projection for Dimension\n  Reduction", "comments": "Reference implementation available at http://github.com/lmcinnes/umap", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UMAP (Uniform Manifold Approximation and Projection) is a novel manifold\nlearning technique for dimension reduction. UMAP is constructed from a\ntheoretical framework based in Riemannian geometry and algebraic topology. The\nresult is a practical scalable algorithm that applies to real world data. The\nUMAP algorithm is competitive with t-SNE for visualization quality, and\narguably preserves more of the global structure with superior run time\nperformance. Furthermore, UMAP has no computational restrictions on embedding\ndimension, making it viable as a general purpose dimension reduction technique\nfor machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 19:39:33 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 18:54:07 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 01:56:41 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["McInnes", "Leland", ""], ["Healy", "John", ""], ["Melville", "James", ""]]}, {"id": "1802.03452", "submitter": "Mingzhi Dong", "authors": "Mingzhi Dong, Yujiang Wang, Xiaochen Yang, Jing-Hao Xue", "title": "Learning Local Metrics and Influential Regions for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of distance-based classifiers heavily depends on the\nunderlying distance metric, so it is valuable to learn a suitable metric from\nthe data. To address the problem of multimodality, it is desirable to learn\nlocal metrics. In this short paper, we define a new intuitive distance with\nlocal metrics and influential regions, and subsequently propose a novel local\nmetric learning method for distance-based classification. Our key intuition is\nto partition the metric space into influential regions and a background region,\nand then regulate the effectiveness of each local metric to be within the\nrelated influential regions. We learn local metrics and influential regions to\nreduce the empirical hinge loss, and regularize the parameters on the basis of\na resultant learning bound. Encouraging experimental results are obtained from\nvarious public and popular data sets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 21:34:24 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Dong", "Mingzhi", ""], ["Wang", "Yujiang", ""], ["Yang", "Xiaochen", ""], ["Xue", "Jing-Hao", ""]]}, {"id": "1802.03464", "submitter": "Mingzhi Dong", "authors": "Mingzhi Dong, Xiaochen Yang, Yang Wu, Jing-Hao Xue", "title": "Metric Learning via Maximizing the Lipschitz Margin Ratio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Lipschitz margin ratio and a new metric\nlearning framework for classification through maximizing the ratio. This\nframework enables the integration of both the inter-class margin and the\nintra-class dispersion, as well as the enhancement of the generalization\nability of a classifier. To introduce the Lipschitz margin ratio and its\nassociated learning bound, we elaborate the relationship between metric\nlearning and Lipschitz functions, as well as the representability and\nlearnability of the Lipschitz functions. After proposing the new metric\nlearning framework based on the introduced Lipschitz margin ratio, we also\nprove that some well known metric learning algorithms can be shown as special\ncases of the proposed framework. In addition, we illustrate the framework by\nimplementing it for learning the squared Mahalanobis metric, and by\ndemonstrating its encouraging results on eight popular datasets of machine\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 22:00:55 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Dong", "Mingzhi", ""], ["Yang", "Xiaochen", ""], ["Wu", "Yang", ""], ["Xue", "Jing-Hao", ""]]}, {"id": "1802.03471", "submitter": "Mathias Lecuyer", "authors": "Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu,\n  Suman Jana", "title": "Certified Robustness to Adversarial Examples with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples that fool machine learning models, particularly deep\nneural networks, have been a topic of intense research interest, with attacks\nand defenses being developed in a tight back-and-forth. Most past defenses are\nbest effort and have been shown to be vulnerable to sophisticated attacks.\nRecently a set of certified defenses have been introduced, which provide\nguarantees of robustness to norm-bounded attacks, but they either do not scale\nto large datasets or are limited in the types of models they can support. This\npaper presents the first certified defense that both scales to large networks\nand datasets (such as Google's Inception network for ImageNet) and applies\nbroadly to arbitrary model types. Our defense, called PixelDP, is based on a\nnovel connection between robustness against adversarial examples and\ndifferential privacy, a cryptographically-inspired formalism, that provides a\nrigorous, generic, and flexible foundation for defense.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 22:24:50 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 15:54:44 GMT"}, {"version": "v3", "created": "Sun, 7 Oct 2018 18:37:06 GMT"}, {"version": "v4", "created": "Wed, 29 May 2019 15:17:39 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Lecuyer", "Mathias", ""], ["Atlidakis", "Vaggelis", ""], ["Geambasu", "Roxana", ""], ["Hsu", "Daniel", ""], ["Jana", "Suman", ""]]}, {"id": "1802.03475", "submitter": "Min Ye", "authors": "Min Ye and Emmanuel Abbe", "title": "Communication-Computation Efficient Gradient Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops coding techniques to reduce the running time of\ndistributed learning tasks. It characterizes the fundamental tradeoff to\ncompute gradients (and more generally vector summations) in terms of three\nparameters: computation load, straggler tolerance and communication cost. It\nfurther gives an explicit coding scheme that achieves the optimal tradeoff\nbased on recursive polynomial constructions, coding both across data subsets\nand vector components. As a result, the proposed scheme allows to minimize the\nrunning time for gradient computations. Implementations are made on Amazon EC2\nclusters using Python with mpi4py package. Results show that the proposed\nscheme maintains the same generalization error while reducing the running time\nby $32\\%$ compared to uncoded schemes and $23\\%$ compared to prior coded\nschemes focusing only on stragglers (Tandon et al., ICML 2017).\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 23:13:24 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Ye", "Min", ""], ["Abbe", "Emmanuel", ""]]}, {"id": "1802.03480", "submitter": "Martin Simonovsky", "authors": "Martin Simonovsky, Nikos Komodakis", "title": "GraphVAE: Towards Generation of Small Graphs Using Variational\n  Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning on graphs has become a popular research topic with many\napplications. However, past work has concentrated on learning graph embedding\ntasks, which is in contrast with advances in generative models for images and\ntext. Is it possible to transfer this progress to the domain of graphs? We\npropose to sidestep hurdles associated with linearization of such discrete\nstructures by having a decoder output a probabilistic fully-connected graph of\na predefined maximum size directly at once. Our method is formulated as a\nvariational autoencoder. We evaluate on the challenging task of molecule\ngeneration.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 23:57:46 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Simonovsky", "Martin", ""], ["Komodakis", "Nikos", ""]]}, {"id": "1802.03482", "submitter": "Ali Shameli", "authors": "Ali Shameli, Yasin Abbasi-Yadkori", "title": "A Continuation Method for Discrete Optimization and its Application to\n  Nearest Neighbor Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuation method is a popular approach in non-convex optimization and\ncomputer vision. The main idea is to start from a simple function that can be\nminimized efficiently, and gradually transform it to the more complicated\noriginal objective function. The solution of the simpler problem is used as the\nstarting point to solve the original problem. We show a continuation method for\ndiscrete optimization problems. Ideally, we would like the evolved function to\nbe hill-climbing friendly and to have the same global minima as the original\nfunction. We show that the proposed continuation method is the best affine\napproximation of a transformation that is guaranteed to transform the function\nto a hill-climbing friendly function and to have the same global minima.\n  We show the effectiveness of the proposed technique in the problem of nearest\nneighbor classification. Although nearest neighbor methods are often\ncompetitive in terms of sample efficiency, the computational complexity in the\ntest phase has been a major obstacle in their applicability in big data\nproblems. Using the proposed continuation method, we show an improved\ngraph-based nearest neighbor algorithm. The method is readily understood and\neasy to implement. We show how the computational complexity of the method in\nthe test phase scales gracefully with the size of the training set, a property\nthat is particularly important in big data applications.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 00:09:42 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Shameli", "Ali", ""], ["Abbasi-Yadkori", "Yasin", ""]]}, {"id": "1802.03486", "submitter": "Ziyi Chen", "authors": "Ziyi Chen", "title": "An LSTM Recurrent Network for Step Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones with sensors such as accelerometer and gyroscope can be used as\npedometers and navigators. In this paper, we propose to use an LSTM recurrent\nnetwork for counting the number of steps taken by both blind and sighted users,\nbased on an annotated smartphone sensor dataset, WeAllWork. The models were\ntrained separately for sighted people, blind people with a long cane or a guide\ndog for Leave-One-Out training modality. It achieved 5% overcount and\nundercount rate.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 00:44:20 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Chen", "Ziyi", ""]]}, {"id": "1802.03487", "submitter": "Chulhee Yun", "authors": "Chulhee Yun, Suvrit Sra, Ali Jadbabaie", "title": "Small nonlinearities in activation functions create bad local minima in\n  neural networks", "comments": "33 pages, appeared at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the loss surface of neural networks. We prove that even for\none-hidden-layer networks with \"slightest\" nonlinearity, the empirical risks\nhave spurious local minima in most cases. Our results thus indicate that in\ngeneral \"no spurious local minima\" is a property limited to deep linear\nnetworks, and insights obtained from linear networks may not be robust.\nSpecifically, for ReLU(-like) networks we constructively prove that for almost\nall practical datasets there exist infinitely many local minima. We also\npresent a counterexample for more general activations (sigmoid, tanh, arctan,\nReLU, etc.), for which there exists a bad local minimum. Our results make the\nleast restrictive assumptions relative to existing results on spurious local\noptima in neural networks. We complete our discussion by presenting a\ncomprehensive characterization of global optimality for deep linear networks,\nwhich unifies other results on this topic.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 00:49:17 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 20:58:56 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2018 04:27:13 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 15:25:47 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Yun", "Chulhee", ""], ["Sra", "Suvrit", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1802.03488", "submitter": "Katja Seeliger", "authors": "Marjolein Troost, Katja Seeliger and Marcel van Gerven", "title": "Generalization of an Upper Bound on the Number of Nodes Needed to\n  Achieve Linear Separability", "comments": "Presented at the 29th Benelux Conference on Artificial Intelligence\n  (BNAIC 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important issue in neural network research is how to choose the number of\nnodes and layers such as to solve a classification problem. We provide new\nintuitions based on earlier results by An et al. (2015) by deriving an upper\nbound on the number of nodes in networks with two hidden layers such that\nlinear separability can be achieved. Concretely, we show that if the data can\nbe described in terms of N finite sets and the used activation function f is\nnon-constant, increasing and has a left asymptote, we can derive how many nodes\nare needed to linearly separate these sets. This will be an upper bound that\ndepends on the structure of the data. This structure can be analyzed using an\nalgorithm. For the leaky rectified linear activation function, we prove\nseparately that under some conditions on the slope, the same number of layers\nand nodes as for the aforementioned activation functions is sufficient. We\nempirically validate our claims.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 00:49:51 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Troost", "Marjolein", ""], ["Seeliger", "Katja", ""], ["van Gerven", "Marcel", ""]]}, {"id": "1802.03497", "submitter": "Scott Gigante", "authors": "Scott Gigante, David van Dijk, Kevin Moon, Alexander Strzalkowski, Guy\n  Wolf, Smita Krishnaswamy", "title": "Modeling Global Dynamics from Local Snapshots with Deep Generative\n  Neural Networks", "comments": "Published in SampTA 2019", "journal-ref": "Sampling Theory & Applications (2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Complex high dimensional stochastic dynamic systems arise in many\napplications in the natural sciences and especially biology. However, while\nthese systems are difficult to describe analytically, \"snapshot\" measurements\nthat sample the output of the system are often available. In order to model the\ndynamics of such systems given snapshot data, or local transitions, we present\na deep neural network framework we call Dynamics Modeling Network or DyMoN.\nDyMoN is a neural network framework trained as a deep generative Markov model\nwhose next state is a probability distribution based on the current state.\nDyMoN is trained using samples of current and next-state pairs, and thus does\nnot require longitudinal measurements. We show the advantage of DyMoN over\nshallow models such as Kalman filters and hidden Markov models, and other deep\nmodels such as recurrent neural networks in its ability to embody the dynamics\n(which can be studied via perturbation of the neural network) and generate\nlongitudinal hypothetical trajectories. We perform three case studies in which\nwe apply DyMoN to different types of biological systems and extract features of\nthe dynamics in each case by examining the learned model.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 01:51:33 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 01:33:56 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 21:10:53 GMT"}, {"version": "v4", "created": "Fri, 28 Sep 2018 23:32:56 GMT"}, {"version": "v5", "created": "Mon, 10 Jun 2019 23:50:34 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gigante", "Scott", ""], ["van Dijk", "David", ""], ["Moon", "Kevin", ""], ["Strzalkowski", "Alexander", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1802.03499", "submitter": "Chuanyun Xu Dr.", "authors": "Chuanyun Xu, Yang Zhang, Xin Feng, YongXing Ge, Yihao Zhang, Jianwu\n  Long", "title": "Local Contrast Learning", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a deep model from small data is yet an opening and challenging\nproblem. We focus on one-shot classification by deep learning approach based on\na small quantity of training samples. We proposed a novel deep learning\napproach named Local Contrast Learning (LCL) based on the key insight about a\nhuman cognitive behavior that human recognizes the objects in a specific\ncontext by contrasting the objects in the context or in her/his memory. LCL is\nused to train a deep model that can contrast the recognizing sample with a\ncouple of contrastive samples randomly drawn and shuffled. On one-shot\nclassification task on Omniglot, the deep model based LCL with 122 layers and\n1.94 millions of parameters, which was trained on a tiny dataset with only 60\nclasses and 20 samples per class, achieved the accuracy 97.99% that outperforms\nhuman and state-of-the-art established by Bayesian Program Learning (BPL)\ntrained on 964 classes. LCL is a fundamental idea which can be applied to\nalleviate parametric model's overfitting resulted by lack of training samples.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 01:54:44 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Xu", "Chuanyun", ""], ["Zhang", "Yang", ""], ["Feng", "Xin", ""], ["Ge", "YongXing", ""], ["Zhang", "Yihao", ""], ["Long", "Jianwu", ""]]}, {"id": "1802.03501", "submitter": "Yinlam Chow", "authors": "Ofir Nachum, Yinlam Chow, and Mohammad Ghavamzadeh", "title": "Path Consistency Learning in Tsallis Entropy Regularized MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sparse entropy-regularized reinforcement learning (ERL) problem\nin which the entropy term is a special form of the Tsallis entropy. The optimal\npolicy of this formulation is sparse, i.e.,~at each state, it has non-zero\nprobability for only a small number of actions. This addresses the main\ndrawback of the standard Shannon entropy-regularized RL (soft ERL) formulation,\nin which the optimal policy is softmax, and thus, may assign a non-negligible\nprobability mass to non-optimal actions. This problem is aggravated as the\nnumber of actions is increased. In this paper, we follow the work of Nachum et\nal. (2017) in the soft ERL setting, and propose a class of novel path\nconsistency learning (PCL) algorithms, called {\\em sparse PCL}, for the sparse\nERL problem that can work with both on-policy and off-policy data. We first\nderive a {\\em sparse consistency} equation that specifies a relationship\nbetween the optimal value function and policy of the sparse ERL along any\nsystem trajectory. Crucially, a weak form of the converse is also true, and we\nquantify the sub-optimality of a policy which satisfies sparse consistency, and\nshow that as we increase the number of actions, this sub-optimality is better\nthan that of the soft ERL optimal policy. We then use this result to derive the\nsparse PCL algorithms. We empirically compare sparse PCL with its soft\ncounterpart, and show its advantage, especially in problems with a large number\nof actions.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 01:57:49 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Nachum", "Ofir", ""], ["Chow", "Yinlam", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "1802.03505", "submitter": "Emanuele Sansone", "authors": "Emanuele Sansone and Hafiz Tiomoko Ali and Sun Jiacheng", "title": "Coulomb Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the true density in high-dimensional feature spaces is a well-known\nproblem in machine learning. In this work, we consider generative autoencoders\nbased on maximum-mean discrepancy (MMD) and provide theoretical insights. In\nparticular, (i) we prove that MMD coupled with Coulomb kernels has optimal\nconvergence properties, which are similar to convex functionals, thus improving\nthe training of autoencoders, and (ii) we provide a probabilistic bound on the\ngeneralization performance, highlighting some fundamental conditions to achieve\nbetter generalization. We validate the theory on synthetic examples and on the\npopular dataset of celebrities' faces, showing that our model, called Coulomb\nautoencoders, outperform the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 02:37:31 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 15:18:59 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 14:18:52 GMT"}, {"version": "v4", "created": "Fri, 19 Oct 2018 12:32:58 GMT"}, {"version": "v5", "created": "Thu, 21 Feb 2019 12:07:34 GMT"}, {"version": "v6", "created": "Tue, 26 Nov 2019 10:25:20 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Sansone", "Emanuele", ""], ["Ali", "Hafiz Tiomoko", ""], ["Jiacheng", "Sun", ""]]}, {"id": "1802.03517", "submitter": "Junyuan Hong", "authors": "Junyuan Hong and Huanhuan Chen and Feng Lin", "title": "Disturbance Grassmann Kernels for Subspace-Based Learning", "comments": "This paper include 3 figures, 10 pages, and has been accpeted to\n  SIGKDD'18", "journal-ref": null, "doi": "10.1145/3219819.3219959", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on subspace-based learning problems, where data\nelements are linear subspaces instead of vectors. To handle this kind of data,\nGrassmann kernels were proposed to measure the space structure and used with\nclassifiers, e.g., Support Vector Machines (SVMs). However, the existing\ndiscriminative algorithms mostly ignore the instability of subspaces, which\nwould cause the classifiers misled by disturbed instances. Thus we propose\nconsidering all potential disturbance of subspaces in learning processes to\nobtain more robust classifiers. Firstly, we derive the dual optimization of\nlinear classifiers with disturbance subject to a known distribution, resulting\nin a new kernel, Disturbance Grassmann (DG) kernel. Secondly, we research into\ntwo kinds of disturbance, relevant to the subspace matrix and singular values\nof bases, with which we extend the Projection kernel on Grassmann manifolds to\ntwo new kernels. Experiments on action data indicate that the proposed kernels\nperform better compared to state-of-the-art subspace-based methods, even in a\nworse environment.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 04:16:22 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 03:16:59 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Hong", "Junyuan", ""], ["Chen", "Huanhuan", ""], ["Lin", "Feng", ""]]}, {"id": "1802.03522", "submitter": "Kyongche Kang", "authors": "Kyongche Kang and Jack Michalak", "title": "Enhanced version of AdaBoostM1 with J48 Tree learning method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning focuses on the construction and study of systems that can\nlearn from data. This is connected with the classification problem, which\nusually is what Machine Learning algorithms are designed to solve. When a\nmachine learning method is used by people with no special expertise in machine\nlearning, it is important that the method be robust in classification, in the\nsense that reasonable performance is obtained with minimal tuning of the\nproblem at hand. Algorithms are evaluated based on how robust they can classify\nthe given data. In this paper, we propose a quantifiable measure of robustness,\nand describe a particular learning method that is robust according to this\nmeasure in the context of classification problem. We proposed Adaptive Boosting\n(AdaBoostM1) with J48(C4.5 tree) as a base learner with tuning weight threshold\n(P) and number of iterations (I) for boosting algorithm. To benchmark the\nperformance, we used the baseline classifier, AdaBoostM1 with Decision Stump as\nbase learner without tuning parameters. By tuning parameters and using J48 as\nbase learner, we are able to reduce the overall average error rate ratio\n(errorC/errorNB) from 2.4 to 0.9 for development sets of data and 2.1 to 1.2\nfor evaluation sets of data.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 05:35:16 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Kang", "Kyongche", ""], ["Michalak", "Jack", ""]]}, {"id": "1802.03532", "submitter": "Wenyi Wang Mr.", "authors": "Wenyi Wang and William J. Welch", "title": "Bayesian Optimization Using Monotonicity Information and Its Application\n  in Machine Learning Hyperparameter", "comments": "Citation style errors fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for a family of optimization problems where the\nobjective can be decomposed as a sum of functions with monotonicity properties.\nThe motivating problem is optimization of hyperparameters of machine learning\nalgorithms, where we argue that the objective, validation error, can be\ndecomposed as monotonic functions of the hyperparameters. Our proposed\nalgorithm adapts Bayesian optimization methods to incorporate the monotonicity\nconstraints. We illustrate the advantages of exploiting monotonicity using\nillustrative examples and demonstrate the improvements in optimization\nefficiency for some machine learning hyperparameter tuning applications.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 07:14:53 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 22:38:34 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Wang", "Wenyi", ""], ["Welch", "William J.", ""]]}, {"id": "1802.03542", "submitter": "Soonam Lee", "authors": "Soonam Lee and Chichen Fu and Paul Salama and Kenneth W. Dunn and\n  Edward J. Delp", "title": "Tubule segmentation of fluorescence microscopy images based on\n  convolutional neural networks with inhomogeneity correction", "comments": "IS&T International Symposium on Electronic Imaging 2018", "journal-ref": null, "doi": "10.2352/ISSN.2470-1173.2018.15.COIMG-199", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fluorescence microscopy has become a widely used tool for studying various\nbiological structures of in vivo tissue or cells. However, quantitative\nanalysis of these biological structures remains a challenge due to their\ncomplexity which is exacerbated by distortions caused by lens aberrations and\nlight scattering. Moreover, manual quantification of such image volumes is an\nintractable and error-prone process, making the need for automated image\nanalysis methods crucial. This paper describes a segmentation method for\ntubular structures in fluorescence microscopy images using convolutional neural\nnetworks with data augmentation and inhomogeneity correction. The segmentation\nresults of the proposed method are visually and numerically compared with other\nmicroscopy segmentation methods. Experimental results indicate that the\nproposed method has better performance with correctly segmenting and\nidentifying multiple tubular structures compared to other methods.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 08:03:22 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Lee", "Soonam", ""], ["Fu", "Chichen", ""], ["Salama", "Paul", ""], ["Dunn", "Kenneth W.", ""], ["Delp", "Edward J.", ""]]}, {"id": "1802.03560", "submitter": "Yihan Gao", "authors": "Yihan Gao, Chao Zhang, Jian Peng, Aditya Parameswaran", "title": "The Importance of Norm Regularization in Linear Graph Embedding:\n  Theoretical Analysis and Empirical Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning distributed representations for nodes in graphs is a crucial\nprimitive in network analysis with a wide spectrum of applications. Linear\ngraph embedding methods learn such representations by optimizing the likelihood\nof both positive and negative edges while constraining the dimension of the\nembedding vectors. We argue that the generalization performance of these\nmethods is not due to the dimensionality constraint as commonly believed, but\nrather the small norm of embedding vectors. Both theoretical and empirical\nevidence are provided to support this argument: (a) we prove that the\ngeneralization error of these methods can be bounded by limiting the norm of\nvectors, regardless of the embedding dimension; (b) we show that the\ngeneralization performance of linear graph embedding methods is correlated with\nthe norm of embedding vectors, which is small due to the early stopping of SGD\nand the vanishing gradients. We performed extensive experiments to validate our\nanalysis and showcased the importance of proper norm regularization in\npractice.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 09:42:56 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 22:31:11 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Gao", "Yihan", ""], ["Zhang", "Chao", ""], ["Peng", "Jian", ""], ["Parameswaran", "Aditya", ""]]}, {"id": "1802.03567", "submitter": "Gilles Ducharme", "authors": "Gilles R. Ducharme", "title": "Crit\\`eres de qualit\\'e d'un classifieur g\\'en\\'eraliste", "comments": "24 pages, in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of choosing a good classifier. For each\nproblem there exist an optimal classifier, but none are optimal, regarding the\nerror rate, in all cases. Because there exists a large number of classifiers, a\nuser would rather prefer an all-purpose classifier that is easy to adjust, in\nthe hope that it will do almost as good as the optimal. In this paper we\nestablish a list of criteria that a good generalist classifier should satisfy .\nWe first discuss data analytic, these criteria are presented. Six among the\nmost popular classifiers are selected and scored according to these criteria.\nTables allow to easily appreciate the relative values of each. In the end,\nrandom forests turn out to be the best classifiers.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 11:25:27 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 09:30:05 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Ducharme", "Gilles R.", ""]]}, {"id": "1802.03568", "submitter": "Francisco Charte", "authors": "Francisco Charte and Antonio J. Rivera and David Charte and Mar\\'ia J.\n  del Jesus and Francisco Herrera", "title": "Tips, guidelines and tools for managing multi-label datasets: the\n  mldr.datasets R package and the Cometa data repository", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2018.02.011", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New proposals in the field of multi-label learning algorithms have been\ngrowing in number steadily over the last few years. The experimentation\nassociated with each of them always goes through the same phases: selection of\ndatasets, partitioning, training, analysis of results and, finally, comparison\nwith existing methods. This last step is often hampered since it involves using\nexactly the same datasets, partitioned in the same way and using the same\nvalidation strategy. In this paper we present a set of tools whose objective is\nto facilitate the management of multi-label datasets, aiming to standardize the\nexperimentation procedure. The two main tools are an R package, mldr.datasets,\nand a web repository with datasets, Cometa. Together, these tools will simplify\nthe collection of datasets, their partitioning, documentation and export to\nmultiple formats, among other functions. Some tips, recommendations and\nguidelines for a good experimental analysis of multi-label methods are also\npresented.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 11:30:31 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Charte", "Francisco", ""], ["Rivera", "Antonio J.", ""], ["Charte", "David", ""], ["del Jesus", "Mar\u00eda J.", ""], ["Herrera", "Francisco", ""]]}, {"id": "1802.03569", "submitter": "Tam Le", "authors": "Tam Le, Makoto Yamada", "title": "Persistence Fisher Kernel: A Riemannian Manifold Kernel for Persistence\n  Diagrams", "comments": "to appear at the 32nd Conference on Neural Information Processing\n  Systems (NIPS), Canada, 2018. (Camera-ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algebraic topology methods have recently played an important role for\nstatistical analysis with complicated geometric structured data such as shapes,\nlinked twist maps, and material data. Among them, \\textit{persistent homology}\nis a well-known tool to extract robust topological features, and outputs as\n\\textit{persistence diagrams} (PDs). However, PDs are point multi-sets which\ncan not be used in machine learning algorithms for vector data. To deal with\nit, an emerged approach is to use kernel methods, and an appropriate geometry\nfor PDs is an important factor to measure the similarity of PDs. A popular\ngeometry for PDs is the \\textit{Wasserstein metric}. However, Wasserstein\ndistance is not \\textit{negative definite}. Thus, it is limited to build\npositive definite kernels upon the Wasserstein distance \\textit{without\napproximation}. In this work, we rely upon the alternative \\textit{Fisher\ninformation geometry} to propose a positive definite kernel for PDs\n\\textit{without approximation}, namely the Persistence Fisher (PF) kernel.\nThen, we analyze eigensystem of the integral operator induced by the proposed\nkernel for kernel machines. Based on that, we derive generalization error\nbounds via covering numbers and Rademacher averages for kernel machines with\nthe PF kernel. Additionally, we show some nice properties such as stability and\ninfinite divisibility for the proposed kernel. Furthermore, we also propose a\nlinear time complexity over the number of points in PDs for an approximation of\nour proposed kernel with a bounded error. Throughout experiments with many\ndifferent tasks on various benchmark datasets, we illustrate that the PF kernel\ncompares favorably with other baseline kernels for PDs.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 12:02:24 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 23:18:08 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 06:18:03 GMT"}, {"version": "v4", "created": "Fri, 19 Oct 2018 08:14:05 GMT"}, {"version": "v5", "created": "Sat, 27 Oct 2018 01:41:04 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Le", "Tam", ""], ["Yamada", "Makoto", ""]]}, {"id": "1802.03583", "submitter": "Ali Shahin Shamsabadi", "authors": "Ali Shahin Shamsabadi, Hamed Haddadi and Andrea Cavallaro", "title": "Distributed One-class Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a cloud-based filter trained to block third parties from uploading\nprivacy-sensitive images of others to online social media. The proposed filter\nuses Distributed One-Class Learning, which decomposes the cloud-based filter\ninto multiple one-class classifiers. Each one-class classifier captures the\nproperties of a class of privacy-sensitive images with an autoencoder. The\nmulti-class filter is then reconstructed by combining the parameters of the\none-class autoencoders. The training takes place on edge devices (e.g.\nsmartphones) and therefore users do not need to upload their private and/or\nsensitive images to the cloud. A major advantage of the proposed filter over\nexisting distributed learning approaches is that users cannot access, even\nindirectly, the parameters of other users. Moreover, the filter can cope with\nthe imbalanced and complex distribution of the image content and the\nindependent probability of addition of new users. We evaluate the performance\nof the proposed distributed filter using the exemplar task of blocking a user\nfrom sharing privacy-sensitive images of other users. In particular, we\nvalidate the behavior of the proposed multi-class filter with\nnon-privacy-sensitive images, the accuracy when the number of classes\nincreases, and the robustness to attacks when an adversary user has access to\nprivacy-sensitive images of other users.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 13:09:47 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Shamsabadi", "Ali Shahin", ""], ["Haddadi", "Hamed", ""], ["Cavallaro", "Andrea", ""]]}, {"id": "1802.03596", "submitter": "Fengwei Zhou", "authors": "Fengwei Zhou, Bin Wu, Zhenguo Li", "title": "Deep Meta-Learning: Learning to Learn in the Concept Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning remains challenging for meta-learning that learns a\nlearning algorithm (meta-learner) from many related tasks. In this work, we\nargue that this is due to the lack of a good representation for meta-learning,\nand propose deep meta-learning to integrate the representation power of deep\nlearning into meta-learning. The framework is composed of three modules, a\nconcept generator, a meta-learner, and a concept discriminator, which are\nlearned jointly. The concept generator, e.g. a deep residual net, extracts a\nrepresentation for each instance that captures its high-level concept, on which\nthe meta-learner performs few-shot learning, and the concept discriminator\nrecognizes the concepts. By learning to learn in the concept space rather than\nin the complicated instance space, deep meta-learning can substantially improve\nvanilla meta-learning, which is demonstrated on various few-shot image\nrecognition problems. For example, on 5-way-1-shot image recognition on\nCIFAR-100 and CUB-200, it improves Matching Nets from 50.53% and 56.53% to\n58.18% and 63.47%, improves MAML from 49.28% and 50.45% to 56.65% and 64.63%,\nand improves Meta-SGD from 53.83% and 53.34% to 61.62% and 66.95%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 14:18:08 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Zhou", "Fengwei", ""], ["Wu", "Bin", ""], ["Li", "Zhenguo", ""]]}, {"id": "1802.03604", "submitter": "Gong-Duo Zhang", "authors": "Gong-Duo Zhang, Shen-Yi Zhao, Hao Gao, Wu-Jun Li", "title": "Feature-Distributed SVRG for High-Dimensional Linear Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear classification has been widely used in many high-dimensional\napplications like text classification. To perform linear classification for\nlarge-scale tasks, we often need to design distributed learning methods on a\ncluster of multiple machines. In this paper, we propose a new distributed\nlearning method, called feature-distributed stochastic variance reduced\ngradient (FD-SVRG) for high-dimensional linear classification. Unlike most\nexisting distributed learning methods which are instance-distributed, FD-SVRG\nis feature-distributed. FD-SVRG has lower communication cost than other\ninstance-distributed methods when the data dimensionality is larger than the\nnumber of data instances. Experimental results on real data demonstrate that\nFD-SVRG can outperform other state-of-the-art distributed methods for\nhigh-dimensional linear classification in terms of both communication cost and\nwall-clock time, when the dimensionality is larger than the number of instances\nin training data.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 14:53:57 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Zhang", "Gong-Duo", ""], ["Zhao", "Shen-Yi", ""], ["Gao", "Hao", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1802.03605", "submitter": "Matthew Guzdial", "authors": "Matthew Guzdial and Mark O. Riedl", "title": "Combinets: Creativity via Recombination of Neural Networks", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the defining characteristics of human creativity is the ability to\nmake conceptual leaps, creating something surprising from typical knowledge. In\ncomparison, deep neural networks often struggle to handle cases outside of\ntheir training data, which is especially problematic for problems with limited\ntraining data. Approaches exist to transfer knowledge from problems with\nsufficient data to those with insufficient data, but they tend to require\nadditional training or a domain-specific method of transfer. We present a new\napproach, conceptual expansion, that serves as a general representation for\nreusing existing trained models to derive new models without backpropagation.\nWe evaluate our approach on few-shot variations of two tasks: image\nclassification and image generation, and outperform standard transfer learning\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 14:54:10 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 03:38:08 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 15:16:21 GMT"}, {"version": "v4", "created": "Thu, 6 Sep 2018 21:44:51 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Guzdial", "Matthew", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1802.03628", "submitter": "Thanh Lam Hoang", "authors": "Han Qiu, Hoang Thanh Lam, Francesco Fusco and Mathieu Sinn", "title": "Learning Correlation Space for Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approximation algorithm for efficient correlation search in\ntime series data. In our method, we use Fourier transform and neural network to\nembed time series into a low-dimensional Euclidean space. The given space is\nlearned such that time series correlation can be effectively approximated from\nEuclidean distance between corresponding embedded vectors. Therefore, search\nfor correlated time series can be done using an index in the embedding space\nfor efficient nearest neighbor search. Our theoretical analysis illustrates\nthat our method's accuracy can be guaranteed under certain regularity\nconditions. We further conduct experiments on real-world datasets and the\nresults show that our method indeed outperforms the baseline solution. In\nparticular, for approximation of correlation, our method reduces the\napproximation loss by a half in most test cases compared to the baseline\nsolution. For top-$k$ highest correlation search, our method improves the\nprecision from 5\\% to 20\\% while the query time is similar to the baseline\napproach query time.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 17:59:25 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 07:34:06 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 12:15:58 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Qiu", "Han", ""], ["Lam", "Hoang Thanh", ""], ["Fusco", "Francesco", ""], ["Sinn", "Mathieu", ""]]}, {"id": "1802.03644", "submitter": "Ruilin Li", "authors": "Ruilin Li, Xiaojing Ye, Haomin Zhou, Hongyuan Zha", "title": "Learning to Match via Inverse Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified data-driven framework based on inverse optimal transport\nthat can learn adaptive, nonlinear interaction cost function from noisy and\nincomplete empirical matching matrix and predict new matching in various\nmatching contexts. We emphasize that the discrete optimal transport plays the\nrole of a variational principle which gives rise to an optimization-based\nframework for modeling the observed empirical matching data. Our formulation\nleads to a non-convex optimization problem which can be solved efficiently by\nan alternating optimization method. A key novel aspect of our formulation is\nthe incorporation of marginal relaxation via regularized Wasserstein distance,\nsignificantly improving the robustness of the method in the face of noisy or\nmissing empirical matching data. Our model falls into the category of\nprescriptive models, which not only predict potential future matching, but is\nalso able to explain what leads to empirical matching and quantifies the impact\nof changes in matching factors. The proposed approach has wide applicability\nincluding predicting matching in online dating, labor market, college\napplication and crowdsourcing. We back up our claims with numerical experiments\non both synthetic data and real world data sets.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 19:33:38 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 03:12:50 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 00:22:27 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Li", "Ruilin", ""], ["Ye", "Xiaojing", ""], ["Zhou", "Haomin", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1802.03646", "submitter": "Yukun Ding", "authors": "Yukun Ding, Jinglan Liu, Jinjun Xiong, Yiyu Shi", "title": "On the Universal Approximability and Complexity Bounds of Quantized ReLU\n  Neural Networks", "comments": "Published in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compression is a key step to deploy large neural networks on\nresource-constrained platforms. As a popular compression technique,\nquantization constrains the number of distinct weight values and thus reducing\nthe number of bits required to represent and store each weight. In this paper,\nwe study the representation power of quantized neural networks. First, we prove\nthe universal approximability of quantized ReLU networks on a wide class of\nfunctions. Then we provide upper bounds on the number of weights and the memory\nsize for a given approximation error bound and the bit-width of weights for\nfunction-independent and function-dependent structures. Our results reveal\nthat, to attain an approximation error bound of $\\epsilon$, the number of\nweights needed by a quantized network is no more than\n$\\mathcal{O}\\left(\\log^5(1/\\epsilon)\\right)$ times that of an unquantized\nnetwork. This overhead is of much lower order than the lower bound of the\nnumber of weights needed for the error bound, supporting the empirical success\nof various quantization techniques. To the best of our knowledge, this is the\nfirst in-depth study on the complexity bounds of quantized neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 19:43:42 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 23:16:45 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 22:51:22 GMT"}, {"version": "v4", "created": "Sat, 12 Jan 2019 21:54:14 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Ding", "Yukun", ""], ["Liu", "Jinglan", ""], ["Xiong", "Jinjun", ""], ["Shi", "Yiyu", ""]]}, {"id": "1802.03651", "submitter": "Sotirios Chatzis", "authors": "Harris Partaourides, Sotirios Chatzis", "title": "Deep learning with t-exponential Bayesian kitchen sinks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian learning has been recently considered as an effective means of\naccounting for uncertainty in trained deep network parameters. This is of\ncrucial importance when dealing with small or sparse training datasets. On the\nother hand, shallow models that compute weighted sums of their inputs, after\npassing them through a bank of arbitrary randomized nonlinearities, have been\nrecently shown to enjoy good test error bounds that depend on the number of\nnonlinearities. Inspired from these advances, in this paper we examine novel\ndeep network architectures, where each layer comprises a bank of arbitrary\nnonlinearities, linearly combined using multiple alternative sets of weights.\nWe effect model training by means of approximate inference based on a\nt-divergence measure; this generalizes the Kullback-Leibler divergence in the\ncontext of the t-exponential family of distributions. We adopt the\nt-exponential family since it can more flexibly accommodate real-world data,\nthat entail outliers and distributions with fat tails, compared to conventional\nGaussian model assumptions. We extensively evaluate our approach using several\nchallenging benchmarks, and provide comparative results to related\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 21:27:02 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Partaourides", "Harris", ""], ["Chatzis", "Sotirios", ""]]}, {"id": "1802.03654", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Gal Dalal, Bruno Scherrer, Shie Mannor", "title": "Beyond the One Step Greedy Approach in Reinforcement Learning", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The famous Policy Iteration algorithm alternates between policy improvement\nand policy evaluation. Implementations of this algorithm with several variants\nof the latter evaluation stage, e.g, $n$-step and trace-based returns, have\nbeen analyzed in previous works. However, the case of multiple-step lookahead\npolicy improvement, despite the recent increase in empirical evidence of its\nstrength, has to our knowledge not been carefully analyzed yet. In this work,\nwe introduce the first such analysis. Namely, we formulate variants of\nmultiple-step policy improvement, derive new algorithms using these definitions\nand prove their convergence. Moreover, we show that recent prominent\nReinforcement Learning algorithms are, in fact, instances of our framework. We\nthus shed light on their empirical success and give a recipe for deriving new\nalgorithms for future study.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 22:22:03 GMT"}, {"version": "v2", "created": "Sat, 2 Jun 2018 17:19:20 GMT"}, {"version": "v3", "created": "Mon, 30 Jul 2018 18:02:11 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Efroni", "Yonathan", ""], ["Dalal", "Gal", ""], ["Scherrer", "Bruno", ""], ["Mannor", "Shie", ""]]}, {"id": "1802.03675", "submitter": "Sandeep Konam", "authors": "Sandeep Konam, Ian Quah, Stephanie Rosenthal, Manuela Veloso", "title": "Understanding Convolutional Networks with APPLE : Automatic Patch\n  Pattern Labeling for Explanation", "comments": "AAAI/ACM Conference on AI, Ethics, and Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of deep learning, recent efforts have been focused on\nanalyzing how learned networks make their classifications. We are interested in\nanalyzing the network output based on the network structure and information\nflow through the network layers. We contribute an algorithm for 1) analyzing a\ndeep network to find neurons that are 'important' in terms of the network\nclassification outcome, and 2)automatically labeling the patches of the input\nimage that activate these important neurons. We propose several measures of\nimportance for neurons and demonstrate that our technique can be used to gain\ninsight into, and explain how a network decomposes an image to make its final\nclassification.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 01:33:33 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Konam", "Sandeep", ""], ["Quah", "Ian", ""], ["Rosenthal", "Stephanie", ""], ["Veloso", "Manuela", ""]]}, {"id": "1802.03676", "submitter": "Mathieu Blondel", "authors": "Arthur Mensch, Mathieu Blondel", "title": "Differentiable Dynamic Programming for Structured Prediction and\n  Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic programming (DP) solves a variety of structured combinatorial\nproblems by iteratively breaking them down into smaller subproblems. In spite\nof their versatility, DP algorithms are usually non-differentiable, which\nhampers their use as a layer in neural networks trained by backpropagation. To\naddress this issue, we propose to smooth the max operator in the dynamic\nprogramming recursion, using a strongly convex regularizer. This allows to\nrelax both the optimal value and solution of the original combinatorial\nproblem, and turns a broad class of DP algorithms into differentiable\noperators. Theoretically, we provide a new probabilistic perspective on\nbackpropagating through these DP operators, and relate them to inference in\ngraphical models. We derive two particular instantiations of our framework, a\nsmoothed Viterbi algorithm for sequence prediction and a smoothed DTW algorithm\nfor time-series alignment. We showcase these instantiations on two structured\nprediction tasks and on structured and sparse attention for neural machine\ntranslation.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 01:36:06 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 06:01:45 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Mensch", "Arthur", ""], ["Blondel", "Mathieu", ""]]}, {"id": "1802.03685", "submitter": "Daniel Selsam", "authors": "Daniel Selsam, Matthew Lamm, Benedikt B\\\"unz, Percy Liang, Leonardo de\n  Moura, David L. Dill", "title": "Learning a SAT Solver from Single-Bit Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present NeuroSAT, a message passing neural network that learns to solve\nSAT problems after only being trained as a classifier to predict\nsatisfiability. Although it is not competitive with state-of-the-art SAT\nsolvers, NeuroSAT can solve problems that are substantially larger and more\ndifficult than it ever saw during training by simply running for more\niterations. Moreover, NeuroSAT generalizes to novel distributions; after\ntraining only on random SAT problems, at test time it can solve SAT problems\nencoding graph coloring, clique detection, dominating set, and vertex cover\nproblems, all on a range of distributions over small random graphs.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 03:04:28 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 22:52:15 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 22:20:18 GMT"}, {"version": "v4", "created": "Tue, 12 Mar 2019 00:56:48 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Selsam", "Daniel", ""], ["Lamm", "Matthew", ""], ["B\u00fcnz", "Benedikt", ""], ["Liang", "Percy", ""], ["de Moura", "Leonardo", ""], ["Dill", "David L.", ""]]}, {"id": "1802.03688", "submitter": "Jingwei Zhang", "authors": "Jingwei Zhang, Tongliang Liu, Dacheng Tao", "title": "On the Rates of Convergence from Surrogate Risk Minimizers to the Bayes\n  Optimal Classifier", "comments": "Under Minor Revision in TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the rates of convergence from empirical surrogate risk minimizers to\nthe Bayes optimal classifier. Specifically, we introduce the notion of\n\\emph{consistency intensity} to characterize a surrogate loss function and\nexploit this notion to obtain the rate of convergence from an empirical\nsurrogate risk minimizer to the Bayes optimal classifier, enabling fair\ncomparisons of the excess risks of different surrogate risk minimizers. The\nmain result of the paper has practical implications including (1) showing that\nhinge loss is superior to logistic and exponential loss in the sense that its\nempirical minimizer converges faster to the Bayes optimal classifier and (2)\nguiding to modify surrogate loss functions to accelerate the convergence to the\nBayes optimal classifier.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 03:43:28 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 16:41:38 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Zhang", "Jingwei", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1802.03689", "submitter": "Thai Hung Le", "authors": "Hung Le, Truyen Tran and Svetha Venkatesh", "title": "Dual Control Memory Augmented Neural Networks for Treatment\n  Recommendations", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-assisted treatment recommendations hold a promise to reduce physician\ntime and decision errors. We formulate the task as a sequence-to-sequence\nprediction model that takes the entire time-ordered medical history as input,\nand predicts a sequence of future clinical procedures and medications. It is\nbuilt on the premise that an effective treatment plan may have long-term\ndependencies from previous medical history. We approach the problem by using a\nmemory-augmented neural network, in particular, by leveraging the recent\ndifferentiable neural computer that consists of a neural controller and an\nexternal memory module. But differing from the original model, we use dual\ncontrollers, one for encoding the history followed by another for decoding the\ntreatment sequences. In the encoding phase, the memory is updated as new input\nis read; at the end of this phase, the memory holds not only the medical\nhistory but also the information about the current illness. During the decoding\nphase, the memory is write-protected. The decoding controller generates a\ntreatment sequence, one treatment option at a time. The resulting dual\ncontroller write-protected memory-augmented neural network is demonstrated on\nthe MIMIC-III dataset on two tasks: procedure prediction and medication\nprescription. The results show improved performance over both traditional\nbag-of-words and sequence-to-sequence methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 03:50:41 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Le", "Hung", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1802.03690", "submitter": "Shubhendu Trivedi", "authors": "Risi Kondor, Shubhendu Trivedi", "title": "On the Generalization of Equivariance and Convolution in Neural Networks\n  to the Action of Compact Groups", "comments": "Final version that appeared in the proceedings of the 35th\n  International Conference on Machine Learning (ICML 2018), Stockholm, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have been extremely successful in the image\nrecognition domain because they ensure equivariance to translations. There have\nbeen many recent attempts to generalize this framework to other domains,\nincluding graphs and data lying on manifolds. In this paper we give a rigorous,\ntheoretical treatment of convolution and equivariance in neural networks with\nrespect to not just translations, but the action of any compact group. Our main\nresult is to prove that (given some natural constraints) convolutional\nstructure is not just a sufficient, but also a necessary condition for\nequivariance to the action of a compact group. Our exposition makes use of\nconcepts from representation theory and noncommutative harmonic analysis and\nderives new generalized convolution formulae.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 04:32:33 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 06:22:57 GMT"}, {"version": "v3", "created": "Sat, 10 Nov 2018 23:20:43 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Kondor", "Risi", ""], ["Trivedi", "Shubhendu", ""]]}, {"id": "1802.03691", "submitter": "Xinyun Chen", "authors": "Xinyun Chen, Chang Liu, Dawn Song", "title": "Tree-to-tree Neural Networks for Program Translation", "comments": "Published in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program translation is an important tool to migrate legacy code in one\nlanguage into an ecosystem built in a different language. In this work, we are\nthe first to employ deep neural networks toward tackling this problem. We\nobserve that program translation is a modular procedure, in which a sub-tree of\nthe source tree is translated into the corresponding target sub-tree at each\nstep. To capture this intuition, we design a tree-to-tree neural network to\ntranslate a source tree into a target one. Meanwhile, we develop an attention\nmechanism for the tree-to-tree model, so that when the decoder expands one\nnon-terminal in the target tree, the attention mechanism locates the\ncorresponding sub-tree in the source tree to guide the expansion of the\ndecoder. We evaluate the program translation capability of our tree-to-tree\nmodel against several state-of-the-art approaches. Compared against other\nneural translation models, we observe that our approach is consistently better\nthan the baselines with a margin of up to 15 points. Further, our approach can\nimprove the previous state-of-the-art program translation approaches by a\nmargin of 20 points on the translation of real-world projects.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 04:42:03 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 17:43:13 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 03:51:27 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Chen", "Xinyun", ""], ["Liu", "Chang", ""], ["Song", "Dawn", ""]]}, {"id": "1802.03692", "submitter": "Yang Cao", "authors": "Yang Cao, Zheng Wen, Branislav Kveton, and Yao Xie", "title": "Nearly Optimal Adaptive Procedure with Change Detection for\n  Piecewise-Stationary Bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-armed bandit (MAB) is a class of online learning problems where a\nlearning agent aims to maximize its expected cumulative reward while repeatedly\nselecting to pull arms with unknown reward distributions. We consider a\nscenario where the reward distributions may change in a piecewise-stationary\nfashion at unknown time steps. We show that by incorporating a simple\nchange-detection component with classic UCB algorithms to detect and adapt to\nchanges, our so-called M-UCB algorithm can achieve nearly optimal regret bound\non the order of $O(\\sqrt{MKT\\log T})$, where $T$ is the number of time steps,\n$K$ is the number of arms, and $M$ is the number of stationary segments.\nComparison with the best available lower bound shows that our M-UCB is nearly\noptimal in $T$ up to a logarithmic factor. We also compare M-UCB with the\nstate-of-the-art algorithms in numerical experiments using a public Yahoo!\ndataset to demonstrate its superior performance.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 04:57:28 GMT"}, {"version": "v2", "created": "Sat, 17 Feb 2018 18:29:03 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2019 20:00:00 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 06:13:01 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Cao", "Yang", ""], ["Wen", "Zheng", ""], ["Kveton", "Branislav", ""], ["Xie", "Yao", ""]]}, {"id": "1802.03699", "submitter": "Jintao Ke", "authors": "Jintao Ke, Shuaichao Zhang, Hai Yang, Xiqun Chen", "title": "PCA-Based Missing Information Imputation for Real-Time Crash Likelihood\n  Prediction Under Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real-time crash likelihood prediction has been an important research\ntopic. Various classifiers, such as support vector machine (SVM) and tree-based\nboosting algorithms, have been proposed in traffic safety studies. However, few\nresearch focuses on the missing data imputation in real-time crash likelihood\nprediction, although missing values are commonly observed due to breakdown of\nsensors or external interference. Besides, classifying imbalanced data is also\na difficult problem in real-time crash likelihood prediction, since it is hard\nto distinguish crash-prone cases from non-crash cases which compose the\nmajority of the observed samples. In this paper, principal component analysis\n(PCA) based approaches, including LS-PCA, PPCA, and VBPCA, are employed for\nimputing missing values, while two kinds of solutions are developed to solve\nthe problem in imbalanced data. The results show that PPCA and VBPCA not only\noutperform LS-PCA and other imputation methods (including mean imputation and\nk-means clustering imputation), in terms of the root mean square error (RMSE),\nbut also help the classifiers achieve better predictive performance. The two\nsolutions, i.e., cost-sensitive learning and synthetic minority oversampling\ntechnique (SMOTE), help improve the sensitivity by adjusting the classifiers to\npay more attention to the minority class.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 06:21:47 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Ke", "Jintao", ""], ["Zhang", "Shuaichao", ""], ["Yang", "Hai", ""], ["Chen", "Xiqun", ""]]}, {"id": "1802.03713", "submitter": "Qi Meng", "authors": "Qi Meng, Shuxin Zheng, Huishuai Zhang, Wei Chen, Zhi-Ming Ma, Tie-Yan\n  Liu", "title": "$\\mathcal{G}$-SGD: Optimizing ReLU Neural Networks in its Positively\n  Scale-Invariant Space", "comments": null, "journal-ref": "ICLR2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that neural networks with rectified linear units (ReLU)\nactivation functions are positively scale-invariant. Conventional algorithms\nlike stochastic gradient descent optimize the neural networks in the vector\nspace of weights, which is, however, not positively scale-invariant. This\nmismatch may lead to problems during the optimization process. Then, a natural\nquestion is: \\emph{can we construct a new vector space that is positively\nscale-invariant and sufficient to represent ReLU neural networks so as to\nbetter facilitate the optimization process }? In this paper, we provide our\npositive answer to this question. First, we conduct a formal study on the\npositive scaling operators which forms a transformation group, denoted as\n$\\mathcal{G}$. We show that the value of a path (i.e. the product of the\nweights along the path) in the neural network is invariant to positive scaling\nand prove that the value vector of all the paths is sufficient to represent the\nneural networks under mild conditions. Second, we show that one can identify\nsome basis paths out of all the paths and prove that the linear span of their\nvalue vectors (denoted as $\\mathcal{G}$-space) is an invariant space with lower\ndimension under the positive scaling group. Finally, we design stochastic\ngradient descent algorithm in $\\mathcal{G}$-space (abbreviated as\n$\\mathcal{G}$-SGD) to optimize the value vector of the basis paths of neural\nnetworks with little extra cost by leveraging back-propagation. Our experiments\nshow that $\\mathcal{G}$-SGD significantly outperforms the conventional SGD\nalgorithm in optimizing ReLU networks on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 08:57:08 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 08:27:07 GMT"}, {"version": "v3", "created": "Wed, 18 Apr 2018 12:43:48 GMT"}, {"version": "v4", "created": "Wed, 23 May 2018 07:36:56 GMT"}, {"version": "v5", "created": "Mon, 25 Jun 2018 08:43:51 GMT"}, {"version": "v6", "created": "Tue, 9 Oct 2018 12:40:55 GMT"}, {"version": "v7", "created": "Wed, 7 Nov 2018 03:26:11 GMT"}, {"version": "v8", "created": "Tue, 23 Mar 2021 13:46:25 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Meng", "Qi", ""], ["Zheng", "Shuxin", ""], ["Zhang", "Huishuai", ""], ["Chen", "Wei", ""], ["Ma", "Zhi-Ming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1802.03725", "submitter": "Shubhm Gupta", "authors": "Shubham Gupta, Gaurav Sharma and Ambedkar Dukkipati", "title": "A Generative Model for Dynamic Networks with Applications", "comments": "Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks observed in real world like social networks, collaboration networks\netc., exhibit temporal dynamics, i.e. nodes and edges appear and/or disappear\nover time. In this paper, we propose a generative, latent space based,\nstatistical model for such networks (called dynamic networks). We consider the\ncase where the number of nodes is fixed, but the presence of edges can vary\nover time. Our model allows the number of communities in the network to be\ndifferent at different time steps. We use a neural network based methodology to\nperform approximate inference in the proposed model and its simplified version.\nExperiments done on synthetic and real world networks for the task of community\ndetection and link prediction demonstrate the utility and effectiveness of our\nmodel as compared to other similar existing approaches.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 11:20:49 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 17:20:05 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Gupta", "Shubham", ""], ["Sharma", "Gaurav", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1802.03752", "submitter": "Sourav Mishra", "authors": "Sourav Mishra, Toshihiko Yamasaki, Hideaki Imaizumi", "title": "Supervised classification of Dermatological diseases by Deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces a deep-learning based efficient classifier for common\ndermatological conditions, aimed at people without easy access to skin\nspecialists. We report approximately 80% accuracy, in a situation where primary\ncare doctors have attained 57% success rate, according to recent literature.\nThe rationale of its design is centered on deploying and updating it on\nhandheld devices in near future. Dermatological diseases are common in every\npopulation and have a wide spectrum in severity. With a shortage of\ndermatological expertise being observed in several countries, machine learning\nsolutions can augment medical services and advise regarding existence of common\ndiseases. The paper implements supervised classification of nine distinct\nconditions which have high occurrence in East Asian countries. Our current\nattempt establishes that deep learning based techniques are viable avenues for\npreliminary information to aid patients.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 15:34:20 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 16:17:12 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2018 17:23:02 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Mishra", "Sourav", ""], ["Yamasaki", "Toshihiko", ""], ["Imaizumi", "Hideaki", ""]]}, {"id": "1802.03753", "submitter": "Pawe{\\l} Budzianowski", "authors": "Gell\\'ert Weisz, Pawe{\\l} Budzianowski, Pei-Hao Su, Milica Ga\\v{s}i\\'c", "title": "Sample Efficient Deep Reinforcement Learning for Dialogue Systems with\n  Large Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spoken dialogue systems, we aim to deploy artificial intelligence to build\nautomated dialogue agents that can converse with humans. A part of this effort\nis the policy optimisation task, which attempts to find a policy describing how\nto respond to humans, in the form of a function taking the current state of the\ndialogue and returning the response of the system. In this paper, we\ninvestigate deep reinforcement learning approaches to solve this problem.\nParticular attention is given to actor-critic methods, off-policy reinforcement\nlearning with experience replay, and various methods aimed at reducing the bias\nand variance of estimators. When combined, these methods result in the\npreviously proposed ACER algorithm that gave competitive results in gaming\nenvironments. These environments however are fully observable and have a\nrelatively small action set so in this paper we examine the application of ACER\nto dialogue policy optimisation. We show that this method beats the current\nstate-of-the-art in deep learning approaches for spoken dialogue systems. This\nnot only leads to a more sample efficient algorithm that can train faster, but\nalso allows us to apply the algorithm in more difficult environments than\nbefore. We thus experiment with learning in a very large action space, which\nhas two orders of magnitude more actions than previously considered. We find\nthat ACER trains significantly faster than the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 15:37:37 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Weisz", "Gell\u00e9rt", ""], ["Budzianowski", "Pawe\u0142", ""], ["Su", "Pei-Hao", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1802.03761", "submitter": "Paul Rubenstein", "authors": "Paul K. Rubenstein, Bernhard Schoelkopf, Ilya Tolstikhin", "title": "On the Latent Space of Wasserstein Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the role of latent space dimensionality in Wasserstein auto-encoders\n(WAEs). Through experimentation on synthetic and real datasets, we argue that\nrandom encoders should be preferred over deterministic encoders. We highlight\nthe potential of WAEs for representation learning with promising results on a\nbenchmark disentanglement task.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 16:10:41 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Rubenstein", "Paul K.", ""], ["Schoelkopf", "Bernhard", ""], ["Tolstikhin", "Ilya", ""]]}, {"id": "1802.03765", "submitter": "Matt Olfat", "authors": "Matt Olfat, Anil Aswani", "title": "Convex Formulations for Fair Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though there is a growing body of literature on fairness for supervised\nlearning, the problem of incorporating fairness into unsupervised learning has\nbeen less well-studied. This paper studies fairness in the context of principal\ncomponent analysis (PCA). We first present a definition of fairness for\ndimensionality reduction, and our definition can be interpreted as saying that\na reduction is fair if information about a protected class (e.g., race or\ngender) cannot be inferred from the dimensionality-reduced data points. Next,\nwe develop convex optimization formulations that can improve the fairness (with\nrespect to our definition) of PCA and kernel PCA. These formulations are\nsemidefinite programs (SDP's), and we demonstrate the effectiveness of our\nformulations using several datasets. We conclude by showing how our approach\ncan be used to perform a fair (with respect to age) clustering of health data\nthat may be used to set health insurance rates.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 16:47:45 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 05:35:20 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 00:45:47 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Olfat", "Matt", ""], ["Aswani", "Anil", ""]]}, {"id": "1802.03774", "submitter": "Shiyu Duan", "authors": "Shiyu Duan, Shujian Yu, Yunmei Chen, Jose Principe", "title": "On Kernel Method-Based Connectionist Models and Supervised Deep Learning\n  Without Backpropagation", "comments": "8 pages main text, 16 pages of references and appendix, 2 figures", "journal-ref": "Neural Computation, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel family of connectionist models based on kernel machines\nand consider the problem of learning layer-by-layer a compositional hypothesis\nclass, i.e., a feedforward, multilayer architecture, in a supervised setting.\nIn terms of the models, we present a principled method to \"kernelize\" (partly\nor completely) any neural network (NN). With this method, we obtain a\ncounterpart of any given NN that is powered by kernel machines instead of\nneurons. In terms of learning, when learning a feedforward deep architecture in\na supervised setting, one needs to train all the components simultaneously\nusing backpropagation (BP) since there are no explicit targets for the hidden\nlayers (Rumelhart86). We consider without loss of generality the two-layer case\nand present a general framework that explicitly characterizes a target for the\nhidden layer that is optimal for minimizing the objective function of the\nnetwork. This characterization then makes possible a purely greedy training\nscheme that learns one layer at a time, starting from the input layer. We\nprovide realizations of the abstract framework under certain architectures and\nobjective functions. Based on these realizations, we present a layer-wise\ntraining algorithm for an l-layer feedforward network for classification, where\nl>=2 can be arbitrary. This algorithm can be given an intuitive geometric\ninterpretation that makes the learning dynamics transparent. Empirical results\nare provided to complement our theory. We show that the kernelized networks,\ntrained layer-wise, compare favorably with classical kernel machines as well as\nother connectionist models trained by BP. We also visualize the inner workings\nof the greedy kernelized models to validate our claim on the transparency of\nthe layer-wise algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 17:18:28 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 03:30:06 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 05:09:06 GMT"}, {"version": "v4", "created": "Thu, 22 Aug 2019 03:48:21 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Duan", "Shiyu", ""], ["Yu", "Shujian", ""], ["Chen", "Yunmei", ""], ["Principe", "Jose", ""]]}, {"id": "1802.03788", "submitter": "Klas Leino", "authors": "Klas Leino, Shayak Sen, Anupam Datta, Matt Fredrikson, Linyi Li", "title": "Influence-Directed Explanations for Deep Convolutional Networks", "comments": "To appear in International Test Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of explaining a rich class of behavioral properties of\ndeep neural networks. Distinctively, our influence-directed explanations\napproach this problem by peering inside the network to identify neurons with\nhigh influence on a quantity and distribution of interest, using an\naxiomatically-justified influence measure, and then providing an interpretation\nfor the concepts these neurons represent. We evaluate our approach by\ndemonstrating a number of its unique capabilities on convolutional neural\nnetworks trained on ImageNet. Our evaluation demonstrates that\ninfluence-directed explanations (1) identify influential concepts that\ngeneralize across instances, (2) can be used to extract the \"essence\" of what\nthe network learned about a class, and (3) isolate individual features the\nnetwork uses to make decisions and distinguish related classes.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 18:28:56 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 06:02:57 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Leino", "Klas", ""], ["Sen", "Shayak", ""], ["Datta", "Anupam", ""], ["Fredrikson", "Matt", ""], ["Li", "Linyi", ""]]}, {"id": "1802.03796", "submitter": "Daphna Weinshall", "authors": "Daphna Weinshall, Gad Cohen and Dan Amir", "title": "Curriculum Learning by Transfer Learning: Theory and Experiments with\n  Deep Networks", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide theoretical investigation of curriculum learning in the context of\nstochastic gradient descent when optimizing the convex linear regression loss.\nWe prove that the rate of convergence of an ideal curriculum learning method is\nmonotonically increasing with the difficulty of the examples. Moreover, among\nall equally difficult points, convergence is faster when using points which\nincur higher loss with respect to the current hypothesis. We then analyze\ncurriculum learning in the context of training a CNN. We describe a method\nwhich infers the curriculum by way of transfer learning from another network,\npre-trained on a different task. While this approach can only approximate the\nideal curriculum, we observe empirically similar behavior to the one predicted\nby the theory, namely, a significant boost in convergence speed at the\nbeginning of training. When the task is made more difficult, improvement in\ngeneralization performance is also observed. Finally, curriculum learning\nexhibits robustness against unfavorable conditions such as excessive\nregularization.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 19:24:47 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 13:53:21 GMT"}, {"version": "v3", "created": "Tue, 22 May 2018 15:20:06 GMT"}, {"version": "v4", "created": "Fri, 8 Jun 2018 18:04:50 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Weinshall", "Daphna", ""], ["Cohen", "Gad", ""], ["Amir", "Dan", ""]]}, {"id": "1802.03800", "submitter": "Mehmet Tan", "authors": "Mehmet Tan, Ozan F{\\i}rat \\\"Ozg\\\"ul, Batuhan Bardak, I\\c{s}{\\i}ksu\n  Ek\\c{s}io\\u{g}lu, Suna Sabuncuo\\u{g}lu", "title": "Drug response prediction by ensemble learning and drug-induced gene\n  expression signatures", "comments": "Will appear in Genomics Journal", "journal-ref": null, "doi": "10.1016/j.ygeno.2018.07.002", "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemotherapeutic response of cancer cells to a given compound is one of the\nmost fundamental information one requires to design anti-cancer drugs. Recent\nadvances in producing large drug screens against cancer cell lines provided an\nopportunity to apply machine learning methods for this purpose. In addition to\ncytotoxicity databases, considerable amount of drug-induced gene expression\ndata has also become publicly available. Following this, several methods that\nexploit omics data were proposed to predict drug activity on cancer cells.\nHowever, due to the complexity of cancer drug mechanisms, none of the existing\nmethods are perfect. One possible direction, therefore, is to combine the\nstrengths of both the methods and the databases for improved performance. We\ndemonstrate that integrating a large number of predictions by the proposed\nmethod improves the performance for this task. The predictors in the ensemble\ndiffer in several aspects such as the method itself, the number of tasks method\nconsiders (multi-task vs. single-task) and the subset of data considered\n(sub-sampling). We show that all these different aspects contribute to the\nsuccess of the final ensemble. In addition, we attempt to use the drug screen\ndata together with two novel signatures produced from the drug-induced gene\nexpression profiles of cancer cell lines. Finally, we evaluate the method\npredictions by in vitro experiments in addition to the tests on data sets.The\npredictions of the methods, the signatures and the software are available from\n\\url{http://mtan.etu.edu.tr/drug-response-prediction/}.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 19:34:10 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 13:25:44 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2018 08:36:58 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Tan", "Mehmet", ""], ["\u00d6zg\u00fcl", "Ozan F\u0131rat", ""], ["Bardak", "Batuhan", ""], ["Ek\u015fio\u011flu", "I\u015f\u0131ksu", ""], ["Sabuncuo\u011flu", "Suna", ""]]}, {"id": "1802.03801", "submitter": "Lam Nguyen", "authors": "Lam M. Nguyen, Phuong Ha Nguyen, Marten van Dijk, Peter Richt\\'arik,\n  Katya Scheinberg, Martin Tak\\'a\\v{c}", "title": "SGD and Hogwild! Convergence Without the Bounded Gradients Assumption", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:3747-3755, 2018", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is the optimization algorithm of choice in\nmany machine learning applications such as regularized empirical risk\nminimization and training deep neural networks. The classical convergence\nanalysis of SGD is carried out under the assumption that the norm of the\nstochastic gradient is uniformly bounded. While this might hold for some loss\nfunctions, it is always violated for cases where the objective function is\nstrongly convex. In (Bottou et al.,2016), a new analysis of convergence of SGD\nis performed under the assumption that stochastic gradients are bounded with\nrespect to the true gradient norm. Here we show that for stochastic problems\narising in machine learning such bound always holds; and we also propose an\nalternative convergence analysis of SGD with diminishing learning rate regime,\nwhich results in more relaxed conditions than those in (Bottou et al.,2016). We\nthen move on the asynchronous parallel setting, and prove convergence of\nHogwild! algorithm in the same regime, obtaining the first convergence results\nfor this method in the case of diminished learning rate.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 19:35:46 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 04:23:40 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Nguyen", "Lam M.", ""], ["Nguyen", "Phuong Ha", ""], ["van Dijk", "Marten", ""], ["Richt\u00e1rik", "Peter", ""], ["Scheinberg", "Katya", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1802.03806", "submitter": "Jeff  (Jun) Zhang", "authors": "Jeff Zhang, Kartheek Rangineni, Zahra Ghodsi, Siddharth Garg", "title": "ThUnderVolt: Enabling Aggressive Voltage Underscaling and Timing Error\n  Resilience for Energy Efficient Deep Neural Network Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware accelerators are being increasingly deployed to boost the\nperformance and energy efficiency of deep neural network (DNN) inference. In\nthis paper we propose Thundervolt, a new framework that enables aggressive\nvoltage underscaling of high-performance DNN accelerators without compromising\nclassification accuracy even in the presence of high timing error rates. Using\npost-synthesis timing simulations of a DNN accelerator modeled on the Google\nTPU, we show that Thundervolt enables between 34%-57% energy savings on\nstate-of-the-art speech and image recognition benchmarks with less than 1% loss\nin classification accuracy and no performance loss. Further, we show that\nThundervolt is synergistic with and can further increase the energy efficiency\nof commonly used run-time DNN pruning techniques like Zero-Skip.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 19:51:59 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 04:10:47 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Zhang", "Jeff", ""], ["Rangineni", "Kartheek", ""], ["Ghodsi", "Zahra", ""], ["Garg", "Siddharth", ""]]}, {"id": "1802.03830", "submitter": "Mladen Kolar", "authors": "Weiran Wang, Jialei Wang, Mladen Kolar, Nathan Srebro", "title": "Distributed Stochastic Multi-Task Learning with Graph Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose methods for distributed graph-based multi-task learning that are\nbased on weighted averaging of messages from other machines. Uniform averaging\nor diminishing stepsize in these methods would yield consensus (single task)\nlearning. We show how simply skewing the averaging weights or controlling the\nstepsize allows learning different, but related, tasks on the different\nmachines.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 22:23:34 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Wang", "Weiran", ""], ["Wang", "Jialei", ""], ["Kolar", "Mladen", ""], ["Srebro", "Nathan", ""]]}, {"id": "1802.03832", "submitter": "Marina Munkhoeva", "authors": "Marina Munkhoeva, Yermek Kapushev, Evgeny Burnaev, Ivan Oseledets", "title": "Quadrature-based features for kernel approximation", "comments": "Accepted to NIPS 2018; 9 pages, 3 figures, Appendix: 4 pages, 2\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of improving kernel approximation via randomized\nfeature maps. These maps arise as Monte Carlo approximation to integral\nrepresentations of kernel functions and scale up kernel methods for larger\ndatasets. Based on an efficient numerical integration technique, we propose a\nunifying approach that reinterprets the previous random features methods and\nextends to better estimates of the kernel approximation. We derive the\nconvergence behaviour and conduct an extensive empirical study that supports\nour hypothesis.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 22:35:28 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 09:00:13 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 10:34:02 GMT"}, {"version": "v4", "created": "Mon, 29 Oct 2018 21:29:40 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Munkhoeva", "Marina", ""], ["Kapushev", "Yermek", ""], ["Burnaev", "Evgeny", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1802.03840", "submitter": "Casey Kneale", "authors": "Casey Kneale, Steven D. Brown", "title": "Uncharted Forest a Technique for Exploratory Data Analysis", "comments": null, "journal-ref": "Talanta. 189, (2018), 71-78", "doi": "10.1016/j.talanta.2018.06.061", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploratory data analysis is crucial for developing and understanding\nclassification models from high-dimensional datasets. We explore the utility of\na new unsupervised tree ensemble called uncharted forest for visualizing class\nassociations, sample-sample associations, class heterogeneity, and\nuninformative classes for provenance studies. The uncharted forest algorithm\ncan be used to partition data using random selections of variables and metrics\nbased on statistical spread. After each tree is grown, a tally of the samples\nthat arrive at every terminal node is maintained. Those tallies are stored in\nsingle sample association matrix and a likelihood measure for each sample being\npartitioned with one another can be made. That matrix may be readily viewed as\na heat map, and the probabilities can be quantified via new metrics that\naccount for class or cluster membership. We display the advantages and\nlimitations of using this technique by applying it to two classification\ndatasets and three provenance study datasets. Two of the metrics presented in\nthis paper are also compared with widely used metrics from two algorithms that\nhave variance-based clustering mechanisms.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 23:22:36 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 22:21:49 GMT"}, {"version": "v3", "created": "Sat, 30 Jun 2018 12:27:25 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Kneale", "Casey", ""], ["Brown", "Steven D.", ""]]}, {"id": "1802.03858", "submitter": "Nathalia Moraes do Nascimento", "authors": "Nathalia Nascimento, Paulo Alencar, Carlos Lucena and Donald Cowan", "title": "Machine Learning-based Variability Handling in IoT Agents", "comments": "8 pages, 6 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based IoT applications have recently been proposed in several domains,\nsuch as health care, smart cities and agriculture. Deploying these applications\nin specific settings has been very challenging for many reasons including the\ncomplex static and dynamic variability of the physical devices such as sensors\nand actuators, the software application behavior and the environment in which\nthe application is embedded. In this paper, we propose a self-configurable IoT\nagent approach based on feedback-evaluative machine-learning. The approach\ninvolves: i) a variability model of IoT agents; ii) generation of sets of\ncustomized agents; iii) feedback evaluative machine learning; iv) modeling and\ncomposition of a group of IoT agents; and v) a feature-selection method based\non manual and automatic feedback.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 01:31:18 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Nascimento", "Nathalia", ""], ["Alencar", "Paulo", ""], ["Lucena", "Carlos", ""], ["Cowan", "Donald", ""]]}, {"id": "1802.03866", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu", "title": "Katyusha X: Practical Momentum Method for Stochastic Sum-of-Nonconvex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of minimizing sum-of-nonconvex functions (i.e., convex functions\nthat are average of non-convex ones) is becoming increasingly important in\nmachine learning, and is the core machinery for PCA, SVD, regularized Newton's\nmethod, accelerated non-convex optimization, and more.\n  We show how to provably obtain an accelerated stochastic algorithm for\nminimizing sum-of-nonconvex functions, by $\\textit{adding one additional line}$\nto the well-known SVRG method. This line corresponds to momentum, and shows how\nto directly apply momentum to the finite-sum stochastic minimization of\nsum-of-nonconvex functions. As a side result, our method enjoys linear parallel\nspeed-up using mini-batch.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 02:49:23 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""]]}, {"id": "1802.03873", "submitter": "Naresh Manwani", "authors": "Naresh Manwani", "title": "PRIL: Perceptron Ranking Using Interval Labeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an online learning algorithm PRIL for learning\nranking classifiers using interval labeled data and show its correctness. We\nshow its convergence in finite number of steps if there exists an ideal\nclassifier such that the rank given by it for an example always lies in its\nlabel interval. We then generalize this mistake bound result for the general\ncase. We also provide regret bound for the proposed algorithm. We propose a\nmultiplicative update algorithm for PRIL called M-PRIL. We provide its\ncorrectness and convergence results. We show the effectiveness of PRIL by\nshowing its performance on various datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 03:43:45 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Manwani", "Naresh", ""]]}, {"id": "1802.03875", "submitter": "Craig Atkinson", "authors": "Craig Atkinson, Brendan McCane, Lech Szymanski, Anthony Robins", "title": "Pseudo-Recursal: Solving the Catastrophic Forgetting Problem in Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, neural networks are not currently capable of learning tasks in a\nsequential fashion. When a novel, unrelated task is learnt by a neural network,\nit substantially forgets how to solve previously learnt tasks. One of the\noriginal solutions to this problem is pseudo-rehearsal, which involves learning\nthe new task while rehearsing generated items representative of the previous\ntask/s. This is very effective for simple tasks. However, pseudo-rehearsal has\nnot yet been successfully applied to very complex tasks because in these tasks\nit is difficult to generate representative items. We accomplish\npseudo-rehearsal by using a Generative Adversarial Network to generate items so\nthat our deep network can learn to sequentially classify the CIFAR-10, SVHN and\nMNIST datasets. After training on all tasks, our network loses only 1.67%\nabsolute accuracy on CIFAR-10 and gains 0.24% absolute accuracy on SVHN. Our\nmodel's performance is a substantial improvement compared to the current state\nof the art solution.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 03:51:41 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 01:42:04 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Atkinson", "Craig", ""], ["McCane", "Brendan", ""], ["Szymanski", "Lech", ""], ["Robins", "Anthony", ""]]}, {"id": "1802.03881", "submitter": "Sang-Woo Lee", "authors": "Sang-Woo Lee, Yu-Jung Heo, Byoung-Tak Zhang", "title": "Answerer in Questioner's Mind: Information Theoretic Approach to\n  Goal-Oriented Visual Dialog", "comments": "Selected for a spotlight presentation at NIPS, 2018. Camera ready\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-oriented dialog has been given attention due to its numerous\napplications in artificial intelligence. Goal-oriented dialogue tasks occur\nwhen a questioner asks an action-oriented question and an answerer responds\nwith the intent of letting the questioner know a correct action to take. To ask\nthe adequate question, deep learning and reinforcement learning have been\nrecently applied. However, these approaches struggle to find a competent\nrecurrent neural questioner, owing to the complexity of learning a series of\nsentences. Motivated by theory of mind, we propose \"Answerer in Questioner's\nMind\" (AQM), a novel information theoretic algorithm for goal-oriented dialog.\nWith AQM, a questioner asks and infers based on an approximated probabilistic\nmodel of the answerer. The questioner figures out the answerer's intention via\nselecting a plausible question by explicitly calculating the information gain\nof the candidate intentions and possible answers to each question. We test our\nframework on two goal-oriented visual dialog tasks: \"MNIST Counting Dialog\" and\n\"GuessWhat?!\". In our experiments, AQM outperforms comparative algorithms by a\nlarge margin.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 04:08:06 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 07:31:24 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 05:07:23 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Lee", "Sang-Woo", ""], ["Heo", "Yu-Jung", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1802.03882", "submitter": "Nathan Lay", "authors": "Nathan Lay, Adam P. Harrison, Sharon Schreiber, Gitesh Dawer, Adrian\n  Barbu", "title": "Random Hinge Forest for Differentiable Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose random hinge forests, a simple, efficient, and novel variant of\ndecision forests. Importantly, random hinge forests can be readily incorporated\nas a general component within arbitrary computation graphs that are optimized\nend-to-end with stochastic gradient descent or variants thereof. We derive\nrandom hinge forest and ferns, focusing on their sparse and efficient nature,\ntheir min-max margin property, strategies to initialize them for arbitrary\nnetwork architectures, and the class of optimizers most suitable for optimizing\nrandom hinge forest. The performance and versatility of random hinge forests\nare demonstrated by experiments incorporating a variety of of small and large\nUCI machine learning data sets and also ones involving the MNIST, Letter, and\nUSPS image datasets. We compare random hinge forests with random forests and\nthe more recent backpropagating deep neural decision forests.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 04:08:53 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 06:25:27 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Lay", "Nathan", ""], ["Harrison", "Adam P.", ""], ["Schreiber", "Sharon", ""], ["Dawer", "Gitesh", ""], ["Barbu", "Adrian", ""]]}, {"id": "1802.03885", "submitter": "Michel Kinsy", "authors": "Mihailo Isakov and Michel A. Kinsy", "title": "ClosNets: a Priori Sparse Topologies for Faster DNN Training", "comments": "Boston Area Architecture 2018 Workshop (BARC18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully-connected layers in deep neural networks (DNN) are often the throughput\nand power bottleneck during training. This is due to their large size and low\ndata reuse. Pruning dense layers can significantly reduce the size of these\nnetworks, but this approach can only be applied after training. In this work we\npropose a novel fully-connected layer that reduces the memory requirements of\nDNNs without sacrificing accuracy. We replace a dense matrix with products of\nsparse matrices whose topologies we pick in advance. This allows us to: (1)\ntrain significantly smaller networks without a loss in accuracy, and (2) store\nthe network weights without having to store connection indices. We therefore\nachieve significant training speedups due to the smaller network size, and a\nreduced amount of computation per epoch. We tested several sparse layer\ntopologies and found that Clos networks perform well due to their high path\ndiversity, shallowness, and high model accuracy. With the ClosNets, we are able\nto reduce dense layer sizes by as much as an order of magnitude without hurting\nmodel accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 04:16:21 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Isakov", "Mihailo", ""], ["Kinsy", "Michel A.", ""]]}, {"id": "1802.03888", "submitter": "Scott Lundberg", "authors": "Scott M. Lundberg, Gabriel G. Erion, and Su-In Lee", "title": "Consistent Individualized Feature Attribution for Tree Ensembles", "comments": "Follow-up to 2017 ICML Workshop arXiv:1706.06060", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpreting predictions from tree ensemble methods such as gradient boosting\nmachines and random forests is important, yet feature attribution for trees is\noften heuristic and not individualized for each prediction. Here we show that\npopular feature attribution methods are inconsistent, meaning they can lower a\nfeature's assigned importance when the true impact of that feature actually\nincreases. This is a fundamental problem that casts doubt on any comparison\nbetween features. To address it we turn to recent applications of game theory\nand develop fast exact tree solutions for SHAP (SHapley Additive exPlanation)\nvalues, which are the unique consistent and locally accurate attribution\nvalues. We then extend SHAP values to interaction effects and define SHAP\ninteraction values. We propose a rich visualization of individualized feature\nattributions that improves over classic attribution summaries and partial\ndependence plots, and a unique \"supervised\" clustering (clustering based on\nfeature attributions). We demonstrate better agreement with human intuition\nthrough a user study, exponential improvements in run time, improved clustering\nperformance, and better identification of influential features. An\nimplementation of our algorithm has also been merged into XGBoost and LightGBM,\nsee http://github.com/slundberg/shap for details.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 04:23:03 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 15:40:29 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 00:06:09 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Lundberg", "Scott M.", ""], ["Erion", "Gabriel G.", ""], ["Lee", "Su-In", ""]]}, {"id": "1802.03891", "submitter": "Madhavun Candadai", "authors": "Madhavun Candadai and Eduardo Izquierdo", "title": "Multifunctionality in embodied agents: Three levels of neural reuse", "comments": "Accepted at Cognitive Science Conference, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain in conjunction with the body is able to adapt to new environments\nand perform multiple behaviors through reuse of neural resources and transfer\nof existing behavioral traits. Although mechanisms that underlie this ability\nare not well understood, they are largely attributed to neuromodulation. In\nthis work, we demonstrate that an agent can be multifunctional using the same\nsensory and motor systems across behaviors, in the absence of modulatory\nmechanisms. Further, we lay out the different levels at which neural reuse can\noccur through a dynamical filtering of the brain-body-environment system's\noperation: structural network, autonomous dynamics, and transient dynamics.\nNotably, transient dynamics reuse could only be explained by studying the\nbrain-body-environment system as a whole and not just the brain. The\nmultifunctional agent we present here demonstrates neural reuse at all three\nlevels.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 04:41:18 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 17:44:36 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 01:44:56 GMT"}, {"version": "v4", "created": "Wed, 16 May 2018 00:43:18 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Candadai", "Madhavun", ""], ["Izquierdo", "Eduardo", ""]]}, {"id": "1802.03900", "submitter": "Qiaomin Xie", "authors": "Devavrat Shah and Qiaomin Xie", "title": "Q-learning with Nearest Neighbors", "comments": "Accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider model-free reinforcement learning for infinite-horizon discounted\nMarkov Decision Processes (MDPs) with a continuous state space and unknown\ntransition kernel, when only a single sample path under an arbitrary policy of\nthe system is available. We consider the Nearest Neighbor Q-Learning (NNQL)\nalgorithm to learn the optimal Q function using nearest neighbor regression\nmethod. As the main contribution, we provide tight finite sample analysis of\nthe convergence rate. In particular, for MDPs with a $d$-dimensional state\nspace and the discounted factor $\\gamma \\in (0,1)$, given an arbitrary sample\npath with \"covering time\" $ L $, we establish that the algorithm is guaranteed\nto output an $\\varepsilon$-accurate estimate of the optimal Q-function using\n$\\tilde{O}\\big(L/(\\varepsilon^3(1-\\gamma)^7)\\big)$ samples. For instance, for a\nwell-behaved MDP, the covering time of the sample path under the purely random\npolicy scales as $ \\tilde{O}\\big(1/\\varepsilon^d\\big),$ so the sample\ncomplexity scales as $\\tilde{O}\\big(1/\\varepsilon^{d+3}\\big).$ Indeed, we\nestablish a lower bound that argues that the dependence of $\n\\tilde{\\Omega}\\big(1/\\varepsilon^{d+2}\\big)$ is necessary.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 05:54:43 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 02:38:11 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Shah", "Devavrat", ""], ["Xie", "Qiaomin", ""]]}, {"id": "1802.03903", "submitter": "Haowen Xu", "authors": "Haowen Xu (1), Wenxiao Chen (1), Nengwen Zhao (1), Zeyan Li (1),\n  Jiahao Bu (1), Zhihan Li (1), Ying Liu (1), Youjian Zhao (1), Dan Pei (1),\n  Yang Feng (2), Jie Chen (2), Zhaogang Wang (2), Honglin Qiao (2) ((1)\n  Tsinghua University, (2) Alibaba Group)", "title": "Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal\n  KPIs in Web Applications", "comments": "12 pages (including references), 17 figures, submitted to WWW 2018:\n  The 2018 Web Conference, April 23--27, 2018, Lyon, France. The contents\n  discarded from the conference version due to the 9-page limitation are also\n  included in this version", "journal-ref": null, "doi": "10.1145/3178876.3185996", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ensure undisrupted business, large Internet companies need to closely\nmonitor various KPIs (e.g., Page Views, number of online users, and number of\norders) of its Web applications, to accurately detect anomalies and trigger\ntimely troubleshooting/mitigation. However, anomaly detection for these\nseasonal KPIs with various patterns and data quality has been a great\nchallenge, especially without labels. In this paper, we proposed Donut, an\nunsupervised anomaly detection algorithm based on VAE. Thanks to a few of our\nkey techniques, Donut greatly outperforms a state-of-arts supervised ensemble\napproach and a baseline VAE approach, and its best F-scores range from 0.75 to\n0.9 for the studied KPIs from a top global Internet company. We come up with a\nnovel KDE interpretation of reconstruction for Donut, making it the first\nVAE-based anomaly detection algorithm with solid theoretical explanation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 06:23:04 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Xu", "Haowen", ""], ["Chen", "Wenxiao", ""], ["Zhao", "Nengwen", ""], ["Li", "Zeyan", ""], ["Bu", "Jiahao", ""], ["Li", "Zhihan", ""], ["Liu", "Ying", ""], ["Zhao", "Youjian", ""], ["Pei", "Dan", ""], ["Feng", "Yang", ""], ["Chen", "Jie", ""], ["Wang", "Zhaogang", ""], ["Qiao", "Honglin", ""]]}, {"id": "1802.03913", "submitter": "Reza Zafarani", "authors": "Reza Zafarani, Sara Eftekharnejad, Urvi Patel", "title": "Assessing the Utility of Weather Data for Photovoltaic Power Prediction", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photovoltaic systems have been widely deployed in recent times to meet the\nincreased electricity demand as an environmental-friendly energy source. The\nmajor challenge for integrating photovoltaic systems in power systems is the\nunpredictability of the solar power generated. In this paper, we analyze the\nimpact of having access to weather information for solar power generation\nprediction and find weather information that can help best predict photovoltaic\npower.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 06:59:00 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Zafarani", "Reza", ""], ["Eftekharnejad", "Sara", ""], ["Patel", "Urvi", ""]]}, {"id": "1802.03916", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, Yu-Xiang Wang, Alex Smola", "title": "Detecting and Correcting for Label Shift with Black Box Predictors", "comments": "Published at the International Conference on Machine Learning (ICML)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faced with distribution shift between training and test set, we wish to\ndetect and quantify the shift, and to correct our classifiers without test set\nlabels. Motivated by medical diagnosis, where diseases (targets) cause symptoms\n(observations), we focus on label shift, where the label marginal $p(y)$\nchanges but the conditional $p(x| y)$ does not. We propose Black Box Shift\nEstimation (BBSE) to estimate the test distribution $p(y)$. BBSE exploits\narbitrary black box predictors to reduce dimensionality prior to shift\ncorrection. While better predictors give tighter estimates, BBSE works even\nwhen predictors are biased, inaccurate, or uncalibrated, so long as their\nconfusion matrices are invertible. We prove BBSE's consistency, bound its\nerror, and introduce a statistical test that uses BBSE to detect shift. We also\nleverage BBSE to correct classifiers. Experiments demonstrate accurate\nestimates and improved prediction, even on high-dimensional datasets of natural\nimages.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 07:16:03 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 17:23:51 GMT"}, {"version": "v3", "created": "Thu, 26 Jul 2018 12:51:37 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Wang", "Yu-Xiang", ""], ["Smola", "Alex", ""]]}, {"id": "1802.03930", "submitter": "Pengfei Zhang", "authors": "Yadong Wu, Pengfei Zhang, Huitao Shen and Hui Zhai", "title": "Visualizing Neural Network Developing Perturbation Theory", "comments": "5 pages, 4 figures", "journal-ref": "Phys. Rev. A 98, 010701 (2018)", "doi": "10.1103/PhysRevA.98.010701", "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn cond-mat.quant-gas cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, motivated by the question that whether the empirical fitting\nof data by neural network can yield the same structure of physical laws, we\napply the neural network to a simple quantum mechanical two-body scattering\nproblem with short-range potentials, which by itself also plays an important\nrole in many branches of physics. We train a neural network to accurately\npredict $ s $-wave scattering length, which governs the low-energy scattering\nphysics, directly from the scattering potential without solving Schr\\\"odinger\nequation or obtaining the wavefunction. After analyzing the neural network, it\nis shown that the neural network develops perturbation theory order by order\nwhen the potential increases. This provides an important benchmark to the\nmachine-assisted physics research or even automated machine learning physics\nlaws.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 08:25:55 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 21:46:23 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Wu", "Yadong", ""], ["Zhang", "Pengfei", ""], ["Shen", "Huitao", ""], ["Zhai", "Hui", ""]]}, {"id": "1802.03936", "submitter": "Anne Morvan", "authors": "Anne Morvan and Antoine Souloumiac and Krzysztof Choromanski and\n  C\\'edric Gouy-Pailler and Jamal Atif", "title": "On the Needs for Rotations in Hypercubic Quantization Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to endow the well-known family of hypercubic\nquantization hashing methods with theoretical guarantees. In hypercubic\nquantization, applying a suitable (random or learned) rotation after\ndimensionality reduction has been experimentally shown to improve the results\naccuracy in the nearest neighbors search problem. We prove in this paper that\nthe use of these rotations is optimal under some mild assumptions: getting\noptimal binary sketches is equivalent to applying a rotation uniformizing the\ndiagonal of the covariance matrix between data points. Moreover, for two closed\npoints, the probability to have dissimilar binary sketches is upper bounded by\na factor of the initial distance between the data points. Relaxing these\nassumptions, we obtain a general concentration result for random matrices. We\nalso provide some experiments illustrating these theoretical points and compare\na set of algorithms in both the batch and online settings.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 08:49:18 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Morvan", "Anne", ""], ["Souloumiac", "Antoine", ""], ["Choromanski", "Krzysztof", ""], ["Gouy-Pailler", "C\u00e9dric", ""], ["Atif", "Jamal", ""]]}, {"id": "1802.03938", "submitter": "Tatsuhiro Aoshima", "authors": "Tatsuhiro Aoshima, Kei Kobayashi, Mihoko Minami", "title": "Revisiting the Vector Space Model: Sparse Weighted Nearest-Neighbor\n  Method for Extreme Multi-Label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has played an important role in information retrieval (IR)\nin recent times. In search engines, for example, query keywords are accepted\nand documents are returned in order of relevance to the given query; this can\nbe cast as a multi-label ranking problem in machine learning. Generally, the\nnumber of candidate documents is extremely large (from several thousand to\nseveral million); thus, the classifier must handle many labels. This problem is\nreferred to as extreme multi-label classification (XMLC). In this paper, we\npropose a novel approach to XMLC termed the Sparse Weighted Nearest-Neighbor\nMethod. This technique can be derived as a fast implementation of\nstate-of-the-art (SOTA) one-versus-rest linear classifiers for very sparse\ndatasets. In addition, we show that the classifier can be written as a sparse\ngeneralization of a representer theorem with a linear kernel. Furthermore, our\nmethod can be viewed as the vector space model used in IR. Finally, we show\nthat the Sparse Weighted Nearest-Neighbor Method can process data points in\nreal time on XMLC datasets with equivalent performance to SOTA models, with a\nsingle thread and smaller storage footprint. In particular, our method exhibits\nsuperior performance to the SOTA models on a dataset with 3 million labels.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 08:51:57 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Aoshima", "Tatsuhiro", ""], ["Kobayashi", "Kei", ""], ["Minami", "Mihoko", ""]]}, {"id": "1802.03971", "submitter": "Deepak Kumar Gupta", "authors": "Deepak Kumar Gupta and Shruti Goyal", "title": "Email Classification into Relevant Category Using Neural Networks", "comments": "9 Pages, 6 figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, many online shopping websites or service provider have\nsingle email-id where customers can send their query, concern etc. At the\nback-end service provider receive million of emails every week, how they can\nidentify which email is belonged of a particular department? This paper\npresents an artificial neural network (ANN) model that is used to solve this\nproblem and experiments are carried out on user personal Gmail emails datasets.\nThis problem can be generalised as typical Text Classification or\nCategorization.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 11:03:00 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Gupta", "Deepak Kumar", ""], ["Goyal", "Shruti", ""]]}, {"id": "1802.03976", "submitter": "Mohammed Amin Abdullah Dr", "authors": "Mohammed Amin Abdullah, Aldo Pacchiano, Moez Draief", "title": "Reinforcement Learning with Wasserstein Distance Regularisation, with\n  Applications to Multipolicy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an application of Wasserstein distance to Reinforcement Learning.\nThe Wasserstein distance in question is between the distribution of mappings of\ntrajectories of a policy into some metric space, and some other fixed\ndistribution (which may, for example, come from another policy). Different\npolicies induce different distributions, so given an underlying metric, the\nWasserstein distance quantifies how different policies are. This can be used to\nlearn multiple polices which are different in terms of such Wasserstein\ndistances by using a Wasserstein regulariser. Changing the sign of the\nregularisation parameter, one can learn a policy for which its trajectory\nmapping distribution is attracted to a given fixed distribution.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 11:08:43 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 23:09:21 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Abdullah", "Mohammed Amin", ""], ["Pacchiano", "Aldo", ""], ["Draief", "Moez", ""]]}, {"id": "1802.03981", "submitter": "Karan Singh", "authors": "Elad Hazan, Holden Lee, Karan Singh, Cyril Zhang, Yi Zhang", "title": "Spectral Filtering for General Linear Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a polynomial-time algorithm for learning latent-state linear\ndynamical systems without system identification, and without assumptions on the\nspectral radius of the system's transition matrix. The algorithm extends the\nrecently introduced technique of spectral filtering, previously applied only to\nsystems with a symmetric transition matrix, using a novel convex relaxation to\nallow for the efficient identification of phases.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 11:20:30 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Hazan", "Elad", ""], ["Lee", "Holden", ""], ["Singh", "Karan", ""], ["Zhang", "Cyril", ""], ["Zhang", "Yi", ""]]}, {"id": "1802.03987", "submitter": "Federico Tomasi", "authors": "Federico Tomasi, Veronica Tozzo, Saverio Salzo, Alessandro Verri", "title": "Latent Variable Time-varying Network Inference", "comments": "9 pages, 5 figures, 1 table", "journal-ref": "Proceedings of the 24th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining (KDD 2018). ACM, New York, NY, USA,\n  2338-2346", "doi": "10.1145/3219819.3220121", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of finance, biology and sociology, complex systems\ninvolve entities interacting with each other. These processes have the\npeculiarity of evolving over time and of comprising latent factors, which\ninfluence the system without being explicitly measured. In this work we present\nlatent variable time-varying graphical lasso (LTGL), a method for multivariate\ntime-series graphical modelling that considers the influence of hidden or\nunmeasurable factors. The estimation of the contribution of the latent factors\nis embedded in the model which produces both sparse and low-rank components for\neach time point. In particular, the first component represents the connectivity\nstructure of observable variables of the system, while the second represents\nthe influence of hidden factors, assumed to be few with respect to the observed\nvariables. Our model includes temporal consistency on both components,\nproviding an accurate evolutionary pattern of the system. We derive a tractable\noptimisation algorithm based on alternating direction method of multipliers,\nand develop a scalable and efficient implementation which exploits proximity\noperators in closed form. LTGL is extensively validated on synthetic data,\nachieving optimal performance in terms of accuracy, structure learning and\nscalability with respect to ground truth and state-of-the-art methods for\ngraphical inference. We conclude with the application of LTGL to real case\nstudies, from biology and finance, to illustrate how our method can be\nsuccessfully employed to gain insights on multivariate time-series data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 11:39:14 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 09:48:48 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Tomasi", "Federico", ""], ["Tozzo", "Veronica", ""], ["Salzo", "Saverio", ""], ["Verri", "Alessandro", ""]]}, {"id": "1802.04007", "submitter": "Zarathustra Amadeus Goertzel", "authors": "Zarathustra Goertzel (1), Jan Jakub\\r{u}v (1), Stephan Schulz (2),\n  Josef Urban (1) ((1) Czech Technical University in Prague, (2) DHBW\n  Stuttgart)", "title": "ProofWatch: Watchlist Guidance for Large Theories in E", "comments": "19 pages, 10 tables, submitted to ITP 2018 at FLOC", "journal-ref": null, "doi": "10.1007/978-3-319-94821-8_16", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Watchlist (also hint list) is a mechanism that allows related proofs to guide\na proof search for a new conjecture. This mechanism has been used with the\nOtter and Prover9 theorem provers, both for interactive formalizations and for\nhuman-assisted proving of open conjectures in small theories. In this work we\nexplore the use of watchlists in large theories coming from first-order\ntranslations of large ITP libraries, aiming at improving hammer-style\nautomation by smarter internal guidance of the ATP systems. In particular, we\n(i) design watchlist-based clause evaluation heuristics inside the E ATP\nsystem, and (ii) develop new proof guiding algorithms that load many previous\nproofs inside the ATP and focus the proof search using a dynamically updated\nnotion of proof matching. The methods are evaluated on a large set of problems\ncoming from the Mizar library, showing significant improvement of E's standard\nportfolio of strategies, and also of the previous best set of strategies\ninvented for Mizar by evolutionary methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 12:38:55 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 10:43:49 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Goertzel", "Zarathustra", ""], ["Jakub\u016fv", "Jan", ""], ["Schulz", "Stephan", ""], ["Urban", "Josef", ""]]}, {"id": "1802.04020", "submitter": "Ronan Fruit", "authors": "Ronan Fruit, Matteo Pirotta, Alessandro Lazaric, Ronald Ortner", "title": "Efficient Bias-Span-Constrained Exploration-Exploitation in\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SCAL, an algorithm designed to perform efficient\nexploration-exploitation in any unknown weakly-communicating Markov decision\nprocess (MDP) for which an upper bound $c$ on the span of the optimal bias\nfunction is known. For an MDP with $S$ states, $A$ actions and $\\Gamma \\leq S$\npossible next states, we prove a regret bound of $\\widetilde{O}(c\\sqrt{\\Gamma\nSAT})$, which significantly improves over existing algorithms (e.g., UCRL and\nPSRL), whose regret scales linearly with the MDP diameter $D$. In fact, the\noptimal bias span is finite and often much smaller than $D$ (e.g., $D=\\infty$\nin non-communicating MDPs). A similar result was originally derived by Bartlett\nand Tewari (2009) for REGAL.C, for which no tractable algorithm is available.\nIn this paper, we relax the optimization problem at the core of REGAL.C, we\ncarefully analyze its properties, and we provide the first computationally\nefficient algorithm to solve it. Finally, we report numerical simulations\nsupporting our theoretical findings and showing how SCAL significantly\noutperforms UCRL in MDPs with large diameter and small span.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 12:58:45 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 12:53:35 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Fruit", "Ronan", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""], ["Ortner", "Ronald", ""]]}, {"id": "1802.04023", "submitter": "L. Elisa Celis", "authors": "L. Elisa Celis, Vijay Keswani, Damian Straszak, Amit Deshpande, Tarun\n  Kathuria and Nisheeth K. Vishnoi", "title": "Fair and Diverse DPP-based Data Summarization", "comments": "A short version of this paper appeared in the workshop FAT/ML 2016 -\n  arXiv:1610.07183", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling methods that choose a subset of the data proportional to its\ndiversity in the feature space are popular for data summarization. However,\nrecent studies have noted the occurrence of bias (under- or over-representation\nof a certain gender or race) in such data summarization methods. In this paper\nwe initiate a study of the problem of outputting a diverse and fair summary of\na given dataset. We work with a well-studied determinantal measure of diversity\nand corresponding distributions (DPPs) and present a framework that allows us\nto incorporate a general class of fairness constraints into such distributions.\nComing up with efficient algorithms to sample from these constrained\ndeterminantal distributions, however, suffers from a complexity barrier and we\npresent a fast sampler that is provably good when the input vectors satisfy a\nnatural property. Our experimental results on a real-world and an image dataset\nshow that the diversity of the samples produced by adding fairness constraints\nis not too far from the unconstrained case, and we also provide a theoretical\nexplanation of it.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 13:12:43 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Celis", "L. Elisa", ""], ["Keswani", "Vijay", ""], ["Straszak", "Damian", ""], ["Deshpande", "Amit", ""], ["Kathuria", "Tarun", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1802.04034", "submitter": "Yusuke Tsuzuku", "authors": "Yusuke Tsuzuku, Issei Sato, Masashi Sugiyama", "title": "Lipschitz-Margin Training: Scalable Certification of Perturbation\n  Invariance for Deep Neural Networks", "comments": "To appear in NIPS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High sensitivity of neural networks against malicious perturbations on inputs\ncauses security concerns. To take a steady step towards robust classifiers, we\naim to create neural network models provably defended from perturbations. Prior\ncertification work requires strong assumptions on network structures and\nmassive computational costs, and thus the range of their applications was\nlimited. From the relationship between the Lipschitz constants and prediction\nmargins, we present a computationally efficient calculation technique to\nlower-bound the size of adversarial perturbations that can deceive networks,\nand that is widely applicable to various complicated networks. Moreover, we\npropose an efficient training procedure that robustifies networks and\nsignificantly improves the provably guarded areas around data points. In\nexperimental evaluations, our method showed its ability to provide a\nnon-trivial guarantee and enhance robustness for even large networks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 13:37:09 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 06:14:31 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 19:02:36 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Tsuzuku", "Yusuke", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1802.04036", "submitter": "Luc Berthouze", "authors": "Antoine Messager, George Parisis, Istvan Z Kiss, Robert Harper, Phil\n  Tee, Luc Berthouze", "title": "Inferring the time-varying functional connectivity of large-scale\n  computer networks from emitted events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring the functional connectivity of a\nlarge-scale computer network from sparse time series of events emitted by its\nnodes. We do so under the following three domain-specific constraints: (a)\nnon-stationarity of the functional connectivity due to unknown temporal changes\nin the network, (b) sparsity of the time-series of events that limits the\neffectiveness of classical correlation-based analysis, and (c) lack of an\nexplicit model describing how events propagate through the network. Under the\nassumption that the probability of two nodes being functionally connected\ncorrelates with the mean delay between their respective events, we develop an\ninference method whose output is an undirected weighted network where the\nweight of an edge between two nodes denotes the probability of these nodes\nbeing functionally connected. Using a combination of windowing and convolution\nto calculate at each time window a score quantifying the likelihood of a pair\nof nodes emitting events in quick succession, we develop a model of\ntime-varying connectivity whose parameters are determined by maximising the\nmodel's predictive power from one time window to the next. To assess the\neffectiveness of our inference method, we construct synthetic data for which\nground truth is available and use these data to benchmark our approach against\nthree state-of-the-art inference methods. We conclude by discussing its\napplication to data from a real-world large-scale computer network.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 13:38:54 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Messager", "Antoine", ""], ["Parisis", "George", ""], ["Kiss", "Istvan Z", ""], ["Harper", "Robert", ""], ["Tee", "Phil", ""], ["Berthouze", "Luc", ""]]}, {"id": "1802.04063", "submitter": "Moritz August", "authors": "Moritz August and Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Taking gradients through experiments: LSTMs and memory proximal policy\n  optimization for black-box quantum control", "comments": "12 pages, 4 figures, 2 tables. Comments very welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce the application of black-box quantum control as an\ninteresting rein- forcement learning problem to the machine learning community.\nWe analyze the structure of the reinforcement learning problems arising in\nquantum physics and argue that agents parameterized by long short-term memory\n(LSTM) networks trained via stochastic policy gradients yield a general method\nto solving them. In this context we introduce a variant of the proximal policy\noptimization (PPO) algorithm called the memory proximal policy optimization\n(MPPO) which is based on this analysis. We then show how it can be applied to\nspecific learning tasks and present results of nu- merical experiments showing\nthat our method achieves state-of-the-art results for several learning tasks in\nquantum control with discrete and continouous control parameters.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 14:27:54 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 12:17:07 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["August", "Moritz", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1802.04064", "submitter": "Alberto Bietti", "authors": "Alberto Bietti, Alekh Agarwal, John Langford", "title": "A Contextual Bandit Bake-off", "comments": "JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms are essential for solving many real-world\ninteractive machine learning problems. Despite multiple recent successes on\nstatistically and computationally efficient methods, the practical behavior of\nthese algorithms is still poorly understood. We leverage the availability of\nlarge numbers of supervised learning datasets to empirically evaluate\ncontextual bandit algorithms, focusing on practical methods that learn by\nrelying on optimization oracles from supervised learning. We find that a recent\nmethod (Foster et al., 2018) using optimism under uncertainty works the best\noverall. A surprisingly close second is a simple greedy baseline that only\nexplores implicitly through the diversity of contexts, followed by a variant of\nOnline Cover (Agarwal et al., 2014) which tends to be more conservative but\nrobust to problem specification by design. Along the way, we also evaluate\nvarious components of contextual bandit algorithm design such as loss\nestimators. Overall, this is a thorough study and review of contextual bandit\nmethodology.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 14:30:56 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 15:18:07 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 23:38:57 GMT"}, {"version": "v4", "created": "Fri, 24 Jan 2020 09:13:07 GMT"}, {"version": "v5", "created": "Fri, 4 Jun 2021 21:46:07 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bietti", "Alberto", ""], ["Agarwal", "Alekh", ""], ["Langford", "John", ""]]}, {"id": "1802.04065", "submitter": "Tian Guo", "authors": "Tian Guo, Albert Bifet, Nino Antulov-Fantulin", "title": "Bitcoin Volatility Forecasting with a Glimpse into Buy and Sell Orders", "comments": "Full version of the paper published at IEEE International Conference\n  on Data Mining (ICDM), 2018", "journal-ref": "2018 IEEE International Conference on Data Mining (ICDM). IEEE,\n  2018: 989-994", "doi": "10.1109/ICDM.2018.00123", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the ability to make the short-term prediction of the\nexchange price fluctuations towards the United States dollar for the Bitcoin\nmarket. We use the data of realized volatility collected from one of the\nlargest Bitcoin digital trading offices in 2016 and 2017 as well as order\ninformation. Experiments are performed to evaluate a variety of statistical and\nmachine learning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 14:31:39 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 14:24:40 GMT"}, {"version": "v3", "created": "Wed, 6 Feb 2019 20:56:15 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Guo", "Tian", ""], ["Bifet", "Albert", ""], ["Antulov-Fantulin", "Nino", ""]]}, {"id": "1802.04085", "submitter": "Di Wang", "authors": "Di Wang and Marco Gaboardi and Jinhui Xu", "title": "Empirical Risk Minimization in Non-interactive Local Differential\n  Privacy: Efficiency and High Dimensional Case", "comments": "Add a new section on high dimensional case", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the Empirical Risk Minimization problem in the\nnon-interactive local model of differential privacy. In the case of constant or\nlow dimensionality ($p\\ll n$), we first show that if the ERM loss function is\n$(\\infty, T)$-smooth, then we can avoid a dependence of the sample complexity,\nto achieve error $\\alpha$, on the exponential of the dimensionality $p$ with\nbase $1/\\alpha$ (i.e., $\\alpha^{-p}$), which answers a question in [smith 2017\ninteraction]. Our approach is based on polynomial approximation. Then, we\npropose player-efficient algorithms with $1$-bit communication complexity and\n$O(1)$ computation cost for each player. The error bound is asymptotically the\nsame as the original one. Also with additional assumptions we show a server\nefficient algorithm. Next we consider the high dimensional case ($n\\ll p$), we\nshow that if the loss function is Generalized Linear function and convex, then\nwe could get an error bound which is dependent on the Gaussian width of the\nunderlying constrained set instead of $p$, which is lower than that in [smith\n2017 interaction].\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 14:52:24 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 03:05:28 GMT"}, {"version": "v3", "created": "Wed, 16 May 2018 20:45:46 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Wang", "Di", ""], ["Gaboardi", "Marco", ""], ["Xu", "Jinhui", ""]]}, {"id": "1802.04128", "submitter": "Cl\\'audio Rebelo De S\\'a", "authors": "Dylan te Lindert and Cl\\'audio Rebelo de S\\'a and Carlos Soares and\n  Arno J. Knobbe", "title": "Smart energy management as a means towards improved energy efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The costs associated with refrigerator equipment often represent more than\nhalf of the total energy costs in supermarkets. This presents a good motivation\nfor running these systems efficiently. In this study, we investigate different\nways to construct a reference behavior, which can serve as a baseline for\njudging the performance of energy consumption. We used 3 distinct learning\nmodels: Multiple Linear Regression, Random Forests, and Artificial Neural\nNetworks. During our experiments we used a variation of the sliding window\nmethod in combination with learning curves. We applied this approach on five\ndifferent supermarkets, across Portugal. We are able to create baselines using\noff-the-shelf data mining techniques. Moreover, we found a way to create them\nbased on short term historical data. We believe that our research will serve as\na base for future studies, for which we provide interesting directions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 13:49:25 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Lindert", "Dylan te", ""], ["de S\u00e1", "Cl\u00e1udio Rebelo", ""], ["Soares", "Carlos", ""], ["Knobbe", "Arno J.", ""]]}, {"id": "1802.04145", "submitter": "Qiang Qiu", "authors": "Qiang Qiu, Xiuyuan Cheng, Robert Calderbank, Guillermo Sapiro", "title": "DCFNet: Deep Neural Network with Decomposed Convolutional Filters", "comments": "Published at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filters in a Convolutional Neural Network (CNN) contain model parameters\nlearned from enormous amounts of data. In this paper, we suggest to decompose\nconvolutional filters in CNN as a truncated expansion with pre-fixed bases,\nnamely the Decomposed Convolutional Filters network (DCFNet), where the\nexpansion coefficients remain learned from data. Such a structure not only\nreduces the number of trainable parameters and computation, but also imposes\nfilter regularity by bases truncation. Through extensive experiments, we\nconsistently observe that DCFNet maintains accuracy for image classification\ntasks with a significant reduction of model parameters, particularly with\nFourier-Bessel (FB) bases, and even with random bases. Theoretically, we\nanalyze the representation stability of DCFNet with respect to input\nvariations, and prove representation stability under generic assumptions on the\nexpansion coefficients. The analysis is consistent with the empirical\nobservations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 15:58:54 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 20:55:55 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2018 23:58:20 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Qiu", "Qiang", ""], ["Cheng", "Xiuyuan", ""], ["Calderbank", "Robert", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1802.04162", "submitter": "Feiyang Pan", "authors": "Feiyang Pan, Qingpeng Cai, Pingzhong Tang, Fuzhen Zhuang, Qing He", "title": "Policy Gradients for Contextual Recommendations", "comments": "Accepted at WWW-2019", "journal-ref": null, "doi": "10.1145/3308558.3313616", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making is a challenging task in online recommender systems. The\ndecision maker often needs to choose a contextual item at each step from a set\nof candidates. Contextual bandit algorithms have been successfully deployed to\nsuch applications, for the trade-off between exploration and exploitation and\nthe state-of-art performance on minimizing online costs. However, the\napplicability of existing contextual bandit methods is limited by the\nover-simplified assumptions of the problem, such as assuming a simple form of\nthe reward function or assuming a static environment where the states are not\naffected by previous actions. In this work, we put forward Policy Gradients for\nContextual Recommendations (PGCR) to solve the problem without those\nunrealistic assumptions. It optimizes over a restricted class of policies where\nthe marginal probability of choosing an item (in expectation of other items)\nhas a simple closed form, and the gradient of the expected return over the\npolicy in this class is in a succinct form. Moreover, PGCR leverages two useful\nheuristic techniques called Time-Dependent Greed and Actor-Dropout. The former\nensures PGCR to be empirically greedy in the limit, and the latter addresses\nthe trade-off between exploration and exploitation by using the policy network\nwith Dropout as a Bayesian approximation. PGCR can solve the standard\ncontextual bandits as well as its Markov Decision Process generalization.\nTherefore it can be applied to a wide range of realistic settings of\nrecommendations, such as personalized advertising. We evaluate PGCR on toy\ndatasets as well as a real-world dataset of personalized music recommendations.\nExperiments show that PGCR enables fast convergence and low regret, and\noutperforms both classic contextual-bandits and vanilla policy gradient\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 16:13:29 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 10:43:29 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 17:34:55 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Pan", "Feiyang", ""], ["Cai", "Qingpeng", ""], ["Tang", "Pingzhong", ""], ["Zhuang", "Fuzhen", ""], ["He", "Qing", ""]]}, {"id": "1802.04178", "submitter": "Robert Bridges", "authors": "Robert A. Bridges, Chris Felder, Chelsey Hoff", "title": "Dimension Reduction Using Active Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientists and engineers rely on accurate mathematical models to quantify the\nobjects of their studies, which are often high-dimensional. Unfortunately,\nhigh-dimensional models are inherently difficult, i.e. when observations are\nsparse or expensive to determine. One way to address this problem is to\napproximate the original model with fewer input dimensions. Our project goal\nwas to recover a function f that takes n inputs and returns one output, where n\nis potentially large. For any given n-tuple, we assume that we can observe a\nsample of the gradient and output of the function but it is computationally\nexpensive to do so. This project was inspired by an approach known as Active\nSubspaces, which works by linearly projecting to a linear subspace where the\nfunction changes most on average. Our research gives mathematical developments\ninforming a novel algorithm for this problem. Our approach, Active Manifolds,\nincreases accuracy by seeking nonlinear analogues that approximate the\nfunction. The benefits of our approach are eliminated unprincipled parameter,\nchoices, guaranteed accessible visualization, and improved estimation accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 16:07:34 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Bridges", "Robert A.", ""], ["Felder", "Chris", ""], ["Hoff", "Chelsey", ""]]}, {"id": "1802.04181", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort, Natalia D\\'iaz-Rodr\\'iguez, Jean-Fran\\c{c}ois\n  Goudou, David Filliat", "title": "State Representation Learning for Control: An Overview", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2018.07.006", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning algorithms are designed to learn abstract features\nthat characterize data. State representation learning (SRL) focuses on a\nparticular kind of representation learning where learned features are in low\ndimension, evolve through time, and are influenced by actions of an agent. The\nrepresentation is learned to capture the variation in the environment generated\nby the agent's actions; this kind of representation is particularly suitable\nfor robotics and control scenarios. In particular, the low dimension\ncharacteristic of the representation helps to overcome the curse of\ndimensionality, provides easier interpretation and utilization by humans and\ncan help improve performance and speed in policy learning algorithms such as\nreinforcement learning.\n  This survey aims at covering the state-of-the-art on state representation\nlearning in the most recent years. It reviews different SRL methods that\ninvolve interaction with the environment, their implementations and their\napplications in robotics control tasks (simulated or real). In particular, it\nhighlights how generic learning objectives are differently exploited in the\nreviewed algorithms. Finally, it discusses evaluation methods to assess the\nrepresentation learned and summarizes current and future lines of research.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 16:53:48 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 13:52:23 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Goudou", "Jean-Fran\u00e7ois", ""], ["Filliat", "David", ""]]}, {"id": "1802.04193", "submitter": "Yingqi Xiong", "authors": "Yingqi Xiong, Bin Wang, Chi-Cheng Chu, Rajit Gadh", "title": "Electric Vehicle Driver Clustering using Statistical Model and Machine\n  Learning", "comments": "2018 IEEE PES General Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electric Vehicle (EV) is playing a significant role in the distribution\nenergy management systems since the power consumption level of the EVs is much\nhigher than the other regular home appliances. The randomness of the EV driver\nbehaviors make the optimal charging or discharging scheduling even more\ndifficult due to the uncertain charging session parameters. To minimize the\nimpact of behavioral uncertainties, it is critical to develop effective methods\nto predict EV load for smart EV energy management. Using the EV smart charging\ninfrastructures on UCLA campus and city of Santa Monica as testbeds, we have\ncollected real-world datasets of EV charging behaviors, based on which we\nproposed an EV user modeling technique which combines statistical analysis and\nmachine learning approaches. Specifically, unsupervised clustering algorithm,\nand multilayer perceptron are applied to historical charging record to make the\nday-ahead EV parking and load prediction. Experimental results with\ncross-validation show that our model can achieve good performance for charging\ncontrol scheduling and online EV load forecasting.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 17:18:50 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Xiong", "Yingqi", ""], ["Wang", "Bin", ""], ["Chu", "Chi-Cheng", ""], ["Gadh", "Rajit", ""]]}, {"id": "1802.04198", "submitter": "Leonardo Baldassini", "authors": "Leonardo Baldassini and Jose Antonio Rodr\\'iguez Serrano", "title": "client2vec: Towards Systematic Baselines for Banking Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The workflow of data scientists normally involves potentially inefficient\nprocesses such as data mining, feature engineering and model selection. Recent\nresearch has focused on automating this workflow, partly or in its entirety, to\nimprove productivity. We choose the former approach and in this paper share our\nexperience in designing the client2vec: an internal library to rapidly build\nbaselines for banking applications. Client2vec uses marginalized stacked\ndenoising autoencoders on current account transactions data to create vector\nembeddings which represent the behaviors of our clients. These representations\ncan then be used in, and optimized against, a variety of tasks such as client\nsegmentation, profiling and targeting. Here we detail how we selected the\nalgorithmic machinery of client2vec and the data it works on and present\nexperimental results on several business cases.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 17:31:43 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Baldassini", "Leonardo", ""], ["Serrano", "Jose Antonio Rodr\u00edguez", ""]]}, {"id": "1802.04204", "submitter": "Akshay Mehra", "authors": "Akshay Mehra, Jihun Hamm, Mikhail Belkin", "title": "Fast Interactive Image Retrieval using large-scale unlabeled data", "comments": "15 Pages, Submitted to KDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An interactive image retrieval system learns which images in the database\nbelong to a user's query concept, by analyzing the example images and feedback\nprovided by the user. The challenge is to retrieve the relevant images with\nminimal user interaction. In this work, we propose to solve this problem by\nposing it as a binary classification task of classifying all images in the\ndatabase as being relevant or irrelevant to the user's query concept. Our\nmethod combines active learning with graph-based semi-supervised learning\n(GSSL) to tackle this problem. Active learning reduces the number of user\ninteractions by querying the labels of the most informative points and GSSL\nallows to use abundant unlabeled data along with the limited labeled data\nprovided by the user. To efficiently find the most informative point, we use an\nuncertainty sampling based method that queries the label of the point nearest\nto the decision boundary of the classifier. We estimate this decision boundary\nusing our heuristic of adaptive threshold. To utilize huge volumes of unlabeled\ndata we use an efficient approximation based method that reduces the complexity\nof GSSL from $O(n^3)$ to $O(n)$, making GSSL scalable. We make the classifier\nrobust to the diversity and noisy labels associated with images in large\ndatabases by incorporating information from multiple modalities such as visual\ninformation extracted from deep learning based models and semantic information\nextracted from the WordNet. High F1 scores within few relevance feedback rounds\nin our experiments with concepts defined on AnimalWithAttributes and Imagenet\n(1.2 million images) datasets indicate the effectiveness and scalability of our\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 17:45:28 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Mehra", "Akshay", ""], ["Hamm", "Jihun", ""], ["Belkin", "Mikhail", ""]]}, {"id": "1802.04208", "submitter": "Chris Donahue", "authors": "Chris Donahue, Julian McAuley, Miller Puckette", "title": "Adversarial Audio Synthesis", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio signals are sampled at high temporal resolutions, and learning to\nsynthesize audio requires capturing structure across a range of timescales.\nGenerative adversarial networks (GANs) have seen wide success at generating\nimages that are both locally and globally coherent, but they have seen little\napplication to audio generation. In this paper we introduce WaveGAN, a first\nattempt at applying GANs to unsupervised synthesis of raw-waveform audio.\nWaveGAN is capable of synthesizing one second slices of audio waveforms with\nglobal coherence, suitable for sound effect generation. Our experiments\ndemonstrate that, without labels, WaveGAN learns to produce intelligible words\nwhen trained on a small-vocabulary speech dataset, and can also synthesize\naudio from other domains such as drums, bird vocalizations, and piano. We\ncompare WaveGAN to a method which applies GANs designed for image generation on\nimage-like audio feature representations, finding both approaches to be\npromising.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 17:50:43 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 22:55:40 GMT"}, {"version": "v3", "created": "Sat, 9 Feb 2019 00:51:18 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Donahue", "Chris", ""], ["McAuley", "Julian", ""], ["Puckette", "Miller", ""]]}, {"id": "1802.04220", "submitter": "Francisco Ruiz", "authors": "Francisco J. R. Ruiz, Michalis K. Titsias, Adji B. Dieng, David M.\n  Blei", "title": "Augment and Reduce: Stochastic Inference for Large Categorical\n  Distributions", "comments": "11 pages, 2 figures", "journal-ref": "Francisco J. R. Ruiz, Michalis K. Titsias, Adji B. Dieng, and\n  David M. Blei. Augment and Reduce: Stochastic Inference for Large Categorical\n  Distributions. International Conference on Machine Learning. Stockholm\n  (Sweden), July 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical distributions are ubiquitous in machine learning, e.g., in\nclassification, language models, and recommendation systems. However, when the\nnumber of possible outcomes is very large, using categorical distributions\nbecomes computationally expensive, as the complexity scales linearly with the\nnumber of outcomes. To address this problem, we propose augment and reduce\n(A&R), a method to alleviate the computational complexity. A&R uses two ideas:\nlatent variable augmentation and stochastic variational inference. It maximizes\na lower bound on the marginal likelihood of the data. Unlike existing methods\nwhich are specific to softmax, A&R is more general and is amenable to other\ncategorical models, such as multinomial probit. On several large-scale\nclassification problems, we show that A&R provides a tighter bound on the\nmarginal likelihood and has better predictive performance than existing\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 18:04:06 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 07:14:20 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 12:53:53 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Ruiz", "Francisco J. R.", ""], ["Titsias", "Michalis K.", ""], ["Dieng", "Adji B.", ""], ["Blei", "David M.", ""]]}, {"id": "1802.04223", "submitter": "Vlad Niculae", "authors": "Vlad Niculae, Andr\\'e F. T. Martins, Mathieu Blondel, Claire Cardie", "title": "SparseMAP: Differentiable Sparse Structured Inference", "comments": "Published in ICML 2018. 14 pages, including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured prediction requires searching over a combinatorial number of\nstructures. To tackle it, we introduce SparseMAP: a new method for sparse\nstructured inference, and its natural loss function. SparseMAP automatically\nselects only a few global structures: it is situated between MAP inference,\nwhich picks a single structure, and marginal inference, which assigns\nprobability mass to all structures, including implausible ones. Importantly,\nSparseMAP can be computed using only calls to a MAP oracle, making it\napplicable to problems with intractable marginal inference, e.g., linear\nassignment. Sparsity makes gradient backpropagation efficient regardless of the\nstructure, enabling us to augment deep neural networks with generic and sparse\nstructured hidden layers. Experiments in dependency parsing and natural\nlanguage inference reveal competitive accuracy, improved interpretability, and\nthe ability to capture natural language ambiguities, which is attractive for\npipeline systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 18:07:34 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 16:09:16 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Niculae", "Vlad", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Blondel", "Mathieu", ""], ["Cardie", "Claire", ""]]}, {"id": "1802.04235", "submitter": "Naresh Manwani", "authors": "Kulin Shah and Naresh Manwani", "title": "Sparse Reject Option Classifier Using Successive Linear Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an approach for learning sparse reject option\nclassifiers using double ramp loss $L_{dr}$. We use DC programming to find the\nrisk minimizer. The algorithm solves a sequence of linear programs to learn the\nreject option classifier. We show that the loss $L_{dr}$ is Fisher consistent.\nWe also show that the excess risk of loss $L_d$ is upper bounded by the excess\nrisk of $L_{dr}$. We derive the generalization error bounds for the proposed\napproach. We show the effectiveness of the proposed approach by experimenting\nit on several real world datasets. The proposed approach not only performs\ncomparable to the state of the art but it also successfully learns sparse\nclassifiers.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 18:38:26 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 07:02:27 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Shah", "Kulin", ""], ["Manwani", "Naresh", ""]]}, {"id": "1802.04240", "submitter": "Mohammadreza Nazari", "authors": "Mohammadreza Nazari, Afshin Oroojlooy, Lawrence V. Snyder, Martin\n  Tak\\'a\\v{c}", "title": "Reinforcement Learning for Solving the Vehicle Routing Problem", "comments": "more results and illustrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end framework for solving the Vehicle Routing Problem\n(VRP) using reinforcement learning. In this approach, we train a single model\nthat finds near-optimal solutions for problem instances sampled from a given\ndistribution, only by observing the reward signals and following feasibility\nrules. Our model represents a parameterized stochastic policy, and by applying\na policy gradient algorithm to optimize its parameters, the trained model\nproduces the solution as a sequence of consecutive actions in real time,\nwithout the need to re-train for every new problem instance. On capacitated\nVRP, our approach outperforms classical heuristics and Google's OR-Tools on\nmedium-sized instances in solution quality with comparable computation time\n(after training). We demonstrate how our approach can handle problems with\nsplit delivery and explore the effect of such deliveries on the solution\nquality. Our proposed framework can be applied to other variants of the VRP\nsuch as the stochastic VRP, and has the potential to be applied more generally\nto combinatorial optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 18:41:57 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 18:25:38 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Nazari", "Mohammadreza", ""], ["Oroojlooy", "Afshin", ""], ["Snyder", "Lawrence V.", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1802.04253", "submitter": "Chengliang Yang", "authors": "Chengliang Yang, Anand Rangarajan, Sanjay Ranka", "title": "Global Model Interpretation via Recursive Partitioning", "comments": "Accepted by The 4th IEEE International Conference on Data Science and\n  Systems (DSS-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a simple but effective method to interpret black-box\nmachine learning models globally. That is, we use a compact binary tree, the\ninterpretation tree, to explicitly represent the most important decision rules\nthat are implicitly contained in the black-box machine learning models. This\ntree is learned from the contribution matrix which consists of the\ncontributions of input variables to predicted scores for each single\nprediction. To generate the interpretation tree, a unified process recursively\npartitions the input variable space by maximizing the difference in the average\ncontribution of the split variable between the divided spaces. We demonstrate\nthe effectiveness of our method in diagnosing machine learning models on\nmultiple tasks. Also, it is useful for new knowledge discovery as such insights\nare not easily identifiable when only looking at single predictions. In\ngeneral, our work makes it easier and more efficient for human beings to\nunderstand machine learning models.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 00:24:32 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 04:05:40 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Yang", "Chengliang", ""], ["Rangarajan", "Anand", ""], ["Ranka", "Sanjay", ""]]}, {"id": "1802.04307", "submitter": "Yujia Xie", "authors": "Yujia Xie, Xiangfeng Wang, Ruijia Wang, Hongyuan Zha", "title": "A Fast Proximal Point Method for Computing Exact Wasserstein Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein distance plays increasingly important roles in machine learning,\nstochastic programming and image processing. Major efforts have been under way\nto address its high computational complexity, some leading to approximate or\nregularized variations such as Sinkhorn distance. However, as we will\ndemonstrate, regularized variations with large regularization parameter will\ndegradate the performance in several important machine learning applications,\nand small regularization parameter will fail due to numerical stability issues\nwith existing algorithms. We address this challenge by developing an Inexact\nProximal point method for exact Optimal Transport problem (IPOT) with the\nproximal operator approximately evaluated at each iteration using projections\nto the probability simplex. The algorithm (a) converges to exact Wasserstein\ndistance with theoretical guarantee and robust regularization parameter\nselection, (b) alleviates numerical stability issue, (c) has similar\ncomputational complexity to Sinkhorn, and (d) avoids the shrinking problem when\napply to generative models. Furthermore, a new algorithm is proposed based on\nIPOT to obtain sharper Wasserstein barycenter.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 19:06:59 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 05:14:58 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 19:08:54 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Xie", "Yujia", ""], ["Wang", "Xiangfeng", ""], ["Wang", "Ruijia", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1802.04310", "submitter": "Adrian Wills", "authors": "Adrian Wills and Thomas Sch\\\"on", "title": "Stochastic quasi-Newton with adaptive step lengths for large-scale\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a numerically robust and fast method capable of exploiting the\nlocal geometry when solving large-scale stochastic optimisation problems. Our\nkey innovation is an auxiliary variable construction coupled with an inverse\nHessian approximation computed using a receding history of iterates and\ngradients. It is the Markov chain nature of the classic stochastic gradient\nalgorithm that enables this development. The construction offers a mechanism\nfor stochastic line search adapting the step length. We numerically evaluate\nand compare against current state-of-the-art with encouraging performance on\nreal-world benchmark problems where the number of observations and unknowns is\nin the order of millions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 19:13:28 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Wills", "Adrian", ""], ["Sch\u00f6n", "Thomas", ""]]}, {"id": "1802.04325", "submitter": "Dane Corneil", "authors": "Dane Corneil, Wulfram Gerstner and Johanni Brea", "title": "Efficient Model-Based Deep Reinforcement Learning with Variational State\n  Tabulation", "comments": "Accepted at ICML 2018; camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern reinforcement learning algorithms reach super-human performance on\nmany board and video games, but they are sample inefficient, i.e. they\ntypically require significantly more playing experience than humans to reach an\nequal performance level. To improve sample efficiency, an agent may build a\nmodel of the environment and use planning methods to update its policy. In this\narticle we introduce Variational State Tabulation (VaST), which maps an\nenvironment with a high-dimensional state space (e.g. the space of visual\ninputs) to an abstract tabular model. Prioritized sweeping with small backups,\na highly efficient planning method, can then be used to update state-action\nvalues. We show how VaST can rapidly learn to maximize reward in tasks like 3D\nnavigation and efficiently adapt to sudden changes in rewards or transition\nprobabilities.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 19:38:44 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 15:27:18 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Corneil", "Dane", ""], ["Gerstner", "Wulfram", ""], ["Brea", "Johanni", ""]]}, {"id": "1802.04339", "submitter": "Xiao Xu", "authors": "Xiao Xu, Sattar Vakili, Qing Zhao, Ananthram Swami", "title": "Multi-Armed Bandits on Partially Revealed Unit Interval Graphs", "comments": "Parts of the work have been presented at the 36th IEEE Military\n  Communication Conference (MILCOM), October, 2017 and the 52nd Asilomar\n  Conference on Signals, Systems and Computers, October, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stochastic multi-armed bandit problem with side information on the\nsimilarity and dissimilarity across different arms is considered. The action\nspace of the problem can be represented by a unit interval graph (UIG) where\neach node represents an arm and the presence (absence) of an edge between two\nnodes indicates similarity (dissimilarity) between their mean rewards. Two\nsettings of complete and partial side information based on whether the UIG is\nfully revealed are studied and a general two-step learning structure consisting\nof an offline reduction of the action space and online aggregation of reward\nobservations from similar arms is proposed to fully exploit the topological\nstructure of the side information. In both cases, the computation efficiency\nand the order optimality of the proposed learning policies in terms of both the\nsize of the action space and the time length are established.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 20:11:16 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 21:39:56 GMT"}, {"version": "v3", "created": "Sat, 31 Aug 2019 18:23:00 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Xu", "Xiao", ""], ["Vakili", "Sattar", ""], ["Zhao", "Qing", ""], ["Swami", "Ananthram", ""]]}, {"id": "1802.04346", "submitter": "Tong Wang", "authors": "Tong Wang", "title": "Gaining Free or Low-Cost Transparency with Interpretable Partial\n  Substitute", "comments": null, "journal-ref": "International Conference on Machine Learning, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the situation where a black-box model with good\npredictive performance is chosen over its interpretable competitors, and we\nshow interpretability is still achievable in this case. Our solution is to find\nan interpretable substitute on a subset of data where the black-box model is\noverkill or nearly overkill while leaving the rest to the black-box. This\ntransparency is obtained at minimal cost or no cost of the predictive\nperformance. Under this framework, we develop a Hybrid Rule Sets (HyRS) model\nthat uses decision rules to capture the subspace of data where the rules are as\naccurate or almost as accurate as the black-box provided. To train a HyRS, we\ndevise an efficient search algorithm that iteratively finds the optimal model\nand exploits theoretically grounded strategies to reduce computation. Our\nframework is agnostic to the black-box during training. Experiments on\nstructured and text data show that HyRS obtains an effective trade-off between\ntransparency and interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 20:24:47 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 16:31:32 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Wang", "Tong", ""]]}, {"id": "1802.04350", "submitter": "Longyun Guo", "authors": "Longyun Guo and Jean Honorio and John Morgan", "title": "Cost-Aware Learning for Improved Identifiability with Multiple\n  Experiments", "comments": "17 pages, 4 figures", "journal-ref": "IEEE International Symposium on Information Theory (ISIT) 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the sample complexity of learning from multiple experiments where\nthe experimenter has a total budget for obtaining samples. In this problem, the\nlearner should choose a hypothesis that performs well with respect to multiple\nexperiments, and their related data distributions. Each collected sample is\nassociated with a cost which depends on the particular experiments. In our\nsetup, a learner performs $m$ experiments, while incurring a total cost $C$. We\nfirst show that learning from multiple experiments allows to improve\nidentifiability. Additionally, by using a Rademacher complexity approach, we\nshow that the gap between the training and generalization error is\n$O(C^{-1/2})$. We also provide some examples for linear prediction, two-layer\nneural networks and kernel methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 20:31:58 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 02:08:53 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 22:32:09 GMT"}, {"version": "v4", "created": "Fri, 18 Jan 2019 18:41:30 GMT"}, {"version": "v5", "created": "Sat, 13 Jul 2019 20:34:57 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Guo", "Longyun", ""], ["Honorio", "Jean", ""], ["Morgan", "John", ""]]}, {"id": "1802.04364", "submitter": "Wengong Jin", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola", "title": "Junction Tree Variational Autoencoder for Molecular Graph Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to automate the design of molecules based on specific chemical\nproperties. In computational terms, this task involves continuous embedding and\ngeneration of molecular graphs. Our primary contribution is the direct\nrealization of molecular graphs, a task previously approached by generating\nlinear SMILES strings instead of graphs. Our junction tree variational\nautoencoder generates molecular graphs in two phases, by first generating a\ntree-structured scaffold over chemical substructures, and then combining them\ninto a molecule with a graph message passing network. This approach allows us\nto incrementally expand molecules while maintaining chemical validity at every\nstep. We evaluate our model on multiple tasks ranging from molecular generation\nto optimization. Across these tasks, our model outperforms previous\nstate-of-the-art baselines by a significant margin.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 21:19:39 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 00:17:35 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 17:20:47 GMT"}, {"version": "v4", "created": "Fri, 29 Mar 2019 14:44:43 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Jin", "Wengong", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1802.04365", "submitter": "Mehadi Hassen", "authors": "Mehadi Hassen and Philip K. Chan", "title": "Learning a Neural-network-based Representation for Open Set Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open set recognition problems exist in many domains. For example in security,\nnew malware classes emerge regularly; therefore malware classification systems\nneed to identify instances from unknown classes in addition to discriminating\nbetween known classes. In this paper we present a neural network based\nrepresentation for addressing the open set recognition problem. In this\nrepresentation instances from the same class are close to each other while\ninstances from different classes are further apart, resulting in statistically\nsignificant improvement when compared to other approaches on three datasets\nfrom two different domains.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 21:20:30 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Hassen", "Mehadi", ""], ["Chan", "Philip K.", ""]]}, {"id": "1802.04374", "submitter": "Mehdi S. M. Sajjadi", "authors": "Mehdi S. M. Sajjadi and Giambattista Parascandolo and Arash Mehrjou\n  and Bernhard Sch\\\"olkopf", "title": "Tempered Adversarial Networks", "comments": "accepted to ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have been shown to produce realistic\nsamples from high-dimensional distributions, but training them is considered\nhard. A possible explanation for training instabilities is the inherent\nimbalance between the networks: While the discriminator is trained directly on\nboth real and fake samples, the generator only has control over the fake\nsamples it produces since the real data distribution is fixed by the choice of\na given dataset. We propose a simple modification that gives the generator\ncontrol over the real samples which leads to a tempered learning process for\nboth generator and discriminator. The real data distribution passes through a\nlens before being revealed to the discriminator, balancing the generator and\ndiscriminator by gradually revealing more detailed features necessary to\nproduce high-quality results. The proposed module automatically adjusts the\nlearning process to the current strength of the networks, yet is generic and\neasy to add to any GAN variant. In a number of experiments, we show that this\ncan improve quality, stability and/or convergence speed across a range of\ndifferent GAN architectures (DCGAN, LSGAN, WGAN-GP).\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 21:49:07 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 18:21:57 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 14:45:23 GMT"}, {"version": "v4", "created": "Wed, 11 Jul 2018 12:13:54 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Sajjadi", "Mehdi S. M.", ""], ["Parascandolo", "Giambattista", ""], ["Mehrjou", "Arash", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1802.04376", "submitter": "Nathan Hilliard", "authors": "Nathan Hilliard and Lawrence Phillips, Scott Howland, Art\\\"em Yankov,\n  Courtney D. Corley, Nathan O. Hodas", "title": "Few-Shot Learning with Metric-Agnostic Conditional Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning high quality class representations from few examples is a key\nproblem in metric-learning approaches to few-shot learning. To accomplish this,\nwe introduce a novel architecture where class representations are conditioned\nfor each few-shot trial based on a target image. We also deviate from\ntraditional metric-learning approaches by training a network to perform\ncomparisons between classes rather than relying on a static metric comparison.\nThis allows the network to decide what aspects of each class are important for\nthe comparison at hand. We find that this flexible architecture works well in\npractice, achieving state-of-the-art performance on the Caltech-UCSD birds\nfine-grained classification task.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 21:56:12 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Hilliard", "Nathan", ""], ["Phillips", "Lawrence", ""], ["Howland", "Scott", ""], ["Yankov", "Art\u00ebm", ""], ["Corley", "Courtney D.", ""], ["Hodas", "Nathan O.", ""]]}, {"id": "1802.04381", "submitter": "Han Bao", "authors": "Han Bao, Gang Niu, Masashi Sugiyama", "title": "Classification from Pairwise Similarity and Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning needs a huge amount of labeled data, which can be a big\nbottleneck under the situation where there is a privacy concern or labeling\ncost is high. To overcome this problem, we propose a new weakly-supervised\nlearning setting where only similar (S) data pairs (two examples belong to the\nsame class) and unlabeled (U) data points are needed instead of fully labeled\ndata, which is called SU classification. We show that an unbiased estimator of\nthe classification risk can be obtained only from SU data, and the estimation\nerror of its empirical risk minimizer achieves the optimal parametric\nconvergence rate. Finally, we demonstrate the effectiveness of the proposed\nmethod through experiments.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 22:35:38 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 06:44:52 GMT"}, {"version": "v3", "created": "Wed, 15 Aug 2018 02:36:36 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Bao", "Han", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1802.04394", "submitter": "Jianshu Chen", "authors": "Yelong Shen, Jianshu Chen, Po-Sen Huang, Yuqing Guo, Jianfeng Gao", "title": "M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search", "comments": "Yelong Shen, Jianshu Chen and Po-Sen Huang contributed equally to the\n  paper. Published at 32nd Conference on Neural Information Processing Systems\n  (NeurIPS 2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to walk over a graph towards a target node for a given query and a\nsource node is an important problem in applications such as knowledge base\ncompletion (KBC). It can be formulated as a reinforcement learning (RL) problem\nwith a known state transition model. To overcome the challenge of sparse\nrewards, we develop a graph-walking agent called M-Walk, which consists of a\ndeep recurrent neural network (RNN) and Monte Carlo Tree Search (MCTS). The RNN\nencodes the state (i.e., history of the walked path) and maps it separately to\na policy and Q-values. In order to effectively train the agent from sparse\nrewards, we combine MCTS with the neural policy to generate trajectories\nyielding more positive rewards. From these trajectories, the network is\nimproved in an off-policy manner using Q-learning, which modifies the RNN\npolicy via parameter sharing. Our proposed RL algorithm repeatedly applies this\npolicy-improvement step to learn the model. At test time, MCTS is combined with\nthe neural policy to predict the target node. Experimental results on several\ngraph-walking benchmarks show that M-Walk is able to learn better policies than\nother RL-based methods, which are mainly based on policy gradients. M-Walk also\noutperforms traditional KBC baselines.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 23:27:23 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 21:02:01 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 00:19:45 GMT"}, {"version": "v4", "created": "Wed, 28 Nov 2018 19:16:36 GMT"}, {"version": "v5", "created": "Tue, 18 Dec 2018 17:43:47 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Shen", "Yelong", ""], ["Chen", "Jianshu", ""], ["Huang", "Po-Sen", ""], ["Guo", "Yuqing", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1802.04397", "submitter": "Bryon Aragam", "authors": "Bryon Aragam, Chen Dan, Eric P. Xing, Pradeep Ravikumar", "title": "Identifiability of Nonparametric Mixture Models and Bayes Optimal\n  Clustering", "comments": "35 pages, to appear in the Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by problems in data clustering, we establish general conditions\nunder which families of nonparametric mixture models are identifiable, by\nintroducing a novel framework involving clustering overfitted \\emph{parametric}\n(i.e. misspecified) mixture models. These identifiability conditions generalize\nexisting conditions in the literature, and are flexible enough to include for\nexample mixtures of Gaussian mixtures. In contrast to the recent literature on\nestimating nonparametric mixtures, we allow for general nonparametric mixture\ncomponents, and instead impose regularity assumptions on the underlying mixing\nmeasure. As our primary application, we apply these results to partition-based\nclustering, generalizing the notion of a Bayes optimal partition from classical\nparametric model-based clustering to nonparametric settings. Furthermore, this\nframework is constructive so that it yields a practical algorithm for learning\nidentified mixtures, which is illustrated through several examples on real\ndata. The key conceptual device in the analysis is the convex, metric geometry\nof probability measures on metric spaces and its connection to the Wasserstein\nconvergence of mixing measures. The result is a flexible framework for\nnonparametric clustering with formal consistency guarantees.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 23:53:52 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 16:20:25 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 20:31:51 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 03:52:29 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Aragam", "Bryon", ""], ["Dan", "Chen", ""], ["Xing", "Eric P.", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1802.04403", "submitter": "Haque Ishfaq", "authors": "Haque Ishfaq, Assaf Hoogi and Daniel Rubin", "title": "TVAE: Triplet-Based Variational Autoencoder using Metric Learning", "comments": "After submission, we realized that our work is very similar to work\n  done in \"Bayesian representation learning with oracle constraints\" by\n  Karaletsos et al (arXiv:1506.05011). This paper somehow didn't come into our\n  notice earlier and now that we know the idea we presented in our paper was\n  already explored there, we decided to withdraw our paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning has been demonstrated to be highly effective in learning\nsemantic representation and encoding information that can be used to measure\ndata similarity, by relying on the embedding learned from metric learning. At\nthe same time, variational autoencoder (VAE) has widely been used to\napproximate inference and proved to have a good performance for directed\nprobabilistic models. However, for traditional VAE, the data label or feature\ninformation are intractable. Similarly, traditional representation learning\napproaches fail to represent many salient aspects of the data. In this project,\nwe propose a novel integrated framework to learn latent embedding in VAE by\nincorporating deep metric learning. The features are learned by optimizing a\ntriplet loss on the mean vectors of VAE in conjunction with standard evidence\nlower bound (ELBO) of VAE. This approach, which we call Triplet based\nVariational Autoencoder (TVAE), allows us to capture more fine-grained\ninformation in the latent embedding. Our model is tested on MNIST data set and\nachieves a high triplet accuracy of 95.60% while the traditional VAE (Kingma &\nWelling, 2013) achieves triplet accuracy of 75.08%.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 00:05:19 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 15:31:47 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Ishfaq", "Haque", ""], ["Hoogi", "Assaf", ""], ["Rubin", "Daniel", ""]]}, {"id": "1802.04407", "submitter": "Guodong Long Dr", "authors": "Shirui Pan, Ruiqi Hu, Guodong Long, Jing Jiang, Lina Yao, Chengqi\n  Zhang", "title": "Adversarially Regularized Graph Autoencoder for Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding is an effective method to represent graph data in a low\ndimensional space for graph analytics. Most existing embedding algorithms\ntypically focus on preserving the topological structure or minimizing the\nreconstruction errors of graph data, but they have mostly ignored the data\ndistribution of the latent codes from the graphs, which often results in\ninferior embedding in real-world graph data. In this paper, we propose a novel\nadversarial graph embedding framework for graph data. The framework encodes the\ntopological structure and node content in a graph to a compact representation,\non which a decoder is trained to reconstruct the graph structure. Furthermore,\nthe latent representation is enforced to match a prior distribution via an\nadversarial training scheme. To learn a robust embedding, two variants of\nadversarial approaches, adversarially regularized graph autoencoder (ARGA) and\nadversarially regularized variational graph autoencoder (ARVGA), are developed.\nExperimental studies on real-world graphs validate our design and demonstrate\nthat our algorithms outperform baselines by a wide margin in link prediction,\ngraph clustering, and graph visualization tasks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 00:29:11 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 00:26:13 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Pan", "Shirui", ""], ["Hu", "Ruiqi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Yao", "Lina", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1802.04412", "submitter": "Kamyar Azizzadenesheli Ph.D.", "authors": "Kamyar Azizzadenesheli and Animashree Anandkumar", "title": "Efficient Exploration through Bayesian Deep Q-Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning (RL) in high dimensional episodic Markov\ndecision processes (MDP). We consider value-based RL when the optimal Q-value\nis a linear function of d-dimensional state-action feature representation. For\ninstance, in deep-Q networks (DQN), the Q-value is a linear function of the\nfeature representation layer (output layer). We propose two algorithms, one\nbased on optimism, LINUCB, and another based on posterior sampling, LINPSRL. We\nguarantee frequentist and Bayesian regret upper bounds of O(d sqrt{T}) for\nthese two algorithms, where T is the number of episodes. We extend these\nmethods to deep RL and propose Bayesian deep Q-networks (BDQN), which uses an\nefficient Thompson sampling algorithm for high dimensional RL. We deploy the\ndouble DQN (DDQN) approach, and instead of learning the last layer of Q-network\nusing linear regression, we use Bayesian linear regression, resulting in an\napproximated posterior over Q-function. This allows us to directly incorporate\nthe uncertainty over the Q-function and deploy Thompson sampling on the learned\nposterior distribution resulting in efficient exploration/exploitation\ntrade-off. We empirically study the behavior of BDQN on a wide range of Atari\ngames. Since BDQN carries out more efficient exploration and exploitation, it\nis able to reach higher return substantially faster compared to DDQN.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 00:48:17 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 03:26:22 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 18:44:40 GMT"}, {"version": "v4", "created": "Fri, 6 Sep 2019 20:54:19 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Azizzadenesheli", "Kamyar", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1802.04416", "submitter": "Baoxu Shi", "authors": "Xian Wu, Baoxu Shi, Yuxiao Dong, Chao Huang, Nitesh Chawla", "title": "Neural Tensor Factorization", "comments": "9 pages. Submitted to KDD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural collaborative filtering (NCF) and recurrent recommender systems (RRN)\nhave been successful in modeling user-item relational data. However, they are\nalso limited in their assumption of static or sequential modeling of relational\ndata as they do not account for evolving users' preference over time as well as\nchanges in the underlying factors that drive the change in user-item\nrelationship over time. We address these limitations by proposing a Neural\nTensor Factorization (NTF) model for predictive tasks on dynamic relational\ndata. The NTF model generalizes conventional tensor factorization from two\nperspectives: First, it leverages the long short-term memory architecture to\ncharacterize the multi-dimensional temporal interactions on relational data.\nSecond, it incorporates the multi-layer perceptron structure for learning the\nnon-linearities between different latent factors. Our extensive experiments\ndemonstrate the significant improvement in rating prediction and link\nprediction on dynamic relational data by our NTF model over both neural network\nbased factorization models and other traditional methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 01:10:38 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Wu", "Xian", ""], ["Shi", "Baoxu", ""], ["Dong", "Yuxiao", ""], ["Huang", "Chao", ""], ["Chawla", "Nitesh", ""]]}, {"id": "1802.04420", "submitter": "Yifan Wu", "authors": "Yifan Wu, Barnabas Poczos, Aarti Singh", "title": "Towards Understanding the Generalization Bias of Two Layer Convolutional\n  Linear Classifiers with Gradient Descent", "comments": "The 22nd International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in understanding the generalization of deep learning is to\nexplain why (stochastic) gradient descent can exploit the network architecture\nto find solutions that have good generalization performance when using high\ncapacity models. We find simple but realistic examples showing that this\nphenomenon exists even when learning linear classifiers --- between two linear\nnetworks with the same capacity, the one with a convolutional layer can\ngeneralize better than the other when the data distribution has some underlying\nspatial structure. We argue that this difference results from a combination of\nthe convolution architecture, data distribution and gradient descent, all of\nwhich are necessary to be included in a meaningful analysis. We provide a\ngeneral analysis of the generalization performance as a function of data\ndistribution and convolutional filter size, given gradient descent as the\noptimization algorithm, then interpret the results using concrete examples.\nExperimental results show that our analysis is able to explain what happens in\nour introduced examples.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 01:20:21 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 00:37:16 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Wu", "Yifan", ""], ["Poczos", "Barnabas", ""], ["Singh", "Aarti", ""]]}, {"id": "1802.04422", "submitter": "Sorelle Friedler", "authors": "Sorelle A. Friedler, Carlos Scheidegger, Suresh Venkatasubramanian,\n  Sonam Choudhary, Evan P. Hamilton, Derek Roth", "title": "A comparative study of fairness-enhancing interventions in machine\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computers are increasingly used to make decisions that have significant\nimpact in people's lives. Often, these predictions can affect different\npopulation subgroups disproportionately. As a result, the issue of fairness has\nreceived much recent interest, and a number of fairness-enhanced classifiers\nand predictors have appeared in the literature. This paper seeks to study the\nfollowing questions: how do these different techniques fundamentally compare to\none another, and what accounts for the differences? Specifically, we seek to\nbring attention to many under-appreciated aspects of such fairness-enhancing\ninterventions. Concretely, we present the results of an open benchmark we have\ndeveloped that lets us compare a number of different algorithms under a variety\nof fairness measures, and a large number of existing datasets. We find that\nalthough different algorithms tend to prefer specific formulations of fairness\npreservations, many of these measures strongly correlate with one another. In\naddition, we find that fairness-preserving algorithms tend to be sensitive to\nfluctuations in dataset composition (simulated in our benchmark by varying\ntraining-test splits), indicating that fairness interventions might be more\nbrittle than previously thought.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 01:31:51 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Friedler", "Sorelle A.", ""], ["Scheidegger", "Carlos", ""], ["Venkatasubramanian", "Suresh", ""], ["Choudhary", "Sonam", ""], ["Hamilton", "Evan P.", ""], ["Roth", "Derek", ""]]}, {"id": "1802.04431", "submitter": "Kyle Hundman", "authors": "Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian\n  Colwell, Tom Soderstrom", "title": "Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic\n  Thresholding", "comments": "KDD 2018 camera-ready version", "journal-ref": null, "doi": "10.1145/3219819.3219845", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As spacecraft send back increasing amounts of telemetry data, improved\nanomaly detection systems are needed to lessen the monitoring burden placed on\noperations engineers and reduce operational risk. Current spacecraft monitoring\nsystems only target a subset of anomaly types and often require costly expert\nknowledge to develop and maintain due to challenges involving scale and\ncomplexity. We demonstrate the effectiveness of Long Short-Term Memory (LSTMs)\nnetworks, a type of Recurrent Neural Network (RNN), in overcoming these issues\nusing expert-labeled telemetry anomaly data from the Soil Moisture Active\nPassive (SMAP) satellite and the Mars Science Laboratory (MSL) rover,\nCuriosity. We also propose a complementary unsupervised and nonparametric\nanomaly thresholding approach developed during a pilot implementation of an\nanomaly detection system for SMAP, and offer false positive mitigation\nstrategies along with other key improvements and lessons learned during\ndevelopment.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 02:09:32 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 01:52:08 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 20:39:29 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Hundman", "Kyle", ""], ["Constantinou", "Valentino", ""], ["Laporte", "Christopher", ""], ["Colwell", "Ian", ""], ["Soderstrom", "Tom", ""]]}, {"id": "1802.04434", "submitter": "Jeremy Bernstein", "authors": "Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, Anima\n  Anandkumar", "title": "signSGD: Compressed Optimisation for Non-Convex Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large neural networks requires distributing learning across multiple\nworkers, where the cost of communicating gradients can be a significant\nbottleneck. signSGD alleviates this problem by transmitting just the sign of\neach minibatch stochastic gradient. We prove that it can get the best of both\nworlds: compressed gradients and SGD-level convergence rate. The relative\n$\\ell_1/\\ell_2$ geometry of gradients, noise and curvature informs whether\nsignSGD or SGD is theoretically better suited to a particular problem. On the\npractical side we find that the momentum counterpart of signSGD is able to\nmatch the accuracy and convergence speed of Adam on deep Imagenet models. We\nextend our theory to the distributed setting, where the parameter server uses\nmajority vote to aggregate gradient signs from each worker enabling 1-bit\ncompression of worker-server communication in both directions. Using a theorem\nby Gauss we prove that majority vote can achieve the same reduction in variance\nas full precision distributed SGD. Thus, there is great promise for sign-based\noptimisation schemes to achieve fast communication and fast convergence. Code\nto reproduce experiments is to be found at https://github.com/jxbz/signSGD .\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 02:14:35 GMT"}, {"version": "v2", "created": "Sat, 23 Jun 2018 18:01:27 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 18:55:19 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Bernstein", "Jeremy", ""], ["Wang", "Yu-Xiang", ""], ["Azizzadenesheli", "Kamyar", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1802.04443", "submitter": "William Guss", "authors": "William H. Guss, Ruslan Salakhutdinov", "title": "On Characterizing the Capacity of Neural Networks using Algebraic\n  Topology", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.NE math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learnability of different neural architectures can be characterized\ndirectly by computable measures of data complexity. In this paper, we reframe\nthe problem of architecture selection as understanding how data determines the\nmost expressive and generalizable architectures suited to that data, beyond\ninductive bias. After suggesting algebraic topology as a measure for data\ncomplexity, we show that the power of a network to express the topological\ncomplexity of a dataset in its decision region is a strictly limiting factor in\nits ability to generalize. We then provide the first empirical characterization\nof the topological capacity of neural networks. Our empirical analysis shows\nthat at every level of dataset complexity, neural networks exhibit topological\nphase transitions. This observation allowed us to connect existing theory to\nempirically driven conjectures on the choice of architectures for\nfully-connected neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 02:32:10 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Guss", "William H.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1802.04457", "submitter": "Angus Galloway", "authors": "Angus Galloway and Graham W. Taylor and Medhat Moussa", "title": "Predicting Adversarial Examples with High Confidence", "comments": "Under review by the International Conference on Machine Learning\n  (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been suggested that adversarial examples cause deep learning models to\nmake incorrect predictions with high confidence. In this work, we take the\nopposite stance: an overly confident model is more likely to be vulnerable to\nadversarial examples. This work is one of the most proactive approaches taken\nto date, as we link robustness with non-calibrated model confidence on noisy\nimages, providing a data-augmentation-free path forward. The adversarial\nexamples phenomenon is most easily explained by the trend of increasing\nnon-regularized model capacity, while the diversity and number of samples in\ncommon datasets has remained flat. Test accuracy has incorrectly been\nassociated with true generalization performance, ignoring that training and\ntest splits are often extremely similar in terms of the overall representation\nspace. The transferability property of adversarial examples was previously used\nas evidence against overfitting arguments, a perceived random effect, but\noverfitting is not always random.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 03:45:28 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Galloway", "Angus", ""], ["Taylor", "Graham W.", ""], ["Moussa", "Medhat", ""]]}, {"id": "1802.04473", "submitter": "Xiao-Yang Liu", "authors": "Xiao-Yang Liu", "title": "Information Scaling Law of Deep Neural Networks", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of Deep Neural Networks (DNNs), various network\nmodels that show strong computing power and impressive expressive power are\nproposed. However, there is no comprehensive informational interpretation of\nDNNs from the perspective of information theory. Due to the nonlinear function\nand the uncertain number of layers and neural units used in the DNNs, the\nnetwork structure shows nonlinearity and complexity. With the typical DNNs\nnamed Convolutional Arithmetic Circuits (ConvACs), the complex DNNs can be\nconverted into mathematical formula. Thus, we can use rigorous mathematical\ntheory especially the information theory to analyse the complicated DNNs. In\nthis paper, we propose a novel information scaling law scheme that can\ninterpret the network's inner organization by information theory. First, we\nshow the informational interpretation of the activation function. Secondly, we\nprove that the information entropy increases when the information is\ntransmitted through the ConvACs. Finally, we propose the information scaling\nlaw of ConvACs through making a reasonable assumption.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 06:13:06 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Liu", "Xiao-Yang", ""]]}, {"id": "1802.04477", "submitter": "Zhize Li", "authors": "Zhize Li, Jian Li", "title": "A Simple Proximal Stochastic Gradient Method for Nonsmooth Nonconvex\n  Optimization", "comments": "32nd Conference on Neural Information Processing Systems (NeurIPS\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze stochastic gradient algorithms for optimizing nonconvex, nonsmooth\nfinite-sum problems. In particular, the objective function is given by the\nsummation of a differentiable (possibly nonconvex) component, together with a\npossibly non-differentiable but convex component. We propose a proximal\nstochastic gradient algorithm based on variance reduction, called ProxSVRG+.\nOur main contribution lies in the analysis of ProxSVRG+. It recovers several\nexisting convergence results and improves/generalizes them (in terms of the\nnumber of stochastic gradient oracle calls and proximal oracle calls). In\nparticular, ProxSVRG+ generalizes the best results given by the SCSG algorithm,\nrecently proposed by [Lei et al., 2017] for the smooth nonconvex case.\nProxSVRG+ is also more straightforward than SCSG and yields simpler analysis.\nMoreover, ProxSVRG+ outperforms the deterministic proximal gradient descent\n(ProxGD) for a wide range of minibatch sizes, which partially solves an open\nproblem proposed in [Reddi et al., 2016b]. Also, ProxSVRG+ uses much less\nproximal oracle calls than ProxSVRG [Reddi et al., 2016b]. Moreover, for\nnonconvex functions satisfied Polyak-\\L{}ojasiewicz condition, we prove that\nProxSVRG+ achieves a global linear convergence rate without restart unlike\nProxSVRG. Thus, it can \\emph{automatically} switch to the faster linear\nconvergence in some regions as long as the objective function satisfies the PL\ncondition locally in these regions. ProxSVRG+ also improves ProxGD and\nProxSVRG/SAGA, and generalizes the results of SCSG in this case. Finally, we\nconduct several experiments and the experimental results are consistent with\nthe theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 06:34:22 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 18:56:56 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 11:31:17 GMT"}, {"version": "v4", "created": "Sat, 1 Dec 2018 20:10:29 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Li", "Zhize", ""], ["Li", "Jian", ""]]}, {"id": "1802.04502", "submitter": "Mahito Sugiyama", "authors": "Mahito Sugiyama, Hiroyuki Nakahara, Koji Tsuda", "title": "Legendre Decomposition for Tensors", "comments": "12 pages, 6 figures, accepted to the 32nd Annual Conference on Neural\n  Information Processing Systems (NIPS 2018)", "journal-ref": null, "doi": "10.1088/1742-5468/ab3196", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel nonnegative tensor decomposition method, called Legendre\ndecomposition, which factorizes an input tensor into a multiplicative\ncombination of parameters. Thanks to the well-developed theory of information\ngeometry, the reconstructed tensor is unique and always minimizes the KL\ndivergence from an input tensor. We empirically show that Legendre\ndecomposition can more accurately reconstruct tensors than other nonnegative\ntensor decomposition methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 08:27:49 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 14:54:37 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Sugiyama", "Mahito", ""], ["Nakahara", "Hiroyuki", ""], ["Tsuda", "Koji", ""]]}, {"id": "1802.04504", "submitter": "Hung Dang", "authors": "Jiyi Zhang and Hung Dang and Hwee Kuan Lee and Ee-Chien Chang", "title": "Flipped-Adversarial AutoEncoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a flipped-Adversarial AutoEncoder (FAAE) that simultaneously\ntrains a generative model G that maps an arbitrary latent code distribution to\na data distribution and an encoder E that embodies an \"inverse mapping\" that\nencodes a data sample into a latent code vector. Unlike previous hybrid\napproaches that leverage adversarial training criterion in constructing\nautoencoders, FAAE minimizes re-encoding errors in the latent space and\nexploits adversarial criterion in the data space. Experimental evaluations\ndemonstrate that the proposed framework produces sharper reconstructed images\nwhile at the same time enabling inference that captures rich semantic\nrepresentation of data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 08:31:01 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 02:59:54 GMT"}, {"version": "v3", "created": "Wed, 21 Feb 2018 01:35:49 GMT"}, {"version": "v4", "created": "Wed, 21 Mar 2018 08:27:01 GMT"}, {"version": "v5", "created": "Wed, 4 Apr 2018 01:09:36 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Zhang", "Jiyi", ""], ["Dang", "Hung", ""], ["Lee", "Hwee Kuan", ""], ["Chang", "Ee-Chien", ""]]}, {"id": "1802.04528", "submitter": "Felix Kreuk", "authors": "Felix Kreuk, Assi Barak, Shir Aviv-Reuven, Moran Baruch, Benny Pinkas,\n  Joseph Keshet", "title": "Deceiving End-to-End Deep Learning Malware Detectors using Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning has shown performance breakthroughs in many\napplications, such as image detection, image segmentation, pose estimation, and\nspeech recognition. However, this comes with a major concern: deep networks\nhave been found to be vulnerable to adversarial examples. Adversarial examples\nare slightly modified inputs that are intentionally designed to cause a\nmisclassification by the model. In the domains of images and speech, the\nmodifications are so small that they are not seen or heard by humans, but\nnevertheless greatly affect the classification of the model.\n  Deep learning models have been successfully applied to malware detection. In\nthis domain, generating adversarial examples is not straightforward, as small\nmodifications to the bytes of the file could lead to significant changes in its\nfunctionality and validity. We introduce a novel loss function for generating\nadversarial examples specifically tailored for discrete input sets, such as\nexecutable bytes. We modify malicious binaries so that they would be detected\nas benign, while preserving their original functionality, by injecting a small\nsequence of bytes (payload) in the binary file. We applied this approach to an\nend-to-end convolutional deep learning malware detection model and show a high\nrate of detection evasion. Moreover, we show that our generated payload is\nrobust enough to be transferable within different locations of the same file\nand across different files, and that its entropy is low and similar to that of\nbenign data sections.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 09:51:41 GMT"}, {"version": "v2", "created": "Sun, 13 May 2018 09:12:55 GMT"}, {"version": "v3", "created": "Thu, 10 Jan 2019 09:21:23 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Kreuk", "Felix", ""], ["Barak", "Assi", ""], ["Aviv-Reuven", "Shir", ""], ["Baruch", "Moran", ""], ["Pinkas", "Benny", ""], ["Keshet", "Joseph", ""]]}, {"id": "1802.04537", "submitter": "Tom Rainforth", "authors": "Tom Rainforth, Adam R. Kosiorek, Tuan Anh Le, Chris J. Maddison,\n  Maximilian Igl, Frank Wood, Yee Whye Teh", "title": "Tighter Variational Bounds are Not Necessarily Better", "comments": "To appear at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide theoretical and empirical evidence that using tighter evidence\nlower bounds (ELBOs) can be detrimental to the process of learning an inference\nnetwork by reducing the signal-to-noise ratio of the gradient estimator. Our\nresults call into question common implicit assumptions that tighter ELBOs are\nbetter variational objectives for simultaneous model learning and inference\namortization schemes. Based on our insights, we introduce three new algorithms:\nthe partially importance weighted auto-encoder (PIWAE), the multiply importance\nweighted auto-encoder (MIWAE), and the combination importance weighted\nauto-encoder (CIWAE), each of which includes the standard importance weighted\nauto-encoder (IWAE) as a special case. We show that each can deliver\nimprovements over IWAE, even when performance is measured by the IWAE target\nitself. Furthermore, our results suggest that PIWAE may be able to deliver\nsimultaneous improvements in the training of both the inference and generative\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 10:17:32 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 16:51:15 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 19:25:55 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Rainforth", "Tom", ""], ["Kosiorek", "Adam R.", ""], ["Le", "Tuan Anh", ""], ["Maddison", "Chris J.", ""], ["Igl", "Maximilian", ""], ["Wood", "Frank", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1802.04551", "submitter": "Hideaki Imamura", "authors": "Hideaki Imamura and Issei Sato and Masashi Sugiyama", "title": "Analysis of Minimax Error Rate for Crowdsourcing and Its Application to\n  Worker Clustering Model", "comments": "Accepted to ICML2018 (International Conference on Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While crowdsourcing has become an important means to label data, there is\ngreat interest in estimating the ground truth from unreliable labels produced\nby crowdworkers. The Dawid and Skene (DS) model is one of the most well-known\nmodels in the study of crowdsourcing. Despite its practical popularity,\ntheoretical error analysis for the DS model has been conducted only under\nrestrictive assumptions on class priors, confusion matrices, or the number of\nlabels each worker provides. In this paper, we derive a minimax error rate\nunder more practical setting for a broader class of crowdsourcing models\nincluding the DS model as a special case. We further propose the worker\nclustering model, which is more practical than the DS model under real\ncrowdsourcing settings. The wide applicability of our theoretical analysis\nallows us to immediately investigate the behavior of this proposed model, which\ncan not be analyzed by existing studies. Experimental results showed that there\nis a strong similarity between the lower bound of the minimax error rate\nderived by our theoretical analysis and the empirical error of the estimated\nvalue.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 10:47:14 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 05:35:35 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Imamura", "Hideaki", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1802.04591", "submitter": "Calvin Seward", "authors": "Calvin Seward, Thomas Unterthiner, Urs Bergmann, Nikolay Jetchev, Sepp\n  Hochreiter", "title": "First Order Generative Adversarial Networks", "comments": "Accepted to 35th International Conference on Machine Learning (ICML).\n  Code to reproduce experiments is available\n  https://github.com/zalandoresearch/first_order_gan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GANs excel at learning high dimensional distributions, but they can update\ngenerator parameters in directions that do not correspond to the steepest\ndescent direction of the objective. Prominent examples of problematic update\ndirections include those used in both Goodfellow's original GAN and the\nWGAN-GP. To formally describe an optimal update direction, we introduce a\ntheoretical framework which allows the derivation of requirements on both the\ndivergence and corresponding method for determining an update direction, with\nthese requirements guaranteeing unbiased mini-batch updates in the direction of\nsteepest descent. We propose a novel divergence which approximates the\nWasserstein distance while regularizing the critic's first order information.\nTogether with an accompanying update direction, this divergence fulfills the\nrequirements for unbiased steepest descent updates. We verify our method, the\nFirst Order GAN, with image generation on CelebA, LSUN and CIFAR-10 and set a\nnew state of the art on the One Billion Word language generation task. Code to\nreproduce experiments is available.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 12:42:58 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 14:16:05 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Seward", "Calvin", ""], ["Unterthiner", "Thomas", ""], ["Bergmann", "Urs", ""], ["Jetchev", "Nikolay", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "1802.04617", "submitter": "Chao Qu", "authors": "Chao Qu, Yan Li, Huan Xu", "title": "Fast Global Convergence via Landscape of Empirical Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While optimizing convex objective (loss) functions has been a powerhouse for\nmachine learning for at least two decades, non-convex loss functions have\nattracted fast growing interests recently, due to many desirable properties\nsuch as superior robustness and classification accuracy, compared with their\nconvex counterparts. The main obstacle for non-convex estimators is that it is\nin general intractable to find the optimal solution. In this paper, we study\nthe computational issues for some non-convex M-estimators. In particular, we\nshow that the stochastic variance reduction methods converge to the global\noptimal with linear rate, by exploiting the statistical property of the\npopulation loss. En route, we improve the convergence analysis for the batch\ngradient method in \\cite{mei2016landscape}.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 13:37:11 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Qu", "Chao", ""], ["Li", "Yan", ""], ["Xu", "Huan", ""]]}, {"id": "1802.04623", "submitter": "Dan Garber", "authors": "Dan Garber", "title": "Logarithmic Regret for Online Gradient Descent Beyond Strong Convexity", "comments": "Revised version. Accepted to AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hoffman's classical result gives a bound on the distance of a point from a\nconvex and compact polytope in terms of the magnitude of violation of the\nconstraints. Recently, several results showed that Hoffman's bound can be used\nto derive strongly-convex-like rates for first-order methods for\n\\textit{offline} convex optimization of curved, though not strongly convex,\nfunctions, over polyhedral sets. In this work, we use this classical result for\nthe first time to obtain faster rates for \\textit{online convex optimization}\nover polyhedral sets with curved convex, though not strongly convex, loss\nfunctions. We show that under several reasonable assumptions on the data, the\nstandard \\textit{Online Gradient Descent} algorithm guarantees logarithmic\nregret. To the best of our knowledge, the only previous algorithm to achieve\nlogarithmic regret in the considered settings is the \\textit{Online Newton\nStep} algorithm which requires quadratic (in the dimension) memory and at least\nquadratic runtime per iteration, which greatly limits its applicability to\nlarge-scale problems. In particular, our results hold for\n\\textit{semi-adversarial} settings in which the data is a combination of an\narbitrary (adversarial) sequence and a stochastic sequence, which might provide\nreasonable approximation for many real-world sequences, or under a natural\nassumption that the data is low-rank. We demonstrate via experiments that the\nregret of OGD is indeed comparable to that of ONS (and even far better) on\ncurved though not strongly-convex losses.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 13:54:33 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 09:22:14 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Garber", "Dan", ""]]}, {"id": "1802.04626", "submitter": "S\\\"oren Klemm", "authors": "Soeren Klemm and Aaron Scherzinger and Dominik Drees and Xiaoyi Jiang", "title": "Barista - a Graphical Tool for Designing and Training Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the importance of deep learning has significantly increased\nin pattern recognition, computer vision, and artificial intelligence research,\nas well as in industry. However, despite the existence of multiple deep\nlearning frameworks, there is a lack of comprehensible and easy-to-use\nhigh-level tools for the design, training, and testing of deep neural networks\n(DNNs). In this paper, we introduce Barista, an open-source graphical\nhigh-level interface for the Caffe deep learning framework. While Caffe is one\nof the most popular frameworks for training DNNs, editing prototext files in\norder to specify the net architecture and hyper parameters can become a\ncumbersome and error-prone task. Instead, Barista offers a fully graphical user\ninterface with a graph-based net topology editor and provides an end-to-end\ntraining facility for DNNs, which allows researchers to focus on solving their\nproblems without having to write code, edit text files, or manually parse\nlogged data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 14:02:48 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Klemm", "Soeren", ""], ["Scherzinger", "Aaron", ""], ["Drees", "Dominik", ""], ["Jiang", "Xiaoyi", ""]]}, {"id": "1802.04633", "submitter": "Joseph Keshet", "authors": "Yossi Adi, Carsten Baum, Moustapha Cisse, Benny Pinkas, Joseph Keshet", "title": "Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks\n  by Backdooring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have recently gained lots of success after enabling\nseveral breakthroughs in notoriously challenging problems. Training these\nnetworks is computationally expensive and requires vast amounts of training\ndata. Selling such pre-trained models can, therefore, be a lucrative business\nmodel. Unfortunately, once the models are sold they can be easily copied and\nredistributed. To avoid this, a tracking mechanism to identify models as the\nintellectual property of a particular vendor is necessary.\n  In this work, we present an approach for watermarking Deep Neural Networks in\na black-box way. Our scheme works for general classification tasks and can\neasily be combined with current learning algorithms. We show experimentally\nthat such a watermark has no noticeable impact on the primary task that the\nmodel is designed for and evaluate the robustness of our proposal against a\nmultitude of practical attacks. Moreover, we provide a theoretical analysis,\nrelating our approach to previous work on backdooring.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 14:20:42 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 09:50:23 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 13:34:21 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Adi", "Yossi", ""], ["Baum", "Carsten", ""], ["Cisse", "Moustapha", ""], ["Pinkas", "Benny", ""], ["Keshet", "Joseph", ""]]}, {"id": "1802.04647", "submitter": "Niketan Pansare", "authors": "Niketan Pansare, Michael Dusenberry, Nakul Jindal, Matthias Boehm,\n  Berthold Reinwald, Prithviraj Sen", "title": "Deep Learning with Apache SystemML", "comments": "Accepted at SysML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enterprises operate large data lakes using Hadoop and Spark frameworks that\n(1) run a plethora of tools to automate powerful data\npreparation/transformation pipelines, (2) run on shared, large clusters to (3)\nperform many different analytics tasks ranging from model preparation,\nbuilding, evaluation, and tuning for both machine learning and deep learning.\nDeveloping machine/deep learning models on data in such shared environments is\nchallenging. Apache SystemML provides a unified framework for implementing\nmachine learning and deep learning algorithms in a variety of shared deployment\nscenarios. SystemML's novel compilation approach automatically generates\nruntime execution plans for machine/deep learning algorithms that are composed\nof single-node and distributed runtime operations depending on data and cluster\ncharacteristics such as data size, data sparsity, cluster size, and memory\nconfigurations, while still exploiting the capabilities of the underlying big\ndata frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 23:54:37 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Pansare", "Niketan", ""], ["Dusenberry", "Michael", ""], ["Jindal", "Nakul", ""], ["Boehm", "Matthias", ""], ["Reinwald", "Berthold", ""], ["Sen", "Prithviraj", ""]]}, {"id": "1802.04657", "submitter": "Jeff  (Jun) Zhang", "authors": "Jeff Zhang, Tianyu Gu, Kanad Basu, Siddharth Garg", "title": "Analyzing and Mitigating the Impact of Permanent Faults on a Systolic\n  Array Based Neural Network Accelerator", "comments": "To appear at IEEE VLSI Test Symposium 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their growing popularity and computational cost, deep neural networks\n(DNNs) are being targeted for hardware acceleration. A popular architecture for\nDNN acceleration, adopted by the Google Tensor Processing Unit (TPU), utilizes\na systolic array based matrix multiplication unit at its core. This paper deals\nwith the design of fault-tolerant, systolic array based DNN accelerators for\nhigh defect rate technologies. To this end, we empirically show that the\nclassification accuracy of a baseline TPU drops significantly even at extremely\nlow fault rates (as low as $0.006\\%$). We then propose two novel strategies,\nfault-aware pruning (FAP) and fault-aware pruning+retraining (FAP+T), that\nenable the TPU to operate at fault rates of up to $50\\%$, with negligible drop\nin classification accuracy (as low as $0.1\\%$) and no run-time performance\noverhead. The FAP+T does introduce a one-time retraining penalty per TPU chip\nbefore it is deployed, but we propose optimizations that reduce this one-time\npenalty to under 12 minutes. The penalty is then amortized over the entire\nlifetime of the TPU's operation.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 19:51:35 GMT"}, {"version": "v2", "created": "Sat, 17 Feb 2018 06:19:12 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Zhang", "Jeff", ""], ["Gu", "Tianyu", ""], ["Basu", "Kanad", ""], ["Garg", "Siddharth", ""]]}, {"id": "1802.04664", "submitter": "Lovedeep Gondara", "authors": "Lovedeep Gondara, Ke Wang", "title": "Recovering Loss to Followup Information Using Denoising Autoencoders", "comments": "Copyright IEEE 2017, IEEE International Conference on Big Data (Big\n  Data)", "journal-ref": null, "doi": "10.1109/BigData.2017.8258139", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loss to followup is a significant issue in healthcare and has serious\nconsequences for a study's validity and cost. Methods available at present for\nrecovering loss to followup information are restricted by their expressive\ncapabilities and struggle to model highly non-linear relations and complex\ninteractions. In this paper we propose a model based on overcomplete denoising\nautoencoders to recover loss to followup information. Designed to work with\nhigh volume data, results on various simulated and real life datasets show our\nmodel is appropriate under varying dataset and loss to followup conditions and\noutperforms the state-of-the-art methods by a wide margin ($\\ge 20\\%$ in some\nscenarios) while preserving the dataset utility for final analysis.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 03:34:03 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Gondara", "Lovedeep", ""], ["Wang", "Ke", ""]]}, {"id": "1802.04680", "submitter": "Shuang Wu", "authors": "Shuang Wu, Guoqi Li, Feng Chen, Luping Shi", "title": "Training and Inference with Integers in Deep Neural Networks", "comments": "14 pages, 5 figures, ICLR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researches on deep neural networks with discrete parameters and their\ndeployment in embedded systems have been active and promising topics. Although\nprevious works have successfully reduced precision in inference, transferring\nboth training and inference processes to low-bitwidth integers has not been\ndemonstrated simultaneously. In this work, we develop a new method termed as\n\"WAGE\" to discretize both training and inference, where weights (W),\nactivations (A), gradients (G) and errors (E) among layers are shifted and\nlinearly constrained to low-bitwidth integers. To perform pure discrete\ndataflow for fixed-point devices, we further replace batch normalization by a\nconstant scaling layer and simplify other components that are arduous for\ninteger implementation. Improved accuracies can be obtained on multiple\ndatasets, which indicates that WAGE somehow acts as a type of regularization.\nEmpirically, we demonstrate the potential to deploy training in hardware\nsystems such as integer-based deep learning accelerators and neuromorphic chips\nwith comparable accuracy and higher energy efficiency, which is crucial to\nfuture AI applications in variable scenarios with transfer and continual\nlearning demands.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 15:23:20 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Wu", "Shuang", ""], ["Li", "Guoqi", ""], ["Chen", "Feng", ""], ["Shi", "Luping", ""]]}, {"id": "1802.04684", "submitter": "Mehmet Eren Ahsen", "authors": "Mehmet Eren Ahsen, Robert Vogel, Gustavo Stolovitzky", "title": "Unsupervised Evaluation and Weighted Aggregation of Ranked Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms that aggregate predictions from an ensemble of diverse\nbase classifiers consistently outperform individual methods. Many of these\nstrategies have been developed in a supervised setting, where the accuracy of\neach base classifier can be empirically measured and this information is\nincorporated in the training process. However, the reliance on labeled data\nprecludes the application of ensemble methods to many real world problems where\nlabeled data has not been curated. To this end we developed a new theoretical\nframework for binary classification, the Strategy for Unsupervised Multiple\nMethod Aggregation (SUMMA), to estimate the performances of base classifiers\nand an optimal strategy for ensemble learning from unlabeled data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 15:28:20 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Ahsen", "Mehmet Eren", ""], ["Vogel", "Robert", ""], ["Stolovitzky", "Gustavo", ""]]}, {"id": "1802.04687", "submitter": "Thomas Kipf", "authors": "Thomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, Richard Zemel", "title": "Neural Relational Inference for Interacting Systems", "comments": "ICML (2018). Code available under https://github.com/ethanfetaya/NRI", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interacting systems are prevalent in nature, from dynamical systems in\nphysics to complex societal dynamics. The interplay of components can give rise\nto complex behavior, which can often be explained using a simple model of the\nsystem's constituent parts. In this work, we introduce the neural relational\ninference (NRI) model: an unsupervised model that learns to infer interactions\nwhile simultaneously learning the dynamics purely from observational data. Our\nmodel takes the form of a variational auto-encoder, in which the latent code\nrepresents the underlying interaction graph and the reconstruction is based on\ngraph neural networks. In experiments on simulated physical systems, we show\nthat our NRI model can accurately recover ground-truth interactions in an\nunsupervised manner. We further demonstrate that we can find an interpretable\nstructure and predict complex dynamics in real motion capture and sports\ntracking data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 15:35:11 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 14:02:33 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Kipf", "Thomas", ""], ["Fetaya", "Ethan", ""], ["Wang", "Kuan-Chieh", ""], ["Welling", "Max", ""], ["Zemel", "Richard", ""]]}, {"id": "1802.04697", "submitter": "Arthur Guez", "authors": "Arthur Guez, Th\\'eophane Weber, Ioannis Antonoglou, Karen Simonyan,\n  Oriol Vinyals, Daan Wierstra, R\\'emi Munos, David Silver", "title": "Learning to Search with MCTSnets", "comments": "ICML 2018 (camera-ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning problems are among the most important and well-studied problems in\nartificial intelligence. They are most typically solved by tree search\nalgorithms that simulate ahead into the future, evaluate future states, and\nback-up those evaluations to the root of a search tree. Among these algorithms,\nMonte-Carlo tree search (MCTS) is one of the most general, powerful and widely\nused. A typical implementation of MCTS uses cleverly designed rules, optimized\nto the particular characteristics of the domain. These rules control where the\nsimulation traverses, what to evaluate in the states that are reached, and how\nto back-up those evaluations. In this paper we instead learn where, what and\nhow to search. Our architecture, which we call an MCTSnet, incorporates\nsimulation-based search inside a neural network, by expanding, evaluating and\nbacking-up a vector embedding. The parameters of the network are trained\nend-to-end using gradient-based optimisation. When applied to small searches in\nthe well known planning problem Sokoban, the learned search algorithm\nsignificantly outperformed MCTS baselines.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 16:10:10 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 14:16:12 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Guez", "Arthur", ""], ["Weber", "Th\u00e9ophane", ""], ["Antonoglou", "Ioannis", ""], ["Simonyan", "Karen", ""], ["Vinyals", "Oriol", ""], ["Wierstra", "Daan", ""], ["Munos", "R\u00e9mi", ""], ["Silver", "David", ""]]}, {"id": "1802.04705", "submitter": "Ziteng Sun", "authors": "Jayadev Acharya, Ziteng Sun, Huanyu Zhang", "title": "Hadamard Response: Estimating Distributions Privately, Efficiently, and\n  with Little Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating $k$-ary distributions under\n$\\varepsilon$-local differential privacy. $n$ samples are distributed across\nusers who send privatized versions of their sample to a central server. All\npreviously known sample optimal algorithms require linear (in $k$)\ncommunication from each user in the high privacy regime $(\\varepsilon=O(1))$,\nand run in time that grows as $n\\cdot k$, which can be prohibitive for large\ndomain size $k$.\n  We propose Hadamard Response (HR}, a local privatization scheme that requires\nno shared randomness and is symmetric with respect to the users. Our scheme has\norder optimal sample complexity for all $\\varepsilon$, a communication of at\nmost $\\log k+2$ bits per user, and nearly linear running time of $\\tilde{O}(n +\nk)$.\n  Our encoding and decoding are based on Hadamard matrices, and are simple to\nimplement. The statistical performance relies on the coding theoretic aspects\nof Hadamard matrices, ie, the large Hamming distance between the rows. An\nefficient implementation of the algorithm using the Fast Walsh-Hadamard\ntransform gives the computational gains.\n  We compare our approach with Randomized Response (RR), RAPPOR, and\nsubset-selection mechanisms (SS), both theoretically, and experimentally. For\n$k=10000$, our algorithm runs about 100x faster than SS, and RAPPOR.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 16:20:56 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 18:03:49 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Acharya", "Jayadev", ""], ["Sun", "Ziteng", ""], ["Zhang", "Huanyu", ""]]}, {"id": "1802.04712", "submitter": "Jakub Tomczak Ph.D.", "authors": "Maximilian Ilse and Jakub M. Tomczak and Max Welling", "title": "Attention-based Deep Multiple Instance Learning", "comments": "ICML 2018 paper, code source:\n  https://github.com/AMLab-Amsterdam/AttentionDeepMIL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple instance learning (MIL) is a variation of supervised learning where\na single class label is assigned to a bag of instances. In this paper, we state\nthe MIL problem as learning the Bernoulli distribution of the bag label where\nthe bag label probability is fully parameterized by neural networks.\nFurthermore, we propose a neural network-based permutation-invariant\naggregation operator that corresponds to the attention mechanism. Notably, an\napplication of the proposed attention-based operator provides insight into the\ncontribution of each instance to the bag label. We show empirically that our\napproach achieves comparable performance to the best MIL methods on benchmark\nMIL datasets and it outperforms other methods on a MNIST-based MIL dataset and\ntwo real-life histopathology datasets without sacrificing interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 16:27:19 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 14:53:24 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 13:31:48 GMT"}, {"version": "v4", "created": "Thu, 28 Jun 2018 13:33:03 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Ilse", "Maximilian", ""], ["Tomczak", "Jakub M.", ""], ["Welling", "Max", ""]]}, {"id": "1802.04715", "submitter": "Zal\\'an Borsos", "authors": "Zal\\'an Borsos, Andreas Krause, Kfir Y. Levy", "title": "Online Variance Reduction for Stochastic Optimization", "comments": "COLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern stochastic optimization methods often rely on uniform sampling which\nis agnostic to the underlying characteristics of the data. This might degrade\nthe convergence by yielding estimates that suffer from a high variance. A\npossible remedy is to employ non-uniform importance sampling techniques, which\ntake the structure of the dataset into account. In this work, we investigate a\nrecently proposed setting which poses variance reduction as an online\noptimization problem with bandit feedback. We devise a novel and efficient\nalgorithm for this setting that finds a sequence of importance sampling\ndistributions competitive with the best fixed distribution in hindsight, the\nfirst result of this kind. While we present our method for sampling datapoints,\nit naturally extends to selecting coordinates or even blocks of thereof.\nEmpirical validations underline the benefits of our method in several settings.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 16:28:45 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 09:54:15 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 13:54:58 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Borsos", "Zal\u00e1n", ""], ["Krause", "Andreas", ""], ["Levy", "Kfir Y.", ""]]}, {"id": "1802.04721", "submitter": "Nataly Brukhim", "authors": "Nataly Brukhim and Amir Globerson", "title": "Predict and Constrain: Modeling Cardinality in Deep Structured\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning problems require the prediction of multi-dimensional\nlabels. Such structured prediction models can benefit from modeling\ndependencies between labels. Recently, several deep learning approaches to\nstructured prediction have been proposed. Here we focus on capturing\ncardinality constraints in such models. Namely, constraining the number of\nnon-zero labels that the model outputs. Such constraints have proven very\nuseful in previous structured prediction approaches, but it is a challenge to\nintroduce them into a deep learning framework. Here we show how to do this via\na novel deep architecture. Our approach outperforms strong baselines, achieving\nstate-of-the-art results on multi-label classification benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 16:40:08 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Brukhim", "Nataly", ""], ["Globerson", "Amir", ""]]}, {"id": "1802.04730", "submitter": "Albert Cohen", "authors": "Nicolas Vasilache, Oleksandr Zinenko, Theodoros Theodoridis, Priya\n  Goyal, Zachary DeVito, William S. Moses, Sven Verdoolaege, Andrew Adams,\n  Albert Cohen", "title": "Tensor Comprehensions: Framework-Agnostic High-Performance Machine\n  Learning Abstractions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models with convolutional and recurrent networks are now\nubiquitous and analyze massive amounts of audio, image, video, text and graph\ndata, with applications in automatic translation, speech-to-text, scene\nunderstanding, ranking user preferences, ad placement, etc. Competing\nframeworks for building these networks such as TensorFlow, Chainer, CNTK,\nTorch/PyTorch, Caffe1/2, MXNet and Theano, explore different tradeoffs between\nusability and expressiveness, research or production orientation and supported\nhardware. They operate on a DAG of computational operators, wrapping\nhigh-performance libraries such as CUDNN (for NVIDIA GPUs) or NNPACK (for\nvarious CPUs), and automate memory allocation, synchronization, distribution.\nCustom operators are needed where the computation does not fit existing\nhigh-performance library calls, usually at a high engineering cost. This is\nfrequently required when new operators are invented by researchers: such\noperators suffer a severe performance penalty, which limits the pace of\ninnovation. Furthermore, even if there is an existing runtime call these\nframeworks can use, it often doesn't offer optimal performance for a user's\nparticular network architecture and dataset, missing optimizations between\noperators as well as optimizations that can be done knowing the size and shape\nof data. Our contributions include (1) a language close to the mathematics of\ndeep learning called Tensor Comprehensions, (2) a polyhedral Just-In-Time\ncompiler to convert a mathematical description of a deep learning DAG into a\nCUDA kernel with delegated memory management and synchronization, also\nproviding optimizations such as operator fusion and specialization for specific\nsizes, (3) a compilation cache populated by an autotuner. [Abstract cutoff]\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 16:53:01 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 08:57:44 GMT"}, {"version": "v3", "created": "Fri, 29 Jun 2018 00:16:36 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Vasilache", "Nicolas", ""], ["Zinenko", "Oleksandr", ""], ["Theodoridis", "Theodoros", ""], ["Goyal", "Priya", ""], ["DeVito", "Zachary", ""], ["Moses", "William S.", ""], ["Verdoolaege", "Sven", ""], ["Adams", "Andrew", ""], ["Cohen", "Albert", ""]]}, {"id": "1802.04734", "submitter": "Yvonne Anne Pignolet", "authors": "Qin Wang, Sandro Schoenborn, Yvonne-Anne Pignolet, Theo Widmer,\n  Carsten Franke", "title": "Substation Signal Matching with a Bagged Token Classifier", "comments": "To be presented at the 31st International Conference on Industrial,\n  Engineering & Other Applications of Applied Intelligent Systems (IEA/AIE)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, engineers at substation service providers match customer data with\nthe corresponding internally used signal names manually. This paper proposes a\nmachine learning method to automate this process based on substation signal\nmapping data from a repository of executed projects. To this end, a bagged\ntoken classifier is proposed, letting words (tokens) in the customer signal\nname vote for provider signal names. In our evaluation, the proposed method\nexhibits better performance in terms of both accuracy and efficiency over\nstandard classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 16:57:31 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Wang", "Qin", ""], ["Schoenborn", "Sandro", ""], ["Pignolet", "Yvonne-Anne", ""], ["Widmer", "Theo", ""], ["Franke", "Carsten", ""]]}, {"id": "1802.04741", "submitter": "Amir Bennatan", "authors": "Amir Bennatan, Yoni Choukroun and Pavel Kisilev", "title": "Deep Learning for Decoding of Linear Codes - A Syndrome-Based Approach", "comments": "The first two authors contributed equally to this work. A shortened\n  version was submitted to the ISIT 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for applying deep neural networks (DNN) to soft\ndecoding of linear codes at arbitrary block lengths. Unlike other approaches,\nour framework allows unconstrained DNN design, enabling the free application of\npowerful designs that were developed in other contexts. Our method is robust to\noverfitting that inhibits many competing methods, which follows from the\nexponentially large number of codewords required for their training. We achieve\nthis by transforming the channel output before feeding it to the network,\nextracting only the syndrome of the hard decisions and the channel output\nreliabilities. We prove analytically that this approach does not involve any\nintrinsic performance penalty, and guarantees the generalization of performance\nobtained during training. Our best results are obtained using a recurrent\nneural network (RNN) architecture combined with simple preprocessing by\npermutation. We provide simulation results that demonstrate performance that\nsometimes approaches that of the ordered statistics decoding (OSD) algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 17:06:40 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Bennatan", "Amir", ""], ["Choukroun", "Yoni", ""], ["Kisilev", "Pavel", ""]]}, {"id": "1802.04742", "submitter": "Thomas Vandal", "authors": "Thomas Vandal, Evan Kodra, Jennifer Dy, Sangram Ganguly, Ramakrishna\n  Nemani, Auroop R. Ganguly", "title": "Quantifying Uncertainty in Discrete-Continuous and Skewed Data with\n  Bayesian Deep Learning", "comments": "10 Pages", "journal-ref": "The 24th ACM SIGKDD International Conference on Knowledge\n  Discovery & Data Mining, August 19--23, 2018, London, United Kingdom", "doi": "10.1145/3219819.3219996", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) methods have been transforming computer vision with\ninnovative adaptations to other domains including climate change. For DL to\npervade Science and Engineering (S&E) applications where risk management is a\ncore component, well-characterized uncertainty estimates must accompany\npredictions. However, S&E observations and model-simulations often follow\nheavily skewed distributions and are not well modeled with DL approaches, since\nthey usually optimize a Gaussian, or Euclidean, likelihood loss. Recent\ndevelopments in Bayesian Deep Learning (BDL), which attempts to capture\nuncertainties from noisy observations, aleatoric, and from unknown model\nparameters, epistemic, provide us a foundation. Here we present a\ndiscrete-continuous BDL model with Gaussian and lognormal likelihoods for\nuncertainty quantification (UQ). We demonstrate the approach by developing UQ\nestimates on `DeepSD', a super-resolution based DL model for Statistical\nDownscaling (SD) in climate applied to precipitation, which follows an\nextremely skewed distribution. We find that the discrete-continuous models\noutperform a basic Gaussian distribution in terms of predictive accuracy and\nuncertainty calibration. Furthermore, we find that the lognormal distribution,\nwhich can handle skewed distributions, produces quality uncertainty estimates\nat the extremes. Such results may be important across S&E, as well as other\ndomains such as finance and economics, where extremes are often of significant\ninterest. Furthermore, to our knowledge, this is the first UQ model in SD where\nboth aleatoric and epistemic uncertainties are characterized.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 17:07:13 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 16:35:23 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Vandal", "Thomas", ""], ["Kodra", "Evan", ""], ["Dy", "Jennifer", ""], ["Ganguly", "Sangram", ""], ["Nemani", "Ramakrishna", ""], ["Ganguly", "Auroop R.", ""]]}, {"id": "1802.04765", "submitter": "Glen Berseth", "authors": "Glen Berseth, Cheng Xie, Paul Cernek, Michiel Van de Panne", "title": "Progressive Reinforcement Learning with Distillation for Multi-Skilled\n  Motion Control", "comments": "15 pages, Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has demonstrated increasing capabilities for\ncontinuous control problems, including agents that can move with skill and\nagility through their environment. An open problem in this setting is that of\ndeveloping good strategies for integrating or merging policies for multiple\nskills, where each individual skill is a specialist in a specific skill and its\nassociated state distribution. We extend policy distillation methods to the\ncontinuous action setting and leverage this technique to combine expert\npolicies, as evaluated in the domain of simulated bipedal locomotion across\ndifferent classes of terrain. We also introduce an input injection method for\naugmenting an existing policy network to exploit new input features. Lastly,\nour method uses transfer learning to assist in the efficient acquisition of new\nskills. The combination of these methods allows a policy to be incrementally\naugmented with new skills. We compare our progressive learning and integration\nvia distillation (PLAID) method against three alternative baselines.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 17:57:21 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Berseth", "Glen", ""], ["Xie", "Cheng", ""], ["Cernek", "Paul", ""], ["Van de Panne", "Michiel", ""]]}, {"id": "1802.04780", "submitter": "David Dao", "authors": "David Dao, Dan Alistarh, Claudiu Musat, Ce Zhang", "title": "DataBright: Towards a Global Exchange for Decentralized Data Ownership\n  and Trusted Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.DB cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is safe to assume that, for the foreseeable future, machine learning,\nespecially deep learning will remain both data- and computation-hungry. In this\npaper, we ask: Can we build a global exchange where everyone can contribute\ncomputation and data to train the next generation of machine learning\napplications?\n  We present an early, but running prototype of DataBright, a system that turns\nthe creation of training examples and the sharing of computation into an\ninvestment mechanism. Unlike most crowdsourcing platforms, where the\ncontributor gets paid when they submit their data, DataBright pays dividends\nwhenever a contributor's data or hardware is used by someone to train a machine\nlearning model. The contributor becomes a shareholder in the dataset they\ncreated. To enable the measurement of usage, a computation platform that\ncontributors can trust is also necessary. DataBright thus merges both a data\nmarket and a trusted computation market.\n  We illustrate that trusted computation can enable the creation of an AI\nmarket, where each data point has an exact value that should be paid to its\ncreator. DataBright allows data creators to retain ownership of their\ncontribution and attaches to it a measurable value. The value of the data is\ngiven by its utility in subsequent distributed computation done on the\nDataBright computation market. The computation market allocates tasks and\nsubsequent payments to pooled hardware. This leads to the creation of a\ndecentralized AI cloud. Our experiments show that trusted hardware such as\nIntel SGX can be added to the usual ML pipeline with no additional costs. We\nuse this setting to orchestrate distributed computation that enables the\ncreation of a computation market. DataBright is available for download at\nhttps://github.com/ds3lab/databright.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 18:20:07 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Dao", "David", ""], ["Alistarh", "Dan", ""], ["Musat", "Claudiu", ""], ["Zhang", "Ce", ""]]}, {"id": "1802.04782", "submitter": "Henry Chai", "authors": "Henry Chai and Roman Garnett", "title": "Improving Quadrature for Constrained Integrands", "comments": "13 pages, 4 figures, 4 tables. Accepted by AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an improved Bayesian framework for performing inference of affine\ntransformations of constrained functions. We focus on quadrature with\nnonnegative functions, a common task in Bayesian inference. We consider\nconstraints on the range of the function of interest, such as nonnegativity or\nboundedness. Although our framework is general, we derive explicit\napproximation schemes for these constraints, and argue for the use of a log\ntransformation for functions with high dynamic range such as likelihood\nsurfaces. We propose a novel method for optimizing hyperparameters in this\nframework: we optimize the marginal likelihood in the original space, as\nopposed to in the transformed space. The result is a model that better explains\nthe actual data. Experiments on synthetic and real-world data demonstrate our\nframework achieves superior estimates using less wall-clock time than existing\nBayesian quadrature procedures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 18:30:52 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 19:12:42 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 20:29:27 GMT"}, {"version": "v4", "created": "Wed, 27 Feb 2019 16:25:38 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Chai", "Henry", ""], ["Garnett", "Roman", ""]]}, {"id": "1802.04791", "submitter": "Quanquan Gu", "authors": "Difan Zou and Pan Xu and Quanquan Gu", "title": "Stochastic Variance-Reduced Hamilton Monte Carlo Methods", "comments": "23 pages, 3 figures, 4 tables. In ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast stochastic Hamilton Monte Carlo (HMC) method, for sampling\nfrom a smooth and strongly log-concave distribution. At the core of our\nproposed method is a variance reduction technique inspired by the recent\nadvance in stochastic optimization. We show that, to achieve $\\epsilon$\naccuracy in 2-Wasserstein distance, our algorithm achieves $\\tilde\nO(n+\\kappa^{2}d^{1/2}/\\epsilon+\\kappa^{4/3}d^{1/3}n^{2/3}/\\epsilon^{2/3})$\ngradient complexity (i.e., number of component gradient evaluations), which\noutperforms the state-of-the-art HMC and stochastic gradient HMC methods in a\nwide regime. We also extend our algorithm for sampling from smooth and general\nlog-concave distributions, and prove the corresponding gradient complexity as\nwell. Experiments on both synthetic and real data demonstrate the superior\nperformance of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 18:54:54 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 00:40:40 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zou", "Difan", ""], ["Xu", "Pan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1802.04796", "submitter": "Quanquan Gu", "authors": "Dongruo Zhou and Pan Xu and Quanquan Gu", "title": "Stochastic Variance-Reduced Cubic Regularized Newton Method", "comments": "16 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stochastic variance-reduced cubic regularized Newton method for\nnon-convex optimization. At the core of our algorithm is a novel\nsemi-stochastic gradient along with a semi-stochastic Hessian, which are\nspecifically designed for cubic regularization method. We show that our\nalgorithm is guaranteed to converge to an\n$(\\epsilon,\\sqrt{\\epsilon})$-approximately local minimum within\n$\\tilde{O}(n^{4/5}/\\epsilon^{3/2})$ second-order oracle calls, which\noutperforms the state-of-the-art cubic regularization algorithms including\nsubsampled cubic regularization. Our work also sheds light on the application\nof variance reduction technique to high-order non-convex optimization methods.\nThorough experiments on various non-convex optimization problems support our\ntheory.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 18:58:51 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Zhou", "Dongruo", ""], ["Xu", "Pan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1802.04799", "submitter": "Tianqi Chen", "authors": "Tianqi Chen, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan,\n  Meghan Cowan, Haichen Shen, Leyuan Wang, Yuwei Hu, Luis Ceze, Carlos\n  Guestrin, Arvind Krishnamurthy", "title": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning", "comments": "Significantly improved version, add automated optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing need to bring machine learning to a wide diversity of\nhardware devices. Current frameworks rely on vendor-specific operator libraries\nand optimize for a narrow range of server-class GPUs. Deploying workloads to\nnew platforms -- such as mobile phones, embedded devices, and accelerators\n(e.g., FPGAs, ASICs) -- requires significant manual effort. We propose TVM, a\ncompiler that exposes graph-level and operator-level optimizations to provide\nperformance portability to deep learning workloads across diverse hardware\nback-ends. TVM solves optimization challenges specific to deep learning, such\nas high-level operator fusion, mapping to arbitrary hardware primitives, and\nmemory latency hiding. It also automates optimization of low-level programs to\nhardware characteristics by employing a novel, learning-based cost modeling\nmethod for rapid exploration of code optimizations. Experimental results show\nthat TVM delivers performance across hardware back-ends that are competitive\nwith state-of-the-art, hand-tuned libraries for low-power CPU, mobile GPU, and\nserver-class GPUs. We also demonstrate TVM's ability to target new accelerator\nback-ends, such as the FPGA-based generic deep learning accelerator. The system\nis open sourced and in production use inside several major companies.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 20:49:34 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 18:44:40 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 18:47:38 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Chen", "Tianqi", ""], ["Moreau", "Thierry", ""], ["Jiang", "Ziheng", ""], ["Zheng", "Lianmin", ""], ["Yan", "Eddie", ""], ["Cowan", "Meghan", ""], ["Shen", "Haichen", ""], ["Wang", "Leyuan", ""], ["Hu", "Yuwei", ""], ["Ceze", "Luis", ""], ["Guestrin", "Carlos", ""], ["Krishnamurthy", "Arvind", ""]]}, {"id": "1802.04821", "submitter": "Rein Houthooft", "authors": "Rein Houthooft, Richard Y. Chen, Phillip Isola, Bradly C. Stadie,\n  Filip Wolski, Jonathan Ho, Pieter Abbeel", "title": "Evolved Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a metalearning approach for learning gradient-based reinforcement\nlearning (RL) algorithms. The idea is to evolve a differentiable loss function,\nsuch that an agent, which optimizes its policy to minimize this loss, will\nachieve high rewards. The loss is parametrized via temporal convolutions over\nthe agent's experience. Because this loss is highly flexible in its ability to\ntake into account the agent's history, it enables fast task learning. Empirical\nresults show that our evolved policy gradient algorithm (EPG) achieves faster\nlearning on several randomized environments compared to an off-the-shelf policy\ngradient method. We also demonstrate that EPG's learned loss can generalize to\nout-of-distribution test time tasks, and exhibits qualitatively different\nbehavior from other popular metalearning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 19:07:43 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2018 04:32:51 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Houthooft", "Rein", ""], ["Chen", "Richard Y.", ""], ["Isola", "Phillip", ""], ["Stadie", "Bradly C.", ""], ["Wolski", "Filip", ""], ["Ho", "Jonathan", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1802.04822", "submitter": "Mengying Sun", "authors": "Mengying Sun, Fengyi Tang, Jinfeng Yi, Fei Wang, Jiayu Zhou", "title": "Identify Susceptible Locations in Medical Records via Adversarial\n  Attacks on Deep Predictive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The surging availability of electronic medical records (EHR) leads to\nincreased research interests in medical predictive modeling. Recently many deep\nlearning based predicted models are also developed for EHR data and\ndemonstrated impressive performance. However, a series of recent studies showed\nthat these deep models are not safe: they suffer from certain vulnerabilities.\nIn short, a well-trained deep network can be extremely sensitive to inputs with\nnegligible changes. These inputs are referred to as adversarial examples. In\nthe context of medical informatics, such attacks could alter the result of a\nhigh performance deep predictive model by slightly perturbing a patient's\nmedical records. Such instability not only reflects the weakness of deep\narchitectures, more importantly, it offers guide on detecting susceptible parts\non the inputs. In this paper, we propose an efficient and effective framework\nthat learns a time-preferential minimum attack targeting the LSTM model with\nEHR inputs, and we leverage this attack strategy to screen medical records of\npatients and identify susceptible events and measurements. The efficient\nscreening procedure can assist decision makers to pay extra attentions to the\nlocations that can cause severe consequence if not measured correctly. We\nconduct extensive empirical studies on a real-world urgent care cohort and\ndemonstrate the effectiveness of the proposed screening approach.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 19:10:12 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Sun", "Mengying", ""], ["Tang", "Fengyi", ""], ["Yi", "Jinfeng", ""], ["Wang", "Fei", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1802.04826", "submitter": "Pierre-Alexandre Mattei", "authors": "Pierre-Alexandre Mattei and Jes Frellsen", "title": "Leveraging the Exact Likelihood of Deep Latent Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models (DLVMs) combine the approximation abilities of\ndeep neural networks and the statistical foundations of generative models.\nVariational methods are commonly used for inference; however, the exact\nlikelihood of these models has been largely overlooked. The purpose of this\nwork is to study the general properties of this quantity and to show how they\ncan be leveraged in practice. We focus on important inferential problems that\nrely on the likelihood: estimation and missing data imputation. First, we\ninvestigate maximum likelihood estimation for DLVMs: in particular, we show\nthat most unconstrained models used for continuous data have an unbounded\nlikelihood function. This problematic behaviour is demonstrated to be a source\nof mode collapse. We also show how to ensure the existence of maximum\nlikelihood estimates, and draw useful connections with nonparametric mixture\nmodels. Finally, we describe an algorithm for missing data imputation using the\nexact conditional likelihood of a deep latent variable model. On several data\nsets, our algorithm consistently and significantly outperforms the usual\nimputation scheme used for DLVMs.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 19:27:38 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 16:44:46 GMT"}, {"version": "v3", "created": "Sun, 18 Feb 2018 14:57:29 GMT"}, {"version": "v4", "created": "Thu, 28 Jun 2018 13:44:24 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Mattei", "Pierre-Alexandre", ""], ["Frellsen", "Jes", ""]]}, {"id": "1802.04834", "submitter": "Amir Rosenfeld", "authors": "Amir Rosenfeld, John K. Tsotsos", "title": "Challenging Images For Minds and Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is no denying the tremendous leap in the performance of machine\nlearning methods in the past half-decade. Some might even say that specific\nsub-fields in pattern recognition, such as machine-vision, are as good as\nsolved, reaching human and super-human levels. Arguably, lack of training data\nand computation power are all that stand between us and solving the remaining\nones. In this position paper we underline cases in vision which are challenging\nto machines and even to human observers. This is to show limitations of\ncontemporary models that are hard to ameliorate by following the current trend\nto increase training data, network capacity or computational power. Moreover,\nwe claim that attempting to do so is in principle a suboptimal approach. We\nprovide a taster of such examples in hope to encourage and challenge the\nmachine learning community to develop new directions to solve the said\ndifficulties.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 19:50:41 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Rosenfeld", "Amir", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1802.04852", "submitter": "Mateusz Juda", "authors": "Bartosz Zielinski, Michal Lipinski, Mateusz Juda, Matthias\n  Zeppelzauer, Pawel Dlotko", "title": "Persistence Codebooks for Topological Data Analysis", "comments": "minor update, remove heading", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent homology (PH) is a rigorous mathematical theory that provides a\nrobust descriptor of data in the form of persistence diagrams (PDs) which are\n2D multisets of points. Their variable size makes them, however, difficult to\ncombine with typical machine learning workflows. In this paper we introduce\npersistence codebooks, a novel expressive and discriminative fixed-size\nvectorized representation of PDs. To this end, we adapt bag-of-words (BoW),\nvectors of locally aggregated descriptors (VLAD) and Fischer vectors (FV) for\nthe quantization of PDs. Persistence codebooks represent PDs in a convenient\nway for machine learning and statistical analysis and have a number of\nfavorable practical and theoretical properties including 1-Wasserstein\nstability. We evaluate the presented representations on several heterogeneous\ndatasets and show their (high) discriminative power. Our approach achieves\nstate-of-the-art performance and beyond in much less time than alternative\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 20:49:01 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 11:38:01 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 15:16:14 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 09:37:59 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Zielinski", "Bartosz", ""], ["Lipinski", "Michal", ""], ["Juda", "Mateusz", ""], ["Zeppelzauer", "Matthias", ""], ["Dlotko", "Pawel", ""]]}, {"id": "1802.04865", "submitter": "Terrance DeVries", "authors": "Terrance DeVries and Graham W. Taylor", "title": "Learning Confidence for Out-of-Distribution Detection in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks are very powerful predictive models, but they are\noften incapable of recognizing when their predictions may be wrong. Closely\nrelated to this is the task of out-of-distribution detection, where a network\nmust determine whether or not an input is outside of the set on which it is\nexpected to safely perform. To jointly address these issues, we propose a\nmethod of learning confidence estimates for neural networks that is simple to\nimplement and produces intuitively interpretable outputs. We demonstrate that\non the task of out-of-distribution detection, our technique surpasses recently\nproposed techniques which construct confidence based on the network's output\ndistribution, without requiring any additional labels or access to\nout-of-distribution examples. Additionally, we address the problem of\ncalibrating out-of-distribution detectors, where we demonstrate that\nmisclassified in-distribution examples can be used as a proxy for\nout-of-distribution examples.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 21:31:36 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["DeVries", "Terrance", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1802.04868", "submitter": "Seyed Mehran Kazemi", "authors": "Seyed Mehran Kazemi, David Poole", "title": "SimplE Embedding for Link Prediction in Knowledge Graphs", "comments": "Accepted for publication at conference on neural information\n  processing systems (NIPS 2018). 12 pages, 2 figure, 2 tables, 5 propositions", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge graphs contain knowledge about the world and provide a structured\nrepresentation of this knowledge. Current knowledge graphs contain only a small\nsubset of what is true in the world. Link prediction approaches aim at\npredicting new links for a knowledge graph given the existing links among the\nentities. Tensor factorization approaches have proved promising for such link\nprediction problems. Proposed in 1927, Canonical Polyadic (CP) decomposition is\namong the first tensor factorization approaches. CP generally performs poorly\nfor link prediction as it learns two independent embedding vectors for each\nentity, whereas they are really tied. We present a simple enhancement of CP\n(which we call SimplE) to allow the two embeddings of each entity to be learned\ndependently. The complexity of SimplE grows linearly with the size of\nembeddings. The embeddings learned through SimplE are interpretable, and\ncertain types of background knowledge can be incorporated into these embeddings\nthrough weight tying. We prove SimplE is fully expressive and derive a bound on\nthe size of its embeddings for full expressivity. We show empirically that,\ndespite its simplicity, SimplE outperforms several state-of-the-art tensor\nfactorization techniques. SimplE's code is available on GitHub at\nhttps://github.com/Mehran-k/SimplE.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 21:41:32 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 03:38:08 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Kazemi", "Seyed Mehran", ""], ["Poole", "David", ""]]}, {"id": "1802.04874", "submitter": "Ian Fischer", "authors": "Alexander A. Alemi, Ian Fischer", "title": "GILBO: One Metric to Measure Them All", "comments": "Accepted at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple, tractable lower bound on the mutual information\ncontained in the joint generative density of any latent variable generative\nmodel: the GILBO (Generative Information Lower BOund). It offers a\ndata-independent measure of the complexity of the learned latent variable\ndescription, giving the log of the effective description length. It is\nwell-defined for both VAEs and GANs. We compute the GILBO for 800 GANs and VAEs\neach trained on four datasets (MNIST, FashionMNIST, CIFAR-10 and CelebA) and\ndiscuss the results.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 21:58:48 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 00:26:50 GMT"}, {"version": "v3", "created": "Thu, 10 Jan 2019 18:51:19 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Alemi", "Alexander A.", ""], ["Fischer", "Ian", ""]]}, {"id": "1802.04877", "submitter": "Natasha Jaques", "authors": "Natasha Jaques, Jennifer McCleary, Jesse Engel, David Ha, Fred\n  Bertsch, Rosalind Picard, Douglas Eck", "title": "Learning via social awareness: Improving a deep generative sketching\n  model with facial feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the quest towards general artificial intelligence (AI), researchers have\nexplored developing loss functions that act as intrinsic motivators in the\nabsence of external rewards. This paper argues that such research has\noverlooked an important and useful intrinsic motivator: social interaction. We\nposit that making an AI agent aware of implicit social feedback from humans can\nallow for faster learning of more generalizable and useful representations, and\ncould potentially impact AI safety. We collect social feedback in the form of\nfacial expression reactions to samples from Sketch RNN, an LSTM-based\nvariational autoencoder (VAE) designed to produce sketch drawings. We use a\nLatent Constraints GAN (LC-GAN) to learn from the facial feedback of a small\ngroup of viewers, by optimizing the model to produce sketches that it predicts\nwill lead to more positive facial expressions. We show in multiple independent\nevaluations that the model trained with facial feedback produced sketches that\nare more highly rated, and induce significantly more positive facial\nexpressions. Thus, we establish that implicit social feedback can improve the\noutput of a deep learning model.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 22:19:10 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 18:45:48 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Jaques", "Natasha", ""], ["McCleary", "Jennifer", ""], ["Engel", "Jesse", ""], ["Ha", "David", ""], ["Bertsch", "Fred", ""], ["Picard", "Rosalind", ""], ["Eck", "Douglas", ""]]}, {"id": "1802.04887", "submitter": "David Blum", "authors": "David M. Blum, M. Elisabeth Pate-Cornell", "title": "Probabilistic Warnings in National Security Crises: Pearl Harbor\n  Revisited", "comments": null, "journal-ref": "Decision Analysis 13:1 (2015) 1-25", "doi": "10.1287/deca.2015.0321", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagine a situation where a group of adversaries is preparing an attack on\nthe United States or U.S. interests. An intelligence analyst has observed some\nsignals, but the situation is rapidly changing. The analyst faces the decision\nto alert a principal decision maker that an attack is imminent, or to wait\nuntil more is known about the situation. This warning decision is based on the\nanalyst's observation and evaluation of signals, independent or correlated, and\non her updating of the prior probabilities of possible scenarios and their\noutcomes. The warning decision also depends on the analyst's assessment of the\ncrisis' dynamics and perception of the preferences of the principal decision\nmaker, as well as the lead time needed for an appropriate response. This\narticle presents a model to support this analyst's dynamic warning decision. As\nwith most problems involving warning, the key is to manage the tradeoffs\nbetween false positives and false negatives given the probabilities and the\nconsequences of intelligence failures of both types. The model is illustrated\nby revisiting the case of the attack on Pearl Harbor in December 1941. It shows\nthat the radio silence of the Japanese fleet carried considerable information\n(Sir Arthur Conan Doyle's \"dog in the night\" problem), which was misinterpreted\nat the time. Even though the probabilities of different attacks were relatively\nlow, their consequences were such that the Bayesian dynamic reasoning described\nhere may have provided valuable information to key decision makers.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 22:54:28 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Blum", "David M.", ""], ["Pate-Cornell", "M. Elisabeth", ""]]}, {"id": "1802.04889", "submitter": "Yunhui Long", "authors": "Yunhui Long, Vincent Bindschaedler, Lei Wang, Diyue Bu, Xiaofeng Wang,\n  Haixu Tang, Carl A. Gunter, and Kai Chen", "title": "Understanding Membership Inferences on Well-Generalized Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership Inference Attack (MIA) determines the presence of a record in a\nmachine learning model's training data by querying the model. Prior work has\nshown that the attack is feasible when the model is overfitted to its training\ndata or when the adversary controls the training algorithm. However, when the\nmodel is not overfitted and the adversary does not control the training\nalgorithm, the threat is not well understood. In this paper, we report a study\nthat discovers overfitting to be a sufficient but not a necessary condition for\nan MIA to succeed. More specifically, we demonstrate that even a\nwell-generalized model contains vulnerable instances subject to a new\ngeneralized MIA (GMIA). In GMIA, we use novel techniques for selecting\nvulnerable instances and detecting their subtle influences ignored by\noverfitting metrics. Specifically, we successfully identify individual records\nwith high precision in real-world datasets by querying black-box machine\nlearning models. Further we show that a vulnerable record can even be\nindirectly attacked by querying other related records and existing\ngeneralization techniques are found to be less effective in protecting the\nvulnerable instances. Our findings sharpen the understanding of the fundamental\ncause of the problem: the unique influences the training instance may have on\nthe model.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 23:05:05 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Long", "Yunhui", ""], ["Bindschaedler", "Vincent", ""], ["Wang", "Lei", ""], ["Bu", "Diyue", ""], ["Wang", "Xiaofeng", ""], ["Tang", "Haixu", ""], ["Gunter", "Carl A.", ""], ["Chen", "Kai", ""]]}, {"id": "1802.04893", "submitter": "Andrei Atanov", "authors": "Andrei Atanov, Arsenii Ashukha, Dmitry Molchanov, Kirill Neklyudov,\n  Dmitry Vetrov", "title": "Uncertainty Estimation via Stochastic Batch Normalization", "comments": "Under review as a workshop paper at ICLR 2018", "journal-ref": "Workshop track - ICLR 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate Batch Normalization technique and propose its\nprobabilistic interpretation. We propose a probabilistic model and show that\nBatch Normalization maximazes the lower bound of its marginalized\nlog-likelihood. Then, according to the new probabilistic model, we design an\nalgorithm which acts consistently during train and test. However, inference\nbecomes computationally inefficient. To reduce memory and computational cost,\nwe propose Stochastic Batch Normalization -- an efficient approximation of\nproper inference procedure. This method provides us with a scalable uncertainty\nestimation technique. We demonstrate the performance of Stochastic Batch\nNormalization on popular architectures (including deep convolutional\narchitectures: VGG-like and ResNets) for MNIST and CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 23:22:16 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 20:21:48 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Atanov", "Andrei", ""], ["Ashukha", "Arsenii", ""], ["Molchanov", "Dmitry", ""], ["Neklyudov", "Kirill", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1802.04899", "submitter": "Luiz Franca-Neto", "authors": "Luiz M Franca-Neto", "title": "Field-Programmable Deep Neural Network (DNN) Learning and Inference\n  accelerator: a concept", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accelerator is a specialized integrated circuit designed to perform\nspecific computations faster than if those were performed by CPU or GPU. A\nField-Programmable DNN learning and inference accelerator (FProg-DNN) using\nhybrid systolic and non-systolic techniques, distributed information-control\nand deep pipelined structure is proposed and its microarchitecture and\noperation presented here. Reconfigurability attends diverse DNN designs and\nallows for different number of workers to be assigned to different layers as a\nfunction of the relative difference in computational load among layers. The\ncomputational delay per layer is made roughly the same along pipelined\naccelerator structure. VGG-16 and recently proposed Inception Modules are used\nfor showing the flexibility of the FProg-DNN reconfigurability. Special\nstructures were also added for a combination of convolution layer, map\ncoincidence and feedback for state of the art learning with small set of\nexamples, which is the focus of a companion paper by the author (Franca-Neto,\n2018). The accelerator described is able to reconfigure from (1) allocating all\na DNN computations to a single worker in one extreme of sub-optimal performance\nto (2) optimally allocating workers per layer according to computational load\nin each DNN layer to be realized. Due the pipelined architecture, more than 50x\nspeedup is achieved relative to GPUs or TPUs. This speed-up is consequence of\nhiding the delay in transporting activation outputs from one layer to the next\nin a DNN behind the computations in the receiving layer. This FProg-DNN concept\nhas been simulated and validated at behavioral-functional level.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 00:02:08 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 06:23:53 GMT"}, {"version": "v3", "created": "Sun, 11 Mar 2018 00:56:28 GMT"}, {"version": "v4", "created": "Thu, 22 Mar 2018 22:41:33 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Franca-Neto", "Luiz M", ""]]}, {"id": "1802.04903", "submitter": "Joshua Staker", "authors": "Joshua Staker, Kyle Marshall, Robert Abel, Carolyn McQuaw", "title": "Molecular Structure Extraction From Documents Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical structure extraction from documents remains a hard problem due to\nboth false positive identification of structures during segmentation and errors\nin the predicted structures. Current approaches rely on handcrafted rules and\nsubroutines that perform reasonably well generally, but still routinely\nencounter situations where recognition rates are not yet satisfactory and\nsystematic improvement is challenging. Complications impacting performance of\ncurrent approaches include the diversity in visual styles used by various\nsoftware to render structures, the frequent use of ad hoc annotations, and\nother challenges related to image quality, including resolution and noise. We\nhere present end-to-end deep learning solutions for both segmenting molecular\nstructures from documents and for predicting chemical structures from these\nsegmented images. This deep learning-based approach does not require any\nhandcrafted features, is learned directly from data, and is robust against\nvariations in image quality and style. Using the deep-learning approach\ndescribed herein we show that it is possible to perform well on both\nsegmentation and prediction of low resolution images containing moderately\nsized molecules found in journal articles and patents.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 00:28:54 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Staker", "Joshua", ""], ["Marshall", "Kyle", ""], ["Abel", "Robert", ""], ["McQuaw", "Carolyn", ""]]}, {"id": "1802.04907", "submitter": "Nezihe Merve G\\\"urel", "authors": "Nezihe Merve G\\\"urel, Kaan Kara, Alen Stojanov, Tyler Smith, Thomas\n  Lemmin, Dan Alistarh, Markus P\\\"uschel, Ce Zhang", "title": "Compressive Sensing Using Iterative Hard Thresholding with Low Precision\n  Data Representation: Theory and Applications", "comments": "19 pages, 5 figures, 1 table, in IEEE Transactions on Signal\n  Processing Vol. 68, No. 7, pp. 4268-4282, 2020", "journal-ref": null, "doi": "10.1109/TSP.2020.3010355", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern scientific instruments produce vast amounts of data, which can\noverwhelm the processing ability of computer systems. Lossy compression of data\nis an intriguing solution, but comes with its own drawbacks, such as potential\nsignal loss, and the need for careful optimization of the compression ratio. In\nthis work, we focus on a setting where this problem is especially acute:\ncompressive sensing frameworks for interferometry and medical imaging. We ask\nthe following question: can the precision of the data representation be lowered\nfor all inputs, with recovery guarantees and practical performance? Our first\ncontribution is a theoretical analysis of the normalized Iterative Hard\nThresholding (IHT) algorithm when all input data, meaning both the measurement\nmatrix and the observation vector are quantized aggressively. We present a\nvariant of low precision normalized {IHT} that, under mild conditions, can\nstill provide recovery guarantees. The second contribution is the application\nof our quantization framework to radio astronomy and magnetic resonance\nimaging. We show that lowering the precision of the data can significantly\naccelerate image recovery. We evaluate our approach on telescope data and\nsamples of brain images using CPU and FPGA implementations achieving up to a 9x\nspeed-up with negligible loss of recovery quality.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 00:41:30 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 16:48:34 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 09:54:44 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 09:49:16 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["G\u00fcrel", "Nezihe Merve", ""], ["Kara", "Kaan", ""], ["Stojanov", "Alen", ""], ["Smith", "Tyler", ""], ["Lemmin", "Thomas", ""], ["Alistarh", "Dan", ""], ["P\u00fcschel", "Markus", ""], ["Zhang", "Ce", ""]]}, {"id": "1802.04911", "submitter": "Richard Zhang", "authors": "Richard Y. Zhang, Salar Fattahi, Somayeh Sojoudi", "title": "Large-Scale Sparse Inverse Covariance Estimation via Thresholding and\n  Max-Det Matrix Completion", "comments": "35-th International Conference on Machine Learning (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparse inverse covariance estimation problem is commonly solved using an\n$\\ell_{1}$-regularized Gaussian maximum likelihood estimator known as\n\"graphical lasso\", but its computational cost becomes prohibitive for large\ndata sets. A recent line of results showed--under mild assumptions--that the\ngraphical lasso estimator can be retrieved by soft-thresholding the sample\ncovariance matrix and solving a maximum determinant matrix completion (MDMC)\nproblem. This paper proves an extension of this result, and describes a\nNewton-CG algorithm to efficiently solve the MDMC problem. Assuming that the\nthresholded sample covariance matrix is sparse with a sparse Cholesky\nfactorization, we prove that the algorithm converges to an $\\epsilon$-accurate\nsolution in $O(n\\log(1/\\epsilon))$ time and $O(n)$ memory. The algorithm is\nhighly efficient in practice: we solve the associated MDMC problems with as\nmany as 200,000 variables to 7-9 digits of accuracy in less than an hour on a\nstandard laptop computer running MATLAB.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 01:00:10 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 03:24:32 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 01:13:24 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Zhang", "Richard Y.", ""], ["Fattahi", "Salar", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "1802.04918", "submitter": "Michael Lash", "authors": "Michael T. Lash and Qihang Lin and W. Nick Street", "title": "Prophit: Causal inverse classification for multiple continuously valued\n  treatment policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse classification uses an induced classifier as a queryable oracle to\nguide test instances towards a preferred posterior class label. The result\nproduced from the process is a set of instance-specific feature perturbations,\nor recommendations, that optimally improve the probability of the class label.\nIn this work, we adopt a causal approach to inverse classification, eliciting\ntreatment policies (i.e., feature perturbations) for models induced with causal\nproperties. In so doing, we solve a long-standing problem of eliciting\nmultiple, continuously valued treatment policies, using an updated framework\nand corresponding set of assumptions, which we term the inverse classification\npotential outcomes framework (ICPOF), along with a new measure, referred to as\nthe individual future estimated effects ($i$FEE). We also develop the\napproximate propensity score (APS), based on Gaussian processes, to weight\ntreatments, much like the inverse propensity score weighting used in past\nworks. We demonstrate the viability of our methods on student performance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 01:33:01 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Lash", "Michael T.", ""], ["Lin", "Qihang", ""], ["Street", "W. Nick", ""]]}, {"id": "1802.04920", "submitter": "Arash Vahdat", "authors": "Arash Vahdat, William G. Macready, Zhengbing Bian, Amir Khoshaman,\n  Evgeny Andriyash", "title": "DVAE++: Discrete Variational Autoencoders with Overlapping\n  Transformations", "comments": "Published as a conference paper at International Conference on\n  Machine Learning (ICML), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training of discrete latent variable models remains challenging because\npassing gradient information through discrete units is difficult. We propose a\nnew class of smoothing transformations based on a mixture of two overlapping\ndistributions, and show that the proposed transformation can be used for\ntraining binary latent models with either directed or undirected priors. We\nderive a new variational bound to efficiently train with Boltzmann machine\npriors. Using this bound, we develop DVAE++, a generative model with a global\ndiscrete prior and a hierarchy of convolutional continuous variables.\nExperiments on several benchmarks show that overlapping transformations\noutperform other recent continuous relaxations of discrete latent variables\nincluding Gumbel-Softmax (Maddison et al., 2016; Jang et al., 2016), and\ndiscrete variational autoencoders (Rolfe 2016).\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 01:39:05 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 23:29:08 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Vahdat", "Arash", ""], ["Macready", "William G.", ""], ["Bian", "Zhengbing", ""], ["Khoshaman", "Amir", ""], ["Andriyash", "Evgeny", ""]]}, {"id": "1802.04924", "submitter": "Zhihao Jia", "authors": "Zhihao Jia, Sina Lin, Charles R. Qi, Alex Aiken", "title": "Exploring Hidden Dimensions in Parallelizing Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have witnessed growth in the computational requirements\nfor training deep convolutional neural networks. Current approaches parallelize\ntraining onto multiple devices by applying a single parallelization strategy\n(e.g., data or model parallelism) to all layers in a network. Although easy to\nreason about, these approaches result in suboptimal runtime performance in\nlarge-scale distributed training, since different layers in a network may\nprefer different parallelization strategies. In this paper, we propose\nlayer-wise parallelism that allows each layer in a network to use an individual\nparallelization strategy. We jointly optimize how each layer is parallelized by\nsolving a graph search problem. Our evaluation shows that layer-wise\nparallelism outperforms state-of-the-art approaches by increasing training\nthroughput, reducing communication costs, achieving better scalability to\nmultiple GPUs, while maintaining original network accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 02:00:40 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 16:19:03 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Jia", "Zhihao", ""], ["Lin", "Sina", ""], ["Qi", "Charles R.", ""], ["Aiken", "Alex", ""]]}, {"id": "1802.04927", "submitter": "Ofir Lindenbaum", "authors": "Ofir Lindenbaum, Jay S. Stanley III, Guy Wolf, Smita Krishnaswamy", "title": "Geometry-Based Data Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Many generative models attempt to replicate the density of their input data.\nHowever, this approach is often undesirable, since data density is highly\naffected by sampling biases, noise, and artifacts. We propose a method called\nSUGAR (Synthesis Using Geometrically Aligned Random-walks) that uses a\ndiffusion process to learn a manifold geometry from the data. Then, it\ngenerates new points evenly along the manifold by pulling randomly generated\npoints into its intrinsic structure using a diffusion kernel. SUGAR equalizes\nthe density along the manifold by selectively generating points in sparse areas\nof the manifold. We demonstrate how the approach corrects sampling biases and\nartifacts, while also revealing intrinsic patterns (e.g. progression) and\nrelations in the data. The method is applicable for correcting missing data,\nfinding hypothetical data points, and learning relationships between data\nfeatures.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 02:03:17 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 16:30:37 GMT"}, {"version": "v3", "created": "Tue, 22 May 2018 18:58:38 GMT"}, {"version": "v4", "created": "Thu, 6 Sep 2018 19:37:19 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Lindenbaum", "Ofir", ""], ["Stanley", "Jay S.", "III"], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "1802.04929", "submitter": "Shromona Ghosh", "authors": "Somil Bansal, Shromona Ghosh, Alberto Sangiovanni-Vincentelli, Sanjit\n  A. Seshia, Claire J. Tomlin", "title": "Context-Specific Validation of Data-Driven Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an increasing use of data-driven models to control robotic systems, it\nhas become important to develop a methodology for validating such models before\nthey can be deployed to design a controller for the actual system.\nSpecifically, it must be ensured that the controller designed for a learned\nmodel would perform as expected on the actual physical system. We propose a\ncontext-specific validation framework to quantify the quality of a learned\nmodel based on a distance measure between the closed-loop actual system and the\nlearned model. We then propose an active sampling scheme to compute a\nprobabilistic upper bound on this distance in a sample-efficient manner. The\nproposed framework validates the learned model against only those behaviors of\nthe system that are relevant for the purpose for which we intend to use this\nmodel, and does not require any a priori knowledge of the system dynamics.\nSeveral simulations illustrate the practicality of the proposed framework for\nvalidating the models of real-world systems, and consequently, for controller\nsynthesis.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 02:07:55 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 03:47:15 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Bansal", "Somil", ""], ["Ghosh", "Shromona", ""], ["Sangiovanni-Vincentelli", "Alberto", ""], ["Seshia", "Sanjit A.", ""], ["Tomlin", "Claire J.", ""]]}, {"id": "1802.04931", "submitter": "Qinglong Wang", "authors": "Qinglong Wang", "title": "Energy Spatio-Temporal Pattern Prediction for Electric Vehicle Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information about the spatio-temporal pattern of electricity energy carried\nby EVs, instead of EVs themselves, is crucial for EVs to establish more\neffective and intelligent interactions with the smart grid. In this paper, we\npropose a framework for predicting the amount of the electricity energy stored\nby a large number of EVs aggregated within different city-scale regions, based\non spatio-temporal pattern of the electricity energy. The spatial pattern is\nmodeled via using a neural network based spatial predictor, while the temporal\npattern is captured via using a linear-chain conditional random field (CRF)\nbased temporal predictor. Two predictors are fed with spatial and temporal\nfeatures respectively, which are extracted based on real trajectories data\nrecorded in Beijing. Furthermore, we combine both predictors to build the\nspatio-temporal predictor, by using an optimal combination coefficient which\nminimizes the normalized mean square error (NMSE) of the predictions. The\nprediction performance is evaluated based on extensive experiments covering\nboth spatial and temporal predictions, and the improvement achieved by the\ncombined spatio-temporal predictor. The experiment results show that the NMSE\nof the spatio-temporal predictor is maintained below 0.1 for all investigate\nregions of Beijing. We further visualize the prediction and discuss the\npotential benefits can be brought to smart grid scheduling and EV charging by\nutilizing the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 02:19:13 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Wang", "Qinglong", ""]]}, {"id": "1802.04942", "submitter": "Ricky T. Q. Chen", "authors": "Ricky T. Q. Chen, Xuechen Li, Roger Grosse, David Duvenaud", "title": "Isolating Sources of Disentanglement in Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We decompose the evidence lower bound to show the existence of a term\nmeasuring the total correlation between latent variables. We use this to\nmotivate our $\\beta$-TCVAE (Total Correlation Variational Autoencoder), a\nrefinement of the state-of-the-art $\\beta$-VAE objective for learning\ndisentangled representations, requiring no additional hyperparameters during\ntraining. We further propose a principled classifier-free measure of\ndisentanglement called the mutual information gap (MIG). We perform extensive\nquantitative and qualitative experiments, in both restricted and non-restricted\nsettings, and show a strong relation between total correlation and\ndisentanglement, when the latent variables model is trained using our\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 03:48:06 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 21:01:39 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 22:26:42 GMT"}, {"version": "v4", "created": "Tue, 22 Jan 2019 21:50:57 GMT"}, {"version": "v5", "created": "Tue, 23 Apr 2019 17:20:14 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Chen", "Ricky T. Q.", ""], ["Li", "Xuechen", ""], ["Grosse", "Roger", ""], ["Duvenaud", "David", ""]]}, {"id": "1802.04944", "submitter": "Chao Shang", "authors": "Chao Shang, Qinqing Liu, Ko-Shin Chen, Jiangwen Sun, Jin Lu, Jinfeng\n  Yi, Jinbo Bi", "title": "Edge Attention-based Multi-Relational Graph Convolutional Networks", "comments": "Haven't meet my expectations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional network (GCN) is generalization of convolutional neural\nnetwork (CNN) to work with arbitrarily structured graphs. A binary adjacency\nmatrix is commonly used in training a GCN. Recently, the attention mechanism\nallows the network to learn a dynamic and adaptive aggregation of the\nneighborhood. We propose a new GCN model on the graphs where edges are\ncharacterized in multiple views or precisely in terms of multiple\nrelationships. For instance, in chemical graph theory, compound structures are\noften represented by the hydrogen-depleted molecular graph where nodes\ncorrespond to atoms and edges correspond to chemical bonds. Multiple attributes\ncan be important to characterize chemical bonds, such as atom pair (the types\nof atoms that a bond connects), aromaticity, and whether a bond is in a ring.\nThe different attributes lead to different graph representations for the same\nmolecule. There is growing interests in both chemistry and machine learning\nfields to directly learn molecular properties of compounds from the molecular\ngraph, instead of from fingerprints predefined by chemists. The proposed GCN\nmodel, which we call edge attention-based multi-relational GCN (EAGCN), jointly\nlearns attention weights and node features in graph convolution. For each bond\nattribute, a real-valued attention matrix is used to replace the binary\nadjacency matrix. By designing a dictionary for the edge attention, and forming\nthe attention matrix of each molecule by looking up the dictionary, the EAGCN\nexploits correspondence between bonds in different molecules. The prediction of\ncompound properties is based on the aggregated node features, which is\nindependent of the varying molecule (graph) size. We demonstrate the efficacy\nof the EAGCN on multiple chemical datasets: Tox21, HIV, Freesolv, and\nLipophilicity, and interpret the resultant attention weights.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 03:52:58 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 14:28:06 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Shang", "Chao", ""], ["Liu", "Qinqing", ""], ["Chen", "Ko-Shin", ""], ["Sun", "Jiangwen", ""], ["Lu", "Jin", ""], ["Yi", "Jinfeng", ""], ["Bi", "Jinbo", ""]]}, {"id": "1802.04947", "submitter": "Cong Xie", "authors": "Cong Xie", "title": "Attack RMSE Leaderboard: An Introduction and Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript, we briefly introduce several tricks to climb the\nleaderboards which use RMSE for evaluation without exploiting any training\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 03:57:59 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Xie", "Cong", ""]]}, {"id": "1802.04948", "submitter": "Shaileshh Bojja Venkatakrishnan", "authors": "Shaileshh Bojja Venkatakrishnan, Mohammad Alizadeh, Pramod Viswanath", "title": "Graph2Seq: Scalable Learning Dynamics for Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been shown to be an effective tool for learning\nalgorithms over graph-structured data. However, graph representation\ntechniques---that convert graphs to real-valued vectors for use with neural\nnetworks---are still in their infancy. Recent works have proposed several\napproaches (e.g., graph convolutional networks), but these methods have\ndifficulty scaling and generalizing to graphs with different sizes and shapes.\nWe present Graph2Seq, a new technique that represents vertices of graphs as\ninfinite time-series. By not limiting the representation to a fixed dimension,\nGraph2Seq scales naturally to graphs of arbitrary sizes and shapes. Graph2Seq\nis also reversible, allowing full recovery of the graph structure from the\nsequences. By analyzing a formal computational model for graph representation,\nwe show that an unbounded sequence is necessary for scalability. Our\nexperimental results with Graph2Seq show strong generalization and new\nstate-of-the-art performance on a variety of graph combinatorial optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 04:04:41 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 15:21:57 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 15:00:04 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Venkatakrishnan", "Shaileshh Bojja", ""], ["Alizadeh", "Mohammad", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1802.04956", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Ian En-Hsu Yen, Fangli Xu, Pradeep Ravikumar, Michael\n  Witbrock", "title": "D2KE: From Distance to Kernel and Embedding", "comments": "15 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many machine learning problem settings, particularly with structured\ninputs such as sequences or sets of objects, a distance measure between inputs\ncan be specified more naturally than a feature representation. However, most\nstandard machine models are designed for inputs with a vector feature\nrepresentation. In this work, we consider the estimation of a function\n$f:\\mathcal{X} \\rightarrow \\R$ based solely on a dissimilarity measure\n$d:\\mathcal{X}\\times\\mathcal{X} \\rightarrow \\R$ between inputs. In particular,\nwe propose a general framework to derive a family of \\emph{positive definite\nkernels} from a given dissimilarity measure, which subsumes the widely-used\n\\emph{representative-set method} as a special case, and relates to the\nwell-known \\emph{distance substitution kernel} in a limiting case. We show that\nfunctions in the corresponding Reproducing Kernel Hilbert Space (RKHS) are\nLipschitz-continuous w.r.t. the given distance metric. We provide a tractable\nalgorithm to estimate a function from this RKHS, and show that it enjoys better\ngeneralizability than Nearest-Neighbor estimates. Our approach draws from the\nliterature of Random Features, but instead of deriving feature maps from an\nexisting kernel, we construct novel kernels from a random feature map, that we\nspecify given the distance measure. We conduct classification experiments with\nsuch disparate domains as strings, time series, and sets of vectors, where our\nproposed framework compares favorably to existing distance-based learning\nmethods such as $k$-nearest-neighbors, distance-substitution kernels,\npseudo-Euclidean embedding, and the representative-set method.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 04:58:13 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 18:43:50 GMT"}, {"version": "v3", "created": "Fri, 16 Feb 2018 04:58:45 GMT"}, {"version": "v4", "created": "Fri, 25 May 2018 06:02:45 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Wu", "Lingfei", ""], ["Yen", "Ian En-Hsu", ""], ["Xu", "Fangli", ""], ["Ravikumar", "Pradeep", ""], ["Witbrock", "Michael", ""]]}, {"id": "1802.04967", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Luiz G. Hafemann, Robert Sabourin and George D. C.\n  Cavalcanti", "title": "DESlib: A Dynamic ensemble selection library in Python", "comments": "Paper introducing DESlib: A dynamic ensemble selection library in\n  Python", "journal-ref": "Journal of Machine Learning Research, 21 (2020), 1-5", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DESlib is an open-source python library providing the implementation of\nseveral dynamic selection techniques. The library is divided into three\nmodules: (i) \\emph{dcs}, containing the implementation of dynamic classifier\nselection methods (DCS); (ii) \\emph{des}, containing the implementation of\ndynamic ensemble selection methods (DES); (iii) \\emph{static}, with the\nimplementation of static ensemble techniques. The library is fully documented\n(documentation available online on Read the Docs), has a high test coverage\n(codecov.io) and is part of the scikit-learn-contrib supported projects.\nDocumentation, code and examples can be found on its GitHub page:\nhttps://github.com/scikit-learn-contrib/DESlib.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 06:30:47 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 01:47:08 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2019 00:34:32 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Hafemann", "Luiz G.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1802.04986", "submitter": "Viet Anh Phan Mr", "authors": "Anh Viet Phan, Minh Le Nguyen, Lam Thu Bui", "title": "Convolutional Neural Networks over Control Flow Graphs for Software\n  Defect Prediction", "comments": "presented at ICTAI 2017", "journal-ref": "ICTAI 2017", "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing defects in software components is unavoidable and leads to not only\na waste of time and money but also many serious consequences. To build\npredictive models, previous studies focus on manually extracting features or\nusing tree representations of programs, and exploiting different machine\nlearning algorithms. However, the performance of the models is not high since\nthe existing features and tree structures often fail to capture the semantics\nof programs. To explore deeply programs' semantics, this paper proposes to\nleverage precise graphs representing program execution flows, and deep neural\nnetworks for automatically learning defect features. Firstly, control flow\ngraphs are constructed from the assembly instructions obtained by compiling\nsource code; we thereafter apply multi-view multi-layer directed graph-based\nconvolutional neural networks (DGCNNs) to learn semantic features. The\nexperiments on four real-world datasets show that our method significantly\noutperforms the baselines including several other deep learning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 08:32:05 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Phan", "Anh Viet", ""], ["Nguyen", "Minh Le", ""], ["Bui", "Lam Thu", ""]]}, {"id": "1802.05027", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Emanuela Keller, Carl Muroi, David J. Mack, Christian\n  Str\\\"assle, Walter Karlen", "title": "Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical\n  Care", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:4518-4527, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients in the intensive care unit (ICU) require constant and close\nsupervision. To assist clinical staff in this task, hospitals use monitoring\nsystems that trigger audiovisual alarms if their algorithms indicate that a\npatient's condition may be worsening. However, current monitoring systems are\nextremely sensitive to movement artefacts and technical errors. As a result,\nthey typically trigger hundreds to thousands of false alarms per patient per\nday - drowning the important alarms in noise and adding to the exhaustion of\nclinical staff. In this setting, data is abundantly available, but obtaining\ntrustworthy annotations by experts is laborious and expensive. We frame the\nproblem of false alarm reduction from multivariate time series as a\nmachine-learning task and address it with a novel multitask network\narchitecture that utilises distant supervision through multiple related\nauxiliary tasks in order to reduce the number of expensive labels required for\ntraining. We show that our approach leads to significant improvements over\nseveral state-of-the-art baselines on real-world ICU data and provide new\ninsights on the importance of task selection and architectural choices in\ndistantly supervised multitask learning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 10:35:08 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 23:31:24 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Schwab", "Patrick", ""], ["Keller", "Emanuela", ""], ["Muroi", "Carl", ""], ["Mack", "David J.", ""], ["Str\u00e4ssle", "Christian", ""], ["Karlen", "Walter", ""]]}, {"id": "1802.05031", "submitter": "Francisco Charte", "authors": "Francisco Charte and Antonio J. Rivera and Mar\\'ia J. del Jesus and\n  Francisco Herrera", "title": "Tackling Multilabel Imbalance through Label Decoupling and Data\n  Resampling Hybridization", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2017.01.118", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning from imbalanced data is a deeply studied problem in standard\nclassification and, in recent times, also in multilabel classification. A\nhandful of multilabel resampling methods have been proposed in late years,\naiming to balance the labels distribution. However these methods have to face a\nnew obstacle, specific for multilabel data, as is the joint appearance of\nminority and majority labels in the same data patterns. We proposed recently a\nnew algorithm designed to decouple imbalanced labels concurring in the same\ninstance, called REMEDIAL (\\textit{REsampling MultilabEl datasets by Decoupling\nhighly ImbAlanced Labels}). The goal of this work is to propose a procedure to\nhybridize this method with some of the best resampling algorithms available in\nthe literature, including random oversampling, heuristic undersampling and\nsynthetic sample generation techniques. These hybrid methods are then\nempirically analyzed, determining how their behavior is influenced by the label\ndecoupling process. As a result, a noteworthy set of guidelines on the combined\nuse of these techniques can be drawn from the conducted experimentation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 10:45:57 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Charte", "Francisco", ""], ["Rivera", "Antonio J.", ""], ["del Jesus", "Mar\u00eda J.", ""], ["Herrera", "Francisco", ""]]}, {"id": "1802.05033", "submitter": "Francisco Charte", "authors": "Francisco Charte and Antonio J. Rivera and Mar\\'ia J. del Jesus and\n  Francisco Herrera", "title": "Dealing with Difficult Minority Labels in Imbalanced Mutilabel Data Sets", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2016.08.158", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilabel classification is an emergent data mining task with a broad range\nof real world applications. Learning from imbalanced multilabel data is being\ndeeply studied latterly, and several resampling methods have been proposed in\nthe literature. The unequal label distribution in most multilabel datasets,\nwith disparate imbalance levels, could be a handicap while learning new\nclassifiers. In addition, this characteristic challenges many of the existent\npreprocessing algorithms. Furthermore, the concurrence between imbalanced\nlabels can make harder the learning from certain labels. These are what we call\n\\textit{difficult} labels. In this work, the problem of difficult labels is\ndeeply analyzed, its influence in multilabel classifiers is studied, and a\nnovel way to solve this problem is proposed. Specific metrics to assess this\ntrait in multilabel datasets, called \\textit{SCUMBLE} (\\textit{Score of\nConcUrrence among iMBalanced LabEls}) and \\textit{SCUMBLELbl}, are presented\nalong with REMEDIAL (\\textit{REsampling MultilabEl datasets by Decoupling\nhighly ImbAlanced Labels}), a new algorithm aimed to relax label concurrence.\nHow to deal with this problem using the R mldr package is also outlined.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 11:00:03 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Charte", "Francisco", ""], ["Rivera", "Antonio J.", ""], ["del Jesus", "Mar\u00eda J.", ""], ["Herrera", "Francisco", ""]]}, {"id": "1802.05036", "submitter": "Xiao He", "authors": "Xiao He, Luis Moreira-Matias", "title": "Robust Continuous Co-Clustering", "comments": "Under reviewing process", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering consists of grouping together samples giving their similar\nproperties. The problem of modeling simultaneously groups of samples and\nfeatures is known as Co-Clustering. This paper introduces ROCCO - a Robust\nContinuous Co-Clustering algorithm. ROCCO is a scalable, hyperparameter-free,\neasy and ready to use algorithm to address Co-Clustering problems in practice\nover massive cross-domain datasets. It operates by learning a graph-based\ntwo-sided representation of the input matrix. The underlying proposed\noptimization problem is non-convex, which assures a flexible pool of solutions.\nMoreover, we prove that it can be solved with a near linear time complexity on\nthe input size. An exhaustive large-scale experimental testbed conducted with\nboth synthetic and real-world datasets demonstrates ROCCO's properties in\npractice: (i) State-of-the-art performance in cross-domain real-world problems\nincluding Biomedicine and Text Mining; (ii) very low sensitivity to\nhyperparameter settings; (iii) robustness to noise and (iv) a linear empirical\nscalability in practice. These results highlight ROCCO as a powerful\ngeneral-purpose co-clustering algorithm for cross-domain practitioners,\nregardless of their technical background.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 11:07:16 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["He", "Xiao", ""], ["Moreira-Matias", "Luis", ""]]}, {"id": "1802.05046", "submitter": "Yishai Shimoni", "authors": "Yishai Shimoni, Chen Yanover, Ehud Karavani and Yaara Goldschmnidt", "title": "Benchmarking Framework for Performance-Evaluation of Causal Inference\n  Analysis", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Causal inference analysis is the estimation of the effects of actions on\noutcomes. In the context of healthcare data this means estimating the outcome\nof counter-factual treatments (i.e. including treatments that were not\nobserved) on a patient's outcome. Compared to classic machine learning methods,\nevaluation and validation of causal inference analysis is more challenging\nbecause ground truth data of counter-factual outcome can never be obtained in\nany real-world scenario. Here, we present a comprehensive framework for\nbenchmarking algorithms that estimate causal effect. The framework includes\nunlabeled data for prediction, labeled data for validation, and code for\nautomatic evaluation of algorithm predictions using both established and novel\nmetrics. The data is based on real-world covariates, and the treatment\nassignments and outcomes are based on simulations, which provides the basis for\nvalidation. In this framework we address two questions: one of scaling, and the\nother of data-censoring. The framework is available as open source code at\nhttps://github.com/IBM-HRL-MLHLS/IBM-Causal-Inference-Benchmarking-Framework\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 11:41:56 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 16:12:47 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Shimoni", "Yishai", ""], ["Yanover", "Chen", ""], ["Karavani", "Ehud", ""], ["Goldschmnidt", "Yaara", ""]]}, {"id": "1802.05054", "submitter": "Olivier Sigaud", "authors": "C\\'edric Colas and Olivier Sigaud and Pierre-Yves Oudeyer", "title": "GEP-PG: Decoupling Exploration and Exploitation in Deep Reinforcement\n  Learning Algorithms", "comments": "accepted at ICML 2018, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In continuous action domains, standard deep reinforcement learning algorithms\nlike DDPG suffer from inefficient exploration when facing sparse or deceptive\nreward problems. Conversely, evolutionary and developmental methods focusing on\nexploration like Novelty Search, Quality-Diversity or Goal Exploration\nProcesses explore more robustly but are less efficient at fine-tuning policies\nusing gradient descent. In this paper, we present the GEP-PG approach, taking\nthe best of both worlds by sequentially combining a Goal Exploration Process\nand two variants of DDPG. We study the learning performance of these components\nand their combination on a low dimensional deceptive reward problem and on the\nlarger Half-Cheetah benchmark. We show that DDPG fails on the former and that\nGEP-PG improves over the best DDPG variant in both environments. Supplementary\nvideos and discussion can be found at http://frama.link/gep_pg, the code at\nhttp://github.com/flowersteam/geppg.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 11:59:21 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 07:22:07 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 14:21:51 GMT"}, {"version": "v4", "created": "Fri, 17 Aug 2018 11:51:01 GMT"}, {"version": "v5", "created": "Thu, 20 Sep 2018 12:53:58 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Colas", "C\u00e9dric", ""], ["Sigaud", "Olivier", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1802.05074", "submitter": "Michal Rolinek", "authors": "Michal Rolinek, and Georg Martius", "title": "L4: Practical loss-based stepsize adaptation for deep learning", "comments": "NeurIPS, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stepsize adaptation scheme for stochastic gradient descent. It\noperates directly with the loss function and rescales the gradient in order to\nmake fixed predicted progress on the loss. We demonstrate its capabilities by\nconclusively improving the performance of Adam and Momentum optimizers. The\nenhanced optimizers with default hyperparameters consistently outperform their\nconstant stepsize counterparts, even the best ones, without a measurable\nincrease in computational cost. The performance is validated on multiple\narchitectures including dense nets, CNNs, ResNets, and the recurrent\nDifferential Neural Computer on classical datasets MNIST, fashion MNIST,\nCIFAR10 and others.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 12:47:37 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 19:31:13 GMT"}, {"version": "v3", "created": "Wed, 21 Feb 2018 18:51:03 GMT"}, {"version": "v4", "created": "Tue, 5 Jun 2018 10:09:37 GMT"}, {"version": "v5", "created": "Fri, 30 Nov 2018 14:42:32 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Rolinek", "Michal", ""], ["Martius", "Georg", ""]]}, {"id": "1802.05098", "submitter": "Jakob Foerster", "authors": "Jakob Foerster, Gregory Farquhar, Maruan Al-Shedivat, Tim\n  Rockt\\\"aschel, Eric P. Xing, Shimon Whiteson", "title": "DiCE: The Infinitely Differentiable Monte-Carlo Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The score function estimator is widely used for estimating gradients of\nstochastic objectives in stochastic computation graphs (SCG), eg, in\nreinforcement learning and meta-learning. While deriving the first-order\ngradient estimators by differentiating a surrogate loss (SL) objective is\ncomputationally and conceptually simple, using the same approach for\nhigher-order derivatives is more challenging. Firstly, analytically deriving\nand implementing such estimators is laborious and not compliant with automatic\ndifferentiation. Secondly, repeatedly applying SL to construct new objectives\nfor each order derivative involves increasingly cumbersome graph manipulations.\nLastly, to match the first-order gradient under differentiation, SL treats part\nof the cost as a fixed sample, which we show leads to missing and wrong terms\nfor estimators of higher-order derivatives. To address all these shortcomings\nin a unified way, we introduce DiCE, which provides a single objective that can\nbe differentiated repeatedly, generating correct estimators of derivatives of\nany order in SCGs. Unlike SL, DiCE relies on automatic differentiation for\nperforming the requisite graph manipulations. We verify the correctness of DiCE\nboth through a proof and numerical evaluation of the DiCE derivative estimates.\nWe also use DiCE to propose and evaluate a novel approach for multi-agent\nlearning. Our code is available at https://www.github.com/alshedivat/lola.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 14:05:54 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 10:59:41 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 19:11:15 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Foerster", "Jakob", ""], ["Farquhar", "Gregory", ""], ["Al-Shedivat", "Maruan", ""], ["Rockt\u00e4schel", "Tim", ""], ["Xing", "Eric P.", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1802.05141", "submitter": "Kelvin Loh", "authors": "Kelvin Loh, Pejman Shoeibi Omrani, Ruud van der Linden", "title": "Deep Learning and Data Assimilation for Real-Time Production Prediction\n  in Natural Gas Wells", "comments": "Reduced length preprint submitted to IJCAI 2018 for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.flu-dyn physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of the gas production from mature gas wells, due to their\ncomplex end-of-life behavior, is challenging and crucial for operational\ndecision making. In this paper, we apply a modified deep LSTM model for\nprediction of the gas flow rates in mature gas wells, including the\nuncertainties in input parameters. Additionally, due to changes in the system\nin time and in order to increase the accuracy and robustness of the prediction,\nthe Ensemble Kalman Filter (EnKF) is used to update the flow rate predictions\nbased on new observations. The developed approach was tested on the data from\ntwo mature gas production wells in which their production is highly dynamic and\nsuffering from salt deposition. The results show that the flow predictions\nusing the EnKF updated model leads to better Jeffreys' J-divergences than the\npredictions without the EnKF model updating scheme.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 15:03:09 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 03:16:08 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Loh", "Kelvin", ""], ["Omrani", "Pejman Shoeibi", ""], ["van der Linden", "Ruud", ""]]}, {"id": "1802.05155", "submitter": "Tianyi Liu", "authors": "Tianyi Liu, Zhehui Chen, Enlu Zhou, Tuo Zhao", "title": "A Diffusion Approximation Theory of Momentum SGD in Nonconvex\n  Optimization", "comments": "arXiv admin note: text overlap with arXiv:1806.01660", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum Stochastic Gradient Descent (MSGD) algorithm has been widely applied\nto many nonconvex optimization problems in machine learning, e.g., training\ndeep neural networks, variational Bayesian inference, and etc. Despite its\nempirical success, there is still a lack of theoretical understanding of\nconvergence properties of MSGD. To fill this gap, we propose to analyze the\nalgorithmic behavior of MSGD by diffusion approximations for nonconvex\noptimization problems with strict saddle points and isolated local optima. Our\nstudy shows that the momentum helps escape from saddle points, but hurts the\nconvergence within the neighborhood of optima (if without the step size\nannealing or momentum annealing). Our theoretical discovery partially\ncorroborates the empirical success of MSGD in training deep neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 15:26:59 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 16:17:15 GMT"}, {"version": "v3", "created": "Mon, 1 Oct 2018 21:29:06 GMT"}, {"version": "v4", "created": "Wed, 9 Oct 2019 03:13:03 GMT"}, {"version": "v5", "created": "Sat, 6 Mar 2021 20:32:04 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Liu", "Tianyi", ""], ["Chen", "Zhehui", ""], ["Zhou", "Enlu", ""], ["Zhao", "Tuo", ""]]}, {"id": "1802.05187", "submitter": "Elad Hoffer", "authors": "Elad Hoffer, Shai Fine, Daniel Soudry", "title": "On the Blindspots of Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional network has been the state-of-the-art approach for a wide\nvariety of tasks over the last few years. Its successes have, in many cases,\nturned it into the default model in quite a few domains. In this work, we will\ndemonstrate that convolutional networks have limitations that may, in some\ncases, hinder it from learning properties of the data, which are easily\nrecognizable by traditional, less demanding, models. To this end, we present a\nseries of competitive analysis studies on image recognition and text analysis\ntasks, for which convolutional networks are known to provide state-of-the-art\nresults. In our studies, we inject a truth-revealing signal, indiscernible for\nthe network, thus hitting time and again the network's blind spots. The signal\ndoes not impair the network's existing performances, but it does provide an\nopportunity for a significant performance boost by models that can capture it.\nThe various forms of the carefully designed signals shed a light on the\nstrengths and weaknesses of convolutional network, which may provide insights\nfor both theoreticians that study the power of deep architectures, and for\npractitioners that consider applying convolutional networks to the task at\nhand.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 16:24:54 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 07:14:42 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Hoffer", "Elad", ""], ["Fine", "Shai", ""], ["Soudry", "Daniel", ""]]}, {"id": "1802.05190", "submitter": "Yuxin Chen", "authors": "Yuxin Chen, Adish Singla, Oisin Mac Aodha, Pietro Perona, Yisong Yue", "title": "Understanding the Role of Adaptivity in Machine Teaching: The Case of\n  Version Space Learners", "comments": "NeurIPS 2018 (extended version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications of education, an effective teacher adaptively\nchooses the next example to teach based on the learner's current state.\nHowever, most existing work in algorithmic machine teaching focuses on the\nbatch setting, where adaptivity plays no role. In this paper, we study the case\nof teaching consistent, version space learners in an interactive setting. At\nany time step, the teacher provides an example, the learner performs an update,\nand the teacher observes the learner's new state. We highlight that adaptivity\ndoes not speed up the teaching process when considering existing models of\nversion space learners, such as \"worst-case\" (the learner picks the next\nhypothesis randomly from the version space) and \"preference-based\" (the learner\npicks hypothesis according to some global preference). Inspired by human\nteaching, we propose a new model where the learner picks hypotheses according\nto some local preference defined by the current hypothesis. We show that our\nmodel exhibits several desirable properties, e.g., adaptivity plays a key role,\nand the learner's transitions over hypotheses are smooth/interpretable. We\ndevelop efficient teaching algorithms and demonstrate our results via\nsimulation and user studies.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 16:27:30 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 16:56:45 GMT"}, {"version": "v3", "created": "Sun, 9 Dec 2018 02:11:03 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Chen", "Yuxin", ""], ["Singla", "Adish", ""], ["Mac Aodha", "Oisin", ""], ["Perona", "Pietro", ""], ["Yue", "Yisong", ""]]}, {"id": "1802.05193", "submitter": "Tao Liu", "authors": "Qi Liu, Tao Liu, Zihao Liu, Yanzhi Wang, Yier Jin, Wujie Wen", "title": "Security Analysis and Enhancement of Model Compressed Deep Learning\n  Systems under Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNN is presenting human-level performance for many complex intelligent tasks\nin real-world applications. However, it also introduces ever-increasing\nsecurity concerns. For example, the emerging adversarial attacks indicate that\neven very small and often imperceptible adversarial input perturbations can\neasily mislead the cognitive function of deep learning systems (DLS). Existing\nDNN adversarial studies are narrowly performed on the ideal software-level DNN\nmodels with a focus on single uncertainty factor, i.e. input perturbations,\nhowever, the impact of DNN model reshaping on adversarial attacks, which is\nintroduced by various hardware-favorable techniques such as hash-based weight\ncompression during modern DNN hardware implementation, has never been\ndiscussed. In this work, we for the first time investigate the multi-factor\nadversarial attack problem in practical model optimized deep learning systems\nby jointly considering the DNN model-reshaping (e.g. HashNet based deep\ncompression) and the input perturbations. We first augment adversarial example\ngenerating method dedicated to the compressed DNN models by incorporating the\nsoftware-based approaches and mathematical modeled DNN reshaping. We then\nconduct a comprehensive robustness and vulnerability analysis of deep\ncompressed DNN models under derived adversarial attacks. A defense technique\nnamed \"gradient inhibition\" is further developed to ease the generating of\nadversarial examples thus to effectively mitigate adversarial attacks towards\nboth software and hardware-oriented DNNs. Simulation results show that\n\"gradient inhibition\" can decrease the average success rate of adversarial\nattacks from 87.99% to 4.77% (from 86.74% to 4.64%) on MNIST (CIFAR-10)\nbenchmark with marginal accuracy degradation across various DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 16:31:35 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 18:02:11 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Liu", "Qi", ""], ["Liu", "Tao", ""], ["Liu", "Zihao", ""], ["Wang", "Yanzhi", ""], ["Jin", "Yier", ""], ["Wen", "Wujie", ""]]}, {"id": "1802.05196", "submitter": "John Seymour", "authors": "John Seymour and Philip Tully", "title": "Generative Models for Spear Phishing Posts on Social Media", "comments": "Presented at NIPS Workshop on Machine Deception (2017), 4 page limit\n  plus references, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historically, machine learning in computer security has prioritized defense:\nthink intrusion detection systems, malware classification, and botnet traffic\nidentification. Offense can benefit from data just as well. Social networks,\nwith their access to extensive personal data, bot-friendly APIs, colloquial\nsyntax, and prevalence of shortened links, are the perfect venues for spreading\nmachine-generated malicious content. We aim to discover what capabilities an\nadversary might utilize in such a domain. We present a long short-term memory\n(LSTM) neural network that learns to socially engineer specific users into\nclicking on deceptive URLs. The model is trained with word vector\nrepresentations of social media posts, and in order to make a click-through\nmore likely, it is dynamically seeded with topics extracted from the target's\ntimeline. We augment the model with clustering to triage high value targets\nbased on their level of social engagement, and measure success of the LSTM's\nphishing expedition using click-rates of IP-tracked links. We achieve state of\nthe art success rates, tripling those of historic email attack campaigns, and\noutperform humans manually performing the same task.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 16:40:02 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Seymour", "John", ""], ["Tully", "Philip", ""]]}, {"id": "1802.05214", "submitter": "Ayan Chakrabarti", "authors": "Francesco Pittaluga, Sanjeev J. Koppal, Ayan Chakrabarti", "title": "Learning Privacy Preserving Encodings through Adversarial Training", "comments": "To appear in WACV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework to learn privacy-preserving encodings of images that\ninhibit inference of chosen private attributes, while allowing recovery of\nother desirable information. Rather than simply inhibiting a given fixed\npre-trained estimator, our goal is that an estimator be unable to learn to\naccurately predict the private attributes even with knowledge of the encoding\nfunction. We use a natural adversarial optimization-based formulation for\nthis---training the encoding function against a classifier for the private\nattribute, with both modeled as deep neural networks. The key contribution of\nour work is a stable and convergent optimization approach that is successful at\nlearning an encoder with our desired properties---maintaining utility while\ninhibiting inference of private attributes, not just within the adversarial\noptimization, but also by classifiers that are trained after the encoder is\nfixed. We adopt a rigorous experimental protocol for verification wherein\nclassifiers are trained exhaustively till saturation on the fixed encoders. We\nevaluate our approach on tasks of real-world complexity---learning\nhigh-dimensional encodings that inhibit detection of different scene\ncategories---and find that it yields encoders that are resilient at maintaining\nprivacy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 17:04:07 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 21:33:11 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 19:24:57 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Pittaluga", "Francesco", ""], ["Koppal", "Sanjeev J.", ""], ["Chakrabarti", "Ayan", ""]]}, {"id": "1802.05234", "submitter": "Jirong Yi", "authors": "Jirong Yi and Weiyu Xu", "title": "Necessary and Sufficient Null Space Condition for Nuclear Norm\n  Minimization in Low-Rank Matrix Recovery", "comments": "17 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank matrix recovery has found many applications in science and\nengineering such as machine learning, signal processing, collaborative\nfiltering, system identification, and Euclidean embedding. But the low-rank\nmatrix recovery problem is an NP hard problem and thus challenging. A commonly\nused heuristic approach is the nuclear norm minimization. In [12,14,15], the\nauthors established the necessary and sufficient null space conditions for\nnuclear norm minimization to recover every possible low-rank matrix with rank\nat most r (the strong null space condition). In addition, in [12], Oymak et al.\nestablished a null space condition for successful recovery of a given low-rank\nmatrix (the weak null space condition) using nuclear norm minimization, and\nderived the phase transition for the nuclear norm minimization. In this paper,\nwe show that the weak null space condition in [12] is only a sufficient\ncondition for successful matrix recovery using nuclear norm minimization, and\nis not a necessary condition as claimed in [12]. In this paper, we further give\na weak null space condition for low-rank matrix recovery, which is both\nnecessary and sufficient for the success of nuclear norm minimization. At the\ncore of our derivation are an inequality for characterizing the nuclear norms\nof block matrices, and the conditions for equality to hold in that inequality.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 17:44:22 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Yi", "Jirong", ""], ["Xu", "Weiyu", ""]]}, {"id": "1802.05249", "submitter": "Matthew Staib", "authors": "Matthew Staib, Bryan Wilder, Stefanie Jegelka", "title": "Distributionally Robust Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions have applications throughout machine learning, but in\nmany settings, we do not have direct access to the underlying function $f$. We\nfocus on stochastic functions that are given as an expectation of functions\nover a distribution $P$. In practice, we often have only a limited set of\nsamples $f_i$ from $P$. The standard approach indirectly optimizes $f$ by\nmaximizing the sum of $f_i$. However, this ignores generalization to the true\n(unknown) distribution. In this paper, we achieve better performance on the\nactual underlying function $f$ by directly optimizing a combination of bias and\nvariance. Algorithmically, we accomplish this by showing how to carry out\ndistributionally robust optimization (DRO) for submodular functions, providing\nefficient algorithms backed by theoretical guarantees which leverage several\nnovel contributions to the general theory of DRO. We also show compelling\nempirical evidence that DRO improves generalization to the unknown stochastic\nsubmodular function.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 18:16:43 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 02:06:25 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Staib", "Matthew", ""], ["Wilder", "Bryan", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1802.05251", "submitter": "Di Wang", "authors": "Di Wang and Minwei Ye and Jinhui Xu", "title": "Differentially Private Empirical Risk Minimization Revisited: Faster and\n  More General", "comments": "Thirty-first Annual Conference on Neural Information Processing\n  Systems (NIPS-2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the differentially private Empirical Risk Minimization\n(ERM) problem in different settings. For smooth (strongly) convex loss function\nwith or without (non)-smooth regularization, we give algorithms that achieve\neither optimal or near optimal utility bounds with less gradient complexity\ncompared with previous work. For ERM with smooth convex loss function in\nhigh-dimensional ($p\\gg n$) setting, we give an algorithm which achieves the\nupper bound with less gradient complexity than previous ones. At last, we\ngeneralize the expected excess empirical risk from convex loss functions to\nnon-convex ones satisfying the Polyak-Lojasiewicz condition and give a tighter\nupper bound on the utility than the one in \\cite{ijcai2017-548}.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 18:20:48 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Wang", "Di", ""], ["Ye", "Minwei", ""], ["Xu", "Jinhui", ""]]}, {"id": "1802.05283", "submitter": "Abir De", "authors": "Bidisha Samanta, Abir De, Gourhari Jana, Pratim Kumar Chattaraj, Niloy\n  Ganguly, Manuel Gomez-Rodriguez", "title": "NeVAE: A Deep Generative Model for Molecular Graphs", "comments": "Accepted in AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have been praised for their ability to learn smooth\nlatent representation of images, text, and audio, which can then be used to\ngenerate new, plausible data. However, current generative models are unable to\nwork with molecular graphs due to their unique characteristics-their underlying\nstructure is not Euclidean or grid-like, they remain isomorphic under\npermutation of the nodes labels, and they come with a different number of nodes\nand edges. In this paper, we first propose a novel variational autoencoder for\nmolecular graphs, whose encoder and decoder are specially designed to account\nfor the above properties by means of several technical innovations. Moreover,\nin contrast with the state of the art, our decoder is able to provide the\nspatial coordinates of the atoms of the molecules it generates. Then, we\ndevelop a gradient-based algorithm to optimize the decoder of our model so that\nit learns to generate molecules that maximize the value of certain property of\ninterest and, given a molecule of interest, it is able to optimize the spatial\nconfiguration of its atoms for greater stability. Experiments reveal that our\nvariational autoencoder can discover plausible, diverse and novel molecules\nmore effectively than several state of the art models. Moreover, for several\nproperties of interest, our optimized decoder is able to identify molecules\nwith property values 121% higher than those identified by several state of the\nart methods based on Bayesian optimization and reinforcement learning\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 19:00:34 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 18:01:28 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 19:11:08 GMT"}, {"version": "v4", "created": "Fri, 6 Sep 2019 15:16:18 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Samanta", "Bidisha", ""], ["De", "Abir", ""], ["Jana", "Gourhari", ""], ["Chattaraj", "Pratim Kumar", ""], ["Ganguly", "Niloy", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1802.05296", "submitter": "Yi Zhang", "authors": "Sanjeev Arora, Rong Ge, Behnam Neyshabur, Yi Zhang", "title": "Stronger generalization bounds for deep nets via a compression approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep nets generalize well despite having more parameters than the number of\ntraining samples. Recent works try to give an explanation using PAC-Bayes and\nMargin-based analyses, but do not as yet result in sample complexity bounds\nbetter than naive parameter counting. The current paper shows generalization\nbounds that're orders of magnitude better in practice. These rely upon new\nsuccinct reparametrizations of the trained net --- a compression that is\nexplicit and efficient. These yield generalization bounds via a simple\ncompression-based framework introduced here. Our results also provide some\ntheoretical justification for widespread empirical success in compressing deep\nnets. Analysis of correctness of our compression relies upon some newly\nidentified \\textquotedblleft noise stability\\textquotedblright properties of\ntrained deep nets, which are also experimentally verified. The study of these\nproperties and resulting generalization bounds are also extended to\nconvolutional nets, which had eluded earlier attempts on proving\ngeneralization.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 19:38:07 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 17:55:49 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 21:43:00 GMT"}, {"version": "v4", "created": "Mon, 26 Nov 2018 19:31:00 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Arora", "Sanjeev", ""], ["Ge", "Rong", ""], ["Neyshabur", "Behnam", ""], ["Zhang", "Yi", ""]]}, {"id": "1802.05300", "submitter": "Mantas Mazeika", "authors": "Dan Hendrycks, Mantas Mazeika, Duncan Wilson, Kevin Gimpel", "title": "Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe\n  Noise", "comments": "NeurIPS 2018. PyTorch code available at\n  https://github.com/mmazeika/glc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing importance of massive datasets used for deep learning makes\nrobustness to label noise a critical property for classifiers to have. Sources\nof label noise include automatic labeling, non-expert labeling, and label\ncorruption by data poisoning adversaries. Numerous previous works assume that\nno source of labels can be trusted. We relax this assumption and assume that a\nsmall subset of the training data is trusted. This enables substantial label\ncorruption robustness performance gains. In addition, particularly severe label\nnoise can be combated by using a set of trusted data with clean labels. We\nutilize trusted data by proposing a loss correction technique that utilizes\ntrusted examples in a data-efficient manner to mitigate the effects of label\nnoise on deep neural network classifiers. Across vision and natural language\nprocessing tasks, we experiment with various label noises at several strengths,\nand show that our method significantly outperforms existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 19:48:50 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 19:07:19 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 17:41:23 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2019 19:55:36 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Hendrycks", "Dan", ""], ["Mazeika", "Mantas", ""], ["Wilson", "Duncan", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1802.05312", "submitter": "Karl Ridgeway", "authors": "Karl Ridgeway, Michael C. Mozer", "title": "Learning Deep Disentangled Embeddings with the F-Statistic Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-embedding methods aim to discover representations of a domain that make\nexplicit the domain's class structure and thereby support few-shot learning.\nDisentangling methods aim to make explicit compositional or factorial\nstructure. We combine these two active but independent lines of research and\npropose a new paradigm suitable for both goals. We propose and evaluate a novel\nloss function based on the $F$ statistic, which describes the separation of two\nor more distributions. By ensuring that distinct classes are well separated on\na subset of embedding dimensions, we obtain embeddings that are useful for\nfew-shot learning. By not requiring separation on all dimensions, we encourage\nthe discovery of disentangled representations. Our embedding method matches or\nbeats state-of-the-art, as evaluated by performance on recall@$k$ and few-shot\nlearning tasks. Our method also obtains performance superior to a variety of\nalternatives on disentangling, as evaluated by two key properties of a\ndisentangled representation: modularity and explicitness. The goal of our work\nis to obtain more interpretable, manipulable, and generalizable deep\nrepresentations of concepts and categories.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 20:28:38 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 00:25:08 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Ridgeway", "Karl", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1802.05313", "submitter": "Huazhe Xu", "authors": "Yang Gao, Huazhe Xu, Ji Lin, Fisher Yu, Sergey Levine, Trevor Darrell", "title": "Reinforcement Learning from Imperfect Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust real-world learning should benefit from both demonstrations and\ninteractions with the environment. Current approaches to learning from\ndemonstration and reward perform supervised learning on expert demonstration\ndata and use reinforcement learning to further improve performance based on the\nreward received from the environment. These tasks have divergent losses which\nare difficult to jointly optimize and such methods can be very sensitive to\nnoisy demonstrations. We propose a unified reinforcement learning algorithm,\nNormalized Actor-Critic (NAC), that effectively normalizes the Q-function,\nreducing the Q-values of actions unseen in the demonstration data. NAC learns\nan initial policy network from demonstrations and refines the policy in the\nenvironment, surpassing the demonstrator's performance. Crucially, both\nlearning from demonstration and interactive refinement use the same objective,\nunlike prior approaches that combine distinct supervised and reinforcement\nlosses. This makes NAC robust to suboptimal demonstration data since the method\nis not forced to mimic all of the examples in the dataset. We show that our\nunified reinforcement learning algorithm can learn robustly and outperform\nexisting baselines when evaluated on several realistic driving games.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 20:37:38 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 04:39:22 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Gao", "Yang", ""], ["Xu", "Huazhe", ""], ["Lin", "Ji", ""], ["Yu", "Fisher", ""], ["Levine", "Sergey", ""], ["Darrell", "Trevor", ""]]}, {"id": "1802.05315", "submitter": "Dong Yin", "authors": "Andr\\'es Mu\\~noz Medina, Sergei Vassilvitskii, Dong Yin", "title": "Online Learning for Non-Stationary A/B Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rollout of new versions of a feature in modern applications is a manual\nmulti-stage process, as the feature is released to ever larger groups of users,\nwhile its performance is carefully monitored. This kind of A/B testing is\nubiquitous, but suboptimal, as the monitoring requires heavy human\nintervention, is not guaranteed to capture consistent, but short-term\nfluctuations in performance, and is inefficient, as better versions take a long\ntime to reach the full population.\n  In this work we formulate this question as that of expert learning, and give\na new algorithm Follow-The-Best-Interval, FTBI, that works in dynamic,\nnon-stationary environments. Our approach is practical, simple, and efficient,\nand has rigorous guarantees on its performance. Finally, we perform a thorough\nevaluation on synthetic and real world datasets and show that our approach\noutperforms current state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 20:42:51 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 06:42:39 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Medina", "Andr\u00e9s Mu\u00f1oz", ""], ["Vassilvitskii", "Sergei", ""], ["Yin", "Dong", ""]]}, {"id": "1802.05319", "submitter": "Suvodeep Majumder", "authors": "Suvodeep Majumder, Nikhila Balaji, Katie Brey, Wei Fu, Tim Menzies", "title": "500+ Times Faster Than Deep Learning (A Case Study Exploring Faster\n  Methods for Text Mining StackOverflow)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are useful for high-dimensional data and are becoming\nwidely used in many areas of software engineering. Deep learners utilizes\nextensive computational power and can take a long time to train-- making it\ndifficult to widely validate and repeat and improve their results. Further,\nthey are not the best solution in all domains. For example, recent results show\nthat for finding related Stack Overflow posts, a tuned SVM performs similarly\nto a deep learner, but is significantly faster to train. This paper extends\nthat recent result by clustering the dataset, then tuning very learners within\neach cluster. This approach is over 500 times faster than deep learning (and\nover 900 times faster if we use all the cores on a standard laptop computer).\nSignificantly, this faster approach generates classifiers nearly as good\n(within 2\\% F1 Score) as the much slower deep learning method. Hence we\nrecommend this faster methods since it is much easier to reproduce and utilizes\nfar fewer CPU resources. More generally, we recommend that before researchers\nrelease research results, that they compare their supposedly sophisticated\nmethods against simpler alternatives (e.g applying simpler learners to build\nlocal models).\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 20:57:48 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Majumder", "Suvodeep", ""], ["Balaji", "Nikhila", ""], ["Brey", "Katie", ""], ["Fu", "Wei", ""], ["Menzies", "Tim", ""]]}, {"id": "1802.05335", "submitter": "Mike Wu", "authors": "Mike Wu and Noah Goodman", "title": "Multimodal Generative Models for Scalable Weakly-Supervised Learning", "comments": "To appear at NIPS 2018; 9 pages with supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple modalities often co-occur when describing natural phenomena.\nLearning a joint representation of these modalities should yield deeper and\nmore useful representations. Previous generative approaches to multi-modal\ninput either do not learn a joint distribution or require additional\ncomputation to handle missing data. Here, we introduce a multimodal variational\nautoencoder (MVAE) that uses a product-of-experts inference network and a\nsub-sampled training paradigm to solve the multi-modal inference problem.\nNotably, our model shares parameters to efficiently learn under any combination\nof missing modalities. We apply the MVAE on four datasets and match\nstate-of-the-art performance using many fewer parameters. In addition, we show\nthat the MVAE is directly applicable to weakly-supervised learning, and is\nrobust to incomplete supervision. We then consider two case studies, one of\nlearning image transformations---edge detection, colorization,\nsegmentation---as a set of modalities, followed by one of machine translation\nbetween two languages. We find appealing results across this range of tasks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 22:08:05 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 18:14:29 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 16:39:10 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Wu", "Mike", ""], ["Goodman", "Noah", ""]]}, {"id": "1802.05351", "submitter": "Binghui Wang", "authors": "Binghui Wang, Neil Zhenqiang Gong", "title": "Stealing Hyperparameters in Machine Learning", "comments": "In the 39th IEEE Symposium on Security and Privacy (IEEE S & P), May\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameters are critical in machine learning, as different\nhyperparameters often result in models with significantly different\nperformance. Hyperparameters may be deemed confidential because of their\ncommercial value and the confidentiality of the proprietary algorithms that the\nlearner uses to learn them. In this work, we propose attacks on stealing the\nhyperparameters that are learned by a learner. We call our attacks\nhyperparameter stealing attacks. Our attacks are applicable to a variety of\npopular machine learning algorithms such as ridge regression, logistic\nregression, support vector machine, and neural network. We evaluate the\neffectiveness of our attacks both theoretically and empirically. For instance,\nwe evaluate our attacks on Amazon Machine Learning. Our results demonstrate\nthat our attacks can accurately steal hyperparameters. We also study\ncountermeasures. Our results highlight the need for new defenses against our\nhyperparameter stealing attacks for certain machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 22:58:31 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 17:21:27 GMT"}, {"version": "v3", "created": "Sat, 7 Sep 2019 01:48:11 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Wang", "Binghui", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1802.05355", "submitter": "Leonardo Rey Vega", "authors": "Mat\\'ias Vera, Pablo Piantanida, Leonardo Rey Vega", "title": "The Role of Information Complexity and Randomization in Representation\n  Learning", "comments": "35 pages, 3 figures. Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A grand challenge in representation learning is to learn the different\nexplanatory factors of variation behind the high dimen- sional data. Encoder\nmodels are often determined to optimize performance on training data when the\nreal objective is to generalize well to unseen data. Although there is enough\nnumerical evidence suggesting that noise injection (during training) at the\nrepresentation level might improve the generalization ability of encoders, an\ninformation-theoretic understanding of this principle remains elusive. This\npaper presents a sample-dependent bound on the generalization gap of the\ncross-entropy loss that scales with the information complexity (IC) of the\nrepresentations, meaning the mutual information between inputs and their\nrepresentations. The IC is empirically investigated for standard multi-layer\nneural networks with SGD on MNIST and CIFAR-10 datasets; the behaviour of the\ngap and the IC appear to be in direct correlation, suggesting that SGD selects\nencoders to implicitly minimize the IC. We specialize the IC to study the role\nof Dropout on the generalization capacity of deep encoders which is shown to be\ndirectly related to the encoder capacity, being a measure of the\ndistinguishability among samples from their representations. Our results\nsupport some recent regularization methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 23:31:11 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Vera", "Mat\u00edas", ""], ["Piantanida", "Pablo", ""], ["Vega", "Leonardo Rey", ""]]}, {"id": "1802.05374", "submitter": "Hao-Jun Shi", "authors": "Raghu Bollapragada, Dheevatsa Mudigere, Jorge Nocedal, Hao-Jun Michael\n  Shi, Ping Tak Peter Tang", "title": "A Progressive Batching L-BFGS Method for Machine Learning", "comments": "ICML 2018. 25 pages, 17 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard L-BFGS method relies on gradient approximations that are not\ndominated by noise, so that search directions are descent directions, the line\nsearch is reliable, and quasi-Newton updating yields useful quadratic models of\nthe objective function. All of this appears to call for a full batch approach,\nbut since small batch sizes give rise to faster algorithms with better\ngeneralization properties, L-BFGS is currently not considered an algorithm of\nchoice for large-scale machine learning applications. One need not, however,\nchoose between the two extremes represented by the full batch or highly\nstochastic regimes, and may instead follow a progressive batching approach in\nwhich the sample size increases during the course of the optimization. In this\npaper, we present a new version of the L-BFGS algorithm that combines three\nbasic components - progressive batching, a stochastic line search, and stable\nquasi-Newton updating - and that performs well on training logistic regression\nand deep neural networks. We provide supporting convergence theory for the\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 01:02:36 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 04:38:48 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Bollapragada", "Raghu", ""], ["Mudigere", "Dheevatsa", ""], ["Nocedal", "Jorge", ""], ["Shi", "Hao-Jun Michael", ""], ["Tang", "Ping Tak Peter", ""]]}, {"id": "1802.05380", "submitter": "Sheng-Jun Huang", "authors": "Sheng-Jun Huang, Miao Xu, Ming-Kun Xie, Masashi Sugiyama, Gang Niu and\n  Songcan Chen", "title": "Active Feature Acquisition with Supervised Matrix Completion", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature missing is a serious problem in many applications, which may lead to\nlow quality of training data and further significantly degrade the learning\nperformance. While feature acquisition usually involves special devices or\ncomplex process, it is expensive to acquire all feature values for the whole\ndataset. On the other hand, features may be correlated with each other, and\nsome values may be recovered from the others. It is thus important to decide\nwhich features are most informative for recovering the other features as well\nas improving the learning performance. In this paper, we try to train an\neffective classification model with least acquisition cost by jointly\nperforming active feature querying and supervised matrix completion. When\ncompleting the feature matrix, a novel target function is proposed to\nsimultaneously minimize the reconstruction error on observed entries and the\nsupervised loss on training data. When querying the feature value, the most\nuncertain entry is actively selected based on the variance of previous\niterations. In addition, a bi-objective optimization method is presented for\ncost-aware active selection when features bear different acquisition costs. The\neffectiveness of the proposed approach is well validated by both theoretical\nanalysis and experimental study.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 01:46:59 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 02:02:01 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Huang", "Sheng-Jun", ""], ["Xu", "Miao", ""], ["Xie", "Ming-Kun", ""], ["Sugiyama", "Masashi", ""], ["Niu", "Gang", ""], ["Chen", "Songcan", ""]]}, {"id": "1802.05385", "submitter": "Congzheng Song", "authors": "Congzheng Song, Vitaly Shmatikov", "title": "Fooling OCR Systems with Adversarial Text Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that state-of-the-art optical character recognition (OCR)\nbased on deep learning is vulnerable to adversarial images. Minor modifications\nto images of printed text, which do not change the meaning of the text to a\nhuman reader, cause the OCR system to \"recognize\" a different text where\ncertain words chosen by the adversary are replaced by their semantic opposites.\nThis completely changes the meaning of the output produced by the OCR system\nand by the NLP applications that use OCR for preprocessing their inputs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 02:08:19 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Song", "Congzheng", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "1802.05386", "submitter": "Fenglei Fan", "authors": "Fenglei Fan, Ziyu Su, Yueyang Teng, Ge Wang", "title": "Shamap: Shape-based Manifold Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For manifold learning, it is assumed that high-dimensional sample/data points\nare embedded on a low-dimensional manifold. Usually, distances among samples\nare computed to capture an underlying data structure. Here we propose a metric\naccording to angular changes along a geodesic line, thereby reflecting the\nunderlying shape-oriented information or a topological similarity between high-\nand low-dimensional representations of a data cloud. Our results demonstrate\nthe feasibility and merits of the proposed dimensionality reduction scheme.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 02:09:23 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 20:51:56 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Fan", "Fenglei", ""], ["Su", "Ziyu", ""], ["Teng", "Yueyang", ""], ["Wang", "Ge", ""]]}, {"id": "1802.05392", "submitter": "Jun Lu", "authors": "Jun Lu, Meng Li, David Dunson", "title": "Reducing over-clustering via the powered Chinese restaurant process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dirichlet process mixture (DPM) models tend to produce many small clusters\nregardless of whether they are needed to accurately characterize the data -\nthis is particularly true for large data sets. However, interpretability,\nparsimony, data storage and communication costs all are hampered by having\noverly many clusters. We propose a powered Chinese restaurant process to limit\nthis kind of problem and penalize over clustering. The method is illustrated\nusing some simulation examples and data with large and small sample size\nincluding MNIST and the Old Faithful Geyser data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 02:53:30 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Lu", "Jun", ""], ["Li", "Meng", ""], ["Dunson", "David", ""]]}, {"id": "1802.05394", "submitter": "Sheng-Jun Huang", "authors": "Sheng-Jun Huang and Jia-Wei Zhao and Zhao-Yang Liu", "title": "Cost-Effective Training of Deep CNNs with Active Model Adaptation", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have achieved great success in various\napplications. However, training an effective DNN model for a specific task is\nrather challenging because it requires a prior knowledge or experience to\ndesign the network architecture, repeated trial-and-error process to tune the\nparameters, and a large set of labeled data to train the model. In this paper,\nwe propose to overcome these challenges by actively adapting a pre-trained\nmodel to a new task with less labeled examples. Specifically, the pre-trained\nmodel is iteratively fine tuned based on the most useful examples. The examples\nare actively selected based on a novel criterion, which jointly estimates the\npotential contribution of an instance on optimizing the feature representation\nas well as improving the classification model for the target task. On one hand,\nthe pre-trained model brings plentiful information from its original task,\navoiding redesign of the network architecture or training from scratch; and on\nthe other hand, the labeling cost can be significantly reduced by active label\nquerying. Experiments on multiple datasets and different pre-trained models\ndemonstrate that the proposed approach can achieve cost-effective training of\nDNNs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 03:06:06 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 08:52:57 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Huang", "Sheng-Jun", ""], ["Zhao", "Jia-Wei", ""], ["Liu", "Zhao-Yang", ""]]}, {"id": "1802.05399", "submitter": "Thodoris Lykouris", "authors": "Thodoris Lykouris, Sergei Vassilvitskii", "title": "Competitive caching with machine learned advice", "comments": "Preliminary versions appeared in ICML 18 and SysML 18. The current\n  version improves the presentation of the suggested framework (Section 2.2),\n  provides a more clear discussion on how it can be more broadly applied, and\n  fixes some more minor presentation issues in other sections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional online algorithms encapsulate decision making under uncertainty,\nand give ways to hedge against all possible future events, while guaranteeing a\nnearly optimal solution as compared to an offline optimum. On the other hand,\nmachine learning algorithms are in the business of extrapolating patterns found\nin the data to predict the future, and usually come with strong guarantees on\nthe expected generalization error.\n  In this work we develop a framework for augmenting online algorithms with a\nmachine learned oracle to achieve competitive ratios that provably improve upon\nunconditional worst case lower bounds when the oracle has low error. Our\napproach treats the oracle as a complete black box, and is not dependent on its\ninner workings, or the exact distribution of its errors.\n  We apply this framework to the traditional caching problem -- creating an\neviction strategy for a cache of size $k$. We demonstrate that naively\nfollowing the oracle's recommendations may lead to very poor performance, even\nwhen the average error is quite low. Instead we show how to modify the Marker\nalgorithm to take into account the oracle's predictions, and prove that this\ncombined approach achieves a competitive ratio that both (i) decreases as the\noracle's error decreases, and (ii) is always capped by $O(\\log k)$, which can\nbe achieved without any oracle input. We complement our results with an\nempirical evaluation of our algorithm on real world datasets, and show that it\nperforms well empirically even using simple off-the-shelf predictions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 04:30:04 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 21:42:13 GMT"}, {"version": "v3", "created": "Mon, 12 Aug 2019 15:50:02 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 14:36:05 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Lykouris", "Thodoris", ""], ["Vassilvitskii", "Sergei", ""]]}, {"id": "1802.05405", "submitter": "Charles Delahunt", "authors": "Charles B. Delahunt, J. Nathan Kutz", "title": "Putting a bug in ML: The moth olfactory network learns to read MNIST", "comments": "23 pages, 7 figures. Version 3: 25 January 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to (i) characterize the learning architectures exploited in\nbiological neural networks for training on very few samples, and (ii) port\nthese algorithmic structures to a machine learning context. The Moth Olfactory\nNetwork is among the simplest biological neural systems that can learn, and its\narchitecture includes key structural elements and mechanisms widespread in\nbiological neural nets, such as cascaded networks, competitive inhibition, high\nintrinsic noise, sparsity, reward mechanisms, and Hebbian plasticity. These\nstructural biological elements, in combination, enable rapid learning.\n  MothNet is a computational model of the Moth Olfactory Network, closely\naligned with the moth's known biophysics and with in vivo electrode data\ncollected from moths learning new odors. We assign this model the task of\nlearning to read the MNIST digits. We show that MothNet successfully learns to\nread given very few training samples (1 to 10 samples per class). In this\nfew-samples regime, it outperforms standard machine learning methods such as\nnearest-neighbors, support-vector machines, and neural networks (NNs), and\nmatches specialized one-shot transfer-learning methods but without the need for\npre-training. The MothNet architecture illustrates how algorithmic structures\nderived from biological brains can be used to build alternative NNs that may\navoid some of the learning rate limitations of current engineered NNs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 04:58:45 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 01:23:22 GMT"}, {"version": "v3", "created": "Sat, 26 Jan 2019 22:40:41 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Delahunt", "Charles B.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1802.05408", "submitter": "Yao-Hung Tsai", "authors": "Denny Wu, Yixiu Zhao, Yao-Hung Hubert Tsai, Makoto Yamada, Ruslan\n  Salakhutdinov", "title": "\"Dependency Bottleneck\" in Auto-encoding Architectures: an Empirical\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works investigated the generalization properties in deep neural\nnetworks (DNNs) by studying the Information Bottleneck in DNNs. However, the\nmea- surement of the mutual information (MI) is often inaccurate due to the\ndensity estimation. To address this issue, we propose to measure the dependency\ninstead of MI between layers in DNNs. Specifically, we propose to use\nHilbert-Schmidt Independence Criterion (HSIC) as the dependency measure, which\ncan measure the dependence of two random variables without estimating\nprobability densities. Moreover, HSIC is a special case of the Squared-loss\nMutual Information (SMI). In the experiment, we empirically evaluate the\ngeneralization property using HSIC in both the reconstruction and prediction\nauto-encoding (AE) architectures.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 05:22:19 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Wu", "Denny", ""], ["Zhao", "Yixiu", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Yamada", "Makoto", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1802.05411", "submitter": "Yao-Hung Tsai", "authors": "Yao-Hung Hubert Tsai, Makoto Yamada, Denny Wu, Ruslan Salakhutdinov,\n  Ichiro Takeuchi, Kenji Fukumizu", "title": "Selecting the Best in GANs Family: a Post Selection Inference Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Which Generative Adversarial Networks (GANs) generates the most plausible\nimages?\" has been a frequently asked question among researchers. To address\nthis problem, we first propose an \\emph{incomplete} U-statistics estimate of\nmaximum mean discrepancy $\\mathrm{MMD}_{inc}$ to measure the distribution\ndiscrepancy between generated and real images. $\\mathrm{MMD}_{inc}$ enjoys the\nadvantages of asymptotic normality, computation efficiency, and model\nagnosticity. We then propose a GANs analysis framework to select and test the\n\"best\" member in GANs family using the Post Selection Inference (PSI) with\n$\\mathrm{MMD}_{inc}$. In the experiments, we adopt the proposed framework on 7\nGANs variants and compare their $\\mathrm{MMD}_{inc}$ scores.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 05:27:54 GMT"}, {"version": "v2", "created": "Sat, 23 Jun 2018 21:03:59 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Yamada", "Makoto", ""], ["Wu", "Denny", ""], ["Salakhutdinov", "Ruslan", ""], ["Takeuchi", "Ichiro", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "1802.05415", "submitter": "Sumeet Sohan Singh", "authors": "Sumeet S. Singh", "title": "Teaching Machines to Code: Neural Markup Generation with Visual\n  Attention", "comments": "For datasets, visualizations and ancillary material see:\n  https://untrix.github.io/i2l . For source code go to:\n  https://github.com/untrix/im2latex", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural transducer model with visual attention that learns to\ngenerate LaTeX markup of a real-world math formula given its image. Applying\nsequence modeling and transduction techniques that have been very successful\nacross modalities such as natural language, image, handwriting, speech and\naudio; we construct an image-to-markup model that learns to produce\nsyntactically and semantically correct LaTeX markup code over 150 words long\nand achieves a BLEU score of 89%; improving upon the previous state-of-art for\nthe Im2Latex problem. We also demonstrate with heat-map visualization how\nattention helps in interpreting the model and can pinpoint (detect and\nlocalize) symbols on the image accurately despite having been trained without\nany bounding box data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 06:17:51 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 21:36:10 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Singh", "Sumeet S.", ""]]}, {"id": "1802.05431", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji, Nicolas Flammarion, Yi-An Ma, Peter L. Bartlett\n  and Michael I. Jordan", "title": "On the Theory of Variance Reduction for Stochastic Gradient Monte Carlo", "comments": "37 pages; 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide convergence guarantees in Wasserstein distance for a variety of\nvariance-reduction methods: SAGA Langevin diffusion, SVRG Langevin diffusion\nand control-variate underdamped Langevin diffusion. We analyze these methods\nunder a uniform set of assumptions on the log-posterior distribution, assuming\nit to be smooth, strongly convex and Hessian Lipschitz. This is achieved by a\nnew proof technique combining ideas from finite-sum optimization and the\nanalysis of sampling methods. Our sharp theoretical bounds allow us to identify\nregimes of interest where each method performs better than the others. Our\ntheory is verified with experiments on real-world and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 08:09:00 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Flammarion", "Nicolas", ""], ["Ma", "Yi-An", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1802.05438", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Rui Luo, Minne Li, Ming Zhou, Weinan Zhang, Jun Wang", "title": "Mean Field Multi-Agent Reinforcement Learning", "comments": "ICML 2018 (Full paper + Long talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing multi-agent reinforcement learning methods are limited typically to\na small number of agents. When the agent number increases largely, the learning\nbecomes intractable due to the curse of the dimensionality and the exponential\ngrowth of agent interactions. In this paper, we present \\emph{Mean Field\nReinforcement Learning} where the interactions within the population of agents\nare approximated by those between a single agent and the average effect from\nthe overall population or neighboring agents; the interplay between the two\nentities is mutually reinforced: the learning of the individual agent's optimal\npolicy depends on the dynamics of the population, while the dynamics of the\npopulation change according to the collective patterns of the individual\npolicies. We develop practical mean field Q-learning and mean field\nActor-Critic algorithms and analyze the convergence of the solution to Nash\nequilibrium. Experiments on Gaussian squeeze, Ising model, and battle games\njustify the learning effectiveness of our mean field approaches. In addition,\nwe report the first result to solve the Ising model via model-free\nreinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 09:07:57 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 16:26:20 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 07:19:04 GMT"}, {"version": "v4", "created": "Thu, 19 Jul 2018 22:15:36 GMT"}, {"version": "v5", "created": "Tue, 15 Dec 2020 11:26:04 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Yang", "Yaodong", ""], ["Luo", "Rui", ""], ["Li", "Minne", ""], ["Zhou", "Ming", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""]]}, {"id": "1802.05451", "submitter": "Roei Herzig", "authors": "Roei Herzig, Moshiko Raboh, Gal Chechik, Jonathan Berant, Amir\n  Globerson", "title": "Mapping Images to Scene Graphs with Permutation-Invariant Structured\n  Prediction", "comments": "Paper is accepted for NIPS 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine understanding of complex images is a key goal of artificial\nintelligence. One challenge underlying this task is that visual scenes contain\nmultiple inter-related objects, and that global context plays an important role\nin interpreting the scene. A natural modeling framework for capturing such\neffects is structured prediction, which optimizes over complex labels, while\nmodeling within-label interactions. However, it is unclear what principles\nshould guide the design of a structured prediction model that utilizes the\npower of deep learning components. Here we propose a design principle for such\narchitectures that follows from a natural requirement of permutation\ninvariance. We prove a necessary and sufficient characterization for\narchitectures that follow this invariance, and discuss its implication on model\ndesign. Finally, we show that the resulting model achieves new state of the art\nresults on the Visual Genome scene graph labeling benchmark, outperforming all\nrecent approaches.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 09:50:15 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 18:07:49 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 13:26:04 GMT"}, {"version": "v4", "created": "Thu, 1 Nov 2018 21:48:19 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Herzig", "Roei", ""], ["Raboh", "Moshiko", ""], ["Chechik", "Gal", ""], ["Berant", "Jonathan", ""], ["Globerson", "Amir", ""]]}, {"id": "1802.05472", "submitter": "Yan Zhu", "authors": "Yan Zhu, Abdullah Mueen, Eamonn Keogh", "title": "Admissible Time Series Motif Discovery with Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of time series motifs has emerged as one of the most useful\nprimitives in time series data mining. Researchers have shown its utility for\nexploratory data mining, summarization, visualization, segmentation,\nclassification, clustering, and rule discovery. Although there has been more\nthan a decade of extensive research, there is still no technique to allow the\ndiscovery of time series motifs in the presence of missing data, despite the\nwell-documented ubiquity of missing data in scientific, industrial, and medical\ndatasets. In this work, we introduce a technique for motif discovery in the\npresence of missing data. We formally prove that our method is admissible,\nproducing no false negatives. We also show that our method can piggy-back off\nthe fastest known motif discovery method with a small constant factor\ntime/space overhead. We will demonstrate our approach on diverse datasets with\nvarying amounts of missing data\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 10:45:46 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Zhu", "Yan", ""], ["Mueen", "Abdullah", ""], ["Keogh", "Eamonn", ""]]}, {"id": "1802.05563", "submitter": "Evgeniy Faerman", "authors": "Evgeniy Faerman, Felix Borutta, Julian Busch, Matthias Schubert", "title": "Semi-Supervised Learning on Graphs Based on Local Label Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most approaches that tackle the problem of node classification consider nodes\nto be similar, if they have shared neighbors or are close to each other in the\ngraph. Recent methods for attributed graphs additionally take attributes of\nneighboring nodes into account. We argue that the class labels of the neighbors\nbear important information and considering them helps to improve classification\nquality. Two nodes which are similar based on class labels in their\nneighborhood do not need to be close-by in the graph and may even belong to\ndifferent connected components. In this work, we propose a novel approach for\nthe semi-supervised node classification. Precisely, we propose a new node\nembedding which is based on the class labels in the local neighborhood of a\nnode. We show that this is a different setting from attribute-based embeddings\nand thus, we propose a new method to learn label-based node embeddings which\ncan mirror a variety of relations between the class labels of neighboring\nnodes. Our experimental evaluation demonstrates that our new methods can\nsignificantly improve the prediction quality on real world data sets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 14:29:10 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 12:33:54 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Faerman", "Evgeniy", ""], ["Borutta", "Felix", ""], ["Busch", "Julian", ""], ["Schubert", "Matthias", ""]]}, {"id": "1802.05581", "submitter": "Dan Garber", "authors": "Dan Garber, Shoham Sabach, Atara Kaplan", "title": "Improved Complexities of Conditional Gradient-Type Methods with\n  Applications to Robust Matrix Recovery Problems", "comments": "Accepted to Mathematical Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by robust matrix recovery problems such as Robust Principal\nComponent Analysis, we consider a general optimization problem of minimizing a\nsmooth and strongly convex loss function applied to the sum of two blocks of\nvariables, where each block of variables is constrained or regularized\nindividually. We study a Conditional Gradient-Type method which is able to\nleverage the special structure of the problem to obtain faster convergence\nrates than those attainable via standard methods, under a variety of\nassumptions. In particular, our method is appealing for matrix problems in\nwhich one of the blocks corresponds to a low-rank matrix since it avoids\nprohibitive full-rank singular value decompositions required by most standard\nmethods. While our initial motivation comes from problems which originated in\nstatistics, our analysis does not impose any statistical assumptions on the\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 14:48:23 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 13:37:22 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 19:27:35 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Garber", "Dan", ""], ["Sabach", "Shoham", ""], ["Kaplan", "Atara", ""]]}, {"id": "1802.05584", "submitter": "Il Yong Chun", "authors": "Il Yong Chun and Jeffrey A. Fessler", "title": "Convolutional Analysis Operator Learning: Acceleration and Convergence", "comments": "22 pages, 11 figures, fixed incorrect math theorem numbers in fig. 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional operator learning is gaining attention in many signal\nprocessing and computer vision applications. Learning kernels has mostly relied\non so-called patch-domain approaches that extract and store many overlapping\npatches across training signals. Due to memory demands, patch-domain methods\nhave limitations when learning kernels from large datasets -- particularly with\nmulti-layered structures, e.g., convolutional neural networks -- or when\napplying the learned kernels to high-dimensional signal recovery problems. The\nso-called convolution approach does not store many overlapping patches, and\nthus overcomes the memory problems particularly with careful algorithmic\ndesigns; it has been studied within the \"synthesis\" signal model, e.g.,\nconvolutional dictionary learning. This paper proposes a new convolutional\nanalysis operator learning (CAOL) framework that learns an analysis sparsifying\nregularizer with the convolution perspective, and develops a new convergent\nBlock Proximal Extrapolated Gradient method using a Majorizer (BPEG-M) to solve\nthe corresponding block multi-nonconvex problems. To learn diverse filters\nwithin the CAOL framework, this paper introduces an orthogonality constraint\nthat enforces a tight-frame filter condition, and a regularizer that promotes\ndiversity between filters. Numerical experiments show that, with sharp\nmajorizers, BPEG-M significantly accelerates the CAOL convergence rate compared\nto the state-of-the-art block proximal gradient (BPG) method. Numerical\nexperiments for sparse-view computational tomography show that a convolutional\nsparsifying regularizer learned via CAOL significantly improves reconstruction\nquality compared to a conventional edge-preserving regularizer. Using more and\nwider kernels in a learned regularizer better preserves edges in reconstructed\nimages.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 14:51:38 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 19:11:31 GMT"}, {"version": "v3", "created": "Wed, 27 Feb 2019 01:29:57 GMT"}, {"version": "v4", "created": "Tue, 9 Jul 2019 07:19:14 GMT"}, {"version": "v5", "created": "Fri, 9 Aug 2019 21:28:38 GMT"}, {"version": "v6", "created": "Thu, 22 Aug 2019 12:45:28 GMT"}, {"version": "v7", "created": "Wed, 11 Sep 2019 10:03:54 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Chun", "Il Yong", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1802.05630", "submitter": "Andrei Petrovskii", "authors": "Caroline Etienne, Guillaume Fidanza, Andrei Petrovskii, Laurence\n  Devillers and Benoit Schmauch", "title": "CNN+LSTM Architecture for Speech Emotion Recognition with Data\n  Augmentation", "comments": "5 pages, 3 figures", "journal-ref": "Workshop on Speech, Music and Mind 2018", "doi": "10.21437/SMM.2018-5", "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we design a neural network for recognizing emotions in speech,\nusing the IEMOCAP dataset. Following the latest advances in audio analysis, we\nuse an architecture involving both convolutional layers, for extracting\nhigh-level features from raw spectrograms, and recurrent ones for aggregating\nlong-term dependencies. We examine the techniques of data augmentation with\nvocal track length perturbation, layer-wise optimizer adjustment, batch\nnormalization of recurrent layers and obtain highly competitive results of\n64.5% for weighted accuracy and 61.7% for unweighted accuracy on four emotions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 16:05:02 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 18:05:16 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Etienne", "Caroline", ""], ["Fidanza", "Guillaume", ""], ["Petrovskii", "Andrei", ""], ["Devillers", "Laurence", ""], ["Schmauch", "Benoit", ""]]}, {"id": "1802.05637", "submitter": "Takeru Miyato", "authors": "Takeru Miyato, Masanori Koyama", "title": "cGANs with Projection Discriminator", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel, projection based way to incorporate the conditional\ninformation into the discriminator of GANs that respects the role of the\nconditional information in the underlining probabilistic model. This approach\nis in contrast with most frameworks of conditional GANs used in application\ntoday, which use the conditional information by concatenating the (embedded)\nconditional vector to the feature vectors. With this modification, we were able\nto significantly improve the quality of the class conditional image generation\non ILSVRC2012 (ImageNet) 1000-class image dataset from the current\nstate-of-the-art result, and we achieved this with a single pair of a\ndiscriminator and a generator. We were also able to extend the application to\nsuper-resolution and succeeded in producing highly discriminative\nsuper-resolution images. This new structure also enabled high quality category\ntransformation based on parametric functional transformation of conditional\nbatch normalization layers in the generator.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 16:19:21 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 00:02:46 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Miyato", "Takeru", ""], ["Koyama", "Masanori", ""]]}, {"id": "1802.05640", "submitter": "Yu Shi", "authors": "Yu Shi, Jian Li and Zhize Li", "title": "Gradient Boosting With Piece-Wise Linear Regression Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Boosted Decision Trees (GBDT) is a very successful ensemble learning\nalgorithm widely used across a variety of applications. Recently, several\nvariants of GBDT training algorithms and implementations have been designed and\nheavily optimized in some very popular open sourced toolkits including XGBoost,\nLightGBM and CatBoost. In this paper, we show that both the accuracy and\nefficiency of GBDT can be further enhanced by using more complex base learners.\nSpecifically, we extend gradient boosting to use piecewise linear regression\ntrees (PL Trees), instead of piecewise constant regression trees, as base\nlearners. We show that PL Trees can accelerate convergence of GBDT and improve\nthe accuracy. We also propose some optimization tricks to substantially reduce\nthe training time of PL Trees, with little sacrifice of accuracy. Moreover, we\npropose several implementation techniques to speedup our algorithm on modern\ncomputer architectures with powerful Single Instruction Multiple Data (SIMD)\nparallelism. The experimental results show that GBDT with PL Trees can provide\nvery competitive testing accuracy with comparable or less training time.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 16:26:35 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 12:34:04 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 18:17:03 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Shi", "Yu", ""], ["Li", "Jian", ""], ["Li", "Zhize", ""]]}, {"id": "1802.05642", "submitter": "David Balduzzi", "authors": "David Balduzzi, Sebastien Racaniere, James Martens, Jakob Foerster,\n  Karl Tuyls, Thore Graepel", "title": "The Mechanics of n-Player Differentiable Games", "comments": "ICML 2018, final version", "journal-ref": "PMLR volume 80, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cornerstone underpinning deep learning is the guarantee that gradient\ndescent on an objective converges to local minima. Unfortunately, this\nguarantee fails in settings, such as generative adversarial nets, where there\nare multiple interacting losses. The behavior of gradient-based methods in\ngames is not well understood -- and is becoming increasingly important as\nadversarial and multi-objective architectures proliferate. In this paper, we\ndevelop new techniques to understand and control the dynamics in general games.\nThe key result is to decompose the second-order dynamics into two components.\nThe first is related to potential games, which reduce to gradient descent on an\nimplicit function; the second relates to Hamiltonian games, a new class of\ngames that obey a conservation law, akin to conservation laws in classical\nmechanical systems. The decomposition motivates Symplectic Gradient Adjustment\n(SGA), a new algorithm for finding stable fixed points in general games. Basic\nexperiments show SGA is competitive with recently proposed algorithms for\nfinding stable fixed points in GANs -- whilst at the same time being applicable\nto -- and having guarantees in -- much more general games.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 16:32:48 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 13:26:15 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Balduzzi", "David", ""], ["Racaniere", "Sebastien", ""], ["Martens", "James", ""], ["Foerster", "Jakob", ""], ["Tuyls", "Karl", ""], ["Graepel", "Thore", ""]]}, {"id": "1802.05649", "submitter": "Zelda Mariet", "authors": "Zelda Mariet, Mike Gartrell, Suvrit Sra", "title": "Learning Determinantal Point Processes by Corrective Negative Sampling", "comments": "Will appear in AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Determinantal Point Processes (DPPs) have attracted significant interest from\nthe machine-learning community due to their ability to elegantly and tractably\nmodel the delicate balance between quality and diversity of sets. DPPs are\ncommonly learned from data using maximum likelihood estimation (MLE). While\nfitting observed sets well, MLE for DPPs may also assign high likelihoods to\nunobserved sets that are far from the true generative distribution of the data.\nTo address this issue, which reduces the quality of the learned model, we\nintroduce a novel optimization problem, Contrastive Estimation (CE), which\nencodes information about \"negative\" samples into the basic learning model. CE\nis grounded in the successful use of negative information in machine-vision and\nlanguage modeling. Depending on the chosen negative distribution (which may be\nstatic or evolve during optimization), CE assumes two different forms, which we\nanalyze theoretically and experimentally. We evaluate our new model on\nreal-world datasets; on a challenging dataset, CE learning delivers a\nconsiderable improvement in predictive performance over a DPP learned without\nusing contrastive information.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 16:41:47 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 22:37:32 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 15:39:45 GMT"}, {"version": "v4", "created": "Tue, 26 Feb 2019 15:26:36 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Mariet", "Zelda", ""], ["Gartrell", "Mike", ""], ["Sra", "Suvrit", ""]]}, {"id": "1802.05666", "submitter": "Jonathan Uesato", "authors": "Jonathan Uesato, Brendan O'Donoghue, Aaron van den Oord, Pushmeet\n  Kohli", "title": "Adversarial Risk and the Dangers of Evaluating Against Weak Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates recently proposed approaches for defending against\nadversarial examples and evaluating adversarial robustness. We motivate\n'adversarial risk' as an objective for achieving models robust to worst-case\ninputs. We then frame commonly used attacks and evaluation metrics as defining\na tractable surrogate objective to the true adversarial risk. This suggests\nthat models may optimize this surrogate rather than the true adversarial risk.\nWe formalize this notion as 'obscurity to an adversary,' and develop tools and\nheuristics for identifying obscured models and designing transparent models. We\ndemonstrate that this is a significant problem in practice by repurposing\ngradient-free optimization techniques into adversarial attacks, which we use to\ndecrease the accuracy of several recently proposed defenses to near zero. Our\nhope is that our formulations and results will help researchers to develop more\npowerful defenses.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 17:13:18 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 14:20:27 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Uesato", "Jonathan", ""], ["O'Donoghue", "Brendan", ""], ["Oord", "Aaron van den", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1802.05668", "submitter": "Antonio Polino", "authors": "Antonio Polino, Razvan Pascanu, Dan Alistarh", "title": "Model compression via distillation and quantization", "comments": "21 pages, published as a conference paper at ICLR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) continue to make significant advances, solving\ntasks from image classification to translation or reinforcement learning. One\naspect of the field receiving considerable attention is efficiently executing\ndeep models in resource-constrained environments, such as mobile or embedded\ndevices. This paper focuses on this problem, and proposes two new compression\nmethods, which jointly leverage weight quantization and distillation of larger\nteacher networks into smaller student networks. The first method we propose is\ncalled quantized distillation and leverages distillation during the training\nprocess, by incorporating distillation loss, expressed with respect to the\nteacher, into the training of a student network whose weights are quantized to\na limited set of levels. The second method, differentiable quantization,\noptimizes the location of quantization points through stochastic gradient\ndescent, to better fit the behavior of the teacher model. We validate both\nmethods through experiments on convolutional and recurrent architectures. We\nshow that quantized shallow students can reach similar accuracy levels to\nfull-precision teacher models, while providing order of magnitude compression,\nand inference speedup that is linear in the depth reduction. In sum, our\nresults enable DNNs for resource-constrained environments to leverage\narchitecture and accuracy advances developed on more powerful devices.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 17:18:49 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Polino", "Antonio", ""], ["Pascanu", "Razvan", ""], ["Alistarh", "Dan", ""]]}, {"id": "1802.05688", "submitter": "David Craft", "authors": "Timo M. Deist, Andrew Patti, Zhaoqi Wang, David Krane, Taylor\n  Sorenson, David Craft", "title": "Simulation assisted machine learning", "comments": "This manuscript has been accepted for publication in Bioinformatics\n  published by Oxford University Press:\n  https://doi.org/10.1093/bioinformatics/btz199 (open access). Timo M. Deist\n  and Andrew Patti contributed equally to this work", "journal-ref": null, "doi": "10.1093/bioinformatics/btz199", "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: In a predictive modeling setting, if sufficient details of the\nsystem behavior are known, one can build and use a simulation for making\npredictions. When sufficient system details are not known, one typically turns\nto machine learning, which builds a black-box model of the system using a large\ndataset of input sample features and outputs. We consider a setting which is\nbetween these two extremes: some details of the system mechanics are known but\nnot enough for creating simulations that can be used to make high quality\npredictions. In this context we propose using approximate simulations to build\na kernel for use in kernelized machine learning methods, such as support vector\nmachines. The results of multiple simulations (under various uncertainty\nscenarios) are used to compute similarity measures between every pair of\nsamples: sample pairs are given a high similarity score if they behave\nsimilarly under a wide range of simulation parameters. These similarity values,\nrather than the original high dimensional feature data, are used to build the\nkernel.\n  Results: We demonstrate and explore the simulation based kernel (SimKern)\nconcept using four synthetic complex systems--three biologically inspired\nmodels and one network flow optimization model. We show that, when the number\nof training samples is small compared to the number of features, the SimKern\napproach dominates over no-prior-knowledge methods. This approach should be\napplicable in all disciplines where predictive models are sought and\ninformative yet approximate simulations are available.\n  Availability: The Python SimKern software, the demonstration models (in\nMATLAB, R), and the datasets are available at\nhttps://github.com/davidcraft/SimKern.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 18:04:34 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 16:55:40 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 14:51:51 GMT"}, {"version": "v4", "created": "Mon, 12 Aug 2019 18:38:09 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Deist", "Timo M.", ""], ["Patti", "Andrew", ""], ["Wang", "Zhaoqi", ""], ["Krane", "David", ""], ["Sorenson", "Taylor", ""], ["Craft", "David", ""]]}, {"id": "1802.05690", "submitter": "Andrea Rocchetto", "authors": "Varun Kanade, Andrea Rocchetto, Simone Severini", "title": "Learning DNFs under product distributions via {\\mu}-biased quantum\n  Fourier sampling", "comments": "17 pages; v3 based on journal version; minor corrections and\n  clarifications", "journal-ref": "Quantum Information and Computation, Vol. 19, No. 15&16 (2019)\n  1261-1278", "doi": null, "report-no": null, "categories": "quant-ph cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that DNF formulae can be quantum PAC-learned in polynomial time under\nproduct distributions using a quantum example oracle. The best classical\nalgorithm (without access to membership queries) runs in superpolynomial time.\nOur result extends the work by Bshouty and Jackson (1998) that proved that DNF\nformulae are efficiently learnable under the uniform distribution using a\nquantum example oracle. Our proof is based on a new quantum algorithm that\nefficiently samples the coefficients of a {\\mu}-biased Fourier transform.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 18:06:14 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 09:21:54 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 21:04:42 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Kanade", "Varun", ""], ["Rocchetto", "Andrea", ""], ["Severini", "Simone", ""]]}, {"id": "1802.05693", "submitter": "Virag Shah", "authors": "Virag Shah, Jose Blanchet, Ramesh Johari", "title": "Bandit Learning with Positive Externalities", "comments": "31 pages, 1 table, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many platforms, user arrivals exhibit a self-reinforcing behavior: future\nuser arrivals are likely to have preferences similar to users who were\nsatisfied in the past. In other words, arrivals exhibit positive externalities.\nWe study multiarmed bandit (MAB) problems with positive externalities. We show\nthat the self-reinforcing preferences may lead standard benchmark algorithms\nsuch as UCB to exhibit linear regret. We develop a new algorithm, Balanced\nExploration (BE), which explores arms carefully to avoid suboptimal convergence\nof arrivals before sufficient evidence is gathered. We also introduce an\nadaptive variant of BE which successively eliminates suboptimal arms. We\nanalyze their asymptotic regret, and establish optimality by showing that no\nalgorithm can perform better.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 18:22:06 GMT"}, {"version": "v2", "created": "Sat, 21 Apr 2018 23:57:43 GMT"}, {"version": "v3", "created": "Sat, 2 Jun 2018 21:35:16 GMT"}, {"version": "v4", "created": "Fri, 26 Oct 2018 23:34:54 GMT"}, {"version": "v5", "created": "Wed, 6 Mar 2019 20:56:15 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Shah", "Virag", ""], ["Blanchet", "Jose", ""], ["Johari", "Ramesh", ""]]}, {"id": "1802.05694", "submitter": "Xilun Chen", "authors": "Xilun Chen, Claire Cardie", "title": "Multinomial Adversarial Networks for Multi-Domain Text Classification", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many text classification tasks are known to be highly domain-dependent.\nUnfortunately, the availability of training data can vary drastically across\ndomains. Worse still, for some domains there may not be any annotated data at\nall. In this work, we propose a multinomial adversarial network (MAN) to tackle\nthe text classification problem in this real-world multidomain setting (MDTC).\nWe provide theoretical justifications for the MAN framework, proving that\ndifferent instances of MANs are essentially minimizers of various f-divergence\nmetrics (Ali and Silvey, 1966) among multiple probability distributions. MANs\nare thus a theoretically sound generalization of traditional adversarial\nnetworks that discriminate over two distributions. More specifically, for the\nMDTC task, MAN learns features that are invariant across multiple domains by\nresorting to its ability to reduce the divergence among the feature\ndistributions of each domain. We present experimental results showing that MANs\nsignificantly outperform the prior art on the MDTC task. We also show that MANs\nachieve state-of-the-art performance for domains with no labeled data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 18:22:58 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Chen", "Xilun", ""], ["Cardie", "Claire", ""]]}, {"id": "1802.05695", "submitter": "James Mullenbach", "authors": "James Mullenbach, Sarah Wiegreffe, Jon Duke, Jimeng Sun, Jacob\n  Eisenstein", "title": "Explainable Prediction of Medical Codes from Clinical Text", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical notes are text documents that are created by clinicians for each\npatient encounter. They are typically accompanied by medical codes, which\ndescribe the diagnosis and treatment. Annotating these codes is labor intensive\nand error prone; furthermore, the connection between the codes and the text is\nnot annotated, obscuring the reasons and details behind specific diagnoses and\ntreatments. We present an attentional convolutional network that predicts\nmedical codes from clinical text. Our method aggregates information across the\ndocument using a convolutional neural network, and uses an attention mechanism\nto select the most relevant segments for each of the thousands of possible\ncodes. The method is accurate, achieving precision@8 of 0.71 and a Micro-F1 of\n0.54, which are both better than the prior state of the art. Furthermore,\nthrough an interpretability evaluation by a physician, we show that the\nattention mechanism identifies meaningful explanations for each code assignment\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 18:25:32 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 21:45:35 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Mullenbach", "James", ""], ["Wiegreffe", "Sarah", ""], ["Duke", "Jon", ""], ["Sun", "Jimeng", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1802.05733", "submitter": "Sergei Vassilvitskii", "authors": "Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, Sergei Vassilvitskii", "title": "Fair Clustering Through Fairlets", "comments": null, "journal-ref": "NIPS 2017: 5036-5044", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the question of fair clustering under the {\\em disparate impact}\ndoctrine, where each protected class must have approximately equal\nrepresentation in every cluster. We formulate the fair clustering problem under\nboth the $k$-center and the $k$-median objectives, and show that even with two\nprotected classes the problem is challenging, as the optimum solution can\nviolate common conventions---for instance a point may no longer be assigned to\nits nearest cluster center! En route we introduce the concept of fairlets,\nwhich are minimal sets that satisfy fair representation while approximately\npreserving the clustering objective. We show that any fair clustering problem\ncan be decomposed into first finding good fairlets, and then using existing\nmachinery for traditional clustering algorithms. While finding good fairlets\ncan be NP-hard, we proceed to obtain efficient approximation algorithms based\non minimum cost flow. We empirically quantify the value of fair clustering on\nreal-world datasets with sensitive attributes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 19:52:49 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Chierichetti", "Flavio", ""], ["Kumar", "Ravi", ""], ["Lattanzi", "Silvio", ""], ["Vassilvitskii", "Sergei", ""]]}, {"id": "1802.05747", "submitter": "Tianyun Zhang", "authors": "Tianyun Zhang, Shaokai Ye, Yipeng Zhang, Yanzhi Wang, Makan Fardad", "title": "Systematic Weight Pruning of DNNs using Alternating Direction Method of\n  Multipliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a systematic weight pruning framework of deep neural networks\n(DNNs) using the alternating direction method of multipliers (ADMM). We first\nformulate the weight pruning problem of DNNs as a constrained nonconvex\noptimization problem, and then adopt the ADMM framework for systematic weight\npruning. We show that ADMM is highly suitable for weight pruning due to the\ncomputational efficiency it offers. We achieve a much higher compression ratio\ncompared with prior work while maintaining the same test accuracy, together\nwith a faster convergence rate. Our models are released at\nhttps://github.com/KaiqiZhang/admm-pruning\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 20:22:42 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 02:53:53 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zhang", "Tianyun", ""], ["Ye", "Shaokai", ""], ["Zhang", "Yipeng", ""], ["Wang", "Yanzhi", ""], ["Fardad", "Makan", ""]]}, {"id": "1802.05756", "submitter": "C\\'edric B\\'eny", "authors": "C\\'edric B\\'eny", "title": "Inferring relevant features: from QFT to PCA", "comments": null, "journal-ref": "IJQI 16, 1840012 (2018)", "doi": "10.1142/S0219749918400129", "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many-body physics, renormalization techniques are used to extract aspects\nof a statistical or quantum state that are relevant at large scale, or for low\nenergy experiments. Recent works have proposed that these features can be\nformally identified as those perturbations of the states whose\ndistinguishability most resist coarse-graining. Here, we examine whether this\nsame strategy can be used to identify important features of an unlabeled\ndataset. This approach indeed results in a technique very similar to kernel PCA\n(principal component analysis), but with a kernel function that is\nautomatically adapted to the data, or \"learned\". We test this approach on\nhandwritten digits, and find that the most relevant features are significantly\nbetter for classification than those obtained from a simple gaussian kernel.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 06:24:04 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["B\u00e9ny", "C\u00e9dric", ""]]}, {"id": "1802.05757", "submitter": "Sebastian Claici", "authors": "Sebastian Claici and Edward Chien and Justin Solomon", "title": "Stochastic Wasserstein Barycenters", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a stochastic algorithm to compute the barycenter of a set of\nprobability distributions under the Wasserstein metric from optimal transport.\nUnlike previous approaches, our method extends to continuous input\ndistributions and allows the support of the barycenter to be adjusted in each\niteration. We tackle the problem without regularization, allowing us to recover\na sharp output whose support is contained within the support of the true\nbarycenter. We give examples where our algorithm recovers a more meaningful\nbarycenter than previous work. Our method is versatile and can be extended to\napplications such as generating super samples from a given distribution and\nrecovering blue noise approximations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 20:47:32 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 15:10:36 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 03:02:55 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Claici", "Sebastian", ""], ["Chien", "Edward", ""], ["Solomon", "Justin", ""]]}, {"id": "1802.05763", "submitter": "Fuxun Yu", "authors": "Fuxun Yu, Qide Dong, Xiang Chen", "title": "ASP:A Fast Adversarial Attack Example Generation Framework based on\n  Adversarial Saliency Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the excellent accuracy and feasibility, the Neural Networks have been\nwidely applied into the novel intelligent applications and systems. However,\nwith the appearance of the Adversarial Attack, the NN based system performance\nbecomes extremely vulnerable:the image classification results can be\narbitrarily misled by the adversarial examples, which are crafted images with\nhuman unperceivable pixel-level perturbation. As this raised a significant\nsystem security issue, we implemented a series of investigations on the\nadversarial attack in this work: We first identify an image's pixel\nvulnerability to the adversarial attack based on the adversarial saliency\nanalysis. By comparing the analyzed saliency map and the adversarial\nperturbation distribution, we proposed a new evaluation scheme to\ncomprehensively assess the adversarial attack precision and efficiency. Then,\nwith a novel adversarial saliency prediction method, a fast adversarial example\ngeneration framework, namely \"ASP\", is proposed with significant attack\nefficiency improvement and dramatic computation cost reduction. Compared to the\nprevious methods, experiments show that ASP has at most 12 times speed-up for\nadversarial example generation, 2 times lower perturbation rate, and high\nattack success rate of 87% on both MNIST and Cifar10. ASP can be also well\nutilized to support the data-hungry NN adversarial training. By reducing the\nattack success rate as much as 90%, ASP can quickly and effectively enhance the\ndefense capability of NN based system to the adversarial attacks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 21:07:05 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 01:08:50 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 22:32:05 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Yu", "Fuxun", ""], ["Dong", "Qide", ""], ["Chen", "Xiang", ""]]}, {"id": "1802.05779", "submitter": "Walter Vinci", "authors": "Amir Khoshaman, Walter Vinci, Brandon Denis, Evgeny Andriyash, Hossein\n  Sadeghi, Mohammad H. Amin", "title": "Quantum Variational Autoencoder", "comments": "v2: published version. 13 pages, 3 figures, 2 tables", "journal-ref": "Quantum Sci. Technol. 4 (2019) 014001", "doi": "10.1088/2058-9565/aada1f", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) are powerful generative models with the\nsalient ability to perform inference. Here, we introduce a quantum variational\nautoencoder (QVAE): a VAE whose latent generative process is implemented as a\nquantum Boltzmann machine (QBM). We show that our model can be trained\nend-to-end by maximizing a well-defined loss-function: a 'quantum' lower-bound\nto a variational approximation of the log-likelihood. We use quantum Monte\nCarlo (QMC) simulations to train and evaluate the performance of QVAEs. To\nachieve the best performance, we first create a VAE platform with discrete\nlatent space generated by a restricted Boltzmann machine (RBM). Our model\nachieves state-of-the-art performance on the MNIST dataset when compared\nagainst similar approaches that only involve discrete variables in the\ngenerative process. We consider QVAEs with a smaller number of latent units to\nbe able to perform QMC simulations, which are computationally expensive. We\nshow that QVAEs can be trained effectively in regimes where quantum effects are\nrelevant despite training via the quantum bound. Our findings open the way to\nthe use of quantum computers to train QVAEs to achieve competitive performance\nfor generative models. Placing a QBM in the latent space of a VAE leverages the\nfull potential of current and next-generation quantum computers as sampling\ndevices.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 22:13:01 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 18:20:12 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Khoshaman", "Amir", ""], ["Vinci", "Walter", ""], ["Denis", "Brandon", ""], ["Andriyash", "Evgeny", ""], ["Sadeghi", "Hossein", ""], ["Amin", "Mohammad H.", ""]]}, {"id": "1802.05792", "submitter": "Fady Medhat", "authors": "Fady Medhat, David Chesmore, John Robinson", "title": "Masked Conditional Neural Networks for Automatic Sound Events\n  Recognition", "comments": "Restricted Boltzmann Machine, RBM, Conditional RBM, CRBM, Deep Belief\n  Net, DBN, Conditional Neural Network, CLNN, Masked Conditional Neural\n  Network, MCLNN, Environmental Sound Recognition, ESR", "journal-ref": "IEEE International Conference on Data Science and Advanced\n  Analytics (DSAA) Year: 2017, Pages: 389 - 394", "doi": "10.1109/DSAA.2017.43", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network architectures designed for application domains other than\nsound, especially image recognition, may not optimally harness the\ntime-frequency representation when adapted to the sound recognition problem. In\nthis work, we explore the ConditionaL Neural Network (CLNN) and the Masked\nConditionaL Neural Network (MCLNN) for multi-dimensional temporal signal\nrecognition. The CLNN considers the inter-frame relationship, and the MCLNN\nenforces a systematic sparseness over the network's links to enable learning in\nfrequency bands rather than bins allowing the network to be frequency shift\ninvariant mimicking a filterbank. The mask also allows considering several\ncombinations of features concurrently, which is usually handcrafted through\nexhaustive manual search. We applied the MCLNN to the environmental sound\nrecognition problem using the ESC-10 and ESC-50 datasets. MCLNN achieved\ncompetitive performance, using 12% of the parameters and without augmentation,\ncompared to state-of-the-art Convolutional Neural Networks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 23:24:39 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 09:53:24 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Medhat", "Fady", ""], ["Chesmore", "David", ""], ["Robinson", "John", ""]]}, {"id": "1802.05799", "submitter": "Alexander Sergeev", "authors": "Alexander Sergeev and Mike Del Balso", "title": "Horovod: fast and easy distributed deep learning in TensorFlow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training modern deep learning models requires large amounts of computation,\noften provided by GPUs. Scaling computation from one GPU to many can enable\nmuch faster training and research progress but entails two complications.\nFirst, the training library must support inter-GPU communication. Depending on\nthe particular methods employed, this communication may entail anywhere from\nnegligible to significant overhead. Second, the user must modify his or her\ntraining code to take advantage of inter-GPU communication. Depending on the\ntraining library's API, the modification required may be either significant or\nminimal.\n  Existing methods for enabling multi-GPU training under the TensorFlow library\nentail non-negligible communication overhead and require users to heavily\nmodify their model-building code, leading many researchers to avoid the whole\nmess and stick with slower single-GPU training. In this paper we introduce\nHorovod, an open source library that improves on both obstructions to scaling:\nit employs efficient inter-GPU communication via ring reduction and requires\nonly a few lines of modification to user code, enabling faster, easier\ndistributed training in TensorFlow. Horovod is available under the Apache 2.0\nlicense at https://github.com/uber/horovod\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 23:36:51 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 21:41:57 GMT"}, {"version": "v3", "created": "Wed, 21 Feb 2018 04:30:30 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Sergeev", "Alexander", ""], ["Del Balso", "Mike", ""]]}, {"id": "1802.05803", "submitter": "David D. Fan", "authors": "Marcus Pereira, David D. Fan, Gabriel Nakajima An, Evangelos Theodorou", "title": "MPC-Inspired Neural Network Policies for Sequential Decision Making", "comments": "Fixed missing reference to section 4.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the use of MPC-inspired neural network policies\nfor sequential decision making. We introduce an extension to the DAgger\nalgorithm for training such policies and show how they have improved training\nperformance and generalization capabilities. We take advantage of this\nextension to show scalable and efficient training of complex planning policy\narchitectures in continuous state and action spaces. We provide an extensive\ncomparison of neural network policies by considering feed forward policies,\nrecurrent policies, and recurrent policies with planning structure inspired by\nthe Path Integral control framework. Our results suggest that MPC-type\nrecurrent policies have better robustness to disturbances and modeling error.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 23:44:55 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 14:00:21 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Pereira", "Marcus", ""], ["Fan", "David D.", ""], ["An", "Gabriel Nakajima", ""], ["Theodorou", "Evangelos", ""]]}, {"id": "1802.05811", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky and Robert Busa-Fekete", "title": "Distributed Stochastic Optimization via Adaptive SGD", "comments": "NIPS 2018, 21 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic convex optimization algorithms are the most popular way to train\nmachine learning models on large-scale data. Scaling up the training process of\nthese models is crucial, but the most popular algorithm, Stochastic Gradient\nDescent (SGD), is a serial method that is surprisingly hard to parallelize. In\nthis paper, we propose an efficient distributed stochastic optimization method\nby combining adaptivity with variance reduction techniques. Our analysis yields\na linear speedup in the number of machines, constant memory footprint, and only\na logarithmic number of communication rounds. Critically, our approach is a\nblack-box reduction that parallelizes any serial online learning algorithm,\nstreamlining prior analysis and allowing us to leverage the significant\nprogress that has been made in designing adaptive algorithms. In particular, we\nachieve optimal convergence rates without any prior knowledge of smoothness\nparameters, yielding a more robust algorithm that reduces the need for\nhyperparameter tuning. We implement our algorithm in the Spark distributed\nframework and exhibit dramatic performance gains on large-scale logistic\nregression problems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 00:47:00 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 21:11:01 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 01:25:57 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Cutkosky", "Ashok", ""], ["Busa-Fekete", "Robert", ""]]}, {"id": "1802.05814", "submitter": "Dawen Liang", "authors": "Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, Tony Jebara", "title": "Variational Autoencoders for Collaborative Filtering", "comments": "10 pages, 3 figures. WWW 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend variational autoencoders (VAEs) to collaborative filtering for\nimplicit feedback. This non-linear probabilistic model enables us to go beyond\nthe limited modeling capacity of linear factor models which still largely\ndominate collaborative filtering research.We introduce a generative model with\nmultinomial likelihood and use Bayesian inference for parameter estimation.\nDespite widespread use in language modeling and economics, the multinomial\nlikelihood receives less attention in the recommender systems literature. We\nintroduce a different regularization parameter for the learning objective,\nwhich proves to be crucial for achieving competitive performance. Remarkably,\nthere is an efficient way to tune the parameter using annealing. The resulting\nmodel and learning algorithm has information-theoretic connections to maximum\nentropy discrimination and the information bottleneck principle. Empirically,\nwe show that the proposed approach significantly outperforms several\nstate-of-the-art baselines, including two recently-proposed neural network\napproaches, on several real-world datasets. We also provide extended\nexperiments comparing the multinomial likelihood with other commonly used\nlikelihood functions in the latent factor collaborative filtering literature\nand show favorable results. Finally, we identify the pros and cons of employing\na principled Bayesian inference approach and characterize settings where it\nprovides the most significant improvements.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 01:41:20 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Liang", "Dawen", ""], ["Krishnan", "Rahul G.", ""], ["Hoffman", "Matthew D.", ""], ["Jebara", "Tony", ""]]}, {"id": "1802.05821", "submitter": "Yuejie Chi", "authors": "Kaiyi Ji, Jian Tan, Jinfeng Xu, Yuejie Chi", "title": "Learning Latent Features with Pairwise Penalties in Low-Rank Matrix\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank matrix completion has achieved great success in many real-world data\napplications. A matrix factorization model that learns latent features is\nusually employed and, to improve prediction performance, the similarities\nbetween latent variables can be exploited by pairwise learning using the graph\nregularized matrix factorization (GRMF) method. However, existing GRMF\napproaches often use the squared loss to measure the pairwise differences,\nwhich may be overly influenced by dissimilar pairs and lead to inferior\nprediction. To fully empower pairwise learning for matrix completion, we\npropose a general optimization framework that allows a rich class of\n(non-)convex pairwise penalty functions. A new and efficient algorithm is\ndeveloped to solve the proposed optimization problem, with a theoretical\nconvergence guarantee under mild assumptions. In an important situation where\nthe latent variables form a small number of subgroups, its statistical\nguarantee is also fully considered. In particular, we theoretically\ncharacterize the performance of the complexity-regularized maximum likelihood\nestimator, as a special case of our framework, which is shown to have smaller\nerrors when compared to the standard matrix completion framework without\npairwise penalties. We conduct extensive experiments on both synthetic and real\ndatasets to demonstrate the superior performance of this general framework.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 02:17:58 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 21:47:14 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Ji", "Kaiyi", ""], ["Tan", "Jian", ""], ["Xu", "Jinfeng", ""], ["Chi", "Yuejie", ""]]}, {"id": "1802.05822", "submitter": "Shuyang Gao", "authors": "Shuyang Gao, Rob Brekelmans, Greg Ver Steeg, Aram Galstyan", "title": "Auto-Encoding Total Correlation Explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in unsupervised learning enable reconstruction and generation of\nsamples from complex distributions, but this success is marred by the\ninscrutability of the representations learned. We propose an\ninformation-theoretic approach to characterizing disentanglement and dependence\nin representation learning using multivariate mutual information, also called\ntotal correlation. The principle of total Cor-relation Ex-planation (CorEx) has\nmotivated successful unsupervised learning applications across a variety of\ndomains, but under some restrictive assumptions. Here we relax those\nrestrictions by introducing a flexible variational lower bound to CorEx.\nSurprisingly, we find that this lower bound is equivalent to the one in\nvariational autoencoders (VAE) under certain conditions. This\ninformation-theoretic view of VAE deepens our understanding of hierarchical VAE\nand motivates a new algorithm, AnchorVAE, that makes latent codes more\ninterpretable through information maximization and enables generation of richer\nand more realistic samples.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 02:33:25 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Gao", "Shuyang", ""], ["Brekelmans", "Rob", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1802.05844", "submitter": "Kui Yu", "authors": "Kui Yu, Lin Liu, and Jiuyong Li", "title": "A Unified View of Causal and Non-causal Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to develop a unified view of causal and non-causal\nfeature selection methods. The unified view will fill in the gap in the\nresearch of the relation between the two types of methods. Based on the\nBayesian network framework and information theory, we first show that causal\nand non-causal feature selection methods share the same objective. That is to\nfind the Markov blanket of a class attribute, the theoretically optimal feature\nset for classification. We then examine the assumptions made by causal and\nnon-causal feature selection methods when searching for the optimal feature\nset, and unify the assumptions by mapping them to the restrictions on the\nstructure of the Bayesian network model of the studied problem. We further\nanalyze in detail how the structural assumptions lead to the different levels\nof approximations employed by the methods in their search, which then result in\nthe approximations in the feature sets found by the methods with respect to the\noptimal feature set. With the unified view, we are able to interpret the output\nof non-causal methods from a causal perspective and derive the error bounds of\nboth types of methods. Finally, we present practical understanding of the\nrelation between causal and non-causal methods using extensive experiments with\nsynthetic data and various types of real-word data.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 06:18:06 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 23:49:40 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 06:38:53 GMT"}, {"version": "v4", "created": "Sun, 16 Dec 2018 03:45:56 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Yu", "Kui", ""], ["Liu", "Lin", ""], ["Li", "Jiuyong", ""]]}, {"id": "1802.05846", "submitter": "Guy Tennenholtz", "authors": "Guy Tennenholtz, Tom Zahavy, Shie Mannor", "title": "Train on Validation: Squeezing the Data Lemon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection on validation data is an essential step in machine learning.\nWhile the mixing of data between training and validation is considered taboo,\npractitioners often violate it to increase performance. Here, we offer a\nsimple, practical method for using the validation set for training, which\nallows for a continuous, controlled trade-off between performance and\noverfitting of model selection. We define the notion of\non-average-validation-stable algorithms as one in which using small portions of\nvalidation data for training does not overfit the model selection process. We\nthen prove that stable algorithms are also validation stable. Finally, we\ndemonstrate our method on the MNIST and CIFAR-10 datasets using stable\nalgorithms as well as state-of-the-art neural networks. Our results show\nsignificant increase in test performance with a minor trade-off in bias\nadmitted to the model selection process.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 06:50:19 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Tennenholtz", "Guy", ""], ["Zahavy", "Tom", ""], ["Mannor", "Shie", ""]]}, {"id": "1802.05861", "submitter": "Hsiang Hsu", "authors": "Hsiang Hsu, Shahab Asoodeh, Salman Salamatian, Flavio P. Calmon", "title": "Generalizing Bottleneck Problems", "comments": "IEEE International Symposium on Information Theory (ISIT), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a pair of random variables $(X,Y)\\sim P_{XY}$ and two convex functions\n$f_1$ and $f_2$, we introduce two bottleneck functionals as the lower and upper\nboundaries of the two-dimensional convex set that consists of the pairs\n$\\left(I_{f_1}(W; X), I_{f_2}(W; Y)\\right)$, where $I_f$ denotes\n$f$-information and $W$ varies over the set of all discrete random variables\nsatisfying the Markov condition $W \\to X \\to Y$. Applying Witsenhausen and\nWyner's approach, we provide an algorithm for computing boundaries of this set\nfor $f_1$, $f_2$, and discrete $P_{XY}$. In the binary symmetric case, we fully\ncharacterize the set when (i) $f_1(t)=f_2(t)=t\\log t$, (ii)\n$f_1(t)=f_2(t)=t^2-1$, and (iii) $f_1$ and $f_2$ are both $\\ell^\\beta$ norm\nfunction for $\\beta \\geq 2$. We then argue that upper and lower boundaries in\n(i) correspond to Mrs. Gerber's Lemma and its inverse (which we call Mr.\nGerber's Lemma), in (ii) correspond to estimation-theoretic variants of\nInformation Bottleneck and Privacy Funnel, and in (iii) correspond to Arimoto\nInformation Bottleneck and Privacy Funnel.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 08:22:29 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 00:05:55 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 20:47:55 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Hsu", "Hsiang", ""], ["Asoodeh", "Shahab", ""], ["Salamatian", "Salman", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "1802.05872", "submitter": "Robert Palovics", "authors": "Andr\\'as A. Bencz\\'ur, Levente Kocsis and R\\'obert P\\'alovics", "title": "Online Machine Learning in Big Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of online machine learning in big data streams covers algorithms\nthat are (1) distributed and (2) work from data streams with only a limited\npossibility to store past data. The first requirement mostly concerns software\narchitectures and efficient algorithms. The second one also imposes nontrivial\ntheoretical restrictions on the modeling methods: In the data stream model,\nolder data is no longer available to revise earlier suboptimal modeling\ndecisions as the fresh data arrives.\n  In this article, we provide an overview of distributed software architectures\nand libraries as well as machine learning models for online learning. We\nhighlight the most important ideas for classification, regression,\nrecommendation, and unsupervised modeling from streaming data, and we show how\nthey are implemented in various distributed data stream processing systems.\n  This article is a reference material and not a survey. We do not attempt to\nbe comprehensive in describing all existing methods and solutions; rather, we\ngive pointers to the most important resources in the field. All related\nsub-fields, online algorithms, online learning, and distributed data processing\nare hugely dominant in current research and development with conceptually new\nresearch results and software components emerging at the time of writing. In\nthis article, we refer to several survey results, both for distributed data\nprocessing and for online machine learning. Compared to past surveys, our\narticle is different because we discuss recommender systems in extended detail.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 09:15:27 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Bencz\u00far", "Andr\u00e1s A.", ""], ["Kocsis", "Levente", ""], ["P\u00e1lovics", "R\u00f3bert", ""]]}, {"id": "1802.05874", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor, Xiaodong He, Ivan Tashev, Shuayb Zarar", "title": "Constrained Convolutional-Recurrent Networks to Improve Speech Quality\n  with Low Impact on Recognition Accuracy", "comments": "Published as a conference paper at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a speech-enhancement algorithm, it is highly desirable to simultaneously\nimprove perceptual quality and recognition rate. Thanks to computational costs\nand model complexities, it is challenging to train a model that effectively\noptimizes both metrics at the same time. In this paper, we propose a method for\nspeech enhancement that combines local and global contextual structures\ninformation through convolutional-recurrent neural networks that improves\nperceptual quality. At the same time, we introduce a new constraint on the\nobjective function using a language model/decoder that limits the impact on\nrecognition rate. Based on experiments conducted with real user data, we\ndemonstrate that our new context-augmented machine-learning approach for speech\nenhancement improves PESQ and WER by an additional 24.5% and 51.3%,\nrespectively, when compared to the best-performing methods in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 09:23:00 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Fakoor", "Rasool", ""], ["He", "Xiaodong", ""], ["Tashev", "Ivan", ""], ["Zarar", "Shuayb", ""]]}, {"id": "1802.05889", "submitter": "Chao Li", "authors": "Chao Li and Shohei Shimizu", "title": "Combining Linear Non-Gaussian Acyclic Model with Logistic Regression\n  Model for Estimating Causal Structure from Mixed Continuous and Discrete Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating causal models from observational data is a crucial task in data\nanalysis. For continuous-valued data, Shimizu et al. have proposed a linear\nacyclic non-Gaussian model to understand the data generating process, and have\nshown that their model is identifiable when the number of data is sufficiently\nlarge. However, situations in which continuous and discrete variables coexist\nin the same problem are common in practice. Most existing causal discovery\nmethods either ignore the discrete data and apply a continuous-valued algorithm\nor discretize all the continuous data and then apply a discrete Bayesian\nnetwork approach. These methods possibly loss important information when we\nignore discrete data or introduce the approximation error due to\ndiscretization. In this paper, we define a novel hybrid causal model which\nconsists of both continuous and discrete variables. The model assumes: (1) the\nvalue of a continuous variable is a linear function of its parent variables\nplus a non-Gaussian noise, and (2) each discrete variable is a logistic\nvariable whose distribution parameters depend on the values of its parent\nvariables. In addition, we derive the BIC scoring function for model selection.\nThe new discovery algorithm can learn causal structures from mixed continuous\nand discrete data without discretization. We empirically demonstrate the power\nof our method through thorough simulations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 10:45:59 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Li", "Chao", ""], ["Shimizu", "Shohei", ""]]}, {"id": "1802.05910", "submitter": "Steven Van Vaerenbergh", "authors": "Steven Van Vaerenbergh, Ignacio Santamaria, Victor Elvira, Matteo\n  Salvatori", "title": "Pattern Localization in Time Series through Signal-To-Model Alignment in\n  Latent Space", "comments": "IEEE ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of locating a predefined sequence of\npatterns in a time series. In particular, the studied scenario assumes a\ntheoretical model is available that contains the expected locations of the\npatterns. This problem is found in several contexts, and it is commonly solved\nby first synthesizing a time series from the model, and then aligning it to the\ntrue time series through dynamic time warping. We propose a technique that\nincreases the similarity of both time series before aligning them, by mapping\nthem into a latent correlation space. The mapping is learned from the data\nthrough a machine-learning setup. Experiments on data from non-destructive\ntesting demonstrate that the proposed approach shows significant improvements\nover the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 12:31:17 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 12:04:20 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Van Vaerenbergh", "Steven", ""], ["Santamaria", "Ignacio", ""], ["Elvira", "Victor", ""], ["Salvatori", "Matteo", ""]]}, {"id": "1802.05957", "submitter": "Takeru Miyato", "authors": "Takeru Miyato, Toshiki Kataoka, Masanori Koyama, Yuichi Yoshida", "title": "Spectral Normalization for Generative Adversarial Networks", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in the study of generative adversarial networks is the\ninstability of its training. In this paper, we propose a novel weight\nnormalization technique called spectral normalization to stabilize the training\nof the discriminator. Our new normalization technique is computationally light\nand easy to incorporate into existing implementations. We tested the efficacy\nof spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we\nexperimentally confirmed that spectrally normalized GANs (SN-GANs) is capable\nof generating images of better or equal quality relative to the previous\ntraining stabilization techniques.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 14:41:39 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Miyato", "Takeru", ""], ["Kataoka", "Toshiki", ""], ["Koyama", "Masanori", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "1802.05980", "submitter": "Marine Le Morvan", "authors": "Marine Le Morvan (CBIO), Jean-Philippe Vert (CBIO, DMA)", "title": "WHInter: A Working set algorithm for High-dimensional sparse second\n  order Interaction models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning sparse linear models with two-way interactions is desirable in many\napplication domains such as genomics. l1-regularised linear models are popular\nto estimate sparse models, yet standard implementations fail to address\nspecifically the quadratic explosion of candidate two-way interactions in high\ndimensions, and typically do not scale to genetic data with hundreds of\nthousands of features. Here we present WHInter, a working set algorithm to\nsolve large l1-regularised problems with two-way interactions for binary design\nmatrices. The novelty of WHInter stems from a new bound to efficiently identify\nworking sets while avoiding to scan all features, and on fast computations\ninspired from solutions to the maximum inner product search problem. We apply\nWHInter to simulated and real genetic data and show that it is more scalable\nand two orders of magnitude faster than the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 15:36:07 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Morvan", "Marine Le", "", "CBIO"], ["Vert", "Jean-Philippe", "", "CBIO, DMA"]]}, {"id": "1802.05981", "submitter": "Konstantinos Makantasis", "authors": "Konstantinos Makantasis, Anastasios Doulamis, Nikolaos Doulamis,\n  Antonis Nikitakis, Athanasios Voulodimos", "title": "Tensor-based Nonlinear Classifier for High-Order Data Analysis", "comments": "To appear in IEEE ICASSP 2018. arXiv admin note: text overlap with\n  arXiv:1709.08164", "journal-ref": null, "doi": "10.1109/ICASSP.2018.8461418", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a tensor-based nonlinear model for high-order data\nclassification. The advantages of the proposed scheme are that (i) it\nsignificantly reduces the number of weight parameters, and hence of required\ntraining samples, and (ii) it retains the spatial structure of the input\nsamples. The proposed model, called \\textit{Rank}-1 FNN, is based on a\nmodification of a feedforward neural network (FNN), such that its weights\nsatisfy the {\\it rank}-1 canonical decomposition. We also introduce a new\nlearning algorithm to train the model, and we evaluate the \\textit{Rank}-1 FNN\non third-order hyperspectral data. Experimental results and comparisons\nindicate that the proposed model outperforms state of the art classification\nmethods, including deep learning based ones, especially in cases with small\nnumbers of available training samples.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 09:49:38 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Makantasis", "Konstantinos", ""], ["Doulamis", "Anastasios", ""], ["Doulamis", "Nikolaos", ""], ["Nikitakis", "Antonis", ""], ["Voulodimos", "Athanasios", ""]]}, {"id": "1802.05983", "submitter": "Hyunjik Kim", "authors": "Hyunjik Kim, Andriy Mnih", "title": "Disentangling by Factorising", "comments": "Shorter version appeared in Learning Disentangled Representations:\n  From Perception to Control workshop at NIPS, 2017:\n  https://sites.google.com/corp/view/disentanglenips2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and address the problem of unsupervised learning of disentangled\nrepresentations on data generated from independent factors of variation. We\npropose FactorVAE, a method that disentangles by encouraging the distribution\nof representations to be factorial and hence independent across the dimensions.\nWe show that it improves upon $\\beta$-VAE by providing a better trade-off\nbetween disentanglement and reconstruction quality. Moreover, we highlight the\nproblems of a commonly used disentanglement metric and introduce a new metric\nthat does not suffer from them.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 15:43:43 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 16:25:57 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 10:43:41 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kim", "Hyunjik", ""], ["Mnih", "Andriy", ""]]}, {"id": "1802.05992", "submitter": "Jakub \\'Swi\\k{a}tkowski", "authors": "Maciej Ja\\'skowski (1), Jakub \\'Swi\\k{a}tkowski (1), Micha{\\l}\n  Zaj\\k{a}c (1), Maciej Klimek (1), Jarek Potiuk (1), Piotr Rybicki (1), Piotr\n  Polatowski (1), Przemys{\\l}aw Walczyk (1), Kacper Nowicki (1), Marek Cygan (1\n  and 2) ((1) NoMagic.AI, (2) Institute of Informatics, University of Warsaw)", "title": "Improved GQ-CNN: Deep Learning Model for Planning Robust Grasps", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in the field of robot grasping have shown great\nimprovements in the grasp success rates when dealing with unknown objects. In\nthis work we improve on one of the most promising approaches, the Grasp Quality\nConvolutional Neural Network (GQ-CNN) trained on the DexNet 2.0 dataset. We\npropose a new architecture for the GQ-CNN and describe practical improvements\nthat increase the model validation accuracy from 92.2% to 95.8% and from 85.9%\nto 88.0% on respectively image-wise and object-wise training and validation\nsplits.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 15:54:31 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Ja\u015bkowski", "Maciej", "", "NoMagic.AI"], ["\u015awi\u0105tkowski", "Jakub", "", "NoMagic.AI"], ["Zaj\u0105c", "Micha\u0142", "", "NoMagic.AI"], ["Klimek", "Maciej", "", "NoMagic.AI"], ["Potiuk", "Jarek", "", "NoMagic.AI"], ["Rybicki", "Piotr", "", "NoMagic.AI"], ["Polatowski", "Piotr", "", "NoMagic.AI"], ["Walczyk", "Przemys\u0142aw", "", "NoMagic.AI"], ["Nowicki", "Kacper", "", "NoMagic.AI"], ["Cygan", "Marek", "", "1\n  and 2"]]}, {"id": "1802.06006", "submitter": "Sercan Arik", "authors": "Sercan O. Arik, Jitong Chen, Kainan Peng, Wei Ping, Yanqi Zhou", "title": "Neural Voice Cloning with a Few Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice cloning is a highly desired feature for personalized speech interfaces.\nNeural network based speech synthesis has been shown to generate high quality\nspeech for a large number of speakers. In this paper, we introduce a neural\nvoice cloning system that takes a few audio samples as input. We study two\napproaches: speaker adaptation and speaker encoding. Speaker adaptation is\nbased on fine-tuning a multi-speaker generative model with a few cloning\nsamples. Speaker encoding is based on training a separate model to directly\ninfer a new speaker embedding from cloning audios and to be used with a\nmulti-speaker generative model. In terms of naturalness of the speech and its\nsimilarity to original speaker, both approaches can achieve good performance,\neven with very few cloning audios. While speaker adaptation can achieve better\nnaturalness and similarity, the cloning time or required memory for the speaker\nencoding approach is significantly less, making it favorable for low-resource\ndeployment.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 18:24:41 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 21:58:02 GMT"}, {"version": "v3", "created": "Fri, 12 Oct 2018 06:27:26 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Arik", "Sercan O.", ""], ["Chen", "Jitong", ""], ["Peng", "Kainan", ""], ["Ping", "Wei", ""], ["Zhou", "Yanqi", ""]]}, {"id": "1802.06012", "submitter": "Julian Sch\\\"utte", "authors": "Johann Vierthaler, Roman Kruszelnicki, Julian Sch\\\"utte", "title": "WebEye - Automated Collection of Malicious HTTP Traffic", "comments": "Software implementation description, dataset, machine learning, 11\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With malware detection techniques increasingly adopting machine learning\napproaches, the creation of precise training sets becomes more and more\nimportant. Large data sets of realistic web traffic, correctly classified as\nbenign or malicious are needed, not only to train classic and deep learning\nalgorithms, but also to serve as evaluation benchmarks for existing malware\ndetection products. Interestingly, despite the vast number and versatility of\nthreats a user may encounter when browsing the web, actual malicious content is\noften hard to come by, since prerequisites such as browser and operating system\ntype and version must be met in order to receive the payload from a malware\ndistributing server. In combination with privacy constraints on data sets of\nactual user traffic, it is difficult for researchers and product developers to\nevaluate anti-malware solutions against large-scale data sets of realistic web\ntraffic. In this paper we present WebEye, a framework that autonomously creates\nrealistic HTTP traffic, enriches recorded traffic with additional information,\nand classifies records as malicious or benign, using different classifiers. We\nare using WebEye to collect malicious HTML and JavaScript and show how datasets\ncreated with WebEye can be used to train machine learning based malware\ndetection algorithms. We regard WebEye and the data sets it creates as a tool\nfor researchers and product developers to evaluate and improve their AI-based\nanti-malware solutions against large-scale benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 16:24:07 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Vierthaler", "Johann", ""], ["Kruszelnicki", "Roman", ""], ["Sch\u00fctte", "Julian", ""]]}, {"id": "1802.06014", "submitter": "Pengtao Xie", "authors": "Pengtao Xie, Wei Wu, Yichen Zhu, Eric P. Xing", "title": "Orthogonality-Promoting Distance Metric Learning: Convex Relaxation and\n  Theoretical Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning (DML), which learns a distance metric from labeled\n\"similar\" and \"dissimilar\" data pairs, is widely utilized. Recently, several\nworks investigate orthogonality-promoting regularization (OPR), which\nencourages the projection vectors in DML to be close to being orthogonal, to\nachieve three effects: (1) high balancedness -- achieving comparable\nperformance on both frequent and infrequent classes; (2) high compactness --\nusing a small number of projection vectors to achieve a \"good\" metric; (3) good\ngeneralizability -- alleviating overfitting to training data. While showing\npromising results, these approaches suffer three problems. First, they involve\nsolving non-convex optimization problems where achieving the global optimal is\nNP-hard. Second, it lacks a theoretical understanding why OPR can lead to\nbalancedness. Third, the current generalization error analysis of OPR is not\ndirectly on the regularizer. In this paper, we address these three issues by\n(1) seeking convex relaxations of the original nonconvex problems so that the\nglobal optimal is guaranteed to be achievable; (2) providing a formal analysis\non OPR's capability of promoting balancedness; (3) providing a theoretical\nanalysis that directly reveals the relationship between OPR and generalization\nperformance. Experiments on various datasets demonstrate that our convex\nmethods are more effective in promoting balancedness, compactness, and\ngeneralization, and are computationally more efficient, compared with the\nnonconvex methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 16:28:22 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Xie", "Pengtao", ""], ["Wu", "Wei", ""], ["Zhu", "Yichen", ""], ["Xing", "Eric P.", ""]]}, {"id": "1802.06037", "submitter": "Angela Zhou", "authors": "Nathan Kallus and Angela Zhou", "title": "Policy Evaluation and Optimization with Continuous Treatments", "comments": "appearing at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of policy evaluation and learning from batched\ncontextual bandit data when treatments are continuous, going beyond previous\nwork on discrete treatments. Previous work for discrete treatment/action spaces\nfocuses on inverse probability weighting (IPW) and doubly robust (DR) methods\nthat use a rejection sampling approach for evaluation and the equivalent\nweighted classification problem for learning. In the continuous setting, this\nreduction fails as we would almost surely reject all observations. To tackle\nthe case of continuous treatments, we extend the IPW and DR approaches to the\ncontinuous setting using a kernel function that leverages treatment proximity\nto attenuate discrete rejection. Our policy estimator is consistent and we\ncharacterize the optimal bandwidth. The resulting continuous policy optimizer\n(CPO) approach using our estimator achieves convergent regret and approaches\nthe best-in-class policy for learnable policy classes. We demonstrate that the\nestimator performs well and, in particular, outperforms a discretization-based\nbenchmark. We further study the performance of our policy optimizer in a case\nstudy on personalized dosing based on a dataset of Warfarin patients, their\ncovariates, and final therapeutic doses. Our learned policy outperforms\nbenchmarks and nears the oracle-best linear policy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 17:23:02 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Kallus", "Nathan", ""], ["Zhou", "Angela", ""]]}, {"id": "1802.06052", "submitter": "Lin Chen", "authors": "Lin Chen, Hamed Hassani, Amin Karbasi", "title": "Online Continuous Submodular Maximization", "comments": "Accepted by AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider an online optimization process, where the\nobjective functions are not convex (nor concave) but instead belong to a broad\nclass of continuous submodular functions. We first propose a variant of the\nFrank-Wolfe algorithm that has access to the full gradient of the objective\nfunctions. We show that it achieves a regret bound of $O(\\sqrt{T})$ (where $T$\nis the horizon of the online optimization problem) against a\n$(1-1/e)$-approximation to the best feasible solution in hindsight. However, in\nmany scenarios, only an unbiased estimate of the gradients are available. For\nsuch settings, we then propose an online stochastic gradient ascent algorithm\nthat also achieves a regret bound of $O(\\sqrt{T})$ regret, albeit against a\nweaker $1/2$-approximation to the best feasible solution in hindsight. We also\ngeneralize our results to $\\gamma$-weakly submodular functions and prove the\nsame sublinear regret bounds. Finally, we demonstrate the efficiency of our\nalgorithms on a few problem instances, including non-convex/non-concave\nquadratic programs, multilinear extensions of submodular set functions, and\nD-optimal design.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 17:56:48 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Chen", "Lin", ""], ["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""]]}, {"id": "1802.06058", "submitter": "Yusuke Tsuzuku", "authors": "Yusuke Tsuzuku, Hiroto Imachi, Takuya Akiba", "title": "Variance-based Gradient Compression for Efficient Distributed Deep\n  Learning", "comments": "ICLR 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the substantial computational cost, training state-of-the-art deep\nneural networks for large-scale datasets often requires distributed training\nusing multiple computation workers. However, by nature, workers need to\nfrequently communicate gradients, causing severe bottlenecks, especially on\nlower bandwidth connections. A few methods have been proposed to compress\ngradient for efficient communication, but they either suffer a low compression\nratio or significantly harm the resulting model accuracy, particularly when\napplied to convolutional neural networks. To address these issues, we propose a\nmethod to reduce the communication overhead of distributed deep learning. Our\nkey observation is that gradient updates can be delayed until an unambiguous\n(high amplitude, low variance) gradient has been calculated. We also present an\nefficient algorithm to compute the variance with negligible additional cost. We\nexperimentally show that our method can achieve very high compression ratio\nwhile maintaining the result model accuracy. We also analyze the efficiency\nusing computation and communication cost models and provide the evidence that\nthis method enables distributed deep learning for many scenarios with commodity\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 18:15:33 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 04:13:14 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Tsuzuku", "Yusuke", ""], ["Imachi", "Hiroto", ""], ["Akiba", "Takuya", ""]]}, {"id": "1802.06091", "submitter": "Amir Rosenfeld", "authors": "Amir Rosenfeld, John K. Tsotsos", "title": "Bridging Cognitive Programs and Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While great advances are made in pattern recognition and machine learning,\nthe successes of such fields remain restricted to narrow applications and seem\nto break down when training data is scarce, a shift in domain occurs, or when\nintelligent reasoning is required for rapid adaptation to new environments. In\nthis work, we list several of the shortcomings of modern machine-learning\nsolutions, specifically in the contexts of computer vision and in reinforcement\nlearning and suggest directions to explore in order to try to ameliorate these\nweaknesses.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 19:19:00 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Rosenfeld", "Amir", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1802.06093", "submitter": "Phil Long", "authors": "Peter L. Bartlett, David P. Helmbold and Philip M. Long", "title": "Gradient descent with identity initialization efficiently learns\n  positive definite linear transformations by deep residual networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze algorithms for approximating a function $f(x) = \\Phi x$ mapping\n$\\Re^d$ to $\\Re^d$ using deep linear neural networks, i.e. that learn a\nfunction $h$ parameterized by matrices $\\Theta_1,...,\\Theta_L$ and defined by\n$h(x) = \\Theta_L \\Theta_{L-1} ... \\Theta_1 x$. We focus on algorithms that\nlearn through gradient descent on the population quadratic loss in the case\nthat the distribution over the inputs is isotropic.\n  We provide polynomial bounds on the number of iterations for gradient descent\nto approximate the least squares matrix $\\Phi$, in the case where the initial\nhypothesis $\\Theta_1 = ... = \\Theta_L = I$ has excess loss bounded by a small\nenough constant. On the other hand, we show that gradient descent fails to\nconverge for $\\Phi$ whose distance from the identity is a larger constant, and\nwe show that some forms of regularization toward the identity in each layer do\nnot help.\n  If $\\Phi$ is symmetric positive definite, we show that an algorithm that\ninitializes $\\Theta_i = I$ learns an $\\epsilon$-approximation of $f$ using a\nnumber of updates polynomial in $L$, the condition number of $\\Phi$, and\n$\\log(d/\\epsilon)$. In contrast, we show that if the least squares matrix\n$\\Phi$ is symmetric and has a negative eigenvalue, then all members of a class\nof algorithms that perform gradient descent with identity initialization, and\noptionally regularize toward the identity in each layer, fail to converge.\n  We analyze an algorithm for the case that $\\Phi$ satisfies $u^{\\top} \\Phi u >\n0$ for all $u$, but may not be symmetric. This algorithm uses two regularizers:\none that maintains the invariant $u^{\\top} \\Theta_L \\Theta_{L-1} ... \\Theta_1 u\n> 0$ for all $u$, and another that \"balances\" $\\Theta_1, ..., \\Theta_L$ so that\nthey have the same singular values.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 19:24:29 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 15:48:00 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 16:10:40 GMT"}, {"version": "v4", "created": "Mon, 18 Jun 2018 16:46:26 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Helmbold", "David P.", ""], ["Long", "Philip M.", ""]]}, {"id": "1802.06095", "submitter": "Saurabh Verma", "authors": "Saurabh Agrawal, Saurabh Verma, Gowtham Atluri, Anuj Karpatne, Stefan\n  Liess, Angus Macdonald III, Snigdhansu Chatterjee, Vipin Kumar", "title": "Mining Sub-Interval Relationships In Time Series Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series data is being increasingly collected and stud- ied in several\nareas such as neuroscience, climate science, transportation, and social media.\nDiscovery of complex patterns of relationships between individual time-series,\nusing data-driven approaches can improve our understanding of real-world\nsystems. While traditional approaches typically study relationships between two\nentire time series, many interesting relationships in real-world applications\nexist in small sub-intervals of time while remaining absent or feeble during\nother sub-intervals. In this paper, we define the notion of a sub-interval\nrelationship (SIR) to capture inter- actions between two time series that are\nprominent only in certain sub-intervals of time. We propose a novel and\nefficient approach to find most interesting SIR in a pair of time series. We\nevaluate our proposed approach on two real-world datasets from climate science\nand neuroscience domain and demonstrated the scalability and computational\nefficiency of our proposed approach. We further evaluated our discovered SIRs\nbased on a randomization based procedure. Our results indicated the existence\nof several such relationships that are statistically significant, some of which\nwere also found to have physical interpretation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 19:30:19 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Agrawal", "Saurabh", ""], ["Verma", "Saurabh", ""], ["Atluri", "Gowtham", ""], ["Karpatne", "Anuj", ""], ["Liess", "Stefan", ""], ["Macdonald", "Angus", "III"], ["Chatterjee", "Snigdhansu", ""], ["Kumar", "Vipin", ""]]}, {"id": "1802.06104", "submitter": "Chuyang Ke", "authors": "Chuyang Ke, Jean Honorio", "title": "Information-theoretic Limits for Community Detection in Network Models", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS), 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the information-theoretic limits for the recovery of node labels\nin several network models. This includes the Stochastic Block Model, the\nExponential Random Graph Model, the Latent Space Model, the Directed\nPreferential Attachment Model, and the Directed Small-world Model. For the\nStochastic Block Model, the non-recoverability condition depends on the\nprobabilities of having edges inside a community, and between different\ncommunities. For the Latent Space Model, the non-recoverability condition\ndepends on the dimension of the latent space, and how far and spread are the\ncommunities in the latent space. For the Directed Preferential Attachment Model\nand the Directed Small-world Model, the non-recoverability condition depends on\nthe ratio between homophily and neighborhood size. We also consider dynamic\nversions of the Stochastic Block Model and the Latent Space Model.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 20:09:16 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 00:29:35 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Ke", "Chuyang", ""], ["Honorio", "Jean", ""]]}, {"id": "1802.06126", "submitter": "Vishesh Jain", "authors": "Vishesh Jain, Frederic Koehler, Elchanan Mossel", "title": "The Mean-Field Approximation: Information Inequalities, Algorithms, and\n  Complexity", "comments": "Updated bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech math-ph math.CO math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mean field approximation to the Ising model is a canonical variational\ntool that is used for analysis and inference in Ising models. We provide a\nsimple and optimal bound for the KL error of the mean field approximation for\nIsing models on general graphs, and extend it to higher order Markov random\nfields. Our bound improves on previous bounds obtained in work in the graph\nlimit literature by Borgs, Chayes, Lov\\'asz, S\\'os, and Vesztergombi and\nanother recent work by Basak and Mukherjee. Our bound is tight up to lower\norder terms. Building on the methods used to prove the bound, along with\ntechniques from combinatorics and optimization, we study the algorithmic\nproblem of estimating the (variational) free energy for Ising models and\ngeneral Markov random fields. For a graph $G$ on $n$ vertices and interaction\nmatrix $J$ with Frobenius norm $\\| J \\|_F$, we provide algorithms that\napproximate the free energy within an additive error of $\\epsilon n \\|J\\|_F$ in\ntime $\\exp(poly(1/\\epsilon))$. We also show that approximation within $(n\n\\|J\\|_F)^{1-\\delta}$ is NP-hard for every $\\delta > 0$. Finally, we provide\nmore efficient approximation algorithms, which find the optimal mean field\napproximation, for ferromagnetic Ising models and for Ising models satisfying\nDobrushin's condition.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 21:18:39 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 20:55:29 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Jain", "Vishesh", ""], ["Koehler", "Frederic", ""], ["Mossel", "Elchanan", ""]]}, {"id": "1802.06129", "submitter": "Vishesh Jain", "authors": "Vishesh Jain, Frederic Koehler, Elchanan Mossel", "title": "The Vertex Sample Complexity of Free Energy is Polynomial", "comments": "arXiv admin note: text overlap with arXiv:1802.06126 Updated\n  bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the following question: given a massive Markov random field on $n$\nnodes, can a small sample from it provide a rough approximation to the free\nenergy $\\mathcal{F}_n = \\log{Z_n}$?\n  Results in graph limit literature by Borgs, Chayes, Lov\\'asz, S\\'os, and\nVesztergombi show that for Ising models on $n$ nodes and interactions of\nstrength $\\Theta(1/n)$, an $\\epsilon$ approximation to $\\log Z_n / n$ can be\nachieved by sampling a randomly induced model on $2^{O(1/\\epsilon^2)}$ nodes.\nWe show that the sampling complexity of this problem is {\\em polynomial in}\n$1/\\epsilon$. We further show a polynomial dependence on $\\epsilon$ cannot be\navoided.\n  Our results are very general as they apply to higher order Markov random\nfields. For Markov random fields of order $r$, we obtain an algorithm that\nachieves $\\epsilon$ approximation using a number of samples polynomial in $r$\nand $1/\\epsilon$ and running time that is $2^{O(1/\\epsilon^2)}$ up to\npolynomial factors in $r$ and $\\epsilon$. For ferromagnetic Ising models, the\nrunning time is polynomial in $1/\\epsilon$.\n  Our results are intimately connected to recent research on the regularity\nlemma and property testing, where the interest is in finding which properties\ncan tested within $\\epsilon$ error in time polynomial in $1/\\epsilon$. In\nparticular, our proofs build on results from a recent work by Alon, de la Vega,\nKannan and Karpinski, who also introduced the notion of polynomial vertex\nsample complexity. Another critical ingredient of the proof is an effective\nbound by the authors of the paper relating the variational free energy and the\nfree energy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 21:25:42 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 00:40:20 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Jain", "Vishesh", ""], ["Koehler", "Frederic", ""], ["Mossel", "Elchanan", ""]]}, {"id": "1802.06132", "submitter": "James Stokes", "authors": "Tengyuan Liang, James Stokes", "title": "Interaction Matters: A Note on Non-asymptotic Local Convergence of\n  Generative Adversarial Networks", "comments": "To appear in the proceedings of the 22nd International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2019", "journal-ref": "The 22nd International Conference on Artificial Intelligence and\n  Statistics 89 (2019) 907-915", "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the pursuit of a systematic computational and algorithmic\nunderstanding of Generative Adversarial Networks (GANs), we present a simple\nyet unified non-asymptotic local convergence theory for smooth two-player\ngames, which subsumes several discrete-time gradient-based saddle point\ndynamics. The analysis reveals the surprising nature of the off-diagonal\ninteraction term as both a blessing and a curse. On the one hand, this\ninteraction term explains the origin of the slow-down effect in the convergence\nof Simultaneous Gradient Ascent (SGA) to stable Nash equilibria. On the other\nhand, for the unstable equilibria, exponential convergence can be proved thanks\nto the interaction term, for four modified dynamics proposed to stabilize GAN\ntraining: Optimistic Mirror Descent (OMD), Consensus Optimization (CO),\nImplicit Updates (IU) and Predictive Method (PM). The analysis uncovers the\nintimate connections among these stabilizing techniques, and provides detailed\ncharacterization on the choice of learning rate. As a by-product, we present a\nnew analysis for OMD proposed in Daskalakis, Ilyas, Syrgkanis, and Zeng [2017]\nwith improved rates.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 21:30:19 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 20:26:16 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Liang", "Tengyuan", ""], ["Stokes", "James", ""]]}, {"id": "1802.06138", "submitter": "Sandeep Soni", "authors": "Sandeep Soni, Shawn Ling Ramirez and Jacob Eisenstein", "title": "Detecting Social Influence in Event Cascades by Comparing Discriminative\n  Rankers", "comments": "Accepted to the SIGKDD Workshop on Causal Discovery, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global dynamics of event cascades are often governed by the local\ndynamics of peer influence. However, detecting social influence from\nobservational data is challenging due to confounds like homophily and practical\nissues like missing data. We propose a simple discriminative method to detect\ninfluence from observational data. The core of the approach is to train a\nranking algorithm to predict the source of the next event in a cascade, and\ncompare its out-of-sample accuracy against a competitive baseline which lacks\naccess to features corresponding to social influence. We analyze synthetically\ngenerated data to show that this method correctly identifies influence in the\npresence of confounds, and is robust to both missing data and misspecification\n--- unlike well-known alternatives. We apply the method to two real-world\ndatasets: (1) the co-sponsorship of legislation in the U.S. House of\nRepresentatives on a social network of shared campaign donors; (2) rumors about\nthe Higgs boson discovery on a follower network of $10^5$ Twitter accounts. Our\nmodel identifies the role of social influence in these scenarios and uses it to\nmake more accurate predictions about the future trajectory of cascades.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 21:54:36 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 10:02:24 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Soni", "Sandeep", ""], ["Ramirez", "Shawn Ling", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1802.06139", "submitter": "Patrick M. Pilarski", "authors": "Jaden B. Travnik, Kory W. Mathewson, Richard S. Sutton, Patrick M.\n  Pilarski", "title": "Reactive Reinforcement Learning in Asynchronous Environments", "comments": "11 pages, 7 figures, currently under journal peer review", "journal-ref": null, "doi": "10.3389/frobt.2018.00079", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relationship between a reinforcement learning (RL) agent and an\nasynchronous environment is often ignored. Frequently used models of the\ninteraction between an agent and its environment, such as Markov Decision\nProcesses (MDP) or Semi-Markov Decision Processes (SMDP), do not capture the\nfact that, in an asynchronous environment, the state of the environment may\nchange during computation performed by the agent. In an asynchronous\nenvironment, minimizing reaction time---the time it takes for an agent to react\nto an observation---also minimizes the time in which the state of the\nenvironment may change following observation. In many environments, the\nreaction time of an agent directly impacts task performance by permitting the\nenvironment to transition into either an undesirable terminal state or a state\nwhere performing the chosen action is inappropriate. We propose a class of\nreactive reinforcement learning algorithms that address this problem of\nasynchronous environments by immediately acting after observing new state\ninformation. We compare a reactive SARSA learning algorithm with the\nconventional SARSA learning algorithm on two asynchronous robotic tasks\n(emergency stopping and impact prevention), and show that the reactive RL\nalgorithm reduces the reaction time of the agent by approximately the duration\nof the algorithm's learning update. This new class of reactive algorithms may\nfacilitate safer control and faster decision making without any change to\nstandard learning guarantees.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 21:55:01 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Travnik", "Jaden B.", ""], ["Mathewson", "Kory W.", ""], ["Sutton", "Richard S.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1802.06153", "submitter": "Jeffrey Chan", "authors": "Jeffrey Chan, Valerio Perrone, Jeffrey P. Spence, Paul A. Jenkins,\n  Sara Mathieson, Yun S. Song", "title": "A Likelihood-Free Inference Framework for Population Genetic Data using\n  Exchangeable Neural Networks", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An explosion of high-throughput DNA sequencing in the past decade has led to\na surge of interest in population-scale inference with whole-genome data.\nRecent work in population genetics has centered on designing inference methods\nfor relatively simple model classes, and few scalable general-purpose inference\ntechniques exist for more realistic, complex models. To achieve this, two\ninferential challenges need to be addressed: (1) population data are\nexchangeable, calling for methods that efficiently exploit the symmetries of\nthe data, and (2) computing likelihoods is intractable as it requires\nintegrating over a set of correlated, extremely high-dimensional latent\nvariables. These challenges are traditionally tackled by likelihood-free\nmethods that use scientific simulators to generate datasets and reduce them to\nhand-designed, permutation-invariant summary statistics, often leading to\ninaccurate inference. In this work, we develop an exchangeable neural network\nthat performs summary statistic-free, likelihood-free inference. Our framework\ncan be applied in a black-box fashion across a variety of simulation-based\ntasks, both within and outside biology. We demonstrate the power of our\napproach on the recombination hotspot testing problem, outperforming the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 22:36:16 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 02:25:35 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Chan", "Jeffrey", ""], ["Perrone", "Valerio", ""], ["Spence", "Jeffrey P.", ""], ["Jenkins", "Paul A.", ""], ["Mathieson", "Sara", ""], ["Song", "Yun S.", ""]]}, {"id": "1802.06167", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Wael AbdAlmageed, Yue Wu, Premkumar Natarajan", "title": "CapsuleGAN: Generative Adversarial Capsule Network", "comments": "To appear in Proceedings of ECCV Workshop on Brain Driven Computer\n  Vision (BDCV) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Generative Adversarial Capsule Network (CapsuleGAN), a framework\nthat uses capsule networks (CapsNets) instead of the standard convolutional\nneural networks (CNNs) as discriminators within the generative adversarial\nnetwork (GAN) setting, while modeling image data. We provide guidelines for\ndesigning CapsNet discriminators and the updated GAN objective function, which\nincorporates the CapsNet margin loss, for training CapsuleGAN models. We show\nthat CapsuleGAN outperforms convolutional-GAN at modeling image data\ndistribution on MNIST and CIFAR-10 datasets, evaluated on the generative\nadversarial metric and at semi-supervised image classification.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 01:04:53 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 20:20:51 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 03:05:23 GMT"}, {"version": "v4", "created": "Tue, 31 Jul 2018 21:28:54 GMT"}, {"version": "v5", "created": "Mon, 6 Aug 2018 00:22:53 GMT"}, {"version": "v6", "created": "Tue, 25 Sep 2018 23:42:04 GMT"}, {"version": "v7", "created": "Tue, 2 Oct 2018 05:49:41 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Jaiswal", "Ayush", ""], ["AbdAlmageed", "Wael", ""], ["Wu", "Yue", ""], ["Natarajan", "Premkumar", ""]]}, {"id": "1802.06175", "submitter": "Yang Yuan", "authors": "Robert Kleinberg, Yuanzhi Li, Yang Yuan", "title": "An Alternative View: When Does SGD Escape Local Minima?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is widely used in machine learning.\nAlthough being commonly viewed as a fast but not accurate version of gradient\ndescent (GD), it always finds better solutions than GD for modern neural\nnetworks.\n  In order to understand this phenomenon, we take an alternative view that SGD\nis working on the convolved (thus smoothed) version of the loss function. We\nshow that, even if the function $f$ has many bad local minima or saddle points,\nas long as for every point $x$, the weighted average of the gradients of its\nneighborhoods is one point convex with respect to the desired solution $x^*$,\nSGD will get close to, and then stay around $x^*$ with constant probability.\nMore specifically, SGD will not get stuck at \"sharp\" local minima with small\ndiameters, as long as the neighborhoods of these regions contain enough\ngradient information. The neighborhood size is controlled by step size and\ngradient noise.\n  Our result identifies a set of functions that SGD provably works, which is\nmuch larger than the set of convex functions. Empirically, we observe that the\nloss surface of neural networks enjoys nice one point convexity properties\nlocally, therefore our theorem helps explain why SGD works so well for neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 02:44:16 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 16:48:42 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Kleinberg", "Robert", ""], ["Li", "Yuanzhi", ""], ["Yuan", "Yang", ""]]}, {"id": "1802.06179", "submitter": "Rafael Dos Santos De Oliveira", "authors": "Rafael Oliveira, Fernando H.M. Rocha, Lionel Ott, Vitor Guizilini,\n  Fabio Ramos and Valdir Grassi Jr", "title": "Learning to Race through Coordinate Descent Bayesian Optimisation", "comments": "Accepted as conference paper for the 2018 IEEE International\n  Conference on Robotics and Automation (ICRA)", "journal-ref": null, "doi": "10.1109/ICRA.2018.8460735", "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the automation of many kinds of processes, the observable outcome can\noften be described as the combined effect of an entire sequence of actions, or\ncontrols, applied throughout its execution. In these cases, strategies to\noptimise control policies for individual stages of the process might not be\napplicable, and instead the whole policy might have to be optimised at once. On\nthe other hand, the cost to evaluate the policy's performance might also be\nhigh, being desirable that a solution can be found with as few interactions as\npossible with the real system. We consider the problem of optimising control\npolicies to allow a robot to complete a given race track within a minimum\namount of time. We assume that the robot has no prior information about the\ntrack or its own dynamical model, just an initial valid driving example.\nLocalisation is only applied to monitor the robot and to provide an indication\nof its position along the track's centre axis. We propose a method for finding\na policy that minimises the time per lap while keeping the vehicle on the track\nusing a Bayesian optimisation (BO) approach over a reproducing kernel Hilbert\nspace. We apply an algorithm to search more efficiently over high-dimensional\npolicy-parameter spaces with BO, by iterating over each dimension individually,\nin a sequential coordinate descent-like scheme. Experiments demonstrate the\nperformance of the algorithm against other methods in a simulated car racing\nenvironment.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 03:19:43 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Oliveira", "Rafael", ""], ["Rocha", "Fernando H. M.", ""], ["Ott", "Lionel", ""], ["Guizilini", "Vitor", ""], ["Ramos", "Fabio", ""], ["Grassi", "Valdir", "Jr"]]}, {"id": "1802.06181", "submitter": "Naji Khosravan", "authors": "Naji Khosravan and Ulas Bagci", "title": "Semi-supervised multi-task learning for lung cancer diagnosis", "comments": "Accepted for publication at IEEE EMBC (40th International Engineering\n  in Medicine and Biology Conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection of lung nodules is of great importance in lung cancer\nscreening. Existing research recognizes the critical role played by CAD systems\nin early detection and diagnosis of lung nodules. However, many CAD systems,\nwhich are used as cancer detection tools, produce a lot of false positives (FP)\nand require a further FP reduction step. Furthermore, guidelines for early\ndiagnosis and treatment of lung cancer are consist of different shape and\nvolume measurements of abnormalities. Segmentation is at the heart of our\nunderstanding of nodules morphology making it a major area of interest within\nthe field of computer aided diagnosis systems. This study set out to test the\nhypothesis that joint learning of false positive (FP) nodule reduction and\nnodule segmentation can improve the computer aided diagnosis (CAD) systems'\nperformance on both tasks. To support this hypothesis we propose a 3D deep\nmulti-task CNN to tackle these two problems jointly. We tested our system on\nLUNA16 dataset and achieved an average dice similarity coefficient (DSC) of 91%\nas segmentation accuracy and a score of nearly 92% for FP reduction. As a proof\nof our hypothesis, we showed improvements of segmentation and FP reduction\ntasks over two baselines. Our results support that joint training of these two\ntasks through a multi-task learning approach improves system performance on\nboth. We also showed that a semi-supervised approach can be used to overcome\nthe limitation of lack of labeled data for the 3D segmentation task.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 03:49:32 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 19:08:13 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Khosravan", "Naji", ""], ["Bagci", "Ulas", ""]]}, {"id": "1802.06182", "submitter": "Jong Wook Kim", "authors": "Jong Wook Kim, Justin Salamon, Peter Li, Juan Pablo Bello", "title": "CREPE: A Convolutional Representation for Pitch Estimation", "comments": "ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of estimating the fundamental frequency of a monophonic sound\nrecording, also known as pitch tracking, is fundamental to audio processing\nwith multiple applications in speech processing and music information\nretrieval. To date, the best performing techniques, such as the pYIN algorithm,\nare based on a combination of DSP pipelines and heuristics. While such\ntechniques perform very well on average, there remain many cases in which they\nfail to correctly estimate the pitch. In this paper, we propose a data-driven\npitch tracking algorithm, CREPE, which is based on a deep convolutional neural\nnetwork that operates directly on the time-domain waveform. We show that the\nproposed model produces state-of-the-art results, performing equally or better\nthan pYIN. Furthermore, we evaluate the model's generalizability in terms of\nnoise robustness. A pre-trained version of CREPE is made freely available as an\nopen-source Python module for easy application.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 03:50:11 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Kim", "Jong Wook", ""], ["Salamon", "Justin", ""], ["Li", "Peter", ""], ["Bello", "Juan Pablo", ""]]}, {"id": "1802.06186", "submitter": "Dheeraj Nagaraj", "authors": "Guy Bresler and Dheeraj Nagaraj", "title": "Optimal Single Sample Tests for Structured versus Unstructured Network\n  Data", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing, using only a single sample, between mean\nfield distributions (like Curie-Weiss, Erd\\H{o}s-R\\'enyi) and structured Gibbs\ndistributions (like Ising model on sparse graphs and Exponential Random\nGraphs). Our goal is to test without knowing the parameter values of the\nunderlying models: only the \\emph{structure} of dependencies is known. We\ndevelop a new approach that applies to both the Ising and Exponential Random\nGraph settings based on a general and natural statistical test. The test can\ndistinguish the hypotheses with high probability above a certain threshold in\nthe (inverse) temperature parameter, and is optimal in that below the threshold\nno test can distinguish the hypotheses.\n  The thresholds do not correspond to the presence of long-range order in the\nmodels. By aggregating information at a global scale, our test works even at\nvery high temperatures.\n  The proofs are based on distributional approximation and sharp concentration\nof quadratic forms, when restricted to Hamming spheres. The restriction to\nHamming spheres is necessary, since otherwise any scalar statistic is useless\nwithout explicit knowledge of the temperature parameter. At the same time, this\nrestriction radically changes the behavior of the functions under\nconsideration, resulting in a much smaller variance than in the independent\nsetting; this makes it hard to directly apply standard methods (i.e., Stein's\nmethod) for concentration of weakly dependent variables. Instead, we carry out\nan additional tensorization argument using a Markov chain that respects the\nsymmetry of the Hamming sphere.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 04:07:29 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 08:43:36 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Bresler", "Guy", ""], ["Nagaraj", "Dheeraj", ""]]}, {"id": "1802.06222", "submitter": "Houssam Zenati", "authors": "Houssam Zenati, Chuan Sheng Foo, Bruno Lecouat, Gaurav Manek, Vijay\n  Ramaseshan Chandrasekhar", "title": "Efficient GAN-Based Anomaly Detection", "comments": "Updated version of this work is published at ICDM 2018, see\n  arXiv:1812.02288 . Submitted to the ICLR Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are able to model the complex\nhighdimensional distributions of real-world data, which suggests they could be\neffective for anomaly detection. However, few works have explored the use of\nGANs for the anomaly detection task. We leverage recently developed GAN models\nfor anomaly detection, and achieve state-of-the-art performance on image and\nnetwork intrusion datasets, while being several hundred-fold faster at test\ntime than the only published GAN-based method.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 11:26:53 GMT"}, {"version": "v2", "created": "Wed, 1 May 2019 21:54:16 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Zenati", "Houssam", ""], ["Foo", "Chuan Sheng", ""], ["Lecouat", "Bruno", ""], ["Manek", "Gaurav", ""], ["Chandrasekhar", "Vijay Ramaseshan", ""]]}, {"id": "1802.06225", "submitter": "Petros Giannakopoulos", "authors": "Petros Giannakopoulos, Yannis Cotronis", "title": "A Deep Q-Learning Agent for the L-Game with Variable Batch Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ the Deep Q-Learning algorithm with Experience Replay to train an\nagent capable of achieving a high-level of play in the L-Game while\nself-learning from low-dimensional states. We also employ variable batch size\nfor training in order to mitigate the loss of the rare reward signal and\nsignificantly accelerate training. Despite the large action space due to the\nnumber of possible moves, the low-dimensional state space and the rarity of\nrewards, which only come at the end of a game, DQL is successful in training an\nagent capable of strong play without the use of any search methods or domain\nknowledge.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 11:45:09 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Giannakopoulos", "Petros", ""], ["Cotronis", "Yannis", ""]]}, {"id": "1802.06260", "submitter": "Naji Khosravan", "authors": "Naji Khosravan, Haydar Celik, Baris Turkbey, Elizabeth Jones, Bradford\n  Wood, Ulas Bagci", "title": "A Collaborative Computer Aided Diagnosis (C-CAD) System with\n  Eye-Tracking, Sparse Attentional Model, and Deep Learning", "comments": "Submitted to Medical Image Analysis Journal (MedIA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are at least two categories of errors in radiology screening that can\nlead to suboptimal diagnostic decisions and interventions:(i)human fallibility\nand (ii)complexity of visual search. Computer aided diagnostic (CAD) tools are\ndeveloped to help radiologists to compensate for some of these errors. However,\ndespite their significant improvements over conventional screening strategies,\nmost CAD systems do not go beyond their use as second opinion tools due to\nproducing a high number of false positives, which human interpreters need to\ncorrect. In parallel with efforts in computerized analysis of radiology scans,\nseveral researchers have examined behaviors of radiologists while screening\nmedical images to better understand how and why they miss tumors, how they\ninteract with the information in an image, and how they search for unknown\npathology in the images. Eye-tracking tools have been instrumental in exploring\nanswers to these fundamental questions. In this paper, we aim to develop a\nparadigm shift CAD system, called collaborative CAD (C-CAD), that unifies both\nof the above mentioned research lines: CAD and eye-tracking. We design an\neye-tracking interface providing radiologists with a real radiology reading\nroom experience. Then, we propose a novel algorithm that unifies eye-tracking\ndata and a CAD system. Specifically, we present a new graph based clustering\nand sparsification algorithm to transform eye-tracking data (gaze) into a\nsignal model to interpret gaze patterns quantitatively and qualitatively. The\nproposed C-CAD collaborates with radiologists via eye-tracking technology and\nhelps them to improve diagnostic decisions. The C-CAD learns radiologists'\nsearch efficiency by processing their gaze patterns. To do this, the C-CAD uses\na deep learning algorithm in a newly designed multi-task learning platform to\nsegment and diagnose cancers simultaneously.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 17:20:50 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 15:06:18 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Khosravan", "Naji", ""], ["Celik", "Haydar", ""], ["Turkbey", "Baris", ""], ["Jones", "Elizabeth", ""], ["Wood", "Bradford", ""], ["Bagci", "Ulas", ""]]}, {"id": "1802.06266", "submitter": "Hrushikesh Mhaskar", "authors": "Hrushikesh Mhaskar, Tomaso Poggio", "title": "An analysis of training and generalization errors in shallow and deep\n  networks", "comments": "21 pages; Accepted for publication in Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is motivated by an open problem around deep networks, namely, the\napparent absence of over-fitting despite large over-parametrization which\nallows perfect fitting of the training data. In this paper, we analyze this\nphenomenon in the case of regression problems when each unit evaluates a\nperiodic activation function. We argue that the minimal expected value of the\nsquare loss is inappropriate to measure the generalization error in\napproximation of compositional functions in order to take full advantage of the\ncompositional structure. Instead, we measure the generalization error in the\nsense of maximum loss, and sometimes, as a pointwise error. We give estimates\non exactly how many parameters ensure both zero training error as well as a\ngood generalization error. We prove that a solution of a regularization problem\nis guaranteed to yield a good training error as well as a good generalization\nerror and estimate how much error to expect at which test data.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 17:50:19 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 03:20:24 GMT"}, {"version": "v3", "created": "Sat, 13 Jul 2019 04:56:49 GMT"}, {"version": "v4", "created": "Tue, 27 Aug 2019 05:18:04 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Mhaskar", "Hrushikesh", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1802.06286", "submitter": "Yuanxin Li", "authors": "Yuanxin Li and Cong Ma and Yuxin Chen and Yuejie Chi", "title": "Nonconvex Matrix Factorization from Rank-One Measurements", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering low-rank matrices from random rank-one\nmeasurements, which spans numerous applications including covariance sketching,\nphase retrieval, quantum state tomography, and learning shallow polynomial\nneural networks, among others. Our approach is to directly estimate the\nlow-rank factor by minimizing a nonconvex quadratic loss function via vanilla\ngradient descent, following a tailored spectral initialization. When the true\nrank is small, this algorithm is guaranteed to converge to the ground truth (up\nto global ambiguity) with near-optimal sample complexity and computational\ncomplexity. To the best of our knowledge, this is the first guarantee that\nachieves near-optimality in both metrics. In particular, the key enabler of\nnear-optimal computational guarantees is an implicit regularization phenomenon:\nwithout explicit regularization, both spectral initialization and the gradient\ndescent iterates automatically stay within a region incoherent with the\nmeasurement vectors. This feature allows one to employ much more aggressive\nstep sizes compared with the ones suggested in prior literature, without the\nneed of sample splitting.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 20:30:47 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 05:37:06 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Li", "Yuanxin", ""], ["Ma", "Cong", ""], ["Chen", "Yuxin", ""], ["Chi", "Yuejie", ""]]}, {"id": "1802.06287", "submitter": "Allon G. Percus", "authors": "Justin Sunu, Blake Hunter, Allon G. Percus", "title": "Unsupervised vehicle recognition using incremental reseeding of acoustic\n  signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle recognition and classification have broad applications, ranging from\ntraffic flow management to military target identification. We demonstrate an\nunsupervised method for automated identification of moving vehicles from\nroadside audio sensors. Using a short-time Fourier transform to decompose audio\nsignals, we treat the frequency signature in each time window as an individual\ndata point. We then use a spectral embedding for dimensionality reduction.\nBased on the leading eigenvectors, we relate the performance of an incremental\nreseeding algorithm to that of spectral clustering. We find that incremental\nreseeding accurately identifies individual vehicles using their acoustic\nsignatures.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 20:36:54 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Sunu", "Justin", ""], ["Hunter", "Blake", ""], ["Percus", "Allon G.", ""]]}, {"id": "1802.06292", "submitter": "Fan Zhou", "authors": "Fan Zhou", "title": "Nonparametric Estimation of Low Rank Matrix Valued Function", "comments": null, "journal-ref": null, "doi": "10.1214/19-EJS1582", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A:[0,1]\\rightarrow\\mathbb{H}_m$ (the space of Hermitian matrices) be a\nmatrix valued function which is low rank with entries in H\\\"{o}lder class\n$\\Sigma(\\beta,L)$. The goal of this paper is to study statistical estimation of\n$A$ based on the regression model $\\mathbb{E}(Y_j|\\tau_j,X_j) = \\langle\nA(\\tau_j), X_j \\rangle,$ where $\\tau_j$ are i.i.d. uniformly distributed in\n$[0,1]$, $X_j$ are i.i.d. matrix completion sampling matrices, $Y_j$ are\nindependent bounded responses. We propose an innovative nuclear norm penalized\nlocal polynomial estimator and establish an upper bound on its point-wise risk\nmeasured by Frobenius norm. Then we extend this estimator globally and prove an\nupper bound on its integrated risk measured by $L_2$-norm. We also propose\nanother new estimator based on bias-reducing kernels to study the case when $A$\nis not necessarily low rank and establish an upper bound on its risk measured\nby $L_{\\infty}$-norm. We show that the obtained rates are all optimal up to\nsome logarithmic factor in minimax sense. Finally, we propose an adaptive\nestimation procedure based on Lepskii's method and model selection with data\nsplitting which is computationally efficient and can be easily implemented and\nparallelized.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 20:56:33 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 02:21:13 GMT"}, {"version": "v3", "created": "Sun, 14 Apr 2019 21:58:45 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhou", "Fan", ""]]}, {"id": "1802.06293", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky and Francesco Orabona", "title": "Black-Box Reductions for Parameter-free Online Learning in Banach Spaces", "comments": "Appears in Conference on Learning Theory 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce several new black-box reductions that significantly improve the\ndesign of adaptive and parameter-free online learning algorithms by simplifying\nanalysis, improving regret guarantees, and sometimes even improving runtime. We\nreduce parameter-free online learning to online exp-concave optimization, we\nreduce optimization in a Banach space to one-dimensional optimization, and we\nreduce optimization over a constrained domain to unconstrained optimization.\nAll of our reductions run as fast as online gradient descent. We use our new\ntechniques to improve upon the previously best regret bounds for parameter-free\nlearning, and do so for arbitrary norms.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 20:59:02 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 02:17:16 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Cutkosky", "Ashok", ""], ["Orabona", "Francesco", ""]]}, {"id": "1802.06300", "submitter": "Kaspar Wuthrich", "authors": "Victor Chernozhukov and Kaspar Wuthrich and Yinchu Zhu", "title": "Exact and Robust Conformal Inference Methods for Predictive Machine\n  Learning With Dependent Data", "comments": null, "journal-ref": "Proceedings of COLT 2018 (PMLR 75:732-749)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend conformal inference to general settings that allow for time series\ndata. Our proposal is developed as a randomization method and accounts for\npotential serial dependence by including block structures in the permutation\nscheme. As a result, the proposed method retains the exact, model-free validity\nwhen the data are i.i.d. or more generally exchangeable, similar to usual\nconformal inference methods. When exchangeability fails, as is the case for\ncommon time series data, the proposed approach is approximately valid under\nweak assumptions on the conformity score.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 21:43:28 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 20:17:34 GMT"}, {"version": "v3", "created": "Thu, 12 Jul 2018 09:16:27 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Wuthrich", "Kaspar", ""], ["Zhu", "Yinchu", ""]]}, {"id": "1802.06305", "submitter": "Mohammad Saeid Mahdavinejad", "authors": "Mohammad Saeid Mahdavinejad, Mohammadreza Rezvan, Mohammadamin\n  Barekatain, Peyman Adibi, Payam Barnaghi, Amit P. Sheth", "title": "Machine learning for Internet of Things data analysis: A survey", "comments": "Digital Communications and Networks (2017)", "journal-ref": null, "doi": "10.1016/j.dcan.2017.10.002", "report-no": null, "categories": "cs.LG cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid developments in hardware, software, and communication technologies have\nallowed the emergence of Internet-connected sensory devices that provide\nobservation and data measurement from the physical world. By 2020, it is\nestimated that the total number of Internet-connected devices being used will\nbe between 25 and 50 billion. As the numbers grow and technologies become more\nmature, the volume of data published will increase. Internet-connected devices\ntechnology, referred to as Internet of Things (IoT), continues to extend the\ncurrent Internet by providing connectivity and interaction between the physical\nand cyber worlds. In addition to increased volume, the IoT generates Big Data\ncharacterized by velocity in terms of time and location dependency, with a\nvariety of multiple modalities and varying data quality. Intelligent processing\nand analysis of this Big Data is the key to developing smart IoT applications.\nThis article assesses the different machine learning methods that deal with the\nchallenges in IoT data by considering smart cities as the main use case. The\nkey contribution of this study is presentation of a taxonomy of machine\nlearning algorithms explaining how different techniques are applied to the data\nin order to extract higher level information. The potential and challenges of\nmachine learning for IoT data analytics will also be discussed. A use case of\napplying Support Vector Machine (SVM) on Aarhus Smart City traffic data is\npresented for a more detailed exploration.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 22:37:17 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Mahdavinejad", "Mohammad Saeid", ""], ["Rezvan", "Mohammadreza", ""], ["Barekatain", "Mohammadamin", ""], ["Adibi", "Peyman", ""], ["Barnaghi", "Payam", ""], ["Sheth", "Amit P.", ""]]}, {"id": "1802.06306", "submitter": "Ziming Li", "authors": "Ziming Li, Julia Kiseleva, Alekh Agarwal, Maarten de Rijke", "title": "Learning Data-Driven Objectives to Optimize Interactive Systems", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective optimization is essential for interactive systems to provide a\nsatisfactory user experience. However, it is often challenging to find an\nobjective to optimize for. Generally, such objectives are manually crafted and\nrarely capture complex user needs in an accurate manner. We propose an approach\nthat infers the objective directly from observed user interactions. These\ninferences can be made regardless of prior knowledge and across different types\nof user behavior. We introduce interactive system optimization, a novel\nalgorithm that uses these inferred objectives for optimization. Our main\ncontribution is a new general principled approach to optimizing interactive\nsystems using data-driven objectives. We demonstrate the high effectiveness of\ninteractive system optimization over several simulations.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 23:04:15 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 09:09:57 GMT"}, {"version": "v3", "created": "Fri, 13 Apr 2018 17:24:19 GMT"}, {"version": "v4", "created": "Wed, 2 May 2018 14:45:08 GMT"}, {"version": "v5", "created": "Tue, 8 May 2018 15:33:21 GMT"}, {"version": "v6", "created": "Tue, 16 Oct 2018 15:54:49 GMT"}, {"version": "v7", "created": "Wed, 17 Oct 2018 10:25:51 GMT"}, {"version": "v8", "created": "Fri, 13 Dec 2019 22:11:21 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Li", "Ziming", ""], ["Kiseleva", "Julia", ""], ["Agarwal", "Alekh", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1802.06309", "submitter": "Elliot Creager", "authors": "David Madras, Elliot Creager, Toniann Pitassi, Richard Zemel", "title": "Learning Adversarially Fair and Transferable Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we advocate for representation learning as the key to\nmitigating unfair prediction outcomes downstream. Motivated by a scenario where\nlearned representations are used by third parties with unknown objectives, we\npropose and explore adversarial representation learning as a natural method of\nensuring those parties act fairly. We connect group fairness (demographic\nparity, equalized odds, and equal opportunity) to different adversarial\nobjectives. Through worst-case theoretical guarantees and experimental\nvalidation, we show that the choice of this objective is crucial to fair\nprediction. Furthermore, we present the first in-depth experimental\ndemonstration of fair transfer learning and demonstrate empirically that our\nlearned representations admit fair predictions on new tasks while maintaining\nutility, an essential goal of fair representation learning.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 23:38:29 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 17:37:44 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 17:01:59 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Madras", "David", ""], ["Creager", "Elliot", ""], ["Pitassi", "Toniann", ""], ["Zemel", "Richard", ""]]}, {"id": "1802.06338", "submitter": "Seong Hyeon Park", "authors": "Seong Hyeon Park, ByeongDo Kim, Chang Mook Kang, Chung Choo Chung and\n  Jun Won Choi", "title": "Sequence-to-Sequence Prediction of Vehicle Trajectory via LSTM\n  Encoder-Decoder Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep learning based vehicle trajectory prediction\ntechnique which can generate the future trajectory sequence of surrounding\nvehicles in real time. We employ the encoder-decoder architecture which\nanalyzes the pattern underlying in the past trajectory using the long\nshort-term memory (LSTM) based encoder and generates the future trajectory\nsequence using the LSTM based decoder. This structure produces the $K$ most\nlikely trajectory candidates over occupancy grid map by employing the beam\nsearch technique which keeps the $K$ locally best candidates from the decoder\noutput. The experiments conducted on highway traffic scenarios show that the\nprediction accuracy of the proposed method is significantly higher than the\nconventional trajectory prediction techniques.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 06:15:07 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 06:30:11 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 04:18:44 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Park", "Seong Hyeon", ""], ["Kim", "ByeongDo", ""], ["Kang", "Chang Mook", ""], ["Chung", "Chung Choo", ""], ["Choi", "Jun Won", ""]]}, {"id": "1802.06355", "submitter": "Insu Han", "authors": "Insu Han, Haim Avron, Jinwoo Shin", "title": "Stochastic Chebyshev Gradient Descent for Spectral Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large class of machine learning techniques requires the solution of\noptimization problems involving spectral functions of parametric matrices, e.g.\nlog-determinant and nuclear norm. Unfortunately, computing the gradient of a\nspectral function is generally of cubic complexity, as such gradient descent\nmethods are rather expensive for optimizing objectives involving the spectral\nfunction. Thus, one naturally turns to stochastic gradient methods in hope that\nthey will provide a way to reduce or altogether avoid the computation of full\ngradients. However, here a new challenge appears: there is no straightforward\nway to compute unbiased stochastic gradients for spectral functions. In this\npaper, we develop unbiased stochastic gradients for spectral-sums, an important\nsubclass of spectral functions. Our unbiased stochastic gradients are based on\ncombining randomized trace estimators with stochastic truncation of the\nChebyshev expansions. A careful design of the truncation distribution allows us\nto offer distributions that are variance-optimal, which is crucial for fast and\nstable convergence of stochastic gradient methods. We further leverage our\nproposed stochastic gradients to devise stochastic methods for objective\nfunctions involving spectral-sums, and rigorously analyze their convergence\nrate. The utility of our methods is demonstrated in numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 09:15:56 GMT"}, {"version": "v2", "created": "Sun, 2 Sep 2018 16:04:16 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 14:46:55 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Han", "Insu", ""], ["Avron", "Haim", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1802.06357", "submitter": "Yunwen Lei", "authors": "Yunwen Lei and Ding-Xuan Zhou", "title": "Convergence of Online Mirror Descent", "comments": "Published in Applied and Computational Harmonic Analysis, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider online mirror descent (OMD) algorithms, a class of\nscalable online learning algorithms exploiting data geometric structures\nthrough mirror maps. Necessary and sufficient conditions are presented in terms\nof the step size sequence $\\{\\eta_t\\}_{t}$ for the convergence of an OMD\nalgorithm with respect to the expected Bregman distance induced by the mirror\nmap. The condition is $\\lim_{t\\to\\infty}\\eta_t=0,\n\\sum_{t=1}^{\\infty}\\eta_t=\\infty$ in the case of positive variances. It is\nreduced to $\\sum_{t=1}^{\\infty}\\eta_t=\\infty$ in the case of zero variances for\nwhich the linear convergence may be achieved by taking a constant step size\nsequence. A sufficient condition on the almost sure convergence is also given.\nWe establish tight error bounds under mild conditions on the mirror map, the\nloss function, and the regularizer. Our results are achieved by some novel\nanalysis on the one-step progress of the OMD algorithm using smoothness and\nstrong convexity of the mirror map and the loss function.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 09:36:09 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 05:44:02 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Lei", "Yunwen", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1802.06360", "submitter": "Raghav Chalapathy", "authors": "Raghavendra Chalapathy (University of Sydney and Capital Markets\n  Cooperative Research Centre (CMCRC)), Aditya Krishna Menon (Data61/CSIRO and\n  the Australian National University), Sanjay Chawla (Qatar Computing Research\n  Institute (QCRI), HBKU)", "title": "Anomaly Detection using One-Class Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a one-class neural network (OC-NN) model to detect anomalies in\ncomplex data sets. OC-NN combines the ability of deep networks to extract a\nprogressively rich representation of data with the one-class objective of\ncreating a tight envelope around normal data. The OC-NN approach breaks new\nground for the following crucial reason: data representation in the hidden\nlayer is driven by the OC-NN objective and is thus customized for anomaly\ndetection. This is a departure from other approaches which use a hybrid\napproach of learning deep features using an autoencoder and then feeding the\nfeatures into a separate anomaly detection method like one-class SVM (OC-SVM).\nThe hybrid OC-SVM approach is sub-optimal because it is unable to influence\nrepresentational learning in the hidden layers. A comprehensive set of\nexperiments demonstrate that on complex data sets (like CIFAR and GTSRB), OC-NN\nperforms on par with state-of-the-art methods and outperformed conventional\nshallow methods in some scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 10:44:53 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 00:05:05 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Chalapathy", "Raghavendra", "", "University of Sydney and Capital Markets\n  Cooperative Research Centre"], ["Menon", "Aditya Krishna", "", "Data61/CSIRO and\n  the Australian National University"], ["Chawla", "Sanjay", "", "Qatar Computing Research\n  Institute"]]}, {"id": "1802.06367", "submitter": "Xingyu Liu", "authors": "Xingyu Liu, Jeff Pool, Song Han, William J. Dally", "title": "Efficient Sparse-Winograd Convolutional Neural Networks", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are computationally intensive, which\nlimits their application on mobile devices. Their energy is dominated by the\nnumber of multiplies needed to perform the convolutions. Winograd's minimal\nfiltering algorithm (Lavin, 2015) and network pruning (Han et al., 2015) can\nreduce the operation count, but these two methods cannot be directly combined\n$-$ applying the Winograd transform fills in the sparsity in both the weights\nand the activations. We propose two modifications to Winograd-based CNNs to\nenable these methods to exploit sparsity. First, we move the ReLU operation\ninto the Winograd domain to increase the sparsity of the transformed\nactivations. Second, we prune the weights in the Winograd domain to exploit\nstatic weight sparsity. For models on CIFAR-10, CIFAR-100 and ImageNet\ndatasets, our method reduces the number of multiplications by $10.4\\times$,\n$6.8\\times$ and $10.8\\times$ respectively with loss of accuracy less than\n$0.1\\%$, outperforming previous baselines by $2.0\\times$-$3.0\\times$. We also\nshow that moving ReLU to the Winograd domain allows more aggressive pruning.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 12:29:05 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Liu", "Xingyu", ""], ["Pool", "Jeff", ""], ["Han", "Song", ""], ["Dally", "William J.", ""]]}, {"id": "1802.06368", "submitter": "Kento Nozawa", "authors": "Kento Nozawa, Masanari Kimura, Atsunori Kanemura", "title": "Node Centralities and Classification Performance for Characterizing Node\n  Embedding Algorithms", "comments": "Under review at ICLR 2018 workshop track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding graph nodes into a vector space can allow the use of machine\nlearning to e.g. predict node classes, but the study of node embedding\nalgorithms is immature compared to the natural language processing field\nbecause of a diverse nature of graphs. We examine the performance of node\nembedding algorithms with respect to graph centrality measures that\ncharacterize diverse graphs, through systematic experiments with four node\nembedding algorithms, four or five graph centralities, and six datasets.\nExperimental results give insights into the properties of node embedding\nalgorithms, which can be a basis for further research on this topic.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 13:03:08 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Nozawa", "Kento", ""], ["Kimura", "Masanari", ""], ["Kanemura", "Atsunori", ""]]}, {"id": "1802.06371", "submitter": "Madhav Nimishakavi Mr", "authors": "Madhav Nimishakavi, Bamdev Mishra, Manish Gupta, and Partha Talukdar", "title": "Inductive Framework for Multi-Aspect Streaming Tensor Completion with\n  Side Information", "comments": "Accepted to International Conference on Information and Knowledge\n  Management (CIKM), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low rank tensor completion is a well studied problem and has applications in\nvarious fields. However, in many real world applications the data is dynamic,\ni.e., new data arrives at different time intervals. As a result, the tensors\nused to represent the data grow in size. Besides the tensors, in many real\nworld scenarios, side information is also available in the form of matrices\nwhich also grow in size with time. The problem of predicting missing values in\nthe dynamically growing tensor is called dynamic tensor completion. Most of the\nprevious work in dynamic tensor completion make an assumption that the tensor\ngrows only in one mode. To the best of our Knowledge, there is no previous work\nwhich incorporates side information with dynamic tensor completion. We bridge\nthis gap in this paper by proposing a dynamic tensor completion framework\ncalled Side Information infused Incremental Tensor Analysis (SIITA), which\nincorporates side information and works for general incremental tensors. We\nalso show how non-negative constraints can be incorporated with SIITA, which is\nessential for mining interpretable latent clusters. We carry out extensive\nexperiments on multiple real world datasets to demonstrate the effectiveness of\nSIITA in various different settings.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 13:06:39 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 13:41:40 GMT"}, {"version": "v3", "created": "Sat, 1 Sep 2018 10:28:07 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Nimishakavi", "Madhav", ""], ["Mishra", "Bamdev", ""], ["Gupta", "Manish", ""], ["Talukdar", "Partha", ""]]}, {"id": "1802.06382", "submitter": "Yasuo Tabei", "authors": "Yasuo Tabei, Yoshihiro Yamanishi, Rasmus Pagh", "title": "Space-efficient Feature Maps for String Alignment Kernels", "comments": "Full version for ICDM'19 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String kernels are attractive data analysis tools for analyzing string data.\nAmong them, alignment kernels are known for their high prediction accuracies in\nstring classifications when tested in combination with SVM in various\napplications. However, alignment kernels have a crucial drawback in that they\nscale poorly due to their quadratic computation complexity in the number of\ninput strings, which limits large-scale applications in practice. We address\nthis need by presenting the first approximation for string alignment kernels,\nwhich we call space-efficient feature maps for edit distance with moves\n(SFMEDM), by leveraging a metric embedding named edit sensitive parsing (ESP)\nand feature maps (FMs) of random Fourier features (RFFs) for large-scale string\nanalyses. The original FMs for RFFs consume a huge amount of memory\nproportional to the dimension d of input vectors and the dimension D of output\nvectors, which prohibits its large-scale applications. We present novel\nspace-efficient feature maps (SFMs) of RFFs for a space reduction from O(dD) of\nthe original FMs to O(d) of SFMs with a theoretical guarantee with respect to\nconcentration bounds. We experimentally test SFMEDM on its ability to learn SVM\nfor large-scale string classifications with various massive string data, and we\ndemonstrate the superior performance of SFMEDM with respect to prediction\naccuracy, scalability and computation efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 14:16:28 GMT"}, {"version": "v10", "created": "Thu, 14 Nov 2019 02:42:51 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 06:29:59 GMT"}, {"version": "v3", "created": "Wed, 7 Mar 2018 14:37:53 GMT"}, {"version": "v4", "created": "Sun, 25 Mar 2018 05:46:27 GMT"}, {"version": "v5", "created": "Wed, 28 Mar 2018 01:33:34 GMT"}, {"version": "v6", "created": "Wed, 6 Feb 2019 08:45:03 GMT"}, {"version": "v7", "created": "Mon, 26 Aug 2019 08:36:23 GMT"}, {"version": "v8", "created": "Mon, 2 Sep 2019 07:04:07 GMT"}, {"version": "v9", "created": "Tue, 10 Sep 2019 08:15:08 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Tabei", "Yasuo", ""], ["Yamanishi", "Yoshihiro", ""], ["Pagh", "Rasmus", ""]]}, {"id": "1802.06383", "submitter": "Florian Wenzel", "authors": "Florian Wenzel, Theo Galy-Fajou, Christan Donner, Marius Kloft,\n  Manfred Opper", "title": "Efficient Gaussian Process Classification Using Polya-Gamma Data\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scalable stochastic variational approach to GP classification\nbuilding on Polya-Gamma data augmentation and inducing points. Unlike former\napproaches, we obtain closed-form updates based on natural gradients that lead\nto efficient optimization. We evaluate the algorithm on real-world datasets\ncontaining up to 11 million data points and demonstrate that it is up to two\norders of magnitude faster than the state-of-the-art while being competitive in\nterms of prediction performance.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 14:20:54 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 10:43:32 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Wenzel", "Florian", ""], ["Galy-Fajou", "Theo", ""], ["Donner", "Christan", ""], ["Kloft", "Marius", ""], ["Opper", "Manfred", ""]]}, {"id": "1802.06384", "submitter": "Luca Venturi", "authors": "Luca Venturi, Afonso S. Bandeira, Joan Bruna", "title": "Spurious Valleys in Two-layer Neural Network Optimization Landscapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks provide a rich class of high-dimensional, non-convex\noptimization problems. Despite their non-convexity, gradient-descent methods\noften successfully optimize these models. This has motivated a recent spur in\nresearch attempting to characterize properties of their loss surface that may\nexplain such success.\n  In this paper, we address this phenomenon by studying a key topological\nproperty of the loss: the presence or absence of spurious valleys, defined as\nconnected components of sub-level sets that do not include a global minimum.\nFocusing on a class of two-layer neural networks defined by smooth (but\ngenerally non-linear) activation functions, we identify a notion of intrinsic\ndimension and show that it provides necessary and sufficient conditions for the\nabsence of spurious valleys. More concretely, finite intrinsic dimension\nguarantees that for sufficiently overparametrised models no spurious valleys\nexist, independently of the data distribution. Conversely, infinite intrinsic\ndimension implies that spurious valleys do exist for certain data\ndistributions, independently of model overparametrisation. Besides these\npositive and negative results, we show that, although spurious valleys may\nexist in general, they are confined to low risk levels and avoided with high\nprobability on overparametrised models.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 14:23:44 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 17:54:56 GMT"}, {"version": "v3", "created": "Wed, 26 Sep 2018 13:39:18 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 02:17:45 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Venturi", "Luca", ""], ["Bandeira", "Afonso S.", ""], ["Bruna", "Joan", ""]]}, {"id": "1802.06394", "submitter": "Fabian Gieseke", "authors": "Fabian Gieseke and Christian Igel", "title": "Training Big Random Forests with Little Resources", "comments": "9 pages, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Without access to large compute clusters, building random forests on large\ndatasets is still a challenging problem. This is, in particular, the case if\nfully-grown trees are desired. We propose a simple yet effective framework that\nallows to efficiently construct ensembles of huge trees for hundreds of\nmillions or even billions of training instances using a cheap desktop computer\nwith commodity hardware. The basic idea is to consider a multi-level\nconstruction scheme, which builds top trees for small random subsets of the\navailable data and which subsequently distributes all training instances to the\ntop trees' leaves for further processing. While being conceptually simple, the\noverall efficiency crucially depends on the particular implementation of the\ndifferent phases. The practical merits of our approach are demonstrated using\ndense datasets with hundreds of millions of training instances.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 15:56:28 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Gieseke", "Fabian", ""], ["Igel", "Christian", ""]]}, {"id": "1802.06398", "submitter": "Evgeny Frolov", "authors": "Evgeny Frolov and Ivan Oseledets", "title": "HybridSVD: When Collaborative Information is Not Enough", "comments": "accepted as a long paper at ACM RecSys 2019; 9 pages, 2 figures, 2\n  tables", "journal-ref": null, "doi": "10.1145/3298689.3347055", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new hybrid algorithm that allows incorporating both user and\nitem side information within the standard collaborative filtering technique.\nOne of its key features is that it naturally extends a simple PureSVD approach\nand inherits its unique advantages, such as highly efficient Lanczos-based\noptimization procedure, simplified hyper-parameter tuning and a quick\nfolding-in computation for generating recommendations instantly even in highly\ndynamic online environments. The algorithm utilizes a generalized formulation\nof the singular value decomposition, which adds flexibility to the solution and\nallows imposing the desired structure on its latent space. Conveniently, the\nresulting model also admits an efficient and straightforward solution for the\ncold start scenario. We evaluate our approach on a diverse set of datasets and\nshow its superiority over similar classes of hybrid models.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 16:39:01 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 13:45:53 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 18:30:37 GMT"}, {"version": "v4", "created": "Tue, 13 Aug 2019 10:03:18 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Frolov", "Evgeny", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1802.06402", "submitter": "Caiwen Ding", "authors": "Yanzhi Wang, Caiwen Ding, Zhe Li, Geng Yuan, Siyu Liao, Xiaolong Ma,\n  Bo Yuan, Xuehai Qian, Jian Tang, Qinru Qiu, Xue Lin", "title": "Towards Ultra-High Performance and Energy Efficiency of Deep Learning\n  Systems: An Algorithm-Hardware Co-Optimization Framework", "comments": "6 figures, AAAI Conference on Artificial Intelligence, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware accelerations of deep learning systems have been extensively\ninvestigated in industry and academia. The aim of this paper is to achieve\nultra-high energy efficiency and performance for hardware implementations of\ndeep neural networks (DNNs). An algorithm-hardware co-optimization framework is\ndeveloped, which is applicable to different DNN types, sizes, and application\nscenarios. The algorithm part adopts the general block-circulant matrices to\nachieve a fine-grained tradeoff between accuracy and compression ratio. It\napplies to both fully-connected and convolutional layers and contains a\nmathematically rigorous proof of the effectiveness of the method. The proposed\nalgorithm reduces computational complexity per layer from O($n^2$) to O($n\\log\nn$) and storage complexity from O($n^2$) to O($n$), both for training and\ninference. The hardware part consists of highly efficient Field Programmable\nGate Array (FPGA)-based implementations using effective reconfiguration, batch\nprocessing, deep pipelining, resource re-using, and hierarchical control.\nExperimental results demonstrate that the proposed framework achieves at least\n152X speedup and 71X energy efficiency gain compared with IBM TrueNorth\nprocessor under the same test accuracy. It achieves at least 31X energy\nefficiency gain compared with the reference FPGA-based work.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 16:51:04 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Wang", "Yanzhi", ""], ["Ding", "Caiwen", ""], ["Li", "Zhe", ""], ["Yuan", "Geng", ""], ["Liao", "Siyu", ""], ["Ma", "Xiaolong", ""], ["Yuan", "Bo", ""], ["Qian", "Xuehai", ""], ["Tang", "Jian", ""], ["Qiu", "Qinru", ""], ["Lin", "Xue", ""]]}, {"id": "1802.06403", "submitter": "Jinsung Yoon", "authors": "Jinsung Yoon, James Jordon, Mihaela van der Schaar", "title": "RadialGAN: Leveraging multiple datasets to improve target-specific\n  predictive models using Generative Adversarial Networks", "comments": "12 pages, 8 figures, 2018 International Conference of Machine\n  Learning (2018 ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training complex machine learning models for prediction often requires a\nlarge amount of data that is not always readily available. Leveraging these\nexternal datasets from related but different sources is therefore an important\ntask if good predictive models are to be built for deployment in settings where\ndata can be rare. In this paper we propose a novel approach to the problem in\nwhich we use multiple GAN architectures to learn to translate from one dataset\nto another, thereby allowing us to effectively enlarge the target dataset, and\ntherefore learn better predictive models than if we simply used the target\ndataset. We show the utility of such an approach, demonstrating that our method\nimproves the prediction performance on the target domain over using just the\ntarget dataset and also show that our framework outperforms several other\nbenchmarks on a collection of real-world medical datasets.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 16:55:15 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 23:14:31 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Yoon", "Jinsung", ""], ["Jordon", "James", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1802.06416", "submitter": "Zhenqiang Su", "authors": "Yongxi Tan, Jin Yang, Xin Chen, Qitao Song, Yunjun Chen, Zhangxiang\n  Ye, Zhenqiang Su", "title": "Sim-to-Real Optimization of Complex Real World Mobile Network with\n  Imperfect Information via Deep Reinforcement Learning from Self-play", "comments": "Accepted by NIPS 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile network that millions of people use every day is one of the most\ncomplex systems in the world. Optimization of mobile network to meet exploding\ncustomer demand and reduce capital/operation expenditures poses great\nchallenges. Despite recent progress, application of deep reinforcement learning\n(DRL) to complex real world problem still remains unsolved, given data\nscarcity, partial observability, risk and complex rules/dynamics in real world,\nas well as the huge reality gap between simulation and real world. To bridge\nthe reality gap, we introduce a Sim-to-Real framework to directly transfer\nlearning from simulation to real world via graph convolutional neural network\n(CNN) - by abstracting partially observable mobile network into graph, then\ndistilling domain-variant irregular graph into domain-invariant tensor in\nlocally Euclidean space as input to CNN -, domain randomization and multi-task\nlearning. We use a novel self-play mechanism to encourage competition among DRL\nagents for best record on multiple tasks via simulated annealing, just like\nathletes compete for world record in decathlon. We also propose a decentralized\nmulti-agent, competitive and cooperative DRL method to coordinate the actions\nof multi-cells to maximize global reward and minimize negative impact to\nneighbor cells. Using 6 field trials on commercial mobile networks, we\ndemonstrate for the first time that a DRL agent can successfully transfer\nlearning from simulation to complex real world problem with imperfect\ninformation, complex rules/dynamics, huge state/action space, and multi-agent\ninteractions, without any training in the real world.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 18:03:39 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 23:45:16 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 12:09:16 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Tan", "Yongxi", ""], ["Yang", "Jin", ""], ["Chen", "Xin", ""], ["Song", "Qitao", ""], ["Chen", "Yunjun", ""], ["Ye", "Zhangxiang", ""], ["Su", "Zhenqiang", ""]]}, {"id": "1802.06428", "submitter": "Fengyi Tang", "authors": "Fengyi Tang, Kaixiang Lin, Ikechukwu Uchendu, Hiroko H. Dodge, Jiayu\n  Zhou", "title": "Improving Mild Cognitive Impairment Prediction via Reinforcement\n  Learning and Dialogue Simulation", "comments": "9 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mild cognitive impairment (MCI) is a prodromal phase in the progression from\nnormal aging to dementia, especially Alzheimers disease. Even though there is\nmild cognitive decline in MCI patients, they have normal overall cognition and\nthus is challenging to distinguish from normal aging. Using transcribed data\nobtained from recorded conversational interactions between participants and\ntrained interviewers, and applying supervised learning models to these data, a\nrecent clinical trial has shown a promising result in differentiating MCI from\nnormal aging. However, the substantial amount of interactions with medical\nstaff can still incur significant medical care expenses in practice. In this\npaper, we propose a novel reinforcement learning (RL) framework to train an\nefficient dialogue agent on existing transcripts from clinical trials.\nSpecifically, the agent is trained to sketch disease-specific lexical\nprobability distribution, and thus to converse in a way that maximizes the\ndiagnosis accuracy and minimizes the number of conversation turns. We evaluate\nthe performance of the proposed reinforcement learning framework on the MCI\ndiagnosis from a real clinical trial. The results show that while using only a\nfew turns of conversation, our framework can significantly outperform\nstate-of-the-art supervised learning approaches.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 19:27:24 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Tang", "Fengyi", ""], ["Lin", "Kaixiang", ""], ["Uchendu", "Ikechukwu", ""], ["Dodge", "Hiroko H.", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1802.06432", "submitter": "Fady Medhat", "authors": "Fady Medhat, David Chesmore, John Robinson", "title": "Music Genre Classification using Masked Conditional Neural Networks", "comments": "Conditional Neural Networks (CLNN), Masked Conditional Neural\n  Networks (MCLNN), Conditional Restricted Boltzmann Machine (CRBM), Deep\n  Belief Nets (DBN), Music Information Retrieval (MIR)", "journal-ref": "International Conference on Neural Information Processing (ICONIP)\n  Year: 2017, Pages: 470-481", "doi": "10.1007/978-3-319-70096-0_49", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ConditionaL Neural Networks (CLNN) and the Masked ConditionaL Neural\nNetworks (MCLNN) exploit the nature of multi-dimensional temporal signals. The\nCLNN captures the conditional temporal influence between the frames in a window\nand the mask in the MCLNN enforces a systematic sparseness that follows a\nfilterbank-like pattern over the network links. The mask induces the network to\nlearn about time-frequency representations in bands, allowing the network to\nsustain frequency shifts. Additionally, the mask in the MCLNN automates the\nexploration of a range of feature combinations, usually done through an\nexhaustive manual search. We have evaluated the MCLNN performance using the\nBallroom and Homburg datasets of music genres. MCLNN has achieved accuracies\nthat are competitive to state-of-the-art handcrafted attempts in addition to\nmodels based on Convolutional Neural Networks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 19:55:09 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 18:14:41 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Medhat", "Fady", ""], ["Chesmore", "David", ""], ["Robinson", "John", ""]]}, {"id": "1802.06439", "submitter": "Maxim Raginsky", "authors": "Belinda Tzen and Tengyuan Liang and Maxim Raginsky", "title": "Local Optimality and Generalization Guarantees for the Langevin\n  Algorithm via Empirical Metastability", "comments": "19 pages", "journal-ref": "Proceedings of the 31st Conference on Learning Theory 75 (2018)\n  857-875", "doi": null, "report-no": null, "categories": "cs.LG math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the detailed path-wise behavior of the discrete-time Langevin\nalgorithm for non-convex Empirical Risk Minimization (ERM) through the lens of\nmetastability, adopting some techniques from Berglund and Gentz (2003.\n  For a particular local optimum of the empirical risk, with an arbitrary\ninitialization, we show that, with high probability, at least one of the\nfollowing two events will occur: (1) the Langevin trajectory ends up somewhere\noutside the $\\varepsilon$-neighborhood of this particular optimum within a\nshort recurrence time; (2) it enters this $\\varepsilon$-neighborhood by the\nrecurrence time and stays there until a potentially exponentially long escape\ntime. We call this phenomenon empirical metastability.\n  This two-timescale characterization aligns nicely with the existing\nliterature in the following two senses. First, the effective recurrence time\n(i.e., number of iterations multiplied by stepsize) is dimension-independent,\nand resembles the convergence time of continuous-time deterministic Gradient\nDescent (GD). However unlike GD, the Langevin algorithm does not require strong\nconditions on local initialization, and has the possibility of eventually\nvisiting all optima. Second, the scaling of the escape time is consistent with\nthe Eyring-Kramers law, which states that the Langevin scheme will eventually\nvisit all local minima, but it will take an exponentially long time to transit\namong them. We apply this path-wise concentration result in the context of\nstatistical learning to examine local notions of generalization and optimality.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 20:34:06 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 16:00:36 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Tzen", "Belinda", ""], ["Liang", "Tengyuan", ""], ["Raginsky", "Maxim", ""]]}, {"id": "1802.06458", "submitter": "Jayaraman J. Thiagarajan", "authors": "Deepta Rajan and Jayaraman J. Thiagarajan", "title": "A Generative Modeling Approach to Limited Channel ECG Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing temporal sequences is central to a variety of applications in\nhealth care, and in particular multi-channel Electrocardiogram (ECG) is a\nhighly prevalent diagnostic modality that relies on robust sequence modeling.\nWhile Recurrent Neural Networks (RNNs) have led to significant advances in\nautomated diagnosis with time-series data, they perform poorly when models are\ntrained using a limited set of channels. A crucial limitation of existing\nsolutions is that they rely solely on discriminative models, which tend to\ngeneralize poorly in such scenarios. In order to combat this limitation, we\ndevelop a generative modeling approach to limited channel ECG classification.\nThis approach first uses a Seq2Seq model to implicitly generate the missing\nchannel information, and then uses the latent representation to perform the\nactual supervisory task. This decoupling enables the use of unsupervised data\nand also provides highly robust metric spaces for subsequent discriminative\nlearning. Our experiments with the Physionet dataset clearly evidence the\neffectiveness of our approach over standard RNNs in disease prediction.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 22:29:31 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 01:53:25 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 01:32:04 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Rajan", "Deepta", ""], ["Thiagarajan", "Jayaraman J.", ""]]}, {"id": "1802.06463", "submitter": "Haoyu Fu", "authors": "Haoyu Fu, Yuejie Chi, Yingbin Liang", "title": "Guaranteed Recovery of One-Hidden-Layer Neural Networks via Cross\n  Entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study model recovery for data classification, where the training labels\nare generated from a one-hidden-layer neural network with sigmoid activations,\nalso known as a single-layer feedforward network, and the goal is to recover\nthe weights of the neural network. We consider two network models, the\nfully-connected network (FCN) and the non-overlapping convolutional neural\nnetwork (CNN). We prove that with Gaussian inputs, the empirical risk based on\ncross entropy exhibits strong convexity and smoothness {\\em uniformly} in a\nlocal neighborhood of the ground truth, as soon as the sample complexity is\nsufficiently large. This implies that if initialized in this neighborhood,\ngradient descent converges linearly to a critical point that is provably close\nto the ground truth. Furthermore, we show such an initialization can be\nobtained via the tensor method. This establishes the global convergence\nguarantee for empirical risk minimization using cross entropy via gradient\ndescent for learning one-hidden-layer neural networks, at the near-optimal\nsample and computational complexity with respect to the network input dimension\nwithout unrealistic assumptions such as requiring a fresh set of samples at\neach iteration.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 22:49:56 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2019 04:40:20 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 04:09:34 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Fu", "Haoyu", ""], ["Chi", "Yuejie", ""], ["Liang", "Yingbin", ""]]}, {"id": "1802.06466", "submitter": "Ying Shan", "authors": "Ying Shan and Jian Jiao and Jie Zhu and JC Mao", "title": "Recurrent Binary Embedding for GPU-Enabled Exhaustive Retrieval from\n  Billion-Scale Semantic Vectors", "comments": "15 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid advances in GPU hardware and multiple areas of Deep Learning open up a\nnew opportunity for billion-scale information retrieval with exhaustive search.\nBuilding on top of the powerful concept of semantic learning, this paper\nproposes a Recurrent Binary Embedding (RBE) model that learns compact\nrepresentations for real-time retrieval. The model has the unique ability to\nrefine a base binary vector by progressively adding binary residual vectors to\nmeet the desired accuracy. The refined vector enables efficient implementation\nof exhaustive similarity computation with bit-wise operations, followed by a\nnear- lossless k-NN selection algorithm, also proposed in this paper. The\nproposed algorithms are integrated into an end-to-end multi-GPU system that\nretrieves thousands of top items from over a billion candidates in real-time.\nThe RBE model and the retrieval system were evaluated with data from a major\npaid search engine. When measured against the state-of-the-art model for binary\nrepresentation and the full precision model for semantic embedding, RBE\nsignificantly outperformed the former, and filled in over 80% of the AUC gap\nin-between. Experiments comparing with our production retrieval system also\ndemonstrated superior performance. While the primary focus of this paper is to\nbuild RBE based on a particular class of semantic models, generalizing to other\ntypes is straightforward, as exemplified by two different models at the end of\nthe paper.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 23:02:58 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Shan", "Ying", ""], ["Jiao", "Jian", ""], ["Zhu", "Jie", ""], ["Mao", "JC", ""]]}, {"id": "1802.06467", "submitter": "Adam Liska", "authors": "Adam Li\\v{s}ka, Germ\\'an Kruszewski, Marco Baroni", "title": "Memorize or generalize? Searching for a compositional RNN in a haystack", "comments": "AEGAP Workshop (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are very powerful learning systems, but they do not readily\ngeneralize from one task to the other. This is partly due to the fact that they\ndo not learn in a compositional way, that is, by discovering skills that are\nshared by different tasks, and recombining them to solve new problems. In this\npaper, we explore the compositional generalization capabilities of recurrent\nneural networks (RNNs). We first propose the lookup table composition domain as\na simple setup to test compositional behaviour and show that it is\ntheoretically possible for a standard RNN to learn to behave compositionally in\nthis domain when trained with standard gradient descent and provided with\nadditional supervision. We then remove this additional supervision and perform\na search over a large number of model initializations to investigate the\nproportion of RNNs that can still converge to a compositional solution. We\ndiscover that a small but non-negligible proportion of RNNs do reach partial\ncompositional solutions even without special architectural constraints. This\nsuggests that a combination of gradient descent and evolutionary strategies\ndirectly favouring the minority models that developed more compositional\napproaches might suffice to lead standard RNNs towards compositional solutions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 23:15:26 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 18:55:27 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Li\u0161ka", "Adam", ""], ["Kruszewski", "Germ\u00e1n", ""], ["Baroni", "Marco", ""]]}, {"id": "1802.06472", "submitter": "Jianjun Yuan", "authors": "Jianjun Yuan, Andrew Lamperski", "title": "Online convex optimization for cumulative constraints", "comments": "The NeurIPS version of the stepsize setup for strongly convex case is\n  not correct. Please see this arxiv setup(e.g.,move the H1 to the denominator)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the algorithms for online convex optimization which lead to\ncumulative squared constraint violations of the form\n$\\sum\\limits_{t=1}^T\\big([g(x_t)]_+\\big)^2=O(T^{1-\\beta})$, where\n$\\beta\\in(0,1)$. Previous literature has focused on long-term constraints of\nthe form $\\sum\\limits_{t=1}^Tg(x_t)$. There, strictly feasible solutions can\ncancel out the effects of violated constraints. In contrast, the new form\nheavily penalizes large constraint violations and cancellation effects cannot\noccur.\n  Furthermore, useful bounds on the single step constraint violation\n$[g(x_t)]_+$ are derived.\n  For convex objectives, our regret bounds generalize existing bounds, and for\nstrongly convex objectives we give improved regret bounds.\n  In numerical experiments, we show that our algorithm closely follows the\nconstraint boundary leading to low cumulative violation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 00:06:47 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 22:14:22 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 19:07:54 GMT"}, {"version": "v4", "created": "Wed, 6 Feb 2019 19:13:08 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Yuan", "Jianjun", ""], ["Lamperski", "Andrew", ""]]}, {"id": "1802.06476", "submitter": "Bin Liu", "authors": "Bin Liu, Ying Li, Soumya Ghosh, Zhaonan Sun, Kenney Ng and Jianying Hu", "title": "Simultaneous Modeling of Multiple Complications for Risk Profiling in\n  Diabetes Care", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, 2019", "doi": "10.1109/TKDE.2019.2904060", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type 2 diabetes mellitus (T2DM) is a chronic disease that often results in\nmultiple complications. Risk prediction and profiling of T2DM complications is\ncritical for healthcare professionals to design personalized treatment plans\nfor patients in diabetes care for improved outcomes. In this paper, we study\nthe risk of developing complications after the initial T2DM diagnosis from\nlongitudinal patient records. We propose a novel multi-task learning approach\nto simultaneously model multiple complications where each task corresponds to\nthe risk modeling of one complication. Specifically, the proposed method\nstrategically captures the relationships (1) between the risks of multiple T2DM\ncomplications, (2) between the different risk factors, and (3) between the risk\nfactor selection patterns. The method uses coefficient shrinkage to identify an\ninformative subset of risk factors from high-dimensional data, and uses a\nhierarchical Bayesian framework to allow domain knowledge to be incorporated as\npriors. The proposed method is favorable for healthcare applications because in\nadditional to improved prediction performance, relationships among the\ndifferent risks and risk factors are also identified. Extensive experimental\nresults on a large electronic medical claims database show that the proposed\nmethod outperforms state-of-the-art models by a significant margin.\nFurthermore, we show that the risk associations learned and the risk factors\nidentified lead to meaningful clinical insights.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 01:01:33 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Liu", "Bin", ""], ["Li", "Ying", ""], ["Ghosh", "Soumya", ""], ["Sun", "Zhaonan", ""], ["Ng", "Kenney", ""], ["Hu", "Jianying", ""]]}, {"id": "1802.06480", "submitter": "Qingkai Liang", "authors": "Qingkai Liang, Fanyu Que, Eytan Modiano", "title": "Accelerated Primal-Dual Policy Optimization for Safe Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained Markov Decision Process (CMDP) is a natural framework for\nreinforcement learning tasks with safety constraints, where agents learn a\npolicy that maximizes the long-term reward while satisfying the constraints on\nthe long-term cost. A canonical approach for solving CMDPs is the primal-dual\nmethod which updates parameters in primal and dual spaces in turn. Existing\nmethods for CMDPs only use on-policy data for dual updates, which results in\nsample inefficiency and slow convergence. In this paper, we propose a policy\nsearch method for CMDPs called Accelerated Primal-Dual Optimization (APDO),\nwhich incorporates an off-policy trained dual variable in the dual update\nprocedure while updating the policy in primal space with on-policy likelihood\nratio gradient. Experimental results on a simulated robot locomotion task show\nthat APDO achieves better sample efficiency and faster convergence than\nstate-of-the-art approaches for CMDPs.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 01:25:26 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Liang", "Qingkai", ""], ["Que", "Fanyu", ""], ["Modiano", "Eytan", ""]]}, {"id": "1802.06485", "submitter": "Arun Sai Suggala", "authors": "Adarsh Prasad, Arun Sai Suggala, Sivaraman Balakrishnan, Pradeep\n  Ravikumar", "title": "Robust Estimation via Robust Gradient Estimation", "comments": "48 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new computationally-efficient class of estimators for risk\nminimization. We show that these estimators are robust for general statistical\nmodels: in the classical Huber epsilon-contamination model and in heavy-tailed\nsettings. Our workhorse is a novel robust variant of gradient descent, and we\nprovide conditions under which our gradient descent variant provides accurate\nestimators in a general convex risk minimization problem. We provide specific\nconsequences of our theory for linear regression, logistic regression and for\nestimation of the canonical parameters in an exponential family. These results\nprovide some of the first computationally tractable and provably robust\nestimators for these canonical statistical models. Finally, we study the\nempirical performance of our proposed methods on synthetic and real datasets,\nand find that our methods convincingly outperform a variety of baselines.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 01:49:31 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 16:07:30 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Prasad", "Adarsh", ""], ["Suggala", "Arun Sai", ""], ["Balakrishnan", "Sivaraman", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1802.06501", "submitter": "Xiangyu Zhao", "authors": "Xiangyu Zhao and Liang Zhang and Zhuoye Ding and Long Xia and Jiliang\n  Tang and Dawei Yin", "title": "Recommendations with Negative Feedback via Pairwise Deep Reinforcement\n  Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1801.00209", "journal-ref": null, "doi": "10.1145/3219819.3219886", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems play a crucial role in mitigating the problem of\ninformation overload by suggesting users' personalized items or services. The\nvast majority of traditional recommender systems consider the recommendation\nprocedure as a static process and make recommendations following a fixed\nstrategy. In this paper, we propose a novel recommender system with the\ncapability of continuously improving its strategies during the interactions\nwith users. We model the sequential interactions between users and a\nrecommender system as a Markov Decision Process (MDP) and leverage\nReinforcement Learning (RL) to automatically learn the optimal strategies via\nrecommending trial-and-error items and receiving reinforcements of these items\nfrom users' feedback. Users' feedback can be positive and negative and both\ntypes of feedback have great potentials to boost recommendations. However, the\nnumber of negative feedback is much larger than that of positive one; thus\nincorporating them simultaneously is challenging since positive feedback could\nbe buried by negative one. In this paper, we develop a novel approach to\nincorporate them into the proposed deep recommender system (DEERS) framework.\nThe experimental results based on real-world e-commerce data demonstrate the\neffectiveness of the proposed framework. Further experiments have been\nconducted to understand the importance of both positive and negative feedback\nin recommendations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 02:30:10 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 11:49:04 GMT"}, {"version": "v3", "created": "Fri, 10 Aug 2018 02:33:08 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Zhao", "Xiangyu", ""], ["Zhang", "Liang", ""], ["Ding", "Zhuoye", ""], ["Xia", "Long", ""], ["Tang", "Jiliang", ""], ["Yin", "Dawei", ""]]}, {"id": "1802.06502", "submitter": "Sheng-Wei Chen", "authors": "Sheng-Wei Chen, Chun-Nan Chou and Edward Y. Chang", "title": "EA-CG: An Approximate Second-Order Method for Training Fully-Connected\n  Neural Networks", "comments": "Change to AAAI-19 Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For training fully-connected neural networks (FCNNs), we propose a practical\napproximate second-order method including: 1) an approximation of the Hessian\nmatrix and 2) a conjugate gradient (CG) based method. Our proposed approximate\nHessian matrix is memory-efficient and can be applied to any FCNNs where the\nactivation and criterion functions are twice differentiable. We devise a\nCG-based method incorporating one-rank approximation to derive Newton\ndirections for training FCNNs, which significantly reduces both space and time\ncomplexity. This CG-based method can be employed to solve any linear equation\nwhere the coefficient matrix is Kronecker-factored, symmetric and positive\ndefinite. Empirical studies show the efficacy and efficiency of our proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 02:31:24 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 03:31:43 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 03:29:56 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Chen", "Sheng-Wei", ""], ["Chou", "Chun-Nan", ""], ["Chang", "Edward Y.", ""]]}, {"id": "1802.06509", "submitter": "Nadav Cohen", "authors": "Sanjeev Arora, Nadav Cohen, Elad Hazan", "title": "On the Optimization of Deep Networks: Implicit Acceleration by\n  Overparameterization", "comments": "Published at the International Conference on Machine Learning (ICML)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional wisdom in deep learning states that increasing depth improves\nexpressiveness but complicates optimization. This paper suggests that,\nsometimes, increasing depth can speed up optimization. The effect of depth on\noptimization is decoupled from expressiveness by focusing on settings where\nadditional layers amount to overparameterization - linear neural networks, a\nwell-studied model. Theoretical analysis, as well as experiments, show that\nhere depth acts as a preconditioner which may accelerate convergence. Even on\nsimple convex problems such as linear regression with $\\ell_p$ loss, $p>2$,\ngradient descent can benefit from transitioning to a non-convex\noverparameterized objective, more than it would from some common acceleration\nschemes. We also prove that it is mathematically impossible to obtain the\nacceleration effect of overparametrization via gradients of any regularizer.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 03:08:26 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 06:17:24 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Arora", "Sanjeev", ""], ["Cohen", "Nadav", ""], ["Hazan", "Elad", ""]]}, {"id": "1802.06516", "submitter": "Mengying Sun", "authors": "Mengying Sun, Inci M. Baytas, Liang Zhan, Zhangyang Wang, Jiayu Zhou", "title": "Subspace Network: Deep Multi-Task Censored Regression for Modeling\n  Neurodegenerative Diseases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade a wide spectrum of machine learning models have been\ndeveloped to model the neurodegenerative diseases, associating biomarkers,\nespecially non-intrusive neuroimaging markers, with key clinical scores\nmeasuring the cognitive status of patients. Multi-task learning (MTL) has been\ncommonly utilized by these studies to address high dimensionality and small\ncohort size challenges. However, most existing MTL approaches are based on\nlinear models and suffer from two major limitations: 1) they cannot explicitly\nconsider upper/lower bounds in these clinical scores; 2) they lack the\ncapability to capture complicated non-linear interactions among the variables.\nIn this paper, we propose Subspace Network, an efficient deep modeling approach\nfor non-linear multi-task censored regression. Each layer of the subspace\nnetwork performs a multi-task censored regression to improve upon the\npredictions from the last layer via sketching a low-dimensional subspace to\nperform knowledge transfer among learning tasks. Under mild assumptions, for\neach layer the parametric subspace can be recovered using only one pass of\ntraining data. Empirical results demonstrate that the proposed subspace network\nquickly picks up the correct parameter subspaces, and outperforms\nstate-of-the-arts in predicting neurodegenerative clinical scores using\ninformation in brain imaging.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 04:50:14 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 04:34:15 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Sun", "Mengying", ""], ["Baytas", "Inci M.", ""], ["Zhan", "Liang", ""], ["Wang", "Zhangyang", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1802.06526", "submitter": "Daniel Rugeles", "authors": "Daniel Rugeles, Zhen Hai, Gao Cong and Manoranjan Dash", "title": "Heron Inference for Bayesian Graphical Models", "comments": "9 pages, 6 Tables and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian graphical models have been shown to be a powerful tool for\ndiscovering uncertainty and causal structure from real-world data in many\napplication fields. Current inference methods primarily follow different kinds\nof trade-offs between computational complexity and predictive accuracy. At one\nend of the spectrum, variational inference approaches perform well in\ncomputational efficiency, while at the other end, Gibbs sampling approaches are\nknown to be relatively accurate for prediction in practice. In this paper, we\nextend an existing Gibbs sampling method, and propose a new deterministic Heron\ninference (Heron) for a family of Bayesian graphical models. In addition to the\nsupport for nontrivial distributability, one more benefit of Heron is that it\nis able to not only allow us to easily assess the convergence status but also\nlargely improve the running efficiency. We evaluate Heron against the standard\ncollapsed Gibbs sampler and state-of-the-art state augmentation method in\ninference for well-known graphical models. Experimental results using publicly\navailable real-life data have demonstrated that Heron significantly outperforms\nthe baseline methods for inferring Bayesian graphical models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 05:52:47 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Rugeles", "Daniel", ""], ["Hai", "Zhen", ""], ["Cong", "Gao", ""], ["Dash", "Manoranjan", ""]]}, {"id": "1802.06552", "submitter": "Yingzhen Li", "authors": "Yingzhen Li, John Bradshaw, Yash Sharma", "title": "Are Generative Classifiers More Robust to Adversarial Attacks?", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a rising interest in studying the robustness of deep neural network\nclassifiers against adversaries, with both advanced attack and defence\ntechniques being actively developed. However, most recent work focuses on\ndiscriminative classifiers, which only model the conditional distribution of\nthe labels given the inputs. In this paper, we propose and investigate the deep\nBayes classifier, which improves classical naive Bayes with conditional deep\ngenerative models. We further develop detection methods for adversarial\nexamples, which reject inputs with low likelihood under the generative model.\nExperimental results suggest that deep Bayes classifiers are more robust than\ndeep discriminative classifiers, and that the proposed detection methods are\neffective against many recently proposed attacks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 08:58:00 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 17:07:51 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 10:54:08 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Li", "Yingzhen", ""], ["Bradshaw", "John", ""], ["Sharma", "Yash", ""]]}, {"id": "1802.06627", "submitter": "Beranger Dumont", "authors": "Beranger Dumont, Simona Maggio, Pablo Montalvo", "title": "Robustness of Rotation-Equivariant Networks to Adversarial Perturbations", "comments": "4 pages + references; public implementation of Spatially Transformed\n  Adversarial Examples can be found at https://github.com/rakutentech/stAdv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to be vulnerable to adversarial\nexamples: very small perturbations of the input having a dramatic impact on the\npredictions. A wealth of adversarial attacks and distance metrics to quantify\nthe similarity between natural and adversarial images have been proposed,\nrecently enlarging the scope of adversarial examples with geometric\ntransformations beyond pixel-wise attacks. In this context, we investigate the\nrobustness to adversarial attacks of new Convolutional Neural Network\narchitectures providing equivariance to rotations. We found that\nrotation-equivariant networks are significantly less vulnerable to\ngeometric-based attacks than regular networks on the MNIST, CIFAR-10, and\nImageNet datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 13:49:15 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 15:24:31 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Dumont", "Beranger", ""], ["Maggio", "Simona", ""], ["Montalvo", "Pablo", ""]]}, {"id": "1802.06640", "submitter": "Boris Sharchilev", "authors": "Boris Sharchilev, Yury Ustinovsky, Pavel Serdyukov, Maarten de Rijke", "title": "Finding Influential Training Samples for Gradient Boosted Decision Trees", "comments": "Added the \"Acknowledgements\" section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of finding influential training samples for a\nparticular case of tree ensemble-based models, e.g., Random Forest (RF) or\nGradient Boosted Decision Trees (GBDT). A natural way of formalizing this\nproblem is studying how the model's predictions change upon leave-one-out\nretraining, leaving out each individual training sample. Recent work has shown\nthat, for parametric models, this analysis can be conducted in a\ncomputationally efficient way. We propose several ways of extending this\nframework to non-parametric GBDT ensembles under the assumption that tree\nstructures remain fixed. Furthermore, we introduce a general scheme of\nobtaining further approximations to our method that balance the trade-off\nbetween performance and computational complexity. We evaluate our approaches on\nvarious experimental setups and use-case scenarios and demonstrate both the\nquality of our approach to finding influential training samples in comparison\nto the baselines and its computational efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 14:19:40 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 19:12:03 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Sharchilev", "Boris", ""], ["Ustinovsky", "Yury", ""], ["Serdyukov", "Pavel", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1802.06677", "submitter": "Huangjie Zheng", "authors": "Huangjie Zheng, Jiangchao Yao, Ya Zhang, Ivor W. Tsang", "title": "Degeneration in VAE: in the Light of Fisher Information Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While enormous progress has been made to Variational Autoencoder (VAE) in\nrecent years, similar to other deep networks, VAE with deep networks suffers\nfrom the problem of degeneration, which seriously weakens the correlation\nbetween the input and the corresponding latent codes, deviating from the goal\nof the representation learning. To investigate how degeneration affects VAE\nfrom a theoretical perspective, we illustrate the information transmission in\nVAE and analyze the intermediate layers of the encoders/decoders. Specifically,\nwe propose a Fisher Information measure for the layer-wise analysis. With such\nmeasure, we demonstrate that information loss is ineluctable in feed-forward\nnetworks and causes the degeneration in VAE. We show that skip connections in\nVAE enable the preservation of information without changing the model\narchitecture. We call this class of VAE equipped with skip connections as SCVAE\nand perform a range of experiments to show its advantages in information\npreservation and degeneration mitigation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 15:45:36 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 08:06:16 GMT"}, {"version": "v3", "created": "Tue, 25 Sep 2018 00:53:57 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Zheng", "Huangjie", ""], ["Yao", "Jiangchao", ""], ["Zhang", "Ya", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "1802.06708", "submitter": "Luca Pedrelli", "authors": "Claudio Gallicchio, Alessio Micheli, Luca Pedrelli", "title": "Deep Echo State Networks for Diagnosis of Parkinson's Disease", "comments": "This is a pre-print of the paper submitted to the European Symposium\n  on Artificial Neural Networks, Computational Intelligence and Machine\n  Learning, ESANN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel approach for diagnosis of Parkinson's\nDisease (PD) based on deep Echo State Networks (ESNs). The identification of PD\nis performed by analyzing the whole time-series collected from a tablet device\nduring the sketching of spiral tests, without the need for feature extraction\nand data preprocessing. We evaluated the proposed approach on a public dataset\nof spiral tests. The results of experimental analysis show that DeepESNs\nperform significantly better than shallow ESN model. Overall, the proposed\napproach obtains state-of-the-art results in the identification of PD on this\nkind of temporal data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 17:10:52 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""], ["Pedrelli", "Luca", ""]]}, {"id": "1802.06739", "submitter": "Liyang Xie", "authors": "Liyang Xie, Kaixiang Lin, Shu Wang, Fei Wang, Jiayu Zhou", "title": "Differentially Private Generative Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) and its variants have recently attracted\nintensive research interests due to their elegant theoretical foundation and\nexcellent empirical performance as generative models. These tools provide a\npromising direction in the studies where data availability is limited. One\ncommon issue in GANs is that the density of the learned generative distribution\ncould concentrate on the training data points, meaning that they can easily\nremember training samples due to the high model complexity of deep networks.\nThis becomes a major concern when GANs are applied to private or sensitive data\nsuch as patient medical records, and the concentration of distribution may\ndivulge critical patient information. To address this issue, in this paper we\npropose a differentially private GAN (DPGAN) model, in which we achieve\ndifferential privacy in GANs by adding carefully designed noise to gradients\nduring the learning procedure. We provide rigorous proof for the privacy\nguarantee, as well as comprehensive empirical evidence to support our analysis,\nwhere we demonstrate that our method can generate high quality data points at a\nreasonable privacy level.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 18:05:33 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Xie", "Liyang", ""], ["Lin", "Kaixiang", ""], ["Wang", "Shu", ""], ["Wang", "Fei", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1802.06749", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Manfred K. Warmuth, Daniel Hsu", "title": "Leveraged volume sampling for linear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose an $n \\times d$ design matrix in a linear regression problem is\ngiven, but the response for each point is hidden unless explicitly requested.\nThe goal is to sample only a small number $k \\ll n$ of the responses, and then\nproduce a weight vector whose sum of squares loss over all points is at most\n$1+\\epsilon$ times the minimum. When $k$ is very small (e.g., $k=d$), jointly\nsampling diverse subsets of points is crucial. One such method called volume\nsampling has a unique and desirable property that the weight vector it produces\nis an unbiased estimate of the optimum. It is therefore natural to ask if this\nmethod offers the optimal unbiased estimate in terms of the number of responses\n$k$ needed to achieve a $1+\\epsilon$ loss approximation.\n  Surprisingly we show that volume sampling can have poor behavior when we\nrequire a very accurate approximation -- indeed worse than some i.i.d. sampling\ntechniques whose estimates are biased, such as leverage score sampling. We then\ndevelop a new rescaled variant of volume sampling that produces an unbiased\nestimate which avoids this bad behavior and has at least as good a tail bound\nas leverage score sampling: sample size $k=O(d\\log d + d/\\epsilon)$ suffices to\nguarantee total loss at most $1+\\epsilon$ times the minimum with high\nprobability. Thus, we improve on the best previously known sample size for an\nunbiased estimator, $k=O(d^2/\\epsilon)$.\n  Our rescaling procedure leads to a new efficient algorithm for volume\nsampling which is based on a determinantal rejection sampling technique with\npotentially broader applications to determinantal point processes. Other\ncontributions include introducing the combinatorics needed for rescaled volume\nsampling and developing tail bounds for sums of dependent random matrices which\narise in the process.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 18:35:39 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 23:54:13 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 17:03:42 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Warmuth", "Manfred K.", ""], ["Hsu", "Daniel", ""]]}, {"id": "1802.06765", "submitter": "Samuel Ainsworth", "authors": "Samuel Ainsworth, Nicholas Foti, Adrian KC Lee, Emily Fox", "title": "Interpretable VAEs for nonlinear group factor analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have recently yielded encouraging results in producing\nsubjectively realistic samples of complex data. Far less attention has been\npaid to making these generative models interpretable. In many scenarios,\nranging from scientific applications to finance, the observed variables have a\nnatural grouping. It is often of interest to understand systems of interaction\namongst these groups, and latent factor models (LFMs) are an attractive\napproach. However, traditional LFMs are limited by assuming a linear\ncorrelation structure. We present an output interpretable VAE (oi-VAE) for\ngrouped data that models complex, nonlinear latent-to-observed relationships.\nWe combine a structured VAE comprised of group-specific generators with a\nsparsity-inducing prior. We demonstrate that oi-VAE yields meaningful notions\nof interpretability in the analysis of motion capture and MEG data. We further\nshow that in these situations, the regularization inherent to oi-VAE can\nactually lead to improved generalization and learned generative processes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 01:47:13 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Ainsworth", "Samuel", ""], ["Foti", "Nicholas", ""], ["Lee", "Adrian KC", ""], ["Fox", "Emily", ""]]}, {"id": "1802.06771", "submitter": "Vivek Gupta", "authors": "Dheeraj Mekala, Vivek Gupta, Purushottam Kar, Harish Karnick", "title": "Bayes-optimal Hierarchical Classification over Asymmetric Tree-Distance\n  Loss", "comments": "CS 396 Undergraduate Project Report, 17 Pages 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hierarchical classification is supervised multi-class classification problem\nover the set of class labels organized according to a hierarchy. In this\nreport, we study the work by Ramaswamy et. al. on hierarchical classification\nover symmetric tree distance loss. We extend the consistency of hierarchical\nclassification algorithm over asymmetric tree distance loss. We design a\n$\\mathcal{O}(nk\\log{}n)$ algorithm to find Bayes optimal classification for a\nk-ary tree as a hierarchy. We show that under reasonable assumptions over\nasymmetric loss function, the Bayes optimal classification over this asymmetric\nloss can be found in $\\mathcal{O}(k\\log{}n)$. We exploit this insight and\nattempt to extend the Ova-Cascade algorithm \\citet{ramaswamy2015convex} for\nhierarchical classification over the asymmetric loss.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 12:51:06 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Mekala", "Dheeraj", ""], ["Gupta", "Vivek", ""], ["Kar", "Purushottam", ""], ["Karnick", "Harish", ""]]}, {"id": "1802.06823", "submitter": "Jaroslaw Zola", "authors": "Frank Schoeneman, Varun Chandola, Nils Napp, Olga Wodo, Jaroslaw Zola", "title": "Entropy-Isomap: Manifold Learning for High-dimensional Dynamic Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific and engineering processes deliver massive high-dimensional data\nsets that are generated as non-linear transformations of an initial state and\nfew process parameters. Mapping such data to a low-dimensional manifold\nfacilitates better understanding of the underlying processes, and enables their\noptimization. In this paper, we first show that off-the-shelf non-linear\nspectral dimensionality reduction methods, e.g., Isomap, fail for such data,\nprimarily due to the presence of strong temporal correlations. Then, we propose\na novel method, Entropy-Isomap, to address the issue. The proposed method is\nsuccessfully applied to large data describing a fabrication process of organic\nmaterials. The resulting low-dimensional representation correctly captures\nprocess control variables, allows for low-dimensional visualization of the\nmaterial morphology evolution, and provides key insights to improve the\nprocess.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 19:39:59 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 09:48:28 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Schoeneman", "Frank", ""], ["Chandola", "Varun", ""], ["Napp", "Nils", ""], ["Wodo", "Olga", ""], ["Zola", "Jaroslaw", ""]]}, {"id": "1802.06825", "submitter": "Stephan Zheng", "authors": "Stephan Zheng, Rose Yu, Yisong Yue", "title": "Multi-resolution Tensor Learning for Large-Scale Spatial Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional tensor models are notoriously computationally expensive to\ntrain. We present a meta-learning algorithm, MMT, that can significantly speed\nup the process for spatial tensor models. MMT leverages the property that\nspatial data can be viewed at multiple resolutions, which are related by\ncoarsening and finegraining from one resolution to another. Using this\nproperty, MMT learns a tensor model by starting from a coarse resolution and\niteratively increasing the model complexity. In order to not \"over-train\" on\ncoarse resolution models, we investigate an information-theoretic fine-graining\ncriterion to decide when to transition into higher-resolution models. We\nprovide both theoretical and empirical evidence for the advantages of this\napproach. When applied to two real-world large-scale spatial datasets for\nbasketball player and animal behavior modeling, our approach demonstrate 3 key\nbenefits: 1) it efficiently captures higher-order interactions (i.e., tensor\nlatent factors), 2) it is orders of magnitude faster than fixed resolution\nlearning and scales to very fine-grained spatial resolutions, and 3) it\nreliably yields accurate and interpretable models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 19:54:46 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 06:35:13 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Zheng", "Stephan", ""], ["Yu", "Rose", ""], ["Yue", "Yisong", ""]]}, {"id": "1802.06832", "submitter": "Nariman Farsad", "authors": "Nariman Farsad and Milind Rao and Andrea Goldsmith", "title": "Deep Learning for Joint Source-Channel Coding of Text", "comments": "accepted for publication in the proceedings of IEEE International\n  Conference on Acoustics, Speech and Signal Processing (ICASSP) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of joint source and channel coding of structured data\nsuch as natural language over a noisy channel. The typical approach to this\nproblem in both theory and practice involves performing source coding to first\ncompress the text and then channel coding to add robustness for the\ntransmission across the channel. This approach is optimal in terms of\nminimizing end-to-end distortion with arbitrarily large block lengths of both\nthe source and channel codes when transmission is over discrete memoryless\nchannels. However, the optimality of this approach is no longer ensured for\ndocuments of finite length and limitations on the length of the encoding. We\nwill show in this scenario that we can achieve lower word error rates by\ndeveloping a deep learning based encoder and decoder. While the approach of\nseparate source and channel coding would minimize bit error rates, our approach\npreserves semantic information of sentences by first embedding sentences in a\nsemantic space where sentences closer in meaning are located closer together,\nand then performing joint source and channel coding on these embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 20:11:36 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Farsad", "Nariman", ""], ["Rao", "Milind", ""], ["Goldsmith", "Andrea", ""]]}, {"id": "1802.06847", "submitter": "Mihaela Rosca", "authors": "Mihaela Rosca, Balaji Lakshminarayanan, Shakir Mohamed", "title": "Distribution Matching in Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasingly widespread deployment of generative models, there is a\nmounting need for a deeper understanding of their behaviors and limitations. In\nthis paper, we expose the limitations of Variational Autoencoders (VAEs), which\nconsistently fail to learn marginal distributions in both latent and visible\nspaces. We show this to be a consequence of learning by matching conditional\ndistributions, and the limitations of explicit model and posterior\ndistributions. It is popular to consider Generative Adversarial Networks (GANs)\nas a means of overcoming these limitations, leading to hybrids of VAEs and\nGANs. We perform a large-scale evaluation of several VAE-GAN hybrids and\nanalyze the implications of class probability estimation for learning\ndistributions. While promising, we conclude that at present, VAE-GAN hybrids\nhave limited applicability: they are harder to scale, evaluate, and use for\ninference compared to VAEs; and they do not improve over the generation quality\nof GANs.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 20:59:33 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 20:40:54 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 22:08:35 GMT"}, {"version": "v4", "created": "Mon, 10 Jun 2019 20:36:10 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Rosca", "Mihaela", ""], ["Lakshminarayanan", "Balaji", ""], ["Mohamed", "Shakir", ""]]}, {"id": "1802.06857", "submitter": "Jian Zhang", "authors": "Emilio Parisotto, Devendra Singh Chaplot, Jian Zhang, Ruslan\n  Salakhutdinov", "title": "Global Pose Estimation with an Attention-based Recurrent Network", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability for an agent to localize itself within an environment is crucial\nfor many real-world applications. For unknown environments, Simultaneous\nLocalization and Mapping (SLAM) enables incremental and concurrent building of\nand localizing within a map. We present a new, differentiable architecture,\nNeural Graph Optimizer, progressing towards a complete neural network solution\nfor SLAM by designing a system composed of a local pose estimation model, a\nnovel pose selection module, and a novel graph optimization process. The entire\narchitecture is trained in an end-to-end fashion, enabling the network to\nautomatically learn domain-specific features relevant to the visual odometry\nand avoid the involved process of feature engineering. We demonstrate the\neffectiveness of our system on a simulated 2D maze and the 3D ViZ-Doom\nenvironment.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 21:17:10 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Parisotto", "Emilio", ""], ["Chaplot", "Devendra Singh", ""], ["Zhang", "Jian", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1802.06875", "submitter": "Benjamin Cowen", "authors": "Benjamin Cowen, Apoorva Nandini Saridena, Anna Choromanska", "title": "LSALSA: Accelerated Source Separation via Learned Sparse Coding", "comments": "ECML-PKDD 2019 via journal track; Special Issue Mach Learn (2019)", "journal-ref": null, "doi": "10.1007/s10994-019-05812-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient algorithm for the generalized sparse coding (SC)\ninference problem. The proposed framework applies to both the single dictionary\nsetting, where each data point is represented as a sparse combination of the\ncolumns of one dictionary matrix, as well as the multiple dictionary setting as\ngiven in morphological component analysis (MCA), where the goal is to separate\na signal into additive parts such that each part has distinct sparse\nrepresentation within a corresponding dictionary. Both the SC task and its\ngeneralization via MCA have been cast as $\\ell_1$-regularized least-squares\noptimization problems. To accelerate traditional acquisition of sparse codes,\nwe propose a deep learning architecture that constitutes a trainable\ntime-unfolded version of the Split Augmented Lagrangian Shrinkage Algorithm\n(SALSA), a special case of the Alternating Direction Method of Multipliers\n(ADMM). We empirically validate both variants of the algorithm, that we refer\nto as LSALSA (learned-SALSA), on image vision tasks and demonstrate that at\ninference our networks achieve vast improvements in terms of the running time,\nthe quality of estimated sparse codes, and visual clarity on both classic SC\nand MCA problems. Finally, we present a theoretical framework for analyzing\nLSALSA network: we show that the proposed approach exactly implements a\ntruncated ADMM applied to a new, learned cost function with curvature modified\nby one of the learned parameterized matrices. We extend a very recent\nStochastic Alternating Optimization analysis framework to show that a gradient\ndescent step along this learned loss landscape is equivalent to a modified\ngradient descent step along the original loss landscape. In this framework, the\nacceleration achieved by LSALSA could potentially be explained by the network's\nability to learn a correction to the gradient direction of steeper descent.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 00:10:00 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 16:04:14 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Cowen", "Benjamin", ""], ["Saridena", "Apoorva Nandini", ""], ["Choromanska", "Anna", ""]]}, {"id": "1802.06891", "submitter": "Matthew Fellows", "authors": "Matthew Fellows, Kamil Ciosek and Shimon Whiteson", "title": "Fourier Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new way of deriving policy gradient updates for reinforcement\nlearning. Our technique, based on Fourier analysis, recasts integrals that\narise with expected policy gradients as convolutions and turns them into\nmultiplications. The obtained analytical solutions allow us to capture the low\nvariance benefits of EPG in a broad range of settings. For the critic, we treat\ntrigonometric and radial basis functions, two function families with the\nuniversal approximation property. The choice of policy can be almost arbitrary,\nincluding mixtures or hybrid continuous-discrete probability distributions.\nMoreover, we derive a general family of sample-based estimators for stochastic\npolicy gradients, which unifies existing results on sample-based approximation.\nWe believe that this technique has the potential to shape the next generation\nof policy gradient approaches, powered by analytical results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 22:28:56 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 16:41:30 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Fellows", "Matthew", ""], ["Ciosek", "Kamil", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1802.06893", "submitter": "Edouard Grave", "authors": "Edouard Grave, Piotr Bojanowski, Prakhar Gupta, Armand Joulin, Tomas\n  Mikolov", "title": "Learning Word Vectors for 157 Languages", "comments": "Accepted to LREC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed word representations, or word vectors, have recently been applied\nto many tasks in natural language processing, leading to state-of-the-art\nperformance. A key ingredient to the successful application of these\nrepresentations is to train them on very large corpora, and use these\npre-trained models in downstream tasks. In this paper, we describe how we\ntrained such high quality word representations for 157 languages. We used two\nsources of data to train these models: the free online encyclopedia Wikipedia\nand data from the common crawl project. We also introduce three new word\nanalogy datasets to evaluate these word vectors, for French, Hindi and Polish.\nFinally, we evaluate our pre-trained word vectors on 10 languages for which\nevaluation datasets exists, showing very strong performance compared to\nprevious models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 22:32:47 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 18:00:30 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Grave", "Edouard", ""], ["Bojanowski", "Piotr", ""], ["Gupta", "Prakhar", ""], ["Joulin", "Armand", ""], ["Mikolov", "Tomas", ""]]}, {"id": "1802.06894", "submitter": "Kejun Huang", "authors": "Kejun Huang, Xiao Fu, Nicholas D. Sidiropoulos", "title": "Learning Hidden Markov Models from Pairwise Co-occurrences with\n  Application to Topic Modeling", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for identifying the transition and emission\nprobabilities of a hidden Markov model (HMM) from the emitted data.\nExpectation-maximization becomes computationally prohibitive for long\nobservation records, which are often required for identification. The new\nalgorithm is particularly suitable for cases where the available sample size is\nlarge enough to accurately estimate second-order output probabilities, but not\nhigher-order ones. We show that if one is only able to obtain a reliable\nestimate of the pairwise co-occurrence probabilities of the emissions, it is\nstill possible to uniquely identify the HMM if the emission probability is\n\\emph{sufficiently scattered}. We apply our method to hidden topic Markov\nmodeling, and demonstrate that we can learn topics with higher quality if\ndocuments are modeled as observations of HMMs sharing the same emission (topic)\nprobability, compared to the simple but widely used bag-of-words model.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 22:33:56 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 21:15:46 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Huang", "Kejun", ""], ["Fu", "Xiao", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1802.06901", "submitter": "Jason Lee", "authors": "Jason Lee, Elman Mansimov, Kyunghyun Cho", "title": "Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative\n  Refinement", "comments": "Accepted to EMNLP'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a conditional non-autoregressive neural sequence model based on\niterative refinement. The proposed model is designed based on the principles of\nlatent variable models and denoising autoencoders, and is generally applicable\nto any sequence generation task. We extensively evaluate the proposed model on\nmachine translation (En-De and En-Ro) and image caption generation, and observe\nthat it significantly speeds up decoding while maintaining the generation\nquality comparable to the autoregressive counterpart.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 22:57:54 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 21:20:55 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 18:00:08 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Lee", "Jason", ""], ["Mansimov", "Elman", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1802.06903", "submitter": "Yi Zhou", "authors": "Yi Zhou and Yingbin Liang and Huishuai Zhang", "title": "Generalization Error Bounds with Probabilistic Guarantee for SGD in\n  Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning has led to a rising interest in the\ngeneralization property of the stochastic gradient descent (SGD) method, and\nstability is one popular approach to study it. Existing works based on\nstability have studied nonconvex loss functions, but only considered the\ngeneralization error of the SGD in expectation. In this paper, we establish\nvarious generalization error bounds with probabilistic guarantee for the SGD.\nSpecifically, for both general nonconvex loss functions and gradient dominant\nloss functions, we characterize the on-average stability of the iterates\ngenerated by SGD in terms of the on-average variance of the stochastic\ngradients. Such characterization leads to improved bounds for the\ngeneralization error for SGD. We then study the regularized risk minimization\nproblem with strongly convex regularizers, and obtain improved generalization\nerror bounds for proximal SGD. With strongly convex regularizers, we further\nestablish the generalization error bounds for nonconvex loss functions under\nproximal SGD with high-probability guarantee, i.e., exponential concentration\nin probability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 23:04:20 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 19:13:12 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 03:30:18 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Zhou", "Yi", ""], ["Liang", "Yingbin", ""], ["Zhang", "Huishuai", ""]]}, {"id": "1802.06924", "submitter": "Oisin Mac Aodha", "authors": "Oisin Mac Aodha and Shihan Su and Yuxin Chen and Pietro Perona and\n  Yisong Yue", "title": "Teaching Categories to Human Learners with Visual Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of computer-assisted teaching with explanations.\nConventional approaches for machine teaching typically only provide feedback at\nthe instance level e.g., the category or label of the instance. However, it is\nintuitive that clear explanations from a knowledgeable teacher can\nsignificantly improve a student's ability to learn a new concept. To address\nthese existing limitations, we propose a teaching framework that provides\ninterpretable explanations as feedback and models how the learner incorporates\nthis additional information. In the case of images, we show that we can\nautomatically generate explanations that highlight the parts of the image that\nare responsible for the class label. Experiments on human learners illustrate\nthat, on average, participants achieve better test set performance on\nchallenging categorization tasks when taught with our interpretable approach\ncompared to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 00:49:38 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Mac Aodha", "Oisin", ""], ["Su", "Shihan", ""], ["Chen", "Yuxin", ""], ["Perona", "Pietro", ""], ["Yue", "Yisong", ""]]}, {"id": "1802.06927", "submitter": "Nishant Desai", "authors": "Vinay Uday Prabhu, Nishant Desai, John Whaley", "title": "On Lyapunov exponents and adversarial perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we would like to disseminate a serendipitous discovery\ninvolving Lyapunov exponents of a 1-D time series and their use in serving as a\nfiltering defense tool against a specific kind of deep adversarial\nperturbation. To this end, we use the state-of-the-art CleverHans library to\ngenerate adversarial perturbations against a standard Convolutional Neural\nNetwork (CNN) architecture trained on the MNIST as well as the Fashion-MNIST\ndatasets. We empirically demonstrate how the Lyapunov exponents computed on the\nflattened 1-D vector representations of the images served as highly\ndiscriminative features that could be to pre-classify images as adversarial or\nlegitimate before feeding the image into the CNN for classification. We also\nexplore the issue of possible false-alarms when the input images are noisy in a\nnon-adversarial sense.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 01:09:22 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Prabhu", "Vinay Uday", ""], ["Desai", "Nishant", ""], ["Whaley", "John", ""]]}, {"id": "1802.06936", "submitter": "Christopher Jung", "authors": "Stephen Gillen, Christopher Jung, Michael Kearns, Aaron Roth", "title": "Online Learning with an Unknown Fairness Metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online learning in the linear contextual bandits\nsetting, but in which there are also strong individual fairness constraints\ngoverned by an unknown similarity metric. These constraints demand that we\nselect similar actions or individuals with approximately equal probability\n(arXiv:1104.3913), which may be at odds with optimizing reward, thus modeling\nsettings where profit and social policy are in tension. We assume we learn\nabout an unknown Mahalanobis similarity metric from only weak feedback that\nidentifies fairness violations, but does not quantify their extent. This is\nintended to represent the interventions of a regulator who \"knows unfairness\nwhen he sees it\" but nevertheless cannot enunciate a quantitative fairness\nmetric over individuals. Our main result is an algorithm in the adversarial\ncontext setting that has a number of fairness violations that depends only\nlogarithmically on $T$, while obtaining an optimal $O(\\sqrt{T})$ regret bound\nto the best fair policy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 02:31:05 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 02:50:13 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Gillen", "Stephen", ""], ["Jung", "Christopher", ""], ["Kearns", "Michael", ""], ["Roth", "Aaron", ""]]}, {"id": "1802.06939", "submitter": "Ayaka Sakata", "authors": "Ayaka Sakata", "title": "Estimator of Prediction Error Based on Approximate Message Passing for\n  Penalized Linear Regression", "comments": null, "journal-ref": null, "doi": "10.1088/1742-5468/aac910", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an estimator of prediction error using an approximate message\npassing (AMP) algorithm that can be applied to a broad range of sparse\npenalties. Following Stein's lemma, the estimator of the generalized degrees of\nfreedom, which is a key quantity for the construction of the estimator of the\nprediction error, is calculated at the AMP fixed point. The resulting form of\nthe AMP-based estimator does not depend on the penalty function, and its value\ncan be further improved by considering the correlation between predictors. The\nproposed estimator is asymptotically unbiased when the components of the\npredictors and response variables are independently generated according to a\nGaussian distribution. We examine the behaviour of the estimator for real data\nunder nonconvex sparse penalties, where Akaike's information criterion does not\ncorrespond to an unbiased estimator of the prediction error. The model selected\nby the proposed estimator is close to that which minimizes the true prediction\nerror.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 02:47:21 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 04:37:50 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Sakata", "Ayaka", ""]]}, {"id": "1802.06942", "submitter": "Ehsan Kazemi", "authors": "Ehsan Kazemi and Lin Chen and Sanjoy Dasgupta and Amin Karbasi", "title": "Comparison Based Learning from Weak Oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increasing interest in learning algorithms that involve interaction\nbetween human and machine. Comparison-based queries are among the most natural\nways to get feedback from humans. A challenge in designing comparison-based\ninteractive learning algorithms is coping with noisy answers. The most common\nfix is to submit a query several times, but this is not applicable in many\nsituations due to its prohibitive cost and due to the unrealistic assumption of\nindependent noise in different repetitions of the same query.\n  In this paper, we introduce a new weak oracle model, where a non-malicious\nuser responds to a pairwise comparison query only when she is quite sure about\nthe answer. This model is able to mimic the behavior of a human in noise-prone\nregions. We also consider the application of this weak oracle model to the\nproblem of content search (a variant of the nearest neighbor search problem)\nthrough comparisons. More specifically, we aim at devising efficient algorithms\nto locate a target object in a database equipped with a dissimilarity metric\nvia invocation of the weak comparison oracle. We propose two algorithms termed\nWORCS-I and WORCS-II (Weak-Oracle Comparison-based Search), which provably\nlocate the target object in a number of comparisons close to the entropy of the\ntarget distribution. While WORCS-I provides better theoretical guarantees,\nWORCS-II is applicable to more technically challenging scenarios where the\nalgorithm has limited access to the ranking dissimilarity between objects. A\nseries of experiments validate the performance of our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 02:57:25 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Kazemi", "Ehsan", ""], ["Chen", "Lin", ""], ["Dasgupta", "Sanjoy", ""], ["Karbasi", "Amin", ""]]}, {"id": "1802.06944", "submitter": "Sara Baghsorkhi", "authors": "Matthew Sotoudeh, Sara S. Baghsorkhi", "title": "DeepThin: A Self-Compressing Library for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the industry deploys increasingly large and complex neural networks to\nmobile devices, more pressure is put on the memory and compute resources of\nthose devices. Deep compression, or compression of deep neural network weight\nmatrices, is a technique to stretch resources for such scenarios. Existing\ncompression methods cannot effectively compress models smaller than 1-2% of\ntheir original size. We develop a new compression technique, DeepThin, building\non existing research in the area of low rank factorization. We identify and\nbreak artificial constraints imposed by low rank approximations by combining\nrank factorization with a reshaping process that adds nonlinearity to the\napproximation function. We deploy DeepThin as a plug-gable library integrated\nwith TensorFlow that enables users to seamlessly compress models at different\ngranularities. We evaluate DeepThin on two state-of-the-art acoustic models,\nTFKaldi and DeepSpeech, comparing it to previous compression work (Pruning,\nHashNet, and Rank Factorization), empirical limit study approaches, and\nhand-tuned models. For TFKaldi, our DeepThin networks show better word error\nrates (WER) than competing methods at practically all tested compression rates,\nachieving an average of 60% relative improvement over rank factorization, 57%\nover pruning, 23% over hand-tuned same-size networks, and 6% over the\ncomputationally expensive HashedNets. For DeepSpeech, DeepThin-compressed\nnetworks achieve better test loss than all other compression methods, reaching\na 28% better result than rank factorization, 27% better than pruning, 20%\nbetter than hand-tuned same-size networks, and 12% better than HashedNets.\nDeepThin also provide inference performance benefits ranging from 2X to 14X\nspeedups, depending on the compression ratio and platform cache sizes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 03:03:40 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Sotoudeh", "Matthew", ""], ["Baghsorkhi", "Sara S.", ""]]}, {"id": "1802.06949", "submitter": "Amith Rajith Mamidala", "authors": "Amith R Mamidala", "title": "Efficient Embedding of MPI Collectives in MXNET DAGs for scaling Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Availability of high performance computing infrastructures such as clusters\nof GPUs and CPUs have fueled the growth of distributed learning systems. Deep\nLearning frameworks express neural nets as DAGs and execute these DAGs on\ncomputation resources such as GPUs. In this paper, we propose efficient designs\nof embedding MPI collective operations into data parallel DAGs. Incorrect\ndesigns can easily lead to deadlocks or program crashes. In particular, we\ndemonstrate three designs: Funneled, Concurrent communication and Dependency\nchaining of using MPI collectives with DAGs. These designs automatically enable\noverlap of computation with communication by allowing for concurrent execution\nwith the other tasks. We directly implement these designs into the KVStore API\nof the MXNET. This allows us to directly leverage the rest of the\ninfrastructure. Using ImageNet and CIFAR data sets, we show the potential of\nour designs. In particular, our designs scale to 256 GPUs with as low as 50\nseconds of epoch times for ImageNet 1K datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 03:36:20 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Mamidala", "Amith R", ""]]}, {"id": "1802.06963", "submitter": "Karim Said Barsim", "authors": "Karim Said Barsim, Lukas Mauch, Bin Yang", "title": "Neural Network Ensembles to Real-time Identification of Plug-level\n  Appliance Measurements", "comments": "NILM Workshop 2016", "journal-ref": null, "doi": null, "report-no": "ID09", "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of identifying end-use electrical appliances from their\nindividual consumption profiles, known as the appliance identification problem,\nis a primary stage in both Non-Intrusive Load Monitoring (NILM) and automated\nplug-wise metering. Therefore, appliance identification has received dedicated\nstudies with various electric appliance signatures, classification models, and\nevaluation datasets. In this paper, we propose a neural network ensembles\napproach to address this problem using high resolution measurements. The models\nare trained on the raw current and voltage waveforms, and thus, eliminating the\nneed for well engineered appliance signatures. We evaluate the proposed model\non a publicly available appliance dataset from 55 residential buildings, 11\nappliance categories, and over 1000 measurements. We further study the\nstability of the trained models with respect to training dataset, sampling\nfrequency, and variations in the steady-state operation of appliances.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 04:32:35 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Barsim", "Karim Said", ""], ["Mauch", "Lukas", ""], ["Yang", "Bin", ""]]}, {"id": "1802.06965", "submitter": "Zakaria Mhammedi", "authors": "Zakaria Mhammedi, Robert C. Williamson", "title": "Constant Regret, Generalized Mixability, and Mirror Descent", "comments": "48 pages, accepted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting of prediction with expert advice; a learner makes\npredictions by aggregating those of a group of experts. Under this setting, and\nfor the right choice of loss function and \"mixing\" algorithm, it is possible\nfor the learner to achieve a constant regret regardless of the number of\nprediction rounds. For example, a constant regret can be achieved for\n\\emph{mixable} losses using the \\emph{aggregating algorithm}. The\n\\emph{Generalized Aggregating Algorithm} (GAA) is a name for a family of\nalgorithms parameterized by convex functions on simplices (entropies), which\nreduce to the aggregating algorithm when using the \\emph{Shannon entropy}\n$\\operatorname{S}$. For a given entropy $\\Phi$, losses for which a constant\nregret is possible using the \\textsc{GAA} are called $\\Phi$-mixable. Which\nlosses are $\\Phi$-mixable was previously left as an open question. We fully\ncharacterize $\\Phi$-mixability and answer other open questions posed by\n\\cite{Reid2015}. We show that the Shannon entropy $\\operatorname{S}$ is\nfundamental in nature when it comes to mixability; any $\\Phi$-mixable loss is\nnecessarily $\\operatorname{S}$-mixable, and the lowest worst-case regret of the\n\\textsc{GAA} is achieved using the Shannon entropy. Finally, by leveraging the\nconnection between the \\emph{mirror descent algorithm} and the update step of\nthe GAA, we suggest a new \\emph{adaptive} generalized aggregating algorithm and\nanalyze its performance in terms of the regret bound.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 04:40:51 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 03:55:02 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 05:00:12 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Mhammedi", "Zakaria", ""], ["Williamson", "Robert C.", ""]]}, {"id": "1802.06984", "submitter": "Lior Wolf", "authors": "Eliya Nachmani, Adam Polyak, Yaniv Taigman, Lior Wolf", "title": "Fitting New Speakers Based on a Short Untranscribed Sample", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based Text To Speech systems have the potential to generalize from\none speaker to the next and thus require a relatively short sample of any new\nvoice. However, this promise is currently largely unrealized. We present a\nmethod that is designed to capture a new speaker from a short untranscribed\naudio sample. This is done by employing an additional network that given an\naudio sample, places the speaker in the embedding space. This network is\ntrained as part of the speech synthesis system using various consistency\nlosses. Our results demonstrate a greatly improved performance on both the\ndataset speakers, and, more importantly, when fitting new voices, even from\nvery short samples.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 07:06:13 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Nachmani", "Eliya", ""], ["Polyak", "Adam", ""], ["Taigman", "Yaniv", ""], ["Wolf", "Lior", ""]]}, {"id": "1802.07007", "submitter": "Zhiyong Cui", "authors": "Zhiyong Cui, Kristian Henrickson, Ruimin Ke, Ziyuan Pu, Yinhai Wang", "title": "Traffic Graph Convolutional Recurrent Neural Network: A Deep Learning\n  Framework for Network-Scale Traffic Learning and Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting is a particularly challenging application of\nspatiotemporal forecasting, due to the time-varying traffic patterns and the\ncomplicated spatial dependencies on road networks. To address this challenge,\nwe learn the traffic network as a graph and propose a novel deep learning\nframework, Traffic Graph Convolutional Long Short-Term Memory Neural Network\n(TGC-LSTM), to learn the interactions between roadways in the traffic network\nand forecast the network-wide traffic state. We define the traffic graph\nconvolution based on the physical network topology. The relationship between\nthe proposed traffic graph convolution and the spectral graph convolution is\nalso discussed. An L1-norm on graph convolution weights and an L2-norm on graph\nconvolution features are added to the model's loss function to enhance the\ninterpretability of the proposed model. Experimental results show that the\nproposed model outperforms baseline methods on two real-world traffic state\ndatasets. The visualization of the graph convolution weights indicates that the\nproposed framework can recognize the most influential road segments in\nreal-world traffic networks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 08:40:21 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 08:06:39 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 01:09:07 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Cui", "Zhiyong", ""], ["Henrickson", "Kristian", ""], ["Ke", "Ruimin", ""], ["Pu", "Ziyuan", ""], ["Wang", "Yinhai", ""]]}, {"id": "1802.07008", "submitter": "Amin Fehri", "authors": "Amin Fehri (CMM), Santiago Velasco-Forero (CMM), Fernand Meyer (CMM)", "title": "Segmentation hi\\'erarchique faiblement supervis\\'ee", "comments": "in French", "journal-ref": "26e colloque GRETSI, Sep 2017, Juan-les-Pins, France", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image segmentation is the process of partitioning an image into a set of\nmeaningful regions according to some criteria. Hierarchical segmentation has\nemerged as a major trend in this regard as it favors the emergence of important\nregions at different scales. On the other hand, many methods allow us to have\nprior information on the position of structures of interest in the images. In\nthis paper, we present a versatile hierarchical segmentation method that takes\ninto account any prior spatial information and outputs a hierarchical\nsegmentation that emphasizes the contours or regions of interest while\npreserving the important structures in the image. An application of this method\nto the weakly-supervised segmentation problem is presented.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 08:42:05 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Fehri", "Amin", "", "CMM"], ["Velasco-Forero", "Santiago", "", "CMM"], ["Meyer", "Fernand", "", "CMM"]]}, {"id": "1802.07024", "submitter": "Avanti Shrikumar", "authors": "Avanti Shrikumar, Amr Alexandari, Anshul Kundaje", "title": "A Flexible and Adaptive Framework for Abstention Under Class Imbalance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical applications of machine learning, it is often desirable to\nidentify and abstain on examples where the model's predictions are likely to be\nincorrect. Much of the prior work on this topic focused on out-of-distribution\ndetection or performance metrics such as top-k accuracy. Comparatively little\nattention was given to metrics such as area-under-the-curve or Cohen's Kappa,\nwhich are extremely relevant for imbalanced datasets. Abstention strategies\naimed at top-k accuracy can produce poor results on these metrics when applied\nto imbalanced datasets, even when all examples are in-distribution. We propose\na framework to address this gap. Our framework leverages the insight that\ncalibrated probability estimates can be used as a proxy for the true class\nlabels, thereby allowing us to estimate the change in an arbitrary metric if an\nexample were abstained on. Using this framework, we derive computationally\nefficient metric-specific abstention algorithms for optimizing the sensitivity\nat a target specificity level, the area under the ROC, and the weighted Cohen's\nKappa. Because our method relies only on calibrated probability estimates, we\nfurther show that by leveraging recent work on domain adaptation under label\nshift, we can generalize to test-set distributions that may have a different\nclass imbalance compared to the training set distribution. On various\nexperiments involving medical imaging, natural language processing, computer\nvision and genomics, we demonstrate the effectiveness of our approach. Source\ncode available at https://github.com/blindauth/abstention. Colab notebooks\nreproducing results available at\nhttps://github.com/blindauth/abstention_experiments.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 09:24:49 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 00:21:34 GMT"}, {"version": "v3", "created": "Fri, 14 Sep 2018 05:11:25 GMT"}, {"version": "v4", "created": "Wed, 30 Oct 2019 06:02:57 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Shrikumar", "Avanti", ""], ["Alexandari", "Amr", ""], ["Kundaje", "Anshul", ""]]}, {"id": "1802.07028", "submitter": "Paul Rolland", "authors": "Paul Rolland, Jonathan Scarlett, Ilija Bogunovic and Volkan Cevher", "title": "High-Dimensional Bayesian Optimization via Additive Models with\n  Overlapping Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a popular technique for sequential black-box\nfunction optimization, with applications including parameter tuning, robotics,\nenvironmental monitoring, and more. One of the most important challenges in BO\nis the development of algorithms that scale to high dimensions, which remains a\nkey open problem despite recent progress. In this paper, we consider the\napproach of Kandasamy et al. (2015), in which the high-dimensional function\ndecomposes as a sum of lower-dimensional functions on subsets of the underlying\nvariables. In particular, we significantly generalize this approach by lifting\nthe assumption that the subsets are disjoint, and consider additive models with\narbitrary overlap among the subsets. By representing the dependencies via a\ngraph, we deduce an efficient message passing algorithm for optimizing the\nacquisition function. In addition, we provide an algorithm for learning the\ngraph from samples based on Gibbs sampling. We empirically demonstrate the\neffectiveness of our methods on both synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 09:42:03 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 13:05:53 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Rolland", "Paul", ""], ["Scarlett", "Jonathan", ""], ["Bogunovic", "Ilija", ""], ["Cevher", "Volkan", ""]]}, {"id": "1802.07044", "submitter": "L\\'eonard Blier", "authors": "L\\'eonard Blier, Yann Ollivier", "title": "The Description Length of Deep Learning Models", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solomonoff's general theory of inference and the Minimum Description Length\nprinciple formalize Occam's razor, and hold that a good model of data is a\nmodel that is good at losslessly compressing the data, including the cost of\ndescribing the model itself. Deep neural networks might seem to go against this\nprinciple given the large number of parameters to be encoded.\n  We demonstrate experimentally the ability of deep neural networks to compress\nthe training data even when accounting for parameter encoding. The compression\nviewpoint originally motivated the use of variational methods in neural\nnetworks. Unexpectedly, we found that these variational methods provide\nsurprisingly poor compression bounds, despite being explicitly built to\nminimize such bounds. This might explain the relatively poor practical\nperformance of variational methods in deep learning. On the other hand, simple\nincremental encoding methods yield excellent compression values on deep\nnetworks, vindicating Solomonoff's approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 10:15:26 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 13:41:03 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 08:15:32 GMT"}, {"version": "v4", "created": "Mon, 29 Oct 2018 14:28:50 GMT"}, {"version": "v5", "created": "Thu, 1 Nov 2018 11:23:09 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Blier", "L\u00e9onard", ""], ["Ollivier", "Yann", ""]]}, {"id": "1802.07051", "submitter": "Hanti Lin", "authors": "Hanti Lin and Jiji Zhang", "title": "On Learning Causal Structures from Non-Experimental Data without Any\n  Faithfulness Assumption", "comments": "To be published in Proceedings of Machine Learning Research, volume\n  117", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of learning, from non-experimental data, the causal\n(Markov equivalence) structure of the true, unknown causal Bayesian network\n(CBN) on a given, fixed set of (categorical) variables. This learning problem\nis known to be so hard that there is no learning algorithm that converges to\nthe truth for all possible CBNs (on the given set of variables). So the\nconvergence property has to be sacrificed for some CBNs---but for which? In\nresponse, the standard practice has been to design and employ learning\nalgorithms that secure the convergence property for at least all the CBNs that\nsatisfy the famous faithfulness condition, which implies sacrificing the\nconvergence property for some CBNs that violate the faithfulness condition\n(Spirtes et al. 2000). This standard design practice can be justified by\nassuming---that is, accepting on faith---that the true, unknown CBN satisfies\nthe faithfulness condition. But the real question is this: Is it possible to\nexplain, without assuming the faithfulness condition or any of its weaker\nvariants, why it is mandatory rather than optional to follow the standard\ndesign practice? This paper aims to answer the above question in the\naffirmative. We first define an array of modes of convergence to the truth as\ndesiderata that might or might not be achieved by a causal learning algorithm.\nThose modes of convergence concern (i) how pervasive the domain of convergence\nis on the space of all possible CBNs and (ii) how uniformly the convergence\nhappens. Then we prove a result to the following effect: for any learning\nalgorithm that tackles the causal learning problem in question, if it achieves\nthe best achievable mode of convergence (considered in this paper), then it\nmust follow the standard design practice of converging to the truth for at\nleast all CBNs that satisfy the faithfulness condition---it is a requirement,\nnot an option.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 10:46:12 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 05:49:25 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Lin", "Hanti", ""], ["Zhang", "Jiji", ""]]}, {"id": "1802.07073", "submitter": "Ilija Bogunovic", "authors": "Ilija Bogunovic, Junyao Zhao, Volkan Cevher", "title": "Robust Maximization of Non-Submodular Objectives", "comments": "Revision of Section 4.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of maximizing a monotone set function subject to a\ncardinality constraint $k$ in the setting where some number of elements $\\tau$\nis deleted from the returned set. The focus of this work is on the worst-case\nadversarial setting. While there exist constant-factor guarantees when the\nfunction is submodular, there are no guarantees for non-submodular objectives.\nIn this work, we present a new algorithm Oblivious-Greedy and prove the first\nconstant-factor approximation guarantees for a wider class of non-submodular\nobjectives. The obtained theoretical bounds are the first constant-factor\nbounds that also hold in the linear regime, i.e. when the number of deletions\n$\\tau$ is linear in $k$. Our bounds depend on established parameters such as\nthe submodularity ratio and some novel ones such as the inverse curvature. We\nbound these parameters for two important objectives including support selection\nand variance reduction. Finally, we numerically demonstrate the robust\nperformance of Oblivious-Greedy for these two objectives on various datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 12:02:01 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 10:58:37 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 11:24:31 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bogunovic", "Ilija", ""], ["Zhao", "Junyao", ""], ["Cevher", "Volkan", ""]]}, {"id": "1802.07088", "submitter": "Edouard Oyallon", "authors": "J\\\"orn-Henrik Jacobsen (IvI), Arnold Smeulders (IvI), Edouard Oyallon\n  (CVN, GALEN, SEQUEL, DI-ENS)", "title": "i-RevNet: Deep Invertible Networks", "comments": null, "journal-ref": "ICLR 2018 - International Conference on Learning Representations,\n  Apr 2018, Vancouver, Canada. 2018, https://iclr.cc/", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely believed that the success of deep convolutional networks is\nbased on progressively discarding uninformative variability about the input\nwith respect to the problem at hand. This is supported empirically by the\ndifficulty of recovering images from their hidden representations, in most\ncommonly used network architectures. In this paper we show via a one-to-one\nmapping that this loss of information is not a necessary condition to learn\nrepresentations that generalize well on complicated problems, such as ImageNet.\nVia a cascade of homeomorphic layers, we build the i-RevNet, a network that can\nbe fully inverted up to the final projection onto the classes, i.e. no\ninformation is discarded. Building an invertible architecture is difficult, for\none, because the local inversion is ill-conditioned, we overcome this by\nproviding an explicit inverse. An analysis of i-RevNets learned representations\nsuggests an alternative explanation for the success of deep networks by a\nprogressive contraction and linear separation with depth. To shed light on the\nnature of the model learned by the i-RevNet we reconstruct linear\ninterpolations between natural image representations.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 12:38:49 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Jacobsen", "J\u00f6rn-Henrik", "", "IvI"], ["Smeulders", "Arnold", "", "IvI"], ["Oyallon", "Edouard", "", "CVN, GALEN, SEQUEL, DI-ENS"]]}, {"id": "1802.07089", "submitter": "Qiuyuan Huang", "authors": "Qiuyuan Huang, Li Deng, Dapeng Wu, Chang Liu, Xiaodong He", "title": "Attentive Tensor Product Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new architecture - Attentive Tensor Product Learning\n(ATPL) - to represent grammatical structures in deep learning models. ATPL is a\nnew architecture to bridge this gap by exploiting Tensor Product\nRepresentations (TPR), a structured neural-symbolic model developed in\ncognitive science, aiming to integrate deep learning with explicit language\nstructures and rules. The key ideas of ATPL are: 1) unsupervised learning of\nrole-unbinding vectors of words via TPR-based deep neural network; 2) employing\nattention modules to compute TPR; and 3) integration of TPR with typical deep\nlearning architectures including Long Short-Term Memory (LSTM) and Feedforward\nNeural Network (FFNN). The novelty of our approach lies in its ability to\nextract the grammatical structure of a sentence by using role-unbinding\nvectors, which are obtained in an unsupervised manner. This ATPL approach is\napplied to 1) image captioning, 2) part of speech (POS) tagging, and 3)\nconstituency parsing of a sentence. Experimental results demonstrate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 12:42:07 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 05:14:18 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Huang", "Qiuyuan", ""], ["Deng", "Li", ""], ["Wu", "Dapeng", ""], ["Liu", "Chang", ""], ["He", "Xiaodong", ""]]}, {"id": "1802.07091", "submitter": "Yancheng Yuan", "authors": "Yancheng Yuan, Defeng Sun, Kim-Chuan Toh", "title": "An Efficient Semismooth Newton Based Algorithm for Convex Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering may be the most fundamental problem in unsupervised learning which\nis still active in machine learning research because its importance in many\napplications. Popular methods like K-means, may suffer from instability as they\nare prone to get stuck in its local minima. Recently, the sum-of-norms (SON)\nmodel (also known as clustering path), which is a convex relaxation of\nhierarchical clustering model, has been proposed in [7] and [5] Although\nnumerical algorithms like ADMM and AMA are proposed to solve convex clustering\nmodel [2], it is known to be very challenging to solve large-scale problems. In\nthis paper, we propose a semi-smooth Newton based augmented Lagrangian method\nfor large-scale convex clustering problems. Extensive numerical experiments on\nboth simulated and real data demonstrate that our algorithm is highly efficient\nand robust for solving large-scale problems. Moreover, the numerical results\nalso show the superior performance and scalability of our algorithm compared to\nexisting first-order methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 12:48:02 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Yuan", "Yancheng", ""], ["Sun", "Defeng", ""], ["Toh", "Kim-Chuan", ""]]}, {"id": "1802.07098", "submitter": "Ehsan Kazemi", "authors": "Moran Feldman and Amin Karbasi and Ehsan Kazemi", "title": "Do Less, Get More: Streaming Submodular Maximization with Subsampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop the first one-pass streaming algorithm for\nsubmodular maximization that does not evaluate the entire stream even once. By\ncarefully subsampling each element of data stream, our algorithm enjoys the\ntightest approximation guarantees in various settings while having the smallest\nmemory footprint and requiring the lowest number of function evaluations. More\nspecifically, for a monotone submodular function and a $p$-matchoid constraint,\nour randomized algorithm achieves a $4p$ approximation ratio (in expectation)\nwith $O(k)$ memory and $O(km/p)$ queries per element ($k$ is the size of the\nlargest feasible solution and $m$ is the number of matroids used to define the\nconstraint). For the non-monotone case, our approximation ratio increases only\nslightly to $4p+2-o(1)$. To the best or our knowledge, our algorithm is the\nfirst that combines the benefits of streaming and subsampling in a novel way in\norder to truly scale submodular maximization to massive machine learning\nproblems. To showcase its practicality, we empirically evaluated the\nperformance of our algorithm on a video summarization application and observed\nthat it outperforms the state-of-the-art algorithm by up to fifty fold, while\nmaintaining practically the same utility.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 13:11:48 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Feldman", "Moran", ""], ["Karbasi", "Amin", ""], ["Kazemi", "Ehsan", ""]]}, {"id": "1802.07107", "submitter": "Yakov Babichenko", "authors": "Yakov Babichenko and Dan Garber", "title": "Learning of Optimal Forecast Aggregation in Partial Evidence\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the forecast aggregation problem in repeated settings, where the\nforecasts are done on a binary event. At each period multiple experts provide\nforecasts about an event. The goal of the aggregator is to aggregate those\nforecasts into a subjective accurate forecast. We assume that experts are\nBayesian; namely they share a common prior, each expert is exposed to some\nevidence, and each expert applies Bayes rule to deduce his forecast. The\naggregator is ignorant with respect to the information structure (i.e.,\ndistribution over evidence) according to which experts make their prediction.\nThe aggregator observes the experts' forecasts only. At the end of each period\nthe actual state is realized. We focus on the question whether the aggregator\ncan learn to aggregate optimally the forecasts of the experts, where the\noptimal aggregation is the Bayesian aggregation that takes into account all the\ninformation (evidence) in the system.\n  We consider the class of partial evidence information structures, where each\nexpert is exposed to a different subset of conditionally independent signals.\nOur main results are positive; We show that optimal aggregation can be learned\nin polynomial time in a quite wide range of instances of the partial evidence\nenvironments. We provide a tight characterization of the instances where\nlearning is possible and impossible.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 13:35:45 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Babichenko", "Yakov", ""], ["Garber", "Dan", ""]]}, {"id": "1802.07124", "submitter": "Mahdieh Abbasi", "authors": "Mahdieh Abbasi, Christian Gagn\\'e", "title": "Out-distribution training confers robustness to deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The easiness at which adversarial instances can be generated in deep neural\nnetworks raises some fundamental questions on their functioning and concerns on\ntheir use in critical systems. In this paper, we draw a connection between\nover-generalization and adversaries: a possible cause of adversaries lies in\nmodels designed to make decisions all over the input space, leading to\ninappropriate high-confidence decisions in parts of the input space not\nrepresented in the training set. We empirically show an augmented neural\nnetwork, which is not trained on any types of adversaries, can increase the\nrobustness by detecting black-box one-step adversaries, i.e. assimilated to\nout-distribution samples, and making generation of white-box one-step\nadversaries harder.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 14:27:40 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 14:19:41 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2018 17:14:35 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Abbasi", "Mahdieh", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "1802.07126", "submitter": "Venkata Sriram Siddhardh (Sid) Nadendla", "authors": "Venkata Sriram Siddhardh Nadendla and Cedric Langbort", "title": "On Estimating Multi-Attribute Choice Preferences using Private Signals\n  and Matrix Factorization", "comments": "6 pages, 2 figures, to be presented at CISS conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Revealed preference theory studies the possibility of modeling an agent's\nrevealed preferences and the construction of a consistent utility function.\nHowever, modeling agent's choices over preference orderings is not always\npractical and demands strong assumptions on human rationality and\ndata-acquisition abilities. Therefore, we propose a simple generative choice\nmodel where agents are assumed to generate the choice probabilities based on\nlatent factor matrices that capture their choice evaluation across multiple\nattributes. Since the multi-attribute evaluation is typically hidden within the\nagent's psyche, we consider a signaling mechanism where agents are provided\nwith choice information through private signals, so that the agent's choices\nprovide more insight about his/her latent evaluation across multiple\nattributes. We estimate the choice model via a novel multi-stage matrix\nfactorization algorithm that minimizes the average deviation of the factor\nestimates from choice data. Simulation results are presented to validate the\nestimation performance of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 08:46:37 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Nadendla", "Venkata Sriram Siddhardh", ""], ["Langbort", "Cedric", ""]]}, {"id": "1802.07128", "submitter": "Matthew Joseph", "authors": "Matthew Joseph, Aaron Roth, Jonathan Ullman, Bo Waggoner", "title": "Local Differential Privacy for Evolving Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are now several large scale deployments of differential privacy used to\ncollect statistical information about users. However, these deployments\nperiodically recollect the data and recompute the statistics using algorithms\ndesigned for a single use. As a result, these systems do not provide meaningful\nprivacy guarantees over long time scales. Moreover, existing techniques to\nmitigate this effect do not apply in the \"local model\" of differential privacy\nthat these systems use.\n  In this paper, we introduce a new technique for local differential privacy\nthat makes it possible to maintain up-to-date statistics over time, with\nprivacy guarantees that degrade only in the number of changes in the underlying\ndistribution rather than the number of collection periods. We use our technique\nfor tracking a changing statistic in the setting where users are partitioned\ninto an unknown collection of groups, and at every time period each user draws\na single bit from a common (but changing) group-specific distribution. We also\nprovide an application to frequency and heavy-hitter estimation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 14:36:35 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 19:49:14 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 19:32:30 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Joseph", "Matthew", ""], ["Roth", "Aaron", ""], ["Ullman", "Jonathan", ""], ["Waggoner", "Bo", ""]]}, {"id": "1802.07129", "submitter": "Il Yong Chun", "authors": "Il Yong Chun and Jeffrey A. Fessler", "title": "Deep BCD-Net Using Identical Encoding-Decoding CNN Structures for\n  Iterative Image Recovery", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In \"extreme\" computational imaging that collects extremely undersampled or\nnoisy measurements, obtaining an accurate image within a reasonable computing\ntime is challenging. Incorporating image mapping convolutional neural networks\n(CNN) into iterative image recovery has great potential to resolve this issue.\nThis paper 1) incorporates image mapping CNN using identical convolutional\nkernels in both encoders and decoders into a block coordinate descent (BCD)\nsignal recovery method and 2) applies alternating direction method of\nmultipliers to train the aforementioned image mapping CNN. We refer to the\nproposed recurrent network as BCD-Net using identical encoding-decoding CNN\nstructures. Numerical experiments show that, for a) denoising low\nsignal-to-noise-ratio images and b) extremely undersampled magnetic resonance\nimaging, the proposed BCD-Net achieves significantly more accurate image\nrecovery, compared to BCD-Net using distinct encoding-decoding structures\nand/or the conventional image recovery model using both wavelets and total\nvariation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 14:37:30 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 22:16:11 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Chun", "Il Yong", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1802.07176", "submitter": "Sumeet Katariya", "authors": "Sumeet Katariya, Lalit Jain, Nandana Sengupta, James Evans, Robert\n  Nowak", "title": "Adaptive Sampling for Coarse Ranking", "comments": "Accepted at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of active coarse ranking, where the goal is to sort\nitems according to their means into clusters of pre-specified sizes, by\nadaptively sampling from their reward distributions. This setting is useful in\nmany social science applications involving human raters and the approximate\nrank of every item is desired. Approximate or coarse ranking can significantly\nreduce the number of ratings required in comparison to the number needed to\nfind an exact ranking. We propose a computationally efficient PAC algorithm\nLUCBRank for coarse ranking, and derive an upper bound on its sample\ncomplexity. We also derive a nearly matching distribution-dependent lower\nbound. Experiments on synthetic as well as real-world data show that LUCBRank\nperforms better than state-of-the-art baseline methods, even when these methods\nhave the advantage of knowing the underlying parametric model.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 16:16:38 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Katariya", "Sumeet", ""], ["Jain", "Lalit", ""], ["Sengupta", "Nandana", ""], ["Evans", "James", ""], ["Nowak", "Robert", ""]]}, {"id": "1802.07191", "submitter": "Kirthevasan Kandasamy", "authors": "Kirthevasan Kandasamy, Willie Neiswanger, Jeff Schneider, Barnabas\n  Poczos, Eric Xing", "title": "Neural Architecture Search with Bayesian Optimisation and Optimal\n  Transport", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS) 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimisation (BO) refers to a class of methods for global\noptimisation of a function $f$ which is only accessible via point evaluations.\nIt is typically used in settings where $f$ is expensive to evaluate. A common\nuse case for BO in machine learning is model selection, where it is not\npossible to analytically model the generalisation performance of a statistical\nmodel, and we resort to noisy and expensive training and validation procedures\nto choose the best model. Conventional BO methods have focused on Euclidean and\ncategorical domains, which, in the context of model selection, only permits\ntuning scalar hyper-parameters of machine learning algorithms. However, with\nthe surge of interest in deep learning, there is an increasing demand to tune\nneural network \\emph{architectures}. In this work, we develop NASBOT, a\nGaussian process based BO framework for neural architecture search. To\naccomplish this, we develop a distance metric in the space of neural network\narchitectures which can be computed efficiently via an optimal transport\nprogram. This distance might be of independent interest to the deep learning\ncommunity as it may find applications outside of BO. We demonstrate that NASBOT\noutperforms other alternatives for architecture search in several cross\nvalidation based model selection tasks on multi-layer perceptrons and\nconvolutional neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 17:45:44 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 15:17:17 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 18:23:39 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Kandasamy", "Kirthevasan", ""], ["Neiswanger", "Willie", ""], ["Schneider", "Jeff", ""], ["Poczos", "Barnabas", ""], ["Xing", "Eric", ""]]}, {"id": "1802.07207", "submitter": "Ahmed Alaa", "authors": "Ahmed M. Alaa and Mihaela van der Schaar", "title": "AutoPrognosis: Automated Clinical Prognostic Modeling via Bayesian\n  Optimization with Structured Kernel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical prognostic models derived from largescale healthcare data can inform\ncritical diagnostic and therapeutic decisions. To enable off-theshelf usage of\nmachine learning (ML) in prognostic research, we developed AUTOPROGNOSIS: a\nsystem for automating the design of predictive modeling pipelines tailored for\nclinical prognosis. AUTOPROGNOSIS optimizes ensembles of pipeline\nconfigurations efficiently using a novel batched Bayesian optimization (BO)\nalgorithm that learns a low-dimensional decomposition of the pipelines\nhigh-dimensional hyperparameter space in concurrence with the BO procedure.\nThis is achieved by modeling the pipelines performances as a black-box function\nwith a Gaussian process prior, and modeling the similarities between the\npipelines baseline algorithms via a sparse additive kernel with a Dirichlet\nprior. Meta-learning is used to warmstart BO with external data from similar\npatient cohorts by calibrating the priors using an algorithm that mimics the\nempirical Bayes method. The system automatically explains its predictions by\npresenting the clinicians with logical association rules that link patients\nfeatures to predicted risk strata. We demonstrate the utility of AUTOPROGNOSIS\nusing 10 major patient cohorts representing various aspects of cardiovascular\npatient care.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 17:18:56 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Alaa", "Ahmed M.", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1802.07229", "submitter": "Gautam Kamath", "authors": "Steve Hanneke, Adam Kalai, Gautam Kamath, Christos Tzamos", "title": "Actively Avoiding Nonsense in Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generative model may generate utter nonsense when it is fit to maximize the\nlikelihood of observed data. This happens due to \"model error,\" i.e., when the\ntrue data generating distribution does not fit within the class of generative\nmodels being learned. To address this, we propose a model of active\ndistribution learning using a binary invalidity oracle that identifies some\nexamples as clearly invalid, together with random positive examples sampled\nfrom the true distribution. The goal is to maximize the likelihood of the\npositive examples subject to the constraint of (almost) never generating\nexamples labeled invalid by the oracle. Guarantees are agnostic compared to a\nclass of probability distributions. We show that, while proper learning often\nrequires exponentially many queries to the invalidity oracle, improper\ndistribution learning can be done using polynomially many queries.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 18:08:53 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Hanneke", "Steve", ""], ["Kalai", "Adam", ""], ["Kamath", "Gautam", ""], ["Tzamos", "Christos", ""]]}, {"id": "1802.07239", "submitter": "Christos Kaplanis", "authors": "Christos Kaplanis, Murray Shanahan, Claudia Clopath", "title": "Continual Reinforcement Learning with Complex Synapses", "comments": "Accepted at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike humans, who are capable of continual learning over their lifetimes,\nartificial neural networks have long been known to suffer from a phenomenon\nknown as catastrophic forgetting, whereby new learning can lead to abrupt\nerasure of previously acquired knowledge. Whereas in a neural network the\nparameters are typically modelled as scalar values, an individual synapse in\nthe brain comprises a complex network of interacting biochemical components\nthat evolve at different timescales. In this paper, we show that by equipping\ntabular and deep reinforcement learning agents with a synaptic model that\nincorporates this biological complexity (Benna & Fusi, 2016), catastrophic\nforgetting can be mitigated at multiple timescales. In particular, we find that\nas well as enabling continual learning across sequential training of two simple\ntasks, it can also be used to overcome within-task forgetting by reducing the\nneed for an experience replay database.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 18:36:57 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 11:07:28 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Kaplanis", "Christos", ""], ["Shanahan", "Murray", ""], ["Clopath", "Claudia", ""]]}, {"id": "1802.07244", "submitter": "Ali Zarezade", "authors": "Ali Zarezade, Abir De, Utkarsh Upadhyay, Hamid R. Rabiee, Manuel\n  Gomez-Rodriguez", "title": "Steering Social Activity: A Stochastic Optimal Control Point Of View", "comments": "To appear in JMLR 2018. arXiv admin note: substantial text overlap\n  with arXiv:1610.05773, arXiv:1703.02059", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User engagement in online social networking depends critically on the level\nof social activity in the corresponding platform--the number of online actions,\nsuch as posts, shares or replies, taken by their users. Can we design\ndata-driven algorithms to increase social activity? At a user level, such\nalgorithms may increase activity by helping users decide when to take an action\nto be more likely to be noticed by their peers. At a network level, they may\nincrease activity by incentivizing a few influential users to take more\nactions, which in turn will trigger additional actions by other users. In this\npaper, we model social activity using the framework of marked temporal point\nprocesses, derive an alternate representation of these processes using\nstochastic differential equations (SDEs) with jumps and, exploiting this\nalternate representation, develop two efficient online algorithms with provable\nguarantees to steer social activity both at a user and at a network level. In\ndoing so, we establish a previously unexplored connection between optimal\ncontrol of jump SDEs and doubly stochastic marked temporal point processes,\nwhich is of independent interest. Finally, we experiment both with synthetic\nand real data gathered from Twitter and show that our algorithms consistently\nsteer social activity more effectively than the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 08:03:26 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Zarezade", "Ali", ""], ["De", "Abir", ""], ["Upadhyay", "Utkarsh", ""], ["Rabiee", "Hamid R.", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1802.07245", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta, Russell Mendonca, YuXuan Liu, Pieter Abbeel, Sergey\n  Levine", "title": "Meta-Reinforcement Learning of Structured Exploration Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a fundamental challenge in reinforcement learning (RL). Many\nof the current exploration methods for deep RL use task-agnostic objectives,\nsuch as information gain or bonuses based on state visitation. However, many\npractical applications of RL involve learning more than a single task, and\nprior tasks can be used to inform how exploration should be performed in new\ntasks. In this work, we explore how prior tasks can inform an agent about how\nto explore effectively in new situations. We introduce a novel gradient-based\nfast adaptation algorithm -- model agnostic exploration with structured noise\n(MAESN) -- to learn exploration strategies from prior experience. The prior\nexperience is used both to initialize a policy and to acquire a latent\nexploration space that can inject structured stochasticity into a policy,\nproducing exploration strategies that are informed by prior knowledge and are\nmore effective than random action-space noise. We show that MAESN is more\neffective at learning exploration strategies when compared to prior meta-RL\nmethods, RL without learned exploration strategies, and task-agnostic\nexploration methods. We evaluate our method on a variety of simulated tasks:\nlocomotion with a wheeled robot, locomotion with a quadrupedal walker, and\nobject manipulation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 18:40:57 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Gupta", "Abhishek", ""], ["Mendonca", "Russell", ""], ["Liu", "YuXuan", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1802.07295", "submitter": "Christopher Frederickson", "authors": "Christopher Frederickson, Michael Moore, Glenn Dawson, Robi Polikar", "title": "Attack Strength vs. Detectability Dilemma in Adversarial Machine\n  Learning", "comments": "8 pages, 9 figures, submitted to IJCNN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the prevalence and everyday use of machine learning algorithms, along with\nour reliance on these algorithms grow dramatically, so do the efforts to attack\nand undermine these algorithms with malicious intent, resulting in a growing\ninterest in adversarial machine learning. A number of approaches have been\ndeveloped that can render a machine learning algorithm ineffective through\npoisoning or other types of attacks. Most attack algorithms typically use\nsophisticated optimization approaches, whose objective function is designed to\ncause maximum damage with respect to accuracy and performance of the algorithm\nwith respect to some task. In this effort, we show that while such an objective\nfunction is indeed brutally effective in causing maximum damage on an embedded\nfeature selection task, it often results in an attack mechanism that can be\neasily detected with an embarrassingly simple novelty or outlier detection\nalgorithm. We then propose an equally simple yet elegant solution by adding a\nregularization term to the attacker's objective function that penalizes\noutlying attack points.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 19:20:31 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Frederickson", "Christopher", ""], ["Moore", "Michael", ""], ["Dawson", "Glenn", ""], ["Polikar", "Robi", ""]]}, {"id": "1802.07301", "submitter": "Marco Mondelli", "authors": "Marco Mondelli and Andrea Montanari", "title": "On the Connection Between Learning Two-Layers Neural Networks and Tensor\n  Decomposition", "comments": "41 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish connections between the problem of learning a two-layer neural\nnetwork and tensor decomposition. We consider a model with feature vectors\n$\\boldsymbol x \\in \\mathbb R^d$, $r$ hidden units with weights $\\{\\boldsymbol\nw_i\\}_{1\\le i \\le r}$ and output $y\\in \\mathbb R$, i.e., $y=\\sum_{i=1}^r\n\\sigma( \\boldsymbol w_i^{\\mathsf T}\\boldsymbol x)$, with activation functions\ngiven by low-degree polynomials. In particular, if $\\sigma(x) =\na_0+a_1x+a_3x^3$, we prove that no polynomial-time learning algorithm can\noutperform the trivial predictor that assigns to each example the response\nvariable $\\mathbb E(y)$, when $d^{3/2}\\ll r\\ll d^2$. Our conclusion holds for a\n`natural data distribution', namely standard Gaussian feature vectors\n$\\boldsymbol x$, and output distributed according to a two-layer neural network\nwith random isotropic weights, and under a certain complexity-theoretic\nassumption on tensor decomposition. Roughly speaking, we assume that no\npolynomial-time algorithm can substantially outperform current methods for\ntensor decomposition based on the sum-of-squares hierarchy.\n  We also prove generalizations of this statement for higher degree polynomial\nactivations, and non-random weight vectors. Remarkably, several existing\nalgorithms for learning two-layer networks with rigorous guarantees are based\non tensor decomposition. Our results support the idea that this is indeed the\ncore computational difficulty in learning such networks, under the stated\ngenerative model for the data. As a side result, we show that under this model\nlearning the network requires accurate learning of its weights, a property that\ndoes not hold in a more general setting.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 19:40:32 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 21:05:02 GMT"}, {"version": "v3", "created": "Wed, 10 Oct 2018 10:34:16 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Mondelli", "Marco", ""], ["Montanari", "Andrea", ""]]}, {"id": "1802.07329", "submitter": "Max Kochurov", "authors": "Max Kochurov, Timur Garipov, Dmitry Podoprikhin, Dmitry Molchanov,\n  Arsenii Ashukha, Dmitry Vetrov", "title": "Bayesian Incremental Learning for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In industrial machine learning pipelines, data often arrive in parts.\nParticularly in the case of deep neural networks, it may be too expensive to\ntrain the model from scratch each time, so one would rather use a previously\nlearned model and the new data to improve performance. However, deep neural\nnetworks are prone to getting stuck in a suboptimal solution when trained on\nonly new data as compared to the full dataset. Our work focuses on a continuous\nlearning setup where the task is always the same and new parts of data arrive\nsequentially. We apply a Bayesian approach to update the posterior\napproximation with each new piece of data and find this method to outperform\nthe traditional approach in our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 21:11:17 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 14:56:37 GMT"}, {"version": "v3", "created": "Tue, 27 Mar 2018 22:28:02 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Kochurov", "Max", ""], ["Garipov", "Timur", ""], ["Podoprikhin", "Dmitry", ""], ["Molchanov", "Dmitry", ""], ["Ashukha", "Arsenii", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1802.07369", "submitter": "Qiuyi Wu", "authors": "Qiuyi Wu, Ernest Fokoue, Dhireesha Kudithipudi", "title": "On the Statistical Challenges of Echo State Networks and Some Potential\n  Remedies", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo state networks are powerful recurrent neural networks. However, they are\noften unstable and shaky, making the process of finding an good ESN for a\nspecific dataset quite hard. Obtaining a superb accuracy by using the Echo\nState Network is a challenging task. We create, develop and implement a family\nof predictably optimal robust and stable ensemble of Echo State Networks via\nregularizing the training and perturbing the input. Furthermore, several\ndistributions of weights have been tried based on the shape to see if the shape\nof the distribution has the impact for reducing the error. We found ESN can\ntrack in short term for most dataset, but it collapses in the long run.\nShort-term tracking with large size reservoir enables ESN to perform strikingly\nwith superior prediction. Based on this scenario, we go a further step to\naggregate many of ESNs into an ensemble to lower the variance and stabilize the\nsystem by stochastic replications and bootstrapping of input data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 22:56:17 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Wu", "Qiuyi", ""], ["Fokoue", "Ernest", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1802.07372", "submitter": "Zhe Wang", "authors": "Zhe Wang, Yi Zhou, Yingbin Liang, Guanghui Lan", "title": "Stochastic Variance-Reduced Cubic Regularization for Nonconvex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cubic regularization (CR) is an optimization method with emerging popularity\ndue to its capability to escape saddle points and converge to second-order\nstationary solutions for nonconvex optimization. However, CR encounters a high\nsample complexity issue for finite-sum problems with a large data size.\n%Various inexact variants of CR have been proposed to improve the sample\ncomplexity. In this paper, we propose a stochastic variance-reduced\ncubic-regularization (SVRC) method under random sampling, and study its\nconvergence guarantee as well as sample complexity. We show that the iteration\ncomplexity of SVRC for achieving a second-order stationary solution within\n$\\epsilon$ accuracy is $O(\\epsilon^{-3/2})$, which matches the state-of-art\nresult on CR types of methods. Moreover, our proposed variance reduction scheme\nsignificantly reduces the per-iteration sample complexity. The resulting total\nHessian sample complexity of our SVRC is ${\\Oc}(N^{2/3} \\epsilon^{-3/2})$,\nwhich outperforms the state-of-art result by a factor of $O(N^{2/15})$. We also\nstudy our SVRC under random sampling without replacement scheme, which yields a\nlower per-iteration sample complexity, and hence justifies its practical\napplicability.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 23:15:17 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 00:25:29 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Wang", "Zhe", ""], ["Zhou", "Yi", ""], ["Liang", "Yingbin", ""], ["Lan", "Guanghui", ""]]}, {"id": "1802.07379", "submitter": "Raphael Petegrosso", "authors": "Zhuliu Li, Raphael Petegrosso, Shaden Smith, David Sterling, George\n  Karypis, Rui Kuang", "title": "Scalable Label Propagation for Multi-relational Learning on the Tensor\n  Product of Graphs", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-relational learning on knowledge graphs infers high-order relations\namong the entities across the graphs. This learning task can be solved by label\npropagation on the tensor product of the knowledge graphs to learn the\nhigh-order relations as a tensor. In this paper, we generalize a widely used\nlabel propagation model to the normalized tensor product graph, and propose an\noptimization formulation and a scalable Low-rank Tensor-based Label Propagation\nalgorithm (LowrankTLP) to infer multi-relations for two learning tasks,\nhyperlink prediction and multiple graph alignment. The optimization formulation\nminimizes the upper bound of the noisy tensor estimation error for multiple\ngraph alignment, by learning with a subset of the eigen-pairs in the spectrum\nof the normalized tensor product graph. We also provide a data-dependent\ntransductive Rademacher bound for binary hyperlink prediction. We accelerate\nLowrankTLP with parallel tensor computation which enables label propagation on\na tensor product of 100 graphs each of size 1000 in less than half hour in the\nsimulation. LowrankTLP was also applied to predicting the author-paper-venue\nhyperlinks in publication records, alignment of segmented regions across up to\n26 CT-scan images and alignment of protein-protein interaction networks across\nmultiple species. The experiments demonstrate that LowrankTLP indeed well\napproximates the original label propagation with better scalability and\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 23:58:08 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 06:03:40 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Li", "Zhuliu", ""], ["Petegrosso", "Raphael", ""], ["Smith", "Shaden", ""], ["Sterling", "David", ""], ["Karypis", "George", ""], ["Kuang", "Rui", ""]]}, {"id": "1802.07382", "submitter": "Elad Tolochinsky", "authors": "Elad Tolochinsky, Dan Feldman", "title": "Generic Coreset for Scalable Learning of Monotonic Kernels: Logistic\n  Regression, Sigmoid and more", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coreset (or core-set) in this paper is a small weighted \\emph{subset} $Q$ of\nthe input set $P$ with respect to a given \\emph{monotonic} function\n$\\phi:\\REAL\\to\\REAL$ that \\emph{provably} approximates its fitting loss\n$\\sum_{p\\in P}f(p\\cdot x)$ to \\emph{any} given $x\\in\\REAL^d$. Using $Q$ we can\nobtain approximation of $x^*$ that minimizes this loss, by running\n\\emph{existing} optimization algorithms on $Q$. We provide: (I) a lower bound\nthat proves that there are sets with no coresets smaller than $n=|P|$ , (II) a\nproof that a small coreset of size near-logarithmic in $n$ exists for\n\\emph{any} input $P$, under natural assumption that holds e.g. for logistic\nregression and the sigmoid activation function. (III) a generic algorithm that\ncomputes $Q$ in $O(nd+n\\log n)$ expected time, (IV) extensive experimental\nresults with open code and benchmarks that show that the coresets are even\nsmaller in practice. Existing papers (e.g.[Huggins,Campbell,Broderick 2016])\nsuggested only specific coresets for specific input sets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 00:16:53 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 01:22:47 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Tolochinsky", "Elad", ""], ["Feldman", "Dan", ""]]}, {"id": "1802.07384", "submitter": "Xin Zhang", "authors": "Xin Zhang, Armando Solar-Lezama, and Rishabh Singh", "title": "Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic\n  Corrections", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm to generate minimal, stable, and symbolic\ncorrections to an input that will cause a neural network with ReLU activations\nto change its output. We argue that such a correction is a useful way to\nprovide feedback to a user when the network's output is different from a\ndesired output. Our algorithm generates such a correction by solving a series\nof linear constraint satisfaction problems. The technique is evaluated on three\nneural network models: one predicting whether an applicant will pay a mortgage,\none predicting whether a first-order theorem can be proved efficiently by a\nsolver using certain heuristics, and the final one judging whether a drawing is\nan accurate rendition of a canonical drawing of a cat.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 00:47:32 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 21:33:26 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Zhang", "Xin", ""], ["Solar-Lezama", "Armando", ""], ["Singh", "Rishabh", ""]]}, {"id": "1802.07389", "submitter": "Hyeontaek Lim", "authors": "Hyeontaek Lim and David G. Andersen and Michael Kaminsky", "title": "3LC: Lightweight and Effective Traffic Compression for Distributed\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance and efficiency of distributed machine learning (ML) depends\nsignificantly on how long it takes for nodes to exchange state changes.\nOverly-aggressive attempts to reduce communication often sacrifice final model\naccuracy and necessitate additional ML techniques to compensate for this loss,\nlimiting their generality. Some attempts to reduce communication incur high\ncomputation overhead, which makes their performance benefits visible only over\nslow networks.\n  We present 3LC, a lossy compression scheme for state change traffic that\nstrikes balance between multiple goals: traffic reduction, accuracy,\ncomputation overhead, and generality. It combines three new\ntechniques---3-value quantization with sparsity multiplication, quartic\nencoding, and zero-run encoding---to leverage strengths of quantization and\nsparsification techniques and avoid their drawbacks. It achieves a data\ncompression ratio of up to 39--107X, almost the same test accuracy of trained\nmodels, and high compression speed. Distributed ML frameworks can employ 3LC\nwithout modifications to existing ML algorithms. Our experiments show that 3LC\nreduces wall-clock training time of ResNet-110--based image classifiers for\nCIFAR-10 on a 10-GPU cluster by up to 16--23X compared to TensorFlow's baseline\ndesign.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 01:08:58 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Lim", "Hyeontaek", ""], ["Andersen", "David G.", ""], ["Kaminsky", "Michael", ""]]}, {"id": "1802.07400", "submitter": "Cynthia Rudin", "authors": "Cynthia Rudin, Yining Wang", "title": "Direct Learning to Rank and Rerank", "comments": null, "journal-ref": "AISTATS 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Learning-to-rank techniques have proven to be extremely useful for\nprioritization problems, where we rank items in order of their estimated\nprobabilities, and dedicate our limited resources to the top-ranked items. This\nwork exposes a serious problem with the state of learning-to-rank algorithms,\nwhich is that they are based on convex proxies that lead to poor\napproximations. We then discuss the possibility of \"exact\" reranking algorithms\nbased on mathematical programming. We prove that a relaxed version of the\n\"exact\" problem has the same optimal solution, and provide an empirical\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 02:04:40 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Rudin", "Cynthia", ""], ["Wang", "Yining", ""]]}, {"id": "1802.07401", "submitter": "Arjun Karuvally", "authors": "Arjun Karuvally", "title": "A Study into the similarity in generator and discriminator in GAN\n  architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One popular generative model that has high-quality results is the Generative\nAdversarial Networks(GAN). This type of architecture consists of two separate\nnetworks that play against each other. The generator creates an output from the\ninput noise that is given to it. The discriminator has the task of determining\nif the input to it is real or fake. This takes place constantly eventually\nleads to the generator modeling the target distribution. This paper includes a\nstudy into the actual weights learned by the network and a study into the\nsimilarity of the discriminator and generator networks. The paper also tries to\nleverage the similarity between these networks and shows that indeed both the\nnetworks may have a similar structure with experimental evidence with a novel\nshared architecture.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 02:24:28 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Karuvally", "Arjun", ""]]}, {"id": "1802.07417", "submitter": "Ashok Makkuva", "authors": "Ashok Vardhan Makkuva, Sewoong Oh, Sreeram Kannan, Pramod Viswanath", "title": "Breaking the gridlock in Mixture-of-Experts: Consistent and Efficient\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mixture-of-Experts (MoE) is a widely popular model for ensemble learning and\nis a basic building block of highly successful modern neural networks as well\nas a component in Gated Recurrent Units (GRU) and Attention networks. However,\npresent algorithms for learning MoE including the EM algorithm, and gradient\ndescent are known to get stuck in local optima. From a theoretical viewpoint,\nfinding an efficient and provably consistent algorithm to learn the parameters\nremains a long standing open problem for more than two decades. In this paper,\nwe introduce the first algorithm that learns the true parameters of a MoE model\nfor a wide class of non-linearities with global consistency guarantees. While\nexisting algorithms jointly or iteratively estimate the expert parameters and\nthe gating paramters in the MoE, we propose a novel algorithm that breaks the\ndeadlock and can directly estimate the expert parameters by sensing its echo in\na carefully designed cross-moment tensor between the inputs and the output.\nOnce the experts are known, the recovery of gating parameters still requires an\nEM algorithm; however, we show that the EM algorithm for this simplified\nproblem, unlike the joint EM algorithm, converges to the true parameters. We\nempirically validate our algorithm on both the synthetic and real data sets in\na variety of settings, and show superior performance to standard baselines.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 03:58:37 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 01:54:45 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 18:33:33 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Makkuva", "Ashok Vardhan", ""], ["Oh", "Sewoong", ""], ["Kannan", "Sreeram", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1802.07426", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Yoshua Bengio, Vikas Verma, Leslie Pack Kaelbling", "title": "Generalization in Machine Learning via Analytical Learning Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": "Massachusetts Institute of Technology (MIT), MIT-CSAIL-TR-2018-019", "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel measure-theoretic theory for machine learning\nthat does not require statistical assumptions. Based on this theory, a new\nregularization method in deep learning is derived and shown to outperform\nprevious methods in CIFAR-10, CIFAR-100, and SVHN. Moreover, the proposed\ntheory provides a theoretical basis for a family of practically successful\nregularization methods in deep learning. We discuss several consequences of our\nresults on one-shot learning, representation learning, deep learning, and\ncurriculum learning. Unlike statistical learning theory, the proposed learning\ntheory analyzes each problem instance individually via measure theory, rather\nthan a set of problem instances via statistics. As a result, it provides\ndifferent types of results and insights when compared to statistical learning\ntheory.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 05:03:52 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 17:39:36 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 22:23:14 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Bengio", "Yoshua", ""], ["Verma", "Vikas", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1802.07427", "submitter": "Peiyun Hu", "authors": "Peiyun Hu, Zachary C. Lipton, Anima Anandkumar, Deva Ramanan", "title": "Active Learning with Partial Feedback", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many active learning papers assume that the learner can simply ask for\na label and receive it, real annotation often presents a mismatch between the\nform of a label (say, one among many classes), and the form of an annotation\n(typically yes/no binary feedback). To annotate examples corpora for multiclass\nclassification, we might need to ask multiple yes/no questions, exploiting a\nlabel hierarchy if one is available. To address this more realistic setting, we\npropose active learning with partial feedback (ALPF), where the learner must\nactively choose both which example to label and which binary question to ask.\nAt each step, the learner selects an example, asking if it belongs to a chosen\n(possibly composite) class. Each answer eliminates some classes, leaving the\nlearner with a partial label. The learner may then either ask more questions\nabout the same example (until an exact label is uncovered) or move on\nimmediately, leaving the first example partially labeled. Active learning with\npartial labels requires (i) a sampling strategy to choose (example, class)\npairs, and (ii) learning from partial labels between rounds. Experiments on\nTiny ImageNet demonstrate that our most effective method improves 26%\n(relative) in top-1 classification accuracy compared to i.i.d. baselines and\nstandard active learners given 30% of the annotation budget that would be\nrequired (naively) to annotate the dataset. Moreover, ALPF-learners fully\nannotate TinyImageNet at 42% lower cost. Surprisingly, we observe that\naccounting for per-example annotation costs can alter the conventional wisdom\nthat active learners should solicit labels for hard examples.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 05:10:22 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 03:21:36 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2018 03:43:20 GMT"}, {"version": "v4", "created": "Tue, 9 Jul 2019 00:55:07 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Hu", "Peiyun", ""], ["Lipton", "Zachary C.", ""], ["Anandkumar", "Anima", ""], ["Ramanan", "Deva", ""]]}, {"id": "1802.07442", "submitter": "Nick Haber", "authors": "Nick Haber, Damian Mrowca, Li Fei-Fei, Daniel L. K. Yamins", "title": "Learning to Play with Intrinsically-Motivated Self-Aware Agents", "comments": "In NIPS 2018. 10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infants are experts at playing, with an amazing ability to generate novel\nstructured behaviors in unstructured environments that lack clear extrinsic\nreward signals. We seek to mathematically formalize these abilities using a\nneural network that implements curiosity-driven intrinsic motivation. Using a\nsimple but ecologically naturalistic simulated environment in which an agent\ncan move and interact with objects it sees, we propose a \"world-model\" network\nthat learns to predict the dynamic consequences of the agent's actions.\nSimultaneously, we train a separate explicit \"self-model\" that allows the agent\nto track the error map of its own world-model, and then uses the self-model to\nadversarially challenge the developing world-model. We demonstrate that this\npolicy causes the agent to explore novel and informative interactions with its\nenvironment, leading to the generation of a spectrum of complex behaviors,\nincluding ego-motion prediction, object attention, and object gathering.\nMoreover, the world-model that the agent learns supports improved performance\non object dynamics prediction, detection, localization and recognition tasks.\nTaken together, our results are initial steps toward creating flexible\nautonomous agents that self-supervise in complex novel physical environments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 07:01:43 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 20:08:46 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Haber", "Nick", ""], ["Mrowca", "Damian", ""], ["Fei-Fei", "Li", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "1802.07444", "submitter": "Chen Luo", "authors": "Chen Luo, Anshumali Shrivastava", "title": "Scaling-up Split-Merge MCMC with Locality Sensitive Sampling (LSS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Split-Merge MCMC (Monte Carlo Markov Chain) is one of the essential and\npopular variants of MCMC for problems when an MCMC state consists of an unknown\nnumber of components. It is well known that state-of-the-art methods for\nsplit-merge MCMC do not scale well. Strategies for rapid mixing requires smart\nand informative proposals to reduce the rejection rate. However, all known\nsmart proposals involve expensive operations to suggest informative\ntransitions. As a result, the cost of each iteration is prohibitive for massive\nscale datasets. It is further known that uninformative but computationally\nefficient proposals, such as random split-merge, leads to extremely slow\nconvergence. This tradeoff between mixing time and per update cost seems hard\nto get around.\n  In this paper, we show a sweet spot. We leverage some unique properties of\nweighted MinHash, which is a popular LSH, to design a novel class of\nsplit-merge proposals which are significantly more informative than random\nsampling but at the same time efficient to compute. Overall, we obtain a\nsuperior tradeoff between convergence and per update cost. As a direct\nconsequence, our proposals are around 6X faster than the state-of-the-art\nsampling methods on two large real datasets KDDCUP and PubMed with several\nmillions of entities and thousands of clusters.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 07:03:32 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 20:36:49 GMT"}, {"version": "v3", "created": "Fri, 12 Oct 2018 05:06:40 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Luo", "Chen", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1802.07461", "submitter": "Nick Haber", "authors": "Nick Haber, Damian Mrowca, Li Fei-Fei, Daniel L. K. Yamins", "title": "Emergence of Structured Behaviors from Curiosity-Based Intrinsic\n  Motivation", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infants are experts at playing, with an amazing ability to generate novel\nstructured behaviors in unstructured environments that lack clear extrinsic\nreward signals. We seek to replicate some of these abilities with a neural\nnetwork that implements curiosity-driven intrinsic motivation. Using a simple\nbut ecologically naturalistic simulated environment in which the agent can move\nand interact with objects it sees, the agent learns a world model predicting\nthe dynamic consequences of its actions. Simultaneously, the agent learns to\ntake actions that adversarially challenge the developing world model, pushing\nthe agent to explore novel and informative interactions with its environment.\nWe demonstrate that this policy leads to the self-supervised emergence of a\nspectrum of complex behaviors, including ego motion prediction, object\nattention, and object gathering. Moreover, the world model that the agent\nlearns supports improved performance on object dynamics prediction and\nlocalization tasks. Our results are a proof-of-principle that computational\nmodels of intrinsic motivation might account for key features of developmental\nvisuomotor learning in infants.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 08:13:12 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Haber", "Nick", ""], ["Mrowca", "Damian", ""], ["Fei-Fei", "Li", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "1802.07486", "submitter": "Pantelis Vlachas", "authors": "Pantelis R. Vlachas, Wonmin Byeon, Zhong Y. Wan, Themistoklis P.\n  Sapsis, Petros Koumoutsakos", "title": "Data-Driven Forecasting of High-Dimensional Chaotic Systems with Long\n  Short-Term Memory Networks", "comments": "31 pages", "journal-ref": null, "doi": "10.1098/rspa.2017.0844", "report-no": null, "categories": "physics.comp-ph cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a data-driven forecasting method for high-dimensional chaotic\nsystems using long short-term memory (LSTM) recurrent neural networks. The\nproposed LSTM neural networks perform inference of high-dimensional dynamical\nsystems in their reduced order space and are shown to be an effective set of\nnonlinear approximators of their attractor. We demonstrate the forecasting\nperformance of the LSTM and compare it with Gaussian processes (GPs) in time\nseries obtained from the Lorenz 96 system, the Kuramoto-Sivashinsky equation\nand a prototype climate model. The LSTM networks outperform the GPs in\nshort-term forecasting accuracy in all applications considered. A hybrid\narchitecture, extending the LSTM with a mean stochastic model (MSM-LSTM), is\nproposed to ensure convergence to the invariant measure. This novel hybrid\nmethod is fully data-driven and extends the forecasting capabilities of LSTM\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 09:59:03 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 14:06:13 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 09:34:37 GMT"}, {"version": "v4", "created": "Tue, 10 Jul 2018 15:08:42 GMT"}, {"version": "v5", "created": "Thu, 19 Sep 2019 11:08:18 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Vlachas", "Pantelis R.", ""], ["Byeon", "Wonmin", ""], ["Wan", "Zhong Y.", ""], ["Sapsis", "Themistoklis P.", ""], ["Koumoutsakos", "Petros", ""]]}, {"id": "1802.07510", "submitter": "Andreas Loukas", "authors": "Andreas Loukas, Pierre Vandergheynst", "title": "Spectrally approximating large graphs with smaller graphs", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does coarsening affect the spectrum of a general graph? We provide\nconditions such that the principal eigenvalues and eigenspaces of a coarsened\nand original graph Laplacian matrices are close. The achieved approximation is\nshown to depend on standard graph-theoretic properties, such as the degree and\neigenvalue distributions, as well as on the ratio between the coarsened and\nactual graph sizes. Our results carry implications for learning methods that\nutilize coarsening. For the particular case of spectral clustering, they imply\nthat coarse eigenvectors can be used to derive good quality assignments even\nwithout refinement---this phenomenon was previously observed, but lacked formal\njustification.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 10:58:25 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Loukas", "Andreas", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1802.07513", "submitter": "Roi Naveiro", "authors": "Roi Naveiro, Alberto Redondo, David R\\'ios Insua, Fabrizio Ruggeri", "title": "Adversarial classification: An adversarial risk analysis approach", "comments": "Published in the International Journal for Approximate Reasoning", "journal-ref": "International Journal of Approximate Reasoning, 113, 133-148\n  (2019)", "doi": "10.1016/j.ijar.2019.07.003", "report-no": null, "categories": "stat.ML cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification problems in security settings are usually contemplated as\nconfrontations in which one or more adversaries try to fool a classifier to\nobtain a benefit. Most approaches to such adversarial classification problems\nhave focused on game theoretical ideas with strong underlying common knowledge\nassumptions, which are actually not realistic in security domains. We provide\nan alternative framework to such problem based on adversarial risk analysis,\nwhich we illustrate with several examples. Computational and implementation\nissues are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 11:07:55 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 15:26:38 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 15:10:28 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Naveiro", "Roi", ""], ["Redondo", "Alberto", ""], ["Insua", "David R\u00edos", ""], ["Ruggeri", "Fabrizio", ""]]}, {"id": "1802.07528", "submitter": "Zilong Tan", "authors": "Zilong Tan and Sayan Mukherjee", "title": "Learning Integral Representations of Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a representation of Gaussian processes (GPs) based on powers of\nthe integral operator defined by a kernel function, we call these stochastic\nprocesses integral Gaussian processes (IGPs). Sample paths from IGPs are\nfunctions contained within the reproducing kernel Hilbert space (RKHS) defined\nby the kernel function, in contrast sample paths from the standard GP are not\nfunctions within the RKHS. We develop computationally efficient non-parametric\nregression models based on IGPs. The main innovation in our regression\nalgorithm is the construction of a low dimensional subspace that captures the\ninformation most relevant to explaining variation in the response. We use ideas\nfrom supervised dimension reduction to compute this subspace. The result of\nusing the construction we propose involves significant improvements in the\ncomputational complexity of estimating kernel hyper-parameters as well as\nreducing the prediction variance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 11:54:00 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 22:30:11 GMT"}, {"version": "v3", "created": "Sat, 6 Oct 2018 14:44:33 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2019 19:38:30 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Tan", "Zilong", ""], ["Mukherjee", "Sayan", ""]]}, {"id": "1802.07543", "submitter": "Tim van Erven", "authors": "Dirk van der Hoeven and Tim van Erven and Wojciech Kot{\\l}owski", "title": "The Many Faces of Exponential Weights in Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard introduction to online learning might place Online Gradient\nDescent at its center and then proceed to develop generalizations and\nextensions like Online Mirror Descent and second-order methods. Here we explore\nthe alternative approach of putting Exponential Weights (EW) first. We show\nthat many standard methods and their regret bounds then follow as a special\ncase by plugging in suitable surrogate losses and playing the EW posterior\nmean. For instance, we easily recover Online Gradient Descent by using EW with\na Gaussian prior on linearized losses, and, more generally, all instances of\nOnline Mirror Descent based on regular Bregman divergences also correspond to\nEW with a prior that depends on the mirror map. Furthermore, appropriate\nquadratic surrogate losses naturally give rise to Online Gradient Descent for\nstrongly convex losses and to Online Newton Step. We further interpret several\nrecent adaptive methods (iProd, Squint, and a variation of Coin Betting for\nexperts) as a series of closely related reductions to exp-concave surrogate\nlosses that are then handled by Exponential Weights. Finally, a benefit of our\nEW interpretation is that it opens up the possibility of sampling from the EW\nposterior distribution instead of playing the mean. As already observed by\nBubeck and Eldan, this recovers the best-known rate in Online Bandit Linear\nOptimization.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 12:38:36 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 13:08:28 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["van der Hoeven", "Dirk", ""], ["van Erven", "Tim", ""], ["Kot\u0142owski", "Wojciech", ""]]}, {"id": "1802.07564", "submitter": "Yasuhiro Fujita", "authors": "Yasuhiro Fujita and Shin-ichi Maeda", "title": "Clipped Action Policy Gradient", "comments": "Accepted at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many continuous control tasks have bounded action spaces. When policy\ngradient methods are applied to such tasks, out-of-bound actions need to be\nclipped before execution, while policies are usually optimized as if the\nactions are not clipped. We propose a policy gradient estimator that exploits\nthe knowledge of actions being clipped to reduce the variance in estimation. We\nprove that our estimator, named clipped action policy gradient (CAPG), is\nunbiased and achieves lower variance than the conventional estimator that\nignores action bounds. Experimental results demonstrate that CAPG generally\noutperforms the conventional estimator, indicating that it is a better policy\ngradient estimator for continuous control tasks. The source code is available\nat https://github.com/pfnet-research/capg.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 13:39:28 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 10:19:00 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Fujita", "Yasuhiro", ""], ["Maeda", "Shin-ichi", ""]]}, {"id": "1802.07569", "submitter": "German I. Parisi", "authors": "German I. Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan,\n  Stefan Wermter", "title": "Continual Lifelong Learning with Neural Networks: A Review", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2019.01.012.", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Humans and animals have the ability to continually acquire, fine-tune, and\ntransfer knowledge and skills throughout their lifespan. This ability, referred\nto as lifelong learning, is mediated by a rich set of neurocognitive mechanisms\nthat together contribute to the development and specialization of our\nsensorimotor skills as well as to long-term memory consolidation and retrieval.\nConsequently, lifelong learning capabilities are crucial for autonomous agents\ninteracting in the real world and processing continuous streams of information.\nHowever, lifelong learning remains a long-standing challenge for machine\nlearning and neural network models since the continual acquisition of\nincrementally available information from non-stationary data distributions\ngenerally leads to catastrophic forgetting or interference. This limitation\nrepresents a major drawback for state-of-the-art deep neural network models\nthat typically learn representations from stationary batches of training data,\nthus without accounting for situations in which information becomes\nincrementally available over time. In this review, we critically summarize the\nmain challenges linked to lifelong learning for artificial learning systems and\ncompare existing neural network approaches that alleviate, to different\nextents, catastrophic forgetting. We discuss well-established and emerging\nresearch motivated by lifelong learning factors in biological systems such as\nstructural plasticity, memory replay, curriculum and transfer learning,\nintrinsic motivation, and multisensory integration.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 13:53:35 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 06:59:28 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2019 18:40:25 GMT"}, {"version": "v4", "created": "Mon, 11 Feb 2019 01:28:39 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Parisi", "German I.", ""], ["Kemker", "Ronald", ""], ["Part", "Jose L.", ""], ["Kanan", "Christopher", ""], ["Wermter", "Stefan", ""]]}, {"id": "1802.07572", "submitter": "David  McAllester", "authors": "David McAllester", "title": "Information Theoretic Co-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an information theoretic co-training objective for\nunsupervised learning. We consider the problem of predicting the future. Rather\nthan predict future sensations (image pixels or sound waves) we predict\n\"hypotheses\" to be confirmed by future sensations. More formally, we assume a\npopulation distribution on pairs $(x,y)$ where we can think of $x$ as a past\nsensation and $y$ as a future sensation. We train both a predictor model\n$P_\\Phi(z|x)$ and a confirmation model $P_\\Psi(z|y)$ where we view $z$ as\nhypotheses (when predicted) or facts (when confirmed). For a population\ndistribution on pairs $(x,y)$ we focus on the problem of measuring the mutual\ninformation between $x$ and $y$. By the data processing inequality this mutual\ninformation is at least as large as the mutual information between $x$ and $z$\nunder the distribution on triples $(x,z,y)$ defined by the confirmation model\n$P_\\Psi(z|y)$. The information theoretic training objective for $P_\\Phi(z|x)$\nand $P_\\Psi(z|y)$ can be viewed as a form of co-training where we want the\nprediction from $x$ to match the confirmation from $y$.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 14:01:20 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 13:06:04 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["McAllester", "David", ""]]}, {"id": "1802.07581", "submitter": "Shengyu Zhu", "authors": "Shengyu Zhu, Biao Chen, Pengfei Yang, Zhitang Chen", "title": "Universal Hypothesis Testing with Kernels: Asymptotically Optimal Tests\n  for Goodness of Fit", "comments": "camera-ready version for AISTATS 2019 (with supplementary material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the asymptotic performance of nonparametric goodness of fit\ntesting. The exponential decay rate of the type-II error probability is used as\nthe asymptotic performance metric, and a test is optimal if it achieves the\nmaximum rate subject to a constant level constraint on the type-I error\nprobability. We show that two classes of Maximum Mean Discrepancy (MMD) based\ntests attain this optimality on $\\mathbb R^d$, while the quadratic-time Kernel\nStein Discrepancy (KSD) based tests achieve the maximum exponential decay rate\nunder a relaxed level constraint. Under the same performance metric, we proceed\nto show that the quadratic-time MMD based two-sample tests are also optimal for\ngeneral two-sample problems, provided that kernels are bounded continuous and\ncharacteristic. Key to our approach are Sanov's theorem from large deviation\ntheory and the weak metrizable properties of the MMD and KSD.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 14:24:30 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 12:04:39 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2019 03:38:17 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Zhu", "Shengyu", ""], ["Chen", "Biao", ""], ["Yang", "Pengfei", ""], ["Chen", "Zhitang", ""]]}, {"id": "1802.07595", "submitter": "Leonard Berrada", "authors": "Leonard Berrada, Andrew Zisserman, M. Pawan Kumar", "title": "Smooth Loss Functions for Deep Top-k Classification", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The top-k error is a common measure of performance in machine learning and\ncomputer vision. In practice, top-k classification is typically performed with\ndeep neural networks trained with the cross-entropy loss. Theoretical results\nindeed suggest that cross-entropy is an optimal learning objective for such a\ntask in the limit of infinite data. In the context of limited and noisy data\nhowever, the use of a loss function that is specifically designed for top-k\nclassification can bring significant improvements. Our empirical evidence\nsuggests that the loss function must be smooth and have non-sparse gradients in\norder to work well with deep neural networks. Consequently, we introduce a\nfamily of smoothed loss functions that are suited to top-k optimization via\ndeep learning. The widely used cross-entropy is a special case of our family.\nEvaluating our smooth loss functions is computationally challenging: a na\\\"ive\nalgorithm would require $\\mathcal{O}(\\binom{n}{k})$ operations, where n is the\nnumber of classes. Thanks to a connection to polynomial algebra and a\ndivide-and-conquer approach, we provide an algorithm with a time complexity of\n$\\mathcal{O}(k n)$. Furthermore, we present a novel approximation to obtain\nfast and stable algorithms on GPUs with single floating point precision. We\ncompare the performance of the cross-entropy loss and our margin-based losses\nin various regimes of noise and data size, for the predominant use case of k=5.\nOur investigation reveals that our loss is more robust to noise and overfitting\nthan cross-entropy.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 14:54:43 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Berrada", "Leonard", ""], ["Zisserman", "Andrew", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1802.07606", "submitter": "Luisa Zintgraf", "authors": "Luisa M Zintgraf, Diederik M Roijers, Sjoerd Linders, Catholijn M\n  Jonker, Ann Now\\'e", "title": "Ordered Preference Elicitation Strategies for Supporting Multi-Objective\n  Decision Making", "comments": "AAMAS 2018, Source code at\n  https://github.com/lmzintgraf/gp_pref_elicit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-objective decision planning and learning, much attention is paid to\nproducing optimal solution sets that contain an optimal policy for every\npossible user preference profile. We argue that the step that follows, i.e,\ndetermining which policy to execute by maximising the user's intrinsic utility\nfunction over this (possibly infinite) set, is under-studied. This paper aims\nto fill this gap. We build on previous work on Gaussian processes and pairwise\ncomparisons for preference modelling, extend it to the multi-objective decision\nsupport scenario, and propose new ordered preference elicitation strategies\nbased on ranking and clustering. Our main contribution is an in-depth\nevaluation of these strategies using computer and human-based experiments. We\nshow that our proposed elicitation strategies outperform the currently used\npairwise methods, and found that users prefer ranking most. Our experiments\nfurther show that utilising monotonicity information in GPs by using a linear\nprior mean at the start and virtual comparisons to the nadir and ideal points,\nincreases performance. We demonstrate our decision support framework in a\nreal-world study on traffic regulation, conducted with the city of Amsterdam.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 15:05:15 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Zintgraf", "Luisa M", ""], ["Roijers", "Diederik M", ""], ["Linders", "Sjoerd", ""], ["Jonker", "Catholijn M", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1802.07623", "submitter": "Amit Dhurandhar", "authors": "Amit Dhurandhar, Pin-Yu Chen, Ronny Luss, Chun-Chen Tu, Paishun Ting,\n  Karthikeyan Shanmugam and Payel Das", "title": "Explanations based on the Missing: Towards Contrastive Explanations with\n  Pertinent Negatives", "comments": null, "journal-ref": null, "doi": null, "report-no": "accepted to NIPS 2018", "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel method that provides contrastive\nexplanations justifying the classification of an input by a black box\nclassifier such as a deep neural network. Given an input we find what should be\n%necessarily and minimally and sufficiently present (viz. important object\npixels in an image) to justify its classification and analogously what should\nbe minimally and necessarily \\emph{absent} (viz. certain background pixels). We\nargue that such explanations are natural for humans and are used commonly in\ndomains such as health care and criminology. What is minimally but critically\n\\emph{absent} is an important part of an explanation, which to the best of our\nknowledge, has not been explicitly identified by current explanation methods\nthat explain predictions of neural networks. We validate our approach on three\nreal datasets obtained from diverse domains; namely, a handwritten digits\ndataset MNIST, a large procurement fraud dataset and a brain activity strength\ndataset. In all three cases, we witness the power of our approach in generating\nprecise explanations that are also easy for human experts to understand and\nevaluate.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 15:51:38 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 16:08:36 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Dhurandhar", "Amit", ""], ["Chen", "Pin-Yu", ""], ["Luss", "Ronny", ""], ["Tu", "Chun-Chen", ""], ["Ting", "Paishun", ""], ["Shanmugam", "Karthikeyan", ""], ["Das", "Payel", ""]]}, {"id": "1802.07687", "submitter": "Emily Denton", "authors": "Emily Denton and Rob Fergus", "title": "Stochastic Video Generation with a Learned Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating video frames that accurately predict future world states is\nchallenging. Existing approaches either fail to capture the full distribution\nof outcomes, or yield blurry generations, or both. In this paper we introduce\nan unsupervised video generation model that learns a prior model of uncertainty\nin a given environment. Video frames are generated by drawing samples from this\nprior and combining them with a deterministic estimate of the future frame. The\napproach is simple and easily trained end-to-end on a variety of datasets.\nSample generations are both varied and sharp, even many frames into the future,\nand compare favorably to those from existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 17:36:27 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 17:39:23 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Denton", "Emily", ""], ["Fergus", "Rob", ""]]}, {"id": "1802.07697", "submitter": "Matthew Streeter", "authors": "Matthew Streeter", "title": "Approximation Algorithms for Cascading Prediction Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approximation algorithm that takes a pool of pre-trained models\nas input and produces from it a cascaded model with similar accuracy but lower\naverage-case cost. Applied to state-of-the-art ImageNet classification models,\nthis yields up to a 2x reduction in floating point multiplications, and up to a\n6x reduction in average-case memory I/O. The auto-generated cascades exhibit\nintuitive properties, such as using lower-resolution input for easier images\nand requiring higher prediction confidence when using a computationally cheaper\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 17:56:05 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Streeter", "Matthew", ""]]}, {"id": "1802.07714", "submitter": "Elias Chaibub Neto", "authors": "Elias Chaibub Neto", "title": "Detecting Learning vs Memorization in Deep Neural Networks using Shared\n  Structure Validation Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The roles played by learning and memorization represent an important topic in\ndeep learning research. Recent work on this subject has shown that the\noptimization behavior of DNNs trained on shuffled labels is qualitatively\ndifferent from DNNs trained with real labels. Here, we propose a novel\npermutation approach that can differentiate memorization from learning in deep\nneural networks (DNNs) trained as usual (i.e., using the real labels to guide\nthe learning, rather than shuffled labels). The evaluation of weather the DNN\nhas learned and/or memorized, happens in a separate step where we compare the\npredictive performance of a shallow classifier trained with the features\nlearned by the DNN, against multiple instances of the same classifier, trained\non the same input, but using shuffled labels as outputs. By evaluating these\nshallow classifiers in validation sets that share structure with the training\nset, we are able to tell apart learning from memorization. Application of our\npermutation approach to multi-layer perceptrons and convolutional neural\nnetworks trained on image data corroborated many findings from other groups.\nMost importantly, our illustrations also uncovered interesting dynamic patterns\nabout how DNNs memorize over increasing numbers of training epochs, and support\nthe surprising result that DNNs are still able to learn, rather than only\nmemorize, when trained with pure Gaussian noise as input.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 18:45:23 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Neto", "Elias Chaibub", ""]]}, {"id": "1802.07756", "submitter": "Ritabrata Maiti", "authors": "Ritabrata Maiti", "title": "Determining the best classifier for predicting the value of a boolean\n  field on a blood donor database using genetic algorithms", "comments": "GitHub Repository here:\n  https://github.com/ritabratamaiti/Blooddonorprediction", "journal-ref": null, "doi": "10.5281/zenodo.1336304", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Motivation: Thanks to digitization, we often have access to large databases,\nconsisting of various fields of information, ranging from numbers to texts and\neven boolean values. Such databases lend themselves especially well to machine\nlearning, classification and big data analysis tasks. We are able to train\nclassifiers, using already existing data and use them for predicting the values\nof a certain field, given that we have information regarding the other fields.\nMost specifically, in this study, we look at the Electronic Health Records\n(EHRs) that are compiled by hospitals. These EHRs are convenient means of\naccessing data of individual patients, but there processing as a whole still\nremains a task. However, EHRs that are composed of coherent, well-tabulated\nstructures lend themselves quite well to the application to machine language,\nvia the usage of classifiers. In this study, we look at a Blood Transfusion\nService Center Data Set (Data taken from the Blood Transfusion Service Center\nin Hsin-Chu City in Taiwan). We used scikit-learn machine learning in python.\nFrom Support Vector Machines(SVM), we use Support Vector Classification(SVC),\nfrom the linear model we import Perceptron. We also used the\nK.neighborsclassifier and the decision tree classifiers. Furthermore, we use\nthe TPOT library to find an optimized pipeline using genetic algorithms. Using\nthe above classifiers, we score each one of them using k fold cross-validation.\n  Contact: ritabratamaiti@hiretrex.com GitHub Repository:\nhttps://github.com/ritabratamaiti/Blooddonorprediction\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 19:09:17 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 13:11:03 GMT"}, {"version": "v3", "created": "Sat, 21 Apr 2018 20:17:24 GMT"}, {"version": "v4", "created": "Sat, 4 Aug 2018 20:38:14 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Maiti", "Ritabrata", ""]]}, {"id": "1802.07796", "submitter": "D. Khu\\^e L\\^e-Huu", "authors": "D. Khu\\^e L\\^e-Huu and Nikos Paragios", "title": "Continuous Relaxation of MAP Inference: A Nonconvex Perspective", "comments": "Accepted for publication at the 2018 IEEE Conference on Computer\n  Vision and Pattern Recognition (CVPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a nonconvex continuous relaxation of MAP inference in\ndiscrete Markov random fields (MRFs). We show that for arbitrary MRFs, this\nrelaxation is tight, and a discrete stationary point of it can be easily\nreached by a simple block coordinate descent algorithm. In addition, we study\nthe resolution of this relaxation using popular gradient methods, and further\npropose a more effective solution using a multilinear decomposition framework\nbased on the alternating direction method of multipliers (ADMM). Experiments on\nmany real-world problems demonstrate that the proposed ADMM significantly\noutperforms other nonconvex relaxation based methods, and compares favorably\nwith state of the art MRF optimization algorithms in different settings.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 20:42:58 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 22:12:55 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["L\u00ea-Huu", "D. Khu\u00ea", ""], ["Paragios", "Nikos", ""]]}, {"id": "1802.07802", "submitter": "Mohammad Malekzadeh", "authors": "Mohammad Malekzadeh, Richard G. Clegg, Andrea Cavallaro and Hamed\n  Haddadi", "title": "Protecting Sensory Data against Sensitive Inferences", "comments": "6 pages", "journal-ref": null, "doi": "10.1145/3195258.3195260", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing concern about how personal data are used when users grant\napplications direct access to the sensors of their mobile devices. In fact,\nhigh resolution temporal data generated by motion sensors reflect directly the\nactivities of a user and indirectly physical and demographic attributes. In\nthis paper, we propose a feature learning architecture for mobile devices that\nprovides flexible and negotiable privacy-preserving sensor data transmission by\nappropriately transforming raw sensor data. The objective is to move from the\ncurrent binary setting of granting or not permission to an application, toward\na model that allows users to grant each application permission over a limited\nrange of inferences according to the provided services. The internal structure\nof each component of the proposed architecture can be flexibly changed and the\ntrade-off between privacy and utility can be negotiated between the constraints\nof the user and the underlying application. We validated the proposed\narchitecture in an activity recognition application using two real-world\ndatasets, with the objective of recognizing an activity without disclosing\ngender as an example of private information. Results show that the proposed\nframework maintains the usefulness of the transformed data for activity\nrecognition, with an average loss of only around three percentage points, while\nreducing the possibility of gender classification to around 50\\%, the target\nrandom guess, from more than 90\\% when using raw sensor data. We also present\nand distribute MotionSense, a new dataset for activity and attribute\nrecognition collected from motion sensors.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 20:57:08 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 23:56:39 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 10:22:49 GMT"}, {"version": "v4", "created": "Wed, 20 Jun 2018 12:40:12 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Malekzadeh", "Mohammad", ""], ["Clegg", "Richard G.", ""], ["Cavallaro", "Andrea", ""], ["Haddadi", "Hamed", ""]]}, {"id": "1802.07814", "submitter": "Jianbo Chen", "authors": "Jianbo Chen, Le Song, Martin J. Wainwright, Michael I. Jordan", "title": "Learning to Explain: An Information-Theoretic Perspective on Model\n  Interpretation", "comments": "Accepted to ICML 2018 as a long oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce instancewise feature selection as a methodology for model\ninterpretation. Our method is based on learning a function to extract a subset\nof features that are most informative for each given example. This feature\nselector is trained to maximize the mutual information between selected\nfeatures and the response variable, where the conditional distribution of the\nresponse variable given the input is the model to be explained. We develop an\nefficient variational approximation to the mutual information, and show the\neffectiveness of our method on a variety of synthetic and real data sets using\nboth quantitative metrics and human evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 21:16:21 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 03:38:00 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Chen", "Jianbo", ""], ["Song", "Le", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1802.07833", "submitter": "Tianbing Xu", "authors": "Tianbing Xu", "title": "Variational Inference for Policy Gradient", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the seminal work on Stein Variational Inference and Stein\nVariational Policy Gradient, we derived a method to generate samples from the\nposterior variational parameter distribution by \\textit{explicitly} minimizing\nthe KL divergence to match the target distribution in an amortize fashion.\nConsequently, we applied this varational inference technique into vanilla\npolicy gradient, TRPO and PPO with Bayesian Neural Network parameterizations\nfor reinforcement learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 22:18:20 GMT"}, {"version": "v2", "created": "Sun, 25 Mar 2018 23:57:28 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Xu", "Tianbing", ""]]}, {"id": "1802.07834", "submitter": "El Mahdi El Mhamdi", "authors": "El Mahdi El Mhamdi, Rachid Guerraoui, Alexandre Maurer, Vladislav\n  Tempez", "title": "Learning to Gather without Communication", "comments": "Preliminary version, presented at the 5th Biological Distributed\n  Algorithms Workshop. Washington D.C, July 28th, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.DC cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard belief on emerging collective behavior is that it emerges from\nsimple individual rules. Most of the mathematical research on such collective\nbehavior starts from imperative individual rules, like always go to the center.\nBut how could an (optimal) individual rule emerge during a short period within\nthe group lifetime, especially if communication is not available. We argue that\nsuch rules can actually emerge in a group in a short span of time via\ncollective (multi-agent) reinforcement learning, i.e learning via rewards and\npunishments. We consider the gathering problem: several agents (social animals,\nswarming robots...) must gather around a same position, which is not determined\nin advance. They must do so without communication on their planned decision,\njust by looking at the position of other agents. We present the first\nexperimental evidence that a gathering behavior can be learned without\ncommunication in a partially observable environment. The learned behavior has\nthe same properties as a self-stabilizing distributed algorithm, as processes\ncan gather from any initial state (and thus tolerate any transient failure).\nBesides, we show that it is possible to tolerate the brutal loss of up to 90\\%\nof agents without significant impact on the behavior.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 22:26:21 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Maurer", "Alexandre", ""], ["Tempez", "Vladislav", ""]]}, {"id": "1802.07876", "submitter": "Fei Chen", "authors": "Fei Chen, Mi Luo, Zhenhua Dong, Zhenguo Li, Xiuqiang He", "title": "Federated Meta-Learning with Fast Convergence and Efficient\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical and systematic challenges in collaboratively training machine\nlearning models across distributed networks of mobile devices have been the\nbottlenecks in the real-world application of federated learning. In this work,\nwe show that meta-learning is a natural choice to handle these issues, and\npropose a federated meta-learning framework FedMeta, where a parameterized\nalgorithm (or meta-learner) is shared, instead of a global model in previous\napproaches. We conduct an extensive empirical evaluation on LEAF datasets and a\nreal-world production dataset, and demonstrate that FedMeta achieves a\nreduction in required communication cost by 2.82-4.33 times with faster\nconvergence, and an increase in accuracy by 3.23%-14.84% as compared to\nFederated Averaging (FedAvg) which is a leading optimization algorithm in\nfederated learning. Moreover, FedMeta preserves user privacy since only the\nparameterized algorithm is transmitted between mobile devices and central\nservers, and no raw data is collected onto the servers.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 02:35:32 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 06:39:54 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Chen", "Fei", ""], ["Luo", "Mi", ""], ["Dong", "Zhenhua", ""], ["Li", "Zhenguo", ""], ["He", "Xiuqiang", ""]]}, {"id": "1802.07877", "submitter": "Maryam Sabzevari", "authors": "Maryam Sabzevari, Gonzalo Mart\\'inez-Mu\\~noz, Alberto Su\\'arez", "title": "Pooling homogeneous ensembles to build heterogeneous ones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ensemble methods, the outputs of a collection of diverse classifiers are\ncombined in the expectation that the global prediction be more accurate than\nthe individual ones. Heterogeneous ensembles consist of predictors of different\ntypes, which are likely to have different biases. If these biases are\ncomplementary, the combination of their decisions is beneficial. In this work,\na family of heterogeneous ensembles is built by pooling classifiers from M\nhomogeneous ensembles of different types of size T. Depending on the fraction\nof base classifiers of each type, a particular heterogeneous combination in\nthis family is represented by a point in a regular simplex in M dimensions. The\nM vertices of this simplex represent the different homogeneous ensembles. A\ndisplacement away from one of these vertices effects a smooth transformation of\nthe corresponding homogeneous ensemble into a heterogeneous one. The optimal\ncomposition of such heterogeneous ensemble can be determined using\ncross-validation or, if bootstrap samples are used to build the individual\nclassifiers, out-of-bag data. An empirical analysis of such combinations of\nbootstraped ensembles composed of neural networks, SVMs, and random trees (i.e.\nfrom a standard random forest) illustrates the gains that can be achieved by\nthis heterogeneous ensemble creation method.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 13:17:42 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 21:15:33 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Sabzevari", "Maryam", ""], ["Mart\u00ednez-Mu\u00f1oz", "Gonzalo", ""], ["Su\u00e1rez", "Alberto", ""]]}, {"id": "1802.07881", "submitter": "Changjian Shui", "authors": "Changjian Shui, Azadeh Sadat Mozafari, Jonathan Marek, Ihsen Hedhli,\n  Christian Gagn\\'e", "title": "Diversity regularization in deep ensembles", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Calibrating the confidence of supervised learning models is important for a\nvariety of contexts where the certainty over predictions should be reliable.\nHowever, it has been reported that deep neural network models are often too\npoorly calibrated for achieving complex tasks requiring reliable uncertainty\nestimates in their prediction. In this work, we are proposing a strategy for\ntraining deep ensembles with a diversity function regularization, which\nimproves the calibration property while maintaining a similar prediction\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 13:24:09 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Shui", "Changjian", ""], ["Mozafari", "Azadeh Sadat", ""], ["Marek", "Jonathan", ""], ["Hedhli", "Ihsen", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "1802.07887", "submitter": "Si Si", "authors": "Si Si and Sanjiv Kumar and Yang Li", "title": "Nonlinear Online Learning with Adaptive Nystr\\\"{o}m Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of nonlinear feature maps via kernel approximation has led to success in\nmany online learning tasks. As a popular kernel approximation method,\nNystr\\\"{o}m approximation, has been well investigated, and various landmark\npoints selection methods have been proposed to improve the approximation\nquality. However, these improved Nystr\\\"{o}m methods cannot be directly applied\nto the online learning setting as they need to access the entire dataset to\nlearn the landmark points, while we need to update model on-the-fly in the\nonline setting. To address this challenge, we propose Adaptive Nystr\\\"{o}m\napproximation for solving nonlinear online learning problems. The key idea is\nto adaptively modify the landmark points via online kmeans and adjust the model\naccordingly via solving least square problem followed by a gradient descent\nstep. We show that the resulting algorithm outperforms state-of-the-art online\nlearning methods under the same budget.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 04:38:38 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 18:21:54 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Si", "Si", ""], ["Kumar", "Sanjiv", ""], ["Li", "Yang", ""]]}, {"id": "1802.07889", "submitter": "Jiantao Jiao", "authors": "Yanjun Han and Jiantao Jiao and Chuan-Zheng Lee and Tsachy Weissman\n  and Yihong Wu and Tiancheng Yu", "title": "Entropy Rate Estimation for Markov Chains with Large State Space", "comments": "Published as a conference paper on NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the entropy based on data is one of the prototypical problems in\ndistribution property testing and estimation. For estimating the Shannon\nentropy of a distribution on $S$ elements with independent samples,\n[Paninski2004] showed that the sample complexity is sublinear in $S$, and\n[Valiant--Valiant2011] showed that consistent estimation of Shannon entropy is\npossible if and only if the sample size $n$ far exceeds $\\frac{S}{\\log S}$. In\nthis paper we consider the problem of estimating the entropy rate of a\nstationary reversible Markov chain with $S$ states from a sample path of $n$\nobservations. We show that:\n  (1) As long as the Markov chain mixes not too slowly, i.e., the relaxation\ntime is at most $O(\\frac{S}{\\ln^3 S})$, consistent estimation is achievable\nwhen $n \\gg \\frac{S^2}{\\log S}$.\n  (2) As long as the Markov chain has some slight dependency, i.e., the\nrelaxation time is at least $1+\\Omega(\\frac{\\ln^2 S}{\\sqrt{S}})$, consistent\nestimation is impossible when $n \\lesssim \\frac{S^2}{\\log S}$.\n  Under both assumptions, the optimal estimation accuracy is shown to be\n$\\Theta(\\frac{S^2}{n \\log S})$. In comparison, the empirical entropy rate\nrequires at least $\\Omega(S^2)$ samples to be consistent, even when the Markov\nchain is memoryless. In addition to synthetic experiments, we also apply the\nestimators that achieve the optimal sample complexity to estimate the entropy\nrate of the English language in the Penn Treebank and the Google One Billion\nWords corpora, which provides a natural benchmark for language modeling and\nrelates it directly to the widely used perplexity measure.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 03:10:17 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 04:51:30 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2018 06:45:27 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Han", "Yanjun", ""], ["Jiao", "Jiantao", ""], ["Lee", "Chuan-Zheng", ""], ["Weissman", "Tsachy", ""], ["Wu", "Yihong", ""], ["Yu", "Tiancheng", ""]]}, {"id": "1802.07895", "submitter": "Yingyu Liang", "authors": "Yuanzhi Li and Yingyu Liang", "title": "Learning Mixtures of Linear Regressions with Nearly Optimal Complexity", "comments": "Fix some typesetting issue in v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixtures of Linear Regressions (MLR) is an important mixture model with many\napplications. In this model, each observation is generated from one of the\nseveral unknown linear regression components, where the identity of the\ngenerated component is also unknown. Previous works either assume strong\nassumptions on the data distribution or have high complexity. This paper\nproposes a fixed parameter tractable algorithm for the problem under general\nconditions, which achieves global convergence and the sample complexity scales\nnearly linearly in the dimension. In particular, different from previous works\nthat require the data to be from the standard Gaussian, the algorithm allows\nthe data from Gaussians with different covariances. When the conditional number\nof the covariances and the number of components are fixed, the algorithm has\nnearly optimal sample complexity $N = \\tilde{O}(d)$ as well as nearly optimal\ncomputational complexity $\\tilde{O}(Nd)$, where $d$ is the dimension of the\ndata space. To the best of our knowledge, this approach provides the first such\nrecovery guarantee for this general setting.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 03:47:07 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 20:59:41 GMT"}, {"version": "v3", "created": "Sat, 28 Mar 2020 16:09:24 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Li", "Yuanzhi", ""], ["Liang", "Yingyu", ""]]}, {"id": "1802.07896", "submitter": "Haifeng Qian", "authors": "Haifeng Qian, Mark N. Wegman", "title": "L2-Nonexpansive Neural Networks", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR), 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a class of well-conditioned neural networks in which a\nunit amount of change in the inputs causes at most a unit amount of change in\nthe outputs or any of the internal layers. We develop the known methodology of\ncontrolling Lipschitz constants to realize its full potential in maximizing\nrobustness, with a new regularization scheme for linear layers, new ways to\nadapt nonlinearities and a new loss function. With MNIST and CIFAR-10\nclassifiers, we demonstrate a number of advantages. Without needing any\nadversarial training, the proposed classifiers exceed the state of the art in\nrobustness against white-box L2-bounded adversarial attacks. They generalize\nbetter than ordinary networks from noisy data with partially random labels.\nTheir outputs are quantitatively meaningful and indicate levels of confidence\nand generalization, among other desirable properties.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 04:01:18 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 18:34:46 GMT"}, {"version": "v3", "created": "Tue, 3 Jul 2018 03:24:08 GMT"}, {"version": "v4", "created": "Wed, 6 Feb 2019 07:12:07 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Qian", "Haifeng", ""], ["Wegman", "Mark N.", ""]]}, {"id": "1802.07917", "submitter": "Cong Shen", "authors": "Zhiyang Wang, Ruida Zhou, Cong Shen", "title": "Regional Multi-Armed Bandits", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the classic multi-armed bandit problem where the\nexpected reward of each arm is a function of an unknown parameter. The arms are\ndivided into different groups, each of which has a common parameter. Therefore,\nwhen the player selects an arm at each time slot, information of other arms in\nthe same group is also revealed. This regional bandit model naturally bridges\nthe non-informative bandit setting where the player can only learn the chosen\narm, and the global bandit model where sampling one arms reveals information of\nall arms. We propose an efficient algorithm, UCB-g, that solves the regional\nbandit problem by combining the Upper Confidence Bound (UCB) and greedy\nprinciples. Both parameter-dependent and parameter-free regret upper bounds are\nderived. We also establish a matching lower bound, which proves the\norder-optimality of UCB-g. Moreover, we propose SW-UCB-g, which is an extension\nof UCB-g for a non-stationary environment where the parameters slowly vary over\ntime.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 07:03:23 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Wang", "Zhiyang", ""], ["Zhou", "Ruida", ""], ["Shen", "Cong", ""]]}, {"id": "1802.07927", "submitter": "El Mahdi El Mhamdi", "authors": "El Mahdi El Mhamdi, Rachid Guerraoui, S\\'ebastien Rouault", "title": "The Hidden Vulnerability of Distributed Learning in Byzantium", "comments": "Accepted to ICML 2018 as a long talk", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While machine learning is going through an era of celebrated success,\nconcerns have been raised about the vulnerability of its backbone: stochastic\ngradient descent (SGD). Recent approaches have been proposed to ensure the\nrobustness of distributed SGD against adversarial (Byzantine) workers sending\npoisoned gradients during the training phase. Some of these approaches have\nbeen proven Byzantine-resilient: they ensure the convergence of SGD despite the\npresence of a minority of adversarial workers.\n  We show in this paper that convergence is not enough. In high dimension $d\n\\gg 1$, an adver\\-sary can build on the loss function's non-convexity to make\nSGD converge to ineffective models. More precisely, we bring to light that\nexisting Byzantine-resilient schemes leave a margin of poisoning of\n$\\Omega\\left(f(d)\\right)$, where $f(d)$ increases at least like $\\sqrt{d~}$.\nBased on this leeway, we build a simple attack, and experimentally show its\nstrong to utmost effectivity on CIFAR-10 and MNIST.\n  We introduce Bulyan, and prove it significantly reduces the attackers leeway\nto a narrow $O( \\frac{1}{\\sqrt{d~}})$ bound. We empirically show that Bulyan\ndoes not suffer the fragility of existing aggregation rules and, at a\nreasonable cost in terms of required batch size, achieves convergence as if\nonly non-Byzantine gradients had been used to update the model.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 07:42:00 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 18:10:23 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Rouault", "S\u00e9bastien", ""]]}, {"id": "1802.07928", "submitter": "El Mahdi El Mhamdi", "authors": "Georgios Damaskinos, El Mahdi El Mhamdi, Rachid Guerraoui, Rhicheek\n  Patra, Mahsa Taziki", "title": "Asynchronous Byzantine Machine Learning (the case of SGD)", "comments": "accepted to ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Asynchronous distributed machine learning solutions have proven very\neffective so far, but always assuming perfectly functioning workers. In\npractice, some of the workers can however exhibit Byzantine behavior, caused by\nhardware failures, software bugs, corrupt data, or even malicious attacks. We\nintroduce \\emph{Kardam}, the first distributed asynchronous stochastic gradient\ndescent (SGD) algorithm that copes with Byzantine workers. Kardam consists of\ntwo complementary components: a filtering and a dampening component. The first\nis scalar-based and ensures resilience against $\\frac{1}{3}$ Byzantine workers.\nEssentially, this filter leverages the Lipschitzness of cost functions and acts\nas a self-stabilizer against Byzantine workers that would attempt to corrupt\nthe progress of SGD. The dampening component bounds the convergence rate by\nadjusting to stale information through a generic gradient weighting scheme. We\nprove that Kardam guarantees almost sure convergence in the presence of\nasynchrony and Byzantine behavior, and we derive its convergence rate. We\nevaluate Kardam on the CIFAR-100 and EMNIST datasets and measure its overhead\nwith respect to non Byzantine-resilient solutions. We empirically show that\nKardam does not introduce additional noise to the learning procedure but does\ninduce a slowdown (the cost of Byzantine resilience) that we both theoretically\nand empirically show to be less than $f/n$, where $f$ is the number of\nByzantine failures tolerated and $n$ the total number of workers.\nInterestingly, we also empirically observe that the dampening component is\ninteresting in its own right for it enables to build an SGD algorithm that\noutperforms alternative staleness-aware asynchronous competitors in\nenvironments with honest workers.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 07:47:35 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 17:48:06 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Damaskinos", "Georgios", ""], ["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Patra", "Rhicheek", ""], ["Taziki", "Mahsa", ""]]}, {"id": "1802.07945", "submitter": "Gabi Shalev", "authors": "Lena Granovsky, Gabi Shalev, Nancy Yacovzada, Yotam Frank, Shai Fine", "title": "Actigraphy-based Sleep/Wake Pattern Detection using Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common medical conditions are often associated with sleep abnormalities.\nPatients with medical disorders often suffer from poor sleep quality compared\nto healthy individuals, which in turn may worsen the symptoms of the disorder.\nAccurate detection of sleep/wake patterns is important in developing\npersonalized digital markers, which can be used for objective measurements and\nefficient disease management. Big Data technologies and advanced analytics\nmethods hold the promise to revolutionize clinical research processes, enabling\nthe effective blending of digital data into clinical trials. Actigraphy, a\nnon-invasive activity monitoring method is heavily used to detect and evaluate\nactivities and movement disorders, and assess sleep/wake behavior. In order to\nstudy the connection between sleep/wake patterns and a cluster headache\ndisorder, activity data was collected using a wearable device in the course of\na clinical trial. This study presents two novel modeling schemes that utilize\nDeep Convolutional Neural Networks (CNN) to identify sleep/wake states. The\nproposed methods are a sequential CNN, reminiscent of the bi-directional CNN\nfor slot filling, and a Multi-Task Learning (MTL) based model. Furthermore, we\nexpand standard \"Sleep\" and \"Wake\" activity states space by adding the \"Falling\nasleep\" and \"Siesta\" states. We show that the proposed methods provide\npromising results in accurate detection of the expanded sleep/wake states.\nFinally, we explore the relations between the detected sleep/wake patterns and\nonset of cluster headache attacks, and present preliminary observations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 09:01:24 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Granovsky", "Lena", ""], ["Shalev", "Gabi", ""], ["Yacovzada", "Nancy", ""], ["Frank", "Yotam", ""], ["Fine", "Shai", ""]]}, {"id": "1802.07954", "submitter": "Fabrice Rossi", "authors": "A. Endert, W. Ribarsky, C. Turkay, W Wong, I. Nabney, I D\\'iaz Blanco,\n  Fabrice Rossi (SAMM)", "title": "The State of the Art in Integrating Machine Learning into Visual\n  Analytics", "comments": null, "journal-ref": "Computer Graphics Forum, Wiley, 2017, 36 (8), pp.458 - 486", "doi": "10.1111/cgf.13092", "report-no": null, "categories": "stat.ML cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual analytics systems combine machine learning or other analytic\ntechniques with interactive data visualization to promote sensemaking and\nanalytical reasoning. It is through such techniques that people can make sense\nof large, complex data. While progress has been made, the tactful combination\nof machine learning and data visualization is still under-explored. This\nstate-of-the-art report presents a summary of the progress that has been made\nby highlighting and synthesizing select research advances. Further, it presents\nopportunities and challenges to enhance the synergy between machine learning\nand visual analytics for impactful future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 09:48:56 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Endert", "A.", "", "SAMM"], ["Ribarsky", "W.", "", "SAMM"], ["Turkay", "C.", "", "SAMM"], ["Wong", "W", "", "SAMM"], ["Nabney", "I.", "", "SAMM"], ["Blanco", "I D\u00edaz", "", "SAMM"], ["Rossi", "Fabrice", "", "SAMM"]]}, {"id": "1802.07966", "submitter": "Arindam Mitra", "authors": "Arindam Mitra and Chitta Baral", "title": "Incremental and Iterative Learning of Answer Set Programs from Mutually\n  Distinct Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years the Artificial Intelligence (AI) community has produced\nseveral datasets which have given the machine learning algorithms the\nopportunity to learn various skills across various domains. However, a subclass\nof these machine learning algorithms that aimed at learning logic programs,\nnamely the Inductive Logic Programming algorithms, have often failed at the\ntask due to the vastness of these datasets. This has impacted the usability of\nknowledge representation and reasoning techniques in the development of AI\nsystems. In this research, we try to address this scalability issue for the\nalgorithms that learn answer set programs. We present a sound and complete\nalgorithm which takes the input in a slightly different manner and performs an\nefficient and more user controlled search for a solution. We show via\nexperiments that our algorithm can learn from two popular datasets from machine\nlearning community, namely bAbl (a question answering dataset) and MNIST (a\ndataset for handwritten digit recognition), which to the best of our knowledge\nwas not previously possible. The system is publicly available at\nhttps://goo.gl/KdWAcV. This paper is under consideration for acceptance in\nTPLP.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 10:22:58 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 14:42:15 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Mitra", "Arindam", ""], ["Baral", "Chitta", ""]]}, {"id": "1802.07971", "submitter": "Jean-Yves Franceschi", "authors": "Jean-Yves Franceschi (LIP), Alhussein Fawzi, Omar Fawzi (LIP)", "title": "Robustness of classifiers to uniform $\\ell\\_p$ and Gaussian noise", "comments": null, "journal-ref": "21st International Conference on Artificial Intelligence and\n  Statistics (AISTATS) 2018, Apr 2018, Playa Blanca, Spain. 2018,\n  http://www.aistats.org/", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the robustness of classifiers to various kinds of random noise\nmodels. In particular, we consider noise drawn uniformly from the $\\ell\\_p$\nball for $p \\in [1, \\infty]$ and Gaussian noise with an arbitrary covariance\nmatrix. We characterize this robustness to random noise in terms of the\ndistance to the decision boundary of the classifier. This analysis applies to\nlinear classifiers as well as classifiers with locally approximately flat\ndecision boundaries, a condition which is satisfied by state-of-the-art deep\nneural networks. The predicted robustness is verified experimentally.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 10:31:21 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Franceschi", "Jean-Yves", "", "LIP"], ["Fawzi", "Alhussein", "", "LIP"], ["Fawzi", "Omar", "", "LIP"]]}, {"id": "1802.07980", "submitter": "Bin Yang", "authors": "Chenjuan Guo, Bin Yang, Jilin Hu, Christian S. Jensen", "title": "Learning to Route with Sparse Trajectory Sets---Extended Version", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the increasing availability of vehicle trajectory data, we\npropose learn-to-route, a comprehensive trajectory-based routing solution.\nSpecifically, we first construct a graph-like structure from trajectories as\nthe routing infrastructure. Second, we enable trajectory-based routing given an\narbitrary (source, destination) pair.\n  In the first step, given a road network and a collection of trajectories, we\npropose a trajectory-based clustering method that identifies regions in a road\nnetwork. If a pair of regions are connected by trajectories, we maintain the\npaths used by these trajectories and learn a routing preference for travel\nbetween the regions. As trajectories are skewed and sparse, many region pairs\nare not connected by trajectories. We thus transfer routing preferences from\nregion pairs with sufficient trajectories to such region pairs and then use the\ntransferred preferences to identify paths between the regions. In the second\nstep, we exploit the above graph-like structure to achieve a comprehensive\ntrajectory-based routing solution. Empirical studies with two substantial\ntrajectory data sets offer insight into the proposed solution, indicating that\nit is practical. A comparison with a leading routing service offers evidence\nthat the paper's proposal is able to enhance routing quality.\n  This is an extended version of \"Learning to Route with Sparse Trajectory\nSets\" [1], to appear in IEEE ICDE 2018.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 11:11:07 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Guo", "Chenjuan", ""], ["Yang", "Bin", ""], ["Hu", "Jilin", ""], ["Jensen", "Christian S.", ""]]}, {"id": "1802.08008", "submitter": "Stephen Sinclair", "authors": "Stephen Sinclair", "title": "Sounderfeit: Cloning a Physical Model with Conditional Adversarial\n  Autoencoders", "comments": "Published in the Brazilian Symposium on Computer Music (SBCM 2017)", "journal-ref": "Proc. Brazilian Symp. on Comp. Music., 2017. p. 67--74", "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial autoencoder conditioned on known parameters of a physical\nmodeling bowed string synthesizer is evaluated for use in parameter estimation\nand resynthesis tasks. Latent dimensions are provided to capture variance not\nexplained by the conditional parameters. Results are compared with and without\nthe adversarial training, and a system capable of \"copying\" a given\nparameter-signal bidirectional relationship is examined. A real-time synthesis\nsystem built on a generative, conditioned and regularized neural network is\npresented, allowing to construct engaging sound synthesizers based purely on\nrecorded data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 12:24:24 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Sinclair", "Stephen", ""]]}, {"id": "1802.08009", "submitter": "Gergely Neu", "authors": "Gergely Neu and Lorenzo Rosasco", "title": "Iterate averaging as regularization for stochastic gradient descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a variant of the classic Polyak-Ruppert averaging\nscheme, broadly used in stochastic gradient methods. Rather than a uniform\naverage of the iterates, we consider a weighted average, with weights decaying\nin a geometric fashion. In the context of linear least squares regression, we\nshow that this averaging scheme has a the same regularizing effect, and indeed\nis asymptotically equivalent, to ridge regression. In particular, we derive\nfinite-sample bounds for the proposed approach that match the best known\nresults for regularized stochastic gradient methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 12:27:40 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Neu", "Gergely", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1802.08012", "submitter": "Ryohei Hisano", "authors": "Ryohei Hisano", "title": "Learning Topic Models by Neighborhood Aggregation", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are frequently used in machine learning owing to their high\ninterpretability and modular structure. However, extending a topic model to\ninclude a supervisory signal, to incorporate pre-trained word embedding vectors\nand to include a nonlinear output function is not an easy task because one has\nto resort to a highly intricate approximate inference procedure. The present\npaper shows that topic modeling with pre-trained word embedding vectors can be\nviewed as implementing a neighborhood aggregation algorithm where messages are\npassed through a network defined over words. From the network view of topic\nmodels, nodes correspond to words in a document and edges correspond to either\na relationship describing co-occurring words in a document or a relationship\ndescribing the same word in the corpus. The network view allows us to extend\nthe model to include supervisory signals, incorporate pre-trained word\nembedding vectors and include a nonlinear output function in a simple manner.\nIn experiments, we show that our approach outperforms the state-of-the-art\nsupervised Latent Dirichlet Allocation implementation in terms of held-out\ndocument classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 12:39:59 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 05:56:31 GMT"}, {"version": "v3", "created": "Tue, 22 May 2018 06:33:12 GMT"}, {"version": "v4", "created": "Tue, 28 Aug 2018 21:52:57 GMT"}, {"version": "v5", "created": "Sun, 2 Jun 2019 12:33:30 GMT"}, {"version": "v6", "created": "Mon, 16 Sep 2019 10:23:33 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Hisano", "Ryohei", ""]]}, {"id": "1802.08013", "submitter": "Daniel Tanneberg", "authors": "Daniel Tanneberg, Jan Peters, Elmar Rueckert", "title": "Intrinsic Motivation and Mental Replay enable Efficient Online\n  Adaptation in Stochastic Recurrent Networks", "comments": "accepted in Neural Networks", "journal-ref": "Volume 109, January 2019, Pages 67-80", "doi": "10.1016/j.neunet.2018.10.005", "report-no": null, "categories": "cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous robots need to interact with unknown, unstructured and changing\nenvironments, constantly facing novel challenges. Therefore, continuous online\nadaptation for lifelong-learning and the need of sample-efficient mechanisms to\nadapt to changes in the environment, the constraints, the tasks, or the robot\nitself are crucial. In this work, we propose a novel framework for\nprobabilistic online motion planning with online adaptation based on a\nbio-inspired stochastic recurrent neural network. By using learning signals\nwhich mimic the intrinsic motivation signalcognitive dissonance in addition\nwith a mental replay strategy to intensify experiences, the stochastic\nrecurrent network can learn from few physical interactions and adapts to novel\nenvironments in seconds. We evaluate our online planning and adaptation\nframework on an anthropomorphic KUKA LWR arm. The rapid online adaptation is\nshown by learning unknown workspace constraints sample-efficiently from few\nphysical interactions while following given way points.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 12:41:06 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 08:36:19 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Tanneberg", "Daniel", ""], ["Peters", "Jan", ""], ["Rueckert", "Elmar", ""]]}, {"id": "1802.08054", "submitter": "Diego Granziol", "authors": "Diego Granziol, Edward Wagstaff, Bin Xin Ru, Michael Osborne, Stephen\n  Roberts", "title": "VBALD - Variational Bayesian Approximation of Log Determinants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the log determinant of a positive definite matrix is ubiquitous in\nmachine learning. Applications thereof range from Gaussian processes,\nminimum-volume ellipsoids, metric learning, kernel learning, Bayesian neural\nnetworks, Determinental Point Processes, Markov random fields to partition\nfunctions of discrete graphical models. In order to avoid the canonical, yet\nprohibitive, Cholesky $\\mathcal{O}(n^{3})$ computational cost, we propose a\nnovel approach, with complexity $\\mathcal{O}(n^{2})$, based on a constrained\nvariational Bayes algorithm. We compare our method to Taylor, Chebyshev and\nLanczos approaches and show state of the art performance on both synthetic and\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 14:11:18 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Granziol", "Diego", ""], ["Wagstaff", "Edward", ""], ["Ru", "Bin Xin", ""], ["Osborne", "Michael", ""], ["Roberts", "Stephen", ""]]}, {"id": "1802.08089", "submitter": "Andre Wibisono", "authors": "Andre Wibisono", "title": "Sampling as optimization in the space of measures: The Langevin dynamics\n  as a composite optimization problem", "comments": "To appear at the Conference on Learning Theory (COLT), July 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sampling as optimization in the space of measures. We focus on\ngradient flow-based optimization with the Langevin dynamics as a case study. We\ninvestigate the source of the bias of the unadjusted Langevin algorithm (ULA)\nin discrete time, and consider how to remove or reduce the bias. We point out\nthe difficulty is that the heat flow is exactly solvable, but neither its\nforward nor backward method is implementable in general, except for Gaussian\ndata. We propose the symmetrized Langevin algorithm (SLA), which should have a\nsmaller bias than ULA, at the price of implementing a proximal gradient step in\nspace. We show SLA is in fact consistent for Gaussian target measure, whereas\nULA is not. We also illustrate various algorithms explicitly for Gaussian\ntarget measure, including gradient descent, proximal gradient, and\nForward-Backward, and show they are all consistent.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 15:06:51 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 18:39:51 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Wibisono", "Andre", ""]]}, {"id": "1802.08154", "submitter": "Nariman Farsad", "authors": "Nariman Farsad and Andrea Goldsmith", "title": "Sliding Bidirectional Recurrent Neural Networks for Sequence Detection\n  in Communication Systems", "comments": "accepted for publication in the proceedings of IEEE International\n  Conference on Acoustics, Speech and Signal Processing (ICASSP) 2018. arXiv\n  admin note: text overlap with arXiv:1802.02046 and arXiv:1705.08044", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design and analysis of communication systems typically rely on the\ndevelopment of mathematical models that describe the underlying communication\nchannel. However, in some systems, such as molecular communication systems\nwhere chemical signals are used for transfer of information, the underlying\nchannel models are unknown. In these scenarios, a completely new approach to\ndesign and analysis is required. In this work, we focus on one important aspect\nof communication systems, the detection algorithms, and demonstrate that by\nusing tools from deep learning, it is possible to train detectors that perform\nwell without any knowledge of the underlying channel models. We propose a\ntechnique we call sliding bidirectional recurrent neural network (SBRNN) for\nreal-time sequence detection. We evaluate this algorithm using experimental\ndata that is collected by a chemical communication platform, where the channel\nmodel is unknown and difficult to model analytically. We show that deep\nlearning algorithms perform significantly better than a detector proposed in\nprevious works, and the SBRNN outperforms other techniques considered in this\nwork.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 20:13:19 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Farsad", "Nariman", ""], ["Goldsmith", "Andrea", ""]]}, {"id": "1802.08159", "submitter": "Lili Su", "authors": "Lili Su, Martin Zubeldia, Nancy Lynch", "title": "Collaboratively Learning the Best Option, Using Bounded Memory", "comments": "Authors's comments: This is a preliminary preprint of our work on\n  complete graphs. New aspects of our approach on general graphs have moved to:\n  Collaboratively Learning the Best Option on Graphs, Using Bounded Local\n  Memory, arXiv:1811.03968", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-armed bandit problems in social groups wherein each\nindividual has bounded memory and shares the common goal of learning the best\narm/option. We say an individual learns the best option if eventually (as $t\n\\to \\infty$) it pulls only the arm with the highest average reward. While this\ngoal is provably impossible for an isolated individual, we show that, in social\ngroups, this goal can be achieved easily with the aid of social persuasion,\ni.e., communication. Specifically, we study the learning dynamics wherein an\nindividual sequentially decides on which arm to pull next based on not only its\nprivate reward feedback but also the suggestions provided by randomly chosen\npeers. Our learning dynamics are hard to analyze via explicit probabilistic\ncalculations due to the stochastic dependency induced by social interaction.\nInstead, we employ the mean-field approximation method from statistical physics\nand we show:\n  (1) With probability $\\to 1$ as the social group size $N \\to \\infty $, every\nindividual in the social group learns the best option.\n  (2) Over an arbitrary finite time horizon $[0, T]$, with high probability (in\n$N$), the fraction of individuals that prefer the best option grows to 1\nexponentially fast as $t$ increases ($t\\in [0, T]$).\n  A major innovation of our mean-filed analysis is a simple yet powerful\ntechnique to deal with absorbing states in the interchange of limits $N \\to\n\\infty$ and $t \\to \\infty $. The mean-field approximation method allows us to\napproximate the probabilistic sample paths of our learning dynamics by a\ndeterministic and smooth trajectory that corresponds to the unique solution of\na well-behaved system of ordinary differential equations (ODEs). Such an\napproximation is desired because the analysis of a system of ODEs is relatively\neasier than that of the original stochastic system.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 16:47:56 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 03:20:45 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 02:21:20 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Su", "Lili", ""], ["Zubeldia", "Martin", ""], ["Lynch", "Nancy", ""]]}, {"id": "1802.08183", "submitter": "Lin Chen", "authors": "Lin Chen, Christopher Harshaw, Hamed Hassani, Amin Karbasi", "title": "Projection-Free Online Optimization with Stochastic Gradient: From\n  Convexity to Submodularity", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online optimization has been a successful framework for solving large-scale\nproblems under computational constraints and partial information. Current\nmethods for online convex optimization require either a projection or exact\ngradient computation at each step, both of which can be prohibitively expensive\nfor large-scale applications. At the same time, there is a growing trend of\nnon-convex optimization in machine learning community and a need for online\nmethods. Continuous DR-submodular functions, which exhibit a natural\ndiminishing returns condition, have recently been proposed as a broad class of\nnon-convex functions which may be efficiently optimized. Although online\nmethods have been introduced, they suffer from similar problems. In this work,\nwe propose Meta-Frank-Wolfe, the first online projection-free algorithm that\nuses stochastic gradient estimates. The algorithm relies on a careful sampling\nof gradients in each round and achieves the optimal $O( \\sqrt{T})$ adversarial\nregret bounds for convex and continuous submodular optimization. We also\npropose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single\nstochastic gradient estimate in each round and achieves an $O(T^{2/3})$\nstochastic regret bound for convex and continuous submodular optimization. We\napply our methods to develop a novel \"lifting\" framework for the online\ndiscrete submodular maximization and also see that they outperform current\nstate-of-the-art techniques on various experiments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 17:13:36 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 21:53:04 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 00:36:28 GMT"}, {"version": "v4", "created": "Thu, 14 Jun 2018 01:10:34 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Chen", "Lin", ""], ["Harshaw", "Christopher", ""], ["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""]]}, {"id": "1802.08195", "submitter": "Gamaleldin Elsayed", "authors": "Gamaleldin F. Elsayed, Shreya Shankar, Brian Cheung, Nicolas Papernot,\n  Alex Kurakin, Ian Goodfellow, Jascha Sohl-Dickstein", "title": "Adversarial Examples that Fool both Computer Vision and Time-Limited\n  Humans", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial examples: small changes\nto images can cause computer vision models to make mistakes such as identifying\na school bus as an ostrich. However, it is still an open question whether\nhumans are prone to similar mistakes. Here, we address this question by\nleveraging recent techniques that transfer adversarial examples from computer\nvision models with known parameters and architecture to other models with\nunknown parameters and architecture, and by matching the initial processing of\nthe human visual system. We find that adversarial examples that strongly\ntransfer across computer vision models influence the classifications made by\ntime-limited human observers.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 17:40:51 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 18:46:56 GMT"}, {"version": "v3", "created": "Tue, 22 May 2018 03:02:41 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Elsayed", "Gamaleldin F.", ""], ["Shankar", "Shreya", ""], ["Cheung", "Brian", ""], ["Papernot", "Nicolas", ""], ["Kurakin", "Alex", ""], ["Goodfellow", "Ian", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1802.08219", "submitter": "Nathaniel Thomas", "authors": "Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai\n  Kohlhoff, Patrick Riley", "title": "Tensor field networks: Rotation- and translation-equivariant neural\n  networks for 3D point clouds", "comments": "changes for NIPS submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce tensor field neural networks, which are locally equivariant to\n3D rotations, translations, and permutations of points at every layer. 3D\nrotation equivariance removes the need for data augmentation to identify\nfeatures in arbitrary orientations. Our network uses filters built from\nspherical harmonics; due to the mathematical consequences of this filter\nchoice, each layer accepts as input (and guarantees as output) scalars,\nvectors, and higher-order tensors, in the geometric sense of these terms. We\ndemonstrate the capabilities of tensor field networks with tasks in geometry,\nphysics, and chemistry.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 18:17:31 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 18:58:16 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 20:09:34 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Thomas", "Nathaniel", ""], ["Smidt", "Tess", ""], ["Kearnes", "Steven", ""], ["Yang", "Lusann", ""], ["Li", "Li", ""], ["Kohlhoff", "Kai", ""], ["Riley", "Patrick", ""]]}, {"id": "1802.08232", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini and Chang Liu and \\'Ulfar Erlingsson and Jernej Kos\n  and Dawn Song", "title": "The Secret Sharer: Evaluating and Testing Unintended Memorization in\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a testing methodology for quantitatively assessing the\nrisk that rare or unique training-data sequences are unintentionally memorized\nby generative sequence models---a common type of machine-learning model.\nBecause such models are sometimes trained on sensitive data (e.g., the text of\nusers' private messages), this methodology can benefit privacy by allowing\ndeep-learning practitioners to select means of training that minimize such\nmemorization.\n  In experiments, we show that unintended memorization is a persistent,\nhard-to-avoid issue that can have serious consequences. Specifically, for\nmodels trained without consideration of memorization, we describe new,\nefficient procedures that can extract unique, secret sequences, such as credit\ncard numbers. We show that our testing strategy is a practical and easy-to-use\nfirst line of defense, e.g., by describing its application to quantitatively\nlimit data exposure in Google's Smart Compose, a commercial text-completion\nneural network trained on millions of users' email messages.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 18:42:41 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 18:13:03 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 17:05:32 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Carlini", "Nicholas", ""], ["Liu", "Chang", ""], ["Erlingsson", "\u00dalfar", ""], ["Kos", "Jernej", ""], ["Song", "Dawn", ""]]}, {"id": "1802.08235", "submitter": "Daniel Vieira Mr.", "authors": "Daniel Vieira, Fabio Rangel, Fabricio Firmino and Joao Paixao", "title": "Vector Field Based Neural Networks", "comments": "6 pages, 5 figures. To appear in the Proceedings of the 26th European\n  Symposium on Artificial Neural Networks, Computational Intelligence and\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel Neural Network architecture is proposed using the mathematically and\nphysically rich idea of vector fields as hidden layers to perform nonlinear\ntransformations in the data. The data points are interpreted as particles\nmoving along a flow defined by the vector field which intuitively represents\nthe desired movement to enable classification. The architecture moves the data\npoints from their original configuration to anew one following the streamlines\nof the vector field with the objective of achieving a final configuration where\nclasses are separable. An optimization problem is solved through gradient\ndescent to learn this vector field.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 18:46:15 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Vieira", "Daniel", ""], ["Rangel", "Fabio", ""], ["Firmino", "Fabricio", ""], ["Paixao", "Joao", ""]]}, {"id": "1802.08241", "submitter": "Amir Gholami", "authors": "Zhewei Yao, Amir Gholami, Qi Lei, Kurt Keutzer, Michael W. Mahoney", "title": "Hessian-based Analysis of Large Batch Training and Robustness to\n  Adversaries", "comments": "Presented in NeurIPS'18 conference", "journal-ref": "NeurIPS 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large batch size training of Neural Networks has been shown to incur accuracy\nloss when trained with the current methods. The exact underlying reasons for\nthis are still not completely understood. Here, we study large batch size\ntraining through the lens of the Hessian operator and robust optimization. In\nparticular, we perform a Hessian based study to analyze exactly how the\nlandscape of the loss function changes when training with large batch size. We\ncompute the true Hessian spectrum, without approximation, by back-propagating\nthe second derivative. Extensive experiments on multiple networks show that\nsaddle-points are not the cause for generalization gap of large batch size\ntraining, and the results consistently show that large batch converges to\npoints with noticeably higher Hessian spectrum. Furthermore, we show that\nrobust training allows one to favor flat areas, as points with large Hessian\nspectrum show poor robustness to adversarial perturbation. We further study\nthis relationship, and provide empirical and theoretical proof that the inner\nloop for robust training is a saddle-free optimization problem \\textit{almost\neverywhere}. We present detailed experiments with five different network\narchitectures, including a residual network, tested on MNIST, CIFAR-10, and\nCIFAR-100 datasets. We have open sourced our method which can be accessed at\n[1].\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 18:55:00 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 19:41:12 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 22:25:00 GMT"}, {"version": "v4", "created": "Sun, 2 Dec 2018 19:58:30 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Lei", "Qi", ""], ["Keutzer", "Kurt", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1802.08246", "submitter": "Suriya Gunasekar", "authors": "Suriya Gunasekar, Jason Lee, Daniel Soudry, Nathan Srebro", "title": "Characterizing Implicit Bias in Terms of Optimization Geometry", "comments": "(1) A bug in the proof of implicit bias for matrix factorization was\n  fixed. v2 gives a characterization of the asymptotic bias of the factor\n  matrices, while v1 made a stronger claim on the limit direction of the\n  unfactored matrix. (2) v2 also includes new results on implicit bias of\n  mirror descent with realizable affine constraints", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the implicit bias of generic optimization methods, such as mirror\ndescent, natural gradient descent, and steepest descent with respect to\ndifferent potentials and norms, when optimizing underdetermined linear\nregression or separable linear classification problems. We explore the question\nof whether the specific global minimum (among the many possible global minima)\nreached by an algorithm can be characterized in terms of the potential or norm\nof the optimization geometry, and independently of hyperparameter choices such\nas step-size and momentum.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 18:58:31 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 03:45:12 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 21:05:43 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Gunasekar", "Suriya", ""], ["Lee", "Jason", ""], ["Soudry", "Daniel", ""], ["Srebro", "Nathan", ""]]}, {"id": "1802.08249", "submitter": "Maziar Sanjabi", "authors": "Maziar Sanjabi, Jimmy Ba, Meisam Razaviyayn, Jason D. Lee", "title": "On the Convergence and Robustness of Training GANs with Regularized\n  Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are one of the most practical methods\nfor learning data distributions. A popular GAN formulation is based on the use\nof Wasserstein distance as a metric between probability distributions.\nUnfortunately, minimizing the Wasserstein distance between the data\ndistribution and the generative model distribution is a computationally\nchallenging problem as its objective is non-convex, non-smooth, and even hard\nto compute. In this work, we show that obtaining gradient information of the\nsmoothed Wasserstein GAN formulation, which is based on regularized Optimal\nTransport (OT), is computationally effortless and hence one can apply first\norder optimization methods to minimize this objective. Consequently, we\nestablish theoretical convergence guarantee to stationarity for a proposed\nclass of GAN optimization algorithms. Unlike the original non-smooth\nformulation, our algorithm only requires solving the discriminator to\napproximate optimality. We apply our method to learning MNIST digits as well as\nCIFAR-10images. Our experiments show that our method is computationally\nefficient and generates images comparable to the state of the art algorithms\ngiven the same architecture and computational power.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 04:11:58 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 05:11:47 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Sanjabi", "Maziar", ""], ["Ba", "Jimmy", ""], ["Razaviyayn", "Meisam", ""], ["Lee", "Jason D.", ""]]}, {"id": "1802.08250", "submitter": "Lu\\'is Alexandre", "authors": "Abel S. Zacarias and Lu\\'is A. Alexandre", "title": "SeNA-CNN: Overcoming Catastrophic Forgetting in Convolutional Neural\n  Networks by Selective Network Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning aims to develop machine learning systems that can learn new\ntasks while preserving the performance on previous learned tasks. In this paper\nwe present a method to overcome catastrophic forgetting on convolutional neural\nnetworks, that learns new tasks and preserves the performance on old tasks\nwithout accessing the data of the original model, by selective network\naugmentation. The experiment results showed that SeNA-CNN, in some scenarios,\noutperforms the state-of-art Learning without Forgetting algorithm. Results\nalso showed that in some situations it is better to use SeNA-CNN instead of\ntraining a neural network using isolated learning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 10:23:36 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 08:59:04 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Zacarias", "Abel S.", ""], ["Alexandre", "Lu\u00eds A.", ""]]}, {"id": "1802.08288", "submitter": "Sagar Sharma", "authors": "Sagar Sharma and Keke Chen", "title": "Confidential Boosting with Random Linear Classifiers for Outsourced\n  User-generated Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-generated data is crucial to predictive modeling in many applications.\nWith a web/mobile/wearable interface, a data owner can continuously record data\ngenerated by distributed users and build various predictive models from the\ndata to improve their operations, services, and revenue. Due to the large size\nand evolving nature of users data, data owners may rely on public cloud service\nproviders (Cloud) for storage and computation scalability. Exposing sensitive\nuser-generated data and advanced analytic models to Cloud raises privacy\nconcerns. We present a confidential learning framework, SecureBoost, for data\nowners that want to learn predictive models from aggregated user-generated data\nbut offload the storage and computational burden to Cloud without having to\nworry about protecting the sensitive data. SecureBoost allows users to submit\nencrypted or randomly masked data to designated Cloud directly. Our framework\nutilizes random linear classifiers (RLCs) as the base classifiers in the\nboosting framework to dramatically simplify the design of the proposed\nconfidential boosting protocols, yet still preserve the model quality. A\nCryptographic Service Provider (CSP) is used to assist the Cloud's processing,\nreducing the complexity of the protocol constructions. We present two\nconstructions of SecureBoost: HE+GC and SecSh+GC, using combinations of\nhomomorphic encryption, garbled circuits, and random masking to achieve both\nsecurity and efficiency. For a boosted model, Cloud learns only the RLCs and\nthe CSP learns only the weights of the RLCs. Finally, the data owner collects\nthe two parts to get the complete model. We conduct extensive experiments to\nunderstand the quality of the RLC-based boosting and the cost distribution of\nthe constructions. Our results show that SecureBoost can efficiently learn\nhigh-quality boosting models from protected user-generated data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 20:22:11 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 23:56:47 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2019 20:11:51 GMT"}, {"version": "v4", "created": "Tue, 30 Apr 2019 18:54:51 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Sharma", "Sagar", ""], ["Chen", "Keke", ""]]}, {"id": "1802.08290", "submitter": "Jinjiang Guo", "authors": "Jinjiang Guo, Pengyuan Ren, Aiguo Gu, Jian Xu, Weixin Wu", "title": "Locally Adaptive Learning Loss for Semantic Image Segmentation", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel locally adaptive learning estimator for enhancing the\ninter- and intra- discriminative capabilities of Deep Neural Networks, which\ncan be used as improved loss layer for semantic image segmentation tasks. Most\nloss layers compute pixel-wise cost between feature maps and ground truths,\nignoring spatial layouts and interactions between neighboring pixels with same\nobject category, and thus networks cannot be effectively sensitive to\nintra-class connections. Stride by stride, our method firstly conducts adaptive\npooling filter operating over predicted feature maps, aiming to merge predicted\ndistributions over a small group of neighboring pixels with same category, and\nthen it computes cost between the merged distribution vector and their category\nlabel. Such design can make groups of neighboring predictions from same\ncategory involved into estimations on predicting correctness with respect to\ntheir category, and hence train networks to be more sensitive to regional\nconnections between adjacent pixels based on their categories. In the\nexperiments on Pascal VOC 2012 segmentation datasets, the consistently improved\nresults show that our proposed approach achieves better segmentation masks\nagainst previous counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 05:18:35 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 03:17:34 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Guo", "Jinjiang", ""], ["Ren", "Pengyuan", ""], ["Gu", "Aiguo", ""], ["Xu", "Jian", ""], ["Wu", "Weixin", ""]]}, {"id": "1802.08294", "submitter": "John Quan", "authors": "Daniel J. Mankowitz, Augustin \\v{Z}\\'idek, Andr\\'e Barreto, Dan\n  Horgan, Matteo Hessel, John Quan, Junhyuk Oh, Hado van Hasselt, David Silver,\n  Tom Schaul", "title": "Unicorn: Continual Learning with a Universal, Off-policy Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some real-world domains are best characterized as a single task, but for\nothers this perspective is limiting. Instead, some tasks continually grow in\ncomplexity, in tandem with the agent's competence. In continual learning, also\nreferred to as lifelong learning, there are no explicit task boundaries or\ncurricula. As learning agents have become more powerful, continual learning\nremains one of the frontiers that has resisted quick progress. To test\ncontinual learning capabilities we consider a challenging 3D domain with an\nimplicit sequence of tasks and sparse rewards. We propose a novel agent\narchitecture called Unicorn, which demonstrates strong continual learning and\noutperforms several baseline agents on the proposed domain. The agent achieves\nthis by jointly representing and learning multiple policies efficiently, using\na parallel off-policy learning setup.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 20:42:19 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 15:14:49 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Mankowitz", "Daniel J.", ""], ["\u017d\u00eddek", "Augustin", ""], ["Barreto", "Andr\u00e9", ""], ["Horgan", "Dan", ""], ["Hessel", "Matteo", ""], ["Quan", "John", ""], ["Oh", "Junhyuk", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""], ["Schaul", "Tom", ""]]}, {"id": "1802.08311", "submitter": "Jian Zhang", "authors": "Mario Srouji, Jian Zhang, Ruslan Salakhutdinov", "title": "Structured Control Nets for Deep Reinforcement Learning", "comments": "First two authors contributed equally", "journal-ref": "PMLR 80:4742-4751, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Reinforcement Learning has made impressive advances in\nsolving several important benchmark problems for sequential decision making.\nMany control applications use a generic multilayer perceptron (MLP) for\nnon-vision parts of the policy network. In this work, we propose a new neural\nnetwork architecture for the policy network representation that is simple yet\neffective. The proposed Structured Control Net (SCN) splits the generic MLP\ninto two separate sub-modules: a nonlinear control module and a linear control\nmodule. Intuitively, the nonlinear control is for forward-looking and global\ncontrol, while the linear control stabilizes the local dynamics around the\nresidual of global control. We hypothesize that this will bring together the\nbenefits of both linear and nonlinear policies: improve training sample\nefficiency, final episodic reward, and generalization of learned policy, while\nrequiring a smaller network and being generally applicable to different\ntraining methods. We validated our hypothesis with competitive results on\nsimulations from OpenAI MuJoCo, Roboschool, Atari, and a custom 2D urban\ndriving environment, with various ablation and generalization tests, trained\nwith multiple black-box and policy gradient training methods. The proposed\narchitecture has the potential to improve upon broader control tasks by\nincorporating problem specific priors into the architecture. As a case study,\nwe demonstrate much improved performance for locomotion tasks by emulating the\nbiological central pattern generators (CPGs) as the nonlinear part of the\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 21:31:34 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Srouji", "Mario", ""], ["Zhang", "Jian", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1802.08318", "submitter": "Uthaipon Tantipongpipat", "authors": "Aleksandar Nikolov and Mohit Singh and Uthaipon Tao Tantipongpipat", "title": "Proportional Volume Sampling and Approximation Algorithms for A-Optimal\n  Design", "comments": "Add that proportional volume sampling also solves D-optimal and\n  generalized ratio problem. Add some reference from last version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the optimal design problems where the goal is to choose a set of\nlinear measurements to obtain the most accurate estimate of an unknown vector\nin $d$ dimensions. We study the $A$-optimal design variant where the objective\nis to minimize the average variance of the error in the maximum likelihood\nestimate of the vector being measured. The problem also finds applications in\nsensor placement in wireless networks, sparse least squares regression, feature\nselection for $k$-means clustering, and matrix approximation. In this paper, we\nintroduce proportional volume sampling to obtain improved approximation\nalgorithms for $A$-optimal design. Our main result is to obtain improved\napproximation algorithms for the $A$-optimal design problem by introducing the\nproportional volume sampling algorithm. Our results nearly optimal bounds in\nthe asymptotic regime when the number of measurements done, $k$, is\nsignificantly more than the dimension $d$. We also give first approximation\nalgorithms when $k$ is small including when $k=d$. The proportional\nvolume-sampling algorithm also gives approximation algorithms for other optimal\ndesign objectives such as $D$-optimal design and generalized ratio objective\nmatching or improving previous best known results. Interestingly, we show that\na similar guarantee cannot be obtained for the $E$-optimal design problem. We\nalso show that the $A$-optimal design problem is NP-hard to approximate within\na fixed constant when $k=d$.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 22:02:42 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 21:17:45 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 14:45:10 GMT"}, {"version": "v4", "created": "Wed, 11 Jul 2018 19:05:11 GMT"}, {"version": "v5", "created": "Tue, 17 Jul 2018 15:10:52 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Nikolov", "Aleksandar", ""], ["Singh", "Mohit", ""], ["Tantipongpipat", "Uthaipon Tao", ""]]}, {"id": "1802.08323", "submitter": "Kyongmin Yeo", "authors": "Kyongmin Yeo and Igor Melnyk", "title": "Deep learning algorithm for data-driven simulation of noisy dynamical\n  system", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2018.10.024", "report-no": null, "categories": "physics.comp-ph cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep learning model, DE-LSTM, for the simulation of a stochastic\nprocess with an underlying nonlinear dynamics. The deep learning model aims to\napproximate the probability density function of a stochastic process via\nnumerical discretization and the underlying nonlinear dynamics is modeled by\nthe Long Short-Term Memory (LSTM) network. It is shown that, when the numerical\ndiscretization is used, the function estimation problem can be solved by a\nmulti-label classification problem. A penalized maximum log likelihood method\nis proposed to impose a smoothness condition in the prediction of the\nprobability distribution. We show that the time evolution of the probability\ndistribution can be computed by a high-dimensional integration of the\ntransition probability of the LSTM internal states. A Monte Carlo algorithm to\napproximate the high-dimensional integration is outlined. The behavior of\nDE-LSTM is thoroughly investigated by using the Ornstein-Uhlenbeck process and\nnoisy observations of nonlinear dynamical systems; Mackey-Glass time series and\nforced Van der Pol oscillator. It is shown that DE-LSTM makes a good prediction\nof the probability distribution without assuming any distributional properties\nof the stochastic process. For a multiple-step forecast of the Mackey-Glass\ntime series, the prediction uncertainty, denoted by the 95\\% confidence\ninterval, first grows, then dynamically adjusts following the evolution of the\nsystem, while in the simulation of the forced Van der Pol oscillator, the\nprediction uncertainty does not grow in time even for a 3,000-step forecast.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 22:08:14 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 15:09:06 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Yeo", "Kyongmin", ""], ["Melnyk", "Igor", ""]]}, {"id": "1802.08331", "submitter": "Andrew Cohen", "authors": "Andrew Cohen, Lei Yu, Robert Wright", "title": "Diverse Exploration for Fast and Safe Policy Improvement", "comments": "AAAI18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an important yet under-addressed problem of quickly and safely\nimproving policies in online reinforcement learning domains. As its solution,\nwe propose a novel exploration strategy - diverse exploration (DE), which\nlearns and deploys a diverse set of safe policies to explore the environment.\nWe provide DE theory explaining why diversity in behavior policies enables\neffective exploration without sacrificing exploitation. Our empirical study\nshows that an online policy improvement algorithm framework implementing the DE\nstrategy can achieve both fast policy improvement and safe online performance.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 22:33:40 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Cohen", "Andrew", ""], ["Yu", "Lei", ""], ["Wright", "Robert", ""]]}, {"id": "1802.08334", "submitter": "Max Simchowitz", "authors": "Max Simchowitz, Horia Mania, Stephen Tu, Michael I. Jordan, Benjamin\n  Recht", "title": "Learning Without Mixing: Towards A Sharp Analysis of Linear System\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the ordinary least-squares (OLS) estimator attains nearly\nminimax optimal performance for the identification of linear dynamical systems\nfrom a single observed trajectory. Our upper bound relies on a generalization\nof Mendelson's small-ball method to dependent data, eschewing the use of\nstandard mixing-time arguments. Our lower bounds reveal that these upper bounds\nmatch up to logarithmic factors. In particular, we capture the correct\nsignal-to-noise behavior of the problem, showing that more unstable linear\nsystems are easier to estimate. This behavior is qualitatively different from\narguments which rely on mixing-time calculations that suggest that unstable\nsystems are more difficult to estimate. We generalize our technique to provide\nbounds for a more general class of linear response time-series.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 22:48:11 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 21:13:21 GMT"}, {"version": "v3", "created": "Wed, 4 Apr 2018 03:05:45 GMT"}, {"version": "v4", "created": "Thu, 24 May 2018 05:57:45 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Simchowitz", "Max", ""], ["Mania", "Horia", ""], ["Tu", "Stephen", ""], ["Jordan", "Michael I.", ""], ["Recht", "Benjamin", ""]]}, {"id": "1802.08352", "submitter": "Phi Vu Tran", "authors": "Phi Vu Tran", "title": "Learning to Make Predictions on Graphs with Autoencoders", "comments": "Published as a conference paper at IEEE DSAA 2018", "journal-ref": null, "doi": "10.1109/DSAA.2018.00034", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We examine two fundamental tasks associated with graph representation\nlearning: link prediction and semi-supervised node classification. We present a\nnovel autoencoder architecture capable of learning a joint representation of\nboth local graph structure and available node features for the multi-task\nlearning of link prediction and node classification. Our autoencoder\narchitecture is efficiently trained end-to-end in a single learning stage to\nsimultaneously perform link prediction and node classification, whereas\nprevious related methods require multiple training steps that are difficult to\noptimize. We provide a comprehensive empirical evaluation of our models on nine\nbenchmark graph-structured datasets and demonstrate significant improvement\nover related methods for graph representation learning. Reference code and data\nare available at https://github.com/vuptran/graph-representation-learning\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 00:02:59 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2018 12:02:52 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Tran", "Phi Vu", ""]]}, {"id": "1802.08363", "submitter": "Ranjan Maitra", "authors": "Andrew Lithio and Ranjan Maitra", "title": "An efficient $k$-means-type algorithm for clustering datasets with\n  incomplete records", "comments": "21 pages, 12 figures, 3 tables, in press, Statistical Analysis and\n  Data Mining -- The ASA Data Science Journal, 2018", "journal-ref": null, "doi": "10.1002/sam.11392", "report-no": null, "categories": "stat.ML astro-ph.HE cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-means algorithm is arguably the most popular nonparametric clustering\nmethod but cannot generally be applied to datasets with incomplete records. The\nusual practice then is to either impute missing values under an assumed\nmissing-completely-at-random mechanism or to ignore the incomplete records, and\napply the algorithm on the resulting dataset. We develop an efficient version\nof the $k$-means algorithm that allows for clustering in the presence of\nincomplete records. Our extension is called $k_m$-means and reduces to the\n$k$-means algorithm when all records are complete. We also provide\ninitialization strategies for our algorithm and methods to estimate the number\nof groups in the dataset. Illustrations and simulations demonstrate the\nefficacy of our approach in a variety of settings and patterns of missing data.\nOur methods are also applied to the analysis of activation images obtained from\na functional Magnetic Resonance Imaging experiment.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 02:24:14 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 13:15:48 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Lithio", "Andrew", ""], ["Maitra", "Ranjan", ""]]}, {"id": "1802.08380", "submitter": "Lai Wei", "authors": "Lai Wei and Vaibhav Srivastava", "title": "On Abruptly-Changing and Slowly-Varying Multiarmed Bandit Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the non-stationary stochastic multiarmed bandit (MAB) problem and\npropose two generic algorithms, namely, the limited memory deterministic\nsequencing of exploration and exploitation (LM-DSEE) and the Sliding-Window\nUpper Confidence Bound# (SW-UCB#). We rigorously analyze these algorithms in\nabruptly-changing and slowly-varying environments and characterize their\nperformance. We show that the expected cumulative regret for these algorithms\nunder either of the environments is upper bounded by sublinear functions of\ntime, i.e., the time average of the regret asymptotically converges to zero. We\ncomplement our analytic results with numerical illustrations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 04:14:45 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 18:13:15 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Wei", "Lai", ""], ["Srivastava", "Vaibhav", ""]]}, {"id": "1802.08397", "submitter": "Yudong Chen", "authors": "Yudong Chen and Yuejie Chi", "title": "Harnessing Structures in Big Data via Guaranteed Low-Rank Matrix\n  Estimation", "comments": "To appear in IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank modeling plays a pivotal role in signal processing and machine\nlearning, with applications ranging from collaborative filtering, video\nsurveillance, medical imaging, to dimensionality reduction and adaptive\nfiltering. Many modern high-dimensional data and interactions thereof can be\nmodeled as lying approximately in a low-dimensional subspace or manifold,\npossibly with additional structures, and its proper exploitations lead to\nsignificant reduction of costs in sensing, computation and storage. In recent\nyears, there is a plethora of progress in understanding how to exploit low-rank\nstructures using computationally efficient procedures in a provable manner,\nincluding both convex and nonconvex approaches. On one side, convex relaxations\nsuch as nuclear norm minimization often lead to statistically optimal\nprocedures for estimating low-rank matrices, where first-order methods are\ndeveloped to address the computational challenges; on the other side, there is\nemerging evidence that properly designed nonconvex procedures, such as\nprojected gradient descent, often provide globally optimal solutions with a\nmuch lower computational cost in many problems. This survey article will\nprovide a unified overview of these recent advances on low-rank matrix\nestimation from incomplete measurements. Attention is paid to rigorous\ncharacterization of the performance of these algorithms, and to problems where\nthe low-rank matrix have additional structural properties that require new\nalgorithmic designs and theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 05:41:37 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 01:48:22 GMT"}, {"version": "v3", "created": "Wed, 2 May 2018 18:17:50 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Chen", "Yudong", ""], ["Chi", "Yuejie", ""]]}, {"id": "1802.08405", "submitter": "Yanjun Han", "authors": "Yanjun Han, Jiantao Jiao, Tsachy Weissman", "title": "Local moment matching: A unified methodology for symmetric functional\n  estimation and distribution estimation under Wasserstein distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present \\emph{Local Moment Matching (LMM)}, a unified methodology for\nsymmetric functional estimation and distribution estimation under Wasserstein\ndistance. We construct an efficiently computable estimator that achieves the\nminimax rates in estimating the distribution up to permutation, and show that\nthe plug-in approach of our unlabeled distribution estimator is \"universal\" in\nestimating symmetric functionals of discrete distributions. Instead of doing\nbest polynomial approximation explicitly as in existing literature of\nfunctional estimation, the plug-in approach conducts polynomial approximation\nimplicitly and attains the optimal sample complexity for the entropy, power sum\nand support size functionals.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 06:33:37 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 23:19:20 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Han", "Yanjun", ""], ["Jiao", "Jiantao", ""], ["Weissman", "Tsachy", ""]]}, {"id": "1802.08406", "submitter": "Viraj Jayminkumar Shah", "authors": "Viraj Shah and Chinmay Hegde", "title": "Solving Linear Inverse Problems Using GAN Priors: An Algorithm with\n  Provable Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent works, both sparsity-based methods as well as learning-based\nmethods have proven to be successful in solving several challenging linear\ninverse problems. However, sparsity priors for natural signals and images\nsuffer from poor discriminative capability, while learning-based methods seldom\nprovide concrete theoretical guarantees. In this work, we advocate the idea of\nreplacing hand-crafted priors, such as sparsity, with a Generative Adversarial\nNetwork (GAN) to solve linear inverse problems such as compressive sensing. In\nparticular, we propose a projected gradient descent (PGD) algorithm for\neffective use of GAN priors for linear inverse problems, and also provide\ntheoretical guarantees on the rate of convergence of this algorithm. Moreover,\nwe show empirically that our algorithm demonstrates superior performance over\nan existing method of leveraging GANs for compressive sensing.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 06:40:58 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Shah", "Viraj", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1802.08407", "submitter": "Shengyu Zhu", "authors": "Shengyu Zhu, Biao Chen, Zhitang Chen", "title": "Exponentially Consistent Kernel Two-Sample Tests", "comments": "17 pages. Added application to off-line change detection", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two sets of independent samples from unknown distributions $P$ and $Q$,\na two-sample test decides whether to reject the null hypothesis that $P=Q$.\nRecent attention has focused on kernel two-sample tests as the test statistics\nare easy to compute, converge fast, and have low bias with their finite sample\nestimates. However, there still lacks an exact characterization on the\nasymptotic performance of such tests, and in particular, the rate at which the\ntype-II error probability decays to zero in the large sample limit. In this\nwork, we establish that a class of kernel two-sample tests are exponentially\nconsistent with Polish, locally compact Hausdorff sample space, e.g., $\\mathbb\nR^d$. The obtained exponential decay rate is further shown to be optimal among\nall two-sample tests satisfying the level constraint, and is independent of\nparticular kernels provided that they are bounded continuous and\ncharacteristic. Our results gain new insights into related issues such as fair\nalternative for testing and kernel selection strategy. Finally, as an\napplication, we show that a kernel based test achieves the optimal detection\nfor off-line change detection in the nonparametric setting.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 06:45:05 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 13:22:09 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Zhu", "Shengyu", ""], ["Chen", "Biao", ""], ["Chen", "Zhitang", ""]]}, {"id": "1802.08435", "submitter": "Nal Kalchbrenner", "authors": "Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Norman\n  Casagrande, Edward Lockhart, Florian Stimberg, Aaron van den Oord, Sander\n  Dieleman, Koray Kavukcuoglu", "title": "Efficient Neural Audio Synthesis", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential models achieve state-of-the-art results in audio, visual and\ntextual domains with respect to both estimating the data distribution and\ngenerating high-quality samples. Efficient sampling for this class of models\nhas however remained an elusive problem. With a focus on text-to-speech\nsynthesis, we describe a set of general techniques for reducing sampling time\nwhile maintaining high output quality. We first describe a single-layer\nrecurrent neural network, the WaveRNN, with a dual softmax layer that matches\nthe quality of the state-of-the-art WaveNet model. The compact form of the\nnetwork makes it possible to generate 24kHz 16-bit audio 4x faster than real\ntime on a GPU. Second, we apply a weight pruning technique to reduce the number\nof weights in the WaveRNN. We find that, for a constant number of parameters,\nlarge sparse networks perform better than small dense networks and this\nrelationship holds for sparsity levels beyond 96%. The small number of weights\nin a Sparse WaveRNN makes it possible to sample high-fidelity audio on a mobile\nCPU in real time. Finally, we propose a new generation scheme based on\nsubscaling that folds a long sequence into a batch of shorter sequences and\nallows one to generate multiple samples at once. The Subscale WaveRNN produces\n16 samples per step without loss of quality and offers an orthogonal method for\nincreasing sampling efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 08:20:23 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 19:45:25 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Kalchbrenner", "Nal", ""], ["Elsen", "Erich", ""], ["Simonyan", "Karen", ""], ["Noury", "Seb", ""], ["Casagrande", "Norman", ""], ["Lockhart", "Edward", ""], ["Stimberg", "Florian", ""], ["Oord", "Aaron van den", ""], ["Dieleman", "Sander", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1802.08465", "submitter": "Francisco Javier Pulgar Rubio", "authors": "Francisco J. Pulgar, Francisco Charte, Antonio J. Rivera, Mar\\'ia J.\n  del Jesus", "title": "AEkNN: An AutoEncoder kNN-based classifier with built-in dimensionality\n  reduction", "comments": "35 pages, 13 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensionality, i.e. data having a large number of variables, tends to\nbe a challenge for most machine learning tasks, including classification. A\nclassifier usually builds a model representing how a set of inputs explain the\noutputs. The larger is the set of inputs and/or outputs, the more complex would\nbe that model. There is a family of classification algorithms, known as lazy\nlearning methods, which does not build a model. One of the best known members\nof this family is the kNN algorithm. Its strategy relies on searching a set of\nnearest neighbors, using the input variables as position vectors and computing\ndistances among them. These distances loss significance in high-dimensional\nspaces. Therefore kNN, as many other classifiers, tends to worse its\nperformance as the number of input variables grows.\n  In this work AEkNN, a new kNN-based algorithm with built-in dimensionality\nreduction, is presented. Aiming to obtain a new representation of the data,\nhaving a lower dimensionality but with more informational features, AEkNN\ninternally uses autoencoders. From this new feature vectors the computed\ndistances should be more significant, thus providing a way to choose better\nneighbors. A experimental evaluation of the new proposal is conducted,\nanalyzing several configurations and comparing them against the classical kNN\nalgorithm. The obtained conclusions demonstrate that AEkNN offers better\nresults in predictive and runtime performance.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 10:02:02 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 10:23:51 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Pulgar", "Francisco J.", ""], ["Charte", "Francisco", ""], ["Rivera", "Antonio J.", ""], ["del Jesus", "Mar\u00eda J.", ""]]}, {"id": "1802.08471", "submitter": "Simon Barthelm\\'e", "authors": "Nicolas Tremblay, Simon Barthelme and Pierre-Olivier Amblard", "title": "Optimized Algorithms to Sample Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report, we discuss several sampling algorithms for\nDeterminantal Point Processes (DPP). DPPs have recently gained a broad interest\nin the machine learning and statistics literature as random point processes\nwith negative correlation, i.e., ones that can generate a \"diverse\" sample from\na set of items. They are parametrized by a matrix $\\mathbf{L}$, called\n$L$-ensemble, that encodes the correlations between items. The standard\nsampling algorithm is separated in three phases: 1/~eigendecomposition of\n$\\mathbf{L}$, 2/~an eigenvector sampling phase where $\\mathbf{L}$'s\neigenvectors are sampled independently via a Bernoulli variable parametrized by\ntheir associated eigenvalue, 3/~a Gram-Schmidt-type orthogonalisation procedure\nof the sampled eigenvectors.\n  In a naive implementation, the computational cost of the third step is on\naverage $\\mathcal{O}(N\\mu^3)$ where $\\mu$ is the average number of samples of\nthe DPP. We give an algorithm which runs in $\\mathcal{O}(N\\mu^2)$ and is\nextremely simple to implement. If memory is a constraint, we also describe a\ndual variant with reduced memory costs. In addition, we discuss implementation\ndetails often missing in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 10:30:41 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Tremblay", "Nicolas", ""], ["Barthelme", "Simon", ""], ["Amblard", "Pierre-Olivier", ""]]}, {"id": "1802.08478", "submitter": "Wlodzislaw Duch", "authors": "Wlodzislaw Duch", "title": "Coloring black boxes: visualization of neural network decisions", "comments": "9 pages, 33 figures. Proc. of International Joint Conference on\n  Neural Networks (IJCNN) 2003, Vol. I, pp. 1735-1740", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are commonly regarded as black boxes performing\nincomprehensible functions. For classification problems networks provide maps\nfrom high dimensional feature space to K-dimensional image space. Images of\ntraining vector are projected on polygon vertices, providing visualization of\nnetwork function. Such visualization may show the dynamics of learning, allow\nfor comparison of different networks, display training vectors around which\npotential problems may arise, show differences due to regularization and\noptimization procedures, investigate stability of network classification under\nperturbation of original vectors, and place new data sample in relation to\ntraining data, allowing for estimation of confidence in classification of a\ngiven sample. An illustrative example for the three-class Wine data and\nfive-class Satimage data is described. The visualization method proposed here\nis applicable to any black box system that provides continuous outputs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 10:59:40 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Duch", "Wlodzislaw", ""]]}, {"id": "1802.08513", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Jerry Li and Ludwig Schmidt", "title": "Fast and Sample Near-Optimal Algorithms for Learning Multidimensional\n  Histograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robustly learning multi-dimensional histograms. A\n$d$-dimensional function $h: D \\rightarrow \\mathbb{R}$ is called a\n$k$-histogram if there exists a partition of the domain $D \\subseteq\n\\mathbb{R}^d$ into $k$ axis-aligned rectangles such that $h$ is constant within\neach such rectangle. Let $f: D \\rightarrow \\mathbb{R}$ be a $d$-dimensional\nprobability density function and suppose that $f$ is $\\mathrm{OPT}$-close, in\n$L_1$-distance, to an unknown $k$-histogram (with unknown partition). Our goal\nis to output a hypothesis that is $O(\\mathrm{OPT}) + \\epsilon$ close to $f$, in\n$L_1$-distance. We give an algorithm for this learning problem that uses $n =\n\\tilde{O}_d(k/\\epsilon^2)$ samples and runs in time $\\tilde{O}_d(n)$. For any\nfixed dimension, our algorithm has optimal sample complexity, up to logarithmic\nfactors, and runs in near-linear time. Prior to our work, the time complexity\nof the $d=1$ case was well-understood, but significant gaps in our\nunderstanding remained even for $d=2$.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 13:07:32 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Li", "Jerry", ""], ["Schmidt", "Ludwig", ""]]}, {"id": "1802.08526", "submitter": "Yunlong Jiao", "authors": "Yunlong Jiao and Jean-Philippe Vert", "title": "The Weighted Kendall and High-order Kernels for Permutations", "comments": "Published in ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new positive definite kernels for permutations. First we introduce\na weighted version of the Kendall kernel, which allows to weight unequally the\ncontributions of different item pairs in the permutations depending on their\nranks. Like the Kendall kernel, we show that the weighted version is invariant\nto relabeling of items and can be computed efficiently in $O(n \\ln(n))$\noperations, where $n$ is the number of items in the permutation. Second, we\npropose a supervised approach to learn the weights by jointly optimizing them\nwith the function estimated by a kernel machine. Third, while the Kendall\nkernel considers pairwise comparison between items, we extend it by considering\nhigher-order comparisons among tuples of items and show that the supervised\napproach of learning the weights can be systematically generalized to\nhigher-order permutation kernels.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 13:50:08 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 08:40:50 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Jiao", "Yunlong", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "1802.08530", "submitter": "Mark McDonnell", "authors": "Mark D. McDonnell", "title": "Training wide residual networks for deployment using a single bit for\n  each weight", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": "ICLR 2018 - International Conference on Learning Representations,\n  Apr 2018, Vancouver, Canada. 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For fast and energy-efficient deployment of trained deep neural networks on\nresource-constrained embedded hardware, each learned weight parameter should\nideally be represented and stored using a single bit. Error-rates usually\nincrease when this requirement is imposed. Here, we report large improvements\nin error rates on multiple datasets, for deep convolutional neural networks\ndeployed with 1-bit-per-weight. Using wide residual networks as our main\nbaseline, our approach simplifies existing methods that binarize weights by\napplying the sign function in training; we apply scaling factors for each layer\nwith constant unlearned values equal to the layer-specific standard deviations\nused for initialization. For CIFAR-10, CIFAR-100 and ImageNet, and models with\n1-bit-per-weight requiring less than 10 MB of parameter memory, we achieve\nerror rates of 3.9%, 18.5% and 26.0% / 8.5% (Top-1 / Top-5) respectively. We\nalso considered MNIST, SVHN and ImageNet32, achieving 1-bit-per-weight test\nresults of 0.27%, 1.9%, and 41.3% / 19.1% respectively. For CIFAR, our error\nrates halve previously reported values, and are within about 1% of our\nerror-rates for the same network with full-precision weights. For networks that\noverfit, we also show significant improvements in error rate by not learning\nbatch normalization scale and offset parameters. This applies to both full\nprecision and 1-bit-per-weight networks. Using a warm-restart learning-rate\nschedule, we found that training for 1-bit-per-weight is just as fast as\nfull-precision networks, with better accuracy than standard schedules, and\nachieved about 98%-99% of peak performance in just 62 training epochs for\nCIFAR-10/100. For full training code and trained models in MATLAB, Keras and\nPyTorch see https://github.com/McDonnell-Lab/1-bit-per-weight/ .\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 13:54:23 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["McDonnell", "Mark D.", ""]]}, {"id": "1802.08534", "submitter": "Yan Zheng", "authors": "Yan Zheng, Jianye Hao, Zongzhang Zhang", "title": "Weighted Double Deep Multiagent Reinforcement Learning in Stochastic\n  Cooperative Environments", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, multiagent deep reinforcement learning (DRL) has received\nincreasingly wide attention. Existing multiagent DRL algorithms are inefficient\nwhen facing with the non-stationarity due to agents update their policies\nsimultaneously in stochastic cooperative environments. This paper extends the\nrecently proposed weighted double estimator to the multiagent domain and\npropose a multiagent DRL framework, named weighted double deep Q-network\n(WDDQN). By utilizing the weighted double estimator and the deep neural\nnetwork, WDDQN can not only reduce the bias effectively but also be extended to\nscenarios with raw visual inputs. To achieve efficient cooperation in the\nmultiagent domain, we introduce the lenient reward network and the scheduled\nreplay strategy. Experiments show that the WDDQN outperforms the existing DRL\nand multiaent DRL algorithms, i.e., double DQN and lenient Q-learning, in terms\nof the average reward and the convergence rate in stochastic cooperative\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 14:03:22 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 16:34:29 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Zheng", "Yan", ""], ["Hao", "Jianye", ""], ["Zhang", "Zongzhang", ""]]}, {"id": "1802.08561", "submitter": "Kelly Peterson", "authors": "Yuria Utsumi, Ognjen Rudovic, Kelly Peterson, Ricardo Guerrero,\n  Rosalind W. Picard", "title": "Personalized Gaussian Processes for Forecasting of Alzheimer's Disease\n  Assessment Scale-Cognition Sub-Scale (ADAS-Cog13)", "comments": "International Engineering in Medicine and Biology Conference (EMBC)\n  2018 - accepted. 5 pages. arXiv admin note: text overlap with\n  arXiv:1712.00181", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the use of a personalized Gaussian Process model\n(pGP) to predict per-patient changes in ADAS-Cog13 -- a significant predictor\nof Alzheimer's Disease (AD) in the cognitive domain -- using data from each\npatient's previous visits, and testing on future (held-out) data. We start by\nlearning a population-level model using multi-modal data from previously seen\npatients using a base Gaussian Process (GP) regression. The personalized GP\n(pGP) is formed by adapting the base GP sequentially over time to a new\n(target) patient using domain adaptive GPs. We extend this personalized\napproach to predict the values of ADAS-Cog13 over the future 6, 12, 18, and 24\nmonths. We compare this approach to a GP model trained only on past data of the\ntarget patients (tGP), as well as to a new approach that combines pGP with tGP.\nWe find that the new approach, combining pGP with tGP, leads to large\nimprovements in accurately forecasting future ADAS-Cog13 scores.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 01:32:54 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 20:15:35 GMT"}, {"version": "v3", "created": "Mon, 12 Mar 2018 17:36:21 GMT"}, {"version": "v4", "created": "Fri, 4 May 2018 06:09:52 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Utsumi", "Yuria", ""], ["Rudovic", "Ognjen", ""], ["Peterson", "Kelly", ""], ["Guerrero", "Ricardo", ""], ["Picard", "Rosalind W.", ""]]}, {"id": "1802.08567", "submitter": "Alireza Bagheri", "authors": "Alireza Bagheri, Osvaldo Simeone, Bipin Rajendran", "title": "Adversarial Training for Probabilistic Spiking Neural Networks", "comments": "Submitted for possible publication. arXiv admin note: text overlap\n  with arXiv:1710.10704", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers trained using conventional empirical risk minimization or maximum\nlikelihood methods are known to suffer dramatic performance degradations when\ntested over examples adversarially selected based on knowledge of the\nclassifier's decision rule. Due to the prominence of Artificial Neural Networks\n(ANNs) as classifiers, their sensitivity to adversarial examples, as well as\nrobust training schemes, have been recently the subject of intense\ninvestigation. In this paper, for the first time, the sensitivity of spiking\nneural networks (SNNs), or third-generation neural networks, to adversarial\nexamples is studied. The study considers rate and time encoding, as well as\nrate and first-to-spike decoding. Furthermore, a robust training mechanism is\nproposed that is demonstrated to enhance the performance of SNNs under\nwhite-box attacks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 04:33:32 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 19:26:30 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Bagheri", "Alireza", ""], ["Simeone", "Osvaldo", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1802.08626", "submitter": "Michele Donini", "authors": "Michele Donini, Luca Oneto, Shai Ben-David, John Shawe-Taylor,\n  Massimiliano Pontil", "title": "Empirical Risk Minimization under Fairness Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We address the problem of algorithmic fairness: ensuring that sensitive\nvariables do not unfairly influence the outcome of a classifier. We present an\napproach based on empirical risk minimization, which incorporates a fairness\nconstraint into the learning problem. It encourages the conditional risk of the\nlearned classifier to be approximately constant with respect to the sensitive\nvariable. We derive both risk and fairness bounds that support the statistical\nconsistency of our approach. We specify our approach to kernel methods and\nobserve that the fairness requirement implies an orthogonality constraint which\ncan be easily added to these methods. We further observe that for linear models\nthe constraint translates into a simple data preprocessing step. Experiments\nindicate that the method is empirically effective and performs favorably\nagainst state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 16:31:52 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 18:11:19 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 08:15:29 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Donini", "Michele", ""], ["Oneto", "Luca", ""], ["Ben-David", "Shai", ""], ["Shawe-Taylor", "John", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1802.08635", "submitter": "Lu Hou", "authors": "Lu Hou, James T. Kwok", "title": "Loss-aware Weight Quantization of Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The huge size of deep networks hinders their use in small computing devices.\nIn this paper, we consider compressing the network by weight quantization. We\nextend a recently proposed loss-aware weight binarization scheme to\nternarization, with possibly different scaling parameters for the positive and\nnegative weights, and m-bit (where m > 2) quantization. Experiments on\nfeedforward and recurrent neural networks show that the proposed scheme\noutperforms state-of-the-art weight quantization algorithms, and is as accurate\n(or even more accurate) than the full-precision network.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 16:54:22 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 11:23:17 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Hou", "Lu", ""], ["Kwok", "James T.", ""]]}, {"id": "1802.08665", "submitter": "Gonzalo Mena E", "authors": "Gonzalo Mena, David Belanger, Scott Linderman, Jasper Snoek", "title": "Learning Latent Permutations with Gumbel-Sinkhorn Networks", "comments": null, "journal-ref": "ICLR 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permutations and matchings are core building blocks in a variety of latent\nvariable models, as they allow us to align, canonicalize, and sort data.\nLearning in such models is difficult, however, because exact marginalization\nover these combinatorial objects is intractable. In response, this paper\nintroduces a collection of new methods for end-to-end learning in such models\nthat approximate discrete maximum-weight matching using the continuous Sinkhorn\noperator. Sinkhorn iteration is attractive because it functions as a simple,\neasy-to-implement analog of the softmax operator. With this, we can define the\nGumbel-Sinkhorn method, an extension of the Gumbel-Softmax method (Jang et al.\n2016, Maddison2016 et al. 2016) to distributions over latent matchings. We\ndemonstrate the effectiveness of our method by outperforming competitive\nbaselines on a range of qualitatively different tasks: sorting numbers, solving\njigsaw puzzles, and identifying neural signals in worms.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 18:15:13 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Mena", "Gonzalo", ""], ["Belanger", "David", ""], ["Linderman", "Scott", ""], ["Snoek", "Jasper", ""]]}, {"id": "1802.08674", "submitter": "L. Elisa Celis", "authors": "L. Elisa Celis, Sayash Kapoor, Farnood Salehi, and Nisheeth K. Vishnoi", "title": "An Algorithmic Framework to Control Bias in Bandit-based Personalization", "comments": "A short version of this paper appeared in FAT/ML 2017\n  (arXiv:1707.02260)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization is pervasive in the online space as it leads to higher\nefficiency and revenue by allowing the most relevant content to be served to\neach user. However, recent studies suggest that personalization methods can\npropagate societal or systemic biases and polarize opinions; this has led to\ncalls for regulatory mechanisms and algorithms to combat bias and inequality.\nAlgorithmically, bandit optimization has enjoyed great success in learning user\npreferences and personalizing content or feeds accordingly. We propose an\nalgorithmic framework that allows for the possibility to control bias or\ndiscrimination in such bandit-based personalization. Our model allows for the\nspecification of general fairness constraints on the sensitive types of the\ncontent that can be displayed to a user. The challenge, however, is to come up\nwith a scalable and low regret algorithm for the constrained optimization\nproblem that arises. Our main technical contribution is a provably fast and\nlow-regret algorithm for the fairness-constrained bandit optimization problem.\nOur proofs crucially leverage the special structure of our problem. Experiments\non synthetic and real-world data sets show that our algorithmic framework can\ncontrol bias with only a minor loss to revenue.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 18:44:01 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Celis", "L. Elisa", ""], ["Kapoor", "Sayash", ""], ["Salehi", "Farnood", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1802.08678", "submitter": "Felix Berkenkamp", "authors": "Shromona Ghosh, Felix Berkenkamp, Gireeja Ranade, Shaz Qadeer, Ashish\n  Kapoor", "title": "Verifying Controllers Against Adversarial Examples with Bayesian\n  Optimization", "comments": "Proc. of the IEEE International Conference on Robotics and\n  Automation, 2018", "journal-ref": null, "doi": "10.1109/ICRA.2018.8460635", "report-no": null, "categories": "cs.SY cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes in reinforcement learning have lead to the development of\ncomplex controllers for real-world robots. As these robots are deployed in\nsafety-critical applications and interact with humans, it becomes critical to\nensure safety in order to avoid causing harm. A first step in this direction is\nto test the controllers in simulation. To be able to do this, we need to\ncapture what we mean by safety and then efficiently search the space of all\nbehaviors to see if they are safe. In this paper, we present an active-testing\nframework based on Bayesian Optimization. We specify safety constraints using\nlogic and exploit structure in the problem in order to test the system for\nadversarial counter examples that violate the safety specifications. These\nspecifications are defined as complex boolean combinations of smooth functions\non the trajectories and, unlike reward functions in reinforcement learning, are\nexpressive and impose hard constraints on the system. In our framework, we\nexploit regularity assumptions on individual functions in form of a Gaussian\nProcess (GP) prior. We combine these into a coherent optimization framework\nusing problem structure. The resulting algorithm is able to provably verify\ncomplex safety specifications or alternatively find counter examples.\nExperimental results show that the proposed method is able to find adversarial\nexamples quickly.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 18:53:44 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 11:03:21 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Ghosh", "Shromona", ""], ["Berkenkamp", "Felix", ""], ["Ranade", "Gireeja", ""], ["Qadeer", "Shaz", ""], ["Kapoor", "Ashish", ""]]}, {"id": "1802.08679", "submitter": "Onur Atan", "authors": "Onur Atan, William R. Zame, M van der Schaar", "title": "Learning Optimal Policies from Observational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing optimal (or at least better) policies is an important problem in\ndomains from medicine to education to finance and many others. One approach to\nthis problem is through controlled experiments/trials - but controlled\nexperiments are expensive. Hence it is important to choose the best policies on\nthe basis of observational data. This presents two difficult challenges: (i)\nmissing counterfactuals, and (ii) selection bias. This paper presents\ntheoretical bounds on estimation errors of counterfactuals from observational\ndata by making connections to domain adaptation theory. It also presents a\nprincipled way of choosing optimal policies using domain adversarial neural\nnetworks. We illustrate the effectiveness of domain adversarial training\ntogether with various features of our algorithm on a semi-synthetic breast\ncancer dataset and a supervised UCI dataset (Statlog).\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 18:56:32 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Atan", "Onur", ""], ["Zame", "William R.", ""], ["van der Schaar", "M", ""]]}, {"id": "1802.08686", "submitter": "Alhussein Fawzi", "authors": "Alhussein Fawzi, Hamza Fawzi, Omar Fawzi", "title": "Adversarial vulnerability for any classifier", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite achieving impressive performance, state-of-the-art classifiers remain\nhighly vulnerable to small, imperceptible, adversarial perturbations. This\nvulnerability has proven empirically to be very intricate to address. In this\npaper, we study the phenomenon of adversarial perturbations under the\nassumption that the data is generated with a smooth generative model. We derive\nfundamental upper bounds on the robustness to perturbations of any\nclassification function, and prove the existence of adversarial perturbations\nthat transfer well across different classifiers with small risk. Our analysis\nof the robustness also provides insights onto key properties of generative\nmodels, such as their smoothness and dimensionality of latent space. We\nconclude with numerical experimental results showing that our bounds provide\ninformative baselines to the maximal achievable robustness on several datasets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 15:46:05 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 15:44:52 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Fawzi", "Alhussein", ""], ["Fawzi", "Hamza", ""], ["Fawzi", "Omar", ""]]}, {"id": "1802.08714", "submitter": "Huaxiu Yao", "authors": "Huaxiu Yao, Fei Wu, Jintao Ke, Xianfeng Tang, Yitian Jia, Siyu Lu,\n  Pinghua Gong, Jieping Ye, Zhenhui Li", "title": "Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction", "comments": "AAAI 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxi demand prediction is an important building block to enabling intelligent\ntransportation systems in a smart city. An accurate prediction model can help\nthe city pre-allocate resources to meet travel demand and to reduce empty taxis\non streets which waste energy and worsen the traffic congestion. With the\nincreasing popularity of taxi requesting services such as Uber and Didi Chuxing\n(in China), we are able to collect large-scale taxi demand data continuously.\nHow to utilize such big data to improve the demand prediction is an interesting\nand critical real-world problem. Traditional demand prediction methods mostly\nrely on time series forecasting techniques, which fail to model the complex\nnon-linear spatial and temporal relations. Recent advances in deep learning\nhave shown superior performance on traditionally challenging tasks such as\nimage classification by learning the complex features and correlations from\nlarge-scale data. This breakthrough has inspired researchers to explore deep\nlearning techniques on traffic prediction problems. However, existing methods\non traffic prediction have only considered spatial relation (e.g., using CNN)\nor temporal relation (e.g., using LSTM) independently. We propose a Deep\nMulti-View Spatial-Temporal Network (DMVST-Net) framework to model both spatial\nand temporal relations. Specifically, our proposed model consists of three\nviews: temporal view (modeling correlations between future demand values with\nnear time points via LSTM), spatial view (modeling local spatial correlation\nvia local CNN), and semantic view (modeling correlations among regions sharing\nsimilar temporal patterns). Experiments on large-scale real taxi demand data\ndemonstrate effectiveness of our approach over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 19:53:13 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 01:42:08 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Yao", "Huaxiu", ""], ["Wu", "Fei", ""], ["Ke", "Jintao", ""], ["Tang", "Xianfeng", ""], ["Jia", "Yitian", ""], ["Lu", "Siyu", ""], ["Gong", "Pinghua", ""], ["Ye", "Jieping", ""], ["Li", "Zhenhui", ""]]}, {"id": "1802.08717", "submitter": "Maciej Mazurowski", "authors": "Maciej A. Mazurowski, Mateusz Buda, Ashirbani Saha, Mustafa R. Bashir", "title": "Deep learning in radiology: an overview of the concepts and a survey of\n  the state of the art", "comments": "27 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a branch of artificial intelligence where networks of simple\ninterconnected units are used to extract patterns from data in order to solve\ncomplex problems. Deep learning algorithms have shown groundbreaking\nperformance in a variety of sophisticated tasks, especially those related to\nimages. They have often matched or exceeded human performance. Since the\nmedical field of radiology mostly relies on extracting useful information from\nimages, it is a very natural application area for deep learning, and research\nin this area has rapidly grown in recent years. In this article, we review the\nclinical reality of radiology and discuss the opportunities for application of\ndeep learning algorithms. We also introduce basic concepts of deep learning\nincluding convolutional neural networks. Then, we present a survey of the\nresearch in deep learning applied to radiology. We organize the studies by the\ntypes of specific tasks that they attempt to solve and review the broad range\nof utilized deep learning algorithms. Finally, we briefly discuss opportunities\nand challenges for incorporating deep learning in the radiology practice of the\nfuture.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 04:00:55 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Mazurowski", "Maciej A.", ""], ["Buda", "Mateusz", ""], ["Saha", "Ashirbani", ""], ["Bashir", "Mustafa R.", ""]]}, {"id": "1802.08718", "submitter": "Sven Schmit", "authors": "Ramesh Johari and Sven Schmit", "title": "Learning with Abandonment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a platform that wants to learn a personalized policy for each user,\nbut the platform faces the risk of a user abandoning the platform if she is\ndissatisfied with the actions of the platform. For example, a platform is\ninterested in personalizing the number of newsletters it sends, but faces the\nrisk that the user unsubscribes forever. We propose a general thresholded\nlearning model for scenarios like this, and discuss the structure of optimal\npolicies. We describe salient features of optimal personalization algorithms\nand how feedback the platform receives impacts the results. Furthermore, we\ninvestigate how the platform can efficiently learn the heterogeneity across\nusers by interacting with a population and provide performance guarantees.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 19:59:39 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Johari", "Ramesh", ""], ["Schmit", "Sven", ""]]}, {"id": "1802.08729", "submitter": "Waleed Alomoush", "authors": "Waleed Alomoush, Ayat Alrosan", "title": "Review: Metaheuristic Search-Based Fuzzy Clustering Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fuzzy clustering is a famous unsupervised learning method used to collecting\nsimilar data elements within cluster according to some similarity measurement.\nBut, clustering algorithms suffer from some drawbacks. Among the main weakness\nincluding, selecting the initial cluster centres and the appropriate clusters\nnumber is normally unknown. These weaknesses are considered the most\nchallenging tasks in clustering algorithms. This paper introduces a\ncomprehensive review of metahueristic search to solve fuzzy clustering\nalgorithms problems.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 17:24:31 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Alomoush", "Waleed", ""], ["Alrosan", "Ayat", ""]]}, {"id": "1802.08735", "submitter": "Rui Shu", "authors": "Rui Shu, Hung H. Bui, Hirokazu Narui, Stefano Ermon", "title": "A DIRT-T Approach to Unsupervised Domain Adaptation", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation refers to the problem of leveraging labeled data in a\nsource domain to learn an accurate model in a target domain where labels are\nscarce or unavailable. A recent approach for finding a common representation of\nthe two domains is via domain adversarial training (Ganin & Lempitsky, 2015),\nwhich attempts to induce a feature extractor that matches the source and target\nfeature distributions in some feature space. However, domain adversarial\ntraining faces two critical limitations: 1) if the feature extraction function\nhas high-capacity, then feature distribution matching is a weak constraint, 2)\nin non-conservative domain adaptation (where no single classifier can perform\nwell in both the source and target domains), training the model to do well on\nthe source domain hurts performance on the target domain. In this paper, we\naddress these issues through the lens of the cluster assumption, i.e., decision\nboundaries should not cross high-density data regions. We propose two novel and\nrelated models: 1) the Virtual Adversarial Domain Adaptation (VADA) model,\nwhich combines domain adversarial training with a penalty term that punishes\nthe violation the cluster assumption; 2) the Decision-boundary Iterative\nRefinement Training with a Teacher (DIRT-T) model, which takes the VADA model\nas initialization and employs natural gradient steps to further minimize the\ncluster assumption violation. Extensive empirical results demonstrate that the\ncombination of these two models significantly improve the state-of-the-art\nperformance on the digit, traffic sign, and Wi-Fi recognition domain adaptation\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 20:57:28 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 13:45:46 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Shu", "Rui", ""], ["Bui", "Hung H.", ""], ["Narui", "Hirokazu", ""], ["Ermon", "Stefano", ""]]}, {"id": "1802.08737", "submitter": "Rajat Sen", "authors": "Rajat Sen, Karthikeyan Shanmugam, Nihal Sharma, Sanjay Shakkottai", "title": "Contextual Bandits with Stochastic Experts", "comments": "20 pages, 2 Figures, Accepted for publication in AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of contextual bandits with stochastic experts, which\nis a variation of the traditional stochastic contextual bandit with experts\nproblem. In our problem setting, we assume access to a class of stochastic\nexperts, where each expert is a conditional distribution over the arms given a\ncontext. We propose upper-confidence bound (UCB) algorithms for this problem,\nwhich employ two different importance sampling based estimators for the mean\nreward for each expert. Both these estimators leverage information leakage\namong the experts, thus using samples collected under all the experts to\nestimate the mean reward of any given expert. This leads to instance dependent\nregret bounds of $\\mathcal{O}\\left(\\lambda(\\pmb{\\mu})\\mathcal{M}\\log T/\\Delta\n\\right)$, where $\\lambda(\\pmb{\\mu})$ is a term that depends on the mean rewards\nof the experts, $\\Delta$ is the smallest gap between the mean reward of the\noptimal expert and the rest, and $\\mathcal{M}$ quantifies the information\nleakage among the experts. We show that under some assumptions\n$\\lambda(\\pmb{\\mu})$ is typically $\\mathcal{O}(\\log N)$, where $N$ is the\nnumber of experts. We implement our algorithm with stochastic experts generated\nfrom cost-sensitive classification oracles and show superior empirical\nperformance on real-world datasets, when compared to other state of the art\ncontextual bandit algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 21:03:49 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 04:58:01 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Sen", "Rajat", ""], ["Shanmugam", "Karthikeyan", ""], ["Sharma", "Nihal", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1802.08757", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Zhuoran Yang, Han Liu, Tong Zhang, and Tamer Ba\\c{s}ar", "title": "Fully Decentralized Multi-Agent Reinforcement Learning with Networked\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of \\emph{fully decentralized} multi-agent\nreinforcement learning (MARL), where the agents are located at the nodes of a\ntime-varying communication network. Specifically, we assume that the reward\nfunctions of the agents might correspond to different tasks, and are only known\nto the corresponding agent. Moreover, each agent makes individual decisions\nbased on both the information observed locally and the messages received from\nits neighbors over the network. Within this setting, the collective goal of the\nagents is to maximize the globally averaged return over the network through\nexchanging information with their neighbors. To this end, we propose two\ndecentralized actor-critic algorithms with function approximation, which are\napplicable to large-scale MARL problems where both the number of states and the\nnumber of agents are massively large. Under the decentralized structure, the\nactor step is performed individually by each agent with no need to infer the\npolicies of others. For the critic step, we propose a consensus update via\ncommunication over the network. Our algorithms are fully incremental and can be\nimplemented in an online fashion. Convergence analyses of the algorithms are\nprovided when the value functions are approximated within the class of linear\nfunctions. Extensive simulation results with both linear and nonlinear function\napproximations are presented to validate the proposed algorithms. Our work\nappears to be the first study of fully decentralized MARL algorithms for\nnetworked agents with function approximation, with provable convergence\nguarantees.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 22:53:32 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 02:15:35 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Liu", "Han", ""], ["Zhang", "Tong", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1802.08760", "submitter": "Roman Novak", "authors": "Roman Novak, Yasaman Bahri, Daniel A. Abolafia, Jeffrey Pennington,\n  Jascha Sohl-Dickstein", "title": "Sensitivity and Generalization in Neural Networks: an Empirical Study", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice it is often found that large over-parameterized neural networks\ngeneralize better than their smaller counterparts, an observation that appears\nto conflict with classical notions of function complexity, which typically\nfavor smaller models. In this work, we investigate this tension between\ncomplexity and generalization through an extensive empirical exploration of two\nnatural metrics of complexity related to sensitivity to input perturbations.\nOur experiments survey thousands of models with various fully-connected\narchitectures, optimizers, and other hyper-parameters, as well as four\ndifferent image classification datasets.\n  We find that trained neural networks are more robust to input perturbations\nin the vicinity of the training data manifold, as measured by the norm of the\ninput-output Jacobian of the network, and that it correlates well with\ngeneralization. We further establish that factors associated with poor\ngeneralization $-$ such as full-batch training or using random labels $-$\ncorrespond to lower robustness, while factors associated with good\ngeneralization $-$ such as data augmentation and ReLU non-linearities $-$ give\nrise to more robust functions. Finally, we demonstrate how the input-output\nJacobian norm can be predictive of generalization at the level of individual\ntest points.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 23:11:07 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 23:45:21 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 18:01:43 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Novak", "Roman", ""], ["Bahri", "Yasaman", ""], ["Abolafia", "Daniel A.", ""], ["Pennington", "Jeffrey", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1802.08762", "submitter": "N. Benjamin Erichson", "authors": "N. Benjamin Erichson and Lionel Mathelin and Steven L. Brunton and J.\n  Nathan Kutz", "title": "Diffusion Maps meet Nystr\\\"om", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion maps are an emerging data-driven technique for non-linear\ndimensionality reduction, which are especially useful for the analysis of\ncoherent structures and nonlinear embeddings of dynamical systems. However, the\ncomputational complexity of the diffusion maps algorithm scales with the number\nof observations. Thus, long time-series data presents a significant challenge\nfor fast and efficient embedding. We propose integrating the Nystr\\\"om method\nwith diffusion maps in order to ease the computational demand. We achieve a\nspeedup of roughly two to four times when approximating the dominant diffusion\nmap components.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 23:33:28 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Erichson", "N. Benjamin", ""], ["Mathelin", "Lionel", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1802.08765", "submitter": "Yejia Liu", "authors": "Oliver Schulte and Yejia Liu and Chao Li", "title": "Model Trees for Identifying Exceptional Players in the NHL Draft", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drafting strong players is crucial for the team success. We describe a new\ndata-driven interpretable approach for assessing draft prospects in the\nNational Hockey League. Successful previous approaches have built a predictive\nmodel based on player features, or derived performance predictions from the\nobserved performance of comparable players in a cohort. This paper develops\nmodel tree learning, which incorporates strengths of both model-based and\ncohort-based approaches. A model tree partitions the feature space according to\nthe values of discrete features, or learned thresholds for continuous features.\nEach leaf node in the tree defines a group of players, easily described to\nhockey experts, with its own group regression model. Compared to a single\nmodel, the model tree forms an ensemble that increases predictive power.\nCompared to cohort-based approaches, the groups of comparables are discovered\nfrom the data, without requiring a similarity metric. The performance\npredictions of the model tree are competitive with the state-of-the-art\nmethods, which validates our model empirically. We show in case studies that\nthe model tree player ranking can be used to highlight strong and weak points\nof players.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 23:39:41 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Schulte", "Oliver", ""], ["Liu", "Yejia", ""], ["Li", "Chao", ""]]}, {"id": "1802.08768", "submitter": "Augustus Odena", "authors": "Augustus Odena, Jacob Buckman, Catherine Olsson, Tom B. Brown,\n  Christopher Olah, Colin Raffel, Ian Goodfellow", "title": "Is Generator Conditioning Causally Related to GAN Performance?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work (Pennington et al, 2017) suggests that controlling the entire\ndistribution of Jacobian singular values is an important design consideration\nin deep learning. Motivated by this, we study the distribution of singular\nvalues of the Jacobian of the generator in Generative Adversarial Networks\n(GANs). We find that this Jacobian generally becomes ill-conditioned at the\nbeginning of training. Moreover, we find that the average (with z from p(z))\nconditioning of the generator is highly predictive of two other ad-hoc metrics\nfor measuring the 'quality' of trained GANs: the Inception Score and the\nFrechet Inception Distance (FID). We test the hypothesis that this relationship\nis causal by proposing a 'regularization' technique (called Jacobian Clamping)\nthat softly penalizes the condition number of the generator Jacobian. Jacobian\nClamping improves the mean Inception Score and the mean FID for GANs trained on\nseveral datasets. It also greatly reduces inter-run variance of the\naforementioned scores, addressing (at least partially) one of the main\ncriticisms of GANs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 23:48:01 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 00:06:57 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Odena", "Augustus", ""], ["Buckman", "Jacob", ""], ["Olsson", "Catherine", ""], ["Brown", "Tom B.", ""], ["Olah", "Christopher", ""], ["Raffel", "Colin", ""], ["Goodfellow", "Ian", ""]]}, {"id": "1802.08770", "submitter": "Devansh Arpit", "authors": "Chen Xing, Devansh Arpit, Christos Tsirigotis, Yoshua Bengio", "title": "A Walk with SGD", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel empirical observations regarding how stochastic gradient\ndescent (SGD) navigates the loss landscape of over-parametrized deep neural\nnetworks (DNNs). These observations expose the qualitatively different roles of\nlearning rate and batch-size in DNN optimization and generalization.\nSpecifically we study the DNN loss surface along the trajectory of SGD by\ninterpolating the loss surface between parameters from consecutive\n\\textit{iterations} and tracking various metrics during training. We find that\nthe loss interpolation between parameters before and after each training\niteration's update is roughly convex with a minimum (\\textit{valley floor}) in\nbetween for most of the training. Based on this and other metrics, we deduce\nthat for most of the training update steps, SGD moves in valley like regions of\nthe loss surface by jumping from one valley wall to another at a height above\nthe valley floor. This 'bouncing between walls at a height' mechanism helps SGD\ntraverse larger distance for small batch sizes and large learning rates which\nwe find play qualitatively different roles in the dynamics. While a large\nlearning rate maintains a large height from the valley floor, a small batch\nsize injects noise facilitating exploration. We find this mechanism is crucial\nfor generalization because the valley floor has barriers and this exploration\nabove the valley floor allows SGD to quickly travel far away from the\ninitialization point (without being affected by barriers) and find flatter\nregions, corresponding to better generalization.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 00:21:10 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 16:39:29 GMT"}, {"version": "v3", "created": "Sun, 8 Apr 2018 11:42:41 GMT"}, {"version": "v4", "created": "Wed, 30 May 2018 01:15:02 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Xing", "Chen", ""], ["Arpit", "Devansh", ""], ["Tsirigotis", "Christos", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1802.08773", "submitter": "Rex Ying", "authors": "Jiaxuan You, Rex Ying, Xiang Ren, William L. Hamilton, Jure Leskovec", "title": "GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling and generating graphs is fundamental for studying networks in\nbiology, engineering, and social sciences. However, modeling complex\ndistributions over graphs and then efficiently sampling from these\ndistributions is challenging due to the non-unique, high-dimensional nature of\ngraphs and the complex, non-local dependencies that exist between edges in a\ngiven graph. Here we propose GraphRNN, a deep autoregressive model that\naddresses the above challenges and approximates any distribution of graphs with\nminimal assumptions about their structure. GraphRNN learns to generate graphs\nby training on a representative set of graphs and decomposes the graph\ngeneration process into a sequence of node and edge formations, conditioned on\nthe graph structure generated so far.\n  In order to quantitatively evaluate the performance of GraphRNN, we introduce\na benchmark suite of datasets, baselines and novel evaluation metrics based on\nMaximum Mean Discrepancy, which measure distances between sets of graphs. Our\nexperiments show that GraphRNN significantly outperforms all baselines,\nlearning to generate diverse graphs that match the structural characteristics\nof a target set, while also scaling to graphs 50 times larger than previous\ndeep models.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 00:39:09 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 22:06:39 GMT"}, {"version": "v3", "created": "Sat, 23 Jun 2018 15:22:19 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["You", "Jiaxuan", ""], ["Ying", "Rex", ""], ["Ren", "Xiang", ""], ["Hamilton", "William L.", ""], ["Leskovec", "Jure", ""]]}, {"id": "1802.08780", "submitter": "Chaitanya Manapragada", "authors": "Chaitanya Manapragada, Geoff Webb, Mahsa Salehi", "title": "Extremely Fast Decision Tree", "comments": "Submitted to KDD'2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel incremental decision tree learning algorithm, Hoeffding\nAnytime Tree, that is statistically more efficient than the current\nstate-of-the-art, Hoeffding Tree. We demonstrate that an implementation of\nHoeffding Anytime Tree---\"Extremely Fast Decision Tree\", a minor modification\nto the MOA implementation of Hoeffding Tree---obtains significantly superior\nprequential accuracy on most of the largest classification datasets from the\nUCI repository. Hoeffding Anytime Tree produces the asymptotic batch tree in\nthe limit, is naturally resilient to concept drift, and can be used as a higher\naccuracy replacement for Hoeffding Tree in most scenarios, at a small\nadditional computational cost.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 01:44:47 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Manapragada", "Chaitanya", ""], ["Webb", "Geoff", ""], ["Salehi", "Mahsa", ""]]}, {"id": "1802.08786", "submitter": "Hanjun Dai", "authors": "Hanjun Dai, Yingtao Tian, Bo Dai, Steven Skiena, Le Song", "title": "Syntax-Directed Variational Autoencoder for Structured Data", "comments": "to appear in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have been enjoying success in modeling continuous\ndata. However it remains challenging to capture the representations for\ndiscrete structures with formal grammars and semantics, e.g., computer programs\nand molecular structures. How to generate both syntactically and semantically\ncorrect data still remains largely an open problem. Inspired by the theory of\ncompiler where the syntax and semantics check is done via syntax-directed\ntranslation (SDT), we propose a novel syntax-directed variational autoencoder\n(SD-VAE) by introducing stochastic lazy attributes. This approach converts the\noffline SDT check into on-the-fly generated guidance for constraining the\ndecoder. Comparing to the state-of-the-art methods, our approach enforces\nconstraints on the output space so that the output will be not only\nsyntactically valid, but also semantically reasonable. We evaluate the proposed\nmodel with applications in programming language and molecules, including\nreconstruction and program/molecule optimization. The results demonstrate the\neffectiveness in incorporating syntactic and semantic constraints in discrete\ngenerative models, which is significantly better than current state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 02:34:40 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Dai", "Hanjun", ""], ["Tian", "Yingtao", ""], ["Dai", "Bo", ""], ["Skiena", "Steven", ""], ["Song", "Le", ""]]}, {"id": "1802.08800", "submitter": "Florin Rusu", "authors": "Yujing Ma, Florin Rusu, Martin Torres", "title": "Stochastic Gradient Descent on Highly-Parallel Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increased interest in building data analytics frameworks with\nadvanced algebraic capabilities both in industry and academia. Many of these\nframeworks, e.g., TensorFlow and BIDMach, implement their compute-intensive\nprimitives in two flavors---as multi-thread routines for multi-core CPUs and as\nhighly-parallel kernels executed on GPU. Stochastic gradient descent (SGD) is\nthe most popular optimization method for model training implemented extensively\non modern data analytics platforms. While the data-intensive properties of SGD\nare well-known, there is an intense debate on which of the many SGD variants is\nbetter in practice. In this paper, we perform a comprehensive study of parallel\nSGD for training generalized linear models. We consider the impact of three\nfactors -- computing architecture (multi-core CPU or GPU), synchronous or\nasynchronous model updates, and data sparsity -- on three measures---hardware\nefficiency, statistical efficiency, and time to convergence. In the process, we\ndesign an optimized asynchronous SGD algorithm for GPU that leverages warp\nshuffling and cache coalescing for data and model access. We draw several\ninteresting findings from our extensive experiments with logistic regression\n(LR) and support vector machines (SVM) on five real datasets. For synchronous\nSGD, GPU always outperforms parallel CPU---they both outperform a sequential\nCPU solution by more than 400X. For asynchronous SGD, parallel CPU is the\nsafest choice while GPU with data replication is better in certain situations.\nThe choice between synchronous GPU and asynchronous CPU depends on the task and\nthe characteristics of the data. As a reference, our best implementation\noutperforms TensorFlow and BIDMach consistently. We hope that our insights\nprovide a useful guide for applying parallel SGD to generalized linear models.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 05:27:04 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Ma", "Yujing", ""], ["Rusu", "Florin", ""], ["Torres", "Martin", ""]]}, {"id": "1802.08831", "submitter": "Mai Zhu", "authors": "Mai Zhu, Bo Chang, Chong Fu", "title": "Convolutional Neural Networks combined with Runge-Kutta Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A convolutional neural network for image classification can be constructed\nmathematically since it can be regarded as a multi-period dynamical system. In\nthis paper, a novel approach is proposed to construct network models from the\ndynamical systems view. Since a pre-activation residual network can be deemed\nan approximation of a time-dependent dynamical system using the forward Euler\nmethod, higher order Runge-Kutta methods (RK methods) can be utilized to build\nnetwork models in order to achieve higher accuracy. The model constructed in\nsuch a way is referred to as the Runge-Kutta Convolutional Neural Network\n(RKNet). RK methods also provide an interpretation of Dense Convolutional\nNetworks (DenseNets) and Convolutional Neural Networks with Alternately Updated\nClique (CliqueNets) from the dynamical systems view. The proposed methods are\nevaluated on benchmark datasets: CIFAR-10/100, SVHN and ImageNet. The\nexperimental results are consistent with the theoretical properties of RK\nmethods and support the dynamical systems interpretation. Moreover, the\nexperimental results show that the RKNets are superior to the state-of-the-art\nnetwork models on CIFAR-10 and on par on CIFAR-100, SVHN and ImageNet.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 10:31:24 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2018 03:58:18 GMT"}, {"version": "v3", "created": "Tue, 10 Apr 2018 13:36:03 GMT"}, {"version": "v4", "created": "Sat, 14 Apr 2018 08:22:15 GMT"}, {"version": "v5", "created": "Sat, 19 May 2018 02:17:21 GMT"}, {"version": "v6", "created": "Thu, 17 Jan 2019 08:59:44 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Zhu", "Mai", ""], ["Chang", "Bo", ""], ["Fu", "Chong", ""]]}, {"id": "1802.08855", "submitter": "Shashank Singh", "authors": "Shashank Singh, Barnab\\'as P\\'oczos", "title": "Minimax Distribution Estimation in Wasserstein Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wasserstein metric is an important measure of distance between\nprobability distributions, with applications in machine learning, statistics,\nprobability theory, and data analysis. This paper provides upper and lower\nbounds on statistical minimax rates for the problem of estimating a probability\ndistribution under Wasserstein loss, using only metric properties, such as\ncovering and packing numbers, of the sample space, and weak moment assumptions\non the probability distributions.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 14:42:43 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 03:43:27 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2019 02:24:49 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Singh", "Shashank", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "1802.08872", "submitter": "Hamid Hamraz", "authors": "Hamid Hamraz, Nathan B. Jacobs, Marco A. Contreras, and Chase H. Clark", "title": "Deep learning for conifer/deciduous classification of airborne LiDAR 3D\n  point clouds representing individual trees", "comments": "Under review as of the date of submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study was to investigate the use of deep learning for\nconiferous/deciduous classification of individual trees from airborne LiDAR\ndata. To enable efficient processing by a deep convolutional neural network\n(CNN), we designed two discrete representations using leaf-off and leaf-on\nLiDAR data: a digital surface model with four channels (DSMx4) and a set of\nfour 2D views (4x2D). A training dataset of labeled tree crowns was generated\nvia segmentation of tree crowns, followed by co-registration with field data.\nPotential mislabels due to GPS error or tree leaning were corrected using a\nstatistical ensemble filtering procedure. Because the training data was heavily\nunbalanced (~8% conifers), we trained an ensemble of CNNs on random balanced\nsub-samples of augmented data (180 rotational variations per instance). The\n4x2D representation yielded similar classification accuracies to the DSMx4\nrepresentation (~82% coniferous and ~90% deciduous) while converging faster.\nThe data augmentation improved the classification accuracies, but more real\ntraining instances (especially coniferous) likely results in much stronger\nimprovements. Leaf-off LiDAR data were the primary source of useful\ninformation, which is likely due to the perennial nature of coniferous foliage.\nLiDAR intensity values also proved to be useful, but normalization yielded no\nsignificant improvements. Lastly, the classification accuracies of overstory\ntrees (~90%) were more balanced than those of understory trees (~90% deciduous\nand ~65% coniferous), which is likely due to the incomplete capture of\nunderstory tree crowns via airborne LiDAR. Automatic derivation of optimal\nfeatures via deep learning provide the opportunity for remarkable improvements\nin prediction tasks where captured data are not friendly to human visual system\n- likely yielding sub-optimal human-designed features.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 16:10:39 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Hamraz", "Hamid", ""], ["Jacobs", "Nathan B.", ""], ["Contreras", "Marco A.", ""], ["Clark", "Chase H.", ""]]}, {"id": "1802.08880", "submitter": "Rui Zhu", "authors": "Rui Zhu, Di Niu, Zongpeng Li", "title": "Asynchronous Stochastic Proximal Methods for Nonconvex Nonsmooth\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic algorithms for solving nonconvex optimization problems\nwith a convex yet possibly nonsmooth regularizer, which find wide applications\nin many practical machine learning applications. However, compared to\nasynchronous parallel stochastic gradient descent (AsynSGD), an algorithm\ntargeting smooth optimization, the understanding of the behavior of stochastic\nalgorithms for nonsmooth regularized optimization problems is limited,\nespecially when the objective function is nonconvex. To fill this theoretical\ngap, in this paper, we propose and analyze asynchronous parallel stochastic\nproximal gradient (Asyn-ProxSGD) methods for nonconvex problems. We establish\nan ergodic convergence rate of $O(1/\\sqrt{K})$ for the proposed Asyn-ProxSGD,\nwhere $K$ is the number of updates made on the model, matching the convergence\nrate currently known for AsynSGD (for smooth problems). To our knowledge, this\nis the first work that provides convergence rates of asynchronous parallel\nProxSGD algorithms for nonconvex problems. Furthermore, our results are also\nthe first to show the convergence of any stochastic proximal methods without\nassuming an increasing batch size or the use of additional variance reduction\ntechniques. We implement the proposed algorithms on Parameter Server and\ndemonstrate its convergence behavior and near-linear speedup, as the number of\nworkers increases, on two real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 17:09:27 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 16:07:35 GMT"}, {"version": "v3", "created": "Sat, 15 Sep 2018 02:51:50 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Zhu", "Rui", ""], ["Niu", "Di", ""], ["Li", "Zongpeng", ""]]}, {"id": "1802.08882", "submitter": "Rui Zhu", "authors": "Rui Zhu, Di Niu, Zongpeng Li", "title": "A Block-wise, Asynchronous and Distributed ADMM Algorithm for General\n  Form Consensus Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning models, including those with non-smooth regularizers,\ncan be formulated as consensus optimization problems, which can be solved by\nthe alternating direction method of multipliers (ADMM). Many recent efforts\nhave been made to develop asynchronous distributed ADMM to handle large amounts\nof training data. However, all existing asynchronous distributed ADMM methods\nare based on full model updates and require locking all global model parameters\nto handle concurrency, which essentially serializes the updates from different\nworkers. In this paper, we present a novel block-wise, asynchronous and\ndistributed ADMM algorithm, which allows different blocks of model parameters\nto be updated in parallel. The lock-free block-wise algorithm may greatly\nspeedup sparse optimization problems, a common scenario in reality, in which\nmost model updates only modify a subset of all decision variables. We\ntheoretically prove the convergence of our proposed algorithm to stationary\npoints for non-convex general form consensus problems with possibly non-smooth\nregularizers. We implement the proposed ADMM algorithm on the Parameter Server\nframework and demonstrate its convergence and near-linear speedup performance\nas the number of workers increases.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 17:31:38 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Zhu", "Rui", ""], ["Niu", "Di", ""], ["Li", "Zongpeng", ""]]}, {"id": "1802.08887", "submitter": "Yuqing Kong", "authors": "Yuqing Kong and Grant Schoenebeck", "title": "Water from Two Rocks: Maximizing the Mutual Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a natural connection between the learning problem, co-training, and\nforecast elicitation without verification (related to peer-prediction) and\naddress them simultaneously using the same information theoretic approach.\n  In co-training/multiview learning, the goal is to aggregate two views of data\ninto a prediction for a latent label. We show how to optimally combine two\nviews of data by reducing the problem to an optimization problem. Our work\ngives a unified and rigorous approach to the general setting.\n  In forecast elicitation without verification we seek to design a mechanism\nthat elicits high quality forecasts from agents in the setting where the\nmechanism does not have access to the ground truth. By assuming the agents'\ninformation is independent conditioning on the outcome, we propose mechanisms\nwhere truth-telling is a strict equilibrium for both the single-task and\nmulti-task settings. Our multi-task mechanism additionally has the property\nthat the truth-telling equilibrium pays better than any other strategy profile\nand strictly better than any other \"non-permutation\" strategy profile when the\nprior satisfies some mild conditions.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 18:27:14 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 03:21:33 GMT"}, {"version": "v3", "created": "Tue, 22 May 2018 21:46:50 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Kong", "Yuqing", ""], ["Schoenebeck", "Grant", ""]]}, {"id": "1802.08888", "submitter": "Sami Abu-El-Haija", "authors": "Sami Abu-El-Haija, Amol Kapoor, Bryan Perozzi, Joonseok Lee", "title": "N-GCN: Multi-scale Graph Convolution for Semi-supervised Node\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have shown significant improvements in\nsemi-supervised learning on graph-structured data. Concurrently, unsupervised\nlearning of graph embeddings has benefited from the information contained in\nrandom walks. In this paper, we propose a model: Network of GCNs (N-GCN), which\nmarries these two lines of work. At its core, N-GCN trains multiple instances\nof GCNs over node pairs discovered at different distances in random walks, and\nlearns a combination of the instance outputs which optimizes the classification\nobjective. Our experiments show that our proposed N-GCN model improves\nstate-of-the-art baselines on all of the challenging node classification tasks\nwe consider: Cora, Citeseer, Pubmed, and PPI. In addition, our proposed method\nhas other desirable properties, including generalization to recently proposed\nsemi-supervised learning methods such as GraphSAGE, allowing us to propose\nN-SAGE, and resilience to adversarial input perturbations.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 18:30:30 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Abu-El-Haija", "Sami", ""], ["Kapoor", "Amol", ""], ["Perozzi", "Bryan", ""], ["Lee", "Joonseok", ""]]}, {"id": "1802.08898", "submitter": "Oren Mangoubi", "authors": "Oren Mangoubi and Nisheeth K. Vishnoi", "title": "Dimensionally Tight Bounds for Second-Order Hamiltonian Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo (HMC) is a widely deployed method to sample from\nhigh-dimensional distributions in Statistics and Machine learning. HMC is known\nto run very efficiently in practice and its popular second-order \"leapfrog\"\nimplementation has long been conjectured to run in $d^{1/4}$ gradient\nevaluations. Here we show that this conjecture is true when sampling from\nstrongly log-concave target distributions that satisfy a weak third-order\nregularity property associated with the input data. Our regularity condition is\nweaker than the Lipschitz Hessian property and allows us to show faster\nconvergence bounds for a much larger class of distributions than would be\npossible with the usual Lipschitz Hessian constant alone. Important\ndistributions that satisfy our regularity condition include posterior\ndistributions used in Bayesian logistic regression for which the data satisfies\nan \"incoherence\" property. Our result compares favorably with the best\navailable bounds for the class of strongly log-concave distributions, which\ngrow like $d^{{1}/{2}}$ gradient evaluations with the dimension. Moreover, our\nsimulations on synthetic data suggest that, when our regularity condition is\nsatisfied, leapfrog HMC performs better than its competitors -- both in terms\nof accuracy and in terms of the number of gradient evaluations it requires.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 19:23:21 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 00:27:58 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2018 16:26:27 GMT"}, {"version": "v4", "created": "Thu, 2 Aug 2018 15:31:10 GMT"}, {"version": "v5", "created": "Thu, 9 Aug 2018 18:24:09 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Mangoubi", "Oren", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1802.08903", "submitter": "Jacob Gardner", "authors": "Jacob R. Gardner, Geoff Pleiss, Ruihan Wu, Kilian Q. Weinberger,\n  Andrew Gordon Wilson", "title": "Product Kernel Interpolation for Scalable Gaussian Processes", "comments": "Appears in Artificial Intelligence and Statistics (AISTATS) 21, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work shows that inference for Gaussian processes can be performed\nefficiently using iterative methods that rely only on matrix-vector\nmultiplications (MVMs). Structured Kernel Interpolation (SKI) exploits these\ntechniques by deriving approximate kernels with very fast MVMs. Unfortunately,\nsuch strategies suffer badly from the curse of dimensionality. We develop a new\ntechnique for MVM based learning that exploits product kernel structure. We\ndemonstrate that this technique is broadly applicable, resulting in linear\nrather than exponential runtime with dimension for SKI, as well as\nstate-of-the-art asymptotic complexity for multi-task GPs.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 19:45:38 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Gardner", "Jacob R.", ""], ["Pleiss", "Geoff", ""], ["Wu", "Ruihan", ""], ["Weinberger", "Kilian Q.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1802.08908", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot, Shuang Song, Ilya Mironov, Ananth Raghunathan, Kunal\n  Talwar, \\'Ulfar Erlingsson", "title": "Scalable Private Learning with PATE", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid adoption of machine learning has increased concerns about the\nprivacy implications of machine learning models trained on sensitive data, such\nas medical records or other personal information. To address those concerns,\none promising approach is Private Aggregation of Teacher Ensembles, or PATE,\nwhich transfers to a \"student\" model the knowledge of an ensemble of \"teacher\"\nmodels, with intuitive privacy provided by training teachers on disjoint data\nand strong privacy guaranteed by noisy aggregation of teachers' answers.\nHowever, PATE has so far been evaluated only on simple classification tasks\nlike MNIST, leaving unclear its utility when applied to larger-scale learning\ntasks and real-world datasets.\n  In this work, we show how PATE can scale to learning tasks with large numbers\nof output classes and uncurated, imbalanced training data with errors. For\nthis, we introduce new noisy aggregation mechanisms for teacher ensembles that\nare more selective and add less noise, and prove their tighter\ndifferential-privacy guarantees. Our new mechanisms build on two insights: the\nchance of teacher consensus is increased by using more concentrated noise and,\nlacking consensus, no answer need be given to a student. The consensus answers\nused are more likely to be correct, offer better intuitive privacy, and incur\nlower-differential privacy cost. Our evaluation shows our mechanisms improve on\nthe original PATE on all measures, and scale to larger tasks with both high\nutility and very strong privacy ($\\varepsilon$ < 1.0).\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 20:39:51 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Papernot", "Nicolas", ""], ["Song", "Shuang", ""], ["Mironov", "Ilya", ""], ["Raghunathan", "Ananth", ""], ["Talwar", "Kunal", ""], ["Erlingsson", "\u00dalfar", ""]]}, {"id": "1802.08924", "submitter": "Marcell Vazquez-Chanlatte", "authors": "Marcell Vazquez-Chanlatte, Shromona Ghosh, Jyotirmoy V. Deshmukh,\n  Alberto Sangiovanni-Vincentelli, Sanjit A. Seshia", "title": "Time Series Learning using Monotonic Logical Properties", "comments": "Submitted to RV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems of today are generating large volumes of time-series\ndata. As manual inspection of such data is not tractable, the need for learning\nmethods to help discover logical structure in the data has increased. We\npropose a logic-based framework that allows domain-specific knowledge to be\nembedded into formulas in a parametric logical specification over time-series\ndata. The key idea is to then map a time series to a surface in the parameter\nspace of the formula. Given this mapping, we identify the Hausdorff distance\nbetween boundaries as a natural distance metric between two time-series data\nunder the lens of the parametric specification. This enables embedding\nnon-trivial domain-specific knowledge into the distance metric and then using\noff-the-shelf machine learning tools to label the data. After labeling the\ndata, we demonstrate how to extract a logical specification for each label.\nFinally, we showcase our technique on real world traffic data to learn\nclassifiers/monitors for slow-downs and traffic jams.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 22:49:29 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 20:22:55 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Vazquez-Chanlatte", "Marcell", ""], ["Ghosh", "Shromona", ""], ["Deshmukh", "Jyotirmoy V.", ""], ["Sangiovanni-Vincentelli", "Alberto", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1802.08938", "submitter": "Tianxiang Gao", "authors": "Tianxiang Gao, Chris Chu", "title": "DID: Distributed Incremental Block Coordinate Descent for Nonnegative\n  Matrix Factorization", "comments": "Accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has attracted much attention in the\nlast decade as a dimension reduction method in many applications. Due to the\nexplosion in the size of data, naturally the samples are collected and stored\ndistributively in local computational nodes. Thus, there is a growing need to\ndevelop algorithms in a distributed memory architecture. We propose a novel\ndistributed algorithm, called \\textit{distributed incremental block coordinate\ndescent} (DID), to solve the problem. By adapting the block coordinate descent\nframework, closed-form update rules are obtained in DID. Moreover, DID performs\nupdates incrementally based on the most recently updated residual matrix. As a\nresult, only one communication step per iteration is required. The correctness,\nefficiency, and scalability of the proposed algorithm are verified in a series\nof numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 01:23:23 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Gao", "Tianxiang", ""], ["Chu", "Chris", ""]]}, {"id": "1802.08946", "submitter": "Yuzhe Ma", "authors": "Yuzhe Ma, Robert Nowak, Philippe Rigollet, Xuezhou Zhang, Xiaojin Zhu", "title": "Teacher Improves Learning by Selecting a Training Subset", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We call a learner super-teachable if a teacher can trim down an iid training\nset while making the learner learn even better. We provide sharp super-teaching\nguarantees on two learners: the maximum likelihood estimator for the mean of a\nGaussian, and the large margin classifier in 1D. For general learners, we\nprovide a mixed-integer nonlinear programming-based algorithm to find a super\nteaching set. Empirical experiments show that our algorithm is able to find\ngood super-teaching sets for both regression and classification problems.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 02:47:46 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Ma", "Yuzhe", ""], ["Nowak", "Robert", ""], ["Rigollet", "Philippe", ""], ["Zhang", "Xuezhou", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1802.08976", "submitter": "Yingfei Wang", "authors": "Yingfei Wang, Juliana Martins Do Nascimento, Warren Powell", "title": "Reinforcement Learning for Dynamic Bidding in Truckload Markets: an\n  Application to Large-Scale Fleet Management with Advance Commitments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truckload brokerages, a $100 billion/year industry in the U.S., plays the\ncritical role of matching shippers with carriers, often to move loads several\ndays into the future. Brokerages not only have to find companies that will\nagree to move a load, the brokerage often has to find a price that both the\nshipper and carrier will agree to. The price not only varies by shipper and\ncarrier, but also by the traffic lanes and other variables such as commodity\ntype. Brokerages have to learn about shipper and carrier response functions by\noffering a price and observing whether each accepts the quote. We propose a\nknowledge gradient policy with bootstrap aggregation for high-dimensional\ncontextual settings to guide price experimentation by maximizing the value of\ninformation. The learning policy is tested using a carefully calibrated fleet\nsimulator that includes a stochastic lookahead policy that simulates fleet\nmovements, as well as the stochastic modeling of driver assignments and the\ncarrier's load commitment policies with advance booking.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 09:48:59 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 05:51:25 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Wang", "Yingfei", ""], ["Nascimento", "Juliana Martins Do", ""], ["Powell", "Warren", ""]]}, {"id": "1802.09025", "submitter": "Xinyi Chen", "authors": "Scott Aaronson (UT Austin), Xinyi Chen (Princeton University and\n  Google AI Princeton), Elad Hazan (Princeton University and Google AI\n  Princeton), Satyen Kale (Google AI), and Ashwin Nayak (University of\n  Waterloo)", "title": "Online Learning of Quantum States", "comments": "18 pages", "journal-ref": null, "doi": "10.1088/1742-5468/ab3988", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we have many copies of an unknown $n$-qubit state $\\rho$. We measure\nsome copies of $\\rho$ using a known two-outcome measurement $E_{1}$, then other\ncopies using a measurement $E_{2}$, and so on. At each stage $t$, we generate a\ncurrent hypothesis $\\sigma_{t}$ about the state $\\rho$, using the outcomes of\nthe previous measurements. We show that it is possible to do this in a way that\nguarantees that $|\\operatorname{Tr}(E_{i} \\sigma_{t}) -\n\\operatorname{Tr}(E_{i}\\rho) |$, the error in our prediction for the next\nmeasurement, is at least $\\varepsilon$ at most $\\operatorname{O}\\!\\left(n /\n\\varepsilon^2 \\right) $ times. Even in the \"non-realizable\" setting---where\nthere could be arbitrary noise in the measurement outcomes---we show how to\noutput hypothesis states that do significantly worse than the best possible\nstates at most $\\operatorname{O}\\!\\left(\\sqrt {Tn}\\right) $ times on the first\n$T$ measurements. These results generalize a 2007 theorem by Aaronson on the\nPAC-learnability of quantum states, to the online and regret-minimization\nsettings. We give three different ways to prove our results---using convex\noptimization, quantum postselection, and sequential fat-shattering\ndimension---which have different advantages in terms of parameters and\nportability.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 16:01:45 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 19:50:30 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 21:34:40 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Aaronson", "Scott", "", "UT Austin"], ["Chen", "Xinyi", "", "Princeton University and\n  Google AI Princeton"], ["Hazan", "Elad", "", "Princeton University and Google AI\n  Princeton"], ["Kale", "Satyen", "", "Google AI"], ["Nayak", "Ashwin", "", "University of\n  Waterloo"]]}, {"id": "1802.09030", "submitter": "Uri Patish", "authors": "Uri Patish, Shimon Ullman", "title": "Cakewalk Sampling", "comments": "Accepted as a conference paper by AAAI-2020 (oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of finding good local optima in combinatorial optimization\nproblems. Although combinatorial optimization is NP-hard in general, locally\noptimal solutions are frequently used in practice. Local search methods however\ntypically converge to a limited set of optima that depend on their\ninitialization. Sampling methods on the other hand can access any valid\nsolution, and thus can be used either directly or alongside methods of the\nformer type as a way for finding good local optima. Since the effectiveness of\nthis strategy depends on the sampling distribution, we derive a robust learning\nalgorithm that adapts sampling distributions towards good local optima of\narbitrary objective functions. As a first use case, we empirically study the\nefficiency in which sampling methods can recover locally maximal cliques in\nundirected graphs. Not only do we show how our adaptive sampler outperforms\nrelated methods, we also show how it can even approach the performance of\nestablished clique algorithms. As a second use case, we consider how greedy\nalgorithms can be combined with our adaptive sampler, and we demonstrate how\nthis leads to superior performance in k-medoid clustering. Together, these\nfindings suggest that our adaptive sampler can provide an effective strategy to\ncombinatorial optimization problems that arise in practice.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 16:15:32 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 11:07:41 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Patish", "Uri", ""], ["Ullman", "Shimon", ""]]}, {"id": "1802.09031", "submitter": "Atsushi Nitanda", "authors": "Atsushi Nitanda, Taiji Suzuki", "title": "Functional Gradient Boosting based on Residual Network Perception", "comments": "22 pages, 1 figure, 1 table. An extended version of ICML 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual Networks (ResNets) have become state-of-the-art models in deep\nlearning and several theoretical studies have been devoted to understanding why\nResNet works so well. One attractive viewpoint on ResNet is that it is\noptimizing the risk in a functional space by combining an ensemble of effective\nfeatures. In this paper, we adopt this viewpoint to construct a new gradient\nboosting method, which is known to be very powerful in data analysis. To do so,\nwe formalize the gradient boosting perspective of ResNet mathematically using\nthe notion of functional gradients and propose a new method called ResFGB for\nclassification tasks by leveraging ResNet perception. Two types of\ngeneralization guarantees are provided from the optimization perspective: one\nis the margin bound and the other is the expected risk bound by the\nsample-splitting technique. Experimental results show superior performance of\nthe proposed method over state-of-the-art methods such as LightGBM.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 16:15:57 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 02:23:08 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Nitanda", "Atsushi", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1802.09047", "submitter": "Anand Kumar Mukhopadhyay", "authors": "Anand Kumar Mukhopadhyay, Indrajit Chakrabarti, Arindam Basu, Mrigank\n  Sharad", "title": "Power efficient Spiking Neural Network Classifier based on memristive\n  crossbar network for spike sorting application", "comments": "10 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper authors have presented a power efficient scheme for\nimplementing a spike sorting module. Spike sorting is an important application\nin the field of neural signal acquisition for implantable biomedical systems\nwhose function is to map the Neural-spikes (N-spikes) correctly to the neurons\nfrom which it originates. The accurate classification is a pre-requisite for\nthe succeeding systems needed in Brain-Machine-Interfaces (BMIs) to give better\nperformance. The primary design constraint to be satisfied for the spike sorter\nmodule is low power with good accuracy. There lies a trade-off in terms of\npower consumption between the on-chip and off-chip training of the N-spike\nfeatures. In the former case care has to be taken to make the computational\nunits power efficient whereas in the later the data rate of wireless\ntransmission should be minimized to reduce the power consumption due to the\ntransceivers. In this work a 2-step shared training scheme involving a K-means\nsorter and a Spiking Neural Network (SNN) is elaborated for on-chip training\nand classification. Also, a low power SNN classifier scheme using memristive\ncrossbar type architecture is compared with a fully digital implementation. The\nadvantage of the former classifier is that it is power efficient while\nproviding comparable accuracy as that of the digital implementation due to the\nrobustness of the SNN training algorithm which has a good tolerance for\nvariation in memristance.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 17:34:43 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Mukhopadhyay", "Anand Kumar", ""], ["Chakrabarti", "Indrajit", ""], ["Basu", "Arindam", ""], ["Sharad", "Mrigank", ""]]}, {"id": "1802.09052", "submitter": "Vaneet Aggarwal", "authors": "Wenqi Wang and Yifan Sun and Brian Eriksson and Wenlin Wang and Vaneet\n  Aggarwal", "title": "Wide Compression: Tensor Ring Nets", "comments": "Accepted to CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have demonstrated state-of-the-art performance in a\nvariety of real-world applications. In order to obtain performance gains, these\nnetworks have grown larger and deeper, containing millions or even billions of\nparameters and over a thousand layers. The trade-off is that these large\narchitectures require an enormous amount of memory, storage, and computation,\nthus limiting their usability. Inspired by the recent tensor ring\nfactorization, we introduce Tensor Ring Networks (TR-Nets), which significantly\ncompress both the fully connected layers and the convolutional layers of deep\nneural networks. Our results show that our TR-Nets approach {is able to\ncompress LeNet-5 by $11\\times$ without losing accuracy}, and can compress the\nstate-of-the-art Wide ResNet by $243\\times$ with only 2.3\\% degradation in\n{Cifar10 image classification}. Overall, this compression scheme shows promise\nin scientific computing and deep learning, especially for emerging\nresource-constrained devices such as smartphones, wearables, and IoT devices.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 18:09:04 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Wang", "Wenqi", ""], ["Sun", "Yifan", ""], ["Eriksson", "Brian", ""], ["Wang", "Wenlin", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1802.09059", "submitter": "Ahmad Pesaranghader", "authors": "Ahmad Pesaranghader, Ali Pesaranghader, Stan Matwin, Marina Sokolova", "title": "One Single Deep Bidirectional LSTM Network for Word Sense Disambiguation\n  of Text Data", "comments": "12 pages, 1 figure, to appear in the Proceedings of the 31st Canadian\n  Conference on Artificial Intelligence, 8-11 May, 2018, Toronto, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to recent technical and scientific advances, we have a wealth of\ninformation hidden in unstructured text data such as offline/online narratives,\nresearch articles, and clinical reports. To mine these data properly,\nattributable to their innate ambiguity, a Word Sense Disambiguation (WSD)\nalgorithm can avoid numbers of difficulties in Natural Language Processing\n(NLP) pipeline. However, considering a large number of ambiguous words in one\nlanguage or technical domain, we may encounter limiting constraints for proper\ndeployment of existing WSD models. This paper attempts to address the problem\nof one-classifier-per-one-word WSD algorithms by proposing a single\nBidirectional Long Short-Term Memory (BLSTM) network which by considering\nsenses and context sequences works on all ambiguous words collectively.\nEvaluated on SensEval-3 benchmark, we show the result of our model is\ncomparable with top-performing WSD algorithms. We also discuss how applying\nadditional modifications alleviates the model fault and the need for more\ntraining data.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 18:51:53 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Pesaranghader", "Ahmad", ""], ["Pesaranghader", "Ali", ""], ["Matwin", "Stan", ""], ["Sokolova", "Marina", ""]]}, {"id": "1802.09064", "submitter": "Dennis Shen", "authors": "Anish Agarwal, Muhammad Jehangir Amjad, Devavrat Shah and Dennis Shen", "title": "Model Agnostic Time Series Analysis via Matrix Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm to impute and forecast a time series by transforming\nthe observed time series into a matrix, utilizing matrix estimation to recover\nmissing values and de-noise observed entries, and performing linear regression\nto make predictions. At the core of our analysis is a representation result,\nwhich states that for a large model class, the transformed time series matrix\nis (approximately) low-rank. In effect, this generalizes the widely used\nSingular Spectrum Analysis (SSA) in time series literature, and allows us to\nestablish a rigorous link between time series analysis and matrix estimation.\nThe key to establishing this link is constructing a Page matrix with\nnon-overlapping entries rather than a Hankel matrix as is commonly done in the\nliterature (e.g., SSA). This particular matrix structure allows us to provide\nfinite sample analysis for imputation and prediction, and prove the asymptotic\nconsistency of our method. Another salient feature of our algorithm is that it\nis model agnostic with respect to both the underlying time dynamics and the\nnoise distribution in the observations. The noise agnostic property of our\napproach allows us to recover the latent states when only given access to noisy\nand partial observations a la a Hidden Markov Model; e.g., recovering the\ntime-varying parameter of a Poisson process without knowing that the underlying\nprocess is Poisson. Furthermore, since our forecasting algorithm requires\nregression with noisy features, our approach suggests a matrix estimation based\nmethod - coupled with a novel, non-standard matrix estimation error metric - to\nsolve the error-in-variable regression problem, which could be of interest in\nits own right. Through synthetic and real-world datasets, we demonstrate that\nour algorithm outperforms standard software packages (including R libraries) in\nthe presence of missing data as well as high levels of noise.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 19:06:06 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 02:50:28 GMT"}, {"version": "v3", "created": "Fri, 24 Aug 2018 17:45:32 GMT"}, {"version": "v4", "created": "Fri, 9 Nov 2018 21:17:18 GMT"}, {"version": "v5", "created": "Sun, 18 Nov 2018 20:23:03 GMT"}, {"version": "v6", "created": "Fri, 26 Apr 2019 17:03:36 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Agarwal", "Anish", ""], ["Amjad", "Muhammad Jehangir", ""], ["Shah", "Devavrat", ""], ["Shen", "Dennis", ""]]}, {"id": "1802.09069", "submitter": "Songbai Yan", "authors": "Songbai Yan, Kamalika Chaudhuri, Tara Javidi", "title": "Active Learning with Logged Data", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider active learning with logged data, where labeled examples are\ndrawn conditioned on a predetermined logging policy, and the goal is to learn a\nclassifier on the entire population, not just conditioned on the logging\npolicy. Prior work addresses this problem either when only logged data is\navailable, or purely in a controlled random experimentation setting where the\nlogged data is ignored. In this work, we combine both approaches to provide an\nalgorithm that uses logged data to bootstrap and inform experimentation, thus\nachieving the best of both worlds. Our work is inspired by a connection between\ncontrolled random experimentation and active learning, and modifies existing\ndisagreement-based active learning algorithms to exploit logged data.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 19:37:58 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 04:14:13 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 17:06:59 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Yan", "Songbai", ""], ["Chaudhuri", "Kamalika", ""], ["Javidi", "Tara", ""]]}, {"id": "1802.09081", "submitter": "Vitchyr H. Pong", "authors": "Vitchyr Pong, Shixiang Gu, Murtaza Dalal, Sergey Levine", "title": "Temporal Difference Models: Model-Free Deep RL for Model-Based Control", "comments": "Appeared in ICLR 2018; typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL) is a powerful, general tool for\nlearning complex behaviors. However, its sample efficiency is often\nimpractically large for solving challenging real-world problems, even with\noff-policy algorithms such as Q-learning. A limiting factor in classic\nmodel-free RL is that the learning signal consists only of scalar rewards,\nignoring much of the rich information contained in state transition tuples.\nModel-based RL uses this information, by training a predictive model, but often\ndoes not achieve the same asymptotic performance as model-free RL due to model\nbias. We introduce temporal difference models (TDMs), a family of\ngoal-conditioned value functions that can be trained with model-free learning\nand used for model-based control. TDMs combine the benefits of model-free and\nmodel-based RL: they leverage the rich information in state transitions to\nlearn very efficiently, while still attaining asymptotic performance that\nexceeds that of direct model-based RL methods. Our experimental results show\nthat, on a range of continuous control tasks, TDMs provide a substantial\nimprovement in efficiency compared to state-of-the-art model-based and\nmodel-free methods.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 21:14:44 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 06:34:11 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Pong", "Vitchyr", ""], ["Gu", "Shixiang", ""], ["Dalal", "Murtaza", ""], ["Levine", "Sergey", ""]]}, {"id": "1802.09089", "submitter": "Yisroel Mirsky Mr.", "authors": "Yisroel Mirsky, Tomer Doitshman, Yuval Elovici, Asaf Shabtai", "title": "Kitsune: An Ensemble of Autoencoders for Online Network Intrusion\n  Detection", "comments": "Appears in Network and Distributed Systems Security Symposium (NDSS)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become an increasingly popular solution for network\nintrusion detection systems (NIDS). Their capability of learning complex\npatterns and behaviors make them a suitable solution for differentiating\nbetween normal traffic and network attacks. However, a drawback of neural\nnetworks is the amount of resources needed to train them. Many network gateways\nand routers devices, which could potentially host an NIDS, simply do not have\nthe memory or processing power to train and sometimes even execute such models.\nMore importantly, the existing neural network solutions are trained in a\nsupervised manner. Meaning that an expert must label the network traffic and\nupdate the model manually from time to time.\n  In this paper, we present Kitsune: a plug and play NIDS which can learn to\ndetect attacks on the local network, without supervision, and in an efficient\nonline manner. Kitsune's core algorithm (KitNET) uses an ensemble of neural\nnetworks called autoencoders to collectively differentiate between normal and\nabnormal traffic patterns. KitNET is supported by a feature extraction\nframework which efficiently tracks the patterns of every network channel. Our\nevaluations show that Kitsune can detect various attacks with a performance\ncomparable to offline anomaly detectors, even on a Raspberry PI. This\ndemonstrates that Kitsune can be a practical and economic NIDS.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 21:42:56 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 09:50:10 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Mirsky", "Yisroel", ""], ["Doitshman", "Tomer", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1802.09098", "submitter": "Aaditya Ramdas", "authors": "Aaditya Ramdas, Tijana Zrnic, Martin Wainwright, Michael Jordan", "title": "SAFFRON: an adaptive algorithm for online control of the false discovery\n  rate", "comments": "19 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online false discovery rate (FDR) problem, one observes a possibly\ninfinite sequence of $p$-values $P_1,P_2,\\dots$, each testing a different null\nhypothesis, and an algorithm must pick a sequence of rejection thresholds\n$\\alpha_1,\\alpha_2,\\dots$ in an online fashion, effectively rejecting the\n$k$-th null hypothesis whenever $P_k \\leq \\alpha_k$. Importantly, $\\alpha_k$\nmust be a function of the past, and cannot depend on $P_k$ or any of the later\nunseen $p$-values, and must be chosen to guarantee that for any time $t$, the\nFDR up to time $t$ is less than some pre-determined quantity $\\alpha \\in\n(0,1)$. In this work, we present a powerful new framework for online FDR\ncontrol that we refer to as SAFFRON. Like older alpha-investing (AI)\nalgorithms, SAFFRON starts off with an error budget, called alpha-wealth, that\nit intelligently allocates to different tests over time, earning back some\nwealth on making a new discovery. However, unlike older methods, SAFFRON's\nthreshold sequence is based on a novel estimate of the alpha fraction that it\nallocates to true null hypotheses. In the offline setting, algorithms that\nemploy an estimate of the proportion of true nulls are called adaptive methods,\nand SAFFRON can be seen as an online analogue of the famous offline Storey-BH\nadaptive procedure. Just as Storey-BH is typically more powerful than the\nBenjamini-Hochberg (BH) procedure under independence, we demonstrate that\nSAFFRON is also more powerful than its non-adaptive counterparts, such as LORD\nand other generalized alpha-investing algorithms. Further, a monotone version\nof the original AI algorithm is recovered as a special case of SAFFRON, that is\noften more stable and powerful than the original. Lastly, the derivation of\nSAFFRON provides a novel template for deriving new online FDR rules.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 22:19:06 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 18:21:55 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Ramdas", "Aaditya", ""], ["Zrnic", "Tijana", ""], ["Wainwright", "Martin", ""], ["Jordan", "Michael", ""]]}, {"id": "1802.09113", "submitter": "Sudhir Kylasa", "authors": "Sudhir B. Kylasa, Farbod Roosta-Khorasani, Michael W. Mahoney and\n  Ananth Grama", "title": "GPU Accelerated Sub-Sampled Newton's Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First order methods, which solely rely on gradient information, are commonly\nused in diverse machine learning (ML) and data analysis (DA) applications. This\nis attributed to the simplicity of their implementations, as well as low\nper-iteration computational/storage costs. However, they suffer from\nsignificant disadvantages; most notably, their performance degrades with\nincreasing problem ill-conditioning. Furthermore, they often involve a large\nnumber of hyper-parameters, and are notoriously sensitive to parameters such as\nthe step-size. By incorporating additional information from the Hessian,\nsecond-order methods, have been shown to be resilient to many such adversarial\neffects. However, these advantages of using curvature information come at the\ncost of higher per-iteration costs, which in \\enquote{big data} regimes, can be\ncomputationally prohibitive.\n  In this paper, we show that, contrary to conventional belief, second-order\nmethods, when implemented appropriately, can be more efficient than first-order\nalternatives in many large-scale ML/ DA applications. In particular, in convex\nsettings, we consider variants of classical Newton\\textsf{'}s method in which\nthe Hessian and/or the gradient are randomly sub-sampled. We show that by\neffectively leveraging the power of GPUs, such randomized Newton-type\nalgorithms can be significantly accelerated, and can easily outperform state of\nthe art implementations of existing techniques in popular ML/ DA software\npackages such as TensorFlow. Additionally these randomized methods incur a\nsmall memory overhead compared to first-order methods. In particular, we show\nthat for million-dimensional problems, our GPU accelerated sub-sampled\nNewton\\textsf{'}s method achieves a higher test accuracy in milliseconds as\ncompared with tens of seconds for first order alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 00:32:31 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2018 01:51:02 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Kylasa", "Sudhir B.", ""], ["Roosta-Khorasani", "Farbod", ""], ["Mahoney", "Michael W.", ""], ["Grama", "Ananth", ""]]}, {"id": "1802.09127", "submitter": "Carlos Riquelme Ruiz", "authors": "Carlos Riquelme, George Tucker, Jasper Snoek", "title": "Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep\n  Networks for Thompson Sampling", "comments": "Sixth International Conference on Learning Representations, ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep reinforcement learning have made significant strides\nin performance on applications such as Go and Atari games. However, developing\npractical methods to balance exploration and exploitation in complex domains\nremains largely unsolved. Thompson Sampling and its extension to reinforcement\nlearning provide an elegant approach to exploration that only requires access\nto posterior samples of the model. At the same time, advances in approximate\nBayesian methods have made posterior approximation for flexible neural network\nmodels practical. Thus, it is attractive to consider approximate Bayesian\nneural networks in a Thompson Sampling framework. To understand the impact of\nusing an approximate posterior on Thompson Sampling, we benchmark\nwell-established and recently developed methods for approximate posterior\nsampling combined with Thompson Sampling over a series of contextual bandit\nproblems. We found that many approaches that have been successful in the\nsupervised learning setting underperformed in the sequential decision-making\nscenario. In particular, we highlight the challenge of adapting slowly\nconverging uncertainty estimates to the online setting.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 02:04:57 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Riquelme", "Carlos", ""], ["Tucker", "George", ""], ["Snoek", "Jasper", ""]]}, {"id": "1802.09128", "submitter": "Nilesh Tripuraneni", "authors": "Nilesh Tripuraneni, Nicolas Flammarion, Francis Bach, Michael I.\n  Jordan", "title": "Averaging Stochastic Gradient Descent on Riemannian Manifolds", "comments": "COLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the minimization of a function defined on a Riemannian manifold\n$\\mathcal{M}$ accessible only through unbiased estimates of its gradients. We\ndevelop a geometric framework to transform a sequence of slowly converging\niterates generated from stochastic gradient descent (SGD) on $\\mathcal{M}$ to\nan averaged iterate sequence with a robust and fast $O(1/n)$ convergence rate.\nWe then present an application of our framework to geodesically-strongly-convex\n(and possibly Euclidean non-convex) problems. Finally, we demonstrate how these\nideas apply to the case of streaming $k$-PCA, where we show how to accelerate\nthe slow rate of the randomized power method (without requiring knowledge of\nthe eigengap) into a robust algorithm achieving the optimal rate of\nconvergence.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 02:05:06 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 14:17:09 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Tripuraneni", "Nilesh", ""], ["Flammarion", "Nicolas", ""], ["Bach", "Francis", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1802.09129", "submitter": "Weifeng Ge", "authors": "Weifeng Ge, Sibei Yang, Yizhou Yu", "title": "Multi-Evidence Filtering and Fusion for Multi-Label Classification,\n  Object Detection and Semantic Segmentation Based on Weakly Supervised\n  Learning", "comments": "accepted by IEEE International Conference on Computer Vision and\n  Pattern Recognition (CVPR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised object detection and semantic segmentation require object or even\npixel level annotations. When there exist image level labels only, it is\nchallenging for weakly supervised algorithms to achieve accurate predictions.\nThe accuracy achieved by top weakly supervised algorithms is still\nsignificantly lower than their fully supervised counterparts. In this paper, we\npropose a novel weakly supervised curriculum learning pipeline for multi-label\nobject recognition, detection and semantic segmentation. In this pipeline, we\nfirst obtain intermediate object localization and pixel labeling results for\nthe training images, and then use such results to train task-specific deep\nnetworks in a fully supervised manner. The entire process consists of four\nstages, including object localization in the training images, filtering and\nfusing object instances, pixel labeling for the training images, and\ntask-specific network training. To obtain clean object instances in the\ntraining images, we propose a novel algorithm for filtering, fusing and\nclassifying object instances collected from multiple solution mechanisms. In\nthis algorithm, we incorporate both metric learning and density-based\nclustering to filter detected object instances. Experiments show that our\nweakly supervised pipeline achieves state-of-the-art results in multi-label\nimage classification as well as weakly supervised object detection and very\ncompetitive results in weakly supervised semantic segmentation on MS-COCO,\nPASCAL VOC 2007 and PASCAL VOC 2012.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 02:07:19 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Ge", "Weifeng", ""], ["Yang", "Sibei", ""], ["Yu", "Yizhou", ""]]}, {"id": "1802.09184", "submitter": "Lin Yang", "authors": "Sham Kakade, Mengdi Wang, Lin F. Yang", "title": "Variance Reduction Methods for Sublinear Reinforcement Learning", "comments": "There is a technical issue in the analysis that is not easily fixable", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a technical issue in the analysis that is not easily fixable. We,\ntherefore, withdraw the submission. Sorry for the inconvenience.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 07:01:24 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 19:53:50 GMT"}, {"version": "v3", "created": "Sat, 25 Aug 2018 05:22:45 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 16:25:37 GMT"}, {"version": "v5", "created": "Sat, 27 Jun 2020 04:14:36 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Kakade", "Sham", ""], ["Wang", "Mengdi", ""], ["Yang", "Lin F.", ""]]}, {"id": "1802.09197", "submitter": "Woo Yong Choi", "authors": "Woo Yong Choi, Kyu Ye Song, Chan Woo Lee", "title": "AI4AI: Quantitative Methods for Classifying Host Species from Avian\n  Influenza DNA Sequence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Avian Influenza breakouts cause millions of dollars in damage each year\nglobally, especially in Asian countries such as China and South Korea. The\nimpact magnitude of a breakout directly correlates to time required to fully\nunderstand the influenza virus, particularly the interspecies pathogenicity.\nThe procedure requires laboratory tests that require resources typically\nlacking in a breakout emergency. In this study, we propose new quantitative\nmethods utilizing machine learning and deep learning to correctly classify host\nspecies given raw DNA sequence data of the influenza virus, and provide\nprobabilities for each classification. The best deep learning models achieve\ntop-1 classification accuracy of 47%, and top-3 classification accuracy of 82%,\non a dataset of 11 host species classes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 08:28:57 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Choi", "Woo Yong", ""], ["Song", "Kyu Ye", ""], ["Lee", "Chan Woo", ""]]}, {"id": "1802.09210", "submitter": "Michael Unser", "authors": "Michael Unser", "title": "A representer theorem for deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to optimize the activation functions of a deep neural network by\nadding a corresponding functional regularization to the cost function. We\njustify the use of a second-order total-variation criterion. This allows us to\nderive a general representer theorem for deep neural networks that makes a\ndirect connection with splines and sparsity. Specifically, we show that the\noptimal network configuration can be achieved with activation functions that\nare nonuniform linear splines with adaptive knots. The bottom line is that the\naction of each neuron is encoded by a spline whose parameters (including the\nnumber of knots) are optimized during the training procedure. The scheme\nresults in a computational structure that is compatible with the existing\ndeep-ReLU, parametric ReLU, APL (adaptive piecewise-linear) and MaxOut\narchitectures. It also suggests novel optimization challenges, while making the\nlink with $\\ell_1$ minimization and sparsity-promoting techniques explicit.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 09:14:48 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 13:15:18 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Unser", "Michael", ""]]}, {"id": "1802.09225", "submitter": "Michael Viderman", "authors": "Noa Avigdor-Elgrabli, Alex Libov, Michael Viderman, Ran Wolff", "title": "Interpreting Complex Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretation of a machine learning induced models is critical for feature\nengineering, debugging, and, arguably, compliance. Yet, best of breed machine\nlearning models tend to be very complex. This paper presents a method for model\ninterpretation which has the main benefit that the simple interpretations it\nprovides are always grounded in actual sets of learning examples. The method is\nvalidated on the task of interpreting a complex regression model in the context\nof both an academic problem -- predicting the year in which a song was recorded\nand an industrial one -- predicting mail user churn.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 09:56:04 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Avigdor-Elgrabli", "Noa", ""], ["Libov", "Alex", ""], ["Viderman", "Michael", ""], ["Wolff", "Ran", ""]]}, {"id": "1802.09246", "submitter": "Xin He", "authors": "Xin He and Junhui Wang and Shaogao Lv", "title": "Efficient kernel-based variable selection with sparsistency", "comments": "27 pages, 5 figures", "journal-ref": "Statistica Sinica, 2022", "doi": "10.5705/ss.202019.0401", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection is central to high-dimensional data analysis, and various\nalgorithms have been developed. Ideally, a variable selection algorithm shall\nbe flexible, scalable, and with theoretical guarantee, yet most existing\nalgorithms cannot attain these properties at the same time. In this article, a\nthree-step variable selection algorithm is developed, involving kernel-based\nestimation of the regression function and its gradient functions as well as a\nhard thresholding. Its key advantage is that it assumes no explicit model\nassumption, admits general predictor effects, allows for scalable computation,\nand attains desirable asymptotic sparsistency. The proposed algorithm can be\nadapted to any reproducing kernel Hilbert space (RKHS) with different kernel\nfunctions, and can be extended to interaction selection with slight\nmodification. Its computational cost is only linear in the data dimension, and\ncan be further improved through parallel computing. The sparsistency of the\nproposed algorithm is established for general RKHS under mild conditions,\nincluding linear and Gaussian kernels as special cases. Its effectiveness is\nalso supported by a variety of simulated and real examples.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 11:09:18 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 13:14:23 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 05:01:23 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["He", "Xin", ""], ["Wang", "Junhui", ""], ["Lv", "Shaogao", ""]]}, {"id": "1802.09301", "submitter": "Ya-Ping Hsieh", "authors": "Ya-Ping Hsieh and Volkan Cevher", "title": "Dimension-free Information Concentration via Exp-Concavity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information concentration of probability measures have important implications\nin learning theory. Recently, it is discovered that the information content of\na log-concave distribution concentrates around their differential entropy,\nalbeit with an unpleasant dependence on the ambient dimension. In this work, we\nprove that if the potentials of the log-concave distribution are exp-concave,\nwhich is a central notion for fast rates in online and statistical learning,\nthen the concentration of information can be further improved to depend only on\nthe exp-concavity parameter, and hence, it can be dimension independent.\nCentral to our proof is a novel yet simple application of the variance\nBrascamp-Lieb inequality. In the context of learning theory, our\nconcentration-of-information result immediately implies high-probability\nresults to many of the previous bounds that only hold in expectation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 13:59:25 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Hsieh", "Ya-Ping", ""], ["Cevher", "Volkan", ""]]}, {"id": "1802.09308", "submitter": "Tianyu Pang", "authors": "Tianyu Pang, Chao Du, Jun Zhu", "title": "Max-Mahalanobis Linear Discriminant Analysis Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep neural network (DNN) consists of a nonlinear transformation from an\ninput to a feature representation, followed by a common softmax linear\nclassifier. Though many efforts have been devoted to designing a proper\narchitecture for nonlinear transformation, little investigation has been done\non the classifier part. In this paper, we show that a properly designed\nclassifier can improve robustness to adversarial attacks and lead to better\nprediction results. Specifically, we define a Max-Mahalanobis distribution\n(MMD) and theoretically show that if the input distributes as a MMD, the linear\ndiscriminant analysis (LDA) classifier will have the best robustness to\nadversarial examples. We further propose a novel Max-Mahalanobis linear\ndiscriminant analysis (MM-LDA) network, which explicitly maps a complicated\ndata distribution in the input space to a MMD in the latent feature space and\nthen applies LDA to make predictions. Our results demonstrate that the MM-LDA\nnetworks are significantly more robust to adversarial attacks, and have better\nperformance in class-biased classification.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 14:07:18 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 07:33:57 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Pang", "Tianyu", ""], ["Du", "Chao", ""], ["Zhu", "Jun", ""]]}, {"id": "1802.09344", "submitter": "Mohammad Khalil", "authors": "Mohammad Khalil", "title": "Learning Analytics in Massive Open Online Courses", "comments": "PhD Thesis, 257 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Educational technology has obtained great importance over the last fifteen\nyears. At present, the umbrella of educational technology incorporates\nmultitudes of engaging online environments and fields. Learning analytics and\nMassive Open Online Courses (MOOCs) are two of the most relevant emerging\ntopics in this domain. Since they are open to everyone at no cost, MOOCs excel\nin attracting numerous participants that can reach hundreds and hundreds of\nthousands. Experts from different disciplines have shown significant interest\nin MOOCs as the phenomenon has rapidly grown. In fact, MOOCs have been proven\nto scale education in disparate areas. Their benefits are crystallized in the\nimprovement of educational outcomes, reduction of costs and accessibility\nexpansion. Due to their unusual massiveness, the large datasets of MOOC\nplatforms require advanced tools and methodologies for further examination. The\nkey importance of learning analytics is reflected here. MOOCs offer diverse\nchallenges and practices for learning analytics to tackle. In view of that,\nthis thesis combines both fields in order to investigate further steps in the\nlearning analytics capabilities in MOOCs. The primary research of this\ndissertation focuses on the integration of learning analytics in MOOCs, and\nthereafter looks into examining students' behavior on one side and bridging\nMOOC issues on the other side. The research was done on the Austrian iMooX\nxMOOC platform. We followed the prototyping and case studies research\nmethodology to carry out the research questions of this dissertation. The main\ncontributions incorporate designing a general learning analytics framework,\nlearning analytics prototype, records of students' behavior in nearly every\nMOOC's variables (discussion forums, interactions in videos, self-assessment\nquizzes, login frequency), a cluster of student engagement...\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 14:09:00 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Khalil", "Mohammad", ""]]}, {"id": "1802.09359", "submitter": "Ismini Psychoula", "authors": "Ismini Psychoula, Erinc Merdivan, Deepika Singh, Liming Chen, Feng\n  Chen, Sten Hanke, Johannes Kropf, Andreas Holzinger, Matthieu Geist", "title": "A Deep Learning Approach for Privacy Preservation in Assisted Living", "comments": "6 pages, 6 figures, To be published in the IEEE International\n  Conference on Pervasive Computing and Communications (SmarterAAL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of Internet of Things (IoT) technologies the potential for privacy\ninvasion is becoming a major concern especially in regards to healthcare data\nand Ambient Assisted Living (AAL) environments. Systems that offer AAL\ntechnologies make extensive use of personal data in order to provide services\nthat are context-aware and personalized. This makes privacy preservation a very\nimportant issue especially since the users are not always aware of the privacy\nrisks they could face. A lot of progress has been made in the deep learning\nfield, however, there has been lack of research on privacy preservation of\nsensitive personal data with the use of deep learning. In this paper we focus\non a Long Short Term Memory (LSTM) Encoder-Decoder, which is a principal\ncomponent of deep learning, and propose a new encoding technique that allows\nthe creation of different AAL data views, depending on the access level of the\nend user and the information they require access to. The efficiency and\neffectiveness of the proposed method are demonstrated with experiments on a\nsimulated AAL dataset. Qualitatively, we show that the proposed model learns\nprivacy operations such as disclosure, deletion and generalization and can\nperform encoding and decoding of the data with almost perfect recovery.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 15:19:54 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Psychoula", "Ismini", ""], ["Merdivan", "Erinc", ""], ["Singh", "Deepika", ""], ["Chen", "Liming", ""], ["Chen", "Feng", ""], ["Hanke", "Sten", ""], ["Kropf", "Johannes", ""], ["Holzinger", "Andreas", ""], ["Geist", "Matthieu", ""]]}, {"id": "1802.09371", "submitter": "Thierry Dumas", "authors": "Thierry Dumas (Sirocco), Aline Roumy (Sirocco), Christine Guillemot\n  (Sirocco)", "title": "Autoencoder based image compression: can the learning be quantization\n  independent?", "comments": "International Conference on Acoustics, Speech and Signal Processing\n  ICASSP, Apr 2018, Calgary, Canada. 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the problem of learning transforms for image compression\nvia autoencoders. Usually, the rate-distortion performances of image\ncompression are tuned by varying the quantization step size. In the case of\nautoen-coders, this in principle would require learning one transform per\nrate-distortion point at a given quantization step size. Here, we show that\ncomparable performances can be obtained with a unique learned transform. The\ndifferent rate-distortion points are then reached by varying the quantization\nstep size at test time. This approach saves a lot of training time.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 08:31:30 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Dumas", "Thierry", "", "Sirocco"], ["Roumy", "Aline", "", "Sirocco"], ["Guillemot", "Christine", "", "Sirocco"]]}, {"id": "1802.09386", "submitter": "Pablo Piantanida", "authors": "Cl\\'ement Feutry and Pablo Piantanida and Yoshua Bengio and Pierre\n  Duhamel", "title": "Learning Anonymized Representations with Adversarial Neural Networks", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical methods protecting sensitive information or the identity of the\ndata owner have become critical to ensure privacy of individuals as well as of\norganizations. This paper investigates anonymization methods based on\nrepresentation learning and deep neural networks, and motivated by novel\ninformation theoretical bounds. We introduce a novel training objective for\nsimultaneously training a predictor over target variables of interest (the\nregular labels) while preventing an intermediate representation to be\npredictive of the private labels. The architecture is based on three\nsub-networks: one going from input to representation, one from representation\nto predicted regular labels, and one from representation to predicted private\nlabels. The training procedure aims at learning representations that preserve\nthe relevant part of the information (about regular labels) while dismissing\ninformation about the private labels which correspond to the identity of a\nperson. We demonstrate the success of this approach for two distinct\nclassification versus anonymization tasks (handwritten digits and sentiment\nanalysis).\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 15:14:51 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Feutry", "Cl\u00e9ment", ""], ["Piantanida", "Pablo", ""], ["Bengio", "Yoshua", ""], ["Duhamel", "Pierre", ""]]}, {"id": "1802.09405", "submitter": "Simone Scardapane", "authors": "Simone Scardapane, Steven Van Vaerenbergh, Danilo Comminiello, Aurelio\n  Uncini", "title": "Improving Graph Convolutional Networks with Non-Parametric Activation\n  Functions", "comments": "Submitted to EUSIPCO 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are a class of neural networks that allow to\nefficiently perform inference on data that is associated to a graph structure,\nsuch as, e.g., citation networks or knowledge graphs. While several variants of\nGNNs have been proposed, they only consider simple nonlinear activation\nfunctions in their layers, such as rectifiers or squashing functions. In this\npaper, we investigate the use of graph convolutional networks (GCNs) when\ncombined with more complex activation functions, able to adapt from the\ntraining data. More specifically, we extend the recently proposed kernel\nactivation function, a non-parametric model which can be implemented easily,\ncan be regularized with standard $\\ell_p$-norms techniques, and is smooth over\nits entire domain. Our experimental evaluation shows that the proposed\narchitecture can significantly improve over its baseline, while similar\nimprovements cannot be obtained by simply increasing the depth or size of the\noriginal GCN.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 15:36:56 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Scardapane", "Simone", ""], ["Van Vaerenbergh", "Steven", ""], ["Comminiello", "Danilo", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1802.09419", "submitter": "Jonathan Lorraine", "authors": "Jonathan Lorraine and David Duvenaud", "title": "Stochastic Hyperparameter Optimization through Hypernetworks", "comments": "9 pages, 6 figures; revised figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are often tuned by nesting optimization of model\nweights inside the optimization of hyperparameters. We give a method to\ncollapse this nested optimization into joint stochastic optimization of weights\nand hyperparameters. Our process trains a neural network to output\napproximately optimal weights as a function of hyperparameters. We show that\nour technique converges to locally optimal weights and hyperparameters for\nsufficiently large hypernetworks. We compare this method to standard\nhyperparameter optimization strategies and demonstrate its effectiveness for\ntuning thousands of hyperparameters.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 16:04:46 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 18:14:35 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Lorraine", "Jonathan", ""], ["Duvenaud", "David", ""]]}, {"id": "1802.09464", "submitter": "Matthias Plappert", "authors": "Matthias Plappert, Marcin Andrychowicz, Alex Ray, Bob McGrew, Bowen\n  Baker, Glenn Powell, Jonas Schneider, Josh Tobin, Maciek Chociej, Peter\n  Welinder, Vikash Kumar, Wojciech Zaremba", "title": "Multi-Goal Reinforcement Learning: Challenging Robotics Environments and\n  Request for Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this technical report is two-fold. First of all, it introduces\na suite of challenging continuous control tasks (integrated with OpenAI Gym)\nbased on currently existing robotics hardware. The tasks include pushing,\nsliding and pick & place with a Fetch robotic arm as well as in-hand object\nmanipulation with a Shadow Dexterous Hand. All tasks have sparse binary rewards\nand follow a Multi-Goal Reinforcement Learning (RL) framework in which an agent\nis told what to do using an additional input.\n  The second part of the paper presents a set of concrete research ideas for\nimproving RL algorithms, most of which are related to Multi-Goal RL and\nHindsight Experience Replay.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 17:20:14 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 18:11:25 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Plappert", "Matthias", ""], ["Andrychowicz", "Marcin", ""], ["Ray", "Alex", ""], ["McGrew", "Bob", ""], ["Baker", "Bowen", ""], ["Powell", "Glenn", ""], ["Schneider", "Jonas", ""], ["Tobin", "Josh", ""], ["Chociej", "Maciek", ""], ["Welinder", "Peter", ""], ["Kumar", "Vikash", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "1802.09477", "submitter": "Scott Fujimoto", "authors": "Scott Fujimoto, Herke van Hoof, David Meger", "title": "Addressing Function Approximation Error in Actor-Critic Methods", "comments": "Accepted at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In value-based reinforcement learning methods such as deep Q-learning,\nfunction approximation errors are known to lead to overestimated value\nestimates and suboptimal policies. We show that this problem persists in an\nactor-critic setting and propose novel mechanisms to minimize its effects on\nboth the actor and the critic. Our algorithm builds on Double Q-learning, by\ntaking the minimum value between a pair of critics to limit overestimation. We\ndraw the connection between target networks and overestimation bias, and\nsuggest delaying policy updates to reduce per-update error and further improve\nperformance. We evaluate our method on the suite of OpenAI gym tasks,\noutperforming the state of the art in every environment tested.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 17:54:49 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 18:21:26 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 17:37:07 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Fujimoto", "Scott", ""], ["van Hoof", "Herke", ""], ["Meger", "David", ""]]}, {"id": "1802.09484", "submitter": "William Fedus", "authors": "Valentin Thomas, Emmanuel Bengio, William Fedus, Jules Pondard,\n  Philippe Beaudoin, Hugo Larochelle, Joelle Pineau, Doina Precup, Yoshua\n  Bengio", "title": "Disentangling the independently controllable factors of variation by\n  interacting with the world", "comments": "Presented at NIPS 2017 Learning Disentangling Representations\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been postulated that a good representation is one that disentangles\nthe underlying explanatory factors of variation. However, it remains an open\nquestion what kind of training framework could potentially achieve that.\nWhereas most previous work focuses on the static setting (e.g., with images),\nwe postulate that some of the causal factors could be discovered if the learner\nis allowed to interact with its environment. The agent can experiment with\ndifferent actions and observe their effects. More specifically, we hypothesize\nthat some of these factors correspond to aspects of the environment which are\nindependently controllable, i.e., that there exists a policy and a learnable\nfeature for each such aspect of the environment, such that this policy can\nyield changes in that feature with minimal changes to other features that\nexplain the statistical variations in the observed data. We propose a specific\nobjective function to find such factors, and verify experimentally that it can\nindeed disentangle independently controllable aspects of the environment\nwithout any extrinsic reward signal.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 18:03:56 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Thomas", "Valentin", ""], ["Bengio", "Emmanuel", ""], ["Fedus", "William", ""], ["Pondard", "Jules", ""], ["Beaudoin", "Philippe", ""], ["Larochelle", "Hugo", ""], ["Pineau", "Joelle", ""], ["Precup", "Doina", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1802.09502", "submitter": "Junbo Zhao", "authors": "Jake Zhao and Kyunghyun Cho", "title": "Retrieval-Augmented Convolutional Neural Networks for Improved\n  Robustness against Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a retrieval-augmented convolutional network and propose to train\nit with local mixup, a novel variant of the recently proposed mixup algorithm.\nThe proposed hybrid architecture combining a convolutional network and an\noff-the-shelf retrieval engine was designed to mitigate the adverse effect of\noff-manifold adversarial examples, while the proposed local mixup addresses\non-manifold ones by explicitly encouraging the classifier to locally behave\nlinearly on the data manifold. Our evaluation of the proposed approach against\nfive readily-available adversarial attacks on three datasets--CIFAR-10, SVHN\nand ImageNet--demonstrate the improved robustness compared to the vanilla\nconvolutional network.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 18:29:20 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Zhao", "Jake", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1802.09511", "submitter": "Amin Jalali", "authors": "Amin Jalali, Rebecca Willett", "title": "Missing Data in Sparse Transition Matrix Estimation for Sub-Gaussian\n  Vector Autoregressive Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional time series data exist in numerous areas such as finance,\ngenomics, healthcare, and neuroscience. An unavoidable aspect of all such\ndatasets is missing data, and dealing with this issue has been an important\nfocus in statistics, control, and machine learning. In this work, we consider a\nhigh-dimensional estimation problem where a dynamical system, governed by a\nstable vector autoregressive model, is randomly and only partially observed at\neach time point. Our task amounts to estimating the transition matrix, which is\nassumed to be sparse. In such a scenario, where covariates are highly\ninterdependent and partially missing, new theoretical challenges arise. While\ntransition matrix estimation in vector autoregressive models has been studied\npreviously, the missing data scenario requires separate efforts. Moreover,\nwhile transition matrix estimation can be studied from a high-dimensional\nsparse linear regression perspective, the covariates are highly dependent and\nexisting results on regularized estimation with missing data from\ni.i.d.~covariates are not applicable. At the heart of our analysis lies 1) a\nnovel concentration result when the innovation noise satisfies the convex\nconcentration property, as well as 2) a new quantity for characterizing the\ninteractions of the time-varying observation process with the underlying\ndynamical system.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 18:54:19 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Jalali", "Amin", ""], ["Willett", "Rebecca", ""]]}, {"id": "1802.09514", "submitter": "Jason Altschuler", "authors": "Jason Altschuler, Victor-Emmanuel Brunel, Alan Malek", "title": "Best Arm Identification for Contaminated Bandits", "comments": "to appear in Journal of Machine Learning Research (JMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies active learning in the context of robust statistics.\nSpecifically, we propose a variant of the Best Arm Identification problem for\n\\emph{contaminated bandits}, where each arm pull has probability $\\varepsilon$\nof generating a sample from an arbitrary contamination distribution instead of\nthe true underlying distribution. The goal is to identify the best (or\napproximately best) true distribution with high probability, with a secondary\ngoal of providing guarantees on the quality of this distribution. The primary\nchallenge of the contaminated bandit setting is that the true distributions are\nonly partially identifiable, even with infinite samples. To address this, we\ndevelop tight, non-asymptotic sample complexity bounds for high-probability\nestimation of the first two robust moments (median and median absolute\ndeviation) from contaminated samples. These concentration inequalities are the\nmain technical contributions of the paper and may be of independent interest.\nUsing these results, we adapt several classical Best Arm Identification\nalgorithms to the contaminated bandit setting and derive sample complexity\nupper bounds for our problem. Finally, we provide matching\ninformation-theoretic lower bounds on the sample complexity (up to a small\nlogarithmic factor).\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 18:59:30 GMT"}, {"version": "v2", "created": "Sun, 8 Apr 2018 22:23:06 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 00:15:37 GMT"}, {"version": "v4", "created": "Fri, 19 Oct 2018 15:31:29 GMT"}, {"version": "v5", "created": "Wed, 15 May 2019 15:32:00 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Altschuler", "Jason", ""], ["Brunel", "Victor-Emmanuel", ""], ["Malek", "Alan", ""]]}, {"id": "1802.09548", "submitter": "Nina Grgi\\'c-Hla\\v{c}a", "authors": "Nina Grgi\\'c-Hla\\v{c}a, Elissa M. Redmiles, Krishna P. Gummadi, Adrian\n  Weller", "title": "Human Perceptions of Fairness in Algorithmic Decision Making: A Case\n  Study of Criminal Risk Prediction", "comments": "To appear in the Proceedings of the Web Conference (WWW 2018). Code\n  available at https://fate-computing.mpi-sws.org/procedural_fairness/", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As algorithms are increasingly used to make important decisions that affect\nhuman lives, ranging from social benefit assignment to predicting risk of\ncriminal recidivism, concerns have been raised about the fairness of\nalgorithmic decision making. Most prior works on algorithmic fairness\nnormatively prescribe how fair decisions ought to be made. In contrast, here,\nwe descriptively survey users for how they perceive and reason about fairness\nin algorithmic decision making.\n  A key contribution of this work is the framework we propose to understand why\npeople perceive certain features as fair or unfair to be used in algorithms.\nOur framework identifies eight properties of features, such as relevance,\nvolitionality and reliability, as latent considerations that inform people's\nmoral judgments about the fairness of feature use in decision-making\nalgorithms. We validate our framework through a series of scenario-based\nsurveys with 576 people. We find that, based on a person's assessment of the\neight latent properties of a feature in our exemplar scenario, we can\naccurately (> 85%) predict if the person will judge the use of the feature as\nfair.\n  Our findings have important implications. At a high-level, we show that\npeople's unfairness concerns are multi-dimensional and argue that future\nstudies need to address unfairness concerns beyond discrimination. At a\nlow-level, we find considerable disagreements in people's fairness judgments.\nWe identify root causes of the disagreements, and note possible pathways to\nresolve them.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 19:00:15 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Grgi\u0107-Hla\u010da", "Nina", ""], ["Redmiles", "Elissa M.", ""], ["Gummadi", "Krishna P.", ""], ["Weller", "Adrian", ""]]}, {"id": "1802.09564", "submitter": "Yuke Zhu", "authors": "Yuke Zhu, Ziyu Wang, Josh Merel, Andrei Rusu, Tom Erez, Serkan Cabi,\n  Saran Tunyasuvunakool, J\\'anos Kram\\'ar, Raia Hadsell, Nando de Freitas,\n  Nicolas Heess", "title": "Reinforcement and Imitation Learning for Diverse Visuomotor Skills", "comments": "13 pages, 6 figures, Published in RSS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model-free deep reinforcement learning method that leverages a\nsmall amount of demonstration data to assist a reinforcement learning agent. We\napply this approach to robotic manipulation tasks and train end-to-end\nvisuomotor policies that map directly from RGB camera inputs to joint\nvelocities. We demonstrate that our approach can solve a wide variety of\nvisuomotor tasks, for which engineering a scripted controller would be\nlaborious. In experiments, our reinforcement and imitation agent achieves\nsignificantly better performances than agents trained with reinforcement\nlearning or imitation learning alone. We also illustrate that these policies,\ntrained with large visual and dynamics variations, can achieve preliminary\nsuccesses in zero-shot sim2real transfer. A brief visual description of this\nwork can be viewed in https://youtu.be/EDl8SQUNjj0\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 19:25:25 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 22:41:09 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zhu", "Yuke", ""], ["Wang", "Ziyu", ""], ["Merel", "Josh", ""], ["Rusu", "Andrei", ""], ["Erez", "Tom", ""], ["Cabi", "Serkan", ""], ["Tunyasuvunakool", "Saran", ""], ["Kram\u00e1r", "J\u00e1nos", ""], ["Hadsell", "Raia", ""], ["de Freitas", "Nando", ""], ["Heess", "Nicolas", ""]]}, {"id": "1802.09568", "submitter": "Tomer Koren", "authors": "Vineet Gupta, Tomer Koren, Yoram Singer", "title": "Shampoo: Preconditioned Stochastic Tensor Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preconditioned gradient methods are among the most general and powerful tools\nin optimization. However, preconditioning requires storing and manipulating\nprohibitively large matrices. We describe and analyze a new structure-aware\npreconditioning algorithm, called Shampoo, for stochastic optimization over\ntensor spaces. Shampoo maintains a set of preconditioning matrices, each of\nwhich operates on a single dimension, contracting over the remaining\ndimensions. We establish convergence guarantees in the stochastic convex\nsetting, the proof of which builds upon matrix trace inequalities. Our\nexperiments with state-of-the-art deep learning models show that Shampoo is\ncapable of converging considerably faster than commonly used optimizers.\nAlthough it involves a more complex update rule, Shampoo's runtime per step is\ncomparable to that of simple gradient methods such as SGD, AdaGrad, and Adam.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 19:36:41 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 00:12:58 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Gupta", "Vineet", ""], ["Koren", "Tomer", ""], ["Singer", "Yoram", ""]]}, {"id": "1802.09578", "submitter": "Yining Wang", "authors": "Yining Wang, Yi Wu, Simon S. Du", "title": "Near-Linear Time Local Polynomial Nonparametric Estimation with Box\n  Kernels", "comments": "Accepted to INFORMS Journal on Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local polynomial regression (Fan and Gijbels 1996) is an important class of\nmethods for nonparametric density estimation and regression problems. However,\nstraightforward implementation of local polynomial regression has quadratic\ntime complexity which hinders its applicability in large-scale data analysis.\nIn this paper, we significantly accelerate the computation of local polynomial\nestimates by novel applications of multi-dimensional binary indexed trees\n(Fenwick 1994). Both time and space complexity of our proposed algorithm is\nnearly linear in the number of input data points. Simulation results confirm\nthe efficiency and effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 20:04:58 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 15:42:41 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Wang", "Yining", ""], ["Wu", "Yi", ""], ["Du", "Simon S.", ""]]}, {"id": "1802.09583", "submitter": "Daniel Roy", "authors": "Gintare Karolina Dziugaite, Daniel M. Roy", "title": "Data-dependent PAC-Bayes priors via differential privacy", "comments": "18 pages, 2 figures; equivalent to camera ready, but includes\n  supplementary materials; subsumes and extends some results first reported in\n  arXiv:1712.09376", "journal-ref": "Advances in Neural Information Processing Systems, 31 (2018), pp.\n  8430-8441", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Probably Approximately Correct (PAC) Bayes framework (McAllester, 1999)\ncan incorporate knowledge about the learning algorithm and (data) distribution\nthrough the use of distribution-dependent priors, yielding tighter\ngeneralization bounds on data-dependent posteriors. Using this flexibility,\nhowever, is difficult, especially when the data distribution is presumed to be\nunknown. We show how an {\\epsilon}-differentially private data-dependent prior\nyields a valid PAC-Bayes bound, and then show how non-private mechanisms for\nchoosing priors can also yield generalization bounds. As an application of this\nresult, we show that a Gaussian prior mean chosen via stochastic gradient\nLangevin dynamics (SGLD; Welling and Teh, 2011) leads to a valid PAC-Bayes\nbound given control of the 2-Wasserstein distance to an\n{\\epsilon}-differentially private stationary distribution. We study our\ndata-dependent bounds empirically, and show that they can be nonvacuous even\nwhen other distribution-dependent bounds are vacuous.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 20:14:03 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 17:06:45 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Dziugaite", "Gintare Karolina", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1802.09640", "submitter": "Roberta Raileanu", "authors": "Roberta Raileanu, Emily Denton, Arthur Szlam, Rob Fergus", "title": "Modeling Others using Oneself in Multi-Agent Reinforcement Learning", "comments": "10 pages, 16 figures, submitted to ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the multi-agent reinforcement learning setting with imperfect\ninformation in which each agent is trying to maximize its own utility. The\nreward function depends on the hidden state (or goal) of both agents, so the\nagents must infer the other players' hidden goals from their observed behavior\nin order to solve the tasks. We propose a new approach for learning in these\ndomains: Self Other-Modeling (SOM), in which an agent uses its own policy to\npredict the other agent's actions and update its belief of their hidden state\nin an online manner. We evaluate this approach on three different tasks and\nshow that the agents are able to learn better policies using their estimate of\nthe other players' hidden states, in both cooperative and adversarial settings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 23:27:53 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 17:07:38 GMT"}, {"version": "v3", "created": "Fri, 23 Mar 2018 21:53:13 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Raileanu", "Roberta", ""], ["Denton", "Emily", ""], ["Szlam", "Arthur", ""], ["Fergus", "Rob", ""]]}, {"id": "1802.09646", "submitter": "Ershad Banijamali Mr.", "authors": "Ershad Banijamali, Yasin Abbasi-Yadkori, Mohammad Ghavamzadeh, Nikos\n  Vlassis", "title": "Optimizing over a Restricted Policy Class in Markov Decision Processes", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of finding an optimal policy in a Markov decision\nprocess under a restricted policy class defined by the convex hull of a set of\nbase policies. This problem is of great interest in applications in which a\nnumber of reasonably good (or safe) policies are already known and we are only\ninterested in optimizing in their convex hull. We show that this problem is\nNP-hard to solve exactly as well as to approximate to arbitrary accuracy.\nHowever, under a condition that is akin to the occupancy measures of the base\npolicies having large overlap, we show that there exists an efficient algorithm\nthat finds a policy that is almost as good as the best convex combination of\nthe base policies. The running time of the proposed algorithm is linear in the\nnumber of states and polynomial in the number of base policies. In practice, we\ndemonstrate an efficient implementation for large state problems. Compared to\ntraditional policy gradient methods, the proposed approach has the advantage\nthat, apart from the computation of occupancy measures of some base policies,\nthe iterative method need not interact with the environment during the\noptimization process. This is especially important in complex systems where\nestimating the value of a policy can be a time consuming process.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 23:51:57 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Banijamali", "Ershad", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Ghavamzadeh", "Mohammad", ""], ["Vlassis", "Nikos", ""]]}, {"id": "1802.09660", "submitter": "George Leu", "authors": "George Leu and Hussein Abbass", "title": "Computational Red Teaming in a Sudoku Solving Context: Neural Network\n  Based Skill Representation and Acquisition", "comments": null, "journal-ref": "Proceedings in Adaptation, Learning and Optimization, vol. 5,\n  Springer, 2016", "doi": "10.1007/978-3-319-27000-5_26", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide an insight into the skill representation, where\nskill representation is seen as an essential part of the skill assessment stage\nin the Computational Red Teaming process. Skill representation is demonstrated\nin the context of Sudoku puzzle, for which the real human skills used in Sudoku\nsolving, along with their acquisition, are represented computationally in a\ncognitively plausible manner, by using feed-forward neural networks with\nback-propagation, and supervised learning. The neural network based skills are\nthen coupled with a hard-coded constraint propagation computational Sudoku\nsolver, in which the solving sequence is kept hard-coded, and the skills are\nrepresented through neural networks. The paper demonstrates that the modified\nsolver can achieve different levels of proficiency, depending on the amount of\nskills acquired through the neural networks. Results are encouraging for\ndeveloping more complex skill and skill acquisition models usable in general\nframeworks related to the skill assessment aspect of Computational Red Teaming.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 00:49:45 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Leu", "George", ""], ["Abbass", "Hussein", ""]]}, {"id": "1802.09680", "submitter": "Nishant Mehta", "authors": "Rafael Frongillo, Nishant A. Mehta, Tom Morgan, Bo Waggoner", "title": "Multi-Observation Regression", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work introduced loss functions which measure the error of a prediction\nbased on multiple simultaneous observations or outcomes. In this paper, we\nexplore the theoretical and practical questions that arise when using such\nmulti-observation losses for regression on data sets of $(x,y)$ pairs. When a\nloss depends on only one observation, the average empirical loss decomposes by\napplying the loss to each pair, but for the multi-observation case, empirical\nloss is not even well-defined, and the possibility of statistical guarantees is\nunclear without several $(x,y)$ pairs with exactly the same $x$ value. We\npropose four algorithms formalizing the concept of empirical risk minimization\nfor this problem, two of which have statistical guarantees in settings allowing\nboth slow and fast convergence rates, but which are out-performed empirically\nby the other two. Empirical results demonstrate practicality of these\nalgorithms in low-dimensional settings, while lower bounds demonstrate\nintrinsic difficulty in higher dimensions. Finally, we demonstrate the\npotential benefit of the algorithms over natural baselines that use traditional\nsingle-observation losses via both lower bounds and simulations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 01:49:09 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Frongillo", "Rafael", ""], ["Mehta", "Nishant A.", ""], ["Morgan", "Tom", ""], ["Waggoner", "Bo", ""]]}, {"id": "1802.09691", "submitter": "Muhan Zhang", "authors": "Muhan Zhang, Yixin Chen", "title": "Link Prediction Based on Graph Neural Networks", "comments": "Accepted by NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is a key problem for network-structured data. Link prediction\nheuristics use some score functions, such as common neighbors and Katz index,\nto measure the likelihood of links. They have obtained wide practical uses due\nto their simplicity, interpretability, and for some of them, scalability.\nHowever, every heuristic has a strong assumption on when two nodes are likely\nto link, which limits their effectiveness on networks where these assumptions\nfail. In this regard, a more reasonable way should be learning a suitable\nheuristic from a given network instead of using predefined ones. By extracting\na local subgraph around each target link, we aim to learn a function mapping\nthe subgraph patterns to link existence, thus automatically learning a\n`heuristic' that suits the current network. In this paper, we study this\nheuristic learning paradigm for link prediction. First, we develop a novel\n$\\gamma$-decaying heuristic theory. The theory unifies a wide range of\nheuristics in a single framework, and proves that all these heuristics can be\nwell approximated from local subgraphs. Our results show that local subgraphs\nreserve rich information related to link existence. Second, based on the\n$\\gamma$-decaying theory, we propose a new algorithm to learn heuristics from\nlocal subgraphs using a graph neural network (GNN). Its experimental results\nshow unprecedented performance, working consistently well on a wide range of\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 02:35:52 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 20:22:42 GMT"}, {"version": "v3", "created": "Tue, 20 Nov 2018 05:52:00 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Zhang", "Muhan", ""], ["Chen", "Yixin", ""]]}, {"id": "1802.09697", "submitter": "Mingwen Dong", "authors": "Mingwen Dong", "title": "Convolutional Neural Network Achieves Human-level Accuracy in Music\n  Genre Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music genre classification is one example of content-based analysis of music\nsignals. Traditionally, human-engineered features were used to automatize this\ntask and 61% accuracy has been achieved in the 10-genre classification.\nHowever, it's still below the 70% accuracy that humans could achieve in the\nsame task. Here, we propose a new method that combines knowledge of human\nperception study in music genre classification and the neurophysiology of the\nauditory system. The method works by training a simple convolutional neural\nnetwork (CNN) to classify a short segment of the music signal. Then, the genre\nof a music is determined by splitting it into short segments and then combining\nCNN's predictions from all short segments. After training, this method achieves\nhuman-level (70%) accuracy and the filters learned in the CNN resemble the\nspectrotemporal receptive field (STRF) in the auditory system.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 03:08:55 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Dong", "Mingwen", ""]]}, {"id": "1802.09700", "submitter": "Zhi Xu", "authors": "Zhi Xu, Chengtao Li, Stefanie Jegelka", "title": "Robust GANs against Dishonest Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of deep learning models is a property that has recently gained\nincreasing attention. We explore a notion of robustness for generative\nadversarial models that is pertinent to their internal interactive structure,\nand show that, perhaps surprisingly, the GAN in its original form is not\nrobust. Our notion of robustness relies on a perturbed discriminator, or noisy,\nadversarial interference with its feedback. We explore, theoretically and\nempirically, the effect of model and training properties on this robustness. In\nparticular, we show theoretical conditions for robustness that are supported by\nempirical evidence. We also test the effect of regularization. Our results\nsuggest variations of GANs that are indeed more robust to noisy attacks and\nhave more stable training behavior, requiring less regularization in general.\nInspired by our theoretical results, we further extend our framework to obtain\na class of models related to WGAN, with good empirical performance. Overall,\nour results suggest a new perspective on understanding and designing GAN models\nfrom the viewpoint of their internal robustness.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 03:21:44 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 19:40:43 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 03:40:46 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Xu", "Zhi", ""], ["Li", "Chengtao", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1802.09707", "submitter": "Lei Wu", "authors": "Lei Wu, Zhanxing Zhu, Cheng Tai, Weinan E", "title": "Understanding and Enhancing the Transferability of Adversarial Examples", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep neural networks are known to be vulnerable to\nadversarial examples, formed by applying small but malicious perturbations to\nthe original inputs. Moreover, the perturbations can \\textit{transfer across\nmodels}: adversarial examples generated for a specific model will often mislead\nother unseen models. Consequently the adversary can leverage it to attack\ndeployed systems without any query, which severely hinder the application of\ndeep learning, especially in the areas where security is crucial. In this work,\nwe systematically study how two classes of factors that might influence the\ntransferability of adversarial examples. One is about model-specific factors,\nincluding network architecture, model capacity and test accuracy. The other is\nthe local smoothness of loss function for constructing adversarial examples.\nBased on these understanding, a simple but effective strategy is proposed to\nenhance transferability. We call it variance-reduced attack, since it utilizes\nthe variance-reduced gradient to generate adversarial example. The\neffectiveness is confirmed by a variety of experiments on both CIFAR-10 and\nImageNet datasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 03:46:38 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Wu", "Lei", ""], ["Zhu", "Zhanxing", ""], ["Tai", "Cheng", ""], ["E", "Weinan", ""]]}, {"id": "1802.09714", "submitter": "Feiyun Zhu", "authors": "Feiyun Zhu, Jun Guo, Ruoyu Li, Junzhou Huang", "title": "Robust Actor-Critic Contextual Bandit for Mobile Health (mHealth)\n  Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the actor-critic contextual bandit for the mobile health\n(mHealth) intervention. State-of-the-art decision-making algorithms generally\nignore the outliers in the dataset. In this paper, we propose a novel robust\ncontextual bandit method for the mHealth. It can achieve the conflicting goal\nof reducing the influence of outliers while seeking for a similar solution\ncompared with the state-of-the-art contextual bandit methods on the datasets\nwithout outliers. Such performance relies on two technologies: (1) the\ncapped-$\\ell_{2}$ norm; (2) a reliable method to set the thresholding\nhyper-parameter, which is inspired by one of the most fundamental techniques in\nthe statistics. Although the model is non-convex and non-differentiable, we\npropose an effective reweighted algorithm and provide solid theoretical\nanalyses. We prove that the proposed algorithm can find sufficiently decreasing\npoints after each iteration and finally converges after a finite number of\niterations. Extensive experiment results on two datasets demonstrate that our\nmethod can achieve almost identical results compared with state-of-the-art\ncontextual bandit methods on the dataset without outliers, and significantly\noutperform those state-of-the-art methods on the badly noised dataset with\noutliers in a variety of parameter settings.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 04:23:00 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Zhu", "Feiyun", ""], ["Guo", "Jun", ""], ["Li", "Ruoyu", ""], ["Huang", "Junzhou", ""]]}, {"id": "1802.09729", "submitter": "Richard Oentaryo", "authors": "Thong Hoang, Richard J. Oentaryo, Tien-Duy B. Le, David Lo", "title": "Network-Clustered Multi-Modal Bug Localization", "comments": "IEEE Transactions on Software Engineering", "journal-ref": null, "doi": "10.1109/TSE.2018.2810892", "report-no": null, "categories": "cs.IR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developers often spend much effort and resources to debug a program. To help\nthe developers debug, numerous information retrieval (IR)-based and\nspectrum-based bug localization techniques have been devised. IR-based\ntechniques process textual information in bug reports, while spectrum-based\ntechniques process program spectra (i.e., a record of which program elements\nare executed for each test case). While both techniques ultimately generate a\nranked list of program elements that likely contain a bug, they only consider\none source of information--either bug reports or program spectra--which is not\noptimal. In light of this deficiency, this paper presents a new approach dubbed\nNetwork-clustered Multi-modal Bug Localization (NetML), which utilizes\nmulti-modal information from both bug reports and program spectra to localize\nbugs. NetML facilitates an effective bug localization by carrying out a joint\noptimization of bug localization error and clustering of both bug reports and\nprogram elements (i.e., methods). The clustering is achieved through the\nincorporation of network Lasso regularization, which incentivizes the model\nparameters of similar bug reports and similar program elements to be close\ntogether. To estimate the model parameters of both bug reports and methods,\nNetML employs an adaptive learning procedure based on Newton method that\nupdates the parameters on a per-feature basis. Extensive experiments on 355\nreal bugs from seven software systems have been conducted to benchmark NetML\nagainst various state-of-the-art localization methods. The results show that\nNetML surpasses the best-performing baseline by 31.82%, 22.35%, 19.72%, and\n19.24%, in terms of the number of bugs successfully localized when a developer\ninspects the top 1, 5, and 10 methods and Mean Average Precision (MAP),\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 06:02:15 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Hoang", "Thong", ""], ["Oentaryo", "Richard J.", ""], ["Le", "Tien-Duy B.", ""], ["Lo", "David", ""]]}, {"id": "1802.09732", "submitter": "Niladri Chatterji", "authors": "Aldo Pacchiano, Niladri S. Chatterji, Peter L. Bartlett", "title": "Online learning with kernel losses", "comments": "40 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generalization of the adversarial linear bandits framework,\nwhere the underlying losses are kernel functions (with an associated\nreproducing kernel Hilbert space) rather than linear functions. We study a\nversion of the exponential weights algorithm and bound its regret in this\nsetting. Under conditions on the eigendecay of the kernel we provide a sharp\ncharacterization of the regret for this algorithm. When we have polynomial\neigendecay $\\mu_j \\le \\mathcal{O}(j^{-\\beta})$, we find that the regret is\nbounded by $\\mathcal{R}_n \\le \\mathcal{O}(n^{\\beta/(2(\\beta-1))})$; while under\nthe assumption of exponential eigendecay $\\mu_j \\le \\mathcal{O}(e^{-\\beta j\n})$, we get an even tighter bound on the regret $\\mathcal{R}_n \\le\n\\mathcal{O}(n^{1/2}\\log(n)^{1/2})$. We also study the full information setting\nwhen the underlying losses are kernel functions and present an adapted\nexponential weights algorithm and a conditional gradient descent algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 06:07:54 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Pacchiano", "Aldo", ""], ["Chatterji", "Niladri S.", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "1802.09747", "submitter": "Cong Fang", "authors": "Cong Fang, Yameng Huang, Zhouchen Lin", "title": "Accelerating Asynchronous Algorithms for Convex Optimization by Momentum\n  Compensation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous algorithms have attracted much attention recently due to the\ncrucial demands on solving large-scale optimization problems. However, the\naccelerated versions of asynchronous algorithms are rarely studied. In this\npaper, we propose the \"momentum compensation\" technique to accelerate\nasynchronous algorithms for convex problems. Specifically, we first accelerate\nthe plain Asynchronous Gradient Descent, which achieves a faster\n$O(1/\\sqrt{\\epsilon})$ (v.s. $O(1/\\epsilon)$) convergence rate for non-strongly\nconvex functions, and $O(\\sqrt{\\kappa}\\log(1/\\epsilon))$ (v.s. $O(\\kappa\n\\log(1/\\epsilon))$) for strongly convex functions to reach an $\\epsilon$-\napproximate minimizer with the condition number $\\kappa$. We further apply the\ntechnique to accelerate modern stochastic asynchronous algorithms such as\nAsynchronous Stochastic Coordinate Descent and Asynchronous Stochastic Gradient\nDescent. Both of the resultant practical algorithms are faster than existing\nones by order. To the best of our knowledge, we are the first to consider\naccelerated algorithms that allow updating by delayed gradients and are the\nfirst to propose truly accelerated asynchronous algorithms. Finally, the\nexperimental results on a shared memory system show that acceleration can lead\nto significant performance gains on ill-conditioned problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 07:12:58 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Fang", "Cong", ""], ["Huang", "Yameng", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1802.09750", "submitter": "Huishuai Zhang", "authors": "Huishuai Zhang, Wei Chen, Tie-Yan Liu", "title": "Train Feedfoward Neural Network with Layer-wise Adaptive Rate via\n  Approximating Back-matching Propagation", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) has achieved great success in training deep\nneural network, where the gradient is computed through back-propagation.\nHowever, the back-propagated values of different layers vary dramatically. This\ninconsistence of gradient magnitude across different layers renders\noptimization of deep neural network with a single learning rate problematic. We\nintroduce the back-matching propagation which computes the backward values on\nthe layer's parameter and the input by matching backward values on the layer's\noutput. This leads to solving a bunch of least-squares problems, which requires\nhigh computational cost. We then reduce the back-matching propagation with\napproximations and propose an algorithm that turns to be the regular SGD with a\nlayer-wise adaptive learning rate strategy. This allows an easy implementation\nof our algorithm in current machine learning frameworks equipped with\nauto-differentiation. We apply our algorithm in training modern deep neural\nnetworks and achieve favorable results over SGD.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 07:25:32 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Zhang", "Huishuai", ""], ["Chen", "Wei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1802.09756", "submitter": "Junqi Jin", "authors": "Junqi Jin, Chengru Song, Han Li, Kun Gai, Jun Wang, Weinan Zhang", "title": "Real-Time Bidding with Multi-Agent Reinforcement Learning in Display\n  Advertising", "comments": null, "journal-ref": "CIKM 2018, Turin, Italy", "doi": "10.1145/3269206.3272021", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time advertising allows advertisers to bid for each impression for a\nvisiting user. To optimize specific goals such as maximizing revenue and return\non investment (ROI) led by ad placements, advertisers not only need to estimate\nthe relevance between the ads and user's interests, but most importantly\nrequire a strategic response with respect to other advertisers bidding in the\nmarket. In this paper, we formulate bidding optimization with multi-agent\nreinforcement learning. To deal with a large number of advertisers, we propose\na clustering method and assign each cluster with a strategic bidding agent. A\npractical Distributed Coordinated Multi-Agent Bidding (DCMAB) has been proposed\nand implemented to balance the tradeoff between the competition and cooperation\namong advertisers. The empirical study on our industry-scaled real-world data\nhas demonstrated the effectiveness of our methods. Our results show\ncluster-based bidding would largely outperform single-agent and bandit\napproaches, and the coordinated bidding achieves better overall objectives than\npurely self-interested bidding agents.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 07:52:35 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 13:53:10 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Jin", "Junqi", ""], ["Song", "Chengru", ""], ["Li", "Han", ""], ["Gai", "Kun", ""], ["Wang", "Jun", ""], ["Zhang", "Weinan", ""]]}, {"id": "1802.09766", "submitter": "Bernhard C. Geiger", "authors": "Rana Ali Amjad and Bernhard C. Geiger", "title": "Learning Representations for Neural Network-Based Classification Using\n  the Information Bottleneck Principle", "comments": "16 pages, to appear in IEEE Trans. Pattern Analysis and Machine\n  Intelligence", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  42(9):2225-2239, 2020. (c) IEEE", "doi": "10.1109/TPAMI.2019.2909031", "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this theory paper, we investigate training deep neural networks (DNNs) for\nclassification via minimizing the information bottleneck (IB) functional. We\nshow that the resulting optimization problem suffers from two severe issues:\nFirst, for deterministic DNNs, either the IB functional is infinite for almost\nall values of network parameters, making the optimization problem ill-posed, or\nit is piecewise constant, hence not admitting gradient-based optimization\nmethods. Second, the invariance of the IB functional under bijections prevents\nit from capturing properties of the learned representation that are desirable\nfor classification, such as robustness and simplicity. We argue that these\nissues are partly resolved for stochastic DNNs, DNNs that include a (hard or\nsoft) decision rule, or by replacing the IB functional with related, but more\nwell-behaved cost functions. We conclude that recent successes reported about\ntraining DNNs using the IB framework must be attributed to such solutions. As a\nside effect, our results indicate limitations of the IB framework for the\nanalysis of DNNs. We also note that rather than trying to repair the inherent\nproblems in the IB functional, a better approach may be to design regularizers\non latent representation enforcing the desired properties directly.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 08:24:19 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 08:27:43 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 07:41:48 GMT"}, {"version": "v4", "created": "Thu, 12 Jul 2018 06:40:42 GMT"}, {"version": "v5", "created": "Thu, 10 Jan 2019 10:58:31 GMT"}, {"version": "v6", "created": "Thu, 11 Apr 2019 11:20:27 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Amjad", "Rana Ali", ""], ["Geiger", "Bernhard C.", ""]]}, {"id": "1802.09769", "submitter": "Shuang Wu", "authors": "Shuang Wu, Guoqi Li, Lei Deng, Liu Liu, Yuan Xie, Luping Shi", "title": "L1-Norm Batch Normalization for Efficient Training of Deep Neural\n  Networks", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": "10.1109/TNNLS.2018.2876179", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) has been proven to be quite effective at\naccelerating and improving the training of deep neural networks (DNNs).\nHowever, BN brings additional computation, consumes more memory and generally\nslows down the training process by a large margin, which aggravates the\ntraining effort. Furthermore, the nonlinear square and root operations in BN\nalso impede the low bit-width quantization techniques, which draws much\nattention in deep learning hardware community. In this work, we propose an\nL1-norm BN (L1BN) with only linear operations in both the forward and the\nbackward propagations during training. L1BN is shown to be approximately\nequivalent to the original L2-norm BN (L2BN) by multiplying a scaling factor.\nExperiments on various convolutional neural networks (CNNs) and generative\nadversarial networks (GANs) reveal that L1BN maintains almost the same\naccuracies and convergence rates compared to L2BN but with higher computational\nefficiency. On FPGA platform, the proposed signum and absolute operations in\nL1BN can achieve 1.5$\\times$ speedup and save 50\\% power consumption, compared\nwith the original costly square and root operations, respectively. This\nhardware-friendly normalization method not only surpasses L2BN in speed, but\nalso simplify the hardware design of ASIC accelerators with higher energy\nefficiency. Last but not the least, L1BN promises a fully quantized training of\nDNNs, which is crucial to future adaptive terminal devices.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 08:29:16 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Wu", "Shuang", ""], ["Li", "Guoqi", ""], ["Deng", "Lei", ""], ["Liu", "Liu", ""], ["Xie", "Yuan", ""], ["Shi", "Luping", ""]]}, {"id": "1802.09777", "submitter": "Niko Br\\\"ummer", "authors": "Niko Brummer and Anna Silnova and Lukas Burget and Themos Stafylakis", "title": "Gaussian meta-embeddings for efficient scoring of a heavy-tailed PLDA\n  model", "comments": "submittted to Odyssey 2018: The Speaker and Language Recognition\n  Workshop, Les Sables d'Olonne, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embeddings in machine learning are low-dimensional representations of complex\ninput patterns, with the property that simple geometric operations like\nEuclidean distances and dot products can be used for classification and\ncomparison tasks. The proposed meta-embeddings are special embeddings that live\nin more general inner product spaces. They are designed to propagate\nuncertainty to the final output in speaker recognition and similar\napplications. The familiar Gaussian PLDA model (GPLDA) can be re-formulated as\nan extractor for Gaussian meta-embeddings (GMEs), such that likelihood ratio\nscores are given by Hilbert space inner products between Gaussian likelihood\nfunctions. GMEs extracted by the GPLDA model have fixed precisions and do not\npropagate uncertainty. We show that a generalization to heavy-tailed PLDA gives\nGMEs with variable precisions, which do propagate uncertainty. Experiments on\nNIST SRE 2010 and 2016 show that the proposed method applied to i-vectors\nwithout length normalization is up to 20% more accurate than GPLDA applied to\nlength-normalized ivectors.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 08:55:05 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Brummer", "Niko", ""], ["Silnova", "Anna", ""], ["Burget", "Lukas", ""], ["Stafylakis", "Themos", ""]]}, {"id": "1802.09788", "submitter": "Longfei Li", "authors": "Li Wang, Chaochao Chen, Jun Zhou, Xiaolong Li", "title": "Time-sensitive Customer Churn Prediction based on PU Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast development of Internet companies throughout the world,\ncustomer churn has become a serious concern. To better help the companies\nretain their customers, it is important to build a customer churn prediction\nmodel to identify the customers who are most likely to churn ahead of time. In\nthis paper, we propose a Time-sensitive Customer Churn Prediction (TCCP)\nframework based on Positive and Unlabeled (PU) learning technique.\nSpecifically, we obtain the recent data by shortening the observation period,\nand start to train model as long as enough positive samples are collected,\nignoring the absence of the negative examples. We conduct thoroughly\nexperiments on real industry data from Alipay.com. The experimental results\ndemonstrate that TCCP outperforms the rule-based models and the traditional\nsupervised learning models.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 09:19:23 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Wang", "Li", ""], ["Chen", "Chaochao", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""]]}, {"id": "1802.09791", "submitter": "Davide Bacciu", "authors": "Davide Bacciu, Paulo J.G. Lisboa, Jos\\'e D. Mart\\'in, Ruxandra Stoean,\n  Alfredo Vellido", "title": "Bioinformatics and Medicine in the Era of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the current scientific advances in the life sciences have their\norigin in the intensive use of data for knowledge discovery. In no area this is\nso clear as in bioinformatics, led by technological breakthroughs in data\nacquisition technologies. It has been argued that bioinformatics could quickly\nbecome the field of research generating the largest data repositories, beating\nother data-intensive areas such as high-energy physics or astroinformatics.\nOver the last decade, deep learning has become a disruptive advance in machine\nlearning, giving new live to the long-standing connectionist paradigm in\nartificial intelligence. Deep learning methods are ideally suited to\nlarge-scale data and, therefore, they should be ideally suited to knowledge\ndiscovery in bioinformatics and biomedicine at large. In this brief paper, we\nreview key aspects of the application of deep learning in bioinformatics and\nmedicine, drawing from the themes covered by the contributions to an ESANN 2018\nspecial session devoted to this topic.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 09:41:44 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Bacciu", "Davide", ""], ["Lisboa", "Paulo J. G.", ""], ["Mart\u00edn", "Jos\u00e9 D.", ""], ["Stoean", "Ruxandra", ""], ["Vellido", "Alfredo", ""]]}, {"id": "1802.09802", "submitter": "Carlos Eduardo Rosar Kos Lassance", "authors": "Carlos Eduardo Rosar Kos Lassance, Jean-Charles Vialatte, Vincent\n  Gripon", "title": "Matching Convolutional Neural Networks without Priors about Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extension of Convolutional Neural Networks (CNNs) to\ngraph-structured data, including strided convolutions and data augmentation on\ngraphs.\n  Our method matches the accuracy of state-of-the-art CNNs when applied on\nimages, without any prior about their 2D regular structure.\n  On fMRI data, we obtain a significant gain in accuracy compared with existing\ngraph-based alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 10:01:55 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Lassance", "Carlos Eduardo Rosar Kos", ""], ["Vialatte", "Jean-Charles", ""], ["Gripon", "Vincent", ""]]}, {"id": "1802.09816", "submitter": "Guillaume Charpiat", "authors": "Armand Zampieri (TITANE), Guillaume Charpiat (TAU), Yuliya Tarabalka\n  (TITANE)", "title": "Coarse to fine non-rigid registration: a chain of scale-specific neural\n  networks for multimodal image alignment with application to remote sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle here the problem of multimodal image non-rigid registration, which\nis of prime importance in remote sensing and medical imaging. The difficulties\nencountered by classical registration approaches include feature design and\nslow optimization by gradient descent. By analyzing these methods, we note the\nsignificance of the notion of scale. We design easy-to-train,\nfully-convolutional neural networks able to learn scale-specific features. Once\nchained appropriately, they perform global registration in linear time, getting\nrid of gradient descent schemes by predicting directly the deformation.We show\ntheir performance in terms of quality and speed through various tasks of remote\nsensing multimodal image alignment. In particular, we are able to register\ncorrectly cadastral maps of buildings as well as road polylines onto RGB\nimages, and outperform current keypoint matching methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 10:47:06 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Zampieri", "Armand", "", "TITANE"], ["Charpiat", "Guillaume", "", "TAU"], ["Tarabalka", "Yuliya", "", "TITANE"]]}, {"id": "1802.09841", "submitter": "M\\'elanie Ducoffe", "authors": "Melanie Ducoffe, Frederic Precioso", "title": "Adversarial Active Learning for Deep Networks: a Margin Based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new active learning strategy designed for deep neural networks.\nThe goal is to minimize the number of data annotation queried from an oracle\nduring training. Previous active learning strategies scalable for deep networks\nwere mostly based on uncertain sample selection. In this work, we focus on\nexamples lying close to the decision boundary. Based on theoretical works on\nmargin theory for active learning, we know that such examples may help to\nconsiderably decrease the number of annotations. While measuring the exact\ndistance to the decision boundaries is intractable, we propose to rely on\nadversarial examples. We do not consider anymore them as a threat instead we\nexploit the information they provide on the distribution of the input space in\norder to approximate the distance to decision boundaries. We demonstrate\nempirically that adversarial active queries yield faster convergence of CNNs\ntrained on MNIST, the Shoe-Bag and the Quick-Draw datasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 12:02:33 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Ducoffe", "Melanie", ""], ["Precioso", "Frederic", ""]]}, {"id": "1802.09850", "submitter": "Anil Kumar Vadathya Mr", "authors": "Akshat Dave, Anil Kumar Vadathya, Ramana Subramanyam, Rahul Baburajan,\n  Kaushik Mitra", "title": "Solving Inverse Computational Imaging Problems using Deep Pixel-level\n  Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Signal reconstruction is a challenging aspect of computational imaging as it\noften involves solving ill-posed inverse problems. Recently, deep feed-forward\nneural networks have led to state-of-the-art results in solving various inverse\nimaging problems. However, being task specific, these networks have to be\nlearned for each inverse problem. On the other hand, a more flexible approach\nwould be to learn a deep generative model once and then use it as a signal\nprior for solving various inverse problems. We show that among the various\nstate of the art deep generative models, autoregressive models are especially\nsuitable for our purpose for the following reasons. First, they explicitly\nmodel the pixel level dependencies and hence are capable of reconstructing\nlow-level details such as texture patterns and edges better. Second, they\nprovide an explicit expression for the image prior which can then be used for\nMAP based inference along with the forward model. Third, they can model long\nrange dependencies in images which make them ideal for handling global\nmultiplexing as encountered in various compressive imaging systems. We\ndemonstrate the efficacy of our proposed approach in solving three\ncomputational imaging problems: Single Pixel Camera (SPC), LiSens and FlatCam.\nFor both real and simulated cases, we obtain better reconstructions than the\nstate-of-the-art methods in terms of perceptual and quantitative metrics.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 12:23:27 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 00:37:58 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Dave", "Akshat", ""], ["Vadathya", "Anil Kumar", ""], ["Subramanyam", "Ramana", ""], ["Baburajan", "Rahul", ""], ["Mitra", "Kaushik", ""]]}, {"id": "1802.09900", "submitter": "Di Tang", "authors": "Di Tang, XiaoFeng Wang, Kehuan Zhang", "title": "Query-Free Attacks on Industry-Grade Face Recognition Systems under\n  Resource Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To launch black-box attacks against a Deep Neural Network (DNN) based Face\nRecognition (FR) system, one needs to build \\textit{substitute} models to\nsimulate the target model, so the adversarial examples discovered from\nsubstitute models could also mislead the target model. Such\n\\textit{transferability} is achieved in recent studies through querying the\ntarget model to obtain data for training the substitute models. A real-world\ntarget, likes the FR system of law enforcement, however, is less accessible to\nthe adversary. To attack such a system, a substitute model with similar quality\nas the target model is needed to identify their common defects. This is hard\nsince the adversary often does not have the enough resources to train such a\npowerful model (hundreds of millions of images and rooms of GPUs are needed to\ntrain a commercial FR system).\n  We found in our research, however, that a resource-constrained adversary\ncould still effectively approximate the target model's capability to recognize\n\\textit{specific} individuals, by training \\textit{biased} substitute models on\nadditional images of those victims whose identities the attacker want to cover\nor impersonate. This is made possible by a new property we discovered, called\n\\textit{Nearly Local Linearity} (NLL), which models the observation that an\nideal DNN model produces the image representations (embeddings) whose distances\namong themselves truthfully describe the human perception of the differences\namong the input images. By simulating this property around the victim's images,\nwe significantly improve the transferability of black-box impersonation attacks\nby nearly 50\\%. Particularly, we successfully attacked a commercial system\ntrained over 20 million images, using 4 million images and 1/5 of the training\ntime but achieving 62\\% transferability in an impersonation attack and 89\\% in\na dodging attack.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 08:44:58 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 13:19:33 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Tang", "Di", ""], ["Wang", "XiaoFeng", ""], ["Zhang", "Kehuan", ""]]}, {"id": "1802.09901", "submitter": "Quentin Debard", "authors": "Quentin Debard, Christian Wolf, St\\'ephane Canu and Julien Arn\\'e", "title": "Learning to recognize touch gestures: recurrent vs. convolutional\n  features and dynamic sampling", "comments": "9 pages, 4 figures, accepted at the 13th IEEE Conference on Automatic\n  Face and Gesture Recognition (FG2018). Dataset available at\n  http://itekube7.itekube.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a fully automatic method for learning gestures on big touch\ndevices in a potentially multi-user context. The goal is to learn general\nmodels capable of adapting to different gestures, user styles and hardware\nvariations (e.g. device sizes, sampling frequencies and regularities).\n  Based on deep neural networks, our method features a novel dynamic sampling\nand temporal normalization component, transforming variable length gestures\ninto fixed length representations while preserving finger/surface contact\ntransitions, that is, the topology of the signal. This sequential\nrepresentation is then processed with a convolutional model capable, unlike\nrecurrent networks, of learning hierarchical representations with different\nlevels of abstraction.\n  To demonstrate the interest of the proposed method, we introduce a new touch\ngestures dataset with 6591 gestures performed by 27 people, which is, up to our\nknowledge, the first of its kind: a publicly available multi-touch gesture\ndataset for interaction.\n  We also tested our method on a standard dataset of symbolic touch gesture\nrecognition, the MMG dataset, outperforming the state of the art and reporting\nclose to perfect performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 10:24:48 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Debard", "Quentin", ""], ["Wolf", "Christian", ""], ["Canu", "St\u00e9phane", ""], ["Arn\u00e9", "Julien", ""]]}, {"id": "1802.09902", "submitter": "Amirsina Torfi", "authors": "Amirsina Torfi, Rouzbeh A. Shirvani, Sobhan Soleymani, Nasser M.\n  Nasrabadi", "title": "Attention-Based Guided Structured Sparsity of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning is aimed at imposing sparsity in a neural network\narchitecture by increasing the portion of zero-valued weights for reducing its\nsize regarding energy-efficiency consideration and increasing evaluation speed.\nIn most of the conducted research efforts, the sparsity is enforced for network\npruning without any attention to the internal network characteristics such as\nunbalanced outputs of the neurons or more specifically the distribution of the\nweights and outputs of the neurons. That may cause severe accuracy drop due to\nuncontrolled sparsity. In this work, we propose an attention mechanism that\nsimultaneously controls the sparsity intensity and supervised network pruning\nby keeping important information bottlenecks of the network to be active. On\nCIFAR-10, the proposed method outperforms the best baseline method by 6% and\nreduced the accuracy drop by 2.6x at the same level of sparsity.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 04:24:49 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 18:24:53 GMT"}, {"version": "v3", "created": "Sun, 10 Jun 2018 17:58:27 GMT"}, {"version": "v4", "created": "Sat, 14 Jul 2018 17:47:49 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Torfi", "Amirsina", ""], ["Shirvani", "Rouzbeh A.", ""], ["Soleymani", "Sobhan", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "1802.09905", "submitter": "Nicolas Keriven", "authors": "Nicolas Keriven, R\\'emi Gribonval (PANAMA)", "title": "Instance Optimal Decoding and the Restricted Isometry Property", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/1131/1/012002", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the question of information preservation in\nill-posed, non-linear inverse problems, assuming that the measured data is\nclose to a low-dimensional model set. We provide necessary and sufficient\nconditions for the existence of a so-called instance optimal decoder, i.e.,\nthat is robust to noise and modelling error. Inspired by existing results in\ncompressive sensing, our analysis is based on a (Lower) Restricted Isometry\nProperty (LRIP), formulated in a non-linear fashion. We also provide sufficient\nconditions for non-uniform recovery with random measurement operators, with a\nnew formulation of the LRIP. We finish by describing typical strategies to\nprove the LRIP in both linear and non-linear cases, and illustrate our results\nby studying the invertibility of a one-layer neural net with random weights.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 14:31:01 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 10:06:57 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Keriven", "Nicolas", "", "PANAMA"], ["Gribonval", "R\u00e9mi", "", "PANAMA"]]}, {"id": "1802.09914", "submitter": "Mircea Andrecut Dr", "authors": "M. Andrecut", "title": "High-Dimensional Vector Semantics", "comments": "12 pages, 5 figures, Int. J. Mod. Phys. C, 2018", "journal-ref": null, "doi": "10.1142/S0129183118500158", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the \"vector semantics\" problem from the perspective\nof \"almost orthogonal\" property of high-dimensional random vectors. We show\nthat this intriguing property can be used to \"memorize\" random vectors by\nsimply adding them, and we provide an efficient probabilistic solution to the\nset membership problem. Also, we discuss several applications to word context\nvector embeddings, document sentences similarity, and spam filtering.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 16:50:16 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Andrecut", "M.", ""]]}, {"id": "1802.09917", "submitter": "Zhaobin Mo", "authors": "Zhaobin Mo, Sisi Li, Diange Yang, Ding Zhao", "title": "Extraction of V2V Encountering Scenarios from Naturalistic Driving\n  Database", "comments": "6 pages; 11 figures; Submitted to International Symposium on Advanced\n  Vehicle Control, Beijing, China, July 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is necessary to thoroughly evaluate the effectiveness and safety of\nConnected Vehicles (CVs) algorithm before their release and deployment. Current\nevaluation approach mainly relies on simulation platform with the\nsingle-vehicle driving model. The main drawback of it is the lack of network\nrealism. To overcome this problem, we extract naturalistic V2V encounters data\nfrom the database, and then separate the primary vehicle encounter category by\nclustering. A fast mining algorithm is proposed that can be applied to parallel\nquery for further process acceleration. 4,500 encounters are mined from a 275\nGB database collected in the Safety Pilot Model Program in Ann Arbor Michigan,\nUSA. K-means and Dynamic Time Warping (DTW) are used in clustering. Results\nshow this method can quickly mine and cluster primary driving scenarios from a\nlarge database. Our results separate the car-following, intersection and\nby-passing, which are the primary category of the vehicle encounter. We\nanticipate the work in the essay can become a general method to effectively\nextract vehicle encounters from any existing database that contains vehicular\nGPS information. What's more, the naturalistic data of different vehicle\nencounters can be applied in Connected Vehicles evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 14:40:04 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 16:22:25 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Mo", "Zhaobin", ""], ["Li", "Sisi", ""], ["Yang", "Diange", ""], ["Zhao", "Ding", ""]]}, {"id": "1802.09932", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, Kaiwen Zhou, Hongying Liu, James Cheng, Ivor W. Tsang,\n  Lijun Zhang, Dacheng Tao, Licheng Jiao", "title": "VR-SGD: A Simple Stochastic Variance Reduction Method for Machine\n  Learning", "comments": "46 pages, 25 figures. IEEE Transactions on Knowledge and Data\n  Engineering, accepted in October, 2018. arXiv admin note: substantial text\n  overlap with arXiv:1704.04966", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple variant of the original SVRG, called\nvariance reduced stochastic gradient descent (VR-SGD). Unlike the choices of\nsnapshot and starting points in SVRG and its proximal variant, Prox-SVRG, the\ntwo vectors of VR-SGD are set to the average and last iterate of the previous\nepoch, respectively. The settings allow us to use much larger learning rates,\nand also make our convergence analysis more challenging. We also design two\ndifferent update rules for smooth and non-smooth objective functions,\nrespectively, which means that VR-SGD can tackle non-smooth and/or non-strongly\nconvex problems directly without any reduction techniques. Moreover, we analyze\nthe convergence properties of VR-SGD for strongly convex problems, which show\nthat VR-SGD attains linear convergence. Different from its counterparts that\nhave no convergence guarantees for non-strongly convex problems, we also\nprovide the convergence guarantees of VR-SGD for this case, and empirically\nverify that VR-SGD with varying learning rates achieves similar performance to\nits momentum accelerated variant that has the optimal convergence rate\n$\\mathcal{O}(1/T^2)$. Finally, we apply VR-SGD to solve various machine\nlearning problems, such as convex and non-convex empirical risk minimization,\nand leading eigenvalue computation. Experimental results show that VR-SGD\nconverges significantly faster than SVRG and Prox-SVRG, and usually outperforms\nstate-of-the-art accelerated methods, e.g., Katyusha.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 12:56:07 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 15:03:47 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Shang", "Fanhua", ""], ["Zhou", "Kaiwen", ""], ["Liu", "Hongying", ""], ["Cheng", "James", ""], ["Tsang", "Ivor W.", ""], ["Zhang", "Lijun", ""], ["Tao", "Dacheng", ""], ["Jiao", "Licheng", ""]]}, {"id": "1802.09933", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, Yuanyuan Liu, Kaiwen Zhou, James Cheng, Kelvin K.W. Ng,\n  Yuichi Yoshida", "title": "Guaranteed Sufficient Decrease for Stochastic Variance Reduced Gradient\n  Optimization", "comments": "24 pages, 10 figures, AISTATS 2018. arXiv admin note: text overlap\n  with arXiv:1703.06807", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel sufficient decrease technique for\nstochastic variance reduced gradient descent methods such as SVRG and SAGA. In\norder to make sufficient decrease for stochastic optimization, we design a new\nsufficient decrease criterion, which yields sufficient decrease versions of\nstochastic variance reduction algorithms such as SVRG-SD and SAGA-SD as a\nbyproduct. We introduce a coefficient to scale current iterate and to satisfy\nthe sufficient decrease property, which takes the decisions to shrink, expand\nor even move in the opposite direction, and then give two specific update rules\nof the coefficient for Lasso and ridge regression. Moreover, we analyze the\nconvergence properties of our algorithms for strongly convex problems, which\nshow that our algorithms attain linear convergence rates. We also provide the\nconvergence guarantees of our algorithms for non-strongly convex problems. Our\nexperimental results further verify that our algorithms achieve significantly\nbetter performance than their counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 03:04:50 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Shang", "Fanhua", ""], ["Liu", "Yuanyuan", ""], ["Zhou", "Kaiwen", ""], ["Cheng", "James", ""], ["Ng", "Kelvin K. W.", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "1802.09941", "submitter": "Tal Ben-Nun", "authors": "Tal Ben-Nun, Torsten Hoefler", "title": "Demystifying Parallel and Distributed Deep Learning: An In-Depth\n  Concurrency Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are becoming an important tool in modern\ncomputing applications. Accelerating their training is a major challenge and\ntechniques range from distributed algorithms to low-level circuit design. In\nthis survey, we describe the problem from a theoretical perspective, followed\nby approaches for its parallelization. We present trends in DNN architectures\nand the resulting implications on parallelization strategies. We then review\nand model the different types of concurrency in DNNs: from the single operator,\nthrough parallelism in network inference and training, to distributed deep\nlearning. We discuss asynchronous stochastic optimization, distributed system\narchitectures, communication schemes, and neural architecture search. Based on\nthose approaches, we extrapolate potential directions for parallelism in deep\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 08:47:34 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2018 08:36:28 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Ben-Nun", "Tal", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1802.09957", "submitter": "Spiros Georgakopoulos", "authors": "Spiros V. Georgakopoulos, Sotiris K. Tasoulis, Aristidis G. Vrahatis\n  and Vassilis P. Plagianakos", "title": "Convolutional Neural Networks for Toxic Comment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flood of information is produced in a daily basis through the global Internet\nusage arising from the on-line interactive communications among users. While\nthis situation contributes significantly to the quality of human life,\nunfortunately it involves enormous dangers, since on-line texts with high\ntoxicity can cause personal attacks, on-line harassment and bullying behaviors.\nThis has triggered both industrial and research community in the last few years\nwhile there are several tries to identify an efficient model for on-line toxic\ncomment prediction. However, these steps are still in their infancy and new\napproaches and frameworks are required. On parallel, the data explosion that\nappears constantly, makes the construction of new machine learning\ncomputational tools for managing this information, an imperative need.\nThankfully advances in hardware, cloud computing and big data management allow\nthe development of Deep Learning approaches appearing very promising\nperformance so far. For text classification in particular the use of\nConvolutional Neural Networks (CNN) have recently been proposed approaching\ntext analytics in a modern manner emphasizing in the structure of words in a\ndocument. In this work, we employ this approach to discover toxic comments in a\nlarge pool of documents provided by a current Kaggle's competition regarding\nWikipedia's talk page edits. To justify this decision we choose to compare CNNs\nagainst the traditional bag-of-words approach for text analysis combined with a\nselection of algorithms proven to be very effective in text classification. The\nreported results provide enough evidence that CNN enhance toxic comment\nclassification reinforcing research interest towards this direction.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 15:11:28 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Georgakopoulos", "Spiros V.", ""], ["Tasoulis", "Sotiris K.", ""], ["Vrahatis", "Aristidis G.", ""], ["Plagianakos", "Vassilis P.", ""]]}, {"id": "1802.09963", "submitter": "Cheng Mao", "authors": "Cheng Mao, Ashwin Pananjady, Martin J. Wainwright", "title": "Breaking the $1/\\sqrt{n}$ Barrier: Faster Rates for Permutation-based\n  Models in Polynomial Time", "comments": "30 pages, 1 figure. Accepted for presentation at Conference on\n  Learning Theory (COLT) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications, including rank aggregation and crowd-labeling, can be\nmodeled in terms of a bivariate isotonic matrix with unknown permutations\nacting on its rows and columns. We consider the problem of estimating such a\nmatrix based on noisy observations of a subset of its entries, and design and\nanalyze a polynomial-time algorithm that improves upon the state of the art. In\nparticular, our results imply that any such $n \\times n$ matrix can be\nestimated efficiently in the normalized Frobenius norm at rate\n$\\widetilde{\\mathcal O}(n^{-3/4})$, thus narrowing the gap between\n$\\widetilde{\\mathcal O}(n^{-1})$ and $\\widetilde{\\mathcal O}(n^{-1/2})$, which\nwere hitherto the rates of the most statistically and computationally efficient\nmethods, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 15:26:15 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 04:19:26 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 15:52:59 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Mao", "Cheng", ""], ["Pananjady", "Ashwin", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1802.09979", "submitter": "Jeffrey Pennington", "authors": "Jeffrey Pennington, Samuel S. Schoenholz, Surya Ganguli", "title": "The Emergence of Spectral Universality in Deep Networks", "comments": "17 pages, 4 figures. Appearing at the 21st International Conference\n  on Artificial Intelligence and Statistics (AISTATS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that tight concentration of the entire spectrum of\nsingular values of a deep network's input-output Jacobian around one at\ninitialization can speed up learning by orders of magnitude. Therefore, to\nguide important design choices, it is important to build a full theoretical\nunderstanding of the spectra of Jacobians at initialization. To this end, we\nleverage powerful tools from free probability theory to provide a detailed\nanalytic understanding of how a deep network's Jacobian spectrum depends on\nvarious hyperparameters including the nonlinearity, the weight and bias\ndistributions, and the depth. For a variety of nonlinearities, our work reveals\nthe emergence of new universal limiting spectral distributions that remain\nconcentrated around one even as the depth goes to infinity.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 15:54:57 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Pennington", "Jeffrey", ""], ["Schoenholz", "Samuel S.", ""], ["Ganguli", "Surya", ""]]}, {"id": "1802.10026", "submitter": "Andrew Wilson", "authors": "Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry Vetrov,\n  Andrew Gordon Wilson", "title": "Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs", "comments": "Appears at Advances in Neural Information Processing Systems (NIPS),\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The loss functions of deep neural networks are complex and their geometric\nproperties are not well understood. We show that the optima of these complex\nloss functions are in fact connected by simple curves over which training and\ntest accuracy are nearly constant. We introduce a training procedure to\ndiscover these high-accuracy pathways between modes. Inspired by this new\ngeometric insight, we also propose a new ensembling method entitled Fast\nGeometric Ensembling (FGE). Using FGE we can train high-performing ensembles in\nthe time required to train a single model. We achieve improved performance\ncompared to the recent state-of-the-art Snapshot Ensembles, on CIFAR-10,\nCIFAR-100, and ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 17:13:28 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 13:53:29 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 00:16:34 GMT"}, {"version": "v4", "created": "Tue, 30 Oct 2018 11:39:49 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Garipov", "Timur", ""], ["Izmailov", "Pavel", ""], ["Podoprikhin", "Dmitrii", ""], ["Vetrov", "Dmitry", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1802.10031", "submitter": "George Tucker", "authors": "George Tucker, Surya Bhupatiraju, Shixiang Gu, Richard E. Turner,\n  Zoubin Ghahramani, Sergey Levine", "title": "The Mirage of Action-Dependent Baselines in Reinforcement Learning", "comments": "Updated to ICML final submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are a widely used class of model-free reinforcement\nlearning algorithms where a state-dependent baseline is used to reduce gradient\nestimator variance. Several recent papers extend the baseline to depend on both\nthe state and action and suggest that this significantly reduces variance and\nimproves sample efficiency without introducing bias into the gradient\nestimates. To better understand this development, we decompose the variance of\nthe policy gradient estimator and numerically show that learned\nstate-action-dependent baselines do not in fact reduce variance over a\nstate-dependent baseline in commonly tested benchmark domains. We confirm this\nunexpected result by reviewing the open-source code accompanying these prior\npapers, and show that subtle implementation decisions cause deviations from the\nmethods presented in the papers and explain the source of the previously\nobserved empirical gains. Furthermore, the variance decomposition highlights\nareas for improvement, which we demonstrate by illustrating a simple change to\nthe typical value function parameterization that can significantly improve\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 17:16:48 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 17:51:12 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 18:57:02 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Tucker", "George", ""], ["Bhupatiraju", "Surya", ""], ["Gu", "Shixiang", ""], ["Turner", "Richard E.", ""], ["Ghahramani", "Zoubin", ""], ["Levine", "Sergey", ""]]}, {"id": "1802.10055", "submitter": "Abdul Wahab", "authors": "Jaejun Yoo and Abdul Wahab and Jong Chul Ye", "title": "A Mathematical Framework for Deep Learning in Elastic Source Imaging", "comments": "28 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An inverse elastic source problem with sparse measurements is of concern. A\ngeneric mathematical framework is proposed which incorporates a low-\ndimensional manifold regularization in the conventional source reconstruction\nalgorithms thereby enhancing their performance with sparse datasets. It is\nrigorously established that the proposed framework is equivalent to the\nso-called \\emph{deep convolutional framelet expansion} in machine learning\nliterature for inverse problems. Apposite numerical examples are furnished to\nsubstantiate the efficacy of the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 18:14:00 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 15:25:36 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 23:17:48 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Yoo", "Jaejun", ""], ["Wahab", "Abdul", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1802.10077", "submitter": "Thee Chanyaswad", "authors": "Thee Chanyaswad, Alex Dytso, H. Vincent Poor, Prateek Mittal", "title": "A Differential Privacy Mechanism Design Under Matrix-Valued Query", "comments": "arXiv admin note: substantial text overlap with arXiv:1801.00823", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, differential privacy mechanism design has been tailored for a\nscalar-valued query function. Although many mechanisms such as the Laplace and\nGaussian mechanisms can be extended to a matrix-valued query function by adding\ni.i.d. noise to each element of the matrix, this method is often sub-optimal as\nit forfeits an opportunity to exploit the structural characteristics typically\nassociated with matrix analysis. In this work, we consider the design of\ndifferential privacy mechanism specifically for a matrix-valued query function.\nThe proposed solution is to utilize a matrix-variate noise, as opposed to the\ntraditional scalar-valued noise. Particularly, we propose a novel differential\nprivacy mechanism called the Matrix-Variate Gaussian (MVG) mechanism, which\nadds a matrix-valued noise drawn from a matrix-variate Gaussian distribution.\nWe prove that the MVG mechanism preserves $(\\epsilon,\\delta)$-differential\nprivacy, and show that it allows the structural characteristics of the\nmatrix-valued query function to naturally be exploited. Furthermore, due to the\nmulti-dimensional nature of the MVG mechanism and the matrix-valued query, we\nintroduce the concept of directional noise, which can be utilized to mitigate\nthe impact the noise has on the utility of the query. Finally, we demonstrate\nthe performance of the MVG mechanism and the advantages of directional noise\nusing three matrix-valued queries on three privacy-sensitive datasets. We find\nthat the MVG mechanism notably outperforms four previous state-of-the-art\napproaches, and provides comparable utility to the non-private baseline. Our\nwork thus presents a promising prospect for both future research and\nimplementation of differential privacy for matrix-valued query functions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 19:54:14 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Chanyaswad", "Thee", ""], ["Dytso", "Alex", ""], ["Poor", "H. Vincent", ""], ["Mittal", "Prateek", ""]]}, {"id": "1802.10123", "submitter": "Steffen Wiewel", "authors": "Steffen Wiewel, Moritz Becher, Nils Thuerey", "title": "Latent-space Physics: Towards Learning the Temporal Evolution of Fluid\n  Flow", "comments": "Eurographics 2019, additional materials:\n  https://ge.in.tum.de/publications/latent-space-physics/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for the data-driven inference of temporal evolutions of\nphysical functions with deep learning. More specifically, we target fluid\nflows, i.e. Navier-Stokes problems, and we propose a novel LSTM-based approach\nto predict the changes of pressure fields over time. The central challenge in\nthis context is the high dimensionality of Eulerian space-time data sets. We\ndemonstrate for the first time that dense 3D+time functions of physics system\ncan be predicted within the latent spaces of neural networks, and we arrive at\na neural-network based simulation algorithm with significant practical\nspeed-ups. We highlight the capabilities of our method with a series of complex\nliquid simulations, and with a set of single-phase buoyancy simulations. With a\nset of trained networks, our method is more than two orders of magnitudes\nfaster than a traditional pressure solver. Additionally, we present and discuss\na series of detailed evaluations for the different components of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 19:18:43 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 16:04:35 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 09:58:44 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Wiewel", "Steffen", ""], ["Becher", "Moritz", ""], ["Thuerey", "Nils", ""]]}, {"id": "1802.10151", "submitter": "Amjad Almahairi", "authors": "Amjad Almahairi, Sai Rajeswar, Alessandro Sordoni, Philip Bachman and\n  Aaron Courville", "title": "Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning inter-domain mappings from unpaired data can improve performance in\nstructured prediction tasks, such as image segmentation, by reducing the need\nfor paired data. CycleGAN was recently proposed for this problem, but\ncritically assumes the underlying inter-domain mapping is approximately\ndeterministic and one-to-one. This assumption renders the model ineffective for\ntasks requiring flexible, many-to-many mappings. We propose a new model, called\nAugmented CycleGAN, which learns many-to-many mappings between domains. We\nexamine Augmented CycleGAN qualitatively and quantitatively on several image\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 20:29:20 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 19:05:45 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Almahairi", "Amjad", ""], ["Rajeswar", "Sai", ""], ["Sordoni", "Alessandro", ""], ["Bachman", "Philip", ""], ["Courville", "Aaron", ""]]}, {"id": "1802.10168", "submitter": "Hamza Anwar", "authors": "Hamza Anwar and Quanyan Zhu", "title": "ADMM-based Networked Stochastic Variational Inference", "comments": "to be submitted for publishing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the recent advances in \"Big Data\" modeling and prediction tasks,\nvariational Bayesian estimation has gained popularity due to their ability to\nprovide exact solutions to approximate posteriors. One key technique for\napproximate inference is stochastic variational inference (SVI). SVI poses\nvariational inference as a stochastic optimization problem and solves it\niteratively using noisy gradient estimates. It aims to handle massive data for\npredictive and classification tasks by applying complex Bayesian models that\nhave observed as well as latent variables. This paper aims to decentralize it\nallowing parallel computation, secure learning and robustness benefits. We use\nAlternating Direction Method of Multipliers in a top-down setting to develop a\ndistributed SVI algorithm such that independent learners running inference\nalgorithms only require sharing the estimated model parameters instead of their\nprivate datasets. Our work extends the distributed SVI-ADMM algorithm that we\nfirst propose, to an ADMM-based networked SVI algorithm in which not only are\nthe learners working distributively but they share information according to\nrules of a graph by which they form a network. This kind of work lies under the\numbrella of `deep learning over networks' and we verify our algorithm for a\ntopic-modeling problem for corpus of Wikipedia articles. We illustrate the\nresults on latent Dirichlet allocation (LDA) topic model in large document\nclassification, compare performance with the centralized algorithm, and use\nnumerical experiments to corroborate the analytical results.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 21:11:56 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Anwar", "Hamza", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1802.10171", "submitter": "Ziyan Wu", "authors": "Kunpeng Li, Ziyan Wu, Kuan-Chuan Peng, Jan Ernst, Yun Fu", "title": "Tell Me Where to Look: Guided Attention Inference Network", "comments": "Accepted in CVPR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly supervised learning with only coarse labels can obtain visual\nexplanations of deep neural network such as attention maps by back-propagating\ngradients. These attention maps are then available as priors for tasks such as\nobject localization and semantic segmentation. In one common framework we\naddress three shortcomings of previous approaches in modeling such attention\nmaps: We (1) first time make attention maps an explicit and natural component\nof the end-to-end training, (2) provide self-guidance directly on these maps by\nexploring supervision form the network itself to improve them, and (3)\nseamlessly bridge the gap between using weak and extra supervision if\navailable. Despite its simplicity, experiments on the semantic segmentation\ntask demonstrate the effectiveness of our methods. We clearly surpass the\nstate-of-the-art on Pascal VOC 2012 val. and test set. Besides, the proposed\nframework provides a way not only explaining the focus of the learner but also\nfeeding back with direct guidance towards specific tasks. Under mild\nassumptions our method can also be understood as a plug-in to existing weakly\nsupervised learners to improve their generalization performance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 21:17:30 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Li", "Kunpeng", ""], ["Wu", "Ziyan", ""], ["Peng", "Kuan-Chuan", ""], ["Ernst", "Jan", ""], ["Fu", "Yun", ""]]}, {"id": "1802.10172", "submitter": "Randall Balestriero", "authors": "Randall Balestriero, Herve Glotin, Richard Baraniuk", "title": "Semi-Supervised Learning Enabled by Multiscale Deep Neural Network\n  Inversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) provide state-of-the-art solutions in several\ndifficult machine perceptual tasks. However, their performance relies on the\navailability of a large set of labeled training data, which limits the breadth\nof their applicability. Hence, there is a need for new {\\em semi-supervised\nlearning} methods for DNNs that can leverage both (a small amount of) labeled\nand unlabeled training data. In this paper, we develop a general loss function\nenabling DNNs of any topology to be trained in a semi-supervised manner without\nextra hyper-parameters. As opposed to current semi-supervised techniques based\non topology-specific or unstable approaches, ours is both robust and general.\nWe demonstrate that our approach reaches state-of-the-art performance on the\nSVHN ($9.82\\%$ test error, with $500$ labels and wide Resnet) and CIFAR10\n(16.38% test error, with 8000 labels and sigmoid convolutional neural network)\ndata sets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 21:27:01 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Balestriero", "Randall", ""], ["Glotin", "Herve", ""], ["Baraniuk", "Richard", ""]]}, {"id": "1802.10174", "submitter": "Ya-Ping Hsieh", "authors": "Ya-Ping Hsieh and Ali Kavis and Paul Rolland and Volkan Cevher", "title": "Mirrored Langevin Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sampling from constrained distributions, which has\nposed significant challenges to both non-asymptotic analysis and algorithmic\ndesign. We propose a unified framework, which is inspired by the classical\nmirror descent, to derive novel first-order sampling schemes. We prove that,\nfor a general target distribution with strongly convex potential, our framework\nimplies the existence of a first-order algorithm achieving\n$\\tilde{O}(\\epsilon^{-2}d)$ convergence, suggesting that the state-of-the-art\n$\\tilde{O}(\\epsilon^{-6}d^5)$ can be vastly improved. With the important Latent\nDirichlet Allocation (LDA) application in mind, we specialize our algorithm to\nsample from Dirichlet posteriors, and derive the first non-asymptotic\n$\\tilde{O}(\\epsilon^{-2}d^2)$ rate for first-order sampling. We further extend\nour framework to the mini-batch setting and prove convergence rates when only\nstochastic gradients are available. Finally, we report promising experimental\nresults for LDA on real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 21:31:53 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 15:01:55 GMT"}, {"version": "v3", "created": "Sat, 14 Apr 2018 19:45:18 GMT"}, {"version": "v4", "created": "Fri, 18 May 2018 13:37:17 GMT"}, {"version": "v5", "created": "Wed, 30 Dec 2020 13:59:47 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Hsieh", "Ya-Ping", ""], ["Kavis", "Ali", ""], ["Rolland", "Paul", ""], ["Cevher", "Volkan", ""]]}, {"id": "1802.10203", "submitter": "Jiangjun Tang", "authors": "Jiangjun Tang and Hussein A. Abbass", "title": "Behavioral Learning of Aircraft Landing Sequencing Using a Society of\n  Probabilistic Finite State Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air Traffic Control (ATC) is a complex safety critical environment. A tower\ncontroller would be making many decisions in real-time to sequence aircraft.\nWhile some optimization tools exist to help the controller in some airports,\neven in these situations, the real sequence of the aircraft adopted by the\ncontroller is significantly different from the one proposed by the optimization\nalgorithm. This is due to the very dynamic nature of the environment. The\nobjective of this paper is to test the hypothesis that one can learn from the\nsequence adopted by the controller some strategies that can act as heuristics\nin decision support tools for aircraft sequencing. This aim is tested in this\npaper by attempting to learn sequences generated from a well-known sequencing\nmethod that is being used in the real world. The approach relies on a genetic\nalgorithm (GA) to learn these sequences using a society Probabilistic\nFinite-state Machines (PFSMs). Each PFSM learns a different sub-space; thus,\ndecomposing the learning problem into a group of agents that need to work\ntogether to learn the overall problem. Three sequence metrics (Levenshtein,\nHamming and Position distances) are compared as the fitness functions in GA. As\nthe results suggest, it is possible to learn the behavior of the\nalgorithm/heuristic that generated the original sequence from very limited\ninformation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 23:07:52 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Tang", "Jiangjun", ""], ["Abbass", "Hussein A.", ""]]}, {"id": "1802.10206", "submitter": "Jiangjun Tang", "authors": "Jiangjun Tang, George Leu and Hussein Abbass", "title": "Networking the Boids is More Robust Against Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm behavior using Boids-like models has been studied primarily using\nclose-proximity spatial sensory information (e.g. vision range). In this study,\nwe propose a novel approach in which the classic definition of\nboids\\textquoteright \\ neighborhood that relies on sensory perception and\nEuclidian space locality is replaced with graph-theoretic network-based\nproximity mimicking communication and social networks. We demonstrate that\nnetworking the boids leads to faster swarming and higher quality of the\nformation. We further investigate the effect of adversarial learning, whereby\nan observer attempts to reverse engineer the dynamics of the swarm through\nobserving its behavior. The results show that networking the swarm demonstrated\na more robust approach against adversarial learning than a local-proximity\nneighborhood structure.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 23:20:16 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Tang", "Jiangjun", ""], ["Leu", "George", ""], ["Abbass", "Hussein", ""]]}, {"id": "1802.10214", "submitter": "Ding Zhao", "authors": "Sisi Li, Wenshuo Wang, Zhaobin Mo and Ding Zhao", "title": "Cluster Naturalistic Driving Encounters Using Deep Unsupervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge from driving encounters could help self-driving cars make\nappropriate decisions when driving in complex settings with nearby vehicles\nengaged. This paper develops an unsupervised classifier to group naturalistic\ndriving encounters into distinguishable clusters by combining an auto-encoder\nwith k-means clustering (AE-kMC). The effectiveness of AE-kMC was validated\nusing the data of 10,000 naturalistic driving encounters which were collected\nby the University of Michigan, Ann Arbor in the past five years. We compare our\ndeveloped method with the $k$-means clustering methods and experimental results\ndemonstrate that the AE-kMC method outperforms the original k-means clustering\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 00:08:28 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 02:28:31 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Li", "Sisi", ""], ["Wang", "Wenshuo", ""], ["Mo", "Zhaobin", ""], ["Zhao", "Ding", ""]]}, {"id": "1802.10215", "submitter": "Sanjit Bhat", "authors": "Sanjit Bhat and David Lu and Albert Kwon and Srinivas Devadas", "title": "Var-CNN: A Data-Efficient Website Fingerprinting Attack Based on Deep\n  Learning", "comments": "Original paper split into \"Var-CNN: A Data-Efficient Website\n  Fingerprinting Attack Based on Deep Learning\" (PETS 2019) and \"DynaFlow: An\n  Efficient Website Fingerprinting Defense Based on Dynamically-Adjusting\n  Flows\" (WPES 2018)", "journal-ref": "Proceedings on Privacy Enhancing Technologies. 2019 (4):292-310", "doi": "10.2478/popets-2019-0070", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been several works that use website\nfingerprinting techniques to enable a local adversary to determine which\nwebsite a Tor user visits. While the current state-of-the-art attack, which\nuses deep learning, outperforms prior art with medium to large amounts of data,\nit attains marginal to no accuracy improvements when both use small amounts of\ntraining data. In this work, we propose Var-CNN, a website fingerprinting\nattack that leverages deep learning techniques along with novel insights\nspecific to packet sequence classification. In open-world settings with large\namounts of data, Var-CNN attains over $1\\%$ higher true positive rate (TPR)\nthan state-of-the-art attacks while achieving $4\\times$ lower false positive\nrate (FPR). Var-CNN's improvements are especially notable in low-data\nscenarios, where it reduces the FPR of prior art by $3.12\\%$ while increasing\nthe TPR by $13\\%$. Overall, insights used to develop Var-CNN can be applied to\nfuture deep learning based attacks, and substantially reduce the amount of\ntraining data needed to perform a successful website fingerprinting attack.\nThis shortens the time needed for data collection and lowers the likelihood of\nhaving data staleness issues.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 00:21:09 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 23:37:57 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Bhat", "Sanjit", ""], ["Lu", "David", ""], ["Kwon", "Albert", ""], ["Devadas", "Srinivas", ""]]}, {"id": "1802.10217", "submitter": "Rachit Dubey", "authors": "Rachit Dubey, Pulkit Agrawal, Deepak Pathak, Thomas L. Griffiths, and\n  Alexei A. Efros", "title": "Investigating Human Priors for Playing Video Games", "comments": "ICML 2018", "journal-ref": "ICML 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  What makes humans so good at solving seemingly complex video games? Unlike\ncomputers, humans bring in a great deal of prior knowledge about the world,\nenabling efficient decision making. This paper investigates the role of human\npriors for solving video games. Given a sample game, we conduct a series of\nablation studies to quantify the importance of various priors on human\nperformance. We do this by modifying the video game environment to\nsystematically mask different types of visual information that could be used by\nhumans as priors. We find that removal of some prior knowledge causes a drastic\ndegradation in the speed with which human players solve the game, e.g. from 2\nminutes to over 20 minutes. Furthermore, our results indicate that general\npriors, such as the importance of objects and visual consistency, are critical\nfor efficient game-play. Videos and the game manipulations are available at\nhttps://rach0012.github.io/humanRL_website/\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 00:26:44 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 20:32:21 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 02:33:41 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Dubey", "Rachit", ""], ["Agrawal", "Pulkit", ""], ["Pathak", "Deepak", ""], ["Griffiths", "Thomas L.", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1802.10235", "submitter": "Chaoyue Liu", "authors": "Chaoyue Liu, Mikhail Belkin", "title": "Parametrized Accelerated Methods Free of Condition Number", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyses of accelerated (momentum-based) gradient descent usually assume\nbounded condition number to obtain exponential convergence rates. However, in\nmany real problems, e.g., kernel methods or deep neural networks, the condition\nnumber, even locally, can be unbounded, unknown or mis-estimated. This poses\nproblems in both implementing and analyzing accelerated algorithms. In this\npaper, we address this issue by proposing parametrized accelerated methods by\nconsidering the condition number as a free parameter. We provide spectral-level\nanalysis for several important accelerated algorithms, obtain explicit\nexpressions and improve worst case convergence rates. Moreover, we show that\nthose algorithm converge exponentially even when the condition number is\nunknown or mis-estimated.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 02:20:31 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Liu", "Chaoyue", ""], ["Belkin", "Mikhail", ""]]}, {"id": "1802.10237", "submitter": "Ali Moin", "authors": "Ali Moin, Andy Zhou, Abbas Rahimi, Simone Benatti, Alisha Menon, Senam\n  Tamakloe, Jonathan Ting, Natasha Yamamoto, Yasser Khan, Fred Burghardt, Luca\n  Benini, Ana C. Arias, Jan M. Rabaey", "title": "An EMG Gesture Recognition System with Flexible High-Density Sensors and\n  Brain-Inspired High-Dimensional Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EMG-based gesture recognition shows promise for human-machine interaction.\nSystems are often afflicted by signal and electrode variability which degrades\nperformance over time. We present an end-to-end system combating this\nvariability using a large-area, high-density sensor array and a robust\nclassification algorithm. EMG electrodes are fabricated on a flexible substrate\nand interfaced to a custom wireless device for 64-channel signal acquisition\nand streaming. We use brain-inspired high-dimensional (HD) computing for\nprocessing EMG features in one-shot learning. The HD algorithm is tolerant to\nnoise and electrode misplacement and can quickly learn from few gestures\nwithout gradient descent or back-propagation. We achieve an average\nclassification accuracy of 96.64% for five gestures, with only 7% degradation\nwhen training and testing across different days. Our system maintains this\naccuracy when trained with only three trials of gestures; it also demonstrates\ncomparable accuracy with the state-of-the-art when trained with one trial.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 02:37:01 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 17:38:05 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Moin", "Ali", ""], ["Zhou", "Andy", ""], ["Rahimi", "Abbas", ""], ["Benatti", "Simone", ""], ["Menon", "Alisha", ""], ["Tamakloe", "Senam", ""], ["Ting", "Jonathan", ""], ["Yamamoto", "Natasha", ""], ["Khan", "Yasser", ""], ["Burghardt", "Fred", ""], ["Benini", "Luca", ""], ["Arias", "Ana C.", ""], ["Rabaey", "Jan M.", ""]]}, {"id": "1802.10238", "submitter": "Benjamin Shickel", "authors": "Benjamin Shickel, Tyler J. Loftus, Lasith Adhikari, Tezcan\n  Ozrazgat-Baslanti, Azra Bihorac, and Parisa Rashidi", "title": "DeepSOFA: A Continuous Acuity Score for Critically Ill Patients using\n  Clinically Interpretable Deep Learning", "comments": null, "journal-ref": "Scientific Reports (2019) 9:1879", "doi": "10.1038/s41598-019-38491-0", "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods for assessing illness severity and predicting in-hospital\nmortality among critically ill patients require time-consuming, error-prone\ncalculations using static variable thresholds. These methods do not capitalize\non the emerging availability of streaming electronic health record data or\ncapture time-sensitive individual physiological patterns, a critical task in\nthe intensive care unit. We propose a novel acuity score framework (DeepSOFA)\nthat leverages temporal measurements and interpretable deep learning models to\nassess illness severity at any point during an ICU stay. We compare DeepSOFA\nwith SOFA (Sequential Organ Failure Assessment) baseline models using the same\nmodel inputs and find that at any point during an ICU admission, DeepSOFA\nyields significantly more accurate predictions of in-hospital mortality. A\nDeepSOFA model developed in a public database and validated in a single\ninstitutional cohort had a mean AUC for the entire ICU stay of 0.90 (95% CI\n0.90-0.91) compared with baseline SOFA models with mean AUC 0.79 (95% CI\n0.79-0.80) and 0.85 (95% CI 0.85-0.86). Deep models are well-suited to identify\nICU patients in need of life-saving interventions prior to the occurrence of an\nunexpected adverse event and inform shared decision-making processes among\npatients, providers, and families regarding goals of care and optimal resource\nutilization.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 02:39:02 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 02:04:16 GMT"}, {"version": "v3", "created": "Sun, 23 Dec 2018 01:33:57 GMT"}, {"version": "v4", "created": "Wed, 13 Feb 2019 18:16:07 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Shickel", "Benjamin", ""], ["Loftus", "Tyler J.", ""], ["Adhikari", "Lasith", ""], ["Ozrazgat-Baslanti", "Tezcan", ""], ["Bihorac", "Azra", ""], ["Rashidi", "Parisa", ""]]}, {"id": "1802.10264", "submitter": "Eric Jang", "authors": "Deirdre Quillen, Eric Jang, Ofir Nachum, Chelsea Finn, Julian Ibarz,\n  Sergey Levine", "title": "Deep Reinforcement Learning for Vision-Based Robotic Grasping: A\n  Simulated Comparative Evaluation of Off-Policy Methods", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore deep reinforcement learning algorithms for\nvision-based robotic grasping. Model-free deep reinforcement learning (RL) has\nbeen successfully applied to a range of challenging environments, but the\nproliferation of algorithms makes it difficult to discern which particular\napproach would be best suited for a rich, diverse task like grasping. To answer\nthis question, we propose a simulated benchmark for robotic grasping that\nemphasizes off-policy learning and generalization to unseen objects. Off-policy\nlearning enables utilization of grasping data over a wide variety of objects,\nand diversity is important to enable the method to generalize to new objects\nthat were not seen during training. We evaluate the benchmark tasks against a\nvariety of Q-function estimation methods, a method previously proposed for\nrobotic grasping with deep neural network models, and a novel approach based on\na combination of Monte Carlo return estimation and an off-policy correction.\nOur results indicate that several simple methods provide a surprisingly strong\ncompetitor to popular algorithms such as double Q-learning, and our analysis of\nstability sheds light on the relative tradeoffs between the algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 05:11:38 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 23:28:14 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Quillen", "Deirdre", ""], ["Jang", "Eric", ""], ["Nachum", "Ofir", ""], ["Finn", "Chelsea", ""], ["Ibarz", "Julian", ""], ["Levine", "Sergey", ""]]}, {"id": "1802.10275", "submitter": "Yuehaw Khoo", "authors": "Yuehaw Khoo, Jianfeng Lu, Lexing Ying", "title": "Solving for high dimensional committor functions using artificial neural\n  networks", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we propose a method based on artificial neural network to study\nthe transition between states governed by stochastic processes. In particular,\nwe aim for numerical schemes for the committor function, the central object of\ntransition path theory, which satisfies a high-dimensional Fokker-Planck\nequation. By working with the variational formulation of such partial\ndifferential equation and parameterizing the committor function in terms of a\nneural network, approximations can be obtained via optimizing the neural\nnetwork weights using stochastic algorithms. The numerical examples show that\nmoderate accuracy can be achieved for high-dimensional problems.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 06:16:33 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Khoo", "Yuehaw", ""], ["Lu", "Jianfeng", ""], ["Ying", "Lexing", ""]]}, {"id": "1802.10280", "submitter": "Xuhao Chen", "authors": "Xuhao Chen", "title": "Escoin: Efficient Sparse Convolutional Neural Network Inference on GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved remarkable accuracy in many artificial\nintelligence applications, e.g. computer vision, at the cost of a large number\nof parameters and high computational complexity. Weight pruning can compress\nDNN models by removing redundant parameters in the networks, but it brings\nsparsity in the weight matrix, and therefore makes the computation inefficient\non GPUs. Although pruning can remove more than 80% of the weights, it actually\nhurts inference performance (speed) when running models on GPUs.\n  Two major problems cause this unsatisfactory performance on GPUs. First,\nlowering convolution onto matrix multiplication reduces data reuse\nopportunities and wastes memory bandwidth. Second, the sparsity brought by\npruning makes the computation irregular, which leads to inefficiency when\nrunning on massively parallel GPUs. To overcome these two limitations, we\npropose Escort, an efficient sparse convolutional neural networks on GPUs.\nInstead of using the lowering method, we choose to compute the sparse\nconvolutions directly. We then orchestrate the parallelism and locality for the\ndirect sparse convolution kernel, and apply customized optimization techniques\nto further improve performance. Evaluation on NVIDIA GPUs show that Escort can\nimprove sparse convolution speed by 2.63x and 3.07x, and inference speed by\n1.43x and 1.69x, compared to CUBLAS and CUSPARSE respectively.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 06:31:45 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 21:11:27 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Chen", "Xuhao", ""]]}, {"id": "1802.10353", "submitter": "Sjoerd van Steenkiste", "authors": "Sjoerd van Steenkiste, Michael Chang, Klaus Greff, J\\\"urgen\n  Schmidhuber", "title": "Relational Neural Expectation Maximization: Unsupervised Discovery of\n  Objects and their Interactions", "comments": "Accepted to ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Common-sense physical reasoning is an essential ingredient for any\nintelligent agent operating in the real-world. For example, it can be used to\nsimulate the environment, or to infer the state of parts of the world that are\ncurrently unobserved. In order to match real-world conditions this causal\nknowledge must be learned without access to supervised data. To address this\nproblem we present a novel method that learns to discover objects and model\ntheir physical interactions from raw visual images in a purely\n\\emph{unsupervised} fashion. It incorporates prior knowledge about the\ncompositional nature of human perception to factor interactions between\nobject-pairs and learn efficiently. On videos of bouncing balls we show the\nsuperior modelling capabilities of our method compared to other unsupervised\nneural approaches that do not incorporate such prior knowledge. We demonstrate\nits ability to handle occlusion and show that it can extrapolate learned\nknowledge to scenes with different numbers of objects.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 10:55:36 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["van Steenkiste", "Sjoerd", ""], ["Chang", "Michael", ""], ["Greff", "Klaus", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1802.10393", "submitter": "Guilherme Wachs-Lopes", "authors": "Henrique X. Goulart, Guilherme A. Wachs-Lopes", "title": "A Bayesian Model for Activities Recommendation and Event Structure\n  Optimization Using Visitors Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In events that are composed by many activities, there is a problem that\ninvolves retrieve and management the information of visitors that are visiting\nthe activities. This management is crucial to find some activities that are\ndrawing attention of visitors; identify an ideal positioning for activities;\nwhich path is more frequented by visitors. In this work, these features are\nstudied using Complex Network theory. For the beginning, an artificial database\nwas generated to study the mentioned features. Secondly, this work shows a\nmethod to optimize the event structure that is better than a random method and\na recommendation system that achieves ~95% of accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 12:59:43 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Goulart", "Henrique X.", ""], ["Wachs-Lopes", "Guilherme A.", ""]]}, {"id": "1802.10410", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Tensor Decomposition for Compressing Recurrent Neural Network", "comments": "Accepted at IJCNN 2018. Source code URL:\n  https://github.com/androstj/tensor_rnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the machine learning fields, Recurrent Neural Network (RNN) has become a\npopular architecture for sequential data modeling. However, behind the\nimpressive performance, RNNs require a large number of parameters for both\ntraining and inference. In this paper, we are trying to reduce the number of\nparameters and maintain the expressive power from RNN simultaneously. We\nutilize several tensor decompositions method including CANDECOMP/PARAFAC (CP),\nTucker decomposition and Tensor Train (TT) to re-parameterize the Gated\nRecurrent Unit (GRU) RNN. We evaluate all tensor-based RNNs performance on\nsequence modeling tasks with a various number of parameters. Based on our\nexperiment results, TT-GRU achieved the best results in a various number of\nparameters compared to other decomposition methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 13:52:22 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 16:07:11 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1802.10440", "submitter": "Brenden Petersen", "authors": "Brenden K. Petersen, Jiachen Yang, Will S. Grathwohl, Chase Cockrell,\n  Claudio Santiago, Gary An, and Daniel M. Faissol", "title": "Precision medicine as a control problem: Using simulation and deep\n  reinforcement learning to discover adaptive, personalized multi-cytokine\n  therapy for sepsis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is a life-threatening condition affecting one million people per year\nin the US in which dysregulation of the body's own immune system causes damage\nto its tissues, resulting in a 28 - 50% mortality rate. Clinical trials for\nsepsis treatment over the last 20 years have failed to produce a single\ncurrently FDA approved drug treatment. In this study, we attempt to discover an\neffective cytokine mediation treatment strategy for sepsis using a previously\ndeveloped agent-based model that simulates the innate immune response to\ninfection: the Innate Immune Response agent-based model (IIRABM). Previous\nattempts at reducing mortality with multi-cytokine mediation using the IIRABM\nhave failed to reduce mortality across all patient parameterizations and\nmotivated us to investigate whether adaptive, personalized multi-cytokine\nmediation can control the trajectory of sepsis and lower patient mortality. We\nused the IIRABM to compute a treatment policy in which systemic patient\nmeasurements are used in a feedback loop to inform future treatment. Using deep\nreinforcement learning, we identified a policy that achieves 0% mortality on\nthe patient parameterization on which it was trained. More importantly, this\npolicy also achieves 0.8% mortality over 500 randomly selected patient\nparameterizations with baseline mortalities ranging from 1 - 99% (with an\naverage of 49%) spanning the entire clinically plausible parameter space of the\nIIRABM. These results suggest that adaptive, personalized multi-cytokine\nmediation therapy could be a promising approach for treating sepsis. We hope\nthat this work motivates researchers to consider such an approach as part of\nfuture clinical trials. To the best of our knowledge, this work is the first to\nconsider adaptive, personalized multi-cytokine mediation therapy for sepsis,\nand is the first to exploit deep reinforcement learning on a biological\nsimulation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 19:50:19 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Petersen", "Brenden K.", ""], ["Yang", "Jiachen", ""], ["Grathwohl", "Will S.", ""], ["Cockrell", "Chase", ""], ["Santiago", "Claudio", ""], ["An", "Gary", ""], ["Faissol", "Daniel M.", ""]]}, {"id": "1802.10458", "submitter": "Hamid Soleimani", "authors": "Hamid Soleimani, Aliasghar, Makhlooghpour, Wilten Nicola, Claudia\n  Clopath, Emmanuel. M. Drakakis", "title": "A High GOPs/Slice Time Series Classifier for Portable and Embedded\n  Biomedical Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays a diverse range of physiological data can be captured continuously\nfor various applications in particular wellbeing and healthcare. Such data\nrequire efficient methods for classification and analysis. Deep learning\nalgorithms have shown remarkable potential regarding such analyses, however,\nthe use of these algorithms on low-power wearable devices is challenged by\nresource constraints such as area and power consumption. Most of the available\non-chip deep learning processors contain complex and dense hardware\narchitectures in order to achieve the highest possible throughput. Such a trend\nin hardware design may not be efficient in applications where on-node\ncomputation is required and the focus is more on the area and power efficiency\nas in the case of portable and embedded biomedical devices. This paper presents\nan efficient time-series classifier capable of automatically detecting\neffective features and classifying the input signals in real-time. In the\nproposed classifier, throughput is traded off with hardware complexity and cost\nusing resource sharing techniques. A Convolutional Neural Network (CNN) is\nemployed to extract input features and then a Long-Short-Term-Memory (LSTM)\narchitecture with ternary weight precision classifies the input signals\naccording to the extracted features. Hardware implementation on a Xilinx FPGA\nconfirm that the proposed hardware can accurately classify multiple complex\nbiomedical time series data with low area and power consumption and outperform\nall previously presented state-of-the-art records. Most notably, our classifier\nreaches 1.3$\\times$ higher GOPs/Slice than similar state of the art FPGA-based\naccelerators.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 02:24:06 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 12:43:02 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Soleimani", "Hamid", ""], ["Aliasghar", "", ""], ["Makhlooghpour", "", ""], ["Nicola", "Wilten", ""], ["Clopath", "Claudia", ""], ["Drakakis", "Emmanuel. M.", ""]]}, {"id": "1802.10463", "submitter": "Phaniteja S", "authors": "Parijat Dewangan, S Phaniteja, K Madhava Krishna, Abhishek Sarkar,\n  Balaraman Ravindran", "title": "DiGrad: Multi-Task Reinforcement Learning with Shared Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most reinforcement learning algorithms are inefficient for learning multiple\ntasks in complex robotic systems, where different tasks share a set of actions.\nIn such environments a compound policy may be learnt with shared neural network\nparameters, which performs multiple tasks concurrently. However such compound\npolicy may get biased towards a task or the gradients from different tasks\nnegate each other, making the learning unstable and sometimes less data\nefficient. In this paper, we propose a new approach for simultaneous training\nof multiple tasks sharing a set of common actions in continuous action spaces,\nwhich we call as DiGrad (Differential Policy Gradient). The proposed framework\nis based on differential policy gradients and can accommodate multi-task\nlearning in a single actor-critic network. We also propose a simple heuristic\nin the differential policy gradient update to further improve the learning. The\nproposed architecture was tested on 8 link planar manipulator and 27 degrees of\nfreedom(DoF) Humanoid for learning multi-goal reachability tasks for 3 and 2\nend effectors respectively. We show that our approach supports efficient\nmulti-task learning in complex robotic systems, outperforming related methods\nin continuous action spaces.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 10:26:08 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Dewangan", "Parijat", ""], ["Phaniteja", "S", ""], ["Krishna", "K Madhava", ""], ["Sarkar", "Abhishek", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1802.10489", "submitter": "Andrew Massimino", "authors": "Andrew K. Massimino and Mark A. Davenport", "title": "As you like it: Localization via paired comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that we wish to estimate a vector $\\mathbf{x}$ from a set of binary\npaired comparisons of the form \"$\\mathbf{x}$ is closer to $\\mathbf{p}$ than to\n$\\mathbf{q}$\" for various choices of vectors $\\mathbf{p}$ and $\\mathbf{q}$. The\nproblem of estimating $\\mathbf{x}$ from this type of observation arises in a\nvariety of contexts, including nonmetric multidimensional scaling, \"unfolding,\"\nand ranking problems, often because it provides a powerful and flexible model\nof preference. We describe theoretical bounds for how well we can expect to\nestimate $\\mathbf{x}$ under a randomized model for $\\mathbf{p}$ and\n$\\mathbf{q}$. We also present results for the case where the comparisons are\nnoisy and subject to some degree of error. Additionally, we show that under a\nrandomized model for $\\mathbf{p}$ and $\\mathbf{q}$, a suitable number of binary\npaired comparisons yield a stable embedding of the space of target vectors.\nFinally, we also that we can achieve significant gains by adaptively changing\nthe distribution for choosing $\\mathbf{p}$ and $\\mathbf{q}$.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 18:53:00 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Massimino", "Andrew K.", ""], ["Davenport", "Mark A.", ""]]}, {"id": "1802.10497", "submitter": "Elif Vural", "authors": "Jeremy Aghaei Mazaheri, Elif Vural, Claude Labit and Christine\n  Guillemot", "title": "Learning Discriminative Multilevel Structured Dictionaries for\n  Supervised Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse representations using overcomplete dictionaries have proved to be a\npowerful tool in many signal processing applications such as denoising,\nsuper-resolution, inpainting, compression or classification. The sparsity of\nthe representation very much depends on how well the dictionary is adapted to\nthe data at hand. In this paper, we propose a method for learning structured\nmultilevel dictionaries with discriminative constraints to make them well\nsuited for the supervised pixelwise classification of images. A multilevel\ntree-structured discriminative dictionary is learnt for each class, with a\nlearning objective concerning the reconstruction errors of the image patches\naround the pixels over each class-representative dictionary. After the initial\nassignment of the class labels to image pixels based on their sparse\nrepresentations over the learnt dictionaries, the final classification is\nachieved by smoothing the label image with a graph cut method and an erosion\nmethod. Applied to a common set of texture images, our supervised\nclassification method shows competitive results with the state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 16:03:45 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Mazaheri", "Jeremy Aghaei", ""], ["Vural", "Elif", ""], ["Labit", "Claude", ""], ["Guillemot", "Christine", ""]]}, {"id": "1802.10501", "submitter": "Andrey Malinin", "authors": "Andrey Malinin and Mark Gales", "title": "Predictive Uncertainty Estimation via Prior Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating how uncertain an AI system is in its predictions is important to\nimprove the safety of such systems. Uncertainty in predictive can result from\nuncertainty in model parameters, irreducible data uncertainty and uncertainty\ndue to distributional mismatch between the test and training data\ndistributions. Different actions might be taken depending on the source of the\nuncertainty so it is important to be able to distinguish between them.\nRecently, baseline tasks and metrics have been defined and several practical\nmethods to estimate uncertainty developed. These methods, however, attempt to\nmodel uncertainty due to distributional mismatch either implicitly through\nmodel uncertainty or as data uncertainty. This work proposes a new framework\nfor modeling predictive uncertainty called Prior Networks (PNs) which\nexplicitly models distributional uncertainty. PNs do this by parameterizing a\nprior distribution over predictive distributions. This work focuses on\nuncertainty for classification and evaluates PNs on the tasks of identifying\nout-of-distribution (OOD) samples and detecting misclassification on the MNIST\ndataset, where they are found to outperform previous methods. Experiments on\nsynthetic and MNIST and CIFAR-10 data show that unlike previous non-Bayesian\nmethods PNs are able to distinguish between data and distributional\nuncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 16:06:19 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 19:44:18 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 10:53:15 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 23:42:18 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Malinin", "Andrey", ""], ["Gales", "Mark", ""]]}, {"id": "1802.10515", "submitter": "Trisha Lawrence Ms.", "authors": "Trisha Lawrence", "title": "Stochastic Dynamic Programming Heuristics for Influence\n  Maximization-Revenue Optimization", "comments": null, "journal-ref": null, "doi": "10.1007/s41060-018-0155-5", "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The well-known Influence Maximization (IM) problem has been actively studied\nby researchers over the past decade, with emphasis on marketing and social\nnetworks. Existing research have obtained solutions to the IM problem by\nobtaining the influence spread and utilizing the property of submodularity.\nThis paper is based on a novel approach to the IM problem geared towards\noptimizing clicks and consequently revenue within anOnline Social Network\n(OSN). Our approach diverts from existing approaches by adopting a novel,\ndecision-making perspective through implementing Stochastic Dynamic Programming\n(SDP). Thus, we define a new problem Influence Maximization-Revenue\nOptimization (IM-RO) and propose SDP as a method in which this problem can be\nsolved. The SDP method has lucrative gains for an advertiser in terms of\noptimizing clicks and generating revenue however, one drawback to the method is\nits associated \"curse of dimensionality\" particularly for problems involving a\nlarge state space. Thus, we introduce the Lawrence Degree Heuristic (LDH),\nAdaptive Hill-Climbing (AHC) and Multistage Particle Swarm Optimization (MPSO)\nheuristics as methods which are orders of magnitude faster than the SDP method\nwhilst achieving near-optimal results. Through a comparative analysis on\nvarious synthetic and real-world networks we present the AHC and LDH as\nheuristics well suited to to the IM-RO problem in terms of their accuracy,\nrunning times and scalability under ideal model parameters. In this paper we\npresent a compelling survey on the SDP method as a practical and lucrative\nmethod for spreading information and optimizing revenue within the context of\nOSNs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 16:26:06 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 17:19:24 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Lawrence", "Trisha", ""]]}, {"id": "1802.10529", "submitter": "Maurits Kaptein", "authors": "Maurits Kaptein and Paul Ketelaar", "title": "Maximum likelihood estimation of a finite mixture of logistic regression\n  models in a continuous data stream", "comments": "1 figure. Working paper including [R] package", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In marketing we are often confronted with a continuous stream of responses to\nmarketing messages. Such streaming data provide invaluable information\nregarding message effectiveness and segmentation. However, streaming data are\nhard to analyze using conventional methods: their high volume and the fact that\nthey are continuously augmented means that it takes considerable time to\nanalyze them. We propose a method for estimating a finite mixture of logistic\nregression models which can be used to cluster customers based on a continuous\nstream of responses. This method, which we coin oFMLR, allows segments to be\nidentified in data streams or extremely large static datasets. Contrary to\nblack box algorithms, oFMLR provides model estimates that are directly\ninterpretable. We first introduce oFMLR, explaining in passing general topics\nsuch as online estimation and the EM algorithm, making this paper a high level\noverview of possible methods of dealing with large data streams in marketing\npractice. Next, we discuss model convergence, identifiability, and relations to\nalternative, Bayesian, methods; we also identify more general issues that arise\nfrom dealing with continuously augmented data sets. Finally, we introduce the\noFMLR [R] package and evaluate the method by numerical simulation and by\nanalyzing a large customer clickstream dataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 16:43:16 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Kaptein", "Maurits", ""], ["Ketelaar", "Paul", ""]]}, {"id": "1802.10542", "submitter": "Siddhant M. Jayakumar", "authors": "Pablo Sprechmann, Siddhant M. Jayakumar, Jack W. Rae, Alexander\n  Pritzel, Adri\\`a Puigdom\\`enech Badia, Benigno Uria, Oriol Vinyals, Demis\n  Hassabis, Razvan Pascanu, Charles Blundell", "title": "Memory-based Parameter Adaptation", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have excelled on a wide range of problems, from vision\nto language and game playing. Neural networks very gradually incorporate\ninformation into weights as they process data, requiring very low learning\nrates. If the training distribution shifts, the network is slow to adapt, and\nwhen it does adapt, it typically performs badly on the training distribution\nbefore the shift. Our method, Memory-based Parameter Adaptation, stores\nexamples in memory and then uses a context-based lookup to directly modify the\nweights of a neural network. Much higher learning rates can be used for this\nlocal adaptation, reneging the need for many iterations over similar data\nbefore good predictions can be made. As our method is memory-based, it\nalleviates several shortcomings of neural networks, such as catastrophic\nforgetting, fast, stable acquisition of new knowledge, learning with an\nimbalanced class labels, and fast learning during evaluation. We demonstrate\nthis on a range of supervised tasks: large-scale image classification and\nlanguage modelling.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 17:21:44 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Sprechmann", "Pablo", ""], ["Jayakumar", "Siddhant M.", ""], ["Rae", "Jack W.", ""], ["Pritzel", "Alexander", ""], ["Badia", "Adri\u00e0 Puigdom\u00e8nech", ""], ["Uria", "Benigno", ""], ["Vinyals", "Oriol", ""], ["Hassabis", "Demis", ""], ["Pascanu", "Razvan", ""], ["Blundell", "Charles", ""]]}, {"id": "1802.10546", "submitter": "Pierre-Yves Oudeyer", "authors": "Pierre-Yves Oudeyer", "title": "Computational Theories of Curiosity-Driven Learning", "comments": "To appear in \"The New Science of Curiosity\", ed. G. Gordon, Nova\n  Science Publishers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the functions of curiosity? What are the mechanisms of\ncuriosity-driven learning? We approach these questions about the living using\nconcepts and tools from machine learning and developmental robotics. We argue\nthat curiosity-driven learning enables organisms to make discoveries to solve\ncomplex problems with rare or deceptive rewards. By fostering exploration and\ndiscovery of a diversity of behavioural skills, and ignoring these rewards,\ncuriosity can be efficient to bootstrap learning when there is no information,\nor deceptive information, about local improvement towards these problems. We\nalso explain the key role of curiosity for efficient learning of world models.\nWe review both normative and heuristic computational frameworks used to\nunderstand the mechanisms of curiosity in humans, conceptualizing the child as\na sense-making organism. These frameworks enable us to discuss the\nbi-directional causal links between curiosity and learning, and to provide new\nhypotheses about the fundamental role of curiosity in self-organizing\ndevelopmental structures through curriculum learning. We present various\ndevelopmental robotics experiments that study these mechanisms in action, both\nsupporting these hypotheses to understand better curiosity in humans and\nopening new research avenues in machine learning and artificial intelligence.\nFinally, we discuss challenges for the design of experimental paradigms for\nstudying curiosity in psychology and cognitive neuroscience.\n  Keywords: Curiosity, intrinsic motivation, lifelong learning, predictions,\nworld model, rewards, free-energy principle, learning progress, machine\nlearning, AI, developmental robotics, development, curriculum learning,\nself-organization.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 17:28:25 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 10:29:41 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1802.10548", "submitter": "Carlos Xavier Hernandez", "authors": "Carlos X. Hern\\'andez and Mohammad M. Sultan and Vijay S. Pande", "title": "Using Deep Learning for Segmentation and Counting within Microscopy Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell counting is a ubiquitous, yet tedious task that would greatly benefit\nfrom automation. From basic biological questions to clinical trials, cell\ncounts provide key quantitative feedback that drive research. Unfortunately,\ncell counting is most commonly a manual task and can be time-intensive. The\ntask is made even more difficult due to overlapping cells, existence of\nmultiple focal planes, and poor imaging quality, among other factors. Here, we\ndescribe a convolutional neural network approach, using a recently described\nfeature pyramid network combined with a VGG-style neural network, for\nsegmenting and subsequent counting of cells in a given microscopy image.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 17:31:16 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Hern\u00e1ndez", "Carlos X.", ""], ["Sultan", "Mohammad M.", ""], ["Pande", "Vijay S.", ""]]}, {"id": "1802.10549", "submitter": "Alex Rodriguez", "authors": "Maria d'Errico, Elena Facco, Alessandro Laio, and Alex Rodriguez", "title": "Automatic topography of high-dimensional data sets by non-parametric\n  Density Peak clustering", "comments": "There is a Supplementary Information document in the ancillary files\n  folder", "journal-ref": "Information Sciences Volume 560, June 2021, Pages 476-492", "doi": "10.1016/j.ins.2021.01.010", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analysis in high-dimensional spaces aims at obtaining a synthetic\ndescription of a data set, revealing its main structure and its salient\nfeatures. We here introduce an approach providing this description in the form\nof a topography of the data, namely a human-readable chart of the probability\ndensity from which the data are harvested. The approach is based on an\nunsupervised extension of Density Peak clustering and a non-parametric density\nestimator that measures the probability density in the manifold containing the\ndata. This allows finding automatically the number and the height of the peaks\nof the probability density, and the depth of the \"valleys\" separating them.\nImportantly, the density estimator provides a measure of the error, which\nallows distinguishing genuine density peaks from density fluctuations due to\nfinite sampling. The approach thus provides robust and visual information about\nthe density peaks' height, their statistical reliability, and their\nhierarchical organization, offering a conceptually powerful extension of the\nstandard clustering partitions. We show that this framework is particularly\nuseful in the analysis of complex data sets.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 17:32:07 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 11:21:28 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["d'Errico", "Maria", ""], ["Facco", "Elena", ""], ["Laio", "Alessandro", ""], ["Rodriguez", "Alex", ""]]}, {"id": "1802.10551", "submitter": "Gauthier Gidel", "authors": "Gauthier Gidel, Hugo Berard, Ga\\\"etan Vignoud, Pascal Vincent and\n  Simon Lacoste-Julien", "title": "A Variational Inequality Perspective on Generative Adversarial Networks", "comments": "Appears in: Proceedings of the Seventh International Conference on\n  Learning Representations (ICLR 2019). Minor modifications with respect to the\n  ICLR version (First paragraph of page 2 and section 3.3): New reference\n  [Popov 1980] and discussion with regards to the novelty of extrapolation from\n  the past. 38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) form a generative modeling approach\nknown for producing appealing samples, but they are notably difficult to train.\nOne common way to tackle this issue has been to propose new formulations of the\nGAN objective. Yet, surprisingly few studies have looked at optimization\nmethods designed for this adversarial training. In this work, we cast GAN\noptimization problems in the general variational inequality framework. Tapping\ninto the mathematical programming literature, we counter some common\nmisconceptions about the difficulties of saddle point optimization and propose\nto extend techniques designed for variational inequalities to the training of\nGANs. We apply averaging, extrapolation and a computationally cheaper variant\nthat we call extrapolation from the past to the stochastic gradient method\n(SGD) and Adam.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 17:40:05 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 17:30:55 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 17:53:52 GMT"}, {"version": "v4", "created": "Tue, 16 Apr 2019 04:47:40 GMT"}, {"version": "v5", "created": "Fri, 28 Aug 2020 20:51:28 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Gidel", "Gauthier", ""], ["Berard", "Hugo", ""], ["Vignoud", "Ga\u00ebtan", ""], ["Vincent", "Pascal", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1802.10558", "submitter": "Jicong Fan", "authors": "Jicong Fan and Tommy W.S. Chow", "title": "Exactly Robust Kernel Principal Component Analysis", "comments": "The paper was accepted by IEEE Transactions on Neural Networks and\n  Learning Systems", "journal-ref": null, "doi": "10.1109/TNNLS.2019.2909686", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust principal component analysis (RPCA) can recover low-rank matrices when\nthey are corrupted by sparse noises. In practice, many matrices are, however,\nof high-rank and hence cannot be recovered by RPCA. We propose a novel method\ncalled robust kernel principal component analysis (RKPCA) to decompose a\npartially corrupted matrix as a sparse matrix plus a high or full-rank matrix\nwith low latent dimensionality. RKPCA can be applied to many problems such as\nnoise removal and subspace clustering and is still the only unsupervised\nnonlinear method robust to sparse noises. Our theoretical analysis shows that,\nwith high probability, RKPCA can provide high recovery accuracy. The\noptimization of RKPCA involves nonconvex and indifferentiable problems. We\npropose two nonconvex optimization algorithms for RKPCA. They are alternating\ndirection method of multipliers with backtracking line search and proximal\nlinearized minimization with adaptive step size. Comparative studies in noise\nremoval and robust subspace clustering corroborate the effectiveness and\nsuperiority of RKPCA.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 17:49:48 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 19:04:45 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Fan", "Jicong", ""], ["Chow", "Tommy W. S.", ""]]}, {"id": "1802.10567", "submitter": "Jost Tobias Springenberg", "authors": "Martin Riedmiller, Roland Hafner, Thomas Lampe, Michael Neunert, Jonas\n  Degrave, Tom Van de Wiele, Volodymyr Mnih, Nicolas Heess, Jost Tobias\n  Springenberg", "title": "Learning by Playing - Solving Sparse Reward Tasks from Scratch", "comments": "A video of the rich set of learned behaviours can be found at\n  https://youtu.be/mPKyvocNe_M", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Scheduled Auxiliary Control (SAC-X), a new learning paradigm in\nthe context of Reinforcement Learning (RL). SAC-X enables learning of complex\nbehaviors - from scratch - in the presence of multiple sparse reward signals.\nTo this end, the agent is equipped with a set of general auxiliary tasks, that\nit attempts to learn simultaneously via off-policy RL. The key idea behind our\nmethod is that active (learned) scheduling and execution of auxiliary policies\nallows the agent to efficiently explore its environment - enabling it to excel\nat sparse reward RL. Our experiments in several challenging robotic\nmanipulation settings demonstrate the power of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 18:15:49 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Riedmiller", "Martin", ""], ["Hafner", "Roland", ""], ["Lampe", "Thomas", ""], ["Neunert", "Michael", ""], ["Degrave", "Jonas", ""], ["Van de Wiele", "Tom", ""], ["Mnih", "Volodymyr", ""], ["Heess", "Nicolas", ""], ["Springenberg", "Jost Tobias", ""]]}, {"id": "1802.10575", "submitter": "Ilias Diakonikolas", "authors": "Timothy Carpenter, Ilias Diakonikolas, Anastasios Sidiropoulos,\n  Alistair Stewart", "title": "Near-Optimal Sample Complexity Bounds for Maximum Likelihood Estimation\n  of Multivariate Log-concave Densities", "comments": null, "journal-ref": "COLT 2018 proceedings version", "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning multivariate log-concave densities with\nrespect to a global loss function. We obtain the first upper bound on the\nsample complexity of the maximum likelihood estimator (MLE) for a log-concave\ndensity on $\\mathbb{R}^d$, for all $d \\geq 4$. Prior to this work, no finite\nsample upper bound was known for this estimator in more than $3$ dimensions.\n  In more detail, we prove that for any $d \\geq 1$ and $\\epsilon>0$, given\n$\\tilde{O}_d((1/\\epsilon)^{(d+3)/2})$ samples drawn from an unknown log-concave\ndensity $f_0$ on $\\mathbb{R}^d$, the MLE outputs a hypothesis $h$ that with\nhigh probability is $\\epsilon$-close to $f_0$, in squared Hellinger loss. A\nsample complexity lower bound of $\\Omega_d((1/\\epsilon)^{(d+1)/2})$ was\npreviously known for any learning algorithm that achieves this guarantee. We\nthus establish that the sample complexity of the log-concave MLE is\nnear-optimal, up to an $\\tilde{O}(1/\\epsilon)$ factor.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 18:32:07 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 00:07:00 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Carpenter", "Timothy", ""], ["Diakonikolas", "Ilias", ""], ["Sidiropoulos", "Anastasios", ""], ["Stewart", "Alistair", ""]]}, {"id": "1802.10576", "submitter": "Martin Treppner", "authors": "Martin Treppner, Stefan Lenz, Harald Binder and Daniela Z\\\"oller", "title": "Modeling Activity Tracker Data Using Deep Boltzmann Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commercial activity trackers are set to become an essential tool in health\nresearch, due to increasing availability in the general population. The\ncorresponding vast amounts of mostly unlabeled data pose a challenge to\nstatistical modeling approaches. To investigate the feasibility of deep\nlearning approaches for unsupervised learning with such data, we examine weekly\nusage patterns of Fitbit activity trackers with deep Boltzmann machines (DBMs).\nThis method is particularly suitable for modeling complex joint distributions\nvia latent variables. We also chose this specific procedure because it is a\ngenerative approach, i.e., artificial samples can be generated to explore the\nlearned structure. We describe how the data can be preprocessed to be\ncompatible with binary DBMs. The results reveal two distinct usage patterns in\nwhich one group frequently uses trackers on Mondays and Tuesdays, whereas the\nother uses trackers during the entire week. This exemplary result shows that\nDBMs are feasible and can be useful for modeling activity tracker data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 18:33:49 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Treppner", "Martin", ""], ["Lenz", "Stefan", ""], ["Binder", "Harald", ""], ["Z\u00f6ller", "Daniela", ""]]}, {"id": "1802.10592", "submitter": "Thanard Kurutach", "authors": "Thanard Kurutach, Ignasi Clavera, Yan Duan, Aviv Tamar, and Pieter\n  Abbeel", "title": "Model-Ensemble Trust-Region Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL) methods are succeeding in a growing\nnumber of tasks, aided by recent advances in deep learning. However, they tend\nto suffer from high sample complexity, which hinders their use in real-world\ndomains. Alternatively, model-based reinforcement learning promises to reduce\nsample complexity, but tends to require careful tuning and to date have\nsucceeded mainly in restrictive domains where simple models are sufficient for\nlearning. In this paper, we analyze the behavior of vanilla model-based\nreinforcement learning methods when deep neural networks are used to learn both\nthe model and the policy, and show that the learned policy tends to exploit\nregions where insufficient data is available for the model to be learned,\ncausing instability in training. To overcome this issue, we propose to use an\nensemble of models to maintain the model uncertainty and regularize the\nlearning process. We further show that the use of likelihood ratio derivatives\nyields much more stable learning than backpropagation through time. Altogether,\nour approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO)\nsignificantly reduces the sample complexity compared to model-free deep RL\nmethods on challenging continuous control benchmark tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 18:58:22 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 05:08:37 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Kurutach", "Thanard", ""], ["Clavera", "Ignasi", ""], ["Duan", "Yan", ""], ["Tamar", "Aviv", ""], ["Abbeel", "Pieter", ""]]}]