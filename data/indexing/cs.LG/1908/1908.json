[{"id": "1908.00045", "submitter": "Itay Safran", "authors": "Itay Safran, Ohad Shamir", "title": "How Good is SGD with Random Shuffling?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of stochastic gradient descent (SGD) on smooth and\nstrongly-convex finite-sum optimization problems. In contrast to the majority\nof existing theoretical works, which assume that individual functions are\nsampled with replacement, we focus here on popular but poorly-understood\nheuristics, which involve going over random permutations of the individual\nfunctions. This setting has been investigated in several recent works, but the\noptimal error rates remain unclear. In this paper, we provide lower bounds on\nthe expected optimization error with these heuristics (using SGD with any\nconstant step size), which elucidate their advantages and disadvantages. In\nparticular, we prove that after $k$ passes over $n$ individual functions, if\nthe functions are re-shuffled after every pass, the best possible optimization\nerror for SGD is at least $\\Omega\\left(1/(nk)^2+1/nk^3\\right)$, which partially\ncorresponds to recently derived upper bounds. Moreover, if the functions are\nonly shuffled once, then the lower bound increases to $\\Omega(1/nk^2)$. Since\nthere are strictly smaller upper bounds for repeated reshuffling, this proves\nan inherent performance gap between SGD with single shuffling and repeated\nshuffling. As a more minor contribution, we also provide a non-asymptotic\n$\\Omega(1/k^2)$ lower bound (independent of $n$) for the incremental gradient\nmethod, when no random shuffling takes place. Finally, we provide an indication\nthat our lower bounds are tight, by proving matching upper bounds for\nunivariate quadratic functions.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 18:43:01 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 13:04:20 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 08:49:25 GMT"}, {"version": "v4", "created": "Wed, 2 Jun 2021 16:25:46 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Safran", "Itay", ""], ["Shamir", "Ohad", ""]]}, {"id": "1908.00061", "submitter": "Vikram Voleti", "authors": "Vincent Michalski, Vikram Voleti, Samira Ebrahimi Kahou, Anthony\n  Ortiz, Pascal Vincent, Chris Pal, Doina Precup", "title": "An Empirical Study of Batch Normalization and Group Normalization in\n  Conditional Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch normalization has been widely used to improve optimization in deep\nneural networks. While the uncertainty in batch statistics can act as a\nregularizer, using these dataset statistics specific to the training set\nimpairs generalization in certain tasks. Recently, alternative methods for\nnormalizing feature activations in neural networks have been proposed. Among\nthem, group normalization has been shown to yield similar, in some domains even\nsuperior performance to batch normalization. All these methods utilize a\nlearned affine transformation after the normalization operation to increase\nrepresentational power. Methods used in conditional computation define the\nparameters of these transformations as learnable functions of conditioning\ninformation. In this work, we study whether and where the conditional\nformulation of group normalization can improve generalization compared to\nconditional batch normalization. We evaluate performances on the tasks of\nvisual question answering, few-shot learning, and conditional image generation.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 19:37:16 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Michalski", "Vincent", ""], ["Voleti", "Vikram", ""], ["Kahou", "Samira Ebrahimi", ""], ["Ortiz", "Anthony", ""], ["Vincent", "Pascal", ""], ["Pal", "Chris", ""], ["Precup", "Doina", ""]]}, {"id": "1908.00080", "submitter": "Faraz Hussain", "authors": "M.G. Sarwar Murshed, Christopher Murphy, Daqing Hou, Nazar Khan,\n  Ganesh Ananthanarayanan, Faraz Hussain", "title": "Machine Learning at the Network Edge: A Survey", "comments": "35 pages, 4 figures; restructured text to combine ML/DL into a single\n  section; updated tables/figures; added a new table summarizing major ML edge\n  applications, fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource-constrained IoT devices, such as sensors and actuators, have become\nubiquitous in recent years. This has led to the generation of large quantities\nof data in real-time, which is an appealing target for AI systems. However,\ndeploying machine learning models on such end-devices is nearly impossible. A\ntypical solution involves offloading data to external computing systems (such\nas cloud servers) for further processing but this worsens latency, leads to\nincreased communication costs, and adds to privacy concerns. To address this\nissue, efforts have been made to place additional computing devices at the edge\nof the network, i.e close to the IoT devices where the data is generated.\nDeploying machine learning systems on such edge computing devices alleviates\nthe above issues by allowing computations to be performed close to the data\nsources. This survey describes major research efforts where machine learning\nsystems have been deployed at the edge of computer networks, focusing on the\noperational aspects including compression techniques, tools, frameworks, and\nhardware used in successful applications of intelligent edge systems.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 20:23:00 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 18:55:40 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 23:00:32 GMT"}, {"version": "v4", "created": "Sun, 23 May 2021 19:52:16 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Murshed", "M. G. Sarwar", ""], ["Murphy", "Christopher", ""], ["Hou", "Daqing", ""], ["Khan", "Nazar", ""], ["Ananthanarayanan", "Ganesh", ""], ["Hussain", "Faraz", ""]]}, {"id": "1908.00085", "submitter": "Ana Lucic", "authors": "Ana Lucic, Hinda Haned, Maarten de Rijke", "title": "Why Does My Model Fail? Contrastive Local Explanations for Retail\n  Forecasting", "comments": "To appear in ACM FAT* 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various business settings, there is an interest in using more complex\nmachine learning techniques for sales forecasting. It is difficult to convince\nanalysts, along with their superiors, to adopt these techniques since the\nmodels are considered to be \"black boxes,\" even if they perform better than\ncurrent models in use. We examine the impact of contrastive explanations about\nlarge errors on users' attitudes towards a \"black-box'\" model. We propose an\nalgorithm, Monte Carlo Bounds for Reasonable Predictions. Given a large error,\nMC-BRP determines (1) feature values that would result in a reasonable\nprediction, and (2) general trends between each feature and the target, both\nbased on Monte Carlo simulations. We evaluate on a real dataset with real users\nby conducting a user study with 75 participants to determine if explanations\ngenerated by MC-BRP help users understand why a prediction results in a large\nerror, and if this promotes trust in an automatically-learned model. Our study\nshows that users are able to answer objective questions about the model's\npredictions with overall 81.1% accuracy when provided with these contrastive\nexplanations. We show that users who saw MC-BRP explanations understand why the\nmodel makes large errors in predictions significantly more than users in the\ncontrol group. We also conduct an in-depth analysis on the difference in\nattitudes between Practitioners and Researchers, and confirm that our results\nhold when conditioning on the users' background.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 12:57:06 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 14:51:52 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Lucic", "Ana", ""], ["Haned", "Hinda", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1908.00086", "submitter": "Zitao Liu", "authors": "Guowei Xu, Wenbiao Ding, Jiliang Tang, Songfan Yang, Gale Yan Huang,\n  Zitao Liu", "title": "Learning Effective Embeddings From Crowdsourced Labels: An Educational\n  Case Study", "comments": null, "journal-ref": "2019 IEEE 35th International Conference on Data Engineering", "doi": "10.1109/ICDE.2019.00208", "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representation has been proven to be helpful in numerous machine\nlearning tasks. The success of the majority of existing representation learning\napproaches often requires a large amount of consistent and noise-free labels.\nHowever, labels are not accessible in many real-world scenarios and they are\nusually annotated by the crowds. In practice, the crowdsourced labels are\nusually inconsistent among crowd workers given their diverse expertise and the\nnumber of crowdsourced labels is very limited. Thus, directly adopting\ncrowdsourced labels for existing representation learning algorithms is\ninappropriate and suboptimal. In this paper, we investigate the above problem\nand propose a novel framework of \\textbf{R}epresentation \\textbf{L}earning with\ncrowdsourced \\textbf{L}abels, i.e., \"RLL\", which learns representation of data\nwith crowdsourced labels by jointly and coherently solving the challenges\nintroduced by limited and inconsistent labels. The proposed representation\nlearning framework is evaluated in two real-world education applications. The\nexperimental results demonstrate the benefits of our approach on learning\nrepresentation from limited labeled data from the crowds, and show RLL is able\nto outperform state-of-the-art baselines. Moreover, detailed experiments are\nconducted on RLL to fully understand its key components and the corresponding\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 03:01:06 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Xu", "Guowei", ""], ["Ding", "Wenbiao", ""], ["Tang", "Jiliang", ""], ["Yang", "Songfan", ""], ["Huang", "Gale Yan", ""], ["Liu", "Zitao", ""]]}, {"id": "1908.00087", "submitter": "Thilo Spinner", "authors": "Thilo Spinner, Udo Schlegel, Hanna Sch\\\"afer and Mennatallah El-Assady", "title": "explAIner: A Visual Analytics Framework for Interactive and Explainable\n  Machine Learning", "comments": "9 pages paper, 2 pages references, 5 pages supplementary material\n  (ancillary files)", "journal-ref": "IEEE Transactions on Visualization and Computer Graphics (2019)", "doi": "10.1109/TVCG.2019.2934629", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for interactive and explainable machine learning that\nenables users to (1) understand machine learning models; (2) diagnose model\nlimitations using different explainable AI methods; as well as (3) refine and\noptimize the models. Our framework combines an iterative XAI pipeline with\neight global monitoring and steering mechanisms, including quality monitoring,\nprovenance tracking, model comparison, and trust building. To operationalize\nthe framework, we present explAIner, a visual analytics system for interactive\nand explainable machine learning that instantiates all phases of the suggested\npipeline within the commonly used TensorBoard environment. We performed a\nuser-study with nine participants across different expertise levels to examine\ntheir perception of our workflow and to collect suggestions to fill the gap\nbetween our system and framework. The evaluation confirms that our tightly\nintegrated system leads to an informed machine learning process while\ndisclosing opportunities for further extensions.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 15:04:59 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 12:54:46 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Spinner", "Thilo", ""], ["Schlegel", "Udo", ""], ["Sch\u00e4fer", "Hanna", ""], ["El-Assady", "Mennatallah", ""]]}, {"id": "1908.00096", "submitter": "Jan Philip G\\\"opfert", "authors": "Christina G\\\"opfert, Jan Philip G\\\"opfert, Barbara Hammer", "title": "Adversarial Robustness Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of adversarial examples has led to considerable uncertainty\nregarding the trust one can justifiably put in predictions produced by\nautomated systems. This uncertainty has, in turn, lead to considerable research\neffort in understanding adversarial robustness. In this work, we take first\nsteps towards separating robustness analysis from the choice of robustness\nthreshold and norm. We propose robustness curves as a more general view of the\nrobustness behavior of a model and investigate under which circumstances they\ncan qualitatively depend on the chosen norm.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 21:02:36 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["G\u00f6pfert", "Christina", ""], ["G\u00f6pfert", "Jan Philip", ""], ["Hammer", "Barbara", ""]]}, {"id": "1908.00105", "submitter": "Marco Henrique De Almeida In\\'acio", "authors": "Marco Henrique de Almeida In\\'acio and Rafael Izbicki and Rafael Bassi\n  Stern", "title": "Conditional independence testing: a predictive perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional independence testing is a key problem required by many machine\nlearning and statistics tools. In particular, it is one way of evaluating the\nusefulness of some features on a supervised prediction problem. We propose a\nnovel conditional independence test in a predictive setting, and show that it\nachieves better power than competing approaches in several settings. Our\napproach consists in deriving a p-value using a permutation test where the\npredictive power using the unpermuted dataset is compared with the predictive\npower of using dataset where the feature(s) of interest are permuted. We\nconclude that the method achives sensible results on simulated and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 21:19:23 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["In\u00e1cio", "Marco Henrique de Almeida", ""], ["Izbicki", "Rafael", ""], ["Stern", "Rafael Bassi", ""]]}, {"id": "1908.00111", "submitter": "Vasileios Belagiannis", "authors": "Leslie Casas, Attila Klimmek, Gustavo Carneiro, Nassir Navab,\n  Vasileios Belagiannis", "title": "Few-Shot Meta-Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of few-shot learning-based denoising where the training\nset contains just a handful of clean and noisy samples. A solution to mitigate\nthe small training set issue is to pre-train a denoising model with small\ntraining sets containing pairs of clean and synthesized noisy signals, produced\nfrom empirical noise priors, and fine-tune on the available small training set.\nWhile such transfer learning seems effective, it may not generalize well\nbecause of the limited amount of training data. In this work, we propose a new\nmeta-learning training approach for few-shot learning-based denoising problems.\nOur model is meta-trained using known synthetic noise models, and then\nfine-tuned with the small training set, with the real noise, as a few-shot\nlearning task. Meta-learning from small training sets of synthetically\ngenerated data during meta-training enables us to not only generate an infinite\nnumber of training tasks, but also train a model to learn with small training\nsets -- both advantages have the potential to improve the generalisation of the\ndenoising model. Our approach is empirically shown to produce more accurate\ndenoising results than supervised learning and transfer learning in three\ndenoising evaluations for images and 1-D signals. Interestingly, our study\nprovides strong indications that meta-learning has the potential to become the\nmain learning algorithm for denoising.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 21:40:44 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 21:19:46 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Casas", "Leslie", ""], ["Klimmek", "Attila", ""], ["Carneiro", "Gustavo", ""], ["Navab", "Nassir", ""], ["Belagiannis", "Vasileios", ""]]}, {"id": "1908.00148", "submitter": "Mansura A. Khan", "authors": "Mansura A. Khan, Ellen Rushe, Barry Smyth and David Coyle", "title": "Personalized, Health-Aware Recipe Recommendation: An Ensemble Topic\n  Modeling Based Approach", "comments": "This is a pre-print version of the accepted full-paper in\n  HealthRecsys2019 workshop (https://healthrecsys.github.io/2019/). The final\n  version of the article would be published in the workshop preceding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Food choices are personal and complex and have a significant impact on our\nlong-term health and quality of life. By helping users to make informed and\nsatisfying decisions, Recommender Systems (RS) have the potential to support\nusers in making healthier food choices. Intelligent users-modeling is a key\nchallenge in achieving this potential. This paper investigates Ensemble Topic\nModelling (EnsTM) based Feature Identification techniques for efficient\nuser-modeling and recipe recommendation. It builds on findings in EnsTM to\npropose a reduced data representation format and a smart user-modeling strategy\nthat makes capturing user-preference fast, efficient and interactive. This\napproach enables personalization, even in a cold-start scenario. This paper\nproposes two different EnsTM based and one Hybrid EnsTM based recommenders. We\ncompared all three EnsTM based variations through a user study with 48\nparticipants, using a large-scale,real-world corpus of 230,876 recipes, and\ncompare against a conventional Content Based (CB) approach. EnsTM based\nrecommenders performed significantly better than the CB approach. Besides\nacknowledging multi-domain contents such as taste, demographics and cost, our\nproposed approach also considers user's nutritional preference and assists them\nfinding recipes under diverse nutritional categories. Furthermore, it provides\nexcellent coverage and enables implicit understanding of user's food practices.\nSubsequent analysis also exposed correlation between certain features and a\nhealthier lifestyle.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 23:51:51 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Khan", "Mansura A.", ""], ["Rushe", "Ellen", ""], ["Smyth", "Barry", ""], ["Coyle", "David", ""]]}, {"id": "1908.00156", "submitter": "Hrushikesh Mhaskar", "authors": "Hrushikesh Mhaskar", "title": "A direct approach for function approximation on data defined manifolds", "comments": "Version 1 was submitted on August 1, 2019 under the title Deep\n  Gaussian networks for function approximation on data defined manifolds. This\n  version is accepted for publication in Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In much of the literature on function approximation by deep networks, the\nfunction is assumed to be defined on some known domain, such as a cube or a\nsphere. In practice, the data might not be dense on these domains, and\ntherefore, the approximation theory results are observed to be too\nconservative. In manifold learning, one assumes instead that the data is\nsampled from an unknown manifold; i.e., the manifold is defined by the data\nitself. Function approximation on this unknown manifold is then a two stage\nprocedure: first, one approximates the Laplace-Beltrami operator (and its\neigen-decomposition) on this manifold using a graph Laplacian, and next,\napproximates the target function using the eigen-functions. Alternatively, one\nestimates first some atlas on the manifold and then uses local approximation\ntechniques based on the local coordinate charts.\n  In this paper, we propose a more direct approach to function approximation on\n\\emph{unknown}, data defined manifolds without computing the\neigen-decomposition of some operator or an atlas for the manifold, and without\nany kind of training in the classical sense. Our constructions are universal;\ni.e., do not require the knowledge of any prior on the target function other\nthan continuity on the manifold. We estimate the degree of approximation. For\nsmooth functions, the estimates do not suffer from the so-called saturation\nphenomenon. We demonstrate via a property called good propagation of errors how\nthe results can be lifted for function approximation using deep networks where\neach channel evaluates a Gaussian network on a possibly unknown manifold.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 00:42:26 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 00:18:59 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 23:35:18 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 04:50:57 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Mhaskar", "Hrushikesh", ""]]}, {"id": "1908.00173", "submitter": "Jianlei Yang", "authors": "Xucheng Ye, Pengcheng Dai, Junyu Luo, Xin Guo, Yingjie Qi, Jianlei\n  Yang, Yiran Chen", "title": "Accelerating CNN Training by Pruning Activation Gradients", "comments": "accepted by ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sparsification is an efficient approach to accelerate CNN inference, but it\nis challenging to take advantage of sparsity in training procedure because the\ninvolved gradients are dynamically changed. Actually, an important observation\nshows that most of the activation gradients in back-propagation are very close\nto zero and only have a tiny impact on weight-updating. Hence, we consider\npruning these very small gradients randomly to accelerate CNN training\naccording to the statistical distribution of activation gradients. Meanwhile,\nwe theoretically analyze the impact of pruning algorithm on the convergence.\nThe proposed approach is evaluated on AlexNet and ResNet-\\{18, 34, 50, 101,\n152\\} with CIFAR-\\{10, 100\\} and ImageNet datasets. Experimental results show\nthat our training approach could substantially achieve up to $5.92 \\times$\nspeedups at back-propagation stage with negligible accuracy loss.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 01:48:11 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 12:18:17 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 11:13:05 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ye", "Xucheng", ""], ["Dai", "Pengcheng", ""], ["Luo", "Junyu", ""], ["Guo", "Xin", ""], ["Qi", "Yingjie", ""], ["Yang", "Jianlei", ""], ["Chen", "Yiran", ""]]}, {"id": "1908.00175", "submitter": "Michael Jacobs", "authors": "Alex E. Bocchieri, Vishwa S. Parekh, Kathryn R. Wagner. Shivani\n  Ahlawat, Vladimir Braverman, Doris G. Leung, Michael A. Jacobs", "title": "Multiparametric Deep Learning Tissue Signatures for Muscular Dystrophy:\n  Preliminary Results", "comments": "6 pages, 3 figures. MIDL 2019 [arXiv:1907.08612]", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/H1g3ICh4cV", "categories": "eess.IV cs.LG physics.med-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A current clinical challenge is identifying limb girdle muscular dystrophy\n2I(LGMD2I)tissue changes in the thighs, in particular, separating fat,\nfat-infiltrated muscle, and muscle tissue. Deep learning algorithms have the\nability to learn different features by using the inherent tissue contrasts from\nmultiparametric magnetic resonance imaging (mpMRI). To that end, we developed a\nnovel multiparametric deep learning network (MPDL) tissue signature model based\non mpMRI and applied it to LGMD2I. We demonstrate a new tissue signature model\nof muscular dystrophy with the MPDL algorithm segments different tissue types\nwith excellent results.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 01:50:27 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Bocchieri", "Alex E.", ""], ["Parekh", "Vishwa S.", ""], ["Ahlawat", "Kathryn R. Wagner. Shivani", ""], ["Braverman", "Vladimir", ""], ["Leung", "Doris G.", ""], ["Jacobs", "Michael A.", ""]]}, {"id": "1908.00176", "submitter": "Yongsu Ahn", "authors": "Yongsu Ahn and Yu-Ru Lin", "title": "FairSight: Visual Analytics for Fairness in Decision Making", "comments": "10 pages, 8 figures, IEEE VIS (VAST) 2019", "journal-ref": "IEEE Transactions on Visualization and Computer Graphics 2020", "doi": "10.1109/TVCG.2019.2934262", "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven decision making related to individuals has become increasingly\npervasive, but the issue concerning the potential discrimination has been\nraised by recent studies. In response, researchers have made efforts to propose\nand implement fairness measures and algorithms, but those efforts have not been\ntranslated to the real-world practice of data-driven decision making. As such,\nthere is still an urgent need to create a viable tool to facilitate fair\ndecision making. We propose FairSight, a visual analytic system to address this\nneed; it is designed to achieve different notions of fairness in ranking\ndecisions through identifying the required actions -- understanding, measuring,\ndiagnosing and mitigating biases -- that together lead to fairer decision\nmaking. Through a case study and user study, we demonstrate that the proposed\nvisual analytic and diagnostic modules in the system are effective in\nunderstanding the fairness-aware decision pipeline and obtaining more fair\noutcomes.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 01:59:54 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 04:03:51 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ahn", "Yongsu", ""], ["Lin", "Yu-Ru", ""]]}, {"id": "1908.00177", "submitter": "Tommy Tram", "authors": "Tommy Tram, Ivo Batkovic, Mohammad Ali, Jonas Sj\\\"oberg", "title": "Learning When to Drive in Intersections by Combining Reinforcement\n  Learning and Model Predictive Control", "comments": "6 pages, 5 figures, 1 table, Accepted to IEEE Intelligent Transport\n  Systems Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a decision making algorithm intended for automated\nvehicles that negotiate with other possibly non-automated vehicles in\nintersections. The decision algorithm is separated into two parts: a high-level\ndecision module based on reinforcement learning, and a low-level planning\nmodule based on model predictive control. Traffic is simulated with numerous\npredefined driver behaviors and intentions, and the performance of the proposed\ndecision algorithm was evaluated against another controller. The results show\nthat the proposed decision algorithm yields shorter training episodes and an\nincreased performance in success rate compared to the other controller.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 02:00:49 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Tram", "Tommy", ""], ["Batkovic", "Ivo", ""], ["Ali", "Mohammad", ""], ["Sj\u00f6berg", "Jonas", ""]]}, {"id": "1908.00187", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Graph Neural Networks for Small Graph and Giant Network Representation\n  Learning: An Overview", "comments": "30 pages. arXiv admin note: text overlap with arXiv:1908.00187", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks denote a group of neural network models introduced for\nthe representation learning tasks on graph data specifically. Graph neural\nnetworks have been demonstrated to be effective for capturing network structure\ninformation, and the learned representations can achieve the state-of-the-art\nperformance on node and graph classification tasks. Besides the different\napplication scenarios, the architectures of graph neural network models also\ndepend on the studied graph types a lot. Graph data studied in research can be\ngenerally categorized into two main types, i.e., small graphs vs. giant\nnetworks, which differ from each other a lot in the size, instance number and\nlabel annotation. Several different types of graph neural network models have\nbeen introduced for learning the representations from such different types of\ngraphs already. In this paper, for these two different types of graph data, we\nwill introduce the graph neural networks introduced in recent years. To be more\nspecific, the graph neural networks introduced in this paper include IsoNN,\nSDBN, LF&ER, GCN, GAT, DifNN, GNL, GraphSage and seGEN. Among these graph\nneural network models, IsoNN, SDBN and LF&ER are initially proposed for small\ngraphs and the remaining ones are initially proposed for giant networks\ninstead. The readers are also suggested to refer to these papers for detailed\ninformation when reading this tutorial paper.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 02:35:12 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1908.00195", "submitter": "Waheed Bajwa", "authors": "Alireza Nooraiepour, Waheed U. Bajwa, and Narayan B. Mandayam", "title": "Learning-Aided Physical Layer Attacks Against Multicarrier\n  Communications in IoT", "comments": "15 pages; 20 figures; 3 tables; preprint of a paper accepted for\n  publication in IEEE Trans. Cognitive Commun. Netw", "journal-ref": "IEEE Trans. Cognitive Commun. Netw., vol. 7, no. 1, pp. 239-254,\n  Mar. 2021", "doi": "10.1109/TCCN.2020.2990657", "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-of-Things (IoT) devices that are limited in power and processing are\nsusceptible to physical layer (PHY) spoofing (signal exploitation) attacks\nowing to their inability to implement a full-blown protocol stack for security.\nThe overwhelming adoption of multicarrier techniques such as orthogonal\nfrequency division multiplexing (OFDM) for the PHY layer makes IoT devices\nfurther vulnerable to PHY spoofing attacks. These attacks which aim at\ninjecting bogus/spurious data into the receiver, involve inferring transmission\nparameters and finding PHY characteristics of the transmitted signals so as to\nspoof the received signal. Non-contiguous (NC) OFDM systems have been argued to\nhave low probability of exploitation (LPE) characteristics against classic\nattacks based on cyclostationary analysis, and the corresponding PHY has been\ndeemed to be secure. However, with the advent of machine learning (ML)\nalgorithms, adversaries can devise data-driven attacks to compromise such\nsystems. It is in this vein that PHY spoofing performance of adversaries\nequipped with supervised and unsupervised ML tools are investigated in this\npaper. The supervised ML approach is based on deep neural networks (DNN) while\nthe unsupervised one employs variational autoencoders (VAEs). In particular,\nVAEs are shown to be capable of learning representations from NC-OFDM signals\nrelated to their PHY characteristics such as frequency pattern and modulation\nscheme, which are useful for PHY spoofing. In addition, a new metric based on\nthe disentanglement principle is proposed to measure the quality of such\nlearned representations. Simulation results demonstrate that the performance of\nthe spoofing adversaries highly depends on the subcarriers' allocation\npatterns. Particularly, it is shown that utilizing a random subcarrier\noccupancy pattern secures NC-OFDM systems against ML-based attacks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 03:34:57 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 19:28:50 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Nooraiepour", "Alireza", ""], ["Bajwa", "Waheed U.", ""], ["Mandayam", "Narayan B.", ""]]}, {"id": "1908.00200", "submitter": "Edward Raff", "authors": "Edward Raff, William Fleming, Richard Zak, Hyrum Anderson, Bill\n  Finlayson, Charles Nicholas, Mark McLean", "title": "KiloGrams: Very Large N-Grams for Malware Classification", "comments": "Appearing in LEMINCS @ KDD'19, August 5th, 2019, Anchorage, Alaska,\n  United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  N-grams have been a common tool for information retrieval and machine\nlearning applications for decades. In nearly all previous works, only a few\nvalues of $n$ are tested, with $n > 6$ being exceedingly rare. Larger values of\n$n$ are not tested due to computational burden or the fear of overfitting. In\nthis work, we present a method to find the top-$k$ most frequent $n$-grams that\nis 60$\\times$ faster for small $n$, and can tackle large $n\\geq1024$. Despite\nthe unprecedented size of $n$ considered, we show how these features still have\npredictive ability for malware classification tasks. More important, large\n$n$-grams provide benefits in producing features that are interpretable by\nmalware analysis, and can be used to create general purpose signatures\ncompatible with industry standard tools like Yara. Furthermore, the counts of\ncommon $n$-grams in a file may be added as features to publicly available\nhuman-engineered features that rival efficacy of professionally-developed\nfeatures when used to train gradient-boosted decision tree models on the EMBER\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 03:58:11 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Raff", "Edward", ""], ["Fleming", "William", ""], ["Zak", "Richard", ""], ["Anderson", "Hyrum", ""], ["Finlayson", "Bill", ""], ["Nicholas", "Charles", ""], ["McLean", "Mark", ""]]}, {"id": "1908.00205", "submitter": "Emma Xue", "authors": "Shan Xue, Jie Lu, Guangquan Zhang", "title": "Cross-domain Network Representations", "comments": null, "journal-ref": "Pattern Recognition 94 (2019): 135-148", "doi": "10.1016/j.patcog.2019.05.009", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of network representation is to learn a set of latent features by\nobtaining community information from network structures to provide knowledge\nfor machine learning tasks. Recent research has driven significant progress in\nnetwork representation by employing random walks as the network sampling\nstrategy. Nevertheless, existing approaches rely on domain-specifically rich\ncommunity structures and fail in the network that lack topological information\nin its own domain. In this paper, we propose a novel algorithm for cross-domain\nnetwork representation, named as CDNR. By generating the random walks from a\nstructural rich domain and transferring the knowledge on the random walks\nacross domains, it enables a network representation for the structural scarce\ndomain as well. To be specific, CDNR is realized by a cross-domain two-layer\nnode-scale balance algorithm and a cross-domain two-layer knowledge transfer\nalgorithm in the framework of cross-domain two-layer random walk learning.\nExperiments on various real-world datasets demonstrate the effectiveness of\nCDNR for universal networks in an unsupervised way.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 04:32:15 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Xue", "Shan", ""], ["Lu", "Jie", ""], ["Zhang", "Guangquan", ""]]}, {"id": "1908.00213", "submitter": "Shunta Saito", "authors": "Seiya Tokui, Ryosuke Okuta, Takuya Akiba, Yusuke Niitani, Toru Ogawa,\n  Shunta Saito, Shuji Suzuki, Kota Uenishi, Brian Vogel, Hiroyuki Yamazaki\n  Vincent", "title": "Chainer: A Deep Learning Framework for Accelerating the Research Cycle", "comments": "Accepted for Applied Data Science Track in KDD'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software frameworks for neural networks play a key role in the development\nand application of deep learning methods. In this paper, we introduce the\nChainer framework, which intends to provide a flexible, intuitive, and high\nperformance means of implementing the full range of deep learning models needed\nby researchers and practitioners. Chainer provides acceleration using Graphics\nProcessing Units with a familiar NumPy-like API through CuPy, supports general\nand dynamic models in Python through Define-by-Run, and also provides add-on\npackages for state-of-the-art computer vision models as well as distributed\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 05:07:00 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Tokui", "Seiya", ""], ["Okuta", "Ryosuke", ""], ["Akiba", "Takuya", ""], ["Niitani", "Yusuke", ""], ["Ogawa", "Toru", ""], ["Saito", "Shunta", ""], ["Suzuki", "Shuji", ""], ["Uenishi", "Kota", ""], ["Vogel", "Brian", ""], ["Vincent", "Hiroyuki Yamazaki", ""]]}, {"id": "1908.00219", "submitter": "Nemanja Djuric", "authors": "Henggang Cui, Thi Nguyen, Fang-Chieh Chou, Tsung-Han Lin, Jeff\n  Schneider, David Bradley, Nemanja Djuric", "title": "Deep Kinematic Models for Kinematically Feasible Vehicle Trajectory\n  Predictions", "comments": "Accepted for publication at IEEE International Conference on Robotics\n  and Automation (ICRA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-driving vehicles (SDVs) hold great potential for improving traffic\nsafety and are poised to positively affect the quality of life of millions of\npeople. To unlock this potential one of the critical aspects of the autonomous\ntechnology is understanding and predicting future movement of vehicles\nsurrounding the SDV. This work presents a deep-learning-based method for\nkinematically feasible motion prediction of such traffic actors. Previous work\ndid not explicitly encode vehicle kinematics and instead relied on the models\nto learn the constraints directly from the data, potentially resulting in\nkinematically infeasible, suboptimal trajectory predictions. To address this\nissue we propose a method that seamlessly combines ideas from the AI with\nphysically grounded vehicle motion models. In this way we employ best of the\nboth worlds, coupling powerful learning models with strong feasibility\nguarantees for their outputs. The proposed approach is general, being\napplicable to any type of learning method. Extensive experiments using deep\nconvnets on real-world data strongly indicate its benefits, outperforming the\nexisting state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 05:44:56 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 22:39:56 GMT"}, {"version": "v3", "created": "Sat, 24 Oct 2020 20:30:48 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Cui", "Henggang", ""], ["Nguyen", "Thi", ""], ["Chou", "Fang-Chieh", ""], ["Lin", "Tsung-Han", ""], ["Schneider", "Jeff", ""], ["Bradley", "David", ""], ["Djuric", "Nemanja", ""]]}, {"id": "1908.00225", "submitter": "Nathaniel Tomasetti", "authors": "Nathaniel Tomasetti and Catherine S. Forbes and Anastasios\n  Panagiotelis", "title": "Updating Variational Bayes: Fast sequential posterior inference", "comments": "35 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayesian (VB) methods produce posterior inference in a time frame\nconsiderably smaller than traditional Markov Chain Monte Carlo approaches.\nAlthough the VB posterior is an approximation, it has been shown to produce\ngood parameter estimates and predicted values when a rich classes of\napproximating distributions are considered. In this paper we propose Updating\nVB (UVB), a recursive algorithm used to update a sequence of VB posterior\napproximations in an online setting, with the computation of each posterior\nupdate requiring only the data observed since the previous update. An extension\nto the proposed algorithm, named UVB-IS, allows the user to trade accuracy for\na substantial increase in computational speed through the use of importance\nsampling. The two methods and their properties are detailed in two separate\nsimulation studies. Two empirical illustrations of the proposed UVB methods are\nprovided, including one where a Dirichlet Process Mixture model with a novel\nposterior dependence structure is repeatedly updated in the context of\npredicting the future behaviour of vehicles on a stretch of the US Highway 101.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 06:12:00 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Tomasetti", "Nathaniel", ""], ["Forbes", "Catherine S.", ""], ["Panagiotelis", "Anastasios", ""]]}, {"id": "1908.00234", "submitter": "Bradly Alicea", "authors": "Hrishikesh Kulkarni, Bradly Alicea", "title": "Cultural association based on machine learning for team formation", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Culture is core to human civilization, and is essential for human\nintellectual achievements in social context. Culture also influences how humans\nwork together, perform particular task and overall lifestyle and dealing with\nother groups of civilization. Thus, culture is concerned with establishing\nshared ideas, particularly those playing a key role in success. Does it impact\non how two individuals can work together in achieving certain goals? In this\npaper, we establish a means to derive cultural association and map it to\nculturally mediated success. Human interactions with the environment are\ntypically in the form of expressions. Association between culture and behavior\nproduce similar beliefs which lead to common principles and actions, while\ncultural similarity as a set of common expressions and responses. To measure\ncultural association among different candidates, we propose the use of a\nGraphical Association Method (GAM). The behaviors of candidates are captured\nthrough series of expressions and represented in the graphical form. The\nassociation among corresponding node and core nodes is used for the same. Our\napproach provides a number of interesting results and promising avenues for\nfuture applications.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 06:57:35 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Kulkarni", "Hrishikesh", ""], ["Alicea", "Bradly", ""]]}, {"id": "1908.00261", "submitter": "Gaurav Mahajan", "authors": "Alekh Agarwal, Sham M. Kakade, Jason D. Lee, Gaurav Mahajan", "title": "On the Theory of Policy Gradient Methods: Optimality, Approximation, and\n  Distribution Shift", "comments": "Corollary 6.1 added for a cleaner comparison to prior work.\n  $\\epsilon_{\\mathrm{bias}}$ is now used instead of\n  $\\epsilon_{\\mathrm{approx}}$ to denote the transfer approximation error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are among the most effective methods in challenging\nreinforcement learning problems with large state and/or action spaces. However,\nlittle is known about even their most basic theoretical convergence properties,\nincluding: if and how fast they converge to a globally optimal solution or how\nthey cope with approximation error due to using a restricted class of\nparametric policies. This work provides provable characterizations of the\ncomputational, approximation, and sample size properties of policy gradient\nmethods in the context of discounted Markov Decision Processes (MDPs). We focus\non both: \"tabular\" policy parameterizations, where the optimal policy is\ncontained in the class and where we show global convergence to the optimal\npolicy; and parametric policy classes (considering both log-linear and neural\npolicy classes), which may not contain the optimal policy and where we provide\nagnostic learning results. One central contribution of this work is in\nproviding approximation guarantees that are average case -- which avoid\nexplicit worst-case dependencies on the size of state space -- by making a\nformal connection to supervised learning under distribution shift. This\ncharacterization shows an important interplay between estimation error,\napproximation error, and exploration (as characterized through a precisely\ndefined condition number).\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 08:22:18 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 15:54:51 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 06:47:50 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 22:50:05 GMT"}, {"version": "v5", "created": "Wed, 14 Oct 2020 18:56:23 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Agarwal", "Alekh", ""], ["Kakade", "Sham M.", ""], ["Lee", "Jason D.", ""], ["Mahajan", "Gaurav", ""]]}, {"id": "1908.00273", "submitter": "Yiyun Zhao", "authors": "Yiyun Zhao, Zhuqing Jiang, Aidong Men, Guodong Ju", "title": "Pyramid Real Image Denoising Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep Convolutional Neural Networks (CNNs) have shown extraordinary\ncapability of modelling specific noise and denoising, they still perform poorly\non real-world noisy images. The main reason is that the real-world noise is\nmore sophisticated and diverse. To tackle the issue of blind denoising, in this\npaper, we propose a novel pyramid real image denoising network (PRIDNet), which\ncontains three stages. First, the noise estimation stage uses channel attention\nmechanism to recalibrate the channel importance of input noise. Second, at the\nmulti-scale denoising stage, pyramid pooling is utilized to extract multi-scale\nfeatures. Third, the stage of feature fusion adopts a kernel selecting\noperation to adaptively fuse multi-scale features. Experiments on two datasets\nof real noisy photographs demonstrate that our approach can achieve competitive\nperformance in comparison with state-of-the-art denoisers in terms of both\nquantitative measure and visual perception quality. Code is available at\nhttps://github.com/491506870/PRIDNet.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 08:51:10 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 03:27:36 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Zhao", "Yiyun", ""], ["Jiang", "Zhuqing", ""], ["Men", "Aidong", ""], ["Ju", "Guodong", ""]]}, {"id": "1908.00274", "submitter": "M. Saquib Sarfraz", "authors": "M. Saquib Sarfraz, Constantin Seibold, Haroon Khalid, Rainer\n  Stiefelhagen", "title": "Content and Colour Distillation for Learning Image Translations with the\n  Spatial Profile Loss", "comments": "BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks has emerged as a defacto standard for image\ntranslation problems. To successfully drive such models, one has to rely on\nadditional networks e.g., discriminators and/or perceptual networks. Training\nthese networks with pixel based losses alone are generally not sufficient to\nlearn the target distribution. In this paper, we propose a novel method of\ncomputing the loss directly between the source and target images that enable\nproper distillation of shape/content and colour/style. We show that this is\nuseful in typical image-to-image translations allowing us to successfully drive\nthe generator without relying on additional networks. We demonstrate this on\nmany difficult image translation problems such as image-to-image domain\nmapping, single image super-resolution and photo realistic makeup transfer. Our\nextensive evaluation shows the effectiveness of the proposed formulation and\nits ability to synthesize realistic images. [Code release:\nhttps://github.com/ssarfraz/SPL]\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 08:53:06 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Sarfraz", "M. Saquib", ""], ["Seibold", "Constantin", ""], ["Khalid", "Haroon", ""], ["Stiefelhagen", "Rainer", ""]]}, {"id": "1908.00281", "submitter": "Shotaro Shiba Funai", "authors": "Kenji Fukushima, Shotaro Shiba Funai, Hideaki Iida", "title": "Featuring the topology with the unsupervised machine learning", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images of line drawings are generally composed of primitive elements. One of\nthe most fundamental elements to characterize images is the topology; line\nsegments belong to a category different from closed circles, and closed circles\nwith different winding degrees are nonequivalent. We investigate images with\nnontrivial winding using the unsupervised machine learning. We build an\nautoencoder model with a combination of convolutional and fully connected\nneural networks. We confirm that compressed data filtered from the trained\nmodel retain more than 90% of correct information on the topology, evidencing\nthat image clustering from the unsupervised learning features the topology.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 09:05:05 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Fukushima", "Kenji", ""], ["Funai", "Shotaro Shiba", ""], ["Iida", "Hideaki", ""]]}, {"id": "1908.00286", "submitter": "Floris Den Hengst", "authors": "Floris den Hengst, Mark Hoogendoorn, Frank van Harmelen, Joost Bosman", "title": "Reinforcement Learning for Personalized Dialogue Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language systems have been of great interest to the research community and\nhave recently reached the mass market through various assistant platforms on\nthe web. Reinforcement Learning methods that optimize dialogue policies have\nseen successes in past years and have recently been extended into methods that\npersonalize the dialogue, e.g. take the personal context of users into account.\nThese works, however, are limited to personalization to a single user with whom\nthey require multiple interactions and do not generalize the usage of context\nacross users. This work introduces a problem where a generalized usage of\ncontext is relevant and proposes two Reinforcement Learning (RL)-based\napproaches to this problem. The first approach uses a single learner and\nextends the traditional POMDP formulation of dialogue state with features that\ndescribe the user context. The second approach segments users by context and\nthen employs a learner per context. We compare these approaches in a benchmark\nof existing non-RL and RL-based methods in three established and one novel\napplication domain of financial product recommendation. We compare the\ninfluence of context and training experiences on performance and find that\nlearning approaches generally outperform a handcrafted gold standard.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 09:19:27 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Hengst", "Floris den", ""], ["Hoogendoorn", "Mark", ""], ["van Harmelen", "Frank", ""], ["Bosman", "Joost", ""]]}, {"id": "1908.00298", "submitter": "Yunyou Huang", "authors": "Yunyou Huang, Nana Wang, Wanling Gao, Xiaoxu Guo, Cheng Huang, Tianshu\n  Hao and Jianfeng Zhan", "title": "LoadCNN: A Low Training Cost Deep Learning Model for Day-Ahead\n  Individual Residential Load Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate day-ahead individual residential load forecasting is of great\nimportance to various applications of smart grid on day-ahead market. Deep\nlearning, as a powerful machine learning technology, has shown great advantages\nand promising application in load forecasting tasks. However, deep learning is\na computationally-hungry method, and requires high costs (e.g., time, energy\nand CO2 emission) to train a deep learning model, which aggravates the energy\ncrisis and incurs a substantial burden to the environment. As a consequence,\nthe deep learning methods are difficult to be popularized and applied in the\nreal smart grid environment. In this paper, we propose a low training cost\nmodel based on convolutional neural network, namely LoadCNN, for next-day load\nforecasting of individual resident with reduced training cost. The experiments\nshow that the training time of LoadCNN is only approximately 1/54 of the one of\nother state-of-the-art models, and energy consumption and CO2 emissions are\nonly approximate 1/45 of those of other state-of-the-art models based on the\nsame indicators. Meanwhile, the prediction accuracy of our model is equal to\nthat of current state-of-the-art models, making LoadCNN the first load\nforecasting model simultaneously achieving high prediction accuracy and low\ntraining costs. LoadCNN is an efficient green model that is able to be quickly,\ncost-effectively and environmentally-friendly deployed in a realistic smart\ngrid environment.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 09:51:01 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 09:17:40 GMT"}, {"version": "v3", "created": "Fri, 20 Dec 2019 01:55:40 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Huang", "Yunyou", ""], ["Wang", "Nana", ""], ["Gao", "Wanling", ""], ["Guo", "Xiaoxu", ""], ["Huang", "Cheng", ""], ["Hao", "Tianshu", ""], ["Zhan", "Jianfeng", ""]]}, {"id": "1908.00300", "submitter": "Feng Ji", "authors": "Runqi Yang, Jianhai Zhang, Xing Gao, Feng Ji, Haiqing Chen", "title": "Simple and Effective Text Matching with Richer Alignment Features", "comments": "11 pages, 7 tables, 3 figures, accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a fast and strong neural approach for general\npurpose text matching applications. We explore what is sufficient to build a\nfast and well-performed text matching model and propose to keep three key\nfeatures available for inter-sequence alignment: original point-wise features,\nprevious aligned features, and contextual features while simplifying all the\nremaining components. We conduct experiments on four well-studied benchmark\ndatasets across tasks of natural language inference, paraphrase identification\nand answer selection. The performance of our model is on par with the\nstate-of-the-art on all datasets with much fewer parameters and the inference\nspeed is at least 6 times faster compared with similarly performed ones.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 10:07:07 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Yang", "Runqi", ""], ["Zhang", "Jianhai", ""], ["Gao", "Xing", ""], ["Ji", "Feng", ""], ["Chen", "Haiqing", ""]]}, {"id": "1908.00308", "submitter": "Zili Wang", "authors": "Zili Wang", "title": "MSnet: A BERT-based Network for Gendered Pronoun Resolution", "comments": "7 pages; 1 figures; accepted by 1st ACL Workshop on Gender Bias for\n  NLP at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pre-trained BERT model achieves a remarkable state of the art across a\nwide range of tasks in natural language processing. For solving the gender bias\nin gendered pronoun resolution task, I propose a novel neural network model\nbased on the pre-trained BERT. This model is a type of mention score classifier\nand uses an attention mechanism with no parameters to compute the contextual\nrepresentation of entity span, and a vector to represent the triple-wise\nsemantic similarity among the pronoun and the entities. In stage 1 of the\ngendered pronoun resolution task, a variant of this model, trained in the\nfine-tuning approach, reduced the multi-class logarithmic loss to 0.3033 in the\n5-fold cross-validation of training set and 0.2795 in testing set. Besides,\nthis variant won the 2nd place with a score at 0.17289 in stage 2 of the task.\nThe code in this paper is available at:\nhttps://github.com/ziliwang/MSnet-for-Gendered-PronounResolution\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 10:27:29 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Wang", "Zili", ""]]}, {"id": "1908.00325", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef", "title": "Estimating the Standard Error of Cross-Validation-Based Estimators of\n  Classification Rules Performance", "comments": "The paper is currently under review in Pattern Recognition Letters\n  (PRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First, we analyze the variance of the Cross Validation (CV)-based estimators\nused for estimating the performance of classification rules. Second, we propose\na novel estimator to estimate this variance using the Influence Function (IF)\napproach that had been used previously very successfully to estimate the\nvariance of the bootstrap-based estimators. The motivation for this research is\nthat, as the best of our knowledge, the literature lacks a rigorous method for\nestimating the variance of the CV-based estimators. What is available is a set\nof ad-hoc procedures that have no mathematical foundation since they ignore the\ncovariance structure among dependent random variables. The conducted\nexperiments show that the IF proposed method has small RMS error with some\nbias. However, surprisingly, the ad-hoc methods still work better than the\nIF-based method. Unfortunately, this is due to the lack of enough smoothness if\ncompared to the bootstrap estimator. This opens the research for three points:\n(1) more comprehensive simulation study to clarify when the IF method win or\nloose; (2) more mathematical analysis to figure out why the ad-hoc methods work\nwell; and (3) more mathematical treatment to figure out the connection between\nthe appropriate amount of \"smoothness\" and decreasing the bias of the IF\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 11:00:36 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:41:03 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 16:39:01 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Yousef", "Waleed A.", ""]]}, {"id": "1908.00355", "submitter": "Dan Teng", "authors": "Dan Teng, Sakyasingha Dasgupta", "title": "Continual Learning via Online Leverage Score Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to mimic the human ability of continual acquisition and transfer of\nknowledge across various tasks, a learning system needs the capability for\ncontinual learning, effectively utilizing the previously acquired skills. As\nsuch, the key challenge is to transfer and generalize the knowledge learned\nfrom one task to other tasks, avoiding forgetting and interference of previous\nknowledge and improving the overall performance. In this paper, within the\ncontinual learning paradigm, we introduce a method that effectively forgets the\nless useful data samples continuously and allows beneficial information to be\nkept for training of the subsequent tasks, in an online manner. The method uses\nstatistical leverage score information to measure the importance of the data\nsamples in every task and adopts frequent directions approach to enable a\ncontinual or life-long learning property. This effectively maintains a constant\ntraining size across all tasks. We first provide mathematical intuition for the\nmethod and then demonstrate its effectiveness in avoiding catastrophic\nforgetting and computational efficiency on continual learning of classification\ntasks when compared with the existing state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 12:21:52 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Teng", "Dan", ""], ["Dasgupta", "Sakyasingha", ""]]}, {"id": "1908.00358", "submitter": "Zitao Liu", "authors": "Wenbiao Ding, Guowei Xu, Tianqiao Liu, Weiping Fu, Yujia Song, Chaoyou\n  Guo, Cong Kong, Songfan Yang, Gale Yan Huang, Zitao Liu", "title": "Dolphin: A Spoken Language Proficiency Assessment System for Elementary\n  Education", "comments": "Proceedings of The Web Conference 2020 (WWW '20)", "journal-ref": null, "doi": "10.1145/3366423.3380018", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language proficiency is critically important for children's growth and\npersonal development. Due to the limited and imbalanced educational resources\nin China, elementary students barely have chances to improve their oral\nlanguage skills in classes. Verbal fluency tasks (VFTs) were invented to let\nthe students practice their spoken language proficiency after school. VFTs are\nsimple but concrete math related questions that ask students to not only report\nanswers but speak out the entire thinking process. In spite of the great\nsuccess of VFTs, they bring a heavy grading burden to elementary teachers. To\nalleviate this problem, we develop Dolphin, a spoken language proficiency\nassessment system for Chinese elementary education. Dolphin is able to\nautomatically evaluate both phonological fluency and semantic relevance of\nstudents' VFT answers. We conduct a wide range of offline and online\nexperiments to demonstrate the effectiveness of Dolphin. In our offline\nexperiments, we show that Dolphin improves both phonological fluency and\nsemantic relevance evaluation performance when compared to state-of-the-art\nbaselines on real-world educational data sets. In our online A/B experiments,\nwe test Dolphin with 183 teachers from 2 major cities (Hangzhou and Xi'an) in\nChina for 10 weeks and the results show that VFT assignments grading coverage\nis improved by 22\\%.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 12:31:49 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 08:00:40 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 08:52:58 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Ding", "Wenbiao", ""], ["Xu", "Guowei", ""], ["Liu", "Tianqiao", ""], ["Fu", "Weiping", ""], ["Song", "Yujia", ""], ["Guo", "Chaoyou", ""], ["Kong", "Cong", ""], ["Yang", "Songfan", ""], ["Huang", "Gale Yan", ""], ["Liu", "Zitao", ""]]}, {"id": "1908.00361", "submitter": "C\\'esar Lincoln Cavalcante Mattos", "authors": "Thiago de P. Vasconcelos, Daniel A. R. M. A. de Souza, C\\'esar L. C.\n  Mattos and Jo\\~ao P. P. Gomes", "title": "No-PASt-BO: Normalized Portfolio Allocation Strategy for Bayesian\n  Optimization", "comments": "8 pages, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization (BO) is a framework for black-box optimization that is\nespecially suitable for expensive cost functions. Among the main parts of a BO\nalgorithm, the acquisition function is of fundamental importance, since it\nguides the optimization algorithm by translating the uncertainty of the\nregression model in a utility measure for each point to be evaluated.\nConsidering such aspect, selection and design of acquisition functions are one\nof the most popular research topics in BO. Since no single acquisition function\nwas proved to have better performance in all tasks, a well-established approach\nconsists of selecting different acquisition functions along the iterations of a\nBO execution. In such an approach, the GP-Hedge algorithm is a widely used\noption given its simplicity and good performance. Despite its success in\nvarious applications, GP-Hedge shows an undesirable characteristic of\naccounting on all past performance measures of each acquisition function to\nselect the next function to be used. In this case, good or bad values obtained\nin an initial iteration may impact the choice of the acquisition function for\nthe rest of the algorithm. This fact may induce a dominant behavior of an\nacquisition function and impact the final performance of the method. Aiming to\novercome such limitation, in this work we propose a variant of GP-Hedge, named\nNo-PASt-BO, that reduce the influence of far past evaluations. Moreover, our\nmethod presents a built-in normalization that avoids the functions in the\nportfolio to have similar probabilities, thus improving the exploration. The\nobtained results on both synthetic and real-world optimization tasks indicate\nthat No-PASt-BO presents competitive performance and always outperforms\nGP-Hedge.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 12:37:00 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Vasconcelos", "Thiago de P.", ""], ["de Souza", "Daniel A. R. M. A.", ""], ["Mattos", "C\u00e9sar L. C.", ""], ["Gomes", "Jo\u00e3o P. P.", ""]]}, {"id": "1908.00385", "submitter": "Pritam Sarkar", "authors": "Pritam Sarkar, Kyle Ross, Aaron J. Ruberto, Dirk Rodenburg, Paul\n  Hungler, Ali Etemad", "title": "Classification of Cognitive Load and Expertise for Adaptive Simulation\n  using Deep Multitask Learning", "comments": "2019 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": "10.1109/ACII.2019.8925507", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Simulations are a pedagogical means of enabling a risk-free way for\nhealthcare practitioners to learn, maintain, or enhance their knowledge and\nskills. Such simulations should provide an optimum amount of cognitive load to\nthe learner and be tailored to their levels of expertise. However, most current\nsimulations are a one-type-fits-all tool used to train different learners\nregardless of their existing skills, expertise, and ability to handle cognitive\nload. To address this problem, we propose an end-to-end framework for a trauma\nsimulation that actively classifies a participant's level of cognitive load and\nexpertise for the development of a dynamically adaptive simulation. To\nfacilitate this solution, trauma simulations were developed for the collection\nof electrocardiogram (ECG) signals of both novice and expert practitioners. A\nmultitask deep neural network was developed to utilize this data and classify\nhigh and low cognitive load, as well as expert and novice participants. A\nleave-one-subject-out (LOSO) validation was used to evaluate the effectiveness\nof our model, achieving an accuracy of 89.4% and 96.6% for classification of\ncognitive load and expertise, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 02:30:42 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Sarkar", "Pritam", ""], ["Ross", "Kyle", ""], ["Ruberto", "Aaron J.", ""], ["Rodenburg", "Dirk", ""], ["Hungler", "Paul", ""], ["Etemad", "Ali", ""]]}, {"id": "1908.00387", "submitter": "Dylan Cashman", "authors": "Dylan Cashman and Adam Perer and Remco Chang and Hendrik Strobelt", "title": "Ablate, Variate, and Contemplate: Visual Analytics for Discovering\n  Neural Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models require the configuration of many layers and parameters\nin order to get good results. However, there are currently few systematic\nguidelines for how to configure a successful model. This means model builders\noften have to experiment with different configurations by manually programming\ndifferent architectures (which is tedious and time consuming) or rely on purely\nautomated approaches to generate and train the architectures (which is\nexpensive). In this paper, we present Rapid Exploration of Model Architectures\nand Parameters, or REMAP, a visual analytics tool that allows a model builder\nto discover a deep learning model quickly via exploration and rapid\nexperimentation of neural network architectures. In REMAP, the user explores\nthe large and complex parameter space for neural network architectures using a\ncombination of global inspection and local experimentation. Through a visual\noverview of a set of models, the user identifies interesting clusters of\narchitectures. Based on their findings, the user can run ablation and variation\nexperiments to identify the effects of adding, removing, or replacing layers in\na given architecture and generate new models accordingly. They can also\nhandcraft new models using a simple graphical interface. As a result, a model\nbuilder can build deep learning models quickly, efficiently, and without manual\nprogramming. We inform the design of REMAP through a design study with four\ndeep learning model builders. Through a use case, we demonstrate that REMAP\nallows users to discover performant neural network architectures efficiently\nusing visual exploration and user-defined semi-automated searches through the\nmodel space.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 18:41:03 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Cashman", "Dylan", ""], ["Perer", "Adam", ""], ["Chang", "Remco", ""], ["Strobelt", "Hendrik", ""]]}, {"id": "1908.00398", "submitter": "Minkesh Asati", "authors": "Asati Minkesh, Kraisittipong Worranitta, Miyachi Taizo", "title": "Extract and Merge: Merging extracted humans from different images\n  utilizing Mask R-CNN", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting human objects out of the various type of objects in images and\nmerging them with other scenes is manual and day-to-day work for photo editors.\nAlthough recently Adobe photoshop released \"select subject\" tool which\nautomatically selects the foreground object in an image, but still requires\nfine manual tweaking separately. In this work, we proposed an application\nutilizing Mask R-CNN (for object detection and mask segmentation) that can\nextract human instances from multiple images and merge them with a new\nbackground. This application does not add any overhead to Mask R-CNN, running\nat 5 frames per second. It can extract human instances from any number of\nimages or videos from merging them together. We also structured the code to\naccept videos of different lengths as input and length of the output-video will\nbe equal to the longest input-video. We wanted to create a simple yet effective\napplication that can serve as a base for photo editing and do most\ntime-consuming work automatically, so, editors can focus more on the design\npart. Other application could be to group people together in a single picture\nwith a new background from different images which could not be physically\ntogether. We are showing single-person and multi-person extraction and\nplacement in two different backgrounds. Also, we are showing a video example\nwith single-person extraction.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 13:50:00 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Minkesh", "Asati", ""], ["Worranitta", "Kraisittipong", ""], ["Taizo", "Miyachi", ""]]}, {"id": "1908.00413", "submitter": "Hoyeop Lee", "authors": "Hoyeop Lee, Jinbae Im, Seongwon Jang, Hyunsouk Cho, Sehee Chung", "title": "MeLU: Meta-Learned User Preference Estimator for Cold-Start\n  Recommendation", "comments": "Accepted as a full paper at KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a recommender system to alleviate the cold-start problem\nthat can estimate user preferences based on only a small number of items. To\nidentify a user's preference in the cold state, existing recommender systems,\nsuch as Netflix, initially provide items to a user; we call those items\nevidence candidates. Recommendations are then made based on the items selected\nby the user. Previous recommendation studies have two limitations: (1) the\nusers who consumed a few items have poor recommendations and (2) inadequate\nevidence candidates are used to identify user preferences. We propose a\nmeta-learning-based recommender system called MeLU to overcome these two\nlimitations. From meta-learning, which can rapidly adopt new task with a few\nexamples, MeLU can estimate new user's preferences with a few consumed items.\nIn addition, we provide an evidence candidate selection strategy that\ndetermines distinguishing items for customized preference estimation. We\nvalidate MeLU with two benchmark datasets, and the proposed model reduces at\nleast 5.92% mean absolute error than two comparative models on the datasets. We\nalso conduct a user study experiment to verify the evidence selection strategy.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 07:43:00 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Lee", "Hoyeop", ""], ["Im", "Jinbae", ""], ["Jang", "Seongwon", ""], ["Cho", "Hyunsouk", ""], ["Chung", "Sehee", ""]]}, {"id": "1908.00419", "submitter": "Derek Bridge", "authors": "Derek Bridge and Mesut Kaya and Pablo Castells", "title": "Sudden Death: A New Way to Compare Recommendation Diversification", "comments": "4 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes problems with the current way we compare the diversity\nof different recommendation lists in offline experiments. We illustrate the\nproblems with a case study. We propose the Sudden Death score as a new and\nbetter way of making these comparisons.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 09:07:13 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Bridge", "Derek", ""], ["Kaya", "Mesut", ""], ["Castells", "Pablo", ""]]}, {"id": "1908.00420", "submitter": "David Eriksson", "authors": "David Eriksson, David Bindel, Christine A. Shoemaker", "title": "pySOT and POAP: An event-driven asynchronous framework for surrogate\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Plumbing for Optimization with Asynchronous Parallelism\n(POAP) and the Python Surrogate Optimization Toolbox (pySOT). POAP is an\nevent-driven framework for building and combining asynchronous optimization\nstrategies, designed for global optimization of expensive functions where\nconcurrent function evaluations are useful. POAP consists of three components:\na worker pool capable of function evaluations, strategies to propose\nevaluations or other actions, and a controller that mediates the interaction\nbetween the workers and strategies. pySOT is a collection of synchronous and\nasynchronous surrogate optimization strategies, implemented in the POAP\nframework. We support the stochastic RBF method by Regis and Shoemaker along\nwith various extensions of this method, and a general surrogate optimization\nstrategy that covers most Bayesian optimization methods. We have implemented\nmany different surrogate models, experimental designs, acquisition functions,\nand a large set of test problems. We make an extensive comparison between\nsynchronous and asynchronous parallelism and find that the advantage of\nasynchronous computation increases as the variance of the evaluation time or\nnumber of processors increases. We observe a close to linear speed-up with 4,\n8, and 16 processors in both the synchronous and asynchronous setting.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 18:06:18 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Eriksson", "David", ""], ["Bindel", "David", ""], ["Shoemaker", "Christine A.", ""]]}, {"id": "1908.00449", "submitter": "Jacob Harer", "authors": "Jacob Harer, Chris Reale and Peter Chin", "title": "Tree-Transformer: A Transformer-Based Method for Correction of\n  Tree-Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many common sequential data sources, such as source code and natural\nlanguage, have a natural tree-structured representation. These trees can be\ngenerated by fitting a sequence to a grammar, yielding a hierarchical ordering\nof the tokens in the sequence. This structure encodes a high degree of\nsyntactic information, making it ideal for problems such as grammar correction.\nHowever, little work has been done to develop neural networks that can operate\non and exploit tree-structured data. In this paper we present the\nTree-Transformer \\textemdash{} a novel neural network architecture designed to\ntranslate between arbitrary input and output trees. We applied this\narchitecture to correction tasks in both the source code and natural language\ndomains. On source code, our model achieved an improvement of $25\\%$\n$\\text{F}0.5$ over the best sequential method. On natural language, we achieved\ncomparable results to the most complex state of the art systems, obtaining a\n$10\\%$ improvement in recall on the CoNLL 2014 benchmark and the highest to\ndate $\\text{F}0.5$ score on the AESW benchmark of $50.43$.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 15:05:41 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Harer", "Jacob", ""], ["Reale", "Chris", ""], ["Chin", "Peter", ""]]}, {"id": "1908.00493", "submitter": "Mohamed Mahmoud", "authors": "Mohamed El-Geish", "title": "Learning Joint Acoustic-Phonetic Word Embeddings", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most speech recognition tasks pertain to mapping words across two modalities:\nacoustic and orthographic. In this work, we suggest learning encoders that map\nvariable-length, acoustic or phonetic, sequences that represent words into\nfixed-dimensional vectors in a shared latent space; such that the distance\nbetween two word vectors represents how closely the two words sound. Instead of\ndirectly learning the distances between word vectors, we employ weak\nsupervision and model a binary classification task to predict whether two\ninputs, one of each modality, represent the same word given a distance\nthreshold. We explore various deep-learning models, bimodal contrastive losses,\nand techniques for mining hard negative examples such as the semi-supervised\ntechnique of self-labeling. Our best model achieves an $F_1$ score of 0.95 for\nthe binary classification task.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 16:42:47 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["El-Geish", "Mohamed", ""]]}, {"id": "1908.00533", "submitter": "Abhishek Halder", "authors": "Kenneth F. Caluya, and Abhishek Halder", "title": "Gradient Flow Algorithms for Density Propagation in Stochastic Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.10844", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new computational framework to solve the partial differential\nequations (PDEs) governing the flow of the joint probability density functions\n(PDFs) in continuous-time stochastic nonlinear systems. The need for computing\nthe transient joint PDFs subject to prior dynamics arises in uncertainty\npropagation, nonlinear filtering and stochastic control. Our methodology breaks\naway from the traditional approach of spatial discretization or function\napproximation -- both of which, in general, suffer from the\n\"curse-of-dimensionality\". In the proposed framework, we discretize time but\nnot the state space. We solve infinite dimensional proximal recursions in the\nmanifold of joint PDFs, which in the small time-step limit, is theoretically\nequivalent to solving the underlying transport PDEs. The resulting computation\nhas the geometric interpretation of gradient flow of certain free energy\nfunctional with respect to the Wasserstein metric arising from the theory of\noptimal mass transport. We show that dualization along with an entropic\nregularization, leads to a cone-preserving fixed point recursion that is proved\nto be contractive in Thompson metric. A block co-ordinate iteration scheme is\nproposed to solve the resulting nonlinear recursions with guaranteed\nconvergence. This approach enables remarkably fast computation for\nnon-parametric transient joint PDF propagation. Numerical examples and various\nextensions are provided to illustrate the scope and efficacy of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 17:47:16 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 08:53:50 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Caluya", "Kenneth F.", ""], ["Halder", "Abhishek", ""]]}, {"id": "1908.00598", "submitter": "Janis Postels", "authors": "Janis Postels, Francesco Ferroni, Huseyin Coskun, Nassir Navab and\n  Federico Tombari", "title": "Sampling-free Epistemic Uncertainty Estimation Using Approximated\n  Variance Propagation", "comments": "International Conference on Computer Vision 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a sampling-free approach for computing the epistemic uncertainty\nof a neural network. Epistemic uncertainty is an important quantity for the\ndeployment of deep neural networks in safety-critical applications, since it\nrepresents how much one can trust predictions on new data. Recently promising\nworks were proposed using noise injection combined with Monte-Carlo sampling at\ninference time to estimate this quantity (e.g. Monte-Carlo dropout). Our main\ncontribution is an approximation of the epistemic uncertainty estimated by\nthese methods that does not require sampling, thus notably reducing the\ncomputational overhead. We apply our approach to large-scale visual tasks\n(i.e., semantic segmentation and depth regression) to demonstrate the\nadvantages of our method compared to sampling-based approaches in terms of\nquality of the uncertainty estimates as well as of computational overhead.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 19:53:35 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 09:21:15 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 20:18:54 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Postels", "Janis", ""], ["Ferroni", "Francesco", ""], ["Coskun", "Huseyin", ""], ["Navab", "Nassir", ""], ["Tombari", "Federico", ""]]}, {"id": "1908.00617", "submitter": "Armin Salimi-Badr", "authors": "Armin Salimi-Badr, Mohammad Mehdi Ebadzadeh", "title": "A self-organizing fuzzy neural network for sequence learning", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics, 2020", "doi": "10.1109/TCYB.2020.2984646", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new self-organizing fuzzy neural network model is presented\nwhich is able to learn and reproduce different sequences accurately. Sequence\nlearning is important in performing skillful tasks, such as writing and playing\npiano. The structure of the proposed network is composed of two parts:\n1-sequence identifier which computes a novel sequence identity value based on\ninitial samples of a sequence, and detects the sequence identity based on\nproper fuzzy rules, and 2-sequence locator, which locates the input sample in\nthe sequence. Therefore, by integrating outputs of these two parts in fuzzy\nrules, the network is able to produce the proper output based on current state\nof the sequence. To learn the proposed structure, a gradual learning procedure\nis proposed. First, learning is performed by adding new fuzzy rules, based on\ncoverage measure, using available correct data. Next, the initialized\nparameters are fine-tuned, by gradient descent algorithm, based on fed back\napproximated network output as the next input. The proposed method has a\ndynamic structure which is able to learn new sequences online. The proposed\nmethod is used to learn and reproduce different sequences simultaneously which\nis the novelty of this method.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 20:41:50 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 08:31:44 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Salimi-Badr", "Armin", ""], ["Ebadzadeh", "Mohammad Mehdi", ""]]}, {"id": "1908.00625", "submitter": "Juliana Siqueira-Gay", "authors": "J. Siqueira-Gay, M. A. Giannotti, M. Sester", "title": "Learning about spatial inequalities: Capturing the heterogeneity in the\n  urban environment", "comments": null, "journal-ref": null, "doi": "10.1016/j.jclepro.2019.117732", "report-no": null, "categories": "physics.soc-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transportation systems can be conceptualized as an instrument of spreading\npeople and resources over the territory, playing an important role in\ndeveloping sustainable cities. The current rationale of transport provision is\nbased on population demand, disregarding land use and socioeconomic\ninformation. To meet the challenge to promote a more equitable resource\ndistribution, this work aims at identifying and describing patterns of urban\nservices supply, their accessibility, and household income. By using a\nmultidimensional approach, the spatial inequalities of a large city of the\nglobal south reveal that the low-income population has low access mainly to\nhospitals and cultural centers. A low-income group presents an intermediate\nlevel of accessibility to public schools and sports centers, evidencing the\ndiverse condition of citizens in the peripheries. These complex outcomes\ngenerated by the interaction of land use and public transportation emphasize\nthe importance of comprehensive methodological approaches to support decisions\nof urban projects, plans and programs. Reducing spatial inequalities,\nespecially providing services for deprived groups, is fundamental to promote\nthe sustainable use of resources and optimize the daily commuting.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 16:39:28 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Siqueira-Gay", "J.", ""], ["Giannotti", "M. A.", ""], ["Sester", "M.", ""]]}, {"id": "1908.00635", "submitter": "Muhammad Usama", "authors": "Muhammad Usama, Junaid Qadir, and Ala Al-Fuqaha", "title": "Black-box Adversarial ML Attack on Modulation Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many deep neural networks (DNN) based modulation classification\nschemes have been proposed in the literature. We have evaluated the robustness\nof two famous such modulation classifiers (based on the techniques of\nconvolutional neural networks and long short term memory) against adversarial\nmachine learning attacks in black-box settings. We have used Carlini \\& Wagner\n(C-W) attack for performing the adversarial attack. To the best of our\nknowledge, the robustness of these modulation classifiers has not been\nevaluated through C-W attack before. Our results clearly indicate that\nstate-of-art deep machine learning-based modulation classifiers are not robust\nagainst adversarial attacks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 21:20:38 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "1908.00636", "submitter": "Dongrui Wu", "authors": "Yuqi Cui, Jian Huang and Dongrui Wu", "title": "Optimize TSK Fuzzy Systems for Classification Problems: Mini-Batch\n  Gradient Descent with Uniform Regularization and Batch Normalization", "comments": null, "journal-ref": "IEEE Trans. on Fuzzy Systems, 28(12):3065-3075, 2020", "doi": "10.1109/TFUZZ.2020.2967282", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Takagi-Sugeno-Kang (TSK) fuzzy systems are flexible and interpretable machine\nlearning models; however, they may not be easily optimized when the data size\nis large, and/or the data dimensionality is high. This paper proposes a\nmini-batch gradient descent (MBGD) based algorithm to efficiently and\neffectively train TSK fuzzy classifiers. It integrates two novel techniques: 1)\nuniform regularization (UR), which forces the rules to have similar average\ncontributions to the output, and hence to increase the generalization\nperformance of the TSK classifier; and, 2) batch normalization (BN), which\nextends BN from deep neural networks to TSK fuzzy classifiers to expedite the\nconvergence and improve the generalization performance. Experiments on 12 UCI\ndatasets from various application domains, with varying size and\ndimensionality, demonstrated that UR and BN are effective individually, and\nintegrating them can further improve the classification performance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 21:28:46 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 04:41:37 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 16:57:29 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Cui", "Yuqi", ""], ["Huang", "Jian", ""], ["Wu", "Dongrui", ""]]}, {"id": "1908.00637", "submitter": "Sacha Sokoloski", "authors": "Sacha Sokoloski and Ruben Coen-Cagli", "title": "Conditional Finite Mixtures of Poisson Distributions for\n  Context-Dependent Neural Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel recordings of neural spike counts have revealed the existence of\ncontext-dependent noise correlations in neural populations. Theories of\npopulation coding have also shown that such correlations can impact the\ninformation encoded by neural populations about external stimuli. Although\nstudies have shown that these correlations often have a low-dimensional\nstructure, it has proven difficult to capture this structure in a model that is\ncompatible with theories of rate coding in correlated populations. To address\nthis difficulty we develop a novel model based on conditional finite mixtures\nof independent Poisson distributions. The model can be conditioned on context\nvariables (e.g. stimuli or task variables), and the number of mixture\ncomponents in the model can be cross-validated to estimate the dimensionality\nof the target correlations. We derive an expectation-maximization algorithm to\nefficiently fit the model to realistic amounts of data from large neural\npopulations. We then demonstrate that the model successfully captures\nstimulus-dependent correlations in the responses of macaque V1 neurons to\noriented gratings. Our model incorporates arbitrary nonlinear\ncontext-dependence, and can thus be applied to improve predictions of neural\nactivity based on deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 21:29:31 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 14:33:10 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sokoloski", "Sacha", ""], ["Coen-Cagli", "Ruben", ""]]}, {"id": "1908.00648", "submitter": "Amine Trabelsi", "authors": "Amine Trabelsi and Osmar R. Zaiane", "title": "Contrastive Reasons Detection and Clustering from Online Polarized\n  Debate", "comments": "Best paper award in CICLing 2019: International Conference on\n  Computational Linguistics and Intelligent Text Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work tackles the problem of unsupervised modeling and extraction of the\nmain contrastive sentential reasons conveyed by divergent viewpoints on\npolarized issues. It proposes a pipeline approach centered around the detection\nand clustering of phrases, assimilated to argument facets using a novel Phrase\nAuthor Interaction Topic-Viewpoint model. The evaluation is based on the\ninformativeness, the relevance and the clustering accuracy of extracted\nreasons. The pipeline approach shows a significant improvement over\nstate-of-the-art methods in contrastive summarization on online debate\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 22:42:36 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Trabelsi", "Amine", ""], ["Zaiane", "Osmar R.", ""]]}, {"id": "1908.00658", "submitter": "Qihang Peng", "authors": "Qihang Peng, Andrew Gilman, Nuno Vasconcelos, Pamela C. Cosman, and\n  Laurence B. Milstein", "title": "Robust Deep Sensing Through Transfer Learning in Cognitive Radio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a robust spectrum sensing framework based on deep learning. The\nreceived signals at the secondary user's receiver are filtered, sampled and\nthen directly fed into a convolutional neural network. Although this deep\nsensing is effective when operating in the same scenario as the collected\ntraining data, the sensing performance is degraded when it is applied in a\ndifferent scenario with different wireless signals and propagation. We\nincorporate transfer learning into the framework to improve the robustness.\nResults validate the effectiveness as well as the robustness of the proposed\ndeep spectrum sensing framework.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 23:12:10 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Peng", "Qihang", ""], ["Gilman", "Andrew", ""], ["Vasconcelos", "Nuno", ""], ["Cosman", "Pamela C.", ""], ["Milstein", "Laurence B.", ""]]}, {"id": "1908.00673", "submitter": "Tony Lei", "authors": "FangYuan Lei, Xun Liu, QingYun Dai, Bingo Wing-Kuen Ling, Huimin Zhao,\n  Yan Liu", "title": "Hybrid Low-order and Higher-order Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With higher-order neighborhood information of graph network, the accuracy of\ngraph representation learning classification can be significantly improved.\nHowever, the current higher order graph convolutional network has a large\nnumber of parameters and high computational complexity. Therefore, we propose a\nHybrid Lower order and Higher order Graph convolutional networks (HLHG)\nlearning model, which uses weight sharing mechanism to reduce the number of\nnetwork parameters. To reduce computational complexity, we propose a novel\nfusion pooling layer to combine the neighborhood information of high order and\nlow order. Theoretically, we compare the model complexity of the proposed model\nwith the other state-of-the-art model. Experimentally, we verify the proposed\nmodel on the large-scale text network datasets by supervised learning, and on\nthe citation network datasets by semi-supervised learning. The experimental\nresults show that the proposed model achieves highest classification accuracy\nwith a small set of trainable weight parameters.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 01:20:54 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Lei", "FangYuan", ""], ["Liu", "Xun", ""], ["Dai", "QingYun", ""], ["Ling", "Bingo Wing-Kuen", ""], ["Zhao", "Huimin", ""], ["Liu", "Yan", ""]]}, {"id": "1908.00681", "submitter": "Bowen Yu", "authors": "Bowen Yu, Claudio T. Silva", "title": "FlowSense: A Natural Language Interface for Visual Data Exploration\n  within a Dataflow System", "comments": "Published in IEEE Transactions on Visualization and Computer Graphics", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934668", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataflow visualization systems enable flexible visual data exploration by\nallowing the user to construct a dataflow diagram that composes query and\nvisualization modules to specify system functionality. However learning\ndataflow diagram usage presents overhead that often discourages the user. In\nthis work we design FlowSense, a natural language interface for dataflow\nvisualization systems that utilizes state-of-the-art natural language\nprocessing techniques to assist dataflow diagram construction. FlowSense\nemploys a semantic parser with special utterance tagging and special utterance\nplaceholders to generalize to different datasets and dataflow diagrams. It\nexplicitly presents recognized dataset and diagram special utterances to the\nuser for dataflow context awareness. With FlowSense the user can expand and\nadjust dataflow diagrams more conveniently via plain English. We apply\nFlowSense to the VisFlow subset-flow visualization system to enhance its\nusability. We evaluate FlowSense by one case study with domain experts on a\nreal-world data analysis problem and a formal user study.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 02:19:21 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 18:30:35 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Yu", "Bowen", ""], ["Silva", "Claudio T.", ""]]}, {"id": "1908.00683", "submitter": "Farhad Pourkamali-Anaraki", "authors": "Farhad Pourkamali-Anaraki", "title": "Large-Scale Sparse Subspace Clustering Using Landmarks", "comments": "9 pages, accepted for publication in 2019 IEEE International Workshop\n  on Machine Learning for Signal Processing (MLSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering methods based on expressing each data point as a linear\ncombination of all other points in a dataset are popular unsupervised learning\ntechniques. However, existing methods incur high computational complexity on\nlarge-scale datasets as they require solving an expensive optimization problem\nand performing spectral clustering on large affinity matrices. This paper\npresents an efficient approach to subspace clustering by selecting a small\nsubset of the input data called landmarks. The resulting subspace clustering\nmethod in the reduced domain runs in linear time with respect to the size of\nthe original data. Numerical experiments on synthetic and real data demonstrate\nthe effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 02:39:40 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Pourkamali-Anaraki", "Farhad", ""]]}, {"id": "1908.00690", "submitter": "Bret Nestor", "authors": "Bret Nestor, Matthew B. A. McDermott, Willie Boag, Gabriela Berner,\n  Tristan Naumann, Michael C. Hughes, Anna Goldenberg, Marzyeh Ghassemi", "title": "Feature Robustness in Non-stationary Health Records: Caveats to\n  Deployable Model Performance in Common Clinical Machine Learning Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When training clinical prediction models from electronic health records\n(EHRs), a key concern should be a model's ability to sustain performance over\ntime when deployed, even as care practices, database systems, and population\ndemographics evolve. Due to de-identification requirements, however, current\nexperimental practices for public EHR benchmarks (such as the MIMIC-III\ncritical care dataset) are time agnostic, assigning care records to train or\ntest sets without regard for the actual dates of care. As a result, current\nbenchmarks cannot assess how well models trained on one year generalise to\nanother. In this work, we obtain a Limited Data Use Agreement to access year of\ncare for each record in MIMIC and show that all tested state-of-the-art models\ndecay in prediction quality when trained on historical data and tested on\nfuture data, particularly in response to a system-wide record-keeping change in\n2008 (0.29 drop in AUROC for mortality prediction, 0.10 drop in AUROC for\nlength-of-stay prediction with a random forest classifier). We further develop\na simple yet effective mitigation strategy: by aggregating raw features into\nexpert-defined clinical concepts, we see only a 0.06 drop in AUROC for\nmortality prediction and a 0.03 drop in AUROC for length-of-stay prediction. We\ndemonstrate that this aggregation strategy outperforms other automatic feature\npreprocessing techniques aimed at increasing robustness to data drift. We\nrelease our aggregated representations and code to encourage more deployable\nclinical prediction models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 03:03:25 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Nestor", "Bret", ""], ["McDermott", "Matthew B. A.", ""], ["Boag", "Willie", ""], ["Berner", "Gabriela", ""], ["Naumann", "Tristan", ""], ["Hughes", "Michael C.", ""], ["Goldenberg", "Anna", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "1908.00692", "submitter": "Tao Hu", "authors": "Tao Hu, Lichao Huang, Xianming Liu, Han Shen", "title": "Real Time Visual Tracking using Spatial-Aware Temporal Aggregation\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More powerful feature representations derived from deep neural networks\nbenefit visual tracking algorithms widely. However, the lack of exploitation on\ntemporal information prevents tracking algorithms from adapting to appearances\nchanging or resisting to drift. This paper proposes a correlation filter based\ntracking method which aggregates historical features in a spatial-aligned and\nscale-aware paradigm. The features of historical frames are sampled and\naggregated to search frame according to a pixel-level alignment module based on\ndeformable convolutions. In addition, we also use a feature pyramid structure\nto handle motion estimation at different scales, and address the different\ndemands on feature granularity between tracking losses and deformation offset\nlearning. By this design, the tracker, named as Spatial-Aware Temporal\nAggregation network (SATA), is able to assemble appearances and motion contexts\nof various scales in a time period, resulting in better performance compared to\na single static image. Our tracker achieves leading performance in OTB2013,\nOTB2015, VOT2015, VOT2016 and LaSOT, and operates at a real-time speed of 26\nFPS, which indicates our method is effective and practical. Our code will be\nmade publicly available at\n\\href{https://github.com/ecart18/SATA}{https://github.com/ecart18/SATA}.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 03:22:58 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Hu", "Tao", ""], ["Huang", "Lichao", ""], ["Liu", "Xianming", ""], ["Shen", "Han", ""]]}, {"id": "1908.00695", "submitter": "Johannes Schmidt-Hieber", "authors": "Johannes Schmidt-Hieber", "title": "Deep ReLU network approximation of functions on a manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas recovery of the manifold from data is a well-studied topic,\napproximation rates for functions defined on manifolds are less known. In this\nwork, we study a regression problem with inputs on a $d^*$-dimensional manifold\nthat is embedded into a space with potentially much larger ambient dimension.\nIt is shown that sparsely connected deep ReLU networks can approximate a\nH\\\"older function with smoothness index $\\beta$ up to error $\\epsilon$ using of\nthe order of $\\epsilon^{-d^*/\\beta}\\log(1/\\epsilon)$ many non-zero network\nparameters. As an application, we derive statistical convergence rates for the\nestimator minimizing the empirical risk over all possible choices of bounded\nnetwork parameters.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 04:01:13 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Schmidt-Hieber", "Johannes", ""]]}, {"id": "1908.00698", "submitter": "Robert M\\\"uller", "authors": "Robert M\\\"uller, Stefan Langer, Fabian Ritz, Christoph Roch, Steffen\n  Illium, Claudia Linnhoff-Popien", "title": "Soccer Team Vectors", "comments": "11 pages, 1 figure; This paper was presented at the 6th Workshop on\n  Machine Learning and Data Mining for Sports Analytics at ECML/PKDD 2019,\n  W\\\"urzburg, Germany, 2019", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2019. Communications in Computer and Information Science, vol 1168. Springer,\n  Cham", "doi": "10.1007/978-3-030-43887-6_19", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present STEVE - Soccer TEam VEctors, a principled approach\nfor learning real valued vectors for soccer teams where similar teams are close\nto each other in the resulting vector space. STEVE only relies on freely\navailable information about the matches teams played in the past. These vectors\ncan serve as input to various machine learning tasks. Evaluating on the task of\nteam market value estimation, STEVE outperforms all its competitors. Moreover,\nwe use STEVE for similarity search and to rank soccer teams.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 13:46:16 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 12:51:09 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["M\u00fcller", "Robert", ""], ["Langer", "Stefan", ""], ["Ritz", "Fabian", ""], ["Roch", "Christoph", ""], ["Illium", "Steffen", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1908.00700", "submitter": "Guannan Liang", "authors": "Qianqian Tong, Guannan Liang and Jinbo Bi", "title": "Calibrating the Adaptive Learning Rate to Improve Convergence of ADAM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient methods (AGMs) have become popular in optimizing the\nnonconvex problems in deep learning area. We revisit AGMs and identify that the\nadaptive learning rate (A-LR) used by AGMs varies significantly across the\ndimensions of the problem over epochs (i.e., anisotropic scale), which may lead\nto issues in convergence and generalization. All existing modified AGMs\nactually represent efforts in revising the A-LR. Theoretically, we provide a\nnew way to analyze the convergence of AGMs and prove that the convergence rate\nof \\textsc{Adam} also depends on its hyper-parameter $\\epsilon$, which has been\noverlooked previously. Based on these two facts, we propose a new AGM by\ncalibrating the A-LR with an activation ({\\em softplus}) function, resulting in\nthe \\textsc{Sadam} and \\textsc{SAMSGrad} methods \\footnote{Code is available at\nhttps://github.com/neilliang90/Sadam.git.}. We further prove that these\nalgorithms enjoy better convergence speed under nonconvex, non-strongly convex,\nand Polyak-{\\L}ojasiewicz conditions compared with \\textsc{Adam}. Empirical\nstudies support our observation of the anisotropic A-LR and show that the\nproposed methods outperform existing AGMs and generalize even better than\nS-Momentum in multiple deep learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 04:20:34 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 15:13:36 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Tong", "Qianqian", ""], ["Liang", "Guannan", ""], ["Bi", "Jinbo", ""]]}, {"id": "1908.00704", "submitter": "Alireza Naghizadeh", "authors": "Alireza Naghizadeh and Mohammadsajad Abavisani and Dimitris N. Metaxas", "title": "Greedy AutoAugment", "comments": "Pattern Recognition Letters (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major problem in data augmentation is to ensure that the generated new\nsamples cover the search space. This is a challenging problem and requires\nexploration for data augmentation policies to ensure their effectiveness in\ncovering the search space. In this paper, we propose Greedy AutoAugment as a\nhighly efficient search algorithm to find the best augmentation policies. We\nuse a greedy approach to reduce the exponential growth of the number of\npossible trials to linear growth. The Greedy Search also helps us to lead the\nsearch towards the sub-policies with better results, which eventually helps to\nincrease the accuracy. The proposed method can be used as a reliable addition\nto the current artifitial neural networks. Our experiments on four datasets\n(Tiny ImageNet, CIFAR-10, CIFAR-100, and SVHN) show that Greedy AutoAugment\nprovides better accuracy, while using 360 times fewer computational resources.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 05:28:03 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 01:34:48 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Naghizadeh", "Alireza", ""], ["Abavisani", "Mohammadsajad", ""], ["Metaxas", "Dimitris N.", ""]]}, {"id": "1908.00706", "submitter": "Puneet Mangla", "authors": "Puneet Mangla, Surgan Jandial, Sakshi Varshney, Vineeth N\n  Balasubramanian", "title": "AdvGAN++ : Harnessing latent layers for adversary generation", "comments": "Accepted at Neural Architects Workshop, ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are fabricated examples, indistinguishable from the\noriginal image that mislead neural networks and drastically lower their\nperformance. Recently proposed AdvGAN, a GAN based approach, takes input image\nas a prior for generating adversaries to target a model. In this work, we show\nhow latent features can serve as better priors than input images for adversary\ngeneration by proposing AdvGAN++, a version of AdvGAN that achieves higher\nattack rates than AdvGAN and at the same time generates perceptually realistic\nimages on MNIST and CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 05:37:03 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 19:31:19 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Mangla", "Puneet", ""], ["Jandial", "Surgan", ""], ["Varshney", "Sakshi", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1908.00709", "submitter": "Xin He", "authors": "Xin He, Kaiyong Zhao, Xiaowen Chu", "title": "AutoML: A Survey of the State-of-the-Art", "comments": "automated machine learning (AutoML), published in journal of\n  Knowledge-Based Systems", "journal-ref": "Knowledge-Based Systems, Volume 212, 5 January 2021, 106622", "doi": "10.1016/j.knosys.2020.106622", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning (DL) techniques have penetrated all aspects of our lives and\nbrought us great convenience. However, building a high-quality DL system for a\nspecific task highly relies on human expertise, hindering the applications of\nDL to more areas. Automated machine learning (AutoML) becomes a promising\nsolution to build a DL system without human assistance, and a growing number of\nresearchers focus on AutoML. In this paper, we provide a comprehensive and\nup-to-date review of the state-of-the-art (SOTA) in AutoML. First, we introduce\nAutoML methods according to the pipeline, covering data preparation, feature\nengineering, hyperparameter optimization, and neural architecture search (NAS).\nWe focus more on NAS, as it is currently very hot sub-topic of AutoML. We\nsummarize the performance of the representative NAS algorithms on the CIFAR-10\nand ImageNet datasets and further discuss several worthy studying directions of\nNAS methods: one/two-stage NAS, one-shot NAS, and joint hyperparameter and\narchitecture optimization. Finally, we discuss some open problems of the\nexisting AutoML methods for future research.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 05:56:13 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 16:11:15 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 13:05:19 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2020 15:00:06 GMT"}, {"version": "v5", "created": "Wed, 8 Jul 2020 11:43:36 GMT"}, {"version": "v6", "created": "Fri, 16 Apr 2021 03:38:23 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["He", "Xin", ""], ["Zhao", "Kaiyong", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1908.00720", "submitter": "Xinhai Liu", "authors": "Xinhai Liu, Zhizhong Han, Xin Wen, Yu-Shen Liu, Matthias Zwicker", "title": "L2G Auto-encoder: Understanding Point Clouds by Local-to-Global\n  Reconstruction with Hierarchical Self-Attention", "comments": null, "journal-ref": null, "doi": "10.1145/3343031.3350960", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-encoder is an important architecture to understand point clouds in an\nencoding and decoding procedure of self reconstruction. Current auto-encoder\nmainly focuses on the learning of global structure by global shape\nreconstruction, while ignoring the learning of local structures. To resolve\nthis issue, we propose Local-to-Global auto-encoder (L2G-AE) to simultaneously\nlearn the local and global structure of point clouds by local to global\nreconstruction. Specifically, L2G-AE employs an encoder to encode the geometry\ninformation of multiple scales in a local region at the same time. In addition,\nwe introduce a novel hierarchical self-attention mechanism to highlight the\nimportant points, scales and regions at different levels in the information\naggregation of the encoder. Simultaneously, L2G-AE employs a recurrent neural\nnetwork (RNN) as decoder to reconstruct a sequence of scales in a local region,\nbased on which the global point cloud is incrementally reconstructed. Our\noutperforming results in shape classification, retrieval and upsampling show\nthat L2G-AE can understand point clouds better than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 06:50:59 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Liu", "Xinhai", ""], ["Han", "Zhizhong", ""], ["Wen", "Xin", ""], ["Liu", "Yu-Shen", ""], ["Zwicker", "Matthias", ""]]}, {"id": "1908.00722", "submitter": "Robin Strudel", "authors": "Robin Strudel, Alexander Pashevich, Igor Kalevatykh, Ivan Laptev,\n  Josef Sivic, Cordelia Schmid", "title": "Learning to combine primitive skills: A step towards versatile robotic\n  manipulation", "comments": "ICRA 2020. See the project webpage at\n  https://www.di.ens.fr/willow/research/rlbc/", "journal-ref": "IEEE ROBOTICS AND AUTOMATION LETTERS, JULY 2020. 4637-4643", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulation tasks such as preparing a meal or assembling furniture remain\nhighly challenging for robotics and vision. Traditional task and motion\nplanning (TAMP) methods can solve complex tasks but require full state\nobservability and are not adapted to dynamic scene changes. Recent learning\nmethods can operate directly on visual inputs but typically require many\ndemonstrations and/or task-specific reward engineering. In this work we aim to\novercome previous limitations and propose a reinforcement learning (RL)\napproach to task planning that learns to combine primitive skills. First,\ncompared to previous learning methods, our approach requires neither\nintermediate rewards nor complete task demonstrations during training. Second,\nwe demonstrate the versatility of our vision-based task planning in challenging\nsettings with temporary occlusions and dynamic scene changes. Third, we propose\nan efficient training of basic skills from few synthetic demonstrations by\nexploring recent CNN architectures and data augmentation. Notably, while all of\nour policies are learned on visual inputs in simulated environments, we\ndemonstrate the successful transfer and high success rates when applying such\npolicies to manipulation tasks on a real UR5 robotic arm.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:04:17 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 16:02:27 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 14:26:45 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Strudel", "Robin", ""], ["Pashevich", "Alexander", ""], ["Kalevatykh", "Igor", ""], ["Laptev", "Ivan", ""], ["Sivic", "Josef", ""], ["Schmid", "Cordelia", ""]]}, {"id": "1908.00723", "submitter": "Jin Jun Li", "authors": "Jin Li", "title": "Universal Transforming Geometric Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recurrent geometric network (RGN), the first end-to-end differentiable\nneural architecture for protein structure prediction, is a competitive\nalternative to existing models. However, the RGN's use of recurrent neural\nnetworks (RNNs) as internal representations results in long training time and\nunstable gradients. And because of its sequential nature, it is less effective\nat learning global dependencies among amino acids than existing transformer\narchitectures. We propose the Universal Transforming Geometric Network (UTGN),\nan end-to-end differentiable model that uses the encoder portion of the\nUniversal Transformer architecture as an alternative for internal\nrepresentations. Our experiments show that compared to RGN, UTGN achieve a\n$1.7$ \\si{\\angstrom} improvement on the free modeling portion and a $0.7$\n\\si{\\angstrom} improvement on the template based modeling of the CASP12\ncompetition.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:14:08 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Li", "Jin", ""]]}, {"id": "1908.00727", "submitter": "Hongliang Duan", "authors": "Hongliang Duan, Ling Wang, Chengyun Zhang, Jianjun Li", "title": "Retrosynthesis with Attention-Based NMT Model and Chemical Analysis of\n  the \"Wrong\" Predictions", "comments": "15 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We cast retrosynthesis as a machine translation problem by introducing a\nspecial Tensor2Tensor, an entire attention-based and fully data-driven model.\nGiven a data set comprising about 50,000 diverse reactions extracted from USPTO\npatents, the model significantly outperforms seq2seq model (34.7%) on a top-1\naccuracy by achieving 54.1%. For yielding better results, parameters such as\nbatch size and training time are thoroughly investigated to train the model.\nAdditionally, we offer a novel insight into the causes of grammatically invalid\nSMILES, and conduct a test in which experienced chemists pick out and analyze\nthe \"wrong\" predictions that may be chemically plausible but differ from the\nground truth. Actually, the effectiveness of our model is un-derestimated and\nthe \"true\" top-1 accuracy can reach to 64.6%.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:34:38 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Duan", "Hongliang", ""], ["Wang", "Ling", ""], ["Zhang", "Chengyun", ""], ["Li", "Jianjun", ""]]}, {"id": "1908.00733", "submitter": "Mohammad Sadegh Aliakbarian", "authors": "Mohammad Sadegh Aliakbarian, Fatemeh Sadat Saleh, Mathieu Salzmann,\n  Lars Petersson, Stephen Gould, Amirhossein Habibian", "title": "Learning Variations in Human Motion via Mix-and-Match Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human motion prediction is a stochastic process: Given an observed sequence\nof poses, multiple future motions are plausible. Existing approaches to\nmodeling this stochasticity typically combine a random noise vector with\ninformation about the previous poses. This combination, however, is done in a\ndeterministic manner, which gives the network the flexibility to learn to\nignore the random noise. In this paper, we introduce an approach to\nstochastically combine the root of variations with previous pose information,\nwhich forces the model to take the noise into account. We exploit this idea for\nmotion prediction by incorporating it into a recurrent encoder-decoder network\nwith a conditional variational autoencoder block that learns to exploit the\nperturbations. Our experiments demonstrate that our model yields high-quality\npose sequences that are much more diverse than those from state-of-the-art\nstochastic motion prediction techniques.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:48:48 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 22:03:12 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Aliakbarian", "Mohammad Sadegh", ""], ["Saleh", "Fatemeh Sadat", ""], ["Salzmann", "Mathieu", ""], ["Petersson", "Lars", ""], ["Gould", "Stephen", ""], ["Habibian", "Amirhossein", ""]]}, {"id": "1908.00734", "submitter": "Marco Schreyer", "authors": "Marco Schreyer, Timur Sattarov, Christian Schulze, Bernd Reimer, and\n  Damian Borth", "title": "Detection of Accounting Anomalies in the Latent Space using Adversarial\n  Autoencoder Neural Networks", "comments": "11 pages, 9 figures, 2nd KDD Workshop on Anomaly Detection in\n  Finance, August 05, 2019, Anchorage, Alaska", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of fraud in accounting data is a long-standing challenge in\nfinancial statement audits. Nowadays, the majority of applied techniques refer\nto handcrafted rules derived from known fraud scenarios. While fairly\nsuccessful, these rules exhibit the drawback that they often fail to generalize\nbeyond known fraud scenarios and fraudsters gradually find ways to circumvent\nthem. In contrast, more advanced approaches inspired by the recent success of\ndeep learning often lack seamless interpretability of the detected results. To\novercome this challenge, we propose the application of adversarial autoencoder\nnetworks. We demonstrate that such artificial neural networks are capable of\nlearning a semantic meaningful representation of real-world journal entries.\nThe learned representation provides a holistic view on a given set of journal\nentries and significantly improves the interpretability of detected accounting\nanomalies. We show that such a representation combined with the networks\nreconstruction error can be utilized as an unsupervised and highly adaptive\nanomaly assessment. Experiments on two datasets and initial feedback received\nby forensic accountants underpinned the effectiveness of the approach.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:50:29 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Schreyer", "Marco", ""], ["Sattarov", "Timur", ""], ["Schulze", "Christian", ""], ["Reimer", "Bernd", ""], ["Borth", "Damian", ""]]}, {"id": "1908.00735", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt, Barbara Hammer", "title": "Efficient computation of counterfactual explanations of LVQ models", "comments": "Short version accepted at ESANN-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of machine learning in practice and legal regulations like\nEU's GDPR cause the necessity to be able to explain the prediction and behavior\nof machine learning models. A prominent example of particularly intuitive\nexplanations of AI models in the context of decision making are counterfactual\nexplanations. Yet, it is still an open research problem how to efficiently\ncompute counterfactual explanations for many models.\n  We investigate how to efficiently compute counterfactual explanations for an\nimportant class of models, prototype-based classifiers such as learning vector\nquantization models. In particular, we derive specific convex and non-convex\nprograms depending on the used metric.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:51:37 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 09:47:49 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "1908.00754", "submitter": "Abon Chaudhuri", "authors": "Abon Chaudhuri", "title": "A Visual Technique to Analyze Flow of Information in a Machine Learning\n  System", "comments": "Published in Visualization and Data Analysis (VDA), part of IS&T\n  Electronic Imaging Symposium 2018", "journal-ref": null, "doi": "10.2352/ISSN.2470-1173.2018.01.VDA-380", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) algorithms and machine learning based software systems\nimplicitly or explicitly involve complex flow of information between various\nentities such as training data, feature space, validation set and results.\nUnderstanding the statistical distribution of such information and how they\nflow from one entity to another influence the operation and correctness of such\nsystems, especially in large-scale applications that perform classification or\nprediction in real time. In this paper, we propose a visual approach to\nunderstand and analyze flow of information during model training and serving\nphases. We build the visualizations using a technique called Sankey Diagram -\nconventionally used to understand data flow among sets - to address various use\ncases of in a machine learning system. We demonstrate how the proposed\ntechnique, tweaked and twisted to suit a classification problem, can play a\ncritical role in better understanding of the training data, the features, and\nthe classifier performance. We also discuss how this technique enables\ndiagnostic analysis of model predictions and comparative analysis of\npredictions from multiple classifiers. The proposed concept is illustrated with\nthe example of categorization of millions of products in the e-commerce domain\n- a multi-class hierarchical classification problem.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 08:31:36 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Chaudhuri", "Abon", ""]]}, {"id": "1908.00762", "submitter": "Kamel Jebreen Mr", "authors": "Kamel Jebreen and Badih Ghattas", "title": "Inferring linear and nonlinear Interaction networks using neighborhood\n  support vector machines", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider modelling interaction between a set of variables\nin the context of time series and high dimension. We suggest two approaches.\nThe first is similar to the neighborhood lasso when the lasso model is replaced\nby a support vector machine (SVMs). The second is a restricted Bayesian network\nadapted for time series. We show the efficiency of our approaches by\nsimulations using linear, nonlinear data set and a mixture of both.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 09:00:14 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Jebreen", "Kamel", ""], ["Ghattas", "Badih", ""]]}, {"id": "1908.00763", "submitter": "Ninnart Fuengfusin", "authors": "Ninnart Fuengfusin, Hakaru Tamukoh", "title": "Network with Sub-Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce network with sub-networks, a neural network which its weight\nlayers could be detached into sub-neural networks during inference. To develop\nweights and biases which could be inserted in both base and sub-neural\nnetworks, firstly, the parameters are copied from sub-model to base-model. Each\nmodel is forward-propagated separately. Gradients from a pair of networks are\naveraged and, used to update both networks. Our base model achieves the\ntest-accuracy which is comparable to the regularly trained models, while the\nmodel maintains the ability to detach weight layers.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 09:04:28 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 04:41:02 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Fuengfusin", "Ninnart", ""], ["Tamukoh", "Hakaru", ""]]}, {"id": "1908.00766", "submitter": "S{\\l}awomir Kapka", "authors": "S{\\l}awomir Kapka, Mateusz Lewandowski", "title": "Sound source detection, localization and classification using\n  consecutive ensemble of CRNN models", "comments": "5 pages, 3 figures, conference", "journal-ref": "Proceedings of the Detection and Classification of Acoustic Scenes\n  and Events 2019 Workshop (DCASE2019), New York University, NY, USA, October\n  2019", "doi": "10.33682/1syg-dy60", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our method for DCASE2019 task3: Sound Event\nLocalization and Detection (SELD). We use four CRNN SELDnet-like single output\nmodels which run in a consecutive manner to recover all possible information of\noccurring events. We decompose the SELD task into estimating number of active\nsources, estimating direction of arrival of a single source, estimating\ndirection of arrival of the second source where the direction of the first one\nis known and a multi-label classification task. We use custom consecutive\nensemble to predict events' onset, offset, direction of arrival and class. The\nproposed approach is evaluated on the TAU Spatial Sound Events 2019 - Ambisonic\nand it is compared with other participants' submissions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 09:10:08 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 09:55:34 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Kapka", "S\u0142awomir", ""], ["Lewandowski", "Mateusz", ""]]}, {"id": "1908.00780", "submitter": "Puyu Wang", "authors": "Puyu Wang and Hai Zhang", "title": "Differential Privacy for Sparse Classification Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a differential privacy version of convex and\nnonconvex sparse classification approach. Based on alternating direction method\nof multiplier (ADMM) algorithm, we transform the solving of sparse problem into\nthe multistep iteration process. Then we add exponential noise to stable steps\nto achieve privacy protection. By the property of the post-processing holding\nof differential privacy, the proposed approach satisfies the\n$\\epsilon-$differential privacy even when the original problem is unstable.\nFurthermore, we present the theoretical privacy bound of the differential\nprivacy classification algorithm. Specifically, the privacy bound of our\nalgorithm is controlled by the algorithm iteration number, the privacy\nparameter, the parameter of loss function, ADMM pre-selected parameter, and the\ndata size. Finally we apply our framework to logistic regression with $L_1$\nregularizer and logistic regression with $L_{1/2}$ regularizer. Numerical\nstudies demonstrate that our method is both effective and efficient which\nperforms well in sensitive data analysis.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 09:57:04 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Wang", "Puyu", ""], ["Zhang", "Hai", ""]]}, {"id": "1908.00785", "submitter": "Francois Coste", "authors": "Fran\\c{c}ois Coste (Dyliss)", "title": "Deep learning languages: a key fundamental shift from probabilities to\n  weights?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes in language modeling, notably with deep learning methods,\ncoincide with a shift from probabilistic to weighted representations. We raise\nhere the question of the importance of this evolution, in the light of the\npractical limitations of a classical and simple probabilistic modeling approach\nfor the classification of protein sequences and in relation to the need for\nprincipled methods to learn non-probabilistic models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 10:09:51 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Coste", "Fran\u00e7ois", "", "Dyliss"]]}, {"id": "1908.00812", "submitter": "Eirina Bourtsoulatze", "authors": "Eirina Bourtsoulatze, Aaron Chadha, Ilya Fadeev, Vasileios Giotsas,\n  Yiannis Andreopoulos", "title": "Deep Video Precoding", "comments": "16 pages, 14 figures, 11 tables, to appear in IEEE Trans. Circ. Syst.\n  for Video Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several groups are currently investigating how deep learning may advance the\nstate-of-the-art in image and video coding. An open question is how to make\ndeep neural networks work in conjunction with existing (and upcoming) video\ncodecs, such as MPEG AVC, HEVC, VVC, Google VP9 and AOM AV1, as well as\nexisting container and transport formats, without imposing any changes at the\nclient side. Such compatibility is a crucial aspect when it comes to practical\ndeployment, especially due to the fact that the video content industry and\nhardware manufacturers are expected to remain committed to these standards for\nthe foreseeable future. We propose to use deep neural networks as precoders for\ncurrent and future video codecs and adaptive video streaming systems. In our\ncurrent design, the core precoding component comprises a cascaded structure of\ndownscaling neural networks that operates during video encoding, prior to\ntransmission. This is coupled with a precoding mode selection algorithm for\neach independently-decodable stream segment, which adjusts the downscaling\nfactor according to scene characteristics, the utilized encoder, and the\ndesired bitrate and encoding configuration. Our framework is compatible with\nall current and future codec and transport standards, as our deep precoding\nnetwork structure is trained in conjunction with linear upscaling filters\n(e.g., the bilinear filter), which are supported by all web video players.\nResults with FHD and UHD content and widely-used AVC, HEVC and VP9 encoders\nshow that coupling such standards with the proposed deep video precoding allows\nfor 15% to 45% rate reduction under encoding configurations and bitrates\nsuitable for video-on-demand adaptive streaming systems. The use of precoding\ncan also lead to encoding complexity reduction, which is essential for\ncost-effective cloud deployment of complex encoders like H.265/HEVC and VP9.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 11:44:14 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 20:10:34 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Bourtsoulatze", "Eirina", ""], ["Chadha", "Aaron", ""], ["Fadeev", "Ilya", ""], ["Giotsas", "Vasileios", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1908.00814", "submitter": "Pengcheng Lin", "authors": "Wan-Lei Zhao, Hui Wang, Peng-Cheng Lin, and Chong-Wah Ngo", "title": "On the Merge of k-NN Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  k-nearest neighbor graph is a fundamental data structure in many disciplines\nsuch as information retrieval, data-mining, pattern recognition, and machine\nlearning, etc. In the literature, considerable research has been focusing on\nhow to efficiently build an approximate k-nearest neighbor graph (k-NN graph)\nfor a fixed dataset. Unfortunately, a closely related issue of how to merge two\nexisting k-NN graphs has been overlooked. In this paper, we address the issue\nof k-NN graph merging in two different scenarios. In the first scenario, a\nsymmetric merge algorithm is proposed to combine two approximate k-NN graphs.\nThe algorithm facilitates large-scale processing by the efficient merging of\nk-NN graphs that are produced in parallel. In the second scenario, a joint\nmerge algorithm is proposed to expand an existing k-NN graph with a raw\ndataset. The algorithm enables the incremental construction of a hierarchical\napproximate k-NN graph. Superior performance is attained when leveraging the\nhierarchy for NN search of various data types, dimensionality, and distance\nmeasures.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 11:46:42 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 08:16:48 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 01:45:23 GMT"}, {"version": "v4", "created": "Fri, 13 Mar 2020 06:37:05 GMT"}, {"version": "v5", "created": "Wed, 15 Apr 2020 04:07:35 GMT"}, {"version": "v6", "created": "Thu, 29 Jul 2021 11:07:40 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Zhao", "Wan-Lei", ""], ["Wang", "Hui", ""], ["Lin", "Peng-Cheng", ""], ["Ngo", "Chong-Wah", ""]]}, {"id": "1908.00825", "submitter": "Abdul-Saboor Sheikh", "authors": "Romain Guigour\\`es, Yuen King Ho, Evgenii Koriagin, Abdul-Saboor\n  Sheikh, Urs Bergmann, Reza Shirvany", "title": "A Hierarchical Bayesian Model for Size Recommendation in Fashion", "comments": null, "journal-ref": "In: Proceedings of the 12th ACM Conference on Recommender Systems.\n  ACM, 2018. S. 392-396", "doi": "10.1145/3240323.3240388", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a hierarchical Bayesian approach to tackle the challenging\nproblem of size recommendation in e-commerce fashion. Our approach jointly\nmodels a size purchased by a customer, and its possible return event: 1. no\nreturn, 2. returned too small 3. returned too big. Those events are drawn\nfollowing a multinomial distribution parameterized on the joint probability of\neach event, built following a hierarchy combining priors. Such a model allows\nus to incorporate extended domain expertise and article characteristics as\nprior knowledge, which in turn makes it possible for the underlying parameters\nto emerge thanks to sufficient data. Experiments are presented on real\n(anonymized) data from millions of customers along with a detailed discussion\non the efficiency of such an approach within a large scale production system.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 12:31:22 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Guigour\u00e8s", "Romain", ""], ["Ho", "Yuen King", ""], ["Koriagin", "Evgenii", ""], ["Sheikh", "Abdul-Saboor", ""], ["Bergmann", "Urs", ""], ["Shirvany", "Reza", ""]]}, {"id": "1908.00831", "submitter": "Masoud Mansoury", "authors": "Masoud Mansoury, Bamshad Mobasher, Robin Burke, Mykola Pechenizkiy", "title": "Bias Disparity in Collaborative Recommendation: Algorithmic Evaluation\n  and Comparison", "comments": "Workshop on Recommendation in Multi-Stakeholder Environments (RMSE)\n  at ACM RecSys 2019, Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on fairness in machine learning has been recently extended to\nrecommender systems. One of the factors that may impact fairness is bias\ndisparity, the degree to which a group's preferences on various item categories\nfail to be reflected in the recommendations they receive. In some cases biases\nin the original data may be amplified or reversed by the underlying\nrecommendation algorithm. In this paper, we explore how different\nrecommendation algorithms reflect the tradeoff between ranking quality and bias\ndisparity. Our experiments include neighborhood-based, model-based, and\ntrust-aware recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 13:00:27 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Mansoury", "Masoud", ""], ["Mobasher", "Bamshad", ""], ["Burke", "Robin", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1908.00858", "submitter": "Muhamad Risqi U. Saputra", "authors": "Muhamad Risqi U. Saputra, Pedro P. B. de Gusmao, Yasin Almalioglu,\n  Andrew Markham, Niki Trigoni", "title": "Distilling Knowledge From a Deep Pose Regressor Network", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel method to distill knowledge from a deep pose\nregressor network for efficient Visual Odometry (VO). Standard distillation\nrelies on \"dark knowledge\" for successful knowledge transfer. As this knowledge\nis not available in pose regression and the teacher prediction is not always\naccurate, we propose to emphasize the knowledge transfer only when we trust the\nteacher. We achieve this by using teacher loss as a confidence score which\nplaces variable relative importance on the teacher prediction. We inject this\nconfidence score to the main training task via Attentive Imitation Loss (AIL)\nand when learning the intermediate representation of the teacher through\nAttentive Hint Training (AHT) approach. To the best of our knowledge, this is\nthe first work which successfully distill the knowledge from a deep pose\nregression network. Our evaluation on the KITTI and Malaga dataset shows that\nwe can keep the student prediction close to the teacher with up to 92.95%\nparameter reduction and 2.12x faster in computation time.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 13:48:31 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Saputra", "Muhamad Risqi U.", ""], ["de Gusmao", "Pedro P. B.", ""], ["Almalioglu", "Yasin", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1908.00868", "submitter": "Owen Howell", "authors": "Owen Howell and Cui Wenping and Robert Marsland III and Pankaj Mehta", "title": "Machine Learning as Ecology", "comments": null, "journal-ref": null, "doi": "10.1088/1751-8121/ab956e", "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods have had spectacular success on numerous problems.\nHere we show that a prominent class of learning algorithms - including Support\nVector Machines (SVMs) -- have a natural interpretation in terms of ecological\ndynamics. We use these ideas to design new online SVM algorithms that exploit\necological invasions, and benchmark performance using the MNIST dataset. Our\nwork provides a new ecological lens through which we can view statistical\nlearning and opens the possibility of designing ecosystems for machine\nlearning.\n  Supplemental code is found at https://github.com/owenhowell20/EcoSVM.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 14:08:17 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 13:52:08 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Howell", "Owen", ""], ["Wenping", "Cui", ""], ["Marsland", "Robert", "III"], ["Mehta", "Pankaj", ""]]}, {"id": "1908.00876", "submitter": "Henrik Skibbe", "authors": "Henrik Skibbe, Akiya Watakabe, Ken Nakae, Carlos Enrique Gutierrez,\n  Hiromichi Tsukada, Junichi Hata, Takashi Kawase, Rui Gong, Alexander\n  Woodward, Kenji Doya, Hideyuki Okano, Tetsuo Yamamori, Shin Ishii", "title": "MarmoNet: a pipeline for automated projection mapping of the common\n  marmoset brain from whole-brain serial two-photon tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the connectivity in the brain is an important prerequisite for\nunderstanding how the brain processes information. In the Brain/MINDS project,\na connectivity study on marmoset brains uses two-photon microscopy fluorescence\nimages of axonal projections to collect the neuron connectivity from defined\nbrain regions at the mesoscopic scale. The processing of the images requires\nthe detection and segmentation of the axonal tracer signal. The objective is to\ndetect as much tracer signal as possible while not misclassifying other\nbackground structures as the signal. This can be challenging because of imaging\nnoise, a cluttered image background, distortions or varying image contrast\ncause problems.\n  We are developing MarmoNet, a pipeline that processes and analyzes tracer\nimage data of the common marmoset brain. The pipeline incorporates\nstate-of-the-art machine learning techniques based on artificial convolutional\nneural networks (CNN) and image registration techniques to extract and map all\nrelevant information in a robust manner. The pipeline processes new images in a\nfully automated way.\n  This report introduces the current state of the tracer signal analysis part\nof the pipeline.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 14:20:27 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Skibbe", "Henrik", ""], ["Watakabe", "Akiya", ""], ["Nakae", "Ken", ""], ["Gutierrez", "Carlos Enrique", ""], ["Tsukada", "Hiromichi", ""], ["Hata", "Junichi", ""], ["Kawase", "Takashi", ""], ["Gong", "Rui", ""], ["Woodward", "Alexander", ""], ["Doya", "Kenji", ""], ["Okano", "Hideyuki", ""], ["Yamamori", "Tetsuo", ""], ["Ishii", "Shin", ""]]}, {"id": "1908.00878", "submitter": "Samuel Rey", "authors": "Samuel Rey, Antonio G. Marques, and Santiago Segarra", "title": "An Underparametrized Deep Decoder Architecture for Graph Signals", "comments": "This paper has already been accepted on 2019 IEEE International\n  Workshop on Computational Advances in Multi-Sensor Adaptive Processing\n  (CAMSAP) and it is going to be published in its proceedings", "journal-ref": null, "doi": "10.1109/CAMSAP45676.2019.9022676", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep convolutional architectures have achieved remarkable results in a\ngamut of supervised applications dealing with images and speech, recent works\nshow that deep untrained non-convolutional architectures can also outperform\nstate-of-the-art methods in several tasks such as image compression and\ndenoising. Motivated by the fact that many contemporary datasets have an\nirregular structure different from a 1D/2D grid, this paper generalizes\nuntrained and underparametrized non-convolutional architectures to signals\ndefined over irregular domains represented by graphs. The proposed architecture\nconsists of a succession of layers, each of them implementing an upsampling\noperator, a linear feature combination, and a scalar nonlinearity. A novel\nelement is the incorporation of upsampling operators accounting for the\nstructure of the supporting graph, which is achieved by considering a\nsystematic graph coarsening approach based on hierarchical clustering. The\nnumerical results carried out in synthetic and real-world datasets showcase\nthat the reconstruction performance can improve drastically if the information\nof the supporting graph topology is taken into account.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 14:21:43 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 12:30:33 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Rey", "Samuel", ""], ["Marques", "Antonio G.", ""], ["Segarra", "Santiago", ""]]}, {"id": "1908.00882", "submitter": "David Blei", "authors": "Rajesh Ranganath and David M. Blei", "title": "Population Predictive Checks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian modeling has become a staple for researchers analyzing data. Thanks\nto recent developments in approximate posterior inference, modern researchers\ncan easily build, use, and revise complicated Bayesian models for large and\nrich data. These new abilities, however, bring into focus the problem of model\nassessment. Researchers need tools to diagnose the fitness of their models, to\nunderstand where a model falls short, and to guide its revision. In this paper\nwe develop a new method for Bayesian model checking, the population predictive\ncheck (Pop-PC). Pop-PCs are built on posterior predictive checks (PPC), a\nseminal method that checks a model by assessing the posterior predictive\ndistribution on the observed data. Though powerful, PPCs use the data\ntwice---both to calculate the posterior predictive and to evaluate it---which\ncan lead to overconfident assessments. Pop-PCs, in contrast, compare the\nposterior predictive distribution to the population distribution of the data.\nThis strategy blends Bayesian modeling with frequentist assessment, leading to\na robust check that validates the model on its generalization. Of course the\npopulation distribution is not usually available; thus we use tools like the\nbootstrap and cross validation to estimate the Pop-PC. Further, we extend\nPop-PCs to hierarchical models. We study Pop-PCs on classical regression and a\nhierarchical model of text. We show that Pop-PCs are robust to overfitting and\ncan be easily deployed on a broad family of models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 14:37:29 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 01:37:54 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Ranganath", "Rajesh", ""], ["Blei", "David M.", ""]]}, {"id": "1908.00907", "submitter": "Yeman Brhane Hagos", "authors": "Yeman Brhane Hagos, Priya Lakshmi Narayanan, Ayse U. Akarca, Teresa\n  Marafioti, and Yinyin Yuan", "title": "ConCORDe-Net: Cell Count Regularized Convolutional Neural Network for\n  Cell Detection in Multiplex Immunohistochemistry Images", "comments": "MICCAI2019 accepted, 3 figures,8.5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In digital pathology, cell detection and classification are often\nprerequisites to quantify cell abundance and explore tissue spatial\nheterogeneity. However, these tasks are particularly challenging for multiplex\nimmunohistochemistry (mIHC) images due to high levels of variability in\nstaining, expression intensity, and inherent noise as a result of preprocessing\nartefacts. We proposed a deep learning method to detect and classify cells in\nmIHC whole-tumour slide images of breast cancer. Inspired by inception-v3, we\ndeveloped Cell COunt RegularizeD Convolutional neural Network (ConCORDe-Net)\nwhich integrates conventional dice overlap and a new cell count loss function\nfor optimizing cell detection, followed by a multi-stage convolutional neural\nnetwork for cell classification. In total, 20447 cells, belonging to five cell\nclasses were annotated by experts from 175 patches extracted from 6\nwhole-tumour mIHC images. These patches were randomly split into training,\nvalidation and testing sets. Using ConCORDe-Net, we obtained a cell detection\nF1 score of 0.873, which is the best score compared to three state of the art\nmethods. In particular, ConCORDe-Net excels at detecting closely located and\nweakly stained cells compared to other methods. Incorporating cell count loss\nin the objective function regularizes the network to learn weak gradient\nboundaries and separate weakly stained cells from background artefacts.\nMoreover, cell classification accuracy of 96.5% was achieved. These results\nsupport that incorporating problem-specific knowledge such as cell count into\ndeep learning-based cell detection architectures improve the robustness of the\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 12:51:01 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Hagos", "Yeman Brhane", ""], ["Narayanan", "Priya Lakshmi", ""], ["Akarca", "Ayse U.", ""], ["Marafioti", "Teresa", ""], ["Yuan", "Yinyin", ""]]}, {"id": "1908.00920", "submitter": "Nils Haug", "authors": "Nils Haug, Stefan Thurner, Alexandra Kautzky-Willer, Michael Gyimesi,\n  Peter Klimek", "title": "Identification of gatekeeper diseases on the way to cardiovascular\n  mortality", "comments": null, "journal-ref": null, "doi": null, "report-no": "18 pages + 62 pages Supplementary Information", "categories": "physics.med-ph cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimorbidity, the co-occurrence of two or more chronic diseases such as\ndiabetes, obesity or cardiovascular diseases in one patient, is a frequent\nphenomenon. To make care more efficient, it is of relevance to understand how\ndifferent diseases condition each other over the life time of a patient.\nHowever, most of our current knowledge on such patient careers is either\nconfined to narrow time spans or specific (sets of) diseases. Here, we present\na population-wide analysis of long-term patient trajectories by clustering them\naccording to their disease history observed over 17 years. When patients\nacquire new diseases, their cluster assignment might change. A health\ntrajectory can then be described by a temporal sequence of disease clusters.\nFrom the transitions between clusters we construct an age-dependent multilayer\nnetwork of disease clusters. Random walks on this multilayer network provide a\nmore precise model for the time evolution of multimorbid health states when\ncompared to models that cluster patients based on single diseases. Our results\ncan be used to identify decisive events that potentially determine the future\ndisease trajectory of a patient. We find that for elderly patients the cluster\nnetwork consists of regions of low, medium and high in-hospital mortality.\nDiagnoses of diabetes and hypertension are found to strongly increase the\nlikelihood for patients to subsequently move into the high-mortality region\nlater in life.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 15:44:12 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Haug", "Nils", ""], ["Thurner", "Stefan", ""], ["Kautzky-Willer", "Alexandra", ""], ["Gyimesi", "Michael", ""], ["Klimek", "Peter", ""]]}, {"id": "1908.00941", "submitter": "Qiuqiang Kong", "authors": "Jie Jiang, Qiuqiang Kong, Mark Plumbley, Nigel Gilbert", "title": "Deep Learning Based Energy Disaggregation and On/Off Detection of\n  Household Appliances", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy disaggregation, a.k.a. Non-Intrusive Load Monitoring, aims to separate\nthe energy consumption of individual appliances from the readings of a mains\npower meter measuring the total energy consumption of, e.g. a whole house.\nEnergy consumption of individual appliances can be useful in many applications,\ne.g., providing appliance-level feedback to the end users to help them\nunderstand their energy consumption and ultimately save energy. Recently, with\nthe availability of large-scale energy consumption datasets, various neural\nnetwork models such as convolutional neural networks and recurrent neural\nnetworks have been investigated to solve the energy disaggregation problem.\nNeural network models can learn complex patterns from large amounts of data and\nhave been shown to outperform the traditional machine learning methods such as\nvariants of hidden Markov models. However, current neural network methods for\nenergy disaggregation are either computational expensive or are not capable of\nhandling long-term dependencies. In this paper, we investigate the application\nof the recently developed WaveNet models for the task of energy disaggregation.\nBased on a real-world energy dataset collected from 20 households over two\nyears, we show that WaveNet models outperforms the state-of-the-art deep\nlearning methods proposed in the literature for energy disaggregation in terms\nof both error measures and computational cost. On the basis of energy\ndisaggregation, we then investigate the performance of two deep-learning based\nframeworks for the task of on/off detection which aims at estimating whether an\nappliance is in operation or not. Based on the same dataset, we show that for\nthe task of on/off detection the second framework, i.e., directly training a\nbinary classifier, achieves better performance in terms of F1 score.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:23:35 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 09:20:42 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Jiang", "Jie", ""], ["Kong", "Qiuqiang", ""], ["Plumbley", "Mark", ""], ["Gilbert", "Nigel", ""]]}, {"id": "1908.00948", "submitter": "Stefan Lattner", "authors": "Stefan Lattner and Maarten Grachten", "title": "High-Level Control of Drum Track Generation Using Learned Patterns of\n  Rhythmic Interaction", "comments": "Paper accepted at the IEEE Workshop on Applications of Signal\n  Processing to Audio and Acoustics (WASPAA 2019), New Paltz, New York, U.S.A.,\n  October 20-23; 6 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.HC cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spurred by the potential of deep learning, computational music generation has\ngained renewed academic interest. A crucial issue in music generation is that\nof user control, especially in scenarios where the music generation process is\nconditioned on existing musical material. Here we propose a model for\nconditional kick drum track generation that takes existing musical material as\ninput, in addition to a low-dimensional code that encodes the desired relation\nbetween the existing material and the new material to be generated. These\nrelational codes are learned in an unsupervised manner from a music dataset. We\nshow that codes can be sampled to create a variety of musically plausible kick\ndrum tracks and that the model can be used to transfer kick drum patterns from\none song to another. Lastly, we demonstrate that the learned codes are largely\ninvariant to tempo and time-shift.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 16:39:02 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Lattner", "Stefan", ""], ["Grachten", "Maarten", ""]]}, {"id": "1908.00963", "submitter": "Mathukumalli Vidyasagar", "authors": "Shantanu Prasad Burnwal and Mathukumalli Vidyasagar", "title": "Deterministic Completion of Rectangular Matrices Using Asymmetric\n  Ramanujan Graphs: Exact and Stable Recovery", "comments": "The original submission 1908.00963 has been split into two parts. The\n  replacement submission is Part-1 of the revised version. Part-2 can also be\n  found on arXiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the matrix completion problem: Suppose $X \\in {\\mathbb\nR}^{n_r \\times n_c}$ is unknown except for a known upper bound $r$ on its rank.\nBy measuring a small number $m \\ll n_r n_c$ of elements of $X$, is it possible\nto recover $X$ exactly with noise-free measurements, or to construct a good\napproximation of $X$ with noisy measurements? Existing solutions to these\nproblems involve sampling the elements uniformly and at random, and can\nguarantee exact recovery of the unknown matrix only with high probability. In\nthis paper, we present a \\textit{deterministic} sampling method for matrix\ncompletion. We achieve this by choosing the sampling set as the edge set of an\nasymmetric Ramanujan bigraph, and constrained nuclear norm minimization is the\nrecovery method. Specifically, we derive sufficient conditions under which the\nunknown matrix is completed exactly with noise-free measurements, and is\napproximately completed with noisy measurements, which we call \"stable\"\ncompletion.\n  The conditions derived here are only sufficient and more restrictive than\nrandom sampling. To study how close they are to being necessary, we conducted\nnumerical simulations on randomly generated low rank matrices, using the LPS\nfamilies of Ramanujan graphs. These simulations demonstrate two facts: (i) In\norder to achieve exact completion, it appears sufficient to choose the degree\n$d$ of the Ramanujan graph to be $\\geq 3r$. (ii) There is a \"phase transition,\"\nwhereby the likelihood of success suddenly drops from 100\\% to 0\\% if the rank\nis increased by just one or two beyond a critical value. The phase transition\nphenomenon is well-known and well-studied in vector recovery using\n$\\ell_1$-norm minimization. However, it is less studied in matrix completion\nand nuclear norm minimization, and not much understood.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 17:32:56 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 16:56:17 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 15:18:12 GMT"}, {"version": "v4", "created": "Thu, 21 May 2020 11:20:07 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Burnwal", "Shantanu Prasad", ""], ["Vidyasagar", "Mathukumalli", ""]]}, {"id": "1908.00966", "submitter": "Chun-An Chou", "authors": "Chun-An Chou and Qingtao Cao and Shao-Jen Weng and Che-Hung Tsai", "title": "Mixed-Integer Optimization Approach to Learning Association Rules for\n  Unplanned ICU Transfer", "comments": null, "journal-ref": "Artificial Intelligence in Medicine, 2020", "doi": "10.1016/j.artmed.2020.101806", "report-no": null, "categories": "cs.LG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After admission to emergency department (ED), patients with critical\nillnesses are transferred to intensive care unit (ICU) due to unexpected\nclinical deterioration occurrence. Identifying such unplanned ICU transfers is\nurgently needed for medical physicians to achieve two-fold goals: improving\ncritical care quality and preventing mortality. A priority task is to\nunderstand the crucial rationale behind diagnosis results of individual\npatients during stay in ED, which helps prepare for an early transfer to ICU.\nMost existing prediction studies were based on univariate analysis or multiple\nlogistic regression to provide one-size-fit-all results. However, patient\ncondition varying from case to case may not be accurately examined by the only\njudgment. In this study, we present a new decision tool using a mathematical\noptimization approach aiming to automatically discover rules associating\ndiagnostic features with high-risk outcome (i.e., unplanned transfers) in\ndifferent deterioration scenarios. We consider four mutually exclusive patient\nsubgroups based on the principal reasons of ED visits: infections,\ncardiovascular/respiratory diseases, gastrointestinal diseases, and\nneurological/other diseases at a suburban teaching hospital. The analysis\nresults demonstrate significant rules associated with unplanned transfer\noutcome for each subgroups and also show comparable prediction accuracy,\ncompared to state-of-the-art machine learning methods while providing\neasy-to-interpret symptom-outcome information.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 17:45:50 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Chou", "Chun-An", ""], ["Cao", "Qingtao", ""], ["Weng", "Shao-Jen", ""], ["Tsai", "Che-Hung", ""]]}, {"id": "1908.00975", "submitter": "Hengrong Lan", "authors": "Hengrong Lan, Daohuai Jiang, Changchun Yang, Fei Gao", "title": "Y-Net: A Hybrid Deep Learning Reconstruction Framework for Photoacoustic\n  Imaging in vivo", "comments": "submitted the journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photoacoustic imaging (PAI) is an emerging non-invasive imaging modality\ncombining the advantages of deep ultrasound penetration and high optical\ncontrast. Image reconstruction is an essential topic in PAI, which is\nunfortunately an ill-posed problem due to the complex and unknown\noptical/acoustic parameters in tissue. Conventional algorithms used in PAI\n(e.g., delay-and-sum) provide a fast solution while many artifacts remain,\nespecially for linear array probe with limited-view issue. Convolutional neural\nnetwork (CNN) has shown state-of-the-art results in computer vision, and more\nand more work based on CNN has been studied in medical image processing\nrecently. In this paper, we present a non-iterative scheme filling the gap\nbetween existing direct-processing and post-processing methods, and propose a\nnew framework Y-Net: a CNN architecture to reconstruct the PA image by\noptimizing both raw data and beamformed images once. The network connected two\nencoders with one decoder path, which optimally utilizes more information from\nraw data and beamformed image. The results of the test set showed good\nperformance compared with conventional reconstruction algorithms and other deep\nlearning methods. Our method is also validated with experiments both in-vitro\nand in vivo, which still performs better than other existing methods. The\nproposed Y-Net architecture also has high potential in medical image\nreconstruction for other imaging modalities beyond PAI.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:27:17 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Lan", "Hengrong", ""], ["Jiang", "Daohuai", ""], ["Yang", "Changchun", ""], ["Gao", "Fei", ""]]}, {"id": "1908.00999", "submitter": "Hao Tang", "authors": "Hao Tang, Dan Xu, Gaowen Liu, Wei Wang, Nicu Sebe, Yan Yan", "title": "Cycle In Cycle Generative Adversarial Networks for Keypoint-Guided Image\n  Generation", "comments": "9 pages, 8 figures, accepted to ACM MM 2019", "journal-ref": "ACM MM 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel Cycle In Cycle Generative Adversarial\nNetwork (C$^2$GAN) for the task of keypoint-guided image generation. The\nproposed C$^2$GAN is a cross-modal framework exploring a joint exploitation of\nthe keypoint and the image data in an interactive manner. C$^2$GAN contains two\ndifferent types of generators, i.e., keypoint-oriented generator and\nimage-oriented generator. Both of them are mutually connected in an end-to-end\nlearnable fashion and explicitly form three cycled sub-networks, i.e., one\nimage generation cycle and two keypoint generation cycles. Each cycle not only\naims at reconstructing the input domain, and also produces useful output\ninvolving in the generation of another cycle. By so doing, the cycles constrain\neach other implicitly, which provides complementary information from the two\ndifferent modalities and brings extra supervision across cycles, thus\nfacilitating more robust optimization of the whole network. Extensive\nexperimental results on two publicly available datasets, i.e., Radboud Faces\nand Market-1501, demonstrate that our approach is effective to generate more\nphoto-realistic images compared with state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 18:21:28 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 17:49:23 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 00:53:39 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Tang", "Hao", ""], ["Xu", "Dan", ""], ["Liu", "Gaowen", ""], ["Wang", "Wei", ""], ["Sebe", "Nicu", ""], ["Yan", "Yan", ""]]}, {"id": "1908.01000", "submitter": "Fan-Yun Sun", "authors": "Fan-Yun Sun, Jordan Hoffmann, Vikas Verma, Jian Tang", "title": "InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation\n  Learning via Mutual Information Maximization", "comments": "ICLR 2020 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies learning the representations of whole graphs in both\nunsupervised and semi-supervised scenarios. Graph-level representations are\ncritical in a variety of real-world applications such as predicting the\nproperties of molecules and community analysis in social networks. Traditional\ngraph kernel based methods are simple, yet effective for obtaining fixed-length\nrepresentations for graphs but they suffer from poor generalization due to\nhand-crafted designs. There are also some recent methods based on language\nmodels (e.g. graph2vec) but they tend to only consider certain substructures\n(e.g. subtrees) as graph representatives. Inspired by recent progress of\nunsupervised representation learning, in this paper we proposed a novel method\ncalled InfoGraph for learning graph-level representations. We maximize the\nmutual information between the graph-level representation and the\nrepresentations of substructures of different scales (e.g., nodes, edges,\ntriangles). By doing so, the graph-level representations encode aspects of the\ndata that are shared across different scales of substructures. Furthermore, we\nfurther propose InfoGraph*, an extension of InfoGraph for semi-supervised\nscenarios. InfoGraph* maximizes the mutual information between unsupervised\ngraph representations learned by InfoGraph and the representations learned by\nexisting supervised methods. As a result, the supervised encoder learns from\nunlabeled data while preserving the latent semantic space favored by the\ncurrent supervised task. Experimental results on the tasks of graph\nclassification and molecular property prediction show that InfoGraph is\nsuperior to state-of-the-art baselines and InfoGraph* can achieve performance\ncompetitive with state-of-the-art semi-supervised models.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 06:28:43 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 16:24:01 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 16:20:00 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Sun", "Fan-Yun", ""], ["Hoffmann", "Jordan", ""], ["Verma", "Vikas", ""], ["Tang", "Jian", ""]]}, {"id": "1908.01007", "submitter": "Spencer Frazier", "authors": "Spencer Frazier, Mark Riedl", "title": "Improving Deep Reinforcement Learning in Minecraft with Action Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep reinforcement learning agents complex behaviors in 3D virtual\nenvironments requires significant computational resources. This is especially\ntrue in environments with high degrees of aliasing, where many states share\nnearly identical visual features. Minecraft is an exemplar of such an\nenvironment. We hypothesize that interactive machine learning IML, wherein\nhuman teachers play a direct role in training through demonstrations, critique,\nor action advice, may alleviate agent susceptibility to aliasing. However,\ninteractive machine learning is only practical when the number of human\ninteractions is limited, requiring a balance between human teacher effort and\nagent performance. We conduct experiments with two reinforcement learning\nalgorithms which enable human teachers to give action advice, Feedback\nArbitration and Newtonian Action Advice, under visual aliasing conditions. To\nassess potential cognitive load per advice type, we vary the accuracy and\nfrequency of various human action advice techniques. Training efficiency,\nrobustness against infrequent and inaccurate advisor input, and sensitivity to\naliasing are examined.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 18:36:44 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Frazier", "Spencer", ""], ["Riedl", "Mark", ""]]}, {"id": "1908.01009", "submitter": "Xiangju Qin", "authors": "Xiangju Qin, Paul Blomstedt and Samuel Kaski", "title": "Scalable Bayesian Non-linear Matrix Completion", "comments": "7 pages, 1 figures, 2 tables. The paper has been accepted for\n  publication in the proceedings of the 28th International Joint Conference on\n  Artificial Intelligence (IJCAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion aims to predict missing elements in a partially observed\ndata matrix which in typical applications, such as collaborative filtering, is\nlarge and extremely sparsely observed. A standard solution is matrix\nfactorization, which predicts unobserved entries as linear combinations of\nlatent variables. We generalize to non-linear combinations in massive-scale\nmatrices. Bayesian approaches have been proven beneficial in linear matrix\ncompletion, but not applied in the more general non-linear case, due to limited\nscalability. We introduce a Bayesian non-linear matrix completion algorithm,\nwhich is based on a recent Bayesian formulation of Gaussian process latent\nvariable models. To solve the challenges regarding scalability and computation,\nwe propose a data-parallel distributed computational approach with a restricted\ncommunication scheme. We evaluate our method on challenging out-of-matrix\nprediction tasks using both simulated and real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 16:48:31 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Qin", "Xiangju", ""], ["Blomstedt", "Paul", ""], ["Kaski", "Samuel", ""]]}, {"id": "1908.01010", "submitter": "Bangti Jin", "authors": "Chen Zhang and Bangti Jin", "title": "Probabilistic Residual Learning for Aleatoric Uncertainty in Image\n  Restoration", "comments": "this version is outdated, and we are completely reorganizing the\n  paper and split it into several different pieces of work. Thus, we prefer to\n  withdraw it from arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aleatoric uncertainty is an intrinsic property of ill-posed inverse and\nimaging problems. Its quantification is vital for assessing the reliability of\nrelevant point estimates. In this paper, we propose an efficient framework for\nquantifying aleatoric uncertainty for deep residual learning and showcase its\nsignificant potential on image restoration. In the framework, we divide the\nconditional probability modeling for the residual variable into a deterministic\nhomo-dimensional level, a stochastic low-dimensional level and a merging level.\nThe low-dimensionality is especially suitable for sparse correlation between\nimage pixels, enables efficient sampling for high dimensional problems and acts\nas a regularizer for the distribution. Preliminary numerical experiments show\nthat the proposed method can give not only state-of-the-art point estimates of\nimage restoration but also useful associated uncertainty information.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 16:06:07 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 13:42:49 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Zhang", "Chen", ""], ["Jin", "Bangti", ""]]}, {"id": "1908.01022", "submitter": "Ross Allen", "authors": "Ross E. Allen, Jayesh K. Gupta, Jaime Pena, Yutai Zhou, Javona White\n  Bear, Mykel J. Kochenderfer", "title": "Health-Informed Policy Gradients for Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a definition of system health in the context of multiple\nagents optimizing a joint reward function. We use this definition as a credit\nassignment term in a policy gradient algorithm to distinguish the contributions\nof individual agents to the global reward. The health-informed credit\nassignment is then extended to a multi-agent variant of the proximal policy\noptimization algorithm and demonstrated on particle and multiwalker robot\nenvironments that have characteristics such as system health, risk-taking,\nsemi-expendable agents, continuous action spaces, and partial observability. We\nshow significant improvement in learning performance compared to policy\ngradient methods that do not perform multi-agent credit assignment.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 19:20:29 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:12:54 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 20:44:39 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 20:16:46 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Allen", "Ross E.", ""], ["Gupta", "Jayesh K.", ""], ["Pena", "Jaime", ""], ["Zhou", "Yutai", ""], ["Bear", "Javona White", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1908.01031", "submitter": "Adam Gudy\\'s", "authors": "Adam Gudy\\'s, Marek Sikora, {\\L}ukasz Wr\\'obel", "title": "RuleKit: A Comprehensive Suite for Rule-Based Learning", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": "10.1016/j.knosys.2020.105480", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule-based models are often used for data analysis as they combine\ninterpretability with predictive power. We present RuleKit, a versatile tool\nfor rule learning. Based on a sequential covering induction algorithm, it is\nsuitable for classification, regression, and survival problems. The presence of\na user-guided induction facilitates verifying hypotheses concerning data\ndependencies which are expected or of interest. The powerful and flexible\nexperimental environment allows straightforward investigation of different\ninduction schemes. The analysis can be performed in batch mode, through\nRapidMiner plug-in, or R package. A documented Java API is also provided for\nconvenience. The software is publicly available at GitHub under GNU AGPL-3.0\nlicense.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 19:53:46 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Gudy\u015b", "Adam", ""], ["Sikora", "Marek", ""], ["Wr\u00f3bel", "\u0141ukasz", ""]]}, {"id": "1908.01034", "submitter": "Vasilis Kontonis", "authors": "Vasilis Kontonis, Christos Tzamos, Manolis Zampetakis", "title": "Efficient Truncated Statistics with Unknown Truncation", "comments": "to appear at 60th Annual IEEE Symposium on Foundations of Computer\n  Science (FOCS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the parameters of a Gaussian distribution\nwhen samples are only shown if they fall in some (unknown) subset $S \\subseteq\n\\R^d$. This core problem in truncated statistics has long history going back to\nGalton, Lee, Pearson and Fisher. Recent work by Daskalakis et al. (FOCS'18),\nprovides the first efficient algorithm that works for arbitrary sets in high\ndimension when the set is known, but leaves as an open problem the more\nchallenging and relevant case of unknown truncation set.\n  Our main result is a computationally and sample efficient algorithm for\nestimating the parameters of the Gaussian under arbitrary unknown truncation\nsets whose performance decays with a natural measure of complexity of the set,\nnamely its Gaussian surface area. Notably, this algorithm works for large\nfamilies of sets including intersections of halfspaces, polynomial threshold\nfunctions and general convex sets. We show that our algorithm closely captures\nthe tradeoff between the complexity of the set and the number of samples needed\nto learn the parameters by exhibiting a set with small Gaussian surface area\nfor which it is information theoretically impossible to learn the true Gaussian\nwith few samples.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:05:52 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kontonis", "Vasilis", ""], ["Tzamos", "Christos", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "1908.01039", "submitter": "Chloe Hsu", "authors": "Chloe Ching-Yun Hsu, Michaela Hardt, Moritz Hardt", "title": "Linear Dynamics: Clustering without identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear dynamical systems are a fundamental and powerful parametric model\nclass. However, identifying the parameters of a linear dynamical system is a\nvenerable task, permitting provably efficient solutions only in special cases.\nThis work shows that the eigenspectrum of unknown linear dynamics can be\nidentified without full system identification. We analyze a computationally\nefficient and provably convergent algorithm to estimate the eigenvalues of the\nstate-transition matrix in a linear dynamical system.\n  When applied to time series clustering, our algorithm can efficiently cluster\nmulti-dimensional time series with temporal offsets and varying lengths, under\nthe assumption that the time series are generated from linear dynamical\nsystems. Evaluating our algorithm on both synthetic data and real\nelectrocardiogram (ECG) signals, we see improvements in clustering quality over\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:15:56 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 13:46:48 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 08:51:25 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Hsu", "Chloe Ching-Yun", ""], ["Hardt", "Michaela", ""], ["Hardt", "Moritz", ""]]}, {"id": "1908.01046", "submitter": "Anthony Corso", "authors": "Anthony Corso, Peter Du, Katherine Driggs-Campbell, Mykel J.\n  Kochenderfer", "title": "Adaptive Stress Testing with Reward Augmentation for Autonomous Vehicle\n  Validation", "comments": "Appears in IEEE ITSC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining possible failure scenarios is a critical step in the evaluation\nof autonomous vehicle systems. Real-world vehicle testing is commonly employed\nfor autonomous vehicle validation, but the costs and time requirements are\nhigh. Consequently, simulation-driven methods such as Adaptive Stress Testing\n(AST) have been proposed to aid in validation. AST formulates the problem of\nfinding the most likely failure scenarios as a Markov decision process, which\ncan be solved using reinforcement learning. In practice, AST tends to find\nscenarios where failure is unavoidable and tends to repeatedly discover the\nsame types of failures of a system. This work addresses these issues by\nencoding domain relevant information into the search procedure. With this\nmodification, the AST method discovers a larger and more expressive subset of\nthe failure space when compared to the original AST formulation. We show that\nour approach is able to identify useful failure scenarios of an autonomous\nvehicle policy.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:39:59 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 18:27:43 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Corso", "Anthony", ""], ["Du", "Peter", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1908.01050", "submitter": "Maciej Wielgosz", "authors": "Marcin Radzio, Maciej Wielgosz, Matej Mertik", "title": "Falls Prediction in eldery people using Gated Recurrent Units", "comments": "short concept paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Falls prevention, especially in older people, becomes an increasingly\nimportant topic in the times of aging societies. In this work, we present Gated\nRecurrent Unit-based neural networks models designed for predicting falls\n(syncope). The cardiovascular systems signals used in the study come from\nGravitational Physiology, Aging and Medicine Research Unit, Institute of\nPhysiology, Medical University of Graz. We used two of the collected signals,\nheart rate, and mean blood pressure. By using bidirectional GRU model, it was\npossible to predict the syncope occurrence approximately ten minutes before the\nmanual marker.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:52:04 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Radzio", "Marcin", ""], ["Wielgosz", "Maciej", ""], ["Mertik", "Matej", ""]]}, {"id": "1908.01052", "submitter": "Gabrielle Liu", "authors": "Gabrielle K. Liu", "title": "Weight Friction: A Simple Method to Overcome Catastrophic Forgetting and\n  Enable Continual Learning", "comments": "9 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, deep neural networks have found success in replicating\nhuman-level cognitive skills, yet they suffer from several major obstacles. One\nsignificant limitation is the inability to learn new tasks without forgetting\npreviously learned tasks, a shortcoming known as catastrophic forgetting. In\nthis research, we propose a simple method to overcome catastrophic forgetting\nand enable continual learning in neural networks. We draw inspiration from\nprinciples in neurology and physics to develop the concept of weight friction.\nWeight friction operates by a modification to the update rule in the gradient\ndescent optimization method. It converges at a rate comparable to that of the\nstochastic gradient descent algorithm and can operate over multiple task\ndomains. It performs comparably to current methods while offering improvements\nin computation and memory efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:55:46 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 20:41:24 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Liu", "Gabrielle K.", ""]]}, {"id": "1908.01057", "submitter": "Asma Balamane", "authors": "Asma Balamane and Zina Taklit", "title": "Proposition d'un mod\\`ele pour l'optimisation automatique de boucles\n  dans le compilateur Tiramisu : cas d'optimisation de d\\'eroulage", "comments": "in french", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer architectures become more and more complex. It requires more effort\nto develop techniques that improve the programs of performance and allow to\nexploit material resources efficiently. As a result, many transformations are\napplied on various levels of code abstraction. The first level is the high\nlevel, where the representation is close to the high level language. The second\none is the low level, where the presentation is close to the machine code.\nThose transformations are called code optimizations. Optimizing programs\nrequires deep expertise. On one hand, it is a tedious task, because it requires\na lot of tests to find out the best combination of optimizations to apply with\ntheir best factors. On the other hand, this task is critical, because it may\ndegrade the performance of the program instead of improving it. The\nautomatization of this task can deal with this problem and permit to obtain\ngood results. Our end of study project consists on proposing a novel approach\nbased on neural networks to automatically optimize loops in Tiramisu. Tiramisu\nis a new language to create a code of high performance. It allows to separate\nbetween the algorithm and its optimizations. We have chosen loop unrolling as a\nstudy case. Our contribution aims to automate the choice of the best loop\nunrolling factor for a program written in Tiramisu.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 23:13:32 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Balamane", "Asma", ""], ["Taklit", "Zina", ""]]}, {"id": "1908.01059", "submitter": "Xin Wang", "authors": "Xin Wang, Hideaki Ishii, Linkang Du, Peng Cheng, Jiming Chen", "title": "Privacy-preserving Distributed Machine Learning via Local Randomization\n  and ADMM Perturbation", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3009007", "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of training data, distributed machine learning (DML)\nis becoming more competent for large-scale learning tasks. However, privacy\nconcerns have to be given priority in DML, since training data may contain\nsensitive information of users. In this paper, we propose a privacy-preserving\nADMM-based DML framework with two novel features: First, we remove the\nassumption commonly made in the literature that the users trust the server\ncollecting their data. Second, the framework provides heterogeneous privacy for\nusers depending on data's sensitive levels and servers' trust degrees. The\nchallenging issue is to keep the accumulation of privacy losses over ADMM\niterations minimal. In the proposed framework, a local randomization approach,\nwhich is differentially private, is adopted to provide users with\nself-controlled privacy guarantee for the most sensitive information. Further,\nthe ADMM algorithm is perturbed through a combined noise-adding method, which\nsimultaneously preserves privacy for users' less sensitive information and\nstrengthens the privacy protection of the most sensitive information. We\nprovide detailed analyses on the performance of the trained model according to\nits generalization error. Finally, we conduct extensive experiments using\nreal-world datasets to validate the theoretical results and evaluate the\nclassification performance of the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 06:31:16 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 07:47:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Wang", "Xin", ""], ["Ishii", "Hideaki", ""], ["Du", "Linkang", ""], ["Cheng", "Peng", ""], ["Chen", "Jiming", ""]]}, {"id": "1908.01061", "submitter": "Martin Strohmeier", "authors": "Martin Strohmeier, Matthew Smith, Vincent Lenders, Ivan Martinovic", "title": "Classi-Fly: Inferring Aircraft Categories from Open Data using Machine\n  Learning", "comments": "10 pages, 6 figures, 8 tables, 40 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, air traffic communication data has become easy to access,\nenabling novel research in many fields. Exploiting this new data source, a wide\nrange of applications have emerged, from weather forecasting to stock market\nprediction, or the collection of information about military and government\nmovements. Typically these applications require knowledge about the metadata of\nthe aircraft, specifically its operator and the aircraft category.\n  armasuisse Science + Technology, the R\\&D agency for the Swiss Armed Forces,\nhas been developing Classi-Fly, a novel approach to obtain metadata about\naircraft based on their movement patterns. We validate Classi-Fly using several\nhundred thousand flights collected through open source means, in conjunction\nwith ground truth from publicly available aircraft registries containing more\nthan two million aircraft. Classi-Fly obtains the correct aircraft category\nwith an accuracy of over 88%, demonstrating that it can improve the meta data\nnecessary for applications working with air traffic communication. Finally, we\nshow that it is feasible to automatically detect specific flights such as\npolice and surveillance missions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 17:31:25 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 15:08:01 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Strohmeier", "Martin", ""], ["Smith", "Matthew", ""], ["Lenders", "Vincent", ""], ["Martinovic", "Ivan", ""]]}, {"id": "1908.01071", "submitter": "Yanting Ma", "authors": "Yanting Ma, Shuchin Aeron, and Hassan Mansour", "title": "On the modes of convergence of Stochastic Optimistic Mirror Descent\n  (OMD) for saddle point problems", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study the convergence of Mirror Descent (MD) and\nOptimistic Mirror Descent (OMD) for saddle point problems satisfying the notion\nof coherence as proposed in Mertikopoulos et al. We prove convergence of OMD\nwith exact gradients for coherent saddle point problems, and show that monotone\nconvergence only occurs after some sufficiently large number of iterations.\nThis is in contrast to the claim in Mertikopoulos et al. of monotone\nconvergence of OMD with exact gradients for coherent saddle point problems.\nBesides highlighting this important subtlety, we note that the almost sure\nconvergence guarantees of MD and OMD with stochastic gradients for strictly\ncoherent saddle point problems that are claimed in Mertikopoulos et al. are not\nfully justified by their proof. As such, we fill out the missing details in the\nproof and as a result have only been able to prove convergence with high\nprobability.\n  We would like to note that our analysis relies heavily on the core ideas and\nproof techniques introduced in Zhou et al. and Mertikopoulos et al., and we\nonly aim to re-state and correct the results in light of what we were able to\nprove rigorously while filling in the much needed missing details in their\nproofs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 21:30:56 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Ma", "Yanting", ""], ["Aeron", "Shuchin", ""], ["Mansour", "Hassan", ""]]}, {"id": "1908.01073", "submitter": "MohammadHossein AskariHemmat", "authors": "MohammadHossein AskariHemmat, Sina Honari, Lucas Rouhier, Christian S.\n  Perone, Julien Cohen-Adad, Yvon Savaria, Jean-Pierre David", "title": "U-Net Fixed-Point Quantization for Medical Image Segmentation", "comments": "Accepted to MICCAI 2019's Hardware Aware Learning for Medical Imaging\n  and Computer Assisted Intervention", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model quantization is leveraged to reduce the memory consumption and the\ncomputation time of deep neural networks. This is achieved by representing\nweights and activations with a lower bit resolution when compared to their high\nprecision floating point counterparts. The suitable level of quantization is\ndirectly related to the model performance. Lowering the quantization precision\n(e.g. 2 bits), reduces the amount of memory required to store model parameters\nand the amount of logic required to implement computational blocks, which\ncontributes to reducing the power consumption of the entire system. These\nbenefits typically come at the cost of reduced accuracy. The main challenge is\nto quantize a network as much as possible, while maintaining the performance\naccuracy. In this work, we present a quantization method for the U-Net\narchitecture, a popular model in medical image segmentation. We then apply our\nquantization algorithm to three datasets: (1) the Spinal Cord Gray Matter\nSegmentation (GM), (2) the ISBI challenge for segmentation of neuronal\nstructures in Electron Microscopic (EM), and (3) the public National Institute\nof Health (NIH) dataset for pancreas segmentation in abdominal CT scans. The\nreported results demonstrate that with only 4 bits for weights and 6 bits for\nactivations, we obtain 8 fold reduction in memory requirements while loosing\nonly 2.21%, 0.57% and 2.09% dice overlap score for EM, GM and NIH datasets\nrespectively. Our fixed point quantization provides a flexible trade off\nbetween accuracy and memory requirement which is not provided by previous\nquantization methods for U-Net such as TernaryNet.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 21:39:56 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 16:51:58 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["AskariHemmat", "MohammadHossein", ""], ["Honari", "Sina", ""], ["Rouhier", "Lucas", ""], ["Perone", "Christian S.", ""], ["Cohen-Adad", "Julien", ""], ["Savaria", "Yvon", ""], ["David", "Jean-Pierre", ""]]}, {"id": "1908.01078", "submitter": "Amir Mosavi Prof", "authors": "Adrienn Dineva, Amir Mosavi, Mate Gyimesi, Istvan Vajda", "title": "Multi-label Classification for Fault Diagnosis of Rotating Electrical\n  Machines", "comments": "30 pages, 6 figures", "journal-ref": null, "doi": "10.20944/preprints201908.0029.v1", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Primary importance is devoted to Fault Detection and Diagnosis (FDI) of\nelectrical machine and drive systems in modern industrial automation. The\nwidespread use of Machine Learning techniques has made it possible to replace\ntraditional motor fault detection techniques with more efficient solutions that\nare capable of early fault recognition by using large amounts of sensory data.\nHowever, the detection of concurrent failures is still a challenge in the\npresence of disturbing noises or when the multiple faults cause overlapping\nfeatures. The contribution of this work is to propose a novel methodology using\nmulti-label classification method for simultaneously diagnosing multiple faults\nand evaluating the fault severity under noisy conditions. Performance of\nvarious multi-label classification models are compared. Current and vibration\nsignals are acquired under normal and fault conditions. The applicability of\nthe proposed method is experimentally validated under diverse fault conditions\nsuch as unbalance and misalignment.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 22:05:55 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Dineva", "Adrienn", ""], ["Mosavi", "Amir", ""], ["Gyimesi", "Mate", ""], ["Vajda", "Istvan", ""]]}, {"id": "1908.01080", "submitter": "Sanidhya Mangal", "authors": "Sanidhya Mangal, Rahul Modak, Poorva Joshi", "title": "LSTM Based Music Generation System", "comments": "6 pages, 11 figures", "journal-ref": "IARJSET: Vol. 6, Issue 5 (2019) 47-54", "doi": "10.17148/IARJSET.2019.6508", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, music was treated as an analogue signal and was generated\nmanually. In recent years, music is conspicuous to technology which can\ngenerate a suite of music automatically without any human intervention. To\naccomplish this task, we need to overcome some technical challenges which are\ndiscussed descriptively in this paper. A brief introduction about music and its\ncomponents is provided in the paper along with the citation and analysis of\nrelated work accomplished by different authors in this domain. Main objective\nof this paper is to propose an algorithm which can be used to generate musical\nnotes using Recurrent Neural Networks (RNN), principally Long Short-Term Memory\n(LSTM) networks. A model is designed to execute this algorithm where data is\nrepresented with the help of musical instrument digital interface (MIDI) file\nformat for easier access and better understanding. Preprocessing of data before\nfeeding it into the model, revealing methods to read, process and prepare MIDI\nfiles for input are also discussed. The model used in this paper is used to\nlearn the sequences of polyphonic musical notes over a single-layered LSTM\nnetwork. The model must have the potential to recall past details of a musical\nsequence and its structure for better learning. Description of layered\narchitecture used in LSTM model and its intertwining connections to develop a\nneural network is presented in this work. This paper imparts a peek view of\ndistributions of weights and biases in every layer of the model along with a\nprecise representation of losses and accuracy at each step and batches. When\nthe model was thoroughly analyzed, it produced stellar results in composing new\nmelodies.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 22:10:19 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Mangal", "Sanidhya", ""], ["Modak", "Rahul", ""], ["Joshi", "Poorva", ""]]}, {"id": "1908.01087", "submitter": "Nesreen Ahmed", "authors": "Nesreen K. Ahmed, Nick Duffield", "title": "Adaptive Shrinkage Estimation for Streaming Graphs", "comments": "This paper is accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are a natural representation of complex systems across the sciences,\nand higher-order dependencies are central to the understanding and modeling of\nthese systems. However, in many practical applications such as online social\nnetworks, networks are massive, dynamic, and naturally streaming, where\npairwise interactions among vertices become available one at a time in some\narbitrary order. The massive size and streaming nature of these networks allow\nonly partial observation, since it is infeasible to analyze the entire network.\nUnder such scenarios, it is challenging to study the higher-order structural\nand connectivity patterns of streaming networks. In this work, we consider the\nfundamental problem of estimating the higher-order dependencies using adaptive\nsampling. We propose a novel adaptive, single-pass sampling framework and\nunbiased estimators for higher-order network analysis of large streaming\nnetworks. Our algorithms exploit adaptive techniques to identify edges that are\nhighly informative for efficiently estimating the higher-order structure of\nstreaming networks from small sample data. We also introduce a novel\nJames-Stein shrinkage estimator to reduce the estimation error. Our approach is\nfully analytic, computationally efficient, and can be incrementally updated in\na streaming setting. Numerical experiments on large networks show that our\napproach is superior to baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 23:02:16 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:06:30 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 23:44:44 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 22:59:24 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ahmed", "Nesreen K.", ""], ["Duffield", "Nick", ""]]}, {"id": "1908.01089", "submitter": "Chirag Gupta", "authors": "Chirag Gupta, Sivaraman Balakrishnan, Aaditya Ramdas", "title": "Path Length Bounds for Gradient Descent and Flow", "comments": "55 pages. Accepted for publication at the Journal of Machine Learning\n  Research (JMLR, 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive bounds on the path length $\\zeta$ of gradient descent (GD) and\ngradient flow (GF) curves for various classes of smooth convex and nonconvex\nfunctions. Among other results, we prove that: (a) if the iterates are linearly\nconvergent with factor $(1-c)$, then $\\zeta$ is at most $\\mathcal{O}(1/c)$; (b)\nunder the Polyak-Kurdyka-Lojasiewicz (PKL) condition, $\\zeta$ is at most\n$\\mathcal{O}(\\sqrt{\\kappa})$, where $\\kappa$ is the condition number, and at\nleast $\\widetilde\\Omega(\\sqrt{d} \\wedge \\kappa^{1/4})$; (c) for quadratics,\n$\\zeta$ is $\\Theta(\\min\\{\\sqrt{d},\\sqrt{\\log \\kappa}\\})$ and in some cases can\nbe independent of $\\kappa$; (d) assuming just convexity, $\\zeta$ can be at most\n$2^{4d\\log d}$; (e) for separable quasiconvex functions, $\\zeta$ is\n${\\Theta}(\\sqrt{d})$. Thus, we advance current understanding of the properties\nof GD and GF curves beyond rates of convergence. We expect our techniques to\nfacilitate future studies for other algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 23:07:42 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 03:54:14 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 22:41:40 GMT"}, {"version": "v4", "created": "Fri, 19 Mar 2021 18:09:00 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gupta", "Chirag", ""], ["Balakrishnan", "Sivaraman", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "1908.01091", "submitter": "Cuong Nguyen", "authors": "Cuong V. Nguyen, Alessandro Achille, Michael Lam, Tal Hassner, Vijay\n  Mahadevan, Stefano Soatto", "title": "Toward Understanding Catastrophic Forgetting in Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relationship between catastrophic forgetting and properties of\ntask sequences. In particular, given a sequence of tasks, we would like to\nunderstand which properties of this sequence influence the error rates of\ncontinual learning algorithms trained on the sequence. To this end, we propose\na new procedure that makes use of recent developments in task space modeling as\nwell as correlation analysis to specify and analyze the properties we are\ninterested in. As an application, we apply our procedure to study two\nproperties of a task sequence: (1) total complexity and (2) sequential\nheterogeneity. We show that error rates are strongly and positively correlated\nto a task sequence's total complexity for some state-of-the-art algorithms. We\nalso show that, surprisingly, the error rates have no or even negative\ncorrelations in some cases to sequential heterogeneity. Our findings suggest\ndirections for improving continual learning benchmarks and methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 23:30:35 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Nguyen", "Cuong V.", ""], ["Achille", "Alessandro", ""], ["Lam", "Michael", ""], ["Hassner", "Tal", ""], ["Mahadevan", "Vijay", ""], ["Soatto", "Stefano", ""]]}, {"id": "1908.01092", "submitter": "Sahar Daraeizadeh", "authors": "Sahar Daraeizadeh, Shavindra P. Premaratne, Xiaoyu Song, Marek\n  Perkowski, Anne Y. Matsuura", "title": "Machine-learning based three-qubit gate for realization of a Toffoli\n  gate with cQED-based transmon systems", "comments": null, "journal-ref": "Phys. Rev. A 102, 012601 (2020)", "doi": "10.1103/PhysRevA.102.012601", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use machine learning techniques to design a 50 ns three-qubit flux-tunable\ncontrolled-controlled-phase gate with fidelity of >99.99% for nearest-neighbor\ncoupled transmons in circuit quantum electrodynamics architectures. We explain\nour gate design procedure where we enforce realistic constraints, and analyze\nthe new gate's robustness under decoherence, distortion, and random noise. Our\ncontrolled-controlled-phase gate in combination with two single-qubit gates\nrealizes a Toffoli gate which is widely used in quantum circuits, logic\nsynthesis, quantum error correction, and quantum games.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 23:39:10 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Daraeizadeh", "Sahar", ""], ["Premaratne", "Shavindra P.", ""], ["Song", "Xiaoyu", ""], ["Perkowski", "Marek", ""], ["Matsuura", "Anne Y.", ""]]}, {"id": "1908.01094", "submitter": "Georgios Fainekos", "authors": "Cumhur Erkan Tuncali, Georgios Fainekos, Danil Prokhorov, Hisahiro\n  Ito, James Kapinski", "title": "Requirements-driven Test Generation for Autonomous Vehicles with Machine\n  Learning Components", "comments": "arXiv admin note: text overlap with arXiv:1804.06760", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles are complex systems that are challenging to test and\ndebug. A requirements-driven approach to the development process can decrease\nthe resources required to design and test these systems, while simultaneously\nincreasing the reliability. We present a testing framework that uses signal\ntemporal logic (STL), which is a precise and unambiguous requirements language.\nOur framework evaluates test cases against the STL formulae and additionally\nuses the requirements to automatically identify test cases that fail to satisfy\nthe requirements. One of the key features of our tool is the support for\nmachine learning (ML) components in the system design, such as deep neural\nnetworks. The framework allows evaluation of the control algorithms, including\nthe ML components, and it also includes models of CCD camera, lidar, and radar\nsensors, as well as the vehicle environment. We use multiple methods to\ngenerate test cases, including covering arrays, which is an efficient method to\nsearch discrete variable spaces. The resulting test cases can be used to debug\nthe controller design by identifying controller behaviors that do not satisfy\nrequirements. The test cases can also enhance the testing phase of development\nby identifying critical corner cases that correspond to the limits of the\nsystem's allowed behaviors. We present STL requirements for an autonomous\nvehicle system, which capture both component-level and system-level behaviors.\nAdditionally, we present three driving scenarios and demonstrate how our\nrequirements-driven testing framework can be used to identify critical system\nbehaviors, which can be used to support the development process.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 23:59:26 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Tuncali", "Cumhur Erkan", ""], ["Fainekos", "Georgios", ""], ["Prokhorov", "Danil", ""], ["Ito", "Hisahiro", ""], ["Kapinski", "James", ""]]}, {"id": "1908.01109", "submitter": "Zhuodong Tang", "authors": "Ningyuan Chen, Guillermo Gallego, Zhuodong Tang", "title": "The Use of Binary Choice Forests to Model and Estimate Discrete Choices", "comments": "86 pages, 10 figures, 26 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show the equivalence of discrete choice models and a forest of binary\ndecision trees. This suggests that standard machine learning techniques based\non random forests can serve to estimate discrete choice models with an\ninterpretable output: the underlying trees can be viewed as the internal choice\nprocess of customers. Our data-driven theoretical results show that random\nforests can predict the choice probability of any discrete choice model\nconsistently. Moreover, our algorithm predicts unseen assortments with\nmechanisms and errors that can be theoretically analyzed. We also prove that\nthe splitting criterion in random forests, the Gini index, is capable of\nrecovering preference rankings of customers. The framework has unique practical\nadvantages: it can capture behavioral patterns such as irrationality or\nsequential searches; it handles nonstandard formats of training data that\nresult from aggregation; it can measure product importance based on how\nfrequently a random customer would make decisions depending on the presence of\nthe product; it can also incorporate price information and customer features.\nOur numerical results show that using random forests to estimate customer\nchoices can outperform the best parametric models in synthetic and real\ndatasets when presented with enough data or when the underlying discrete choice\nmodel cannot be correctly specified by existing parametric models.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 02:34:49 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 01:43:31 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 10:05:29 GMT"}, {"version": "v4", "created": "Sat, 3 Apr 2021 03:07:27 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Chen", "Ningyuan", ""], ["Gallego", "Guillermo", ""], ["Tang", "Zhuodong", ""]]}, {"id": "1908.01112", "submitter": "Yinchuan Li", "authors": "Xinyi Li, Yinchuan Li, Xiao-Yang Liu and Christina Dan Wang", "title": "Risk Management via Anomaly Circumvent: Mnemonic Deep Learning for\n  Midterm Stock Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Midterm stock price prediction is crucial for value investments in the stock\nmarket. However, most deep learning models are essentially short-term and\napplying them to midterm predictions encounters large cumulative errors because\nthey cannot avoid anomalies. In this paper, we propose a novel deep neural\nnetwork Mid-LSTM for midterm stock prediction, which incorporates the market\ntrend as hidden states. First, based on the autoregressive moving average model\n(ARMA), a midterm ARMA is formulated by taking into consideration both hidden\nstates and the capital asset pricing model. Then, a midterm LSTM-based deep\nneural network is designed, which consists of three components: LSTM, hidden\nMarkov model and linear regression networks. The proposed Mid-LSTM can avoid\nanomalies to reduce large prediction errors, and has good explanatory effects\non the factors affecting stock prices. Extensive experiments on S&P 500 stocks\nshow that (i) the proposed Mid-LSTM achieves 2-4% improvement in prediction\naccuracy, and (ii) in portfolio allocation investment, we achieve up to 120.16%\nannual return and 2.99 average Sharpe ratio.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 03:00:56 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Li", "Xinyi", ""], ["Li", "Yinchuan", ""], ["Liu", "Xiao-Yang", ""], ["Wang", "Christina Dan", ""]]}, {"id": "1908.01113", "submitter": "Yuntian Chen", "authors": "Yuntian Chen, Haibin Chang, Meng Jin, Dongxiao Zhang", "title": "Ensemble Neural Networks (ENN): A gradient-free stochastic method", "comments": null, "journal-ref": "Neural Networks, 110, 170-185 (2019)", "doi": "10.1016/j.neunet.2018.11.009", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this study, an efficient stochastic gradient-free method, the ensemble\nneural networks (ENN), is developed. In the ENN, the optimization process\nrelies on covariance matrices rather than derivatives. The covariance matrices\nare calculated by the ensemble randomized maximum likelihood algorithm (EnRML),\nwhich is an inverse modeling method. The ENN is able to simultaneously provide\nestimations and perform uncertainty quantification since it is built under the\nBayesian framework. The ENN is also robust to small training data size because\nthe ensemble of stochastic realizations essentially enlarges the training\ndataset. This constitutes a desirable characteristic, especially for real-world\nengineering applications. In addition, the ENN does not require the calculation\nof gradients, which enables the use of complicated neuron models and loss\nfunctions in neural networks. We experimentally demonstrate benefits of the\nproposed model, in particular showing that the ENN performs much better than\nthe traditional Bayesian neural networks (BNN). The EnRML in ENN is a\nsubstitution of gradient-based optimization algorithms, which means that it can\nbe directly combined with the feed-forward process in other existing (deep)\nneural networks, such as convolutional neural networks (CNN) and recurrent\nneural networks (RNN), broadening future applications of the ENN.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 03:11:32 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Chen", "Yuntian", ""], ["Chang", "Haibin", ""], ["Jin", "Meng", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "1908.01133", "submitter": "Ardavan Bidgoli", "authors": "Ardavan Bidgoli, Eunsu Kang, Daniel Cardoso Llach", "title": "Machinic Surrogates: Human-Machine Relationships in Computational\n  Creativity", "comments": "25th International Symposium on Electronic Art, ISEA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in artificial intelligence (AI) and its sub-branch\nmachine learning (ML) promise machines that go beyond the boundaries of\nautomation and behave autonomously. Applications of these machines in creative\npractices such as art and design entail relationships between users and\nmachines that have been described as a form of collaboration or co-creation\nbetween computational and human agents. This paper uses examples from art and\ndesign to argue that this frame is incomplete as it fails to acknowledge the\nsocio-technical nature of AI systems, and the different human agencies involved\nin their design, implementation, and operation. Situating applications of\nAI-enabled tools in creative practices in a spectrum between automation and\nautonomy, this paper distinguishes different kinds of human engagement elicited\nby systems deemed automated or autonomous. Reviewing models of artistic\ncollaboration during the late 20th century, it suggests that collaboration is\nat the core of these artistic practices. We build upon the growing literature\nof machine learning and art to look for the human agencies inscribed in works\nof computational creativity, and expand the co-creation frame to incorporate\nemerging forms of human-human collaboration mediated through technical\nartifacts such as algorithms and data.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 08:15:59 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Bidgoli", "Ardavan", ""], ["Kang", "Eunsu", ""], ["Llach", "Daniel Cardoso", ""]]}, {"id": "1908.01135", "submitter": "Simina Br\\^anzei", "authors": "Simina Br\\^anzei and Yuval Peres", "title": "Multiplayer Bandit Learning, from Competition to Cooperation", "comments": "41 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic multi-armed bandit model captures the tradeoff between\nexploration and exploitation. We study the effects of competition and\ncooperation on this tradeoff. Suppose there are $k$ arms and two players, Alice\nand Bob. In every round, each player pulls an arm, receives the resulting\nreward, and observes the choice of the other player but not their reward.\nAlice's utility is $\\Gamma_A + \\lambda \\Gamma_B$ (and similarly for Bob), where\n$\\Gamma_A$ is Alice's total reward and $\\lambda \\in [-1, 1]$ is a cooperation\nparameter. At $\\lambda = -1$ the players are competing in a zero-sum game, at\n$\\lambda = 1$, they are fully cooperating, and at $\\lambda = 0$, they are\nneutral: each player's utility is their own reward. The model is related to the\neconomics literature on strategic experimentation, where usually players\nobserve each other's rewards.\n  With discount factor $\\beta$, the Gittins index reduces the one-player\nproblem to the comparison between a risky arm, with a prior $\\mu$, and a\npredictable arm, with success probability $p$. The value of $p$ where the\nplayer is indifferent between the arms is the Gittins index $g = g(\\mu,\\beta) >\nm$, where $m$ is the mean of the risky arm.\n  We show that competing players explore less than a single player: there is\n$p^* \\in (m, g)$ so that for all $p > p^*$, the players stay at the predictable\narm. However, the players are not myopic: they still explore for some $p > m$.\nOn the other hand, cooperating players explore more than a single player. We\nalso show that neutral players learn from each other, receiving strictly higher\ntotal rewards than they would playing alone, for all $ p\\in (p^*, g)$, where\n$p^*$ is the threshold from the competing case.\n  Finally, we show that competing and neutral players eventually settle on the\nsame arm in every Nash equilibrium, while this can fail for cooperating\nplayers.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 08:20:54 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 04:19:36 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Br\u00e2nzei", "Simina", ""], ["Peres", "Yuval", ""]]}, {"id": "1908.01146", "submitter": "Wentai Wu", "authors": "Wentai Wu, Ligang He, Weiwei Lin, Yi Su, Yuhua Cui, Carsten Maple and\n  Stephen Jarvis", "title": "Developing an Unsupervised Real-time Anomaly Detection Scheme for Time\n  Series with Multi-seasonality", "comments": "14 pages, 11 figures. IEEE Transactions on Knowledge and Data\n  Engineering (2020)", "journal-ref": null, "doi": "10.1109/TKDE.2020.3035685", "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  On-line detection of anomalies in time series is a key technique used in\nvarious event-sensitive scenarios such as robotic system monitoring, smart\nsensor networks and data center security. However, the increasing diversity of\ndata sources and the variety of demands make this task more challenging than\never. Firstly, the rapid increase in unlabeled data means supervised learning\nis becoming less suitable in many cases. Secondly, a large portion of time\nseries data have complex seasonality features. Thirdly, on-line anomaly\ndetection needs to be fast and reliable. In light of this, we have developed a\nprediction-driven, unsupervised anomaly detection scheme, which adopts a\nbackbone model combining the decomposition and the inference of time series\ndata. Further, we propose a novel metric, Local Trend Inconsistency (LTI), and\nan efficient detection algorithm that computes LTI in a real-time manner and\nscores each data point robustly in terms of its probability of being anomalous.\nWe have conducted extensive experimentation to evaluate our algorithm with\nseveral datasets from both public repositories and production environments. The\nexperimental results show that our scheme outperforms existing representative\nanomaly detection algorithms in terms of the commonly used metric, Area Under\nCurve (AUC), while achieving the desired efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 10:38:22 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 16:38:35 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 10:33:06 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Wu", "Wentai", ""], ["He", "Ligang", ""], ["Lin", "Weiwei", ""], ["Su", "Yi", ""], ["Cui", "Yuhua", ""], ["Maple", "Carsten", ""], ["Jarvis", "Stephen", ""]]}, {"id": "1908.01165", "submitter": "Utpal Garain", "authors": "Akshay Chaturvedi, Abijith KP, and Utpal Garain", "title": "Exploring the Robustness of NMT Systems to Nonsensical Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) systems have been shown to give undesirable\ntranslation when a small change is made in the source sentence. In this paper,\nwe study the behaviour of NMT systems when multiple changes are made to the\nsource sentence. In particular, we ask the following question \"Is it possible\nfor an NMT system to predict same translation even when multiple words in the\nsource sentence have been replaced?\". To this end, we propose a soft-attention\nbased technique to make the aforementioned word replacements. The experiments\nare conducted on two language pairs: English-German (en-de) and English-French\n(en-fr) and two state-of-the-art NMT systems: BLSTM-based encoder-decoder with\nattention and Transformer. The proposed soft-attention based technique achieves\nhigh success rate and outperforms existing methods like HotFlip by a\nsignificant margin for all the conducted experiments. The results demonstrate\nthat state-of-the-art NMT systems are unable to capture the semantics of the\nsource language. The proposed soft-attention based technique is an\ninvariance-based adversarial attack on NMT systems. To better evaluate such\nattacks, we propose an alternate metric and argue its benefits in comparison\nwith success rate.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 12:59:40 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 13:05:38 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 14:23:26 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Chaturvedi", "Akshay", ""], ["KP", "Abijith", ""], ["Garain", "Utpal", ""]]}, {"id": "1908.01174", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Zhenhua Guo, Site Li, Lingsheng Kong, Ping Jia, Jane\n  You, B.V.K. Kumar", "title": "Permutation-invariant Feature Restructuring for Correlation-aware Image\n  Set-based Recognition", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of comparing the similarity of image sets with\nvariable-quantity, quality and un-ordered heterogeneous images. We use feature\nrestructuring to exploit the correlations of both inner$\\&$inter-set images.\nSpecifically, the residual self-attention can effectively restructure the\nfeatures using the other features within a set to emphasize the discriminative\nimages and eliminate the redundancy. Then, a sparse/collaborative\nlearning-based dependency-guided representation scheme reconstructs the probe\nfeatures conditional to the gallery features in order to adaptively align the\ntwo sets. This enables our framework to be compatible with both verification\nand open-set identification. We show that the parametric self-attention network\nand non-parametric dictionary learning can be trained end-to-end by a unified\nalternative optimization scheme, and that the full framework is\npermutation-invariant. In the numerical experiments we conducted, our method\nachieves top performance on competitive image set/video-based face recognition\nand person re-identification benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 13:39:41 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Guo", "Zhenhua", ""], ["Li", "Site", ""], ["Kong", "Lingsheng", ""], ["Jia", "Ping", ""], ["You", "Jane", ""], ["Kumar", "B. V. K.", ""]]}, {"id": "1908.01176", "submitter": "Rachana Sathish", "authors": "Rachana Sathish, Ronnie Rajan, Anusha Vupputuri, Nirmalya Ghosh and\n  Debdoot Sheet", "title": "Adversarially Trained Convolutional Neural Networks for Semantic\n  Segmentation of Ischaemic Stroke Lesion using Multisequence Magnetic\n  Resonance Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Ischaemic stroke is a medical condition caused by occlusion of blood supply\nto the brain tissue thus forming a lesion. A lesion is zoned into a core\nassociated with irreversible necrosis typically located at the center of the\nlesion, while reversible hypoxic changes in the outer regions of the lesion are\ntermed as the penumbra. Early estimation of core and penumbra in ischaemic\nstroke is crucial for timely intervention with thrombolytic therapy to reverse\nthe damage and restore normalcy. Multisequence magnetic resonance imaging (MRI)\nis commonly employed for clinical diagnosis. However, a sequence singly has not\nbeen found to be sufficiently able to differentiate between core and penumbra,\nwhile a combination of sequences is required to determine the extent of the\ndamage. The challenge, however, is that with an increase in the number of\nsequences, it cognitively taxes the clinician to discover symptomatic\nbiomarkers in these images. In this paper, we present a data-driven fully\nautomated method for estimation of core and penumbra in ischaemic lesions using\ndiffusion-weighted imaging (DWI) and perfusion-weighted imaging (PWI) sequence\nmaps of MRI. The method employs recent developments in convolutional neural\nnetworks (CNN) for semantic segmentation in medical images. In the absence of\navailability of a large amount of labeled data, the CNN is trained using an\nadversarial approach employing cross-entropy as a segmentation loss along with\nlosses aggregated from three discriminators of which two employ relativistic\nvisual Turing test. This method is experimentally validated on the ISLES-2015\ndataset through three-fold cross-validation to obtain with an average Dice\nscore of 0.82 and 0.73 for segmentation of penumbra and core respectively.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 13:48:27 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Sathish", "Rachana", ""], ["Rajan", "Ronnie", ""], ["Vupputuri", "Anusha", ""], ["Ghosh", "Nirmalya", ""], ["Sheet", "Debdoot", ""]]}, {"id": "1908.01207", "submitter": "Srijan Kumar", "authors": "Srijan Kumar, Xikun Zhang, Jure Leskovec", "title": "Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks", "comments": "ACM SIGKDD 2019 research track oral paper. The code and datasets are\n  available on the project website: https://github.com/srijankr/jodie/ arXiv\n  admin note: substantial text overlap with arXiv:1812.02289", "journal-ref": null, "doi": "10.1145/3292500.3330895", "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling sequential interactions between users and items/products is crucial\nin domains such as e-commerce, social networking, and education. Representation\nlearning presents an attractive opportunity to model the dynamic evolution of\nusers and items, where each user/item can be embedded in a Euclidean space and\nits evolution can be modeled by an embedding trajectory in this space. However,\nexisting dynamic embedding methods generate embeddings only when users take\nactions and do not explicitly model the future trajectory of the user/item in\nthe embedding space. Here we propose JODIE, a coupled recurrent neural network\nmodel that learns the embedding trajectories of users and items. JODIE employs\ntwo recurrent neural networks to update the embedding of a user and an item at\nevery interaction. Crucially, JODIE also models the future embedding trajectory\nof a user/item. To this end, it introduces a novel projection operator that\nlearns to estimate the embedding of the user at any time in the future. These\nestimated embeddings are then used to predict future user-item interactions. To\nmake the method scalable, we develop a t-Batch algorithm that creates\ntime-consistent batches and leads to 9x faster training. We conduct six\nexperiments to validate JODIE on two prediction tasks---future interaction\nprediction and state change prediction---using four real-world datasets. We\nshow that JODIE outperforms six state-of-the-art algorithms in these tasks by\nat least 20% in predicting future interactions and 12% in state change\nprediction.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 17:52:13 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kumar", "Srijan", ""], ["Zhang", "Xikun", ""], ["Leskovec", "Jure", ""]]}, {"id": "1908.01211", "submitter": "David Matthews", "authors": "David Matthews, Sam Kriegman, Collin Cappelle, Josh Bongard", "title": "Word2vec to behavior: morphology facilitates the grounding of language\n  in machines", "comments": "D. Matthews, S. Kriegman, C. Cappelle and J. Bongard, \"Word2vec to\n  behavior: morphology facilitates the grounding of language in machines,\" 2019\n  IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),\n  Macau, China, 2019. \\c{opyright} 2019 IEEE. Personal use of this material is\n  permitted. Permission from IEEE must be obtained for all other uses", "journal-ref": null, "doi": "10.1109/IROS40897.2019.8967639", "report-no": null, "categories": "cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling machines to respond appropriately to natural language commands could\ngreatly expand the number of people to whom they could be of service. Recently,\nadvances in neural network-trained word embeddings have empowered non-embodied\ntext-processing algorithms, and suggest they could be of similar utility for\nembodied machines. Here we introduce a method that does so by training robots\nto act similarly to semantically-similar word2vec encoded commands. We show\nthat this enables them to act appropriately, after training, to\npreviously-unheard commands. Finally, we show that inducing such an alignment\nbetween motoric and linguistic similarities can be facilitated or hindered by\nthe mechanical structure of the robot. This points to future, large scale\nmethods that find and exploit relationships between action, language, and robot\nstructure.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 18:09:56 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Matthews", "David", ""], ["Kriegman", "Sam", ""], ["Cappelle", "Collin", ""], ["Bongard", "Josh", ""]]}, {"id": "1908.01219", "submitter": "Christopher Sweet", "authors": "Christopher Sweet, Stephen Moskal, Shanchieh Jay Yang", "title": "On the Veracity of Cyber Intrusion Alerts Synthesized by Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recreating cyber-attack alert data with a high level of fidelity is\nchallenging due to the intricate interaction between features, non-homogeneity\nof alerts, and potential for rare yet critical samples. Generative Adversarial\nNetworks (GANs) have been shown to effectively learn complex data distributions\nwith the intent of creating increasingly realistic data. This paper presents\nthe application of GANs to cyber-attack alert data and shows that GANs not only\nsuccessfully learn to generate realistic alerts, but also reveal feature\ndependencies within alerts. This is accomplished by reviewing the intersection\nof histograms for varying alert-feature combinations between the ground truth\nand generated datsets. Traditional statistical metrics, such as conditional and\njoint entropy, are also employed to verify the accuracy of these dependencies.\nFinally, it is shown that a Mutual Information constraint on the network can be\nused to increase the generation of low probability, critical, alert values. By\nmapping alerts to a set of attack stages it is shown that the output of these\nlow probability alerts has a direct contextual meaning for Cyber Security\nanalysts. Overall, this work provides the basis for generating new cyber\nintrusion alerts and provides evidence that synthesized alerts emulate critical\ndependencies from the source dataset.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 18:56:43 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Sweet", "Christopher", ""], ["Moskal", "Stephen", ""], ["Yang", "Shanchieh Jay", ""]]}, {"id": "1908.01228", "submitter": "Christina Lee Yu", "authors": "Nirandika Wanigasekara, Christina Lee Yu", "title": "Nonparametric Contextual Bandits in an Unknown Metric Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a nonparametric contextual multi-arm bandit problem where each arm\n$a \\in [K]$ is associated to a nonparametric reward function $f_a: [0,1] \\to\n\\mathbb{R}$ mapping from contexts to the expected reward. Suppose that there is\na large set of arms, yet there is a simple but unknown structure amongst the\narm reward functions, e.g. finite types or smooth with respect to an unknown\nmetric space. We present a novel algorithm which learns data-driven\nsimilarities amongst the arms, in order to implement adaptive partitioning of\nthe context-arm space for more efficient learning. We provide regret bounds\nalong with simulations that highlight the algorithm's dependence on the local\ngeometry of the reward functions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 20:24:27 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Wanigasekara", "Nirandika", ""], ["Yu", "Christina Lee", ""]]}, {"id": "1908.01241", "submitter": "Christina Lee Yu", "authors": "Devavrat Shah, Christina Lee Yu", "title": "Iterative Collaborative Filtering for Sparse Noisy Tensor Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the task of tensor estimation, i.e. estimating a low-rank 3-order $n\n\\times n \\times n$ tensor from noisy observations of randomly chosen entries in\nthe sparse regime. We introduce a generalization of the collaborative filtering\nalgorithm for sparse tensor estimation and argue that it achieves sample\ncomplexity that nearly matches the conjectured computationally efficient lower\nbound on the sample complexity. Our algorithm uses the matrix obtained from the\nflattened tensor to compute similarity, and estimates the tensor entries using\na nearest neighbor estimator. We prove that the algorithm recovers the tensor\nwith maximum entry-wise error and mean-squared-error (MSE) decaying to $0$ as\nlong as each entry is observed independently with probability $p =\n\\Omega(n^{-3/2 + \\kappa})$ for any arbitrarily small $\\kappa> 0$. Our analysis\nsheds insight into the conjectured sample complexity lower bound, showing that\nit matches the connectivity threshold of the graph used by our algorithm for\nestimating similarity between coordinates.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 22:27:26 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 04:28:39 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Shah", "Devavrat", ""], ["Yu", "Christina Lee", ""]]}, {"id": "1908.01242", "submitter": "Vinay Prabhu", "authors": "Vinay Uday Prabhu", "title": "Kannada-MNIST: A new handwritten digits dataset for the Kannada language", "comments": "The companion github repository for this paper is :\n  https://github.com/vinayprabhu/Kannada_MNIST", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we disseminate a new handwritten digits-dataset, termed\nKannada-MNIST, for the Kannada script, that can potentially serve as a direct\ndrop-in replacement for the original MNIST dataset. In addition to this\ndataset, we disseminate an additional real world handwritten dataset (with\n$10k$ images), which we term as the Dig-MNIST dataset that can serve as an\nout-of-domain test dataset. We also duly open source all the code as well as\nthe raw scanned images along with the scanner settings so that researchers who\nwant to try out different signal processing pipelines can perform end-to-end\ncomparisons. We provide high level morphological comparisons with the MNIST\ndataset and provide baselines accuracies for the dataset disseminated. The\ninitial baselines obtained using an oft-used CNN architecture ($96.8\\%$ for the\nmain test-set and $76.1\\%$ for the Dig-MNIST test-set) indicate that these\ndatasets do provide a sterner challenge with regards to generalizability than\nMNIST or the KMNIST datasets. We also hope this dissemination will spur the\ncreation of similar datasets for all the languages that use different symbols\nfor the numeral digits.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 22:33:52 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Prabhu", "Vinay Uday", ""]]}, {"id": "1908.01244", "submitter": "Mohammadreza Baharani", "authors": "Mohammadreza Baharani, Mehrdad Biglarbegian, Babak Parkhideh, Hamed\n  Tabkhi", "title": "Real-time Deep Learning at the Edge for Scalable Reliability Modeling of\n  Si-MOSFET Power Electronics Converters", "comments": "2019 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "IEEE Internet of Things Journal, 2019", "doi": "10.1109/JIOT.2019.2896174", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the significant growth of advanced high-frequency power converters,\non-line monitoring and active reliability assessment of power electronic\ndevices are extremely crucial. This article presents a transformative approach,\nnamed Deep Learning Reliability Awareness of Converters at the Edge (Deep\nRACE), for real-time reliability modeling and prediction of high-frequency\nMOSFET power electronic converters. Deep RACE offers a holistic solution which\ncomprises algorithm advances, and full system integration (from the cloud down\nto the edge node) to create a near real-time reliability awareness. On the\nalgorithm side, this paper proposes a deep learning algorithmic solution based\non stacked LSTM for collective reliability training and inference across\ncollective MOSFET converters based on device resistance changes. Deep RACE also\nproposes an integrative edge-to-cloud solution to offer a scalable\ndecentralized devices-specific reliability monitoring, awareness, and modeling.\nThe MOSFET convertors are IoT devices which have been empowered with edge\nreal-time deep learning processing capabilities. The proposed Deep RACE\nsolution has been prototyped and implemented through learning from MOSFET data\nset provided by NASA. Our experimental results show an average miss prediction\nof $8.9\\%$ over five different devices which is a much higher accuracy compared\nto well-known classical approaches (Kalman Filter, and Particle Filter). Deep\nRACE only requires $26ms$ processing time and $1.87W$ computing power on Edge\nIoT device.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 22:52:03 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Baharani", "Mohammadreza", ""], ["Biglarbegian", "Mehrdad", ""], ["Parkhideh", "Babak", ""], ["Tabkhi", "Hamed", ""]]}, {"id": "1908.01251", "submitter": "Miles Lopes", "authors": "Miles E. Lopes, Suofei Wu, Thomas C. M. Lee", "title": "Measuring the Algorithmic Convergence of Randomized Ensembles: The\n  Regression Setting", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When randomized ensemble methods such as bagging and random forests are\nimplemented, a basic question arises: Is the ensemble large enough? In\nparticular, the practitioner desires a rigorous guarantee that a given ensemble\nwill perform nearly as well as an ideal infinite ensemble (trained on the same\ndata). The purpose of the current paper is to develop a bootstrap method for\nsolving this problem in the context of regression --- which complements our\ncompanion paper in the context of classification (Lopes 2019). In contrast to\nthe classification setting, the current paper shows that theoretical guarantees\nfor the proposed bootstrap can be established under much weaker assumptions. In\naddition, we illustrate the flexibility of the method by showing how it can be\nadapted to measure algorithmic convergence for variable selection. Lastly, we\nprovide numerical results demonstrating that the method works well in a range\nof situations.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 00:45:59 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Lopes", "Miles E.", ""], ["Wu", "Suofei", ""], ["Lee", "Thomas C. M.", ""]]}, {"id": "1908.01253", "submitter": "Fei Wang", "authors": "Fei Wang, Ling Zhou, Lu Tang, and Peter X.-K. Song", "title": "Method of Contraction-Expansion (MOCE) for Simultaneous Inference in\n  Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous inference after model selection is of critical importance to\naddress scientific hypotheses involving a set of parameters. In this paper, we\nconsider high-dimensional linear regression model in which a regularization\nprocedure such as LASSO is applied to yield a sparse model. To establish a\nsimultaneous post-model selection inference, we propose a method of contraction\nand expansion (MOCE) along the line of debiasing estimation that enables us to\nbalance the bias-and-variance trade-off so that the super-sparsity assumption\nmay be relaxed. We establish key theoretical results for the proposed MOCE\nprocedure from which the expanded model can be selected with theoretical\nguarantees and simultaneous confidence regions can be constructed by the joint\nasymptotic normal distribution. In comparison with existing methods, our\nproposed method exhibits stable and reliable coverage at a nominal significance\nlevel with substantially less computational burden, and thus it is trustworthy\nfor its application in solving real-world problems.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 01:35:41 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Wang", "Fei", ""], ["Zhou", "Ling", ""], ["Tang", "Lu", ""], ["Song", "Peter X. -K.", ""]]}, {"id": "1908.01262", "submitter": "Wang Yan", "authors": "Yan Wang, Peng Jia, Luping Liu, Jiayong Liu", "title": "A systematic review of fuzzing based on machine learning techniques", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0237749", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security vulnerabilities play a vital role in network security system.\nFuzzing technology is widely used as a vulnerability discovery technology to\nreduce damage in advance. However, traditional fuzzing techniques have many\nchallenges, such as how to mutate input seed files, how to increase code\ncoverage, and how to effectively bypass verification. Machine learning\ntechnology has been introduced as a new method into fuzzing test to alleviate\nthese challenges. This paper reviews the research progress of using machine\nlearning technology for fuzzing test in recent years, analyzes how machine\nlearning improve the fuzz process and results, and sheds light on future work\nin fuzzing. Firstly, this paper discusses the reasons why machine learning\ntechniques can be used for fuzzing scenarios and identifies six different\nstages in which machine learning have been used. Then this paper systematically\nstudy the machine learning based fuzzing models from selection of machine\nlearning algorithm, pre-processing methods, datasets, evaluation metrics, and\nhyperparameters setting. Next, this paper assesses the performance of the\nmachine learning models based on the frequently used evaluation metrics. The\nresults of the evaluation prove that machine learning technology has an\nacceptable capability of categorize predictive for fuzzing. Finally, the\ncomparison on capability of discovering vulnerabilities between traditional\nfuzzing tools and machine learning based fuzzing tools is analyzed. The results\ndepict that the introduction of machine learning technology can improve the\nperformance of fuzzing. However, there are still some limitations, such as\nunbalanced training samples and difficult to extract the characteristics\nrelated to vulnerabilities.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 02:51:53 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Wang", "Yan", ""], ["Jia", "Peng", ""], ["Liu", "Luping", ""], ["Liu", "Jiayong", ""]]}, {"id": "1908.01270", "submitter": "Abhishek Halder", "authors": "Abhishek Halder, Kenneth F. Caluya, Bertrand Travacca, and Scott J.\n  Moura", "title": "Hopfield Neural Network Flow: A Geometric Viewpoint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide gradient flow interpretations for the continuous-time\ncontinuous-state Hopfield neural network (HNN). The ordinary and stochastic\ndifferential equations associated with the HNN were introduced in the\nliterature as analog optimizers, and were reported to exhibit good performance\nin numerical experiments. In this work, we point out that the deterministic HNN\ncan be transcribed into Amari's natural gradient descent, and thereby uncover\nthe explicit relation between the underlying Riemannian metric and the\nactivation functions. By exploiting an equivalence between the natural gradient\ndescent and the mirror descent, we show how the choice of activation function\ngoverns the geometry of the HNN dynamics.\n  For the stochastic HNN, we show that the so-called \"diffusion machine\", while\nnot a gradient flow itself, induces a gradient flow when lifted in the space of\nprobability measures. We characterize this infinite dimensional flow as the\ngradient descent of certain free energy with respect to a Wasserstein metric\nthat depends on the geodesic distance on the ground manifold. Furthermore, we\ndemonstrate how this gradient flow interpretation can be used for fast\ncomputation via recently developed proximal algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 04:23:36 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 23:21:37 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Halder", "Abhishek", ""], ["Caluya", "Kenneth F.", ""], ["Travacca", "Bertrand", ""], ["Moura", "Scott J.", ""]]}, {"id": "1908.01275", "submitter": "Ameer Haj-Ali", "authors": "Ameer Haj-Ali, Nesreen K. Ahmed, Ted Willke, Joseph Gonzalez, Krste\n  Asanovic, Ion Stoica", "title": "A View on Deep Reinforcement Learning in System Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world systems problems require reasoning about the long term\nconsequences of actions taken to configure and manage the system. These\nproblems with delayed and often sequentially aggregated reward, are often\ninherently reinforcement learning problems and present the opportunity to\nleverage the recent substantial advances in deep reinforcement learning.\nHowever, in some cases, it is not clear why deep reinforcement learning is a\ngood fit for the problem. Sometimes, it does not perform better than the\nstate-of-the-art solutions. And in other cases, random search or greedy\nalgorithms could outperform deep reinforcement learning. In this paper, we\nreview, discuss, and evaluate the recent trends of using deep reinforcement\nlearning in system optimization. We propose a set of essential metrics to guide\nfuture works in evaluating the efficacy of using deep reinforcement learning in\nsystem optimization. Our evaluation includes challenges, the types of problems,\ntheir formulation in the deep reinforcement learning setting, embedding, the\nmodel used, efficiency, and robustness. We conclude with a discussion on open\nchallenges and potential directions for pushing further the integration of\nreinforcement learning in system optimization.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 05:55:56 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 01:52:21 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 23:13:04 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Haj-Ali", "Ameer", ""], ["Ahmed", "Nesreen K.", ""], ["Willke", "Ted", ""], ["Gonzalez", "Joseph", ""], ["Asanovic", "Krste", ""], ["Stoica", "Ion", ""]]}, {"id": "1908.01281", "submitter": "Zhongdao Wang", "authors": "Lanqing He, Zhongdao Wang, Yali Li, Shengjin Wang", "title": "Softmax Dissection: Towards Understanding Intra- and Inter-class\n  Objective for Embedding Learning", "comments": "Accepted to AAAI-2020, Oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The softmax loss and its variants are widely used as objectives for embedding\nlearning, especially in applications like face recognition. However, the intra-\nand inter-class objectives in the softmax loss are entangled, therefore a\nwell-optimized inter-class objective leads to relaxation on the intra-class\nobjective, and vice versa. In this paper, we propose to dissect the softmax\nloss into independent intra- and inter-class objective (D-Softmax). With\nD-Softmax as objective, we can have a clear understanding of both the intra-\nand inter-class objective, therefore it is straightforward to tune each part to\nthe best state. Furthermore, we find the computation of the inter-class\nobjective is redundant and propose two sampling-based variants of D-Softmax to\nreduce the computation cost. Training with regular-scale data, experiments in\nface verification show D-Softmax is favorably comparable to existing losses\nsuch as SphereFace and ArcFace. Training with massive-scale data, experiments\nshow the fast variants of D-Softmax significantly accelerates the training\nprocess (such as 64x) with only a minor sacrifice in performance, outperforming\nexisting acceleration methods of softmax in terms of both performance and\nefficiency.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 06:50:20 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 08:03:55 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["He", "Lanqing", ""], ["Wang", "Zhongdao", ""], ["Li", "Yali", ""], ["Wang", "Shengjin", ""]]}, {"id": "1908.01287", "submitter": "Xuehang Zheng", "authors": "Il Yong Chun, Xuehang Zheng, Yong Long, Jeffrey A. Fessler", "title": "BCD-Net for Low-dose CT Reconstruction: Acceleration, Convergence, and\n  Generalization", "comments": "Accepted to MICCAI 2019, and the authors indicated by asterisks (*)\n  equally contributed to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining accurate and reliable images from low-dose computed tomography (CT)\nis challenging. Regression convolutional neural network (CNN) models that are\nlearned from training data are increasingly gaining attention in low-dose CT\nreconstruction. This paper modifies the architecture of an iterative regression\nCNN, BCD-Net, for fast, stable, and accurate low-dose CT reconstruction, and\npresents the convergence property of the modified BCD-Net. Numerical results\nwith phantom data show that applying faster numerical solvers to model-based\nimage reconstruction (MBIR) modules of BCD-Net leads to faster and more\naccurate BCD-Net; BCD-Net significantly improves the reconstruction accuracy,\ncompared to the state-of-the-art MBIR method using learned transforms; BCD-Net\nachieves better image quality, compared to a state-of-the-art iterative NN\narchitecture, ADMM-Net. Numerical results with clinical data show that BCD-Net\ngeneralizes significantly better than a state-of-the-art deep (non-iterative)\nregression NN, FBPConvNet, that lacks MBIR modules.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 07:10:24 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Chun", "Il Yong", ""], ["Zheng", "Xuehang", ""], ["Long", "Yong", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1908.01288", "submitter": "Md. Rezaul Karim", "authors": "Md. Rezaul Karim, Michael Cochez, Joao Bosco Jares, Mamtaz Uddin, Oya\n  Beyan, Stefan Decker", "title": "Drug-Drug Interaction Prediction Based on Knowledge Graph Embeddings and\n  Convolutional-LSTM Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interference between pharmacological substances can cause serious medical\ninjuries. Correctly predicting so-called drug-drug interactions (DDI) does not\nonly reduce these cases but can also result in a reduction of drug development\ncost. Presently, most drug-related knowledge is the result of clinical\nevaluations and post-marketing surveillance; resulting in a limited amount of\ninformation. Existing data-driven prediction approaches for DDIs typically rely\non a single source of information, while using information from multiple\nsources would help improve predictions. Machine learning (ML) techniques are\nused, but the techniques are often unable to deal with skewness in the data.\nHence, we propose a new ML approach for predicting DDIs based on multiple data\nsources. For this task, we use 12,000 drug features from DrugBank, PharmGKB,\nand KEGG drugs, which are integrated using Knowledge Graphs (KGs). To train our\nprediction model, we first embed the nodes in the graph using various embedding\napproaches. We found that the best performing combination was a ComplEx\nembedding method creating using PyTorch-BigGraph (PBG) with a\nConvolutional-LSTM network and classic machine learning-based prediction\nmodels. The model averaging ensemble method of three best classifiers yields up\nto 0.94, 0.92, 0.80 for AUPR, F1-score, and MCC, respectively during 5-fold\ncross-validation tests.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 07:19:21 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Karim", "Md. Rezaul", ""], ["Cochez", "Michael", ""], ["Jares", "Joao Bosco", ""], ["Uddin", "Mamtaz", ""], ["Beyan", "Oya", ""], ["Decker", "Stefan", ""]]}, {"id": "1908.01289", "submitter": "Ellen Novoseller", "authors": "Ellen R. Novoseller, Yibing Wei, Yanan Sui, Yisong Yue, and Joel W.\n  Burdick", "title": "Dueling Posterior Sampling for Preference-Based Reinforcement Learning", "comments": "To appear in Conference on Uncertainty in Artificial Intelligence\n  (UAI), 2020. 9 pages before references and appendix; 51 pages total; 7\n  figures; 4 tables. This replacement incorporates reviewer comments, and in\n  comparison to version 1, extends the theoretical and empirical analyses and\n  adds mathematical detail. Code:\n  https://github.com/ernovoseller/DuelingPosteriorSampling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In preference-based reinforcement learning (RL), an agent interacts with the\nenvironment while receiving preferences instead of absolute feedback. While\nthere is increasing research activity in preference-based RL, the design of\nformal frameworks that admit tractable theoretical analysis remains an open\nchallenge. Building upon ideas from preference-based bandit learning and\nposterior sampling in RL, we present DUELING POSTERIOR SAMPLING (DPS), which\nemploys preference-based posterior sampling to learn both the system dynamics\nand the underlying utility function that governs the preference feedback. As\npreference feedback is provided on trajectories rather than individual\nstate-action pairs, we develop a Bayesian approach for the credit assignment\nproblem, translating preferences to a posterior distribution over state-action\nreward models. We prove an asymptotic Bayesian no-regret rate for DPS with a\nBayesian linear regression credit assignment model. This is the first regret\nguarantee for preference-based RL to our knowledge. We also discuss possible\navenues for extending the proof methodology to other credit assignment models.\nFinally, we evaluate the approach empirically, showing competitive performance\nagainst existing baselines.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 07:51:36 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 05:27:33 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 05:26:41 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 16:09:49 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Novoseller", "Ellen R.", ""], ["Wei", "Yibing", ""], ["Sui", "Yanan", ""], ["Yue", "Yisong", ""], ["Burdick", "Joel W.", ""]]}, {"id": "1908.01297", "submitter": "Heng Chang", "authors": "Heng Chang, Yu Rong, Tingyang Xu, Wenbing Huang, Honglei Zhang, Peng\n  Cui, Wenwu Zhu, Junzhou Huang", "title": "A Restricted Black-box Adversarial Framework Towards Attacking Graph\n  Embedding Models", "comments": "Accepted by the AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the great success of graph embedding model on both academic and industry\narea, the robustness of graph embedding against adversarial attack inevitably\nbecomes a central problem in graph learning domain. Regardless of the fruitful\nprogress, most of the current works perform the attack in a white-box fashion:\nthey need to access the model predictions and labels to construct their\nadversarial loss. However, the inaccessibility of model predictions in real\nsystems makes the white-box attack impractical to real graph learning system.\nThis paper promotes current frameworks in a more general and flexible sense --\nwe demand to attack various kinds of graph embedding model with black-box\ndriven. To this end, we begin by investigating the theoretical connections\nbetween graph signal processing and graph embedding models in a principled way\nand formulate the graph embedding model as a general graph signal process with\ncorresponding graph filter. As such, a generalized adversarial attacker:\nGF-Attack is constructed by the graph filter and feature matrix. Instead of\naccessing any knowledge of the target classifiers used in graph embedding,\nGF-Attack performs the attack only on the graph filter in a black-box attack\nfashion. To validate the generalization of GF-Attack, we construct the attacker\non four popular graph embedding models. Extensive experimental results validate\nthe effectiveness of our attacker on several benchmark datasets. Particularly\nby using our attack, even small graph perturbations like one-edge flip is able\nto consistently make a strong attack in performance to different graph\nembedding models.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 09:03:20 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 01:48:02 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 20:27:20 GMT"}, {"version": "v4", "created": "Tue, 3 Dec 2019 00:13:29 GMT"}, {"version": "v5", "created": "Tue, 17 Dec 2019 20:48:26 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Chang", "Heng", ""], ["Rong", "Yu", ""], ["Xu", "Tingyang", ""], ["Huang", "Wenbing", ""], ["Zhang", "Honglei", ""], ["Cui", "Peng", ""], ["Zhu", "Wenwu", ""], ["Huang", "Junzhou", ""]]}, {"id": "1908.01300", "submitter": "Sai Raam Venkatraman", "authors": "Sairaam Venkatraman, S. Balasubramanian, R. Raghunatha Sarma", "title": "Building Deep, Equivariant Capsule Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule networks are constrained by the parameter-expensive nature of their\nlayers, and the general lack of provable equivariance guarantees. We present a\nvariation of capsule networks that aims to remedy this. We identify that\nlearning all pair-wise part-whole relationships between capsules of successive\nlayers is inefficient. Further, we also realise that the choice of prediction\nnetworks and the routing mechanism are both key to equivariance. Based on\nthese, we propose an alternative framework for capsule networks that learns to\nprojectively encode the manifold of pose-variations, termed the\nspace-of-variation (SOV), for every capsule-type of each layer. This is done\nusing a trainable, equivariant function defined over a grid of\ngroup-transformations. Thus, the prediction-phase of routing involves\nprojection into the SOV of a deeper capsule using the corresponding function.\nAs a specific instantiation of this idea, and also in order to reap the\nbenefits of increased parameter-sharing, we use type-homogeneous\ngroup-equivariant convolutions of shallower capsules in this phase. We also\nintroduce an equivariant routing mechanism based on degree-centrality. We show\nthat this particular instance of our general model is equivariant, and hence\npreserves the compositional representation of an input under transformations.\nWe conduct several experiments on standard object-classification datasets that\nshowcase the increased transformation-robustness, as well as general\nperformance, of our model to several capsule baselines.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 09:14:29 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 15:14:40 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 04:26:10 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Venkatraman", "Sairaam", ""], ["Balasubramanian", "S.", ""], ["Sarma", "R. Raghunatha", ""]]}, {"id": "1908.01301", "submitter": "Zhongdao Wang", "authors": "Yixuan Liu, Yuwang Wang, Shengjin Wang", "title": "Adversarial View-Consistent Learning for Monocular Depth Estimation", "comments": "BMVC 2019 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of Monocular Depth Estimation (MDE).\nExisting approaches on MDE usually model it as a pixel-level regression\nproblem, ignoring the underlying geometry property. We empirically find this\nmay result in sub-optimal solution: while the predicted depth map presents\nsmall loss value in one specific view, it may exhibit large loss if viewed in\ndifferent directions. In this paper, inspired by multi-view stereo (MVS), we\npropose an Adversarial View-Consistent Learning (AVCL) framework to force the\nestimated depth map to be all reasonable viewed from multiple views. To this\nend, we first design a differentiable depth map warping operation, which is\nend-to-end trainable, and then propose a pose generator to generate novel views\nfor a given image in an adversarial manner. Collaborating with the\ndifferentiable depth map warping operation, the pose generator encourages the\ndepth estimation network to learn from hard views, hence produce\nview-consistent depth maps . We evaluate our method on NYU Depth V2 dataset and\nthe experimental results show promising performance gain upon state-of-the-art\nMDE approaches.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 09:37:24 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Liu", "Yixuan", ""], ["Wang", "Yuwang", ""], ["Wang", "Shengjin", ""]]}, {"id": "1908.01310", "submitter": "Denis Sidorov", "authors": "Denis Sidorov, Ildar Muftahov, Nikita Tomin, Dmitriy Karamov, Daniil\n  Panasetsky, Aliona Dreglea, Fang Liu, Aoife Foley", "title": "A Dynamic Analysis of Energy Storage with Renewable and Diesel\n  Generation using Volterra Equations", "comments": "9 pages, 12 figures; accepted to IEEE Transactions on Industrial\n  Informatics", "journal-ref": "IEEE TII 2019", "doi": "10.1109/TII.2019.2932453", "report-no": null, "categories": "math.NA cs.LG cs.NA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy storage systems will play a key role in the power system of the twenty\nfirst century considering the large penetrations of variable renewable energy,\ngrowth in transport electrification and decentralisation of heating loads.\nTherefore reliable real time methods to optimise energy storage, demand\nresponse and generation are vital for power system operations. This paper\npresents a concise review of battery energy storage and an example of battery\nmodelling for renewable energy applications and second details an adaptive\napproach to solve this load levelling problem with storage. A dynamic\nevolutionary model based on the first kind Volterra integral equation is used\nin both cases. A direct regularised numerical method is employed to find the\nleast-cost dispatch of the battery in terms of integral equation solution.\nValidation on real data shows that the proposed evolutionary Volterra model\neffectively generalises conventional discrete integral model taking into\naccount both state of health and the availability of generation/storage.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 10:06:14 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Sidorov", "Denis", ""], ["Muftahov", "Ildar", ""], ["Tomin", "Nikita", ""], ["Karamov", "Dmitriy", ""], ["Panasetsky", "Daniil", ""], ["Dreglea", "Aliona", ""], ["Liu", "Fang", ""], ["Foley", "Aoife", ""]]}, {"id": "1908.01314", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu, Bo Zhang, Ruijun Xu", "title": "MoGA: Searching Beyond MobileNetV3", "comments": "Accepted by ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of MobileNets has laid a solid foundation for neural network\napplications on mobile end. With the latest MobileNetV3, neural architecture\nsearch again claimed its supremacy in network design. Unfortunately, till today\nall mobile methods mainly focus on CPU latencies instead of GPU, the latter,\nhowever, is much preferred in practice for it has faster speed, lower overhead\nand less interference. Bearing the target hardware in mind, we propose the\nfirst Mobile GPU-Aware (MoGA) neural architecture search in order to be\nprecisely tailored for real-world applications. Further, the ultimate objective\nto devise a mobile network lies in achieving better performance by maximizing\nthe utilization of bounded resources. Urging higher capability while\nrestraining time consumption is not reconcilable. We alleviate the tension by\nweighted evolution techniques. Moreover, we encourage increasing the number of\nparameters for higher representational power. With 200x fewer GPU days than\nMnasNet, we obtain a series of models that outperform MobileNetV3 under the\nsimilar latency constraints, i.e., MoGA-A achieves 75.9% top-1 accuracy on\nImageNet, MoGA-B meets 75.5% which costs only 0.5 ms more on mobile GPU. MoGA-C\nbest attests GPU-awareness by reaching 75.3% and being slower on CPU but faster\non GPU.The models and test code is made available here\nhttps://github.com/xiaomi-automl/MoGA.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 10:40:04 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 15:22:20 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 07:24:44 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 04:11:41 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhang", "Bo", ""], ["Xu", "Ruijun", ""]]}, {"id": "1908.01321", "submitter": "Shujaat Khan Engr", "authors": "Shujaat Khan, Jawwad Ahmad, Alishba Sadiq, Imran Naseem, Muhammad\n  Moinuddin", "title": "Spatio-Temporal RBF Neural Networks", "comments": "Published in 2018 3rd International Conference on Emerging Trends in\n  Engineering, Sciences and Technology (ICEEST)", "journal-ref": "2018 3rd International Conference on Emerging Trends in\n  Engineering, Sciences and Technology (ICEEST)", "doi": "10.1109/ICEEST.2018.8643322", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein, we propose a spatio-temporal extension of RBFNN for nonlinear system\nidentification problem. The proposed algorithm employs the concept of\ntime-space orthogonality and separately models the dynamics and nonlinear\ncomplexities of the system. The proposed RBF architecture is explored for the\nestimation of a highly nonlinear system and results are compared with the\nstandard architecture for both the conventional and fractional gradient\ndecent-based learning rules. The spatio-temporal RBF is shown to perform better\nthan the standard and fractional RBFNNs by achieving fast convergence and\nsignificantly reduced estimation error.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 11:47:31 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Khan", "Shujaat", ""], ["Ahmad", "Jawwad", ""], ["Sadiq", "Alishba", ""], ["Naseem", "Imran", ""], ["Moinuddin", "Muhammad", ""]]}, {"id": "1908.01342", "submitter": "Shuai Yang", "authors": "Shuai Yang, Hao Wang, Yuhong Zhang, Pei-Pei Li, Yi Zhu and Xuegang Hu", "title": "Semi-supervised representation learning via dual autoencoders for domain\n  adaptation", "comments": "This paper has been accepted by the journal of KNOWLEDGE-BASED\n  SYSTEMS (KBS) 2019", "journal-ref": "Knowledge-Based Systems(2019)", "doi": "10.1016/j.knosys.2019.105161", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation aims to exploit the knowledge in source domain to promote\nthe learning tasks in target domain, which plays a critical role in real-world\napplications. Recently, lots of deep learning approaches based on autoencoders\nhave achieved a significance performance in domain adaptation. However, most\nexisting methods focus on minimizing the distribution divergence by putting the\nsource and target data together to learn global feature representations, while\nthey do not consider the local relationship between instances in the same\ncategory from different domains. To address this problem, we propose a novel\nSemi-Supervised Representation Learning framework via Dual Autoencoders for\ndomain adaptation, named SSRLDA. More specifically, we extract richer feature\nrepresentations by learning the global and local feature representations\nsimultaneously using two novel autoencoders, which are referred to as\nmarginalized denoising autoencoder with adaptation distribution (MDAad) and\nmulti-class marginalized denoising autoencoder (MMDA) respectively. Meanwhile,\nwe make full use of label information to optimize feature representations.\nExperimental results show that our proposed approach outperforms several\nstate-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 13:49:34 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 02:56:43 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 02:49:04 GMT"}, {"version": "v4", "created": "Fri, 25 Oct 2019 08:13:48 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Yang", "Shuai", ""], ["Wang", "Hao", ""], ["Zhang", "Yuhong", ""], ["Li", "Pei-Pei", ""], ["Zhu", "Yi", ""], ["Hu", "Xuegang", ""]]}, {"id": "1908.01384", "submitter": "Yawei Zhao", "authors": "Yawei Zhao, En Zhu, Xinwang Liu, Chang Tang, Deke Guo, Jianping Yin", "title": "Simultaneous Clustering and Optimization for Evolving Datasets", "comments": "Accepted by IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous clustering and optimization (SCO) has recently drawn much\nattention due to its wide range of practical applications. Many methods have\nbeen previously proposed to solve this problem and obtain the optimal model.\nHowever, when a dataset evolves over time, those existing methods have to\nupdate the model frequently to guarantee accuracy; such updating is\ncomputationally infeasible. In this paper, we propose a new formulation of SCO\nto handle evolving datasets. Specifically, we propose a new variant of the\nalternating direction method of multipliers (ADMM) to solve this problem\nefficiently. The guarantee of model accuracy is analyzed theoretically for two\nspecific tasks: ridge regression and convex clustering. Extensive empirical\nstudies confirm the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 18:45:42 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zhao", "Yawei", ""], ["Zhu", "En", ""], ["Liu", "Xinwang", ""], ["Tang", "Chang", ""], ["Guo", "Deke", ""], ["Yin", "Jianping", ""]]}, {"id": "1908.01394", "submitter": "Andrea Schioppa", "authors": "Andrea Schioppa", "title": "Learning to Transport with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare several approaches to learn an Optimal Map, represented as a\nneural network, between probability distributions. The approaches fall into two\ncategories: ``Heuristics'' and approaches with a more sound mathematical\njustification, motivated by the dual of the Kantorovitch problem. Among the\nalgorithms we consider a novel approach involving dynamic flows and reductions\nof Optimal Transport to supervised learning.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 20:29:28 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Schioppa", "Andrea", ""]]}, {"id": "1908.01399", "submitter": "Wei XIa", "authors": "Wei Xia, Kazuhito Koishida", "title": "Sound Event Detection in Multichannel Audio using Convolutional\n  Time-Frequency-Channel Squeeze and Excitation", "comments": "Accepted by Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we introduce a convolutional time-frequency-channel \"Squeeze\nand Excitation\" (tfc-SE) module to explicitly model inter-dependencies between\nthe time-frequency domain and multiple channels. The tfc-SE module consists of\ntwo parts: tf-SE block and c-SE block which are designed to provide attention\non time-frequency and channel domain, respectively, for adaptively\nrecalibrating the input feature map. The proposed tfc-SE module, together with\na popular Convolutional Recurrent Neural Network (CRNN) model, are evaluated on\na multi-channel sound event detection task with overlapping audio sources: the\ntraining and test data are synthesized TUT Sound Events 2018 datasets, recorded\nwith microphone arrays. We show that the tfc-SE module can be incorporated into\nthe CRNN model at a small additional computational cost and bring significant\nimprovements on sound event detection accuracy. We also perform detailed\nablation studies by analyzing various factors that may influence the\nperformance of the SE blocks. We show that with the best tfc-SE block, error\nrate (ER) decreases from 0.2538 to 0.2026, relative 20.17\\% reduction of ER,\nand 5.72\\% improvement of F1 score. The results indicate that the learned\nacoustic embeddings with the tfc-SE module efficiently strengthen\ntime-frequency and channel-wise feature representations to improve the\ndiscriminative performance.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 20:58:52 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Xia", "Wei", ""], ["Koishida", "Kazuhito", ""]]}, {"id": "1908.01425", "submitter": "Ksenia Korovina", "authors": "Ksenia Korovina, Sailun Xu, Kirthevasan Kandasamy, Willie Neiswanger,\n  Barnabas Poczos, Jeff Schneider, Eric P. Xing", "title": "ChemBO: Bayesian Optimization of Small Organic Molecules with\n  Synthesizable Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications such as molecule design or drug discovery, it is desirable to\nhave an algorithm which recommends new candidate molecules based on the results\nof past tests. These molecules first need to be synthesized and then tested for\nobjective properties. We describe ChemBO, a Bayesian optimization framework for\ngenerating and optimizing organic molecules for desired molecular properties.\nWhile most existing data-driven methods for this problem do not account for\nsample efficiency or fail to enforce realistic constraints on synthesizability,\nour approach explores the synthesis graph in a sample-efficient way and\nproduces synthesizable candidates. We implement ChemBO as a Gaussian process\nmodel and explore existing molecular kernels for it. Moreover, we propose a\nnovel optimal-transport based distance and kernel that accounts for graphical\ninformation explicitly. In our experiments, we demonstrate the efficacy of the\nproposed approach on several molecular optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 00:12:54 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 00:36:27 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Korovina", "Ksenia", ""], ["Xu", "Sailun", ""], ["Kandasamy", "Kirthevasan", ""], ["Neiswanger", "Willie", ""], ["Poczos", "Barnabas", ""], ["Schneider", "Jeff", ""], ["Xing", "Eric P.", ""]]}, {"id": "1908.01447", "submitter": "Wei XIa", "authors": "Wei Xia, Jing Huang, John H.L. Hansen", "title": "Cross-lingual Text-independent Speaker Verification using Unsupervised\n  Adversarial Discriminative Domain Adaptation", "comments": "Published in ICASSP2019", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682259", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker verification systems often degrade significantly when there is a\nlanguage mismatch between training and testing data. Being able to improve\ncross-lingual speaker verification system using unlabeled data can greatly\nincrease the robustness of the system and reduce human labeling costs. In this\nstudy, we introduce an unsupervised Adversarial Discriminative Domain\nAdaptation (ADDA) method to effectively learn an asymmetric mapping that adapts\nthe target domain encoder to the source domain, where the target domain and\nsource domain are speech data from different languages. ADDA, together with a\npopular Domain Adversarial Training (DAT) approach, are evaluated on a\ncross-lingual speaker verification task: the training data is in English from\nNIST SRE04-08, Mixer 6 and Switchboard, and the test data is in Chinese from\nAISHELL-I. We show that with the ADDA adaptation, Equal Error Rate (EER) of the\nx-vector system decreases from 9.331\\% to 7.645\\%, relatively 18.07\\% reduction\nof EER, and 6.32\\% reduction from DAT as well. Further data analysis of ADDA\nadapted speaker embedding shows that the learned speaker embeddings can perform\nwell on speaker classification for the target domain data, and are less\ndependent with respect to the shift in language.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 02:35:22 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Xia", "Wei", ""], ["Huang", "Jing", ""], ["Hansen", "John H. L.", ""]]}, {"id": "1908.01454", "submitter": "Yuki Saito", "authors": "Taiki Nakamura and Yuki Saito and Shinnosuke Takamichi and Yusuke\n  Ijima and Hiroshi Saruwatari", "title": "V2S attack: building DNN-based voice conversion from automatic speaker\n  verification", "comments": "5 pages, 2 figures, accepted for The 10th ISCA Speech Synthesis\n  Workshop (SSW10)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new voice impersonation attack using voice conversion\n(VC). Enrolling personal voices for automatic speaker verification (ASV) offers\nnatural and flexible biometric authentication systems. Basically, the ASV\nsystems do not include the users' voice data. However, if the ASV system is\nunexpectedly exposed and hacked by a malicious attacker, there is a risk that\nthe attacker will use VC techniques to reproduce the enrolled user's voices. We\nname this the ``verification-to-synthesis (V2S) attack'' and propose VC\ntraining with the ASV and pre-trained automatic speech recognition (ASR) models\nand without the targeted speaker's voice data. The VC model reproduces the\ntargeted speaker's individuality by deceiving the ASV model and restores\nphonetic property of an input voice by matching phonetic posteriorgrams\npredicted by the ASR model. The experimental evaluation compares converted\nvoices between the proposed method that does not use the targeted speaker's\nvoice data and the standard VC that uses the data. The experimental results\ndemonstrate that the proposed method performs comparably to the existing VC\nmethods that trained using a very small amount of parallel voice data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 03:28:13 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Nakamura", "Taiki", ""], ["Saito", "Yuki", ""], ["Takamichi", "Shinnosuke", ""], ["Ijima", "Yusuke", ""], ["Saruwatari", "Hiroshi", ""]]}, {"id": "1908.01456", "submitter": "Sanjay Madria", "authors": "Md. Yasin Kabir and Sanjay Madria", "title": "A Deep Learning Approach for Tweet Classification and Rescue Scheduling\n  for Effective Disaster Management", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a challenging and complex task to acquire information from different\nregions of a disaster-affected area in a timely fashion. The extensive spread\nand reach of social media and networks allow people to share information in\nreal-time. However, the processing of social media data and gathering of\nvaluable information require a series of operations such as (1) processing each\nspecific tweet for a text classification, (2) possible location determination\nof people needing help based on tweets, and (3) priority calculations of rescue\ntasks based on the classification of tweets. These are three primary challenges\nin developing an effective rescue scheduling operation using social media data.\nIn this paper, first, we propose a deep learning model combining attention\nbased Bi-directional Long Short-Term Memory (BLSTM) and Convolutional Neural\nNetwork (CNN) to classify the tweets under different categories. We use\npre-trained crisis word vectors and global vectors for word representation\n(GLoVe) for capturing semantic meaning from tweets. Next, we perform feature\nengineering to create an auxiliary feature map which dramatically increases the\nmodel accuracy. In our experiments using real data sets from Hurricanes Harvey\nand Irma, it is observed that our proposed approach performs better compared to\nother classification methods based on Precision, Recall, F1-score, and\nAccuracy, and is highly effective to determine the correct priority of a tweet.\nFurthermore, to evaluate the effectiveness and robustness of the proposed\nclassification model a merged dataset comprises of 4 different datasets from\nCrisisNLP and another 15 different disasters data from CrisisLex are used.\nFinally, we develop an adaptive multitask hybrid scheduling algorithm\nconsidering resource constraints to perform an effective rescue scheduling\noperation considering different rescue priorities.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 03:45:17 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kabir", "Md. Yasin", ""], ["Madria", "Sanjay", ""]]}, {"id": "1908.01457", "submitter": "Hayeon Lee", "authors": "Hayeon Lee, Donghyun Na, Hae Beom Lee, Sung Ju Hwang", "title": "Learning to Generalize to Unseen Tasks with Bilevel Optimization", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent metric-based meta-learning approaches, which learn a metric space that\ngeneralizes well over combinatorial number of different classification tasks\nsampled from a task distribution, have been shown to be effective for few-shot\nclassification tasks of unseen classes. They are often trained with episodic\ntraining where they iteratively train a common metric space that reduces\ndistance between the class representatives and instances belonging to each\nclass, over large number of episodes with random classes. However, this\ntraining is limited in that while the main target is the generalization to the\nclassification of unseen classes during training, there is no explicit\nconsideration of generalization during meta-training phase. To tackle this\nissue, we propose a simple yet effective meta-learning framework for\nmetricbased approaches, which we refer to as learning to generalize (L2G), that\nexplicitly constrains the learning on a sampled classification task to reduce\nthe classification error on a randomly sampled unseen classification task with\na bilevel optimization scheme. This explicit learning aimed toward\ngeneralization allows the model to obtain a metric that separates well between\nunseen classes. We validate our L2G framework on mini-ImageNet and\ntiered-ImageNet datasets with two base meta-learning few-shot classification\nmodels, Prototypical Networks and Relation Networks. The results show that L2G\nsignificantly improves the performance of the two methods over episodic\ntraining. Further visualization shows that L2G obtains a metric space that\nclusters and separates unseen classes well.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 04:04:09 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Lee", "Hayeon", ""], ["Na", "Donghyun", ""], ["Lee", "Hae Beom", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1908.01469", "submitter": "Thang Dang Duy", "authors": "Dang Duy Thang and Toshihiro Matsui", "title": "Automated Detection System for Adversarial Examples with High-Frequency\n  Noises Sieve", "comments": "Appear to 11th International Symposium on Cyberspace Safety and\n  Security CSS 2019, Guangzhou, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are being applied in many tasks with encouraging\nresults, and have often reached human-level performance. However, deep neural\nnetworks are vulnerable to well-designed input samples called adversarial\nexamples. In particular, neural networks tend to misclassify adversarial\nexamples that are imperceptible to humans. This paper introduces a new\ndetection system that automatically detects adversarial examples on deep neural\nnetworks. Our proposed system can mostly distinguish adversarial samples and\nbenign images in an end-to-end manner without human intervention. We exploit\nthe important role of the frequency domain in adversarial samples and propose a\nmethod that detects malicious samples in observations. When evaluated on two\nstandard benchmark datasets (MNIST and ImageNet), our method achieved an\nout-detection rate of 99.7 - 100% in many settings.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 05:05:29 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Thang", "Dang Duy", ""], ["Matsui", "Toshihiro", ""]]}, {"id": "1908.01477", "submitter": "Haibao Yu", "authors": "Haibao Yu, Tuopu Wen, Guangliang Cheng, Jiankai Sun, Qi Han, Jianping\n  Shi", "title": "GDRQ: Group-based Distribution Reshaping for Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-bit quantization is challenging to maintain high performance with limited\nmodel capacity (e.g., 4-bit for both weights and activations). Naturally, the\ndistribution of both weights and activations in deep neural network are\nGaussian-like. Nevertheless, due to the limited bitwidth of low-bit model,\nuniform-like distributed weights and activations have been proved to be more\nfriendly to quantization while preserving accuracy~\\cite{Han2015Learning}.\nMotivated by this, we propose Scale-Clip, a Distribution Reshaping technique\nthat can reshape weights or activations into a uniform-like distribution in a\ndynamic manner. Furthermore, to increase the model capability for a low-bit\nmodel, a novel Group-based Quantization algorithm is proposed to split the\nfilters into several groups. Different groups can learn different quantization\nparameters, which can be elegantly merged in to batch normalization layer\nwithout extra computational cost in the inference stage. Finally, we integrate\nScale-Clip technique with Group-based Quantization algorithm and propose the\nGroup-based Distribution Reshaping Quantization (GDQR) framework to further\nimprove the quantization performance. Experiments on various networks (e.g.\nVGGNet and ResNet) and vision tasks (e.g. classification, detection and\nsegmentation) demonstrate that our framework achieves good performance.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 05:44:52 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Yu", "Haibao", ""], ["Wen", "Tuopu", ""], ["Cheng", "Guangliang", ""], ["Sun", "Jiankai", ""], ["Han", "Qi", ""], ["Shi", "Jianping", ""]]}, {"id": "1908.01478", "submitter": "Yi-Hsiang Chang", "authors": "Yi-Hsiang Chang, Kuan-Yu Chang, Henry Kuo, Chun-Yi Lee", "title": "Reusability and Transferability of Macro Actions for Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional reinforcement learning (RL) typically determines an appropriate\nprimitive action at each timestep. However, by using a proper macro action,\ndefined as a sequence of primitive actions, an agent is able to bypass\nintermediate states to a farther state and facilitate its learning procedure.\nThe problem we would like to investigate is what associated beneficial\nproperties that macro actions may possess. In this paper, we unveil the\nproperties of reusability and transferability of macro actions. The first\nproperty, reusability, means that a macro action generated along with one RL\nmethod can be reused by another RL method for training, while the second one,\ntransferability, means that a macro action can be utilized for training agents\nin similar environments with different reward settings. In our experiments, we\nfirst generate macro actions along with RL methods. We then provide a set of\nanalyses to reveal the properties of reusability and transferability of the\ngenerated macro actions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 05:59:40 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 06:04:26 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chang", "Yi-Hsiang", ""], ["Chang", "Kuan-Yu", ""], ["Kuo", "Henry", ""], ["Lee", "Chun-Yi", ""]]}, {"id": "1908.01479", "submitter": "Alexei Novikov", "authors": "Miguel Moscoso, Alexei Novikov, George Papanicolaou, Chrysoula Tsogka", "title": "Imaging with highly incomplete and corrupted data", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6420/ab5a21", "report-no": null, "categories": "eess.IV cs.LG cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of imaging sparse scenes from a few noisy data using\nan $l_1$-minimization approach. This problem can be cast as a linear system of\nthe form $A \\, \\rho =b$, where $A$ is an $N\\times K$ measurement matrix. We\nassume that the dimension of the unknown sparse vector $\\rho \\in\n{\\mathbb{C}}^K$ is much larger than the dimension of the data vector $b \\in\n{\\mathbb{C}}^N$, i.e, $K \\gg N$. We provide a theoretical framework that allows\nus to examine under what conditions the $\\ell_1$-minimization problem admits a\nsolution that is close to the exact one in the presence of noise. Our analysis\nshows that $l_1$-minimization is not robust for imaging with noisy data when\nhigh resolution is required. To improve the performance of $l_1$-minimization\nwe propose to solve instead the augmented linear system $ [A \\, | \\, C] \\rho\n=b$, where the $N \\times \\Sigma$ matrix $C$ is a noise collector. It is\nconstructed so as its column vectors provide a frame on which the noise of the\ndata, a vector of dimension $N$, can be well approximated. Theoretically, the\ndimension $\\Sigma$ of the noise collector should be $e^N$ which would make its\nuse not practical. However, our numerical results illustrate that robust\nresults in the presence of noise can be obtained with a large enough number of\ncolumns $\\Sigma \\approx 10 K$.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 06:03:59 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Moscoso", "Miguel", ""], ["Novikov", "Alexei", ""], ["Papanicolaou", "George", ""], ["Tsogka", "Chrysoula", ""]]}, {"id": "1908.01499", "submitter": "Natalia Soboleva", "authors": "Natalia Soboleva and Konstantin Yakovlev", "title": "GAN Path Finder: Preliminary results", "comments": "Camera-ready version of the paper as to appear in KI 2019 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  2D path planning in static environment is a well-known problem and one of the\ncommon ways to solve it is to 1) represent the environment as a grid and 2)\nperform a heuristic search for a path on it. At the same time 2D grid resembles\nmuch a digital image, thus an appealing idea comes to being -- to treat the\nproblem as an image generation task and to solve it utilizing the recent\nadvances in deep learning. In this work we make an attempt to apply a\ngenerative neural network as a path finder and report preliminary results,\nconvincing enough to claim that this direction of research is worth further\nexploration.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 07:41:41 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Soboleva", "Natalia", ""], ["Yakovlev", "Konstantin", ""]]}, {"id": "1908.01505", "submitter": "Hiroki Tanioka Dr", "authors": "Hiroki Tanioka", "title": "A Fast Content-Based Image Retrieval Method Using Deep Visual Features", "comments": "accepted in ICDAR-WML: The 2nd International Workshop on Machine\n  Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and scalable Content-Based Image Retrieval using visual features is\nrequired for document analysis, Medical image analysis, etc. in the present\nage. Convolutional Neural Network (CNN) activations as features achieved their\noutstanding performance in this area. Deep Convolutional representations using\nthe softmax function in the output layer are also ones among visual features.\nHowever, almost all the image retrieval systems hold their index of visual\nfeatures on main memory in order to high responsiveness, limiting their\napplicability for big data applications. In this paper, we propose a fast\ncalculation method of cosine similarity with L2 norm indexed in advance on\nElasticsearch. We evaluate our approach with ImageNet Dataset and VGG-16\npre-trained model. The evaluation results show the effectiveness and efficiency\nof our proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 08:09:36 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Tanioka", "Hiroki", ""]]}, {"id": "1908.01536", "submitter": "Liam Hiley BSc", "authors": "Liam Hiley and Alun Preece and Yulia Hicks and David Marshall and\n  Harrison Taylor", "title": "Discriminating Spatial and Temporal Relevance in Deep Taylor\n  Decompositions for Explainable Activity Recognition", "comments": "5 pages, 2 figures, published at IJCAI19 ExAI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current techniques for explainable AI have been applied with some success to\nimage processing. The recent rise of research in video processing has called\nfor similar work n deconstructing and explaining spatio-temporal models. While\nmany techniques are designed for 2D convolutional models, others are inherently\napplicable to any input domain. One such body of work, deep Taylor\ndecomposition, propagates relevance from the model output distributively onto\nits input and thus is not restricted to image processing models. However, by\nexploiting a simple technique that removes motion information, we show that it\nis not the case that this technique is effective as-is for representing\nrelevance in non-image tasks. We instead propose a discriminative method that\nproduces a na\\\"ive representation of both the spatial and temporal relevance of\na frame as two separate objects. This new discriminative relevance model\nexposes relevance in the frame attributed to motion, that was previously\nambiguous in the original explanation. We observe the effectiveness of this\ntechnique on a range of samples from the UCF-101 action recognition dataset,\ntwo of which are demonstrated in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 09:42:25 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 14:36:13 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Hiley", "Liam", ""], ["Preece", "Alun", ""], ["Hicks", "Yulia", ""], ["Marshall", "David", ""], ["Taylor", "Harrison", ""]]}, {"id": "1908.01551", "submitter": "Lea Sch\\\"onherr", "authors": "Lea Sch\\\"onherr, Thorsten Eisenhofer, Steffen Zeiler, Thorsten Holz,\n  Dorothea Kolossa", "title": "Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech\n  Recognition Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) systems can be fooled via targeted\nadversarial examples, which induce the ASR to produce arbitrary transcriptions\nin response to altered audio signals. However, state-of-the-art adversarial\nexamples typically have to be fed into the ASR system directly, and are not\nsuccessful when played in a room. The few published over-the-air adversarial\nexamples fall into one of three categories: they are either handcrafted\nexamples, they are so conspicuous that human listeners can easily recognize the\ntarget transcription once they are alerted to its content, or they require\nprecise information about the room where the attack takes place, and are hence\nnot transferable to other rooms. In this paper, we demonstrate the first\nalgorithm that produces generic adversarial examples, which remain robust in an\nover-the-air attack that is not adapted to the specific environment. Hence, no\nprior knowledge of the room characteristics is required. Instead, we use room\nimpulse responses (RIRs) to compute robust adversarial examples for arbitrary\nroom characteristics and employ the ASR system Kaldi to demonstrate the attack.\nFurther, our algorithm can utilize psychoacoustic methods to hide changes of\nthe original audio signal below the human thresholds of hearing. In practical\nexperiments, we show that the adversarial examples work for varying room\nsetups, and that no direct line-of-sight between speaker and microphone is\nnecessary. As a result, an attacker can create inconspicuous adversarial\nexamples for any target transcription and apply these to arbitrary room setups\nwithout any prior knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 10:29:40 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 09:17:15 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 07:35:37 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2020 09:24:15 GMT"}, {"version": "v5", "created": "Tue, 24 Nov 2020 16:41:30 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Sch\u00f6nherr", "Lea", ""], ["Eisenhofer", "Thorsten", ""], ["Zeiler", "Steffen", ""], ["Holz", "Thorsten", ""], ["Kolossa", "Dorothea", ""]]}, {"id": "1908.01580", "submitter": "Wan-Duo Ma", "authors": "Wan-Duo Kurt Ma, J.P. Lewis, and W. Bastiaan Kleijn", "title": "The HSIC Bottleneck: Deep Learning without Back-Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for\ntraining deep neural networks. The HSIC bottleneck is an alternative to the\nconventional cross-entropy loss and backpropagation that has a number of\ndistinct advantages. It mitigates exploding and vanishing gradients, resulting\nin the ability to learn very deep networks without skip connections. There is\nno requirement for symmetric feedback or update locking. We find that the HSIC\nbottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification\ncomparable to backpropagation with a cross-entropy target, even when the system\nis not encouraged to make the output resemble the classification labels.\nAppending a single layer trained with SGD (without backpropagation) to reformat\nthe information further improves performance.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 12:23:24 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 10:38:45 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 09:24:24 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Ma", "Wan-Duo Kurt", ""], ["Lewis", "J. P.", ""], ["Kleijn", "W. Bastiaan", ""]]}, {"id": "1908.01581", "submitter": "Quanshi Zhang", "authors": "Ruofan Liang, Tianlin Li, Longfei Li, Jing Wang, Quanshi Zhang", "title": "Knowledge Consistency between Neural Networks and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to analyze knowledge consistency between pre-trained deep\nneural networks. We propose a generic definition for knowledge consistency\nbetween neural networks at different fuzziness levels. A task-agnostic method\nis designed to disentangle feature components, which represent the consistent\nknowledge, from raw intermediate-layer features of each neural network. As a\ngeneric tool, our method can be broadly used for different applications. In\npreliminary experiments, we have used knowledge consistency as a tool to\ndiagnose representations of neural networks. Knowledge consistency provides new\ninsights to explain the success of existing deep-learning techniques, such as\nknowledge distillation and network compression. More crucially, knowledge\nconsistency can also be used to refine pre-trained networks and boost\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 12:25:37 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 17:30:39 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Liang", "Ruofan", ""], ["Li", "Tianlin", ""], ["Li", "Longfei", ""], ["Wang", "Jing", ""], ["Zhang", "Quanshi", ""]]}, {"id": "1908.01587", "submitter": "Amir Mosavi Prof", "authors": "Muhammad Zubair Asghar, Fazli Subhan, Muhammad Imran, Fazal Masud\n  Kundi, Shahboddin Shamshirband, Amir Mosavi, Peter Csiba, Annamaria R.\n  Varkonyi-Koczy", "title": "Performance Evaluation of Supervised Machine Learning Techniques for\n  Efficient Detection of Emotions from Online Content", "comments": "30 pages, 13 tables, 1 figure", "journal-ref": null, "doi": "10.20944/preprints201908.0019.v1", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion detection from the text is an important and challenging problem in\ntext analytics. The opinion-mining experts are focusing on the development of\nemotion detection applications as they have received considerable attention of\nonline community including users and business organization for collecting and\ninterpreting public emotions. However, most of the existing works on emotion\ndetection used less efficient machine learning classifiers with limited\ndatasets, resulting in performance degradation. To overcome this issue, this\nwork aims at the evaluation of the performance of different machine learning\nclassifiers on a benchmark emotion dataset. The experimental results show the\nperformance of different machine learning classifiers in terms of different\nevaluation metrics like precision, recall ad f-measure. Finally, a classifier\nwith the best performance is recommended for the emotion classification.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 16:48:22 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Asghar", "Muhammad Zubair", ""], ["Subhan", "Fazli", ""], ["Imran", "Muhammad", ""], ["Kundi", "Fazal Masud", ""], ["Shamshirband", "Shahboddin", ""], ["Mosavi", "Amir", ""], ["Csiba", "Peter", ""], ["Varkonyi-Koczy", "Annamaria R.", ""]]}, {"id": "1908.01602", "submitter": "Timo Welti", "authors": "Sebastian Becker, Patrick Cheridito, Arnulf Jentzen, and Timo Welti", "title": "Solving high-dimensional optimal stopping problems using deep learning", "comments": "42 pages, 1 figure", "journal-ref": "Eur. J. Appl. Math 32 (2021) 470-514", "doi": "10.1017/S0956792521000073", "report-no": null, "categories": "cs.CE cs.LG math.PR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays many financial derivatives which are traded on stock and futures\nexchanges, such as American or Bermudan options, are of early exercise type.\nOften the pricing of early exercise options gives rise to high-dimensional\noptimal stopping problems, since the dimension corresponds to the number of\nunderlyings in the associated hedging portfolio. High-dimensional optimal\nstopping problems are, however, notoriously difficult to solve due to the\nwell-known curse of dimensionality. In this work we propose an algorithm for\nsolving such problems, which is based on deep learning and computes, in the\ncontext of early exercise option pricing, both approximations for an optimal\nexercise strategy and the price of the considered option. The proposed\nalgorithm can also be applied to optimal stopping problems that arise in other\nareas where the underlying stochastic process can be efficiently simulated. We\npresent numerical results for a large number of example problems, which include\nthe pricing of many high-dimensional American and Bermudan options such as, for\nexample, Bermudan max-call options in up to 5000 dimensions. Most of the\nobtained results are compared to reference values computed by exploiting the\nspecific problem design or, where available, to reference values from the\nliterature. These numerical results suggest that the proposed algorithm is\nhighly effective in the case of many underlyings, in terms of both accuracy and\nspeed.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 13:11:28 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 12:36:03 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Becker", "Sebastian", ""], ["Cheridito", "Patrick", ""], ["Jentzen", "Arnulf", ""], ["Welti", "Timo", ""]]}, {"id": "1908.01612", "submitter": "Qing Lyu", "authors": "Qing Lyu, Hongming Shan, Ge Wang", "title": "Multi-Contrast Super-Resolution MRI Through a Progressive Network", "comments": "10 figures, 5 tables, 11 pages", "journal-ref": "IEEE Transactions on Medical Imaging, early access, 2020", "doi": "10.1109/TMI.2020.2974858", "report-no": null, "categories": "eess.IV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance imaging (MRI) is widely used for screening, diagnosis,\nimage-guided therapy, and scientific research. A significant advantage of MRI\nover other imaging modalities such as computed tomography (CT) and nuclear\nimaging is that it clearly shows soft tissues in multi-contrasts. Compared with\nother medical image super-resolution (SR) methods that are in a single\ncontrast, multi-contrast super-resolution studies can synergize multiple\ncontrast images to achieve better super-resolution results. In this paper, we\npropose a one-level non-progressive neural network for low up-sampling\nmulti-contrast super-resolution and a two-level progressive network for high\nup-sampling multi-contrast super-resolution. Multi-contrast information is\ncombined in high-level feature space. Our experimental results demonstrate that\nthe proposed networks can produce MRI super-resolution images with good image\nquality and outperform other multi-contrast super-resolution methods in terms\nof structural similarity and peak signal-to-noise ratio. Also, the progressive\nnetwork produces a better SR image quality than the non-progressive network,\neven if the original low-resolution images were highly down-sampled.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 13:35:24 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 14:04:01 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Lyu", "Qing", ""], ["Shan", "Hongming", ""], ["Wang", "Ge", ""]]}, {"id": "1908.01613", "submitter": "Mathieu Lauri\\`ere", "authors": "Ren\\'e Carmona and Mathieu Lauri\\`ere", "title": "Convergence Analysis of Machine Learning Algorithms for the Numerical\n  Solution of Mean Field Control and Games: II -- The Finite Horizon Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two numerical methods for the optimal control of McKean-Vlasov\ndynamics in finite time horizon. Both methods are based on the introduction of\na suitable loss function defined over the parameters of a neural network. This\nallows the use of machine learning tools, and efficient implementations of\nstochastic gradient descent in order to perform the optimization. In the first\nmethod, the loss function stems directly from the optimal control problem. The\nsecond method tackles a generic forward-backward stochastic differential\nequation system (FBSDE) of McKean-Vlasov type, and relies on suitable\nreformulation as a mean field control problem. To provide a guarantee on how\nour numerical schemes approximate the solution of the original mean field\ncontrol problem, we introduce a new optimization problem, directly amenable to\nnumerical computation, and for which we rigorously provide an error rate.\nSeveral numerical examples are provided. Both methods can easily be applied to\ncertain problems with common noise, which is not the case with the existing\ntechnology. Furthermore, although the first approach is designed for mean field\ncontrol problems, the second is more general and can also be applied to the\nFBSDE arising in the theory of mean field games.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 13:38:34 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 18:02:08 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Carmona", "Ren\u00e9", ""], ["Lauri\u00e8re", "Mathieu", ""]]}, {"id": "1908.01618", "submitter": "Nusrah Hussain", "authors": "Nusrah Hussain, Engin Erzin, T. Metin Sezgin, and Yucel Yemez", "title": "Speech Driven Backchannel Generation using Deep Q-Network for Enhancing\n  Engagement in Human-Robot Interaction", "comments": "8 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for training a social robot to generate\nbackchannels during human-robot interaction. We address the problem within an\noff-policy reinforcement learning framework, and show how a robot may learn to\nproduce non-verbal backchannels like laughs, when trained to maximize the\nengagement and attention of the user. A major contribution of this work is the\nformulation of the problem as a Markov decision process (MDP) with states\ndefined by the speech activity of the user and rewards generated by quantified\nengagement levels. The problem that we address falls into the class of\napplications where unlimited interaction with the environment is not possible\n(our environment being a human) because it may be time-consuming, costly,\nimpracticable or even dangerous in case a bad policy is executed. Therefore, we\nintroduce deep Q-network (DQN) in a batch reinforcement learning framework,\nwhere an optimal policy is learned from a batch data collected using a more\ncontrolled policy. We suggest the use of human-to-human dyadic interaction\ndatasets as a batch of trajectories to train an agent for engaging\ninteractions. Our experiments demonstrate the potential of our method to train\na robot for engaging behaviors in an offline manner.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 13:47:31 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Hussain", "Nusrah", ""], ["Erzin", "Engin", ""], ["Sezgin", "T. Metin", ""], ["Yemez", "Yucel", ""]]}, {"id": "1908.01623", "submitter": "Weichang Wu", "authors": "Weichang Wu, Huanxi Liu, Xiaohu Zhang, Yu Liu, Hongyuan Zha", "title": "Modeling Event Propagation via Graph Biased Temporal Point Process", "comments": "9 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal point process is widely used for sequential data modeling. In this\npaper, we focus on the problem of modeling sequential event propagation in\ngraph, such as retweeting by social network users, news transmitting between\nwebsites, etc. Given a collection of event propagation sequences, conventional\npoint process model consider only the event history, i.e. embed event history\ninto a vector, not the latent graph structure. We propose a Graph Biased\nTemporal Point Process (GBTPP) leveraging the structural information from graph\nrepresentation learning, where the direct influence between nodes and indirect\ninfluence from event history is modeled respectively. Moreover, the learned\nnode embedding vector is also integrated into the embedded event history as\nside information. Experiments on a synthetic dataset and two real-world\ndatasets show the efficacy of our model compared to conventional methods and\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 13:53:04 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 01:23:33 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Wu", "Weichang", ""], ["Liu", "Huanxi", ""], ["Zhang", "Xiaohu", ""], ["Liu", "Yu", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1908.01642", "submitter": "Yoni Sher", "authors": "Yoni Sher", "title": "Review of Algorithms for Compressive Sensing of Images", "comments": "14 pages, 8 figures, all data available in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We provide a comprehensive review of classical algorithms for compressive\nsensing of images, focused on Total variation methods, with a view to\napplication in LiDAR systems. Our primary focus is providing a full review for\nbeginners in the field, as well as simulating the kind of noise found in real\nLiDAR systems. To this end, we provide an overview of the theoretical\nbackground, a brief discussion of various considerations that come in to play\nin compressive sensing, and a standardized comparison of off-the-shelf methods,\nintended as a quick-start guide to choosing algorithms for compressive sensing\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 14:24:57 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Sher", "Yoni", ""]]}, {"id": "1908.01656", "submitter": "Simone Disabato", "authors": "Simone Disabato, Manuel Roveri, Cesare Alippi", "title": "Distributed Deep Convolutional Neural Networks for the\n  Internet-of-Things", "comments": null, "journal-ref": "in IEEE Transactions on Computers, vol. 70, no. 8, pp. 1239-1252,\n  1 Aug. 2021", "doi": "10.1109/TC.2021.3062227", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Severe constraints on memory and computation characterizing the\nInternet-of-Things (IoT) units may prevent the execution of Deep Learning\n(DL)-based solutions, which typically demand large memory and high processing\nload. In order to support a real-time execution of the considered DL model at\nthe IoT unit level, DL solutions must be designed having in mind constraints on\nmemory and processing capability exposed by the chosen IoT technology. In this\npaper, we introduce a design methodology aiming at allocating the execution of\nConvolutional Neural Networks (CNNs) on a distributed IoT application. Such a\nmethodology is formalized as an optimization problem where the latency between\nthe data-gathering phase and the subsequent decision-making one is minimized,\nwithin the given constraints on memory and processing load at the units level.\nThe methodology supports multiple sources of data as well as multiple CNNs in\nexecution on the same IoT system allowing the design of CNN-based applications\ndemanding autonomy, low decision-latency, and high Quality-of-Service.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 12:19:52 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 18:41:23 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Disabato", "Simone", ""], ["Roveri", "Manuel", ""], ["Alippi", "Cesare", ""]]}, {"id": "1908.01667", "submitter": "Chris Finlay", "authors": "Aram-Alexandre Pooladian, Chris Finlay, Tim Hoheisel, Adam Oberman", "title": "A principled approach for generating adversarial images under non-smooth\n  dissimilarity metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks perform well on real world data but are prone to\nadversarial perturbations: small changes in the input easily lead to\nmisclassification. In this work, we propose an attack methodology not only for\ncases where the perturbations are measured by $\\ell_p$ norms, but in fact any\nadversarial dissimilarity metric with a closed proximal form. This includes,\nbut is not limited to, $\\ell_1, \\ell_2$, and $\\ell_\\infty$ perturbations; the\n$\\ell_0$ counting \"norm\" (i.e. true sparseness); and the total variation\nseminorm, which is a (non-$\\ell_p$) convolutional dissimilarity measuring local\npixel changes. Our approach is a natural extension of a recent adversarial\nattack method, and eliminates the differentiability requirement of the metric.\nWe demonstrate our algorithm, ProxLogBarrier, on the MNIST, CIFAR10, and\nImageNet-1k datasets. We consider undefended and defended models, and show that\nour algorithm easily transfers to various datasets. We observe that\nProxLogBarrier outperforms a host of modern adversarial attacks specialized for\nthe $\\ell_0$ case. Moreover, by altering images in the total variation\nseminorm, we shed light on a new class of perturbations that exploit\nneighboring pixel information.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 14:57:01 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 17:21:21 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Pooladian", "Aram-Alexandre", ""], ["Finlay", "Chris", ""], ["Hoheisel", "Tim", ""], ["Oberman", "Adam", ""]]}, {"id": "1908.01672", "submitter": "Chen Wang", "authors": "Chen Wang, Chengyuan Deng, Suzhen Wang", "title": "Imbalance-XGBoost: Leveraging Weighted and Focal Losses for Binary\n  Label-Imbalanced Classification with XGBoost", "comments": "11 pages, to be submitted to peer-reviewed journal/conference soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The paper presents Imbalance-XGBoost, a Python package that combines the\npowerful XGBoost software with weighted and focal losses to tackle binary\nlabel-imbalanced classification tasks. Though a small-scale program in terms of\nsize, the package is, to the best of the authors' knowledge, the first of its\nkind which provides an integrated implementation for the two losses on XGBoost\nand brings a general-purpose extension on XGBoost for label-imbalanced\nscenarios. In this paper, the design and usage of the package are described\nwith exemplar code listings, and its convenience to be integrated into\nPython-driven Machine Learning projects is illustrated. Furthermore, as the\nfirst- and second-order derivatives of the loss functions are essential for the\nimplementations, the algebraic derivation is discussed and it can be deemed as\na separate algorithmic contribution. The performances of the algorithms\nimplemented in the package are empirically evaluated on Parkinson's disease\nclassification data set, and multiple state-of-the-art performances have been\nobserved. Given the scalable nature of XGBoost, the package has great\npotentials to be applied to real-life binary classification tasks, which are\nusually of large-scale and label-imbalanced.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 15:01:28 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Wang", "Chen", ""], ["Deng", "Chengyuan", ""], ["Wang", "Suzhen", ""]]}, {"id": "1908.01675", "submitter": "Thomas McAndrew PhD", "authors": "Thomas McAndrew, Nicholas G. Reich", "title": "Adaptively stacking ensembles for influenza forecasting with incomplete\n  data", "comments": "V0.2 added small paragraph on BMA and acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seasonal influenza infects between 10 and 50 million people in the United\nStates every year, overburdening hospitals during weeks of peak incidence.\nNamed by the CDC as an important tool to fight the damaging effects of these\nepidemics, accurate forecasts of influenza and influenza-like illness (ILI)\nforewarn public health officials about when, and where, seasonal influenza\noutbreaks will hit hardest. Multi-model ensemble forecasts---weighted\ncombinations of component models---have shown positive results in forecasting.\nEnsemble forecasts of influenza outbreaks have been static, training on all\npast ILI data at the beginning of a season, generating a set of optimal weights\nfor each model in the ensemble, and keeping the weights constant. We propose an\nadaptive ensemble forecast that (i) changes model weights week-by-week\nthroughout the influenza season, (ii) only needs the current influenza season's\ndata to make predictions, and (iii) by introducing a prior distribution,\nshrinks weights toward the reference equal weighting approach and adjusts for\nobserved ILI percentages that are subject to future revisions. We investigate\nthe prior's ability to impact adaptive ensemble performance and, after finding\nan optimal prior via a cross-validation approach, compare our adaptive\nensemble's performance to equal-weighted and static ensembles. Applied to\nforecasts of short-term ILI incidence at the regional and national level in the\nUS, our adaptive model outperforms a naive equal-weighted ensemble, and has\nsimilar or better performance to the static ensemble, which requires multiple\nyears of training data. Adaptive ensembles are able to quickly train and\nforecast during epidemics, and provide a practical tool to public health\nofficials looking for forecasts that can conform to unique features of a\nspecific season.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 18:02:57 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 19:01:30 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["McAndrew", "Thomas", ""], ["Reich", "Nicholas G.", ""]]}, {"id": "1908.01678", "submitter": "Melih Yesilli", "authors": "Melih C. Yesilli, Firas A. Khasawneh, Andreas Otto", "title": "Chatter Detection in Turning Using Machine Learning and Similarity\n  Measures of Time Series via Dynamic Time Warping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatter detection from sensor signals has been an active field of research.\nWhile some success has been reported using several featurization tools and\nmachine learning algorithms, existing methods have several drawbacks such as\nmanual preprocessing and requiring a large data set. In this paper, we present\nan alternative approach for chatter detection based on K-Nearest Neighbor (kNN)\nalgorithm for classification and the Dynamic Time Warping (DTW) as a time\nseries similarity measure. The used time series are the acceleration signals\nacquired from the tool holder in a series of turning experiments. Our results,\nshow that this approach achieves detection accuracies that in most cases\noutperform existing methods. We compare our results to the traditional methods\nbased on Wavelet Packet Transform (WPT) and the Ensemble Empirical Mode\nDecomposition (EEMD), as well as to the more recent Topological Data Analysis\n(TDA) based approach. We show that in three out of four cutting configurations\nour DTW-based approach attains the highest average classification rate reaching\nin one case as high as 99% accuracy. Our approach does not require feature\nextraction, is capable of reusing a classifier across different cutting\nconfigurations, and it uses reasonably sized training sets. Although the\nresulting high accuracy in our approach is associated with high computational\ncost, this is specific to the DTW implementation that we used. Specifically, we\nhighlight available, very fast DTW implementations that can even be implemented\non small consumer electronics. Therefore, further code optimization and the\nsignificantly reduced computational effort during the implementation phase make\nour approach a viable option for in-process chatter detection.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 15:09:49 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Yesilli", "Melih C.", ""], ["Khasawneh", "Firas A.", ""], ["Otto", "Andreas", ""]]}, {"id": "1908.01686", "submitter": "Hari Prasanna Das", "authors": "Hari Prasanna Das, Pieter Abbeel and Costas J. Spanos", "title": "Likelihood Contribution based Multi-scale Architecture for Generative\n  Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative modeling using flows has gained popularity owing to the\ntractable exact log-likelihood estimation with efficient training and synthesis\nprocess. However, flow models suffer from the challenge of having high\ndimensional latent space, same in dimension as the input space. An effective\nsolution to the above challenge as proposed by Dinh et al. (2016) is a\nmulti-scale architecture, which is based on iterative early factorization of a\npart of the total dimensions at regular intervals. Prior works on generative\nflows involving a multi-scale architecture perform the dimension factorization\nbased on a static masking. We propose a novel multi-scale architecture that\nperforms data dependent factorization to decide which dimensions should pass\nthrough more flow layers. To facilitate the same, we introduce a heuristic\nbased on the contribution of each dimension to the total log-likelihood which\nencodes the importance of the dimensions. Our proposed heuristic is readily\nobtained as part of the flow training process, enabling versatile\nimplementation of our likelihood contribution based multi-scale architecture\nfor generic flow models. We present such an implementation for the original\nflow introduced in Dinh et al. (2016), and demonstrate improvements in\nlog-likelihood score and sampling quality on standard image benchmarks. We also\nconduct ablation studies to compare proposed method with other options for\ndimension factorization.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 15:14:18 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 06:18:38 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Das", "Hari Prasanna", ""], ["Abbeel", "Pieter", ""], ["Spanos", "Costas J.", ""]]}, {"id": "1908.01718", "submitter": "Yifei Huang", "authors": "Yifei Huang, Matt Shum, Xi Wu, Jason Zezhong Xiao", "title": "Discovery of Bias and Strategic Behavior in Crowdsourced Performance\n  Assessment", "comments": "International Workshop of Talent and Management Computing, KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the industry trend of shifting from a traditional hierarchical approach\nto flatter management structure, crowdsourced performance assessment gained\nmainstream popularity. One fundamental challenge of crowdsourced performance\nassessment is the risks that personal interest can introduce distortions of\nfacts, especially when the system is used to determine merit pay or promotion.\nIn this paper, we developed a method to identify bias and strategic behavior in\ncrowdsourced performance assessment, using a rich dataset collected from a\nprofessional service firm in China. We find a pattern of \"discriminatory\ngenerosity\" on the part of peer evaluation, where raters downgrade their peer\ncoworkers who have passed objective promotion requirements while overrating\ntheir peer coworkers who have not yet passed. This introduces two types of\nbiases: the first aimed against more competent competitors, and the other\nfavoring less eligible peers which can serve as a mask of the first bias. This\npaper also aims to bring angles of fairness-aware data mining to talent and\nmanagement computing. Historical decision records, such as performance ratings,\noften contain subjective judgment which is prone to bias and strategic\nbehavior. For practitioners of predictive talent analytics, it is important to\ninvestigate potential bias and strategic behavior underlying historical\ndecision records.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 16:51:09 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 06:13:31 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Huang", "Yifei", ""], ["Shum", "Matt", ""], ["Wu", "Xi", ""], ["Xiao", "Jason Zezhong", ""]]}, {"id": "1908.01720", "submitter": "Felipe Campelo", "authors": "Felipe Campelo, Elizabeth F. Wanner", "title": "Sample size calculations for the experimental comparison of multiple\n  algorithms on multiple problem instances", "comments": "31 pages. 7 Figures. Submitted to the Journal of Heuristics on 5\n  August 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a statistically principled method for estimating the\nrequired number of instances in the experimental comparison of multiple\nalgorithms on a given problem class of interest. This approach generalises\nearlier results by allowing researchers to design experiments based on the\ndesired best, worst, mean or median-case statistical power to detect\ndifferences between algorithms larger than a certain threshold. Holm's\nstep-down procedure is used to maintain the overall significance level\ncontrolled at desired levels, without resulting in overly conservative\nexperiments. This paper also presents an approach for sampling each algorithm\non each instance, based on optimal sample size ratios that minimise the total\nrequired number of runs subject to a desired accuracy in the estimation of\npaired differences. A case study investigating the effect of 21 variants of a\ncustom-tailored Simulated Annealing for a class of scheduling problems is used\nto illustrate the application of the proposed methods for sample size\ncalculations in the experimental comparison of algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 16:53:59 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Campelo", "Felipe", ""], ["Wanner", "Elizabeth F.", ""]]}, {"id": "1908.01748", "submitter": "Albert Shaw", "authors": "Albert Shaw, Daniel Hunter, Forrest Iandola and Sammy Sidhu", "title": "SqueezeNAS: Fast neural architecture search for faster semantic\n  segmentation", "comments": "11 pages, 10 figures, 3 tables, 3 pages of appendix; Added found\n  networks to Appendix tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For real time applications utilizing Deep Neural Networks (DNNs), it is\ncritical that the models achieve high-accuracy on the target task and\nlow-latency inference on the target computing platform. While Neural\nArchitecture Search (NAS) has been effectively used to develop low-latency\nnetworks for image classification, there has been relatively little effort to\nuse NAS to optimize DNN architectures for other vision tasks. In this work, we\npresent what we believe to be the first proxyless hardware-aware search\ntargeted for dense semantic segmentation. With this approach, we advance the\nstate-of-the-art accuracy for latency-optimized networks on the Cityscapes\nsemantic segmentation dataset. Our latency-optimized small SqueezeNAS network\nachieves 68.02% validation class mIOU with less than 35 ms inference times on\nthe NVIDIA AGX Xavier. Our latency-optimized large SqueezeNAS network achieves\n73.62% class mIOU with less than 100 ms inference times. We demonstrate that\nsignificant performance gains are possible by utilizing NAS to find networks\noptimized for both the specific task and inference hardware. We also present\ndetailed analysis comparing our networks to recent state-of-the-art\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 17:46:36 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 06:46:25 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Shaw", "Albert", ""], ["Hunter", "Daniel", ""], ["Iandola", "Forrest", ""], ["Sidhu", "Sammy", ""]]}, {"id": "1908.01753", "submitter": "Hayden Schaeffer", "authors": "Hayden Schaeffer and Scott G. McCalla", "title": "Extending the step-size restriction for gradient descent to avoid strict\n  saddle points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide larger step-size restrictions for which gradient descent based\nalgorithms (almost surely) avoid strict saddle points. In particular, consider\na twice differentiable (non-convex) objective function whose gradient has\nLipschitz constant L and whose Hessian is well-behaved. We prove that the\nprobability of initial conditions for gradient descent with step-size up to 2/L\nconverging to a strict saddle point, given one uniformly random initialization,\nis zero. This extends previous results up to the sharp limit imposed by the\nconvex case. In addition, the arguments hold in the case when a learning rate\nschedule is given, with either a continuous decaying rate or a piece-wise\nconstant schedule.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 17:50:55 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Schaeffer", "Hayden", ""], ["McCalla", "Scott G.", ""]]}, {"id": "1908.01755", "submitter": "Lesia Semenova", "authors": "Lesia Semenova, Cynthia Rudin, and Ronald Parr", "title": "A study in Rashomon curves and volumes: A new perspective on\n  generalization and model simplicity in machine learning", "comments": "Revisited sections 3, 4, 5, 6, 7, and 8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Rashomon effect occurs when many different explanations exist for the\nsame phenomenon. In machine learning, Leo Breiman used this term to\ncharacterize problems where many accurate-but-different models exist to\ndescribe the same data. In this work, we study how the Rashomon effect can be\nuseful for understanding the relationship between training and test\nperformance, and the possibility that simple-yet-accurate models exist for many\nproblems. We consider the Rashomon set - the set of almost-equally-accurate\nmodels for a given problem - and study its properties and the types of models\nit could contain. We present the Rashomon ratio as a new measure related to\nsimplicity of model classes, which is the ratio of the volume of the set of\naccurate models to the volume of the hypothesis space; the Rashomon ratio is\ndifferent from standard complexity measures from statistical learning theory.\nFor a hierarchy of hypothesis spaces, the Rashomon ratio can help modelers to\nnavigate the trade-off between simplicity and accuracy. In particular, we find\nempirically that a plot of empirical risk vs. Rashomon ratio forms a\ncharacteristic $\\Gamma$-shaped Rashomon curve, whose elbow seems to be a\nreliable model selection criterion. When the Rashomon set is large, models that\nare accurate - but that also have various other useful properties - can often\nbe obtained. These models might obey various constraints such as\ninterpretability, fairness, or monotonicity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 17:52:53 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 03:34:43 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 23:32:21 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Semenova", "Lesia", ""], ["Rudin", "Cynthia", ""], ["Parr", "Ronald", ""]]}, {"id": "1908.01760", "submitter": "V\\'it R\\r{u}\\v{z}i\\v{c}ka", "authors": "V\\'it R\\r{u}\\v{z}i\\v{c}ka, Eunsu Kang, David Gordon, Ankita Patel,\n  Jacqui Fashimpaur, Manzil Zaheer", "title": "The Myths of Our Time: Fake News", "comments": "5 pages, 5 figures, in proceedings of International Symposium on\n  Electronic Art 2019 (ISEA)", "journal-ref": "Proceedings of International Symposium on Electronic Art 2019\n  (ISEA), pages 494-498", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the purpose of most fake news is misinformation and political\npropaganda, our team sees it as a new type of myth that is created by people in\nthe age of internet identities and artificial intelligence. Seeking insights on\nthe fear and desire hidden underneath these modified or generated stories, we\nuse machine learning methods to generate fake articles and present them in the\nform of an online news blog. This paper aims to share the details of our\npipeline and the techniques used for full generation of fake news, from dataset\ncollection to presentation as a media art project on the internet.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 17:59:44 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["R\u016f\u017ei\u010dka", "V\u00edt", ""], ["Kang", "Eunsu", ""], ["Gordon", "David", ""], ["Patel", "Ankita", ""], ["Fashimpaur", "Jacqui", ""], ["Zaheer", "Manzil", ""]]}, {"id": "1908.01767", "submitter": "Suhas Gupta", "authors": "Suhas Gupta", "title": "Exploring Neural Net Augmentation to BERT for Question Answering on\n  SQUAD 2.0", "comments": "Code bug found", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enhancing machine capabilities to answer questions has been a topic of\nconsiderable focus in recent years of NLP research. Language models like\nEmbeddings from Language Models (ELMo)[1] and Bidirectional Encoder\nRepresentations from Transformers (BERT) [2] have been very successful in\ndeveloping general purpose language models that can be optimized for a large\nnumber of downstream language tasks. In this work, we focused on augmenting the\npre-trained BERT language model with different output neural net architectures\nand compared their performance on question answering task posed by the Stanford\nQuestion Answering Dataset 2.0 (SQUAD 2.0) [3]. Additionally, we also\nfine-tuned the pre-trained BERT model parameters to demonstrate its\neffectiveness in adapting to specialized language tasks. Our best output\nnetwork, is the contextualized CNN that performs on both the unanswerable and\nanswerable question answering tasks with F1 scores of 75.32 and 64.85\nrespectively.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 16:48:24 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 03:21:33 GMT"}, {"version": "v3", "created": "Sun, 8 Mar 2020 23:10:16 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Gupta", "Suhas", ""]]}, {"id": "1908.01768", "submitter": "Soheil Khorram", "authors": "Midia Yousefi, Soheil Khorram, John H.L. Hansen", "title": "Probabilistic Permutation Invariant Training for Speech Separation", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Single-microphone, speaker-independent speech separation is normally\nperformed through two steps: (i) separating the specific speech sources, and\n(ii) determining the best output-label assignment to find the separation error.\nThe second step is the main obstacle in training neural networks for speech\nseparation. Recently proposed Permutation Invariant Training (PIT) addresses\nthis problem by determining the output-label assignment which minimizes the\nseparation error. In this study, we show that a major drawback of this\ntechnique is the overconfident choice of the output-label assignment,\nespecially in the initial steps of training when the network generates\nunreliable outputs. To solve this problem, we propose Probabilistic PIT\n(Prob-PIT) which considers the output-label permutation as a discrete latent\nrandom variable with a uniform prior distribution. Prob-PIT defines a\nlog-likelihood function based on the prior distributions and the separation\nerrors of all permutations; it trains the speech separation networks by\nmaximizing the log-likelihood function. Prob-PIT can be easily implemented by\nreplacing the minimum function of PIT with a soft-minimum function. We evaluate\nour approach for speech separation on both TIMIT and CHiME datasets. The\nresults show that the proposed method significantly outperforms PIT in terms of\nSignal to Distortion Ratio and Signal to Interference Ratio.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 17:42:31 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Yousefi", "Midia", ""], ["Khorram", "Soheil", ""], ["Hansen", "John H. L.", ""]]}, {"id": "1908.01769", "submitter": "Abu Reyan Ahmed", "authors": "Sabin Devkota, Reyan Ahmed, Felice De Luca, Katherine E. Isaacs,\n  Stephen Kobourov", "title": "Stress-Plus-X (SPX) Graph Layout", "comments": "25 pages, 12 figures, accepted in the 27th International Symposium on\n  Graph Drawing and Network Visualization (GD 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stress, edge crossings, and crossing angles play an important role in the\nquality and readability of graph drawings. Most standard graph drawing\nalgorithms optimize one of these criteria which may lead to layouts that are\ndeficient in other criteria. We introduce an optimization framework,\nStress-Plus-X (SPX), that simultaneously optimizes stress together with several\nother criteria: edge crossings, minimum crossing angle, and upwardness (for\ndirected acyclic graphs). SPX achieves results that are close to the\nstate-of-the-art algorithms that optimize these metrics individually. SPX is\nflexible and extensible and can optimize a subset or all of these criteria\nsimultaneously. Our experimental analysis shows that our joint optimization\napproach is successful in drawing graphs with good performance across\nreadability criteria.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 22:31:02 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 03:32:21 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2019 22:39:49 GMT"}, {"version": "v4", "created": "Mon, 19 Aug 2019 22:31:37 GMT"}, {"version": "v5", "created": "Fri, 23 Aug 2019 17:13:17 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Devkota", "Sabin", ""], ["Ahmed", "Reyan", ""], ["De Luca", "Felice", ""], ["Isaacs", "Katherine E.", ""], ["Kobourov", "Stephen", ""]]}, {"id": "1908.01786", "submitter": "Eric Bradford", "authors": "E. Bradford, L. Imsland, D. Zhang, E. A. del Rio-Chanona", "title": "Stochastic data-driven model predictive control using Gaussian processes", "comments": "26 pages, 12 figures, 3 tables", "journal-ref": "Computers & Chemical Engineering, Volume 139, 106844 (2020)", "doi": "10.1016/j.compchemeng.2020.106844", "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear model predictive control (NMPC) is one of the few control methods\nthat can handle multivariable nonlinear controlsystems with constraints.\nGaussian processes (GPs) present a powerful tool to identify the required plant\nmodel and quantifythe residual uncertainty of the plant-model mismatch. It is\ncrucial to consider this uncertainty, since it may lead to worsecontrol\nperformance and constraint violations. In this paper we propose a new method to\ndesign a GP-based NMPC algorithmfor finite horizon control problems. The method\ngenerates Monte Carlo samples of the GP offline for constraint tighteningusing\nback-offs. The tightened constraints then guarantee the satisfaction of chance\nconstraints online. Advantages of our proposed approach over existing methods\ninclude fast online evaluation, consideration of closed-loop behaviour, and\nthepossibility to alleviate conservativeness by considering both online\nlearning and state dependency of the uncertainty. The algorithm is verified on\na challenging semi-batch bioprocess case study.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:06:23 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 10:40:37 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Bradford", "E.", ""], ["Imsland", "L.", ""], ["Zhang", "D.", ""], ["del Rio-Chanona", "E. A.", ""]]}, {"id": "1908.01790", "submitter": "Veeru Talreja", "authors": "Veeru Talreja, Fariborz Taherkhani, Matthew C Valenti, Nasser M\n  Nasrabadi", "title": "Attribute-Guided Coupled GAN for Cross-Resolution Face Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel attribute-guided cross-resolution\n(low-resolution to high-resolution) face recognition framework that leverages a\ncoupled generative adversarial network (GAN) structure with adversarial\ntraining to find the hidden relationship between the low-resolution and\nhigh-resolution images in a latent common embedding subspace. The coupled GAN\nframework consists of two sub-networks, one dedicated to the low-resolution\ndomain and the other dedicated to the high-resolution domain. Each sub-network\naims to find a projection that maximizes the pair-wise correlation between the\ntwo feature domains in a common embedding subspace. In addition to projecting\nthe images into a common subspace, the coupled network also predicts facial\nattributes to improve the cross-resolution face recognition. Specifically, our\nproposed coupled framework exploits facial attributes to further maximize the\npair-wise correlation by implicitly matching facial attributes of the low and\nhigh-resolution images during the training, which leads to a more\ndiscriminative embedding subspace resulting in performance enhancement for\ncross-resolution face recognition. The efficacy of our approach compared with\nthe state-of-the-art is demonstrated using the LFWA, Celeb-A, SCFace and UCCS\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:10:55 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Talreja", "Veeru", ""], ["Taherkhani", "Fariborz", ""], ["Valenti", "Matthew C", ""], ["Nasrabadi", "Nasser M", ""]]}, {"id": "1908.01794", "submitter": "Ran Zhao", "authors": "Qidi Peng, Nan Rao, Ran Zhao", "title": "Some Developments in Clustering Analysis on Stochastic Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some developments on clustering stochastic processes and come with\nthe conclusion that asymptotically consistent clustering algorithms can be\nobtained when the processes are ergodic and the dissimilarity measure satisfies\nthe triangle inequality. Examples are provided when the processes are\ndistribution ergodic, covariance ergodic and locally asymptotically\nself-similar, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:16:36 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Peng", "Qidi", ""], ["Rao", "Nan", ""], ["Zhao", "Ran", ""]]}, {"id": "1908.01801", "submitter": "Kushal Kafle", "authors": "Kushal Kafle, Robik Shrestha, Brian Price, Scott Cohen, Christopher\n  Kanan", "title": "Answering Questions about Data Visualizations using Efficient Bimodal\n  Fusion", "comments": "Presented at WACV, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chart question answering (CQA) is a newly proposed visual question answering\n(VQA) task where an algorithm must answer questions about data visualizations,\ne.g. bar charts, pie charts, and line graphs. CQA requires capabilities that\nnatural-image VQA algorithms lack: fine-grained measurements, optical character\nrecognition, and handling out-of-vocabulary words in both questions and\nanswers. Without modifications, state-of-the-art VQA algorithms perform poorly\non this task. Here, we propose a novel CQA algorithm called parallel recurrent\nfusion of image and language (PReFIL). PReFIL first learns bimodal embeddings\nby fusing question and image features and then intelligently aggregates these\nlearned embeddings to answer the given question. Despite its simplicity, PReFIL\ngreatly surpasses state-of-the art systems and human baselines on both the\nFigureQA and DVQA datasets. Additionally, we demonstrate that PReFIL can be\nused to reconstruct tables by asking a series of questions about a chart.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:47:30 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 15:10:29 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Kafle", "Kushal", ""], ["Shrestha", "Robik", ""], ["Price", "Brian", ""], ["Cohen", "Scott", ""], ["Kanan", "Christopher", ""]]}, {"id": "1908.01815", "submitter": "Taha Shangipour Ataei", "authors": "Taha Shangipour Ataei, Kamyar Darvishi, Soroush Javdan, Behrouz\n  Minaei-Bidgoli, Sauleh Eetemadi", "title": "Pars-ABSA: an Aspect-based Sentiment Analysis dataset for Persian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increased availability of online reviews, sentiment analysis had\nbeen witnessed a booming interest from the researchers. Sentiment analysis is a\ncomputational treatment of sentiment used to extract and understand the\nopinions of authors. While many systems were built to predict the sentiment of\na document or a sentence, many others provide the necessary detail on various\naspects of the entity (i.e. aspect-based sentiment analysis). Most of the\navailable data resources were tailored to English and the other popular\nEuropean languages. Although Persian is a language with more than 110 million\nspeakers, to the best of our knowledge, there is a lack of public dataset on\naspect-based sentiment analysis for Persian. This paper provides a manually\nannotated Persian dataset, Pars-ABSA, which is verified by 3 native Persian\nspeakers. The dataset consists of 5,114 positive, 3,061 negative and 1,827\nneutral data samples from 5,602 unique reviews. Moreover, as a baseline, this\npaper reports the performance of some state-of-the-art aspect-based sentiment\nanalysis methods with a focus on deep learning, on Pars-ABSA. The obtained\nresults are impressive compared to similar English state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 16:19:07 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 08:09:31 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 14:35:42 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Ataei", "Taha Shangipour", ""], ["Darvishi", "Kamyar", ""], ["Javdan", "Soroush", ""], ["Minaei-Bidgoli", "Behrouz", ""], ["Eetemadi", "Sauleh", ""]]}, {"id": "1908.01816", "submitter": "Boyuan Pan", "authors": "Boyuan Pan, Yazheng Yang, Hao Li, Zhou Zhao, Yueting Zhuang, Deng Cai,\n  Xiaofei He", "title": "MacNet: Transferring Knowledge from Machine Comprehension to\n  Sequence-to-Sequence Models", "comments": "Accepted In NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Comprehension (MC) is one of the core problems in natural language\nprocessing, requiring both understanding of the natural language and knowledge\nabout the world. Rapid progress has been made since the release of several\nbenchmark datasets, and recently the state-of-the-art models even surpass human\nperformance on the well-known SQuAD evaluation. In this paper, we transfer\nknowledge learned from machine comprehension to the sequence-to-sequence tasks\nto deepen the understanding of the text. We propose MacNet: a novel\nencoder-decoder supplementary architecture to the widely used attention-based\nsequence-to-sequence models. Experiments on neural machine translation (NMT)\nand abstractive text summarization show that our proposed framework can\nsignificantly improve the performance of the baseline models, and our method\nfor the abstractive text summarization achieves the state-of-the-art results on\nthe Gigaword dataset.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:38:09 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Pan", "Boyuan", ""], ["Yang", "Yazheng", ""], ["Li", "Hao", ""], ["Zhao", "Zhou", ""], ["Zhuang", "Yueting", ""], ["Cai", "Deng", ""], ["He", "Xiaofei", ""]]}, {"id": "1908.01817", "submitter": "Naomi Saphra", "authors": "Naomi Saphra, Adam Lopez", "title": "Sparsity Emerges Naturally in Neural Language Models", "comments": "Published in the ICML 2019 Workshop on Identifying and Understanding\n  Deep Learning Phenomena: https://openreview.net/forum?id=H1ets1h56E", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Concerns about interpretability, computational resources, and principled\ninductive priors have motivated efforts to engineer sparse neural models for\nNLP tasks. If sparsity is important for NLP, might well-trained neural models\nnaturally become roughly sparse? Using the Taxi-Euclidean norm to measure\nsparsity, we find that frequent input words are associated with concentrated or\nsparse activations, while frequent target words are associated with dispersed\nactivations but concentrated gradients. We find that gradients associated with\nfunction words are more concentrated than the gradients of content words, even\ncontrolling for word frequency.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:06:15 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Saphra", "Naomi", ""], ["Lopez", "Adam", ""]]}, {"id": "1908.01819", "submitter": "Andrea Zugarini", "authors": "Giuseppe Marra and Andrea Zugarini and Stefano Melacci and Marco\n  Maggini", "title": "An Unsupervised Character-Aware Neural Approach to Word and Context\n  Representation Learning", "comments": null, "journal-ref": "Lecture Notes in Computer Science, vol 11141. Springer, Cham 2018", "doi": "10.1007/978-3-030-01424-7_13", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, neural networks have been intensively used to develop\nmeaningful distributed representations of words and contexts around them. When\nthese representations, also known as \"embeddings\", are learned from\nunsupervised large corpora, they can be transferred to different tasks with\npositive effects in terms of performances, especially when only a few\nsupervisions are available. In this work, we further extend this concept, and\nwe present an unsupervised neural architecture that jointly learns word and\ncontext embeddings, processing words as sequences of characters. This allows\nour model to spot the regularities that are due to the word morphology, and to\navoid the need of a fixed-sized input vocabulary of words. We show that we can\nlearn compact encoders that, despite the relatively small number of parameters,\nreach high-level performances in downstream tasks, comparing them with related\nstate-of-the-art approaches or with fully supervised methods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 09:34:11 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Marra", "Giuseppe", ""], ["Zugarini", "Andrea", ""], ["Melacci", "Stefano", ""], ["Maggini", "Marco", ""]]}, {"id": "1908.01821", "submitter": "Ozan \\.Irsoy", "authors": "Ozan \\.Irsoy, Rakesh Gosangi, Haimin Zhang, Mu-Hsin Wei, Peter Lund,\n  Duccio Pappadopulo, Brendan Fahy, Neophytos Nephytou, Camilo Ortiz", "title": "Dialogue Act Classification in Group Chats with DAG-LSTMs", "comments": "Appeared in SIGIR 2019 Workshop on Conversational Interaction Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue act (DA) classification has been studied for the past two decades\nand has several key applications such as workflow automation and conversation\nanalytics. Researchers have used, to address this problem, various traditional\nmachine learning models, and more recently deep neural network models such as\nhierarchical convolutional neural networks (CNNs) and long short-term memory\n(LSTM) networks. In this paper, we introduce a new model architecture,\ndirected-acyclic-graph LSTM (DAG-LSTM) for DA classification. A DAG-LSTM\nexploits the turn-taking structure naturally present in a multi-party\nconversation, and encodes this relation in its model structure. Using the STAC\ncorpus, we show that the proposed method performs roughly 0.8% better in\naccuracy and 1.2% better in macro-F1 score when compared to existing methods.\nThe proposed method is generic and not limited to conversation applications.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 17:12:38 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["\u0130rsoy", "Ozan", ""], ["Gosangi", "Rakesh", ""], ["Zhang", "Haimin", ""], ["Wei", "Mu-Hsin", ""], ["Lund", "Peter", ""], ["Pappadopulo", "Duccio", ""], ["Fahy", "Brendan", ""], ["Nephytou", "Neophytos", ""], ["Ortiz", "Camilo", ""]]}, {"id": "1908.01832", "submitter": "Bilge Sipal", "authors": "Bilge Sipal, Ozcan Sari, Asena Teke, Nurullah Demirci", "title": "Word Sense Disambiguation using Diffusion Kernel PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major problems in natural language processing (NLP) is the word\nsense disambiguation (WSD) problem. It is the task of computationally\nidentifying the right sense of a polysemous word based on its context.\nResolving the WSD problem boosts the accuracy of many NLP focused algorithms\nsuch as text classification and machine translation. In this paper, we\nintroduce a new supervised algorithm for WSD, that is based on Kernel PCA and\nSemantic Diffusion Kernel, which is called Diffusion Kernel PCA (DKPCA). DKPCA\ngrasps the semantic similarities within terms, and it is based on PCA. These\nproperties enable us to perform feature extraction and dimension reduction\nguided by semantic similarities and within the algorithm. Our empirical results\non SensEval data demonstrate that DKPCA achieves higher or very close accuracy\nresults compared to SVM and KPCA with various well-known kernels when the\nlabeled data ratio is meager. Considering the scarcity of labeled data, whereas\nlarge quantities of unlabeled textual data are easily accessible, these are\nhighly encouraging first results to develop DKPCA further.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 07:16:55 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Sipal", "Bilge", ""], ["Sari", "Ozcan", ""], ["Teke", "Asena", ""], ["Demirci", "Nurullah", ""]]}, {"id": "1908.01837", "submitter": "Chenwei Zhang", "authors": "Chenwei Zhang", "title": "Structured Knowledge Discovery from Massive Text Corpus", "comments": "PhD Thesis, University of Illinois at Chicago, July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the booming development of the Internet, people benefit from\nits convenience due to its open and sharing nature. A large volume of natural\nlanguage texts is being generated by users in various forms, such as search\nqueries, documents, and social media posts. As the unstructured text corpus is\nusually noisy and messy, it becomes imperative to correctly identify and\naccurately annotate structured information in order to obtain meaningful\ninsights or better understand unstructured texts. On the other hand, the\nexisting structured information, which embodies our knowledge such as entity or\nconcept relations, often suffers from incompleteness or quality-related issues.\nGiven a gigantic collection of texts which offers rich semantic information, it\nis also important to harness the massiveness of the unannotated text corpus to\nexpand and refine existing structured knowledge with fewer annotation efforts.\n  In this dissertation, I will introduce principles, models, and algorithms for\neffective structured knowledge discovery from the massive text corpus. We are\ngenerally interested in obtaining insights and better understanding\nunstructured texts with the help of structured annotations or by\nstructure-aware modeling. Also, given the existing structured knowledge, we are\ninterested in expanding its scale and improving its quality harnessing the\nmassiveness of the text corpus. In particular, four problems are studied in\nthis dissertation: Structured Intent Detection for Natural Language\nUnderstanding, Structure-aware Natural Language Modeling, Generative Structured\nKnowledge Expansion, and Synonym Refinement on Structured Knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 20:45:41 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Zhang", "Chenwei", ""]]}, {"id": "1908.01839", "submitter": "Ping Wang", "authors": "Ping Wang, Tian Shi, Chandan K. Reddy", "title": "Text-to-SQL Generation for Question Answering on Electronic Medical\n  Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic medical records (EMR) contain comprehensive patient information\nand are typically stored in a relational database with multiple tables.\nEffective and efficient patient information retrieval from EMR data is a\nchallenging task for medical experts. Question-to-SQL generation methods tackle\nthis problem by first predicting the SQL query for a given question about a\ndatabase, and then, executing the query on the database. However, most of the\nexisting approaches have not been adapted to the healthcare domain due to a\nlack of healthcare Question-to-SQL dataset for learning models specific to this\ndomain. In addition, wide use of the abbreviation of terminologies and possible\ntypos in questions introduce additional challenges for accurately generating\nthe corresponding SQL queries. In this paper, we tackle these challenges by\ndeveloping a deep learning based TRanslate-Edit Model for Question-to-SQL\n(TREQS) generation, which adapts the widely used sequence-to-sequence model to\ndirectly generate the SQL query for a given question, and further performs the\nrequired edits using an attentive-copying mechanism and task-specific look-up\ntables. Based on the widely used publicly available electronic medical\ndatabase, we create a new large-scale Question-SQL pair dataset, named\nMIMICSQL, in order to perform the Question-to-SQL generation task in healthcare\ndomain. An extensive set of experiments are conducted to evaluate the\nperformance of our proposed model on MIMICSQL. Both quantitative and\nqualitative experimental results indicate the flexibility and efficiency of our\nproposed method in predicting condition values and its robustness to random\nquestions with abbreviations and typos.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 21:04:05 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 04:20:44 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Wang", "Ping", ""], ["Shi", "Tian", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1908.01841", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi and Erik T. Mueller", "title": "DLGNet: A Transformer-based Model for Dialogue Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Neural dialogue models, despite their successes, still suffer from lack of\nrelevance, diversity, and in many cases coherence in their generated responses.\nThese issues can attributed to reasons including (1) short-range model\narchitectures that capture limited temporal dependencies, (2) limitations of\nthe maximum likelihood training objective, (3) the concave entropy profile of\ndialogue datasets resulting in short and generic responses, and (4) the\nout-of-vocabulary problem leading to generation of a large number of <UNK>\ntokens. On the other hand, transformer-based models such as GPT-2 have\ndemonstrated an excellent ability to capture long-range structures in language\nmodeling tasks. In this paper, we present DLGNet, a transformer-based model for\ndialogue modeling. We specifically examine the use of DLGNet for multi-turn\ndialogue response generation. In our experiments, we evaluate DLGNet on the\nopen-domain Movie Triples dataset and the closed-domain Ubuntu Dialogue\ndataset. DLGNet models, although trained with only the maximum likelihood\nobjective, achieve significant improvements over state-of-the-art multi-turn\ndialogue models. They also produce best performance to date on the two datasets\nbased on several metrics, including BLEU, ROUGE, and distinct n-gram. Our\nanalysis shows that the performance improvement is mostly due to the\ncombination of (1) the long-range transformer architecture with (2) the\ninjection of random informative paddings. Other contributing factors include\nthe joint modeling of dialogue context and response, and the 100% tokenization\ncoverage from the byte pair encoding (BPE).\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 21:53:09 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 23:08:10 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Mueller", "Erik T.", ""]]}, {"id": "1908.01842", "submitter": "Minshuo Chen", "authors": "Minshuo Chen, Haoming Jiang, Wenjing Liao, Tuo Zhao", "title": "Nonparametric Regression on Low-Dimensional Manifolds using Deep ReLU\n  Networks : Function Approximation and Statistical Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world data often exhibit low-dimensional geometric structures, and can\nbe viewed as samples near a low-dimensional manifold. This paper studies\nnonparametric regression of H\\\"{o}lder functions on low-dimensional manifolds\nusing deep ReLU networks. Suppose $n$ training data are sampled from a\nH\\\"{o}lder function in $\\mathcal{H}^{s,\\alpha}$ supported on a $d$-dimensional\nRiemannian manifold isometrically embedded in $\\mathbb{R}^D$, with sub-gaussian\nnoise. A deep ReLU network architecture is designed to estimate the underlying\nfunction from the training data. The mean squared error of the empirical\nestimator is proved to converge in the order of\n$n^{-\\frac{2(s+\\alpha)}{2(s+\\alpha) + d}}\\log^3 n$. This result shows that deep\nReLU networks give rise to a fast convergence rate depending on the data\nintrinsic dimension $d$, which is usually much smaller than the ambient\ndimension $D$. It therefore demonstrates the adaptivity of deep ReLU networks\nto low-dimensional geometric structures of data, and partially explains the\npower of deep ReLU networks in tackling high-dimensional data with\nlow-dimensional geometric structures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 20:22:29 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 19:44:12 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2020 19:39:43 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 04:07:11 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Chen", "Minshuo", ""], ["Jiang", "Haoming", ""], ["Liao", "Wenjing", ""], ["Zhao", "Tuo", ""]]}, {"id": "1908.01843", "submitter": "Jie Zhou", "authors": "Jie Zhou, Xu Han, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li,\n  Maosong Sun", "title": "GEAR: Graph-based Evidence Aggregating and Reasoning for Fact\n  Verification", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact verification (FV) is a challenging task which requires to retrieve\nrelevant evidence from plain text and use the evidence to verify given claims.\nMany claims require to simultaneously integrate and reason over several pieces\nof evidence for verification. However, previous work employs simple models to\nextract information from evidence without letting evidence communicate with\neach other, e.g., merely concatenate the evidence for processing. Therefore,\nthese methods are unable to grasp sufficient relational and logical information\namong the evidence. To alleviate this issue, we propose a graph-based evidence\naggregating and reasoning (GEAR) framework which enables information to\ntransfer on a fully-connected evidence graph and then utilizes different\naggregators to collect multi-evidence information. We further employ BERT, an\neffective pre-trained language representation model, to improve the\nperformance. Experimental results on a large-scale benchmark dataset FEVER have\ndemonstrated that GEAR could leverage multi-evidence information for FV and\nthus achieves the promising result with a test FEVER score of 67.10%. Our code\nis available at https://github.com/thunlp/GEAR.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 08:25:16 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Zhou", "Jie", ""], ["Han", "Xu", ""], ["Yang", "Cheng", ""], ["Liu", "Zhiyuan", ""], ["Wang", "Lifeng", ""], ["Li", "Changcheng", ""], ["Sun", "Maosong", ""]]}, {"id": "1908.01851", "submitter": "Sangchul Hahn", "authors": "Sangchul Hahn and Heeyoul Choi", "title": "Self-Knowledge Distillation in Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since deep learning became a key player in natural language processing (NLP),\nmany deep learning models have been showing remarkable performances in a\nvariety of NLP tasks, and in some cases, they are even outperforming humans.\nSuch high performance can be explained by efficient knowledge representation of\ndeep learning models. While many methods have been proposed to learn more\nefficient representation, knowledge distillation from pretrained deep networks\nsuggest that we can use more information from the soft target probability to\ntrain other neural networks. In this paper, we propose a new knowledge\ndistillation method self-knowledge distillation, based on the soft target\nprobabilities of the training model itself, where multimode information is\ndistilled from the word embedding space right below the softmax layer. Due to\nthe time complexity, our method approximates the soft target probabilities. In\nexperiments, we applied the proposed method to two different and fundamental\nNLP tasks: language model and neural machine translation. The experiment\nresults show that our proposed method improves performance on the tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 15:17:27 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Hahn", "Sangchul", ""], ["Choi", "Heeyoul", ""]]}, {"id": "1908.01853", "submitter": "Kun Han", "authors": "Kun Han, Junwen Chen, Hui Zhang, Haiyang Xu, Yiping Peng, Yun Wang,\n  Ning Ding, Hui Deng, Yonghu Gao, Tingwei Guo, Yi Zhang, Yahao He, Baochang\n  Ma, Yulong Zhou, Kangli Zhang, Chao Liu, Ying Lyu, Chenxi Wang, Cheng Gong,\n  Yunbo Wang, Wei Zou, Hui Song, and Xiangang Li", "title": "DELTA: A DEep learning based Language Technology plAtform", "comments": "White paper for an open source library:\n  https://github.com/didi/delta. 13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present DELTA, a deep learning based language technology\nplatform. DELTA is an end-to-end platform designed to solve industry level\nnatural language and speech processing problems. It integrates most popular\nneural network models for training as well as comprehensive deployment tools\nfor production. DELTA aims to provide easy and fast experiences for using,\ndeploying, and developing natural language processing and speech models for\nboth academia and industry use cases. We demonstrate the reliable performance\nwith DELTA on several natural language processing and speech tasks, including\ntext classification, named entity recognition, natural language inference,\nspeech recognition, speaker verification, etc. DELTA has been used for\ndeveloping several state-of-the-art algorithms for publications and delivering\nreal production to serve millions of users.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 01:13:50 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Han", "Kun", ""], ["Chen", "Junwen", ""], ["Zhang", "Hui", ""], ["Xu", "Haiyang", ""], ["Peng", "Yiping", ""], ["Wang", "Yun", ""], ["Ding", "Ning", ""], ["Deng", "Hui", ""], ["Gao", "Yonghu", ""], ["Guo", "Tingwei", ""], ["Zhang", "Yi", ""], ["He", "Yahao", ""], ["Ma", "Baochang", ""], ["Zhou", "Yulong", ""], ["Zhang", "Kangli", ""], ["Liu", "Chao", ""], ["Lyu", "Ying", ""], ["Wang", "Chenxi", ""], ["Gong", "Cheng", ""], ["Wang", "Yunbo", ""], ["Zou", "Wei", ""], ["Song", "Hui", ""], ["Li", "Xiangang", ""]]}, {"id": "1908.01866", "submitter": "Peter He", "authors": "Peter He, Gerard Glowacki, Alexis Gkantiragas", "title": "Unsupervised Representations of Pollen in Bright-Field Microscopy", "comments": "Accepted at the Workshop on Computational Biology at the\n  International Conference on Machine Learning (ICML) in Long Beach, CA, USA on\n  June 14, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first unsupervised deep learning method for pollen analysis\nusing bright-field microscopy. Using a modest dataset of 650 images of pollen\ngrains collected from honey, we achieve family level identification of pollen.\nWe embed images of pollen grains into a low-dimensional latent space and\ncompare Euclidean and Riemannian metrics on these spaces for clustering. We\npropose this system for automated analysis of pollen and other microscopic\nbiological structures which have only small or unlabelled datasets available.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:29:51 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["He", "Peter", ""], ["Glowacki", "Gerard", ""], ["Gkantiragas", "Alexis", ""]]}, {"id": "1908.01872", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu and Zhenhua Guo and Jane You and B.V.K Vijaya Kumar", "title": "Attention Control with Metric Learning Alignment for Image Set-based\n  Recognition", "comments": "Accepted to IEEE T-IFS (Extension of ECCV 2018 paper:\n  Dependency-aware Attention Control for Unconstrained Face Recognition with\n  Image Sets). arXiv admin note: substantial text overlap with\n  arXiv:1907.03030; text overlap with arXiv:1707.00130 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of image set-based face verification and\nidentification. Unlike traditional single sample (an image or a video) setting,\nthis situation assumes the availability of a set of heterogeneous collection of\norderless images and videos. The samples can be taken at different check\npoints, different identity documents $etc$. The importance of each image is\nusually considered either equal or based on a quality assessment of that image\nindependent of other images and/or videos in that image set. How to model the\nrelationship of orderless images within a set remains a challenge. We address\nthis problem by formulating it as a Markov Decision Process (MDP) in a latent\nspace. Specifically, we first propose a dependency-aware attention control\n(DAC) network, which uses actor-critic reinforcement learning for attention\ndecision of each image to exploit the correlations among the unordered images.\nAn off-policy experience replay is introduced to speed up the learning process.\nMoreover, the DAC is combined with a temporal model for videos using divide and\nconquer strategies. We also introduce a pose-guided representation (PGR) scheme\nthat can further boost the performance at extreme poses. We propose a\nparameter-free PGR without the need for training as well as a novel metric\nlearning-based PGR for pose alignment without the need for pose detection in\ntesting stage. Extensive evaluations on IJB-A/B/C, YTF, Celebrity-1000 datasets\ndemonstrate that our method outperforms many state-of-art approaches on the\nset-based as well as video-based face recognition databases.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:48:05 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Guo", "Zhenhua", ""], ["You", "Jane", ""], ["Kumar", "B. V. K Vijaya", ""]]}, {"id": "1908.01874", "submitter": "Arip Asadulaev", "authors": "Arip Asadulaev", "title": "Backronym", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Machine Learning research is divided into subject areas, where\neach area tries to solve a specific problem, using specific methods. In recent\nyears, borders have almost been erased, and many areas inherit methods from\nother areas. This trend leads to better results and the number of papers in the\nfield is growing every year. The problem is that the amount of information is\nalso growing, and many methods remain unknown in a large number of papers. In\nthis work, we propose the concept of inheritance between machine learning\nmodels, which allows conducting research, processing much less information, and\npay attention to previously unnoticed models. We hope that this project will\nallow researchers to find ways to improve their ideas. In addition, it can be\nused by researchers to publish their methods too. Project is available by link:\nhttps://www.infornopolitan.xyz/backronym\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:53:07 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 15:59:57 GMT"}, {"version": "v3", "created": "Thu, 8 Aug 2019 14:56:01 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Asadulaev", "Arip", ""]]}, {"id": "1908.01875", "submitter": "Matteo Foglio", "authors": "Matteo Foglio, Lorenzo Semeria, Guido Muscioni, Riccardo Pressiani,\n  Tanya Berger-Wolf", "title": "Animal Wildlife Population Estimation Using Social Media Images\n  Collections", "comments": "KDD19 Workshop on Data Mining and AI for Conservation, Earth Day (5\n  August 2019), Anchorage, AL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are losing biodiversity at an unprecedented scale and in many cases, we do\nnot even know the basic data for the species. Traditional methods for wildlife\nmonitoring are inadequate. Development of new computer vision tools enables the\nuse of images as the source of information about wildlife. Social media is the\nrich source of wildlife images, which come with a huge bias, thus thwarting\ntraditional population size estimate approaches. Here, we present a new\nframework to take into account the social media bias when using this data\nsource to provide wildlife population size estimates. We show that,\nsurprisingly, this is a learnable and potentially solvable problem.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:53:32 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 16:37:38 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Foglio", "Matteo", ""], ["Semeria", "Lorenzo", ""], ["Muscioni", "Guido", ""], ["Pressiani", "Riccardo", ""], ["Berger-Wolf", "Tanya", ""]]}, {"id": "1908.01878", "submitter": "Kaichao You", "authors": "Kaichao You, Mingsheng Long, Jianmin Wang, Michael I. Jordan", "title": "How Does Learning Rate Decay Help Modern Neural Networks?", "comments": "title changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning rate decay (lrDecay) is a \\emph{de facto} technique for training\nmodern neural networks. It starts with a large learning rate and then decays it\nmultiple times. It is empirically observed to help both optimization and\ngeneralization. Common beliefs in how lrDecay works come from the optimization\nanalysis of (Stochastic) Gradient Descent: 1) an initially large learning rate\naccelerates training or helps the network escape spurious local minima; 2)\ndecaying the learning rate helps the network converge to a local minimum and\navoid oscillation. Despite the popularity of these common beliefs, experiments\nsuggest that they are insufficient in explaining the general effectiveness of\nlrDecay in training modern neural networks that are deep, wide, and nonconvex.\nWe provide another novel explanation: an initially large learning rate\nsuppresses the network from memorizing noisy data while decaying the learning\nrate improves the learning of complex patterns. The proposed explanation is\nvalidated on a carefully-constructed dataset with tractable pattern complexity.\nAnd its implication, that additional patterns learned in later stages of\nlrDecay are more complex and thus less transferable, is justified in real-world\ndatasets. We believe that this alternative explanation will shed light into the\ndesign of better training strategies for modern neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:56:41 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 06:53:59 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["You", "Kaichao", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1908.01887", "submitter": "Yusuke Urakami", "authors": "Yusuke Urakami, Alec Hodgkinson, Casey Carlin, Randall Leu, Luca\n  Rigazio, Pieter Abbeel", "title": "DoorGym: A Scalable Door Opening Environment And Baseline Agent", "comments": "Full version (Real world transfer experiments result)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to practically implement the door opening task, a policy ought to be\nrobust to a wide distribution of door types and environment settings.\nReinforcement Learning (RL) with Domain Randomization (DR) is a promising\ntechnique to enforce policy generalization, however, there are only a few\naccessible training environments that are inherently designed to train agents\nin domain randomized environments. We introduce DoorGym, an open-source door\nopening simulation framework designed to utilize domain randomization to train\na stable policy. We intend for our environment to lie at the intersection of\ndomain transfer, practical tasks, and realism. We also provide baseline\nProximal Policy Optimization and Soft Actor-Critic implementations, which\nachieves success rates between 0% up to 95% for opening various types of doors\nin this environment. Moreover, the real-world transfer experiment shows the\ntrained policy is able to work in the real world. Environment kit available\nhere: https://github.com/PSVL/DoorGym/\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 22:20:32 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 17:21:36 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 07:56:55 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Urakami", "Yusuke", ""], ["Hodgkinson", "Alec", ""], ["Carlin", "Casey", ""], ["Leu", "Randall", ""], ["Rigazio", "Luca", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1908.01901", "submitter": "Charles Delahunt", "authors": "Charles B. Delahunt, Mayoore S. Jaiswal, Matthew P. Horning, Samantha\n  Janko, Clay M. Thompson, Sourabh Kulhare, Liming Hu, Travis Ostbye, Grace\n  Yun, Roman Gebrehiwot, Benjamin K. Wilson, Earl Long, Stephane Proux,\n  Dionicia Gamboa, Peter Chiodini, Jane Carter, Mehul Dhorda, David Isaboke,\n  Bernhards Ogutu, Wellington Oyibo, Elizabeth Villasis, Kyaw Myo Tun,\n  Christine Bachman, David Bell, Courosh Mehanian", "title": "Fully-automated patient-level malaria assessment on field-prepared thin\n  blood film microscopy images, including Supplementary Information", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malaria is a life-threatening disease affecting millions. Microscopy-based\nassessment of thin blood films is a standard method to (i) determine malaria\nspecies and (ii) quantitate high-parasitemia infections. Full automation of\nmalaria microscopy by machine learning (ML) is a challenging task because\nfield-prepared slides vary widely in quality and presentation, and artifacts\noften heavily outnumber relatively rare parasites. In this work, we describe a\ncomplete, fully-automated framework for thin film malaria analysis that applies\nML methods, including convolutional neural nets (CNNs), trained on a large and\ndiverse dataset of field-prepared thin blood films. Quantitation and species\nidentification results are close to sufficiently accurate for the concrete\nneeds of drug resistance monitoring and clinical use-cases on field-prepared\nsamples. We focus our methods and our performance metrics on the field use-case\nrequirements. We discuss key issues and important metrics for the application\nof ML methods to malaria microscopy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 23:25:48 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Delahunt", "Charles B.", ""], ["Jaiswal", "Mayoore S.", ""], ["Horning", "Matthew P.", ""], ["Janko", "Samantha", ""], ["Thompson", "Clay M.", ""], ["Kulhare", "Sourabh", ""], ["Hu", "Liming", ""], ["Ostbye", "Travis", ""], ["Yun", "Grace", ""], ["Gebrehiwot", "Roman", ""], ["Wilson", "Benjamin K.", ""], ["Long", "Earl", ""], ["Proux", "Stephane", ""], ["Gamboa", "Dionicia", ""], ["Chiodini", "Peter", ""], ["Carter", "Jane", ""], ["Dhorda", "Mehul", ""], ["Isaboke", "David", ""], ["Ogutu", "Bernhards", ""], ["Oyibo", "Wellington", ""], ["Villasis", "Elizabeth", ""], ["Tun", "Kyaw Myo", ""], ["Bachman", "Christine", ""], ["Bell", "David", ""], ["Mehanian", "Courosh", ""]]}, {"id": "1908.01920", "submitter": "Andrew Bennett", "authors": "Andrew Bennett and Nathan Kallus", "title": "Policy Evaluation with Latent Confounders via Optimal Balance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating novel contextual bandit policies using logged data is crucial in\napplications where exploration is costly, such as medicine. But it usually\nrelies on the assumption of no unobserved confounders, which is bound to fail\nin practice. We study the question of policy evaluation when we instead have\nproxies for the latent confounders and develop an importance weighting method\nthat avoids fitting a latent outcome regression model. We show that unlike the\nunconfounded case no single set of weights can give unbiased evaluation for all\noutcome models, yet we propose a new algorithm that can still provably\nguarantee consistency by instead minimizing an adversarial balance objective.\nWe further develop tractable algorithms for optimizing this objective and\ndemonstrate empirically the power of our method when confounders are latent.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 01:17:57 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Bennett", "Andrew", ""], ["Kallus", "Nathan", ""]]}, {"id": "1908.01946", "submitter": "Shuyang Gao", "authors": "Shuyang Gao, Abhishek Sethi, Sanchit Agarwal, Tagyoung Chung, Dilek\n  Hakkani-Tur", "title": "Dialog State Tracking: A Neural Reading Comprehension Approach", "comments": "10 pages, to appear in Special Interest Group on Discourse and\n  Dialogue (SIGDIAL) 2019 (ORAL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog state tracking is used to estimate the current belief state of a\ndialog given all the preceding conversation. Machine reading comprehension, on\nthe other hand, focuses on building systems that read passages of text and\nanswer questions that require some understanding of passages. We formulate\ndialog state tracking as a reading comprehension task to answer the question\n$what\\ is\\ the\\ state\\ of\\ the\\ current\\ dialog?$ after reading conversational\ncontext. In contrast to traditional state tracking methods where the dialog\nstate is often predicted as a distribution over a closed set of all the\npossible slot values within an ontology, our method uses a simple\nattention-based neural network to point to the slot values within the\nconversation. Experiments on MultiWOZ-2.0 cross-domain dialog dataset show that\nour simple system can obtain similar accuracies compared to the previous more\ncomplex methods. By exploiting recent advances in contextual word embeddings,\nadding a model that explicitly tracks whether a slot value should be carried\nover to the next turn, and combining our method with a traditional joint state\ntracking method that relies on closed set vocabulary, we can obtain a\njoint-goal accuracy of $47.33\\%$ on the standard test split, exceeding current\nstate-of-the-art by $11.75\\%$**.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 04:01:42 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 01:21:21 GMT"}, {"version": "v3", "created": "Thu, 15 Aug 2019 01:37:56 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Gao", "Shuyang", ""], ["Sethi", "Abhishek", ""], ["Agarwal", "Sanchit", ""], ["Chung", "Tagyoung", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1908.01968", "submitter": "Shen Li", "authors": "Shen Li, Chenhao Su, Renfen Hu, Zhengdong Lu", "title": "Self-Balanced Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is known as an effective way to reduce overfitting via preventing\nco-adaptations of units. In this paper, we theoretically prove that the\nco-adaptation problem still exists after using dropout due to the correlations\namong the inputs. Based on the proof, we further propose Self-Balanced Dropout,\na novel dropout method which uses a trainable variable to balance the influence\nof the input correlation on parameter update. We evaluate Self-Balanced Dropout\non a range of tasks with both simple and complex models. The experimental\nresults show that the mechanism can effectively solve the co-adaption problem\nto some extent and significantly improve the performance on all tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 05:57:22 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Li", "Shen", ""], ["Su", "Chenhao", ""], ["Hu", "Renfen", ""], ["Lu", "Zhengdong", ""]]}, {"id": "1908.01978", "submitter": "Binyuan Hui", "authors": "Pengfei Zhu, Binyuan Hui, Changqing Zhang, Dawei Du, Longyin Wen,\n  Qinghua Hu", "title": "Multi-view Deep Subspace Clustering Networks", "comments": "Submitted to the IEEE Transactions on Image Processing (TIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view subspace clustering aims to discover the inherent structure by\nfusing multi-view complementary information. Most existing methods first\nextract multiple types of hand-crafted features and then learn a joint affinity\nmatrix for clustering. The disadvantage lies in two aspects: 1) Multi-view\nrelations are not embedded into feature learning. 2) The end-to-end learning\nmanner of deep learning is not well used in multi-view clustering. To address\nthe above issues, we propose a novel multi-view deep subspace clustering\nnetwork (MvDSCN) by learning a multi-view self-representation matrix in an\nend-to-end manner. MvDSCN consists of two sub-networks, i.e., diversity network\n(Dnet) and universality network (Unet). A latent space is built upon deep\nconvolutional auto-encoders and a self-representation matrix is learned in the\nlatent space using a fully connected layer. Dnet learns view-specific\nself-representation matrices while Unet learns a common self-representation\nmatrix for all views. To exploit the complementarity of multi-view\nrepresentations, Hilbert Schmidt Independence Criterion (HSIC) is introduced as\na diversity regularization, which can capture the non-linear and high-order\ninter-view relations. As different views share the same label space, the\nself-representation matrices of each view are aligned to the common one by a\nuniversality regularization. Experiments on both multi-feature and\nmulti-modality learning validate the superiority of the proposed multi-view\nsubspace clustering model.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 06:44:43 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Zhu", "Pengfei", ""], ["Hui", "Binyuan", ""], ["Zhang", "Changqing", ""], ["Du", "Dawei", ""], ["Wen", "Longyin", ""], ["Hu", "Qinghua", ""]]}, {"id": "1908.02023", "submitter": "Kai Han", "authors": "Kai Han, Yunhe Wang, Yixing Xu, Chunjing Xu, Dacheng Tao, Chang Xu", "title": "Full-Stack Filters to Build Minimum Viable CNNs", "comments": "Tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) are usually over-parameterized,\nwhich cannot be easily deployed on edge devices such as mobile phones and smart\ncameras. Existing works used to decrease the number or size of requested\nconvolution filters for a minimum viable CNN on edge devices. In contrast, this\npaper introduces filters that are full-stack and can be used to generate many\nmore sub-filters. Weights of these sub-filters are inherited from full-stack\nfilters with the help of different binary masks. Orthogonal constraints are\napplied over binary masks to decrease their correlation and promote the\ndiversity of generated sub-filters. To preserve the same volume of output\nfeature maps, we can naturally reduce the number of established filters by only\nmaintaining a few full-stack filters and a set of binary masks. We also conduct\ntheoretical analysis on the memory cost and an efficient implementation is\nintroduced for the convolution of the proposed filters. Experiments on several\nbenchmark datasets and CNN models demonstrate that the proposed method is able\nto construct minimum viable convolution networks of comparable performance.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 08:55:47 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Han", "Kai", ""], ["Wang", "Yunhe", ""], ["Xu", "Yixing", ""], ["Xu", "Chunjing", ""], ["Tao", "Dacheng", ""], ["Xu", "Chang", ""]]}, {"id": "1908.02037", "submitter": "Nusrah Hussain", "authors": "Nusrah Hussain, Engin Erzin, T. Metin Sezgin, and Yucel Yemez", "title": "Batch Recurrent Q-Learning for Backchannel Generation Towards Engaging\n  Agents", "comments": "8 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:1908.01618", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to generate appropriate verbal and non-verbal backchannels by an\nagent during human-robot interaction greatly enhances the interaction\nexperience. Backchannels are particularly important in applications like\ntutoring and counseling, which require constant attention and engagement of the\nuser. We present here a method for training a robot for backchannel generation\nduring a human-robot interaction within the reinforcement learning (RL)\nframework, with the goal of maintaining high engagement level. Since online\nlearning by interaction with a human is highly time-consuming and impractical,\nwe take advantage of the recorded human-to-human dataset and approach our\nproblem as a batch reinforcement learning problem. The dataset is utilized as a\nbatch data acquired by some behavior policy. We perform experiments with laughs\nas a backchannel and train an agent with value-based techniques. In particular,\nwe demonstrate the effectiveness of recurrent layers in the approximate value\nfunction for this problem, that boosts the performance in partially observable\nenvironments. With off-policy policy evaluation, it is shown that the RL agents\nare expected to produce more engagement than an agent trained from imitation\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 09:25:51 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Hussain", "Nusrah", ""], ["Erzin", "Engin", ""], ["Sezgin", "T. Metin", ""], ["Yemez", "Yucel", ""]]}, {"id": "1908.02047", "submitter": "Xianfu Chen", "authors": "Xianfu Chen and Celimuge Wu and Tao Chen and Honggang Zhang and Zhi\n  Liu and Yan Zhang and Mehdi Bennis", "title": "Age of Information-Aware Radio Resource Management in Vehicular\n  Networks: A Proactive Deep Reinforcement Learning Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we investigate the problem of age of information (AoI)-aware\nradio resource management for expected long-term performance optimization in a\nManhattan grid vehicle-to-vehicle network. With the observation of global\nnetwork state at each scheduling slot, the roadside unit (RSU) allocates the\nfrequency bands and schedules packet transmissions for all vehicle user\nequipment-pairs (VUE-pairs). We model the stochastic decision-making procedure\nas a discrete-time single-agent Markov decision process (MDP). The technical\nchallenges in solving the optimal control policy originate from high spatial\nmobility and temporally varying traffic information arrivals of the VUE-pairs.\nTo make the problem solving tractable, we first decompose the original MDP into\na series of per-VUE-pair MDPs. Then we propose a proactive algorithm based on\nlong short-term memory and deep reinforcement learning techniques to address\nthe partial observability and the curse of high dimensionality in local network\nstate space faced by each VUE-pair. With the proposed algorithm, the RSU makes\nthe optimal frequency band allocation and packet scheduling decision at each\nscheduling slot in a decentralized way in accordance with the partial\nobservations of the global network state at the VUE-pairs. Numerical\nexperiments validate the theoretical analysis and demonstrate the significant\nperformance improvements from the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 10:06:42 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 08:59:37 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Chen", "Xianfu", ""], ["Wu", "Celimuge", ""], ["Chen", "Tao", ""], ["Zhang", "Honggang", ""], ["Liu", "Zhi", ""], ["Zhang", "Yan", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1908.02065", "submitter": "Hagen Triendl", "authors": "Matthias Bal, Hagen Triendl, Mariana Assmann, Michael Craig, Lawrence\n  Phillips, Jarvist Moore Frost, Usman Bashir, Noor Shaker and Vid Stojevic", "title": "Sparse hierarchical representation learning on molecular graphs", "comments": "4 pages, 2 figures, accepted as a DLG 2019 workshop paper at KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Architectures for sparse hierarchical representation learning have recently\nbeen proposed for graph-structured data, but so far assume the absence of edge\nfeatures in the graph. We close this gap and propose a method to pool graphs\nwith edge features, inspired by the hierarchical nature of chemistry. In\nparticular, we introduce two types of pooling layers compatible with an\nedge-feature graph-convolutional architecture and investigate their performance\nfor molecules relevant to drug discovery on a set of two classification and two\nregression benchmark datasets of MoleculeNet. We find that our models\nsignificantly outperform previous benchmarks on three of the datasets and reach\nstate-of-the-art results on the fourth benchmark, with pooling improving\nperformance for three out of four tasks, keeping performance stable on the\nfourth task, and generally speeding up the training process.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 10:36:41 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Bal", "Matthias", ""], ["Triendl", "Hagen", ""], ["Assmann", "Mariana", ""], ["Craig", "Michael", ""], ["Phillips", "Lawrence", ""], ["Frost", "Jarvist Moore", ""], ["Bashir", "Usman", ""], ["Shaker", "Noor", ""], ["Stojevic", "Vid", ""]]}, {"id": "1908.02095", "submitter": "G\\\"ozde Nur G\\\"une\\c{s}li", "authors": "Gozde Nur Gunesli, Cenk Sokmensuer, and Cigdem Gunduz-Demir", "title": "AttentionBoost: Learning What to Attend by Boosting Fully Convolutional\n  Networks", "comments": "This work has been submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense prediction models are widely used for image segmentation. One important\nchallenge is to sufficiently train these models to yield good generalizations\nfor hard-to-learn pixels. A typical group of such hard-to-learn pixels are\nboundaries between instances. Many studies have proposed to give specific\nattention to learning the boundary pixels. They include designing multi-task\nnetworks with an additional task of boundary prediction and increasing the\nweights of boundary pixels' predictions in the loss function. Such strategies\nrequire defining what to attend beforehand and incorporating this defined\nattention to the learning model. However, there may exist other groups of\nhard-to-learn pixels and manually defining and incorporating the appropriate\nattention for each group may not be feasible. In order to provide a more\nattainable and scalable solution, this paper proposes AttentionBoost, which is\na new multi-attention learning model based on adaptive boosting. AttentionBoost\ndesigns a multi-stage network and introduces a new loss adjustment mechanism\nfor a dense prediction model to adaptively learn what to attend at each stage\ndirectly on image data without necessitating any prior definition about what to\nattend. This mechanism modulates the attention of each stage to correct the\nmistakes of previous stages, by adjusting the loss weight of each pixel\nprediction separately with respect to how accurate the previous stages are on\nthis pixel. This mechanism enables AttentionBoost to learn different attentions\nfor different pixels at the same stage, according to difficulty of learning\nthese pixels, as well as multiple attentions for the same pixel at different\nstages, according to confidence of these stages on their predictions for this\npixel. Using gland segmentation as a showcase application, our experiments\ndemonstrate that AttentionBoost improves the results of its counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 12:06:12 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Gunesli", "Gozde Nur", ""], ["Sokmensuer", "Cenk", ""], ["Gunduz-Demir", "Cigdem", ""]]}, {"id": "1908.02096", "submitter": "Luca Zanetti", "authors": "Mihai Cucuringu, Huan Li, He Sun, Luca Zanetti", "title": "Hermitian matrices for clustering directed graphs: insights and\n  applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph clustering is a basic technique in machine learning, and has widespread\napplications in different domains. While spectral techniques have been\nsuccessfully applied for clustering undirected graphs, the performance of\nspectral clustering algorithms for directed graphs (digraphs) is not in general\nsatisfactory: these algorithms usually require symmetrising the matrix\nrepresenting a digraph, and typical objective functions for undirected graph\nclustering do not capture cluster-structures in which the information given by\nthe direction of the edges is crucial. To overcome these downsides, we propose\na spectral clustering algorithm based on a complex-valued matrix representation\nof digraphs. We analyse its theoretical performance on a Stochastic Block Model\nfor digraphs in which the cluster-structure is given not only by variations in\nedge densities, but also by the direction of the edges. The significance of our\nwork is highlighted on a data set pertaining to internal migration in the\nUnited States: while previous spectral clustering algorithms for digraphs can\nonly reveal that people are more likely to move between counties that are\ngeographically close, our approach is able to cluster together counties with a\nsimilar socio-economical profile even when they are geographically distant, and\nillustrates how people tend to move from rural to more urbanised areas.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 12:06:44 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Cucuringu", "Mihai", ""], ["Li", "Huan", ""], ["Sun", "He", ""], ["Zanetti", "Luca", ""]]}, {"id": "1908.02105", "submitter": "David K.E. Green", "authors": "David K. E. Green and Filip Rindler", "title": "Model inference for Ordinary Differential Equations by parametric\n  polynomial kernel regression", "comments": "23 pages, 7 figures. Submission to 3rd International Conference on\n  Uncertainty Quantification in Computational Sciences and Engineering\n  (UNCECOMP), Crete, Greece, 24-26 June 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model inference for dynamical systems aims to estimate the future behaviour\nof a system from observations. Purely model-free statistical methods, such as\nArtificial Neural Networks, tend to perform poorly for such tasks. They are\ntherefore not well suited to many questions from applications, for example in\nBayesian filtering and reliability estimation.\n  This work introduces a parametric polynomial kernel method that can be used\nfor inferring the future behaviour of Ordinary Differential Equation models,\nincluding chaotic dynamical systems, from observations. Using numerical\nintegration techniques, parametric representations of Ordinary Differential\nEquations can be learnt using Backpropagation and Stochastic Gradient Descent.\nThe polynomial technique presented here is based on a nonparametric method,\nkernel ridge regression. However, the time complexity of nonparametric kernel\nridge regression scales cubically with the number of training data points. Our\nparametric polynomial method avoids this manifestation of the curse of\ndimensionality, which becomes particularly relevant when working with large\ntime series data sets.\n  Two numerical demonstrations are presented. First, a simple regression test\ncase is used to illustrate the method and to compare the performance with\nstandard Artificial Neural Network techniques. Second, a more substantial test\ncase is the inference of a chaotic spatio-temporal dynamical system, the\nLorenz--Emanuel system, from observations. Our method was able to successfully\ntrack the future behaviour of the system over time periods much larger than the\ntraining data sampling rate. Finally, some limitations of the method are\npresented, as well as proposed directions for future work to mitigate these\nlimitations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 12:31:11 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Green", "David K. E.", ""], ["Rindler", "Filip", ""]]}, {"id": "1908.02119", "submitter": "Zulkarnaen Hatala", "authors": "Zulkarnaen Hatala", "title": "Practical Speech Recognition with HTK", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.HC cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practical aspects of developing an Automatic Speech Recognition System\n(ASR) with HTK are reviewed. Steps are explained concerning hardware, software,\nlibraries, applications and computer programs used. The common procedure to\nrapidly apply speech recognition system is summarized. The procedure is\nillustrated, to implement a speech based electrical switch in home automation\nfor the Indonesian language. The main key of the procedure is to match the\nenvironment for training and testing using the training data recorded from the\ntesting program, HVite. Often the silence detector of HTK is wrongly triggered\nby noises because the microphone is too sensitive. This problem is mitigated by\nsimply scaling down the volume. In this sub-word phone-based speech\nrecognition, noise is included in the training database and labelled\nparticularly. Illustration of the procedure is applied to a home automation\napplication. Electrical switches are controlled by Indonesian speech\nrecognizer. The results show 100% command completion rate.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 13:12:57 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Hatala", "Zulkarnaen", ""]]}, {"id": "1908.02125", "submitter": "Wei-Ting Wang", "authors": "Wei-Ting Wang, Han-Lin Li, Wei-Shiang Lin, Cheng-Ming Chiang, Yi-Min\n  Tsai", "title": "Architecture-aware Network Pruning for Vision Quality Applications", "comments": "Accepted to be Published in the 26th IEEE International Conference on\n  Image Processing (ICIP 2019). Updated to contain the IEEE copyright notice", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) delivers impressive achievements in\ncomputer vision and machine learning field. However, CNN incurs high\ncomputational complexity, especially for vision quality applications because of\nlarge image resolution. In this paper, we propose an iterative\narchitecture-aware pruning algorithm with adaptive magnitude threshold while\ncooperating with quality-metric measurement simultaneously. We show the\nperformance improvement applied on vision quality applications and provide\ncomprehensive analysis with flexible pruning configuration. With the proposed\nmethod, the Multiply-Accumulate (MAC) of state-of-the-art low-light imaging\n(SID) and super-resolution (EDSR) are reduced by 58% and 37% without quality\ndrop, respectively. The memory bandwidth (BW) requirements of convolutional\nlayer can be also reduced by 20% to 40%.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 01:54:22 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Wang", "Wei-Ting", ""], ["Li", "Han-Lin", ""], ["Lin", "Wei-Shiang", ""], ["Chiang", "Cheng-Ming", ""], ["Tsai", "Yi-Min", ""]]}, {"id": "1908.02127", "submitter": "Longteng Guo", "authors": "Longteng Guo, Jing Liu, Jinhui Tang, Jiangwei Li, Wei Luo, Hanqing Lu", "title": "Aligning Linguistic Words and Visual Semantic Units for Image Captioning", "comments": "8 pages, 5 figures. Accepted by ACM MM 2019", "journal-ref": null, "doi": "10.1145/3343031.3350943", "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning attempts to generate a sentence composed of several\nlinguistic words, which are used to describe objects, attributes, and\ninteractions in an image, denoted as visual semantic units in this paper. Based\non this view, we propose to explicitly model the object interactions in\nsemantics and geometry based on Graph Convolutional Networks (GCNs), and fully\nexploit the alignment between linguistic words and visual semantic units for\nimage captioning. Particularly, we construct a semantic graph and a geometry\ngraph, where each node corresponds to a visual semantic unit, i.e., an object,\nan attribute, or a semantic (geometrical) interaction between two objects.\nAccordingly, the semantic (geometrical) context-aware embeddings for each unit\nare obtained through the corresponding GCN learning processers. At each time\nstep, a context gated attention module takes as inputs the embeddings of the\nvisual semantic units and hierarchically align the current word with these\nunits by first deciding which type of visual semantic unit (object, attribute,\nor interaction) the current word is about, and then finding the most correlated\nvisual semantic units under this type. Extensive experiments are conducted on\nthe challenging MS-COCO image captioning dataset, and superior results are\nreported when comparing to state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 13:19:24 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Guo", "Longteng", ""], ["Liu", "Jing", ""], ["Tang", "Jinhui", ""], ["Li", "Jiangwei", ""], ["Luo", "Wei", ""], ["Lu", "Hanqing", ""]]}, {"id": "1908.02130", "submitter": "Aras Dargazany", "authors": "Aras R. Dargazany", "title": "Deep learning research landscape & roadmap in a nutshell: past, present\n  and future -- Towards deep cortical learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past, present and future of deep learning is presented in this work.\nGiven this landscape & roadmap, we predict that deep cortical learning will be\nthe convergence of deep learning & cortical learning which builds an artificial\ncortical column ultimately.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:57:38 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Dargazany", "Aras R.", ""]]}, {"id": "1908.02134", "submitter": "Hiroshi Kuwajima", "authors": "Hiroshi Kuwajima and Fuyuki Ishikawa", "title": "Adapting SQuaRE for Quality Assessment of Artificial Intelligence\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more software practitioners are tackling towards industrial\napplications of artificial intelligence (AI) systems, especially those based on\nmachine learning (ML). However, many of existing principles and approaches to\ntraditional systems do not work effectively for the system behavior obtained by\ntraining not by logical design. In addition, unique kinds of requirements are\nemerging such as fairness and explainability. To provide clear guidance to\nunderstand and tackle these difficulties, we present an analysis on what\nquality concepts we should evaluate for AI systems. We base our discussion on\nISO/IEC 25000 series, known as SQuaRE, and identify how it should be adapted\nfor the unique nature of ML and $\\textit{Ethics guidelines for trustworthy AI}$\nfrom European Commission. We thus provide holistic insights for quality of AI\nsystems by incorporating the ML nature and AI ethics to the traditional\nsoftware quality concepts.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 18:31:06 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Kuwajima", "Hiroshi", ""], ["Ishikawa", "Fuyuki", ""]]}, {"id": "1908.02138", "submitter": "Stevan Tomic", "authors": "Stevan Tomic, Federico Pecora and Alessandro Saffiotti", "title": "Robby is Not a Robber (anymore): On the Use of Institutions for Learning\n  Normative Behavior", "comments": "16 pages, 11 figures, Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future robots should follow human social norms in order to be useful and\naccepted in human society. In this paper, we leverage already existing social\nknowledge in human societies by capturing it in our framework through the\nnotion of social norms. We show how norms can be used to guide a reinforcement\nlearning agent towards achieving normative behavior and apply the same set of\nnorms over different domains. Thus, we are able to: (1) provide a way to\nintuitively encode social knowledge (through norms); (2) guide learning towards\nnormative behaviors (through an automatic norm reward system); and (3) achieve\na transfer of learning by abstracting policies; Finally, (4) the method is not\ndependent on a particular RL algorithm. We show how our approach can be seen as\na means to achieve abstract representation and learn procedural knowledge based\non the declarative semantics of norms and discuss possible implications of this\nin some areas of cognitive science.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 23:46:55 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Tomic", "Stevan", ""], ["Pecora", "Federico", ""], ["Saffiotti", "Alessandro", ""]]}, {"id": "1908.02144", "submitter": "Robert Pinsler", "authors": "Robert Pinsler, Jonathan Gordon, Eric Nalisnick, Jos\\'e Miguel\n  Hern\\'andez-Lobato", "title": "Bayesian Batch Active Learning as Sparse Subset Approximation", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging the wealth of unlabeled data produced in recent years provides\ngreat potential for improving supervised models. When the cost of acquiring\nlabels is high, probabilistic active learning methods can be used to greedily\nselect the most informative data points to be labeled. However, for many\nlarge-scale problems standard greedy procedures become computationally\ninfeasible and suffer from negligible model change. In this paper, we introduce\na novel Bayesian batch active learning approach that mitigates these issues.\nOur approach is motivated by approximating the complete data posterior of the\nmodel parameters. While naive batch construction methods result in correlated\nqueries, our algorithm produces diverse batches that enable efficient active\nlearning at scale. We derive interpretable closed-form solutions akin to\nexisting active learning procedures for linear models, and generalize to\narbitrary models using random projections. We demonstrate the benefits of our\napproach on several large-scale regression and classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 13:36:27 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 18:07:51 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 15:07:07 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 16:21:08 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Pinsler", "Robert", ""], ["Gordon", "Jonathan", ""], ["Nalisnick", "Eric", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1908.02146", "submitter": "Jinseok Lee", "authors": "Jinseok Lee, Dit-Yan Yeung", "title": "Knowledge Query Network: How Knowledge Interacts with Skills", "comments": "10 pages, Learning Analytics & Knowledge 2019", "journal-ref": "Proceedings of the 9th International Conference on Learning\n  Analytics & Knowledge Tempe, AZ, USA, March 04 - 08, 2019", "doi": "10.1145/3303772.3303786", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Tracing (KT) is to trace the knowledge of students as they solve a\nsequence of problems represented by their related skills. This involves\nabstract concepts of students' states of knowledge and the interactions between\nthose states and skills. Therefore, a KT model is designed to predict whether\nstudents will give correct answers and to describe such abstract concepts.\nHowever, existing methods either give relatively low prediction accuracy or\nfail to explain those concepts intuitively. In this paper, we propose a new\nmodel called Knowledge Query Network (KQN) to solve these problems. KQN uses\nneural networks to encode student learning activities into knowledge state and\nskill vectors, and models the interactions between the two types of vectors\nwith the dot product. Through this, we introduce a novel concept called\n\\textit{probabilistic skill similarity} that relates the pairwise cosine and\nEuclidean distances between skill vectors to the odds ratios of the\ncorresponding skills, which makes KQN interpretable and intuitive.\n  On four public datasets, we have carried out experiments to show the\nfollowing: 1. KQN outperforms all the existing KT models based on prediction\naccuracy. 2. The interaction between the knowledge state and skills can be\nvisualized for interpretation. 3. Based on probabilistic skill similarity, a\nskill domain can be analyzed with clustering using the distances between the\nskill vectors of KQN. 4. For different values of the vector space\ndimensionality, KQN consistently exhibits high prediction accuracy and a strong\npositive correlation between the distance matrices of the skill vectors.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 14:33:10 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 12:10:46 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Lee", "Jinseok", ""], ["Yeung", "Dit-Yan", ""]]}, {"id": "1908.02160", "submitter": "Jiangfan Han", "authors": "Jiangfan Han, Ping Luo, Xiaogang Wang", "title": "Deep Self-Learning From Noisy Labels", "comments": "Accepted by IEEE International Conference on Computer Vision (ICCV)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ConvNets achieve good results when training from clean data, but learning\nfrom noisy labels significantly degrades performances and remains challenging.\nUnlike previous works constrained by many conditions, making them infeasible to\nreal noisy cases, this work presents a novel deep self-learning framework to\ntrain a robust network on the real noisy datasets without extra supervision.\nThe proposed approach has several appealing benefits. (1) Different from most\nexisting work, it does not rely on any assumption on the distribution of the\nnoisy labels, making it robust to real noises. (2) It does not need extra clean\nsupervision or accessorial network to help training. (3) A self-learning\nframework is proposed to train the network in an iterative end-to-end manner,\nwhich is effective and efficient. Extensive experiments in challenging\nbenchmarks such as Clothing1M and Food101-N show that our approach outperforms\nits counterparts in all empirical settings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 13:43:58 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 08:37:35 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Han", "Jiangfan", ""], ["Luo", "Ping", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1908.02166", "submitter": "Nir Billfeld", "authors": "Nir Billfeld, Moshe Kim", "title": "Semiparametric Wavelet-based JPEG IV Estimator for endogenously\n  truncated data", "comments": "18 pages", "journal-ref": "IEEE Access, 7, 99602-99621 (2019)", "doi": "10.1109/ACCESS.2019.2929571", "report-no": null, "categories": "stat.ME cs.CV cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new and an enriched JPEG algorithm is provided for identifying redundancies\nin a sequence of irregular noisy data points which also accommodates a\nreference-free criterion function. Our main contribution is by formulating\nanalytically (instead of approximating) the inverse of the transpose of\nJPEGwavelet transform without involving matrices which are computationally\ncumbersome. The algorithm is suitable for the widely-spread situations where\nthe original data distribution is unobservable such as in cases where there is\ndeficient representation of the entire population in the training data (in\nmachine learning) and thus the covariate shift assumption is violated. The\nproposed estimator corrects for both biases, the one generated by endogenous\ntruncation and the one generated by endogenous covariates. Results from\nutilizing 2,000,000 different distribution functions verify the applicability\nand high accuracy of our procedure to cases in which the disturbances are\nneither jointly nor marginally normally distributed.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 13:54:52 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Billfeld", "Nir", ""], ["Kim", "Moshe", ""]]}, {"id": "1908.02170", "submitter": "Dennis Banga", "authors": "Dennis Banga and Peter Waiganjo", "title": "Abnormality Detection in Musculoskeletal Radiographs with Convolutional\n  Neural Networks(Ensembles) and Performance Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Musculoskeletal conditions affect more than 1.7 billion people worldwide\nbased on a study by Global Burden Disease, and they are the second greatest\ncause of disability[1,2]. The diagnosis of these conditions vary but mostly\nphysical exams carried out and image tests. There are few imaging and\ndiagnostic experts while there is a huge workload of radiograph examinations\nwhich might affect diagnostic accuracy. We built machine learning models to\nperform abnormality detection using the available musculoskeletal public\ndataset [3]. Convolutional Neural Networks (CNN) were used as are the most\nsuccessful models in performing various tasks such as classification and object\ndetection [4]. The development of the models involved theoretical study,\niterative prototyping, and empirical evaluation of the results. The current\nmodel, 169 layer DenseNet, by Pranav et al.(2018) on the abnormality detection\ntask, the performance was lower than the worst radiologist in 5 out of the 7\nstudies, and the overall model performance was lower than the best radiologist.\nWe developed the ensemble200 model which scored 0.66 Cohen Kappa which was\nlower than the DenseNet model (Pranav et al, 2018) but the model performance\nwith the F1 score outperforms the DenseNet model and its Cohen Kappa score\nvariability with the different studies is lower as the best cohen kappa score\non the upper extremity studies is 0.7408 (Wrist) and the lowest is (0.5844)\nhand. The ensemble200 model outperformed DenseNet model on the finger studies\nwith a Cohen Kappa score of 0.653 showing reduced performance variability on\nthe model performance.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 14:06:45 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Banga", "Dennis", ""], ["Waiganjo", "Peter", ""]]}, {"id": "1908.02172", "submitter": "Ke Li Kl", "authors": "Ran Wang, Suhe Ye, Ke Li and Sam Kwong", "title": "Bayesian Network Based Label Correlation Analysis For Multi-label\n  Classifier Chain", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifier chain (CC) is a multi-label learning approach that constructs a\nsequence of binary classifiers according to a label order. Each classifier in\nthe sequence is responsible for predicting the relevance of one label. When\ntraining the classifier for a label, proceeding labels will be taken as\nextended features. If the extended features are highly correlated to the label,\nthe performance will be improved, otherwise, the performance will not be\ninfluenced or even degraded. How to discover label correlation and determine\nthe label order is critical for CC approach. This paper employs Bayesian\nnetwork (BN) to model the label correlations and proposes a new BN-based CC\nmethod (BNCC). First, conditional entropy is used to describe the dependency\nrelations among labels. Then, a BN is built up by taking nodes as labels and\nweights of edges as their dependency relations. A new scoring function is\nproposed to evaluate a BN structure, and a heuristic algorithm is introduced to\noptimize the BN. At last, by applying topological sorting on the nodes of the\noptimized BN, the label order for constructing CC model is derived.\nExperimental comparisons demonstrate the feasibility and effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 14:07:18 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Wang", "Ran", ""], ["Ye", "Suhe", ""], ["Li", "Ke", ""], ["Kwong", "Sam", ""]]}, {"id": "1908.02182", "submitter": "Fabian Isensee", "authors": "Fabian Isensee and Klaus H. Maier-Hein", "title": "An attempt at beating the 3D U-Net", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The U-Net is arguably the most successful segmentation architecture in the\nmedical domain. Here we apply a 3D U-Net to the 2019 Kidney and Kidney Tumor\nSegmentation Challenge and attempt to improve upon it by augmenting it with\nresidual and pre-activation residual blocks. Cross-validation results on the\ntraining cases suggest only very minor, barely measurable improvements. Due to\nmarginally higher dice scores, the residual 3D U-Net is chosen for test set\nprediction. With a Composite Dice score of 91.23 on the test set, our method\noutperformed all 105 competing teams and won the KiTS2019 challenge by a small\nmargin.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 14:28:17 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 11:03:40 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Isensee", "Fabian", ""], ["Maier-Hein", "Klaus H.", ""]]}, {"id": "1908.02199", "submitter": "Chen Ma", "authors": "Chen Ma, Chenxu Zhao, Hailin Shi, Li Chen, Junhai Yong and Dan Zeng", "title": "MetaAdvDet: Towards Robust Detection of Evolving Adversarial Attacks", "comments": "10 pages, 2 figures, accepted as the conference paper of Proceedings\n  of the 27th ACM International Conference on Multimedia (MM'19)", "journal-ref": null, "doi": "10.1145/3343031.3350887", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial attack which is\nmaliciously implemented by adding human-imperceptible perturbation to images\nand thus leads to incorrect prediction. Existing studies have proposed various\nmethods to detect the new adversarial attacks. However, new attack methods keep\nevolving constantly and yield new adversarial examples to bypass the existing\ndetectors. It needs to collect tens of thousands samples to train detectors,\nwhile the new attacks evolve much more frequently than the high-cost data\ncollection. Thus, this situation leads the newly evolved attack samples to\nremain in small scales. To solve such few-shot problem with the evolving\nattack, we propose a meta-learning based robust detection method to detect new\nadversarial attacks with limited examples. Specifically, the learning consists\nof a double-network framework: a task-dedicated network and a master network\nwhich alternatively learn the detection capability for either seen attack or a\nnew attack. To validate the effectiveness of our approach, we construct the\nbenchmarks with few-shot-fashion protocols based on three conventional\ndatasets, i.e. CIFAR-10, MNIST and Fashion-MNIST. Comprehensive experiments are\nconducted on them to verify the superiority of our approach with respect to the\ntraditional adversarial attack detection methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 15:06:21 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Ma", "Chen", ""], ["Zhao", "Chenxu", ""], ["Shi", "Hailin", ""], ["Chen", "Li", ""], ["Yong", "Junhai", ""], ["Zeng", "Dan", ""]]}, {"id": "1908.02203", "submitter": "Sakshi Udeshi", "authors": "Sakshi Udeshi, Shanshan Peng, Gerald Woo, Lionell Loh, Louth Rawshan\n  and Sudipta Chattopadhyay", "title": "Model Agnostic Defence against Backdoor Attacks in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has automated a multitude of our day-to-day decision\nmaking domains such as education, employment and driving automation. The\ncontinued success of ML largely depends on our ability to trust the model we\nare using. Recently, a new class of attacks called Backdoor Attacks have been\ndeveloped. These attacks undermine the user's trust in ML models. In this work,\nwe present NEO, a model agnostic framework to detect and mitigate such backdoor\nattacks in image classification ML models. For a given image classification\nmodel, our approach analyses the inputs it receives and determines if the model\nis backdoored. In addition to this feature, we also mitigate these attacks by\ndetermining the correct predictions of the poisoned images. An appealing\nfeature of NEO is that it can, for the first time, isolate and reconstruct the\nbackdoor trigger. NEO is also the first defence methodology, to the best of our\nknowledge that is completely blackbox.\n  We have implemented NEO and evaluated it against three state of the art\npoisoned models. These models include highly critical applications such as\ntraffic sign detection (USTS) and facial detection. In our evaluation, we show\nthat NEO can detect $\\approx$88\\% of the poisoned inputs on average and it is\nas fast as 4.4 ms per input image. We also reconstruct the poisoned input for\nthe user to effectively test their systems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 15:11:37 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 11:24:50 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Udeshi", "Sakshi", ""], ["Peng", "Shanshan", ""], ["Woo", "Gerald", ""], ["Loh", "Lionell", ""], ["Rawshan", "Louth", ""], ["Chattopadhyay", "Sudipta", ""]]}, {"id": "1908.02233", "submitter": "Craig Bakker", "authors": "Craig Bakker, Steven Rosenthal, Kathleen E. Nowak", "title": "Koopman Representations of Dynamic Systems with Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design and analysis of optimal control policies for dynamical systems can\nbe complicated by nonlinear dependence in the state variables. Koopman\noperators have been used to simplify the analysis of dynamical systems by\nmapping the flow of the system onto a space of observables where the dynamics\nare linear (and possibly infinte). This paper focuses on the development of\nconsistent Koopman representations for controlled dynamical system. We\nintroduce the concept of dynamical consistency for Koopman representations and\nanalyze several existing and proposed representations deriving necessary\nconstraints on the dynamical system, observables, and Koopman operators. Our\nmain result is a hybrid formulation which independently and jointly observes\nthe state and control inputs. This formulation admits a relatively large space\nof dynamical systems compared to earlier formulations while keeping the Koopman\noperator independent of the state and control inputs. More generally, this work\nprovides an analysis framework to evaluate and rank proposed simplifications to\nthe general Koopman representation for controlled dynamical systems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 16:16:21 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Bakker", "Craig", ""], ["Rosenthal", "Steven", ""], ["Nowak", "Kathleen E.", ""]]}, {"id": "1908.02246", "submitter": "Ping Li", "authors": "Xiao-Tong Yuan and Ping Li", "title": "On Convergence of Distributed Approximate Newton Methods: Globalization,\n  Sharper Bounds and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DANE algorithm is an approximate Newton method popularly used for\ncommunication-efficient distributed machine learning. Reasons for the interest\nin DANE include scalability and versatility. Convergence of DANE, however, can\nbe tricky; its appealing convergence rate is only rigorous for quadratic\nobjective, and for more general convex functions the known results are no\nstronger than those of the classic first-order methods. To remedy these\ndrawbacks, we propose in this paper some new alternatives of DANE which are\nmore suitable for analysis. We first introduce a simple variant of DANE\nequipped with backtracking line search, for which global asymptotic convergence\nand sharper local non-asymptotic convergence rate guarantees can be proved for\nboth quadratic and non-quadratic strongly convex functions. Then we propose a\nheavy-ball method to accelerate the convergence of DANE, showing that nearly\ntight local rate of convergence can be established for strongly convex\nfunctions, and with proper modification of algorithm the same result applies\nglobally to linear prediction models. Numerical evidence is provided to confirm\nthe theoretical and practical advantages of our methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 16:36:30 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Yuan", "Xiao-Tong", ""], ["Li", "Ping", ""]]}, {"id": "1908.02252", "submitter": "Guangyi Zhang", "authors": "Guangyi Zhang, Vandad Davoodnia, Alireza Sepas-Moghaddam, Yaoxue\n  Zhang, and Ali Etemad", "title": "Classification of Hand Movements from EEG using a Deep Attention-based\n  LSTM Network", "comments": null, "journal-ref": null, "doi": "10.1109/JSEN.2019.2956998", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying limb movements using brain activity is an important task in\nBrain-computer Interfaces (BCI) that has been successfully used in multiple\napplication domains, ranging from human-computer interaction to medical and\nbiomedical applications. This paper proposes a novel solution for\nclassification of left/right hand movement by exploiting a Long Short-Term\nMemory (LSTM) network with attention mechanism to learn the\nelectroencephalogram (EEG) time-series information. To this end, a wide range\nof time and frequency domain features are extracted from the EEG signals and\nused to train an LSTM network to perform the classification task. We conduct\nextensive experiments with the EEG Movement dataset and show that our proposed\nsolution our method achieves improvements over several benchmarks and\nstate-of-the-art methods in both intra-subject and cross-subject validation\nschemes. Moreover, we utilize the proposed framework to analyze the information\nas received by the sensors and monitor the activated regions of the brain by\ntracking EEG topography throughout the experiments.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 16:42:46 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 09:59:28 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Zhang", "Guangyi", ""], ["Davoodnia", "Vandad", ""], ["Sepas-Moghaddam", "Alireza", ""], ["Zhang", "Yaoxue", ""], ["Etemad", "Ali", ""]]}, {"id": "1908.02254", "submitter": "S M Nadim Uddin", "authors": "S. M. A. Sharif, Ghulam Mujtaba, S. M. Nadim Uddin", "title": "EdgeNet: A novel approach for Arabic numeral classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Despite the importance of handwritten numeral classification, a robust and\neffective method for a widely used language like Arabic is still due. This\nstudy focuses to overcome two major limitations of existing works: data\ndiversity and effective learning method. Hence, the existing Arabic numeral\ndatasets have been merged into a single dataset and augmented to introduce data\ndiversity. Moreover, a novel deep model has been proposed to exploit diverse\ndata samples of unified dataset. The proposed deep model utilizes the low-level\nedge features by propagating them through residual connection. To make a fair\ncomparison with the proposed model, the existing works have been studied under\nthe unified dataset. The comparison experiments illustrate that the unified\ndataset accelerates the performance of the existing works. Moreover, the\nproposed model outperforms the existing state-of-the-art Arabic handwritten\nnumeral classification methods and obtain an accuracy of 99.59% in the\nvalidation phase. Apart from that, different state-of-the-art classification\nmodels have studied with the same dataset to reveal their feasibility for the\nArabic numeral classification. Code available at\nhttp://github.com/sharif-apu/EdgeNet.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 10:17:43 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Sharif", "S. M. A.", ""], ["Mujtaba", "Ghulam", ""], ["Uddin", "S. M. Nadim", ""]]}, {"id": "1908.02256", "submitter": "Ravi Raju", "authors": "Ravi Raju, Mikko Lipasti", "title": "BlurNet: Defense by Filtering the Feature Maps", "comments": "10 pages, 4 figures, Accepted at DSN 2020 workshop: Dependable and\n  Secure Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the field of adversarial machine learning has been garnering\nattention by showing that state-of-the-art deep neural networks are vulnerable\nto adversarial examples, stemming from small perturbations being added to the\ninput image. Adversarial examples are generated by a malicious adversary by\nobtaining access to the model parameters, such as gradient information, to\nalter the input or by attacking a substitute model and transferring those\nmalicious examples over to attack the victim model. Specifically, one of these\nattack algorithms, Robust Physical Perturbations ($RP_2$), generates\nadversarial images of stop signs with black and white stickers to achieve high\ntargeted misclassification rates against standard-architecture traffic sign\nclassifiers. In this paper, we propose BlurNet, a defense against the $RP_2$\nattack. First, we motivate the defense with a frequency analysis of the first\nlayer feature maps of the network on the LISA dataset, which shows that high\nfrequency noise is introduced into the input image by the $RP_2$ algorithm. To\nremove the high frequency noise, we introduce a depthwise convolution layer of\nstandard blur kernels after the first layer. We perform a blackbox transfer\nattack to show that low-pass filtering the feature maps is more beneficial than\nfiltering the input. We then present various regularization schemes to\nincorporate this low-pass filtering behavior into the training regime of the\nnetwork and perform white-box attacks. We conclude with an adaptive attack\nevaluation to show that the success rate of the attack drops from 90\\% to 20\\%\nwith total variation regularization, one of the proposed defenses.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 16:55:47 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 20:39:13 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Raju", "Ravi", ""], ["Lipasti", "Mikko", ""]]}, {"id": "1908.02269", "submitter": "Julien Roy", "authors": "Julien Roy, Paul Barde, F\\'elix G. Harvey, Derek Nowrouzezahrai and\n  Christopher Pal", "title": "Promoting Coordination through Policy Regularization in Multi-Agent Deep\n  Reinforcement Learning", "comments": "23 pages, 16 figures. This revised version contains additional\n  results and minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent reinforcement learning, discovering successful collective\nbehaviors is challenging as it requires exploring a joint action space that\ngrows exponentially with the number of agents. While the tractability of\nindependent agent-wise exploration is appealing, this approach fails on tasks\nthat require elaborate group strategies. We argue that coordinating the agents'\npolicies can guide their exploration and we investigate techniques to promote\nsuch an inductive bias. We propose two policy regularization methods: TeamReg,\nwhich is based on inter-agent action predictability and CoachReg that relies on\nsynchronized behavior selection. We evaluate each approach on four challenging\ncontinuous control tasks with sparse rewards that require varying levels of\ncoordination as well as on the discrete action Google Research Football\nenvironment. Our experiments show improved performance across many cooperative\nmulti-agent problems. Finally, we analyze the effects of our proposed methods\non the policies that our agents learn and show that our methods successfully\nenforce the qualities that we propose as proxies for coordinated behaviors.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 17:48:17 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 20:33:08 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 19:24:21 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2020 16:30:41 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Roy", "Julien", ""], ["Barde", "Paul", ""], ["Harvey", "F\u00e9lix G.", ""], ["Nowrouzezahrai", "Derek", ""], ["Pal", "Christopher", ""]]}, {"id": "1908.02282", "submitter": "Srijith Rajamohan", "authors": "Srijith Rajamohan, Alana Romanella, Amit Ramesh", "title": "A Weakly-Supervised Attention-based Visualization Tool for Assessing\n  Political Affiliation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we seek to finetune a weakly-supervised expert-guided Deep\nNeural Network (DNN) for the purpose of determining political affiliations. In\nthis context, stance detection is used for determining political affiliation or\nideology which is framed in the form of relative proximities between entities\nin a low-dimensional space. An attention-based mechanism is used to provide\nmodel interpretability. A Deep Neural Network for Natural Language\nUnderstanding (NLU) using static and contextual embeddings is trained and\nevaluated. Various techniques to visualize the projections generated from the\nnetwork are evaluated for visualization efficiency. An overview of the pipeline\nfrom data ingestion, processing and generation of visualization is given here.\nA web-based framework created to faciliate this interaction and exploration is\npresented here. Preliminary results of this study are summarized and future\nwork is outlined.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:14:06 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Rajamohan", "Srijith", ""], ["Romanella", "Alana", ""], ["Ramesh", "Amit", ""]]}, {"id": "1908.02283", "submitter": "Zachary Ren", "authors": "Zongze Ren, Zhiyong Chen, Shugong Xu", "title": "Triplet Based Embedding Distance and Similarity Learning for\n  Text-independent Speaker Verification", "comments": "5 pages, Accepted to The Asia-Pacific Signal and Information\n  Processing Association Annual Summit and Conference 2019 (APSIPA ASC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker embeddings become growing popular in the text-independent speaker\nverification task. In this paper, we propose two improvements during the\ntraining stage. The improvements are both based on triplet cause the training\nstage and the evaluation stage of the baseline x-vector system focus on\ndifferent aims. Firstly, we introduce triplet loss for optimizing the Euclidean\ndistances between embeddings while minimizing the multi-class cross entropy\nloss. Secondly, we design an embedding similarity measurement network for\ncontrolling the similarity between the two selected embeddings. We further\njointly train the two new methods with the original network and achieve\nstate-of-the-art. The multi-task training synergies are shown with a 9%\nreduction equal error rate (EER) and detected cost function (DCF) on the 2016\nNIST Speaker Recognition Evaluation (SRE) Test Set.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 04:23:27 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Ren", "Zongze", ""], ["Chen", "Zhiyong", ""], ["Xu", "Shugong", ""]]}, {"id": "1908.02284", "submitter": "Zachary Ren", "authors": "Zongze Ren, Guofu Yang, Shugong Xu", "title": "Two-stage Training for Chinese Dialect Recognition", "comments": "Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a two-stage language identification (LID) system\nbased on a shallow ResNet14 followed by a simple 2-layer recurrent neural\nnetwork (RNN) architecture, which was used for Xunfei (iFlyTek) Chinese Dialect\nRecognition Challenge and won the first place among 110 teams. The system\ntrains an acoustic model (AM) firstly with connectionist temporal\nclassification (CTC) to recognize the given phonetic sequence annotation and\nthen train another RNN to classify dialect category by utilizing the\nintermediate features as inputs from the AM. Compared with a three-stage system\nwe further explore, our results show that the two-stage system can achieve high\naccuracy for Chinese dialects recognition under both short utterance and long\nutterance conditions with less training time.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 04:28:56 GMT"}, {"version": "v2", "created": "Sat, 10 Aug 2019 09:28:00 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Ren", "Zongze", ""], ["Yang", "Guofu", ""], ["Xu", "Shugong", ""]]}, {"id": "1908.02315", "submitter": "Emille E. O. Ishida", "authors": "Emille E. O. Ishida", "title": "Machine Learning and the future of Supernova Cosmology", "comments": "Author version of invited Comment Article published as part of a\n  Supernova Focus Issue in Nature Astronomy; 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning methods will play a fundamental role in our ability to\noptimize the science output from the next generation of large scale surveys.\nGiven the peculiarities of astronomical data, it is crucial that algorithms are\nadapted to the data situation at hand. In this comment, I review the recent\nefforts towards the development of automatic systems to identify and classify\nsupernova with the goal of enabling their use as cosmological standard candles.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 18:31:43 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Ishida", "Emille E. O.", ""]]}, {"id": "1908.02334", "submitter": "Emily Diller", "authors": "Emily E Diller, Sha Cao, Beth Ey, Robert Lober, Jason G Parker", "title": "Predicted disease compositions of human gliomas estimated from\n  multiparametric MRI can predict endothelial proliferation, tumor grade, and\n  overall survival", "comments": "13 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV physics.med-ph stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background and Purpose: Biopsy is the main determinants of glioma clinical\nmanagement, but require invasive sampling that fail to detect relevant features\nbecause of tumor heterogeneity. The purpose of this study was to evaluate the\naccuracy of a voxel-wise, multiparametric MRI radiomic method to predict\nfeatures and develop a minimally invasive method to objectively assess\nneoplasms.\n  Methods: Multiparametric MRI were registered to T1-weighted gadolinium\ncontrast-enhanced data using a 12 degree-of-freedom affine model. The\nretrospectively collected MRI data included T1-weighted, T1-weighted gadolinium\ncontrast-enhanced, T2-weighted, fluid attenuated inversion recovery, and\nmulti-b-value diffusion-weighted acquired at 1.5T or 3.0T. Clinical experts\nprovided voxel-wise annotations for five disease states on a subset of patients\nto establish a training feature vector of 611,930 observations. Then, a\nk-nearest-neighbor (k-NN) classifier was trained using a 25% hold-out design.\nThe trained k-NN model was applied to 13,018,171 observations from seventeen\nhistologically confirmed glioma patients. Linear regression tested overall\nsurvival (OS) relationship to predicted disease compositions (PDC) and\ndiagnostic age (alpha = 0.05). Canonical discriminant analysis tested if PDC\nand diagnostic age could differentiate clinical, genetic, and microscopic\nfactors (alpha = 0.05).\n  Results: The model predicted voxel annotation class with a Dice similarity\ncoefficient of 94.34% +/- 2.98. Linear combinations of PDCs and diagnostic age\npredicted OS (p = 0.008), grade (p = 0.014), and endothelia proliferation (p =\n0.003); but fell short predicting gene mutations for TP53BP1 and IDH1.\n  Conclusions: This voxel-wise, multi-parametric MRI radiomic strategy holds\npotential as a non-invasive decision-making aid for clinicians managing\npatients with glioma.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 19:10:32 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Diller", "Emily E", ""], ["Cao", "Sha", ""], ["Ey", "Beth", ""], ["Lober", "Robert", ""], ["Parker", "Jason G", ""]]}, {"id": "1908.02337", "submitter": "Lili Zhao", "authors": "Lili Zhao and Dai Feng", "title": "DNNSurv: Deep Neural Networks for Survival Analysis Using Pseudo Values", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been increasing interest in modelling survival data using deep\nlearning methods in medical research. Current approaches have focused on\ndesigning special cost functions to handle censored survival data. We propose a\nvery different method with two steps. In the first step, we transform each\nsubject's survival time into a series of jackknife pseudo conditional survival\nprobabilities and then use these pseudo probabilities as a quantitative\nresponse variable in the deep neural network model. By using the pseudo values,\nwe reduce a complex survival analysis to a standard regression problem, which\ngreatly simplifies the neural network construction. Our two-step approach is\nsimple, yet very flexible in making risk predictions for survival data, which\nis very appealing from the practice point of view. The source code is freely\navailable at http://github.com/lilizhaoUM/DNNSurv.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 19:16:58 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 18:57:05 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Zhao", "Lili", ""], ["Feng", "Dai", ""]]}, {"id": "1908.02338", "submitter": "Paul Fergus Dr", "authors": "Paul Fergus, Carl Chalmers, Casimiro Curbelo Montanez, Denis Reilly,\n  Paulo Lisboa and Beth Pineles", "title": "Modelling Segmented Cardiotocography Time-Series Signals Using\n  One-Dimensional Convolutional Neural Networks for the Early Detection of\n  Abnormal Birth Outcomes", "comments": "11 Pages, 12 Figures (excluding profile pictures), accepted for\n  publication in IEEE Transactions in Emerging Topics in Computational\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gynaecologists and obstetricians visually interpret cardiotocography (CTG)\ntraces using the International Federation of Gynaecology and Obstetrics (FIGO)\nguidelines to assess the wellbeing of the foetus during antenatal care. This\napproach has raised concerns among professionals with regards to inter- and\nintra-variability where clinical diagnosis only has a 30\\% positive predictive\nvalue when classifying pathological outcomes. Machine learning models, trained\nwith FIGO and other user derived features extracted from CTG traces, have been\nshown to increase positive predictive capacity and minimise variability. This\nis only possible however when class distributions are equal which is rarely the\ncase in clinical trials where case-control observations are heavily skewed in\nfavour of normal outcomes. Classes can be balanced using either synthetic data\nderived from resampled case training data or by decreasing the number of\ncontrol instances. However, this either introduces bias or removes valuable\ninformation. Concerns have also been raised regarding machine learning studies\nand their reliance on manually handcrafted features. While this has led to some\ninteresting results, deriving an optimal set of features is considered to be an\nart as well as a science and is often an empirical and time consuming process.\nIn this paper, we address both of these issues and propose a novel CTG analysis\nmethodology that a) splits CTG time-series signals into n-size windows with\nequal class distributions, and b) automatically extracts features from\ntime-series windows using a one dimensional convolutional neural network\n(1DCNN) and multilayer perceptron (MLP) ensemble. Collectively, the proposed\napproach normally distributes classes and removes the need to handcrafted\nfeatures from CTG traces.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 19:20:23 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 09:03:21 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Fergus", "Paul", ""], ["Chalmers", "Carl", ""], ["Montanez", "Casimiro Curbelo", ""], ["Reilly", "Denis", ""], ["Lisboa", "Paulo", ""], ["Pineles", "Beth", ""]]}, {"id": "1908.02341", "submitter": "Nilesh Tripuraneni", "authors": "Nilesh Tripuraneni, Lester Mackey", "title": "Single Point Transductive Prediction", "comments": "37th International Conference on Machine Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard methods in supervised learning separate training and prediction: the\nmodel is fit independently of any test points it may encounter. However, can\nknowledge of the next test point $\\mathbf{x}_{\\star}$ be exploited to improve\nprediction accuracy? We address this question in the context of linear\nprediction, showing how techniques from semi-parametric inference can be used\ntransductively to combat regularization bias. We first lower bound the\n$\\mathbf{x}_{\\star}$ prediction error of ridge regression and the Lasso,\nshowing that they must incur significant bias in certain test directions. We\nthen provide non-asymptotic upper bounds on the $\\mathbf{x}_{\\star}$ prediction\nerror of two transductive prediction rules. We conclude by showing the efficacy\nof our methods on both synthetic and real data, highlighting the improvements\nsingle point transductive prediction can provide in settings with distribution\nshift.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 19:34:30 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 04:44:37 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 03:17:34 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 04:54:59 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tripuraneni", "Nilesh", ""], ["Mackey", "Lester", ""]]}, {"id": "1908.02353", "submitter": "Flavio de Barros Vidal", "authors": "Lucas F. Porto, Laise N. Correia Lima, Ademir Franco, Donald M.\n  Pianto, Carlos Eduardo Machado Palhares, Donald M. Pianto and Flavio de\n  Barros Vidal", "title": "Estimating sex and age for forensic applications using machine learning\n  based on facial measurements from frontal cephalometric landmarks", "comments": "17 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial analysis permits many investigations some of the most important of\nwhich are craniofacial identification, facial recognition, and age and sex\nestimation. In forensics, photo-anthropometry describes the study of facial\ngrowth and allows the identification of patterns in facial skull development by\nusing a group of cephalometric landmarks to estimate anthropological\ninformation. In several areas, automation of manual procedures has achieved\nadvantages over and similar measurement confidence as a forensic expert. This\nmanuscript presents an approach using photo-anthropometric indexes, generated\nfrom frontal faces cephalometric landmarks, to create an artificial neural\nnetwork classifier that allows the estimation of anthropological information,\nin this specific case age and sex. The work is focused on four tasks: i) sex\nestimation over ages from 5 to 22 years old, evaluating the interference of age\non sex estimation; ii) age estimation from photo-anthropometric indexes for\nfour age intervals (1 year, 2 years, 4 years and 5 years); iii) age group\nestimation for thresholds of over 14 and over 18 years old; and; iv) the\nprovision of a new data set, available for academic purposes only, with a large\nand complete set of facial photo-anthropometric points marked and checked by\nforensic experts, measured from over 18,000 faces of individuals from Brazil\nover the last 4 years. The proposed classifier obtained significant results,\nusing this new data set, for the sex estimation of individuals over 14 years\nold, achieving accuracy values greater than 0.85 by the F_1 measure. For age\nestimation, the accuracy results are 0.72 for measure with an age interval of 5\nyears. For the age group estimation, the measures of accuracy are greater than\n0.93 and 0.83 for thresholds of 14 and 18 years, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 20:33:11 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Porto", "Lucas F.", ""], ["Lima", "Laise N. Correia", ""], ["Franco", "Ademir", ""], ["Pianto", "Donald M.", ""], ["Palhares", "Carlos Eduardo Machado", ""], ["Pianto", "Donald M.", ""], ["Vidal", "Flavio de Barros", ""]]}, {"id": "1908.02357", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang and Erik Miehling and Tamer Ba\\c{s}ar", "title": "Online Planning for Decentralized Stochastic Control with Partial\n  History Sharing", "comments": "Accepted to American Control Conference (ACC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decentralized stochastic control, standard approaches for sequential\ndecision-making, e.g. dynamic programming, quickly become intractable due to\nthe need to maintain a complex information state. Computational challenges are\nfurther compounded if agents do not possess complete model knowledge. In this\npaper, we take advantage of the fact that in many problems agents share some\ncommon information, or history, termed partial history sharing. Under this\ninformation structure the policy search space is greatly reduced. We propose a\nprovably convergent, online tree-search based algorithm that does not require a\nclosed-form model or explicit communication among agents. Interestingly, our\nalgorithm can be viewed as a generalization of several existing heuristic\nsolvers for decentralized partially observable Markov decision processes. To\ndemonstrate the applicability of the model, we propose a novel collaborative\nintrusion response model, where multiple agents (defenders) possessing\nasymmetric information aim to collaboratively defend a computer network.\nNumerical results demonstrate the performance of our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 20:38:58 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Miehling", "Erik", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1908.02367", "submitter": "Chaoyu Guan", "authors": "Chaoyu Guan, Yuhao Cheng, Hai Zhao", "title": "Semantic Role Labeling with Associated Memory Network", "comments": "Published at NAACL 2019; This is camera Ready version; Code is\n  available at https://github.com/Frozenmad/AMN_SRL", "journal-ref": null, "doi": "10.18653/v1/N19-1340", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) is a task to recognize all the\npredicate-argument pairs of a sentence, which has been in a performance\nimprovement bottleneck after a series of latest works were presented. This\npaper proposes a novel syntax-agnostic SRL model enhanced by the proposed\nassociated memory network (AMN), which makes use of inter-sentence attention of\nlabel-known associated sentences as a kind of memory to further enhance\ndependency-based SRL. In detail, we use sentences and their labels from train\ndataset as an associated memory cue to help label the target sentence.\nFurthermore, we compare several associated sentences selecting strategies and\nlabel merging methods in AMN to find and utilize the label of associated\nsentences while attending them. By leveraging the attentive memory from known\ntraining data, Our full model reaches state-of-the-art on CoNLL-2009 benchmark\ndatasets for syntax-agnostic setting, showing a new effective research line of\nSRL enhancement other than exploiting external resources such as well\npre-trained language models.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 09:40:18 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Guan", "Chaoyu", ""], ["Cheng", "Yuhao", ""], ["Zhao", "Hai", ""]]}, {"id": "1908.02374", "submitter": "Youcheng Sun", "authors": "Youcheng Sun, Hana Chockler, Xiaowei Huang, Daniel Kroening", "title": "Explaining Image Classifiers using Statistical Fault Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The black-box nature of deep neural networks (DNNs) makes it impossible to\nunderstand why a particular output is produced, creating demand for\n\"Explainable AI\". In this paper, we show that statistical fault localization\n(SFL) techniques from software engineering deliver high quality explanations of\nthe outputs of DNNs, where we define an explanation as a minimal subset of\nfeatures sufficient for making the same decision as for the original input. We\npresent an algorithm and a tool called DeepCover, which synthesizes a ranking\nof the features of the inputs using SFL and constructs explanations for the\ndecisions of the DNN based on this ranking. We compare explanations produced by\nDeepCover with those of the state-of-the-art tools GradCAM, LIME, SHAP, RISE\nand Extremal and show that explanations generated by DeepCover are consistently\nbetter across a broad set of experiments. On a benchmark set with known ground\ntruth, DeepCover achieves 76.7% accuracy, which is 6% better than the second\nbest Extremal.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 21:44:48 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 15:10:20 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Sun", "Youcheng", ""], ["Chockler", "Hana", ""], ["Huang", "Xiaowei", ""], ["Kroening", "Daniel", ""]]}, {"id": "1908.02386", "submitter": "Seyed Hamed Fatemi Langroudi", "authors": "Hamed F. Langroudi, Zachariah Carmichael, David Pastuch, Dhireesha\n  Kudithipudi", "title": "Cheetah: Mixed Low-Precision Hardware & Software Co-Design Framework for\n  DNNs on the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-precision DNNs have been extensively explored in order to reduce the size\nof DNN models for edge devices. Recently, the posit numerical format has shown\npromise for DNN data representation and compute with ultra-low precision in\n[5..8]-bits. However, previous studies were limited to studying posit for DNN\ninference only. In this paper, we propose the Cheetah framework, which supports\nboth DNN training and inference using posits, as well as other commonly used\nformats. Additionally, the framework is amenable for different quantization\napproaches and supports mixed-precision floating point and fixed-point\nnumerical formats. Cheetah is evaluated on three datasets: MNIST, Fashion\nMNIST, and CIFAR-10. Results indicate that 16-bit posits outperform 16-bit\nfloating point in DNN training. Furthermore, performing inference with\n[5..8]-bit posits improves the trade-off between performance and\nenergy-delay-product over both [5..8]-bit float and fixed-point.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 22:28:29 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Langroudi", "Hamed F.", ""], ["Carmichael", "Zachariah", ""], ["Pastuch", "David", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1908.02388", "submitter": "Adrien Ali Taiga", "authors": "Adrien Ali Ta\\\"iga, William Fedus, Marlos C. Machado, Aaron Courville,\n  Marc G. Bellemare", "title": "Benchmarking Bonus-Based Exploration Methods on the Arcade Learning\n  Environment", "comments": "Accepted at the second Exploration in Reinforcement Learning Workshop\n  at the 36th International Conference on Machine Learning, Long Beach,\n  California", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an empirical evaluation of recently developed exploration\nalgorithms within the Arcade Learning Environment (ALE). We study the use of\ndifferent reward bonuses that incentives exploration in reinforcement learning.\nWe do so by fixing the learning algorithm used and focusing only on the impact\nof the different exploration bonuses in the agent's performance. We use\nRainbow, the state-of-the-art algorithm for value-based agents, and focus on\nsome of the bonuses proposed in the last few years. We consider the impact\nthese algorithms have on performance within the popular game Montezuma's\nRevenge which has gathered a lot of interest from the exploration community,\nacross the the set of seven games identified by Bellemare et al. (2016) as\nchallenging for exploration, and easier games where exploration is not an\nissue. We find that, in our setting, recently developed bonuses do not provide\nsignificantly improved performance on Montezuma's Revenge or hard exploration\ngames. We also find that existing bonus-based methods may negatively impact\nperformance on games in which exploration is not an issue and may even perform\nworse than $\\epsilon$-greedy exploration.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 22:36:35 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 14:39:25 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Ta\u00efga", "Adrien Ali", ""], ["Fedus", "William", ""], ["Machado", "Marlos C.", ""], ["Courville", "Aaron", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1908.02400", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh, Dianne P O'Leary", "title": "Refining the Structure of Neural Networks Using Matrix Conditioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have proven to be exceptionally useful in performing\nmany machine learning tasks. However, for each new dataset, choosing an\neffective size and structure of the model can be a time-consuming process of\ntrial and error. While a small network with few neurons might not be able to\ncapture the intricacies of a given task, having too many neurons can lead to\noverfitting and poor generalization. Here, we propose a practical method that\nemploys matrix conditioning to automatically design the structure of layers of\na feed-forward network, by first adjusting the proportion of neurons among the\nlayers of a network and then scaling the size of network up or down. Results on\nsample image and non-image datasets demonstrate that our method results in\nsmall networks with high accuracies. Finally, guided by matrix conditioning, we\nprovide a method to effectively squeeze models that are already trained. Our\ntechniques reduce the human cost of designing deep learning models and can also\nreduce training time and the expense of using neural networks for applications.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 23:45:34 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""], ["O'Leary", "Dianne P", ""]]}, {"id": "1908.02402", "submitter": "Lei Shu", "authors": "Lei Shu, Piero Molino, Mahdi Namazifar, Hu Xu, Bing Liu, Huaixiu\n  Zheng, Gokhan Tur", "title": "Flexibly-Structured Model for Task-Oriented Dialogues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel end-to-end architecture for task-oriented\ndialogue systems. It is based on a simple and practical yet very effective\nsequence-to-sequence approach, where language understanding and state tracking\ntasks are modeled jointly with a structured copy-augmented sequential decoder\nand a multi-label decoder for each slot. The policy engine and language\ngeneration tasks are modeled jointly following that. The copy-augmented\nsequential decoder deals with new or unknown values in the conversation, while\nthe multi-label decoder combined with the sequential decoder ensures the\nexplicit assignment of values to slots. On the generation part, slot binary\nclassifiers are used to improve performance. This architecture is scalable to\nreal-world scenarios and is shown through an empirical evaluation to achieve\nstate-of-the-art performance on both the Cambridge Restaurant dataset and the\nStanford in-car assistant dataset\\footnote{The code is available at\n\\url{https://github.com/uber-research/FSDM}}\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 23:56:25 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Shu", "Lei", ""], ["Molino", "Piero", ""], ["Namazifar", "Mahdi", ""], ["Xu", "Hu", ""], ["Liu", "Bing", ""], ["Zheng", "Huaixiu", ""], ["Tur", "Gokhan", ""]]}, {"id": "1908.02419", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Jiaoyang Huang", "title": "Gradient Descent Finds Global Minima for Generalizable Deep Neural\n  Networks of Practical Sizes", "comments": "Accepted. All the results remain the same. Additional explanations\n  were added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we theoretically prove that gradient descent can find a global\nminimum of non-convex optimization of all layers for nonlinear deep neural\nnetworks of sizes commonly encountered in practice. The theory developed in\nthis paper only requires the practical degrees of over-parameterization unlike\nprevious theories. Our theory only requires the number of trainable parameters\nto increase linearly as the number of training samples increases. This allows\nthe size of the deep neural networks to be consistent with practice and to be\nseveral orders of magnitude smaller than that required by the previous\ntheories. Moreover, we prove that the linear increase of the size of the\nnetwork is the optimal rate and that it cannot be improved, except by a\nlogarithmic factor. Furthermore, deep neural networks with the trainability\nguarantee are shown to generalize well to unseen test samples with a natural\ndataset but not a random dataset.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 20:19:39 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 18:27:14 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 19:40:44 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Huang", "Jiaoyang", ""]]}, {"id": "1908.02426", "submitter": "Jing Cheng", "authors": "Jing Cheng, Haifeng Wang, Leslie Ying, Dong Liang", "title": "Model Learning: Primal Dual Networks for Fast MR imaging", "comments": "accepted in MICCAI2019. arXiv admin note: text overlap with\n  arXiv:1906.08143", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance imaging (MRI) is known to be a slow imaging modality and\nundersampling in k-space has been used to increase the imaging speed. However,\nimage reconstruction from undersampled k-space data is an ill-posed inverse\nproblem. Iterative algorithms based on compressed sensing have been used to\naddress the issue. In this work, we unroll the iterations of the primal-dual\nhybrid gradient algorithm to a learnable deep network architecture, and\ngradually relax the constraints to reconstruct MR images from highly\nundersampled k-space data. The proposed method combines the theoretical\nconvergence guarantee of optimi-zation methods with the powerful learning\ncapability of deep networks. As the constraints are gradually relaxed, the\nreconstruction model is finally learned from the training data by updating in\nk-space and image domain alternatively. Experi-ments on in vivo MR data\ndemonstrate that the proposed method achieves supe-rior MR reconstructions from\nhighly undersampled k-space data over other state-of-the-art image\nreconstruction methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 02:59:08 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Cheng", "Jing", ""], ["Wang", "Haifeng", ""], ["Ying", "Leslie", ""], ["Liang", "Dong", ""]]}, {"id": "1908.02427", "submitter": "Franklin Abodo", "authors": "Franklin Abodo, Andrew Berthaume, Stephen Zitzow-Childs and Leonardo\n  Bobadilla", "title": "Strengthening the Case for a Bayesian Approach to Car-following Model\n  Calibration and Validation using Probabilistic Programming", "comments": "IEEE 22nd Intelligent Transportation Systems Conference, ITSC 2019, 2\n  figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compute and memory constraints have historically prevented traffic simulation\nsoftware users from fully utilizing the predictive models underlying them. When\ncalibrating car-following models, particularly, accommodations have included 1)\nusing sensitivity analysis to limit the number of parameters to be calibrated,\nand 2) identifying only one set of parameter values using data collected from\nmultiple car-following instances across multiple drivers. Shortcuts are further\nmotivated by insufficient data set sizes, for which a driver may have too few\ninstances to fully account for the variation in their driving behavior. In this\npaper, we demonstrate that recent technological advances can enable\ntransportation researchers and engineers to overcome these constraints and\nproduce calibration results that 1) outperform industry standard approaches,\nand 2) allow for a unique set of parameters to be estimated for each driver in\na data set, even given a small amount of data. We propose a novel calibration\nprocedure for car-following models based on Bayesian machine learning and\nprobabilistic programming, and apply it to real-world data from a naturalistic\ndriving study. We also discuss how this combination of mathematical and\nsoftware tools can offer additional benefits such as more informative model\nvalidation and the incorporation of true-to-data uncertainty into simulation\ntraces.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 03:04:38 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Abodo", "Franklin", ""], ["Berthaume", "Andrew", ""], ["Zitzow-Childs", "Stephen", ""], ["Bobadilla", "Leonardo", ""]]}, {"id": "1908.02435", "submitter": "Andras Rozsa", "authors": "Andras Rozsa and Terrance E. Boult", "title": "Improved Adversarial Robustness by Reducing Open Space Risk via Tent\n  Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples contain small perturbations that can remain\nimperceptible to human observers but alter the behavior of even the best\nperforming deep learning models and yield incorrect outputs. Since their\ndiscovery, adversarial examples have drawn significant attention in machine\nlearning: researchers try to reveal the reasons for their existence and improve\nthe robustness of machine learning models to adversarial perturbations. The\nstate-of-the-art defense is the computationally expensive and very time\nconsuming adversarial training via projected gradient descent (PGD). We\nhypothesize that adversarial attacks exploit the open space risk of classic\nmonotonic activation functions. This paper introduces the tent activation\nfunction with bounded open space risk and shows that tents make deep learning\nmodels more robust to adversarial attacks. We demonstrate on the MNIST dataset\nthat a classifier with tents yields an average accuracy of 91.8% against six\nwhite-box adversarial attacks, which is more than 15 percentage points above\nthe state of the art. On the CIFAR-10 dataset, our approach improves the\naverage accuracy against the six white-box adversarial attacks to 73.5% from\n41.8% achieved by adversarial training via PGD.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 04:11:01 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Rozsa", "Andras", ""], ["Boult", "Terrance E.", ""]]}, {"id": "1908.02436", "submitter": "Megha Nawhal", "authors": "Zhiwei Deng, Megha Nawhal, Lili Meng, Greg Mori", "title": "Continuous Graph Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Continuous Graph Flow, a generative continuous flow\nbased method that aims to model complex distributions of graph-structured data.\nOnce learned, the model can be applied to an arbitrary graph, defining a\nprobability density over the random variables represented by the graph. It is\nformulated as an ordinary differential equation system with shared and reusable\nfunctions that operate over the graphs. This leads to a new type of neural\ngraph message passing scheme that performs continuous message passing over\ntime. This class of models offers several advantages: a flexible representation\nthat can generalize to variable data dimensions; ability to model dependencies\nin complex data distributions; reversible and memory-efficient; and exact and\nefficient computation of the likelihood of the data. We demonstrate the\neffectiveness of our model on a diverse set of generation tasks across\ndifferent domains: graph generation, image puzzle generation, and layout\ngeneration from scene graphs. Our proposed model achieves significantly better\nperformance compared to state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 04:24:48 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 04:34:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Deng", "Zhiwei", ""], ["Nawhal", "Megha", ""], ["Meng", "Lili", ""], ["Mori", "Greg", ""]]}, {"id": "1908.02441", "submitter": "Jiwoong Park", "authors": "Jiwoong Park, Minsik Lee, Hyung Jin Chang, Kyuewang Lee, Jin Young\n  Choi", "title": "Symmetric Graph Convolutional Autoencoder for Unsupervised Graph\n  Representation Learning", "comments": "10 pages, 3 figures, ICCV 2019 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a symmetric graph convolutional autoencoder which produces a\nlow-dimensional latent representation from a graph. In contrast to the existing\ngraph autoencoders with asymmetric decoder parts, the proposed autoencoder has\na newly designed decoder which builds a completely symmetric autoencoder form.\nFor the reconstruction of node features, the decoder is designed based on\nLaplacian sharpening as the counterpart of Laplacian smoothing of the encoder,\nwhich allows utilizing the graph structure in the whole processes of the\nproposed autoencoder architecture. In order to prevent the numerical\ninstability of the network caused by the Laplacian sharpening introduction, we\nfurther propose a new numerically stable form of the Laplacian sharpening by\nincorporating the signed graphs. In addition, a new cost function which finds a\nlatent representation and a latent affinity matrix simultaneously is devised to\nboost the performance of image clustering tasks. The experimental results on\nclustering, link prediction and visualization tasks strongly support that the\nproposed model is stable and outperforms various state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 05:08:15 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Park", "Jiwoong", ""], ["Lee", "Minsik", ""], ["Chang", "Hyung Jin", ""], ["Lee", "Kyuewang", ""], ["Choi", "Jin Young", ""]]}, {"id": "1908.02502", "submitter": "Danqing Shi", "authors": "Danqing Shi, Yang Shi, Xinyue Xu, Nan Chen, Siwei Fu, Hongjin Wu, Nan\n  Cao", "title": "Task-Oriented Optimal Sequencing of Visualization Charts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A chart sequence is used to describe a series of visualization charts\ngenerated in the exploratory analysis by data analysts. It provides information\ndetails in each chart as well as a logical relationship among charts. While\nexisting research targets on generating chart sequences that match human's\nperceptions, little attention has been paid to formulate task-oriented\nconnections between charts in a chart design space. We present a novel chart\nsequencing method based on reinforcement learning to capture the connections\nbetween charts in the context of three major analysis tasks, including\ncorrelation analysis, anomaly detection, and cluster analysis. The proposed\nmethod formulates a chart sequencing procedure as an optimization problem,\nwhich seeks an optimal policy to sequencing charts for the specific analysis\ntask. In our method, a novel reward function is introduced, which takes both\nthe analysis task and the factor of human cognition into consideration. We\nconducted one case study and two user studies to evaluate the effectiveness of\nour method under the application scenarios of visualization demonstration,\nsequencing charts for reasoning analysis results, and making a chart design\nchoice. The study results showed the power of our method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 09:43:09 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Shi", "Danqing", ""], ["Shi", "Yang", ""], ["Xu", "Xinyue", ""], ["Chen", "Nan", ""], ["Fu", "Siwei", ""], ["Wu", "Hongjin", ""], ["Cao", "Nan", ""]]}, {"id": "1908.02507", "submitter": "Yujie Yuan", "authors": "Yu-Jie Yuan, Yu-Kun Lai, Jie Yang, Hongbo Fu, Lin Gao", "title": "Mesh Variational Autoencoders with Edge Contraction Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D shape analysis is an important research topic in computer vision and\ngraphics. While existing methods have generalized image-based deep learning to\nmeshes using graph-based convolutions, the lack of an effective pooling\noperation restricts the learning capability of their networks. In this paper,\nwe propose a novel pooling operation for mesh datasets with the same\nconnectivity but different geometry, by building a mesh hierarchy using mesh\nsimplification. For this purpose, we develop a modified mesh simplification\nmethod to avoid generating highly irregularly sized triangles. Our pooling\noperation effectively encodes the correspondence between coarser and finer\nmeshes in the hierarchy. We then present a variational auto-encoder structure\nwith the edge contraction pooling and graph-based convolutions, to explore\nprobability latent spaces of 3D surfaces. Our network requires far fewer\nparameters than the original mesh VAE and thus can handle denser models thanks\nto our new pooling operation and convolutional kernels. Our evaluation also\nshows that our method has better generalization ability and is more reliable in\nvarious applications, including shape generation, shape interpolation and shape\nembedding.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 09:59:08 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Yuan", "Yu-Jie", ""], ["Lai", "Yu-Kun", ""], ["Yang", "Jie", ""], ["Fu", "Hongbo", ""], ["Gao", "Lin", ""]]}, {"id": "1908.02511", "submitter": "Dmitry Nikulin", "authors": "Dmitry Nikulin, Anastasia Ianina, Vladimir Aliev, Sergey Nikolenko", "title": "Free-Lunch Saliency via Attention in Atari Agents", "comments": "2019 ICCV Workshop on Interpreting and Explaining Visual Artificial\n  Intelligence Models. 15 pages, 14 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to visualize saliency maps for deep neural network\nmodels and apply it to deep reinforcement learning agents trained on Atari\nenvironments. Our method adds an attention module that we call FLS (Free Lunch\nSaliency) to the feature extractor from an established baseline (Mnih et al.,\n2015). This addition results in a trainable model that can produce saliency\nmaps, i.e., visualizations of the importance of different parts of the input\nfor the agent's current decision making. We show experimentally that a network\nwith an FLS module exhibits performance similar to the baseline (i.e., it is\n\"free\", with no performance cost) and can be used as a drop-in replacement for\nreinforcement learning agents. We also design another feature extractor that\nscores slightly lower but provides higher-fidelity visualizations. In addition\nto attained scores, we report saliency metrics evaluated on the Atari-HEAD\ndataset of human gameplay.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 10:10:45 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 17:42:50 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Nikulin", "Dmitry", ""], ["Ianina", "Anastasia", ""], ["Aliev", "Vladimir", ""], ["Nikolenko", "Sergey", ""]]}, {"id": "1908.02556", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Bla\\v{z} \\v{S}krlj, Jan Kralj and Nada Lavra\\v{c}", "title": "Embedding-based Silhouette Community Detection", "comments": null, "journal-ref": null, "doi": "10.1007/s10994-020-05882-8", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining complex data in the form of networks is of increasing interest in many\nscientific disciplines. Network communities correspond to densely connected\nsubnetworks, and often represent key functional parts of real-world systems. In\nthis work, we propose Silhouette Community Detection (SCD), an approach for\ndetecting communities, based on clustering of network node embeddings, i.e.\nreal valued representations of nodes derived from their neighborhoods. We\ninvestigate the performance of the proposed SCD approach on 234 synthetic\nnetworks, as well as on a real-life social network. Even though SCD is not\nbased on any form of modularity optimization, it performs comparably or better\nthan state-of-the-art community detection algorithms, such as the InfoMap and\nLouvain algorithms. Further, we demonstrate how SCD's outputs can be used along\nwith domain ontologies in semantic subgroup discovery, yielding\nhuman-understandable explanations of communities detected in a real-life\nprotein interaction network. Being embedding-based, SCD is widely applicable\nand can be tested out-of-the-box as part of many existing network learning and\nexploration pipelines.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 08:22:58 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["\u0160krlj", "Bla\u017e", ""], ["Kralj", "Jan", ""], ["Lavra\u010d", "Nada", ""]]}, {"id": "1908.02569", "submitter": "Kyungmin Kim", "authors": "Kyung-Min Kim, Donghyun Kwak, Hanock Kwak, Young-Jin Park, Sangkwon\n  Sim, Jae-Han Cho, Minkyu Kim, Jihun Kwon, Nako Sung, and Jung-Woo Ha", "title": "Tripartite Heterogeneous Graph Propagation for Large-scale Social\n  Recommendation", "comments": "6 pages, accepted for RecSys 2019 LBR Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been emerging as a promising method for\nrelational representation including recommender systems. However, various\nchallenging issues of social graphs hinder the practical usage of GNNs for\nsocial recommendation, such as their complex noisy connections and high\nheterogeneity. The oversmoothing of GNNs is an obstacle of GNN-based social\nrecommendation as well. Here we propose a new graph embedding method\nHeterogeneous Graph Propagation (HGP) to tackle these issues. HGP uses a\ngroup-user-item tripartite graph as input to reduce the number of edges and the\ncomplexity of paths in a social graph. To solve the oversmoothing issue, HGP\nembeds nodes under a personalized PageRank based propagation scheme, separately\nfor group-user graph and user-item graph. Node embeddings from each graph are\nintegrated using an attention mechanism. We evaluate our HGP on a large-scale\nreal-world dataset consisting of 1,645,279 nodes and 4,711,208 edges. The\nexperimental results show that HGP outperforms several baselines in terms of\nAUC and F1-score metrics.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 08:27:07 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Kim", "Kyung-Min", ""], ["Kwak", "Donghyun", ""], ["Kwak", "Hanock", ""], ["Park", "Young-Jin", ""], ["Sim", "Sangkwon", ""], ["Cho", "Jae-Han", ""], ["Kim", "Minkyu", ""], ["Kwon", "Jihun", ""], ["Sung", "Nako", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "1908.02570", "submitter": "Shakila Khan Rumi", "authors": "Shakila Khan Rumi, Flora D. Salim", "title": "Modelling Regional Crime Risk using Directed Graph of Check-ins", "comments": "4 Pages, This paper has been accepted to publish in Proceedings of\n  the 29th ACM International Conference on Information and Knowledge Management\n  (CIKM' 20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The location-based social network, Foursquare, reflects the human activities\nof a city. The mobility dynamics inferred from Foursquare helps us\nunderstanding urban social events like crime In this paper, we propose a\ndirected graph from the aggregated movement between regions using Foursquare\ndata. We derive region risk factor from the movement direction, quantity and\ncrime history in different periods of the day. Later, we propose a new set of\nfeatures, DIrected graph Flow FEatuRes (DIFFER) which are associated with\nregion risk factor. The reliable correlations between DIFFER and crime count\nare observed. We verify the effectiveness of the DIFFER in monthly crime count\nusing Linear, XGBoost, and Random Forest regression in two cities, Chicago and\nNew York City.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 02:34:38 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 02:46:33 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Rumi", "Shakila Khan", ""], ["Salim", "Flora D.", ""]]}, {"id": "1908.02571", "submitter": "Afshin Sadeghi", "authors": "Afshin Sadeghi and Jens Lehmann", "title": "Linking Physicians to Medical Research Results via Knowledge Graph\n  Embeddings and Twitter", "comments": "AI for Good, Data Science for Social Good, Machine learning for\n  Social Good, Twitter Data, Knowledge Graph Embeddings, Medical Research", "journal-ref": "ECML SOGOOD 2019", "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informing professionals about the latest research results in their field is a\nparticularly important task in the field of health care, since any development\nin this field directly improves the health status of the patients. Meanwhile,\nsocial media is an infrastructure that allows public instant sharing of\ninformation, thus it has recently become popular in medical applications. In\nthis study, we apply Multi Distance Knowledge Graph Embeddings (MDE) to link\nphysicians and surgeons to the latest medical breakthroughs that are shared as\nthe research results on Twitter. Our study shows that using this method\nphysicians can be informed about the new findings in their field given that\nthey have an account dedicated to their profession.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 10:15:40 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 14:37:36 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 14:25:56 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Sadeghi", "Afshin", ""], ["Lehmann", "Jens", ""]]}, {"id": "1908.02573", "submitter": "Akifumi Okuno", "authors": "Akifumi Okuno, Hidetoshi Shimodaira", "title": "Hyperlink Regression via Bregman Divergence", "comments": "41 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collection of $U \\: (\\in \\mathbb{N})$ data vectors is called a $U$-tuple,\nand the association strength among the vectors of a tuple is termed as the\n\\emph{hyperlink weight}, that is assumed to be symmetric with respect to\npermutation of the entries in the index. We herein propose Bregman hyperlink\nregression (BHLR), which learns a user-specified symmetric similarity function\nsuch that it predicts the tuple's hyperlink weight from data vectors stored in\nthe $U$-tuple. BHLR is a simple and general framework for hyper-relational\nlearning, that minimizes Bregman-divergence (BD) between the hyperlink weights\nand estimated similarities defined for the corresponding tuples; BHLR\nencompasses various existing methods, such as logistic regression ($U=1$),\nPoisson regression ($U=1$), link prediction ($U=2$), and those for\nrepresentation learning, such as graph embedding ($U=2$), matrix factorization\n($U=2$), tensor factorization ($U \\geq 2$), and their variants equipped with\narbitrary BD. Nonlinear functions (e.g., neural networks), can be employed for\nthe similarity functions. However, there are theoretical challenges such that\nsome of different tuples of BHLR may share data vectors therein, unlike the\ni.i.d. setting of classical regression. We address these theoretical issues,\nand proved that BHLR equipped with arbitrary BD and $U \\in \\mathbb{N}$ is (P-1)\nstatistically consistent, that is, it asymptotically recovers the underlying\ntrue conditional expectation of hyperlink weights given data vectors, and (P-2)\ncomputationally tractable, that is, it is efficiently computed by stochastic\noptimization algorithms using a novel generalized minibatch sampling procedure\nfor hyper-relational data. Consequently, theoretical guarantees for BHLR\nincluding several existing methods, that have been examined experimentally, are\nprovided in a unified manner.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 01:38:21 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 07:34:57 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Okuno", "Akifumi", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "1908.02575", "submitter": "Oscar Correa", "authors": "Oscar Correa and Jeffrey Chan and Vinh Nguyen", "title": "Alternative Blockmodelling", "comments": "56 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many approaches have been proposed to discover clusters within networks.\nCommunity finding field encompasses approaches which try to discover clusters\nwhere nodes are tightly related within them but loosely related with nodes of\nother clusters. However, a community network configuration is not the only\npossible latent structure in a graph. Core-periphery and hierarchical network\nconfigurations are valid structures to discover in a relational dataset. On the\nother hand, a network is not completely explained by only knowing the\nmembership of each node. A high level view of the inter-cluster relationships\nis needed. Blockmodelling techniques deal with these two issues. Firstly,\nblockmodelling allows finding any network configuration besides to the\nwell-known community structure. Secondly, blockmodelling is a summary\nrepresentation of a network which regards not only membership of nodes but also\nrelations between clusters. Finally, a unique summary representation of a\nnetwork is unlikely. Networks might hide more than one blockmodel. Therefore,\nour proposed problem aims to discover a secondary blockmodel representation of\na network that is of good quality and dissimilar with respect to a given\nblockmodel. Our methodology is presented through two approaches, (a) inclusion\nof cannot-link constraints and (b) dissimilarity between image matrices. Both\napproaches are based on non-negative matrix factorisation NMF which fits the\nblockmodelling representation. The evaluation of these two approaches regards\nquality and dissimilarity of the discovered alternative blockmodel as these are\nthe requirements of the problem.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 06:49:47 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Correa", "Oscar", ""], ["Chan", "Jeffrey", ""], ["Nguyen", "Vinh", ""]]}, {"id": "1908.02582", "submitter": "Samuel Budd", "authors": "Samuel Budd, Matthew Sinclair, Bishesh Khanal, Jacqueline Matthew,\n  David Lloyd, Alberto Gomez, Nicolas Toussaint, Emma Robinson and Bernhard\n  Kainz", "title": "Confident Head Circumference Measurement from Ultrasound with Real-time\n  Feedback for Sonographers", "comments": "Accepted at MICCAI 2019; Demo video available on Twitter\n  (@sambuddinc)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manual estimation of fetal Head Circumference (HC) from Ultrasound (US) is a\nkey biometric for monitoring the healthy development of fetuses. Unfortunately,\nsuch measurements are subject to large inter-observer variability, resulting in\nlow early-detection rates of fetal abnormalities. To address this issue, we\npropose a novel probabilistic Deep Learning approach for real-time automated\nestimation of fetal HC. This system feeds back statistics on measurement\nrobustness to inform users how confident a deep neural network is in evaluating\nsuitable views acquired during free-hand ultrasound examination. In real-time\nscenarios, this approach may be exploited to guide operators to scan planes\nthat are as close as possible to the underlying distribution of training\nimages, for the purpose of improving inter-operator consistency. We train on\nfree-hand ultrasound data from over 2000 subjects (2848 training/540 test) and\nshow that our method is able to predict HC measurements within 1.81$\\pm$1.65mm\ndeviation from the ground truth, with 50% of the test images fully contained\nwithin the predicted confidence margins, and an average of 1.82$\\pm$1.78mm\ndeviation from the margin for the remaining cases that are not fully contained.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 12:35:54 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Budd", "Samuel", ""], ["Sinclair", "Matthew", ""], ["Khanal", "Bishesh", ""], ["Matthew", "Jacqueline", ""], ["Lloyd", "David", ""], ["Gomez", "Alberto", ""], ["Toussaint", "Nicolas", ""], ["Robinson", "Emma", ""], ["Kainz", "Bernhard", ""]]}, {"id": "1908.02588", "submitter": "Luke Snyder", "authors": "Luke S. Snyder, Yi-Shan Lin, Morteza Karimzadeh, Dan Goldwasser, and\n  David S. Ebert", "title": "Interactive Learning for Identifying Relevant Tweets to Support\n  Real-time Situational Awareness", "comments": "12 pages, 8 figures, 3 tables, IEEE VIS VAST 2019, TVCG", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934614", "report-no": null, "categories": "cs.SI cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various domain users are increasingly leveraging real-time social media data\nto gain rapid situational awareness. However, due to the high noise in the\ndeluge of data, effectively determining semantically relevant information can\nbe difficult, further complicated by the changing definition of relevancy by\neach end user for different events. The majority of existing methods for short\ntext relevance classification fail to incorporate users' knowledge into the\nclassification process. Existing methods that incorporate interactive user\nfeedback focus on historical datasets. Therefore, classifiers cannot be\ninteractively retrained for specific events or user-dependent needs in\nreal-time. This limits real-time situational awareness, as streaming data that\nis incorrectly classified cannot be corrected immediately, permitting the\npossibility for important incoming data to be incorrectly classified as well.\nWe present a novel interactive learning framework to improve the classification\nprocess in which the user iteratively corrects the relevancy of tweets in\nreal-time to train the classification model on-the-fly for immediate predictive\nimprovements. We computationally evaluate our classification model adapted to\nlearn at interactive rates. Our results show that our approach outperforms\nstate-of-the-art machine learning models. In addition, we integrate our\nframework with the extended Social Media Analytics and Reporting Toolkit\n(SMART) 2.0 system, allowing the use of our interactive learning framework\nwithin a visual analytics system tailored for real-time situational awareness.\nTo demonstrate our framework's effectiveness, we provide domain expert feedback\nfrom first responders who used the extended SMART 2.0 system.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 09:01:19 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 19:11:52 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Snyder", "Luke S.", ""], ["Lin", "Yi-Shan", ""], ["Karimzadeh", "Morteza", ""], ["Goldwasser", "Dan", ""], ["Ebert", "David S.", ""]]}, {"id": "1908.02590", "submitter": "Radu Horaud P", "authors": "Mostafa Sadeghi, Simon Leglaive, Xavier Alameda-PIneda, Laurent Girin\n  and Radu Horaud", "title": "Audio-visual Speech Enhancement Using Conditional Variational\n  Auto-Encoders", "comments": "Submitted to IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing", "journal-ref": "IEEE/ACM Transactions on Audio, Speech and Language Processing,\n  28, 2020", "doi": "10.1109/TASLP.2020.3000593", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational auto-encoders (VAEs) are deep generative latent variable models\nthat can be used for learning the distribution of complex data. VAEs have been\nsuccessfully used to learn a probabilistic prior over speech signals, which is\nthen used to perform speech enhancement. One advantage of this generative\napproach is that it does not require pairs of clean and noisy speech signals at\ntraining. In this paper, we propose audio-visual variants of VAEs for\nsingle-channel and speaker-independent speech enhancement. We develop a\nconditional VAE (CVAE) where the audio speech generative process is conditioned\non visual information of the lip region. At test time, the audio-visual speech\ngenerative model is combined with a noise model based on nonnegative matrix\nfactorization, and speech enhancement relies on a Monte Carlo\nexpectation-maximization algorithm. Experiments are conducted with the recently\npublished NTCD-TIMIT dataset as well as the GRID corpus. The results confirm\nthat the proposed audio-visual CVAE effectively fuses audio and visual\ninformation, and it improves the speech enhancement performance compared with\nthe audio-only VAE model, especially when the speech signal is highly corrupted\nby noise. We also show that the proposed unsupervised audio-visual speech\nenhancement approach outperforms a state-of-the-art supervised deep learning\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 12:38:32 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 11:47:41 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 09:38:39 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Sadeghi", "Mostafa", ""], ["Leglaive", "Simon", ""], ["Alameda-PIneda", "Xavier", ""], ["Girin", "Laurent", ""], ["Horaud", "Radu", ""]]}, {"id": "1908.02591", "submitter": "Mark Weber", "authors": "Mark Weber, Giacomo Domeniconi, Jie Chen, Daniel Karl I. Weidele,\n  Claudio Bellei, Tom Robinson, Charles E. Leiserson", "title": "Anti-Money Laundering in Bitcoin: Experimenting with Graph Convolutional\n  Networks for Financial Forensics", "comments": "7 pages, Tutorial in the Anomaly Detection in Finance Workshop at the\n  25th SIGKDD Conference on Knowledge Discovery and Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anti-money laundering (AML) regulations play a critical role in safeguarding\nfinancial systems, but bear high costs for institutions and drive financial\nexclusion for those on the socioeconomic and international margins. The advent\nof cryptocurrency has introduced an intriguing paradox: pseudonymity allows\ncriminals to hide in plain sight, but open data gives more power to\ninvestigators and enables the crowdsourcing of forensic analysis. Meanwhile\nadvances in learning algorithms show great promise for the AML toolkit. In this\nworkshop tutorial, we motivate the opportunity to reconcile the cause of safety\nwith that of financial inclusion. We contribute the Elliptic Data Set, a time\nseries graph of over 200K Bitcoin transactions (nodes), 234K directed payment\nflows (edges), and 166 node features, including ones based on non-public data;\nto our knowledge, this is the largest labelled transaction data set publicly\navailable in any cryptocurrency. We share results from a binary classification\ntask predicting illicit transactions using variations of Logistic Regression\n(LR), Random Forest (RF), Multilayer Perceptrons (MLP), and Graph Convolutional\nNetworks (GCN), with GCN being of special interest as an emergent new method\nfor capturing relational information. The results show the superiority of\nRandom Forest (RF), but also invite algorithmic work to combine the respective\npowers of RF and graph methods. Lastly, we consider visualization for analysis\nand explainability, which is difficult given the size and dynamism of\nreal-world transaction graphs, and we offer a simple prototype capable of\nnavigating the graph and observing model performance on illicit activity over\ntime. With this tutorial and data set, we hope to a) invite feedback in support\nof our ongoing inquiry, and b) inspire others to work on this societally\nimportant challenge.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 22:10:01 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Weber", "Mark", ""], ["Domeniconi", "Giacomo", ""], ["Chen", "Jie", ""], ["Weidele", "Daniel Karl I.", ""], ["Bellei", "Claudio", ""], ["Robinson", "Tom", ""], ["Leiserson", "Charles E.", ""]]}, {"id": "1908.02607", "submitter": "Zihan Jiang", "authors": "Zihan Jiang, Wanling Gao, Lei Wang, Xingwang Xiong, Yuchen Zhang, Xu\n  Wen, Chunjie Luo, Hainan Ye, Yunquan Zhang, Shengzhong Feng, Kenli Li, Weijia\n  Xu, Jianfeng Zhan", "title": "HPC AI500: A Benchmark Suite for HPC AI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the trend of applying deep learning (DL) in high\nperformance scientific computing, the unique characteristics of emerging DL\nworkloads in HPC raise great challenges in designing, implementing HPC AI\nsystems. The community needs a new yard stick for evaluating the future HPC\nsystems. In this paper, we propose HPC AI500 --- a benchmark suite for\nevaluating HPC systems that running scientific DL workloads. Covering the most\nrepresentative scientific fields, each workload from HPC AI500 is based on\nreal-world scientific DL applications. Currently, we choose 14 scientific DL\nbenchmarks from perspectives of application scenarios, data sets, and software\nstack. We propose a set of metrics for comprehensively evaluating the HPC AI\nsystems, considering both accuracy, performance as well as power and cost. We\nprovide a scalable reference implementation of HPC AI500. HPC AI500 is a part\nof the open-source AIBench project, the specification and source code are\npublicly available from \\url{http://www.benchcouncil.org/AIBench/index.html}.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 10:18:08 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 03:38:49 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 09:31:40 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Jiang", "Zihan", ""], ["Gao", "Wanling", ""], ["Wang", "Lei", ""], ["Xiong", "Xingwang", ""], ["Zhang", "Yuchen", ""], ["Wen", "Xu", ""], ["Luo", "Chunjie", ""], ["Ye", "Hainan", ""], ["Zhang", "Yunquan", ""], ["Feng", "Shengzhong", ""], ["Li", "Kenli", ""], ["Xu", "Weijia", ""], ["Zhan", "Jianfeng", ""]]}, {"id": "1908.02612", "submitter": "Sungrack Yun", "authors": "Sungrack Yun, Janghoon Cho, Jungyun Eum, Wonil Chang, Kyuwoong Hwang", "title": "An End-to-End Text-independent Speaker Verification Framework with a\n  Keyword Adversarial Network", "comments": "Will be appeared in INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an end-to-end text-independent speaker verification\nframework by jointly considering the speaker embedding (SE) network and\nautomatic speech recognition (ASR) network. The SE network learns to output an\nembedding vector which distinguishes the speaker characteristics of the input\nutterance, while the ASR network learns to recognize the phonetic context of\nthe input. In training our speaker verification framework, we consider both the\ntriplet loss minimization and adversarial gradient of the ASR network to obtain\nmore discriminative and text-independent speaker embedding vectors. With the\ntriplet loss, the distances between the embedding vectors of the same speaker\nare minimized while those of different speakers are maximized. Also, with the\nadversarial gradient of the ASR network, the text-dependency of the speaker\nembedding vector can be reduced. In the experiments, we evaluated our speaker\nverification framework using the LibriSpeech and CHiME 2013 dataset, and the\nevaluation results show that our speaker verification framework shows lower\nequal error rate and better text-independency compared to the other approaches.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 11:05:20 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Yun", "Sungrack", ""], ["Cho", "Janghoon", ""], ["Eum", "Jungyun", ""], ["Chang", "Wonil", ""], ["Hwang", "Kyuwoong", ""]]}, {"id": "1908.02614", "submitter": "Shikang Liu", "authors": "Shikang Liu, David Hachen, Omar Lizardo, Christian Poellabauer, Aaron\n  Striegel, Tijana Milenkovic", "title": "The power of dynamic social networks to predict individuals' mental\n  health", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision medicine has received attention both in and outside the clinic. We\nfocus on the latter, by exploiting the relationship between individuals' social\ninteractions and their mental health to develop a predictive model of one's\nlikelihood to be depressed or anxious from rich dynamic social network data. To\nour knowledge, we are the first to do this. Existing studies differ from our\nwork in at least one aspect: they do not model social interaction data as a\nnetwork; they do so but analyze static network data; they examine \"correlation\"\nbetween social networks and health but without developing a predictive model;\nor they study other individual traits but not mental health. In a systematic\nand comprehensive evaluation, we show that our predictive model that uses\ndynamic social network data is superior to its static network as well as\nnon-network equivalents when run on the same data.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 00:50:36 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Liu", "Shikang", ""], ["Hachen", "David", ""], ["Lizardo", "Omar", ""], ["Poellabauer", "Christian", ""], ["Striegel", "Aaron", ""], ["Milenkovic", "Tijana", ""]]}, {"id": "1908.02619", "submitter": "Vaishak Belle", "authors": "Drew Hemment, Ruth Aylett, Vaishak Belle, Dave Murray-Rust, Ewa Luger,\n  Jane Hillston, Michael Rovatsos, Frank Broz", "title": "Experiential AI", "comments": "To appear in AI Matters 5(1): 25-31 (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiential AI is proposed as a new research agenda in which artists and\nscientists come together to dispel the mystery of algorithms and make their\nmechanisms vividly apparent. It addresses the challenge of finding novel ways\nof opening up the field of artificial intelligence to greater transparency and\ncollaboration between human and machine. The hypothesis is that art can mediate\nbetween computer code and human comprehension to overcome the limitations of\nexplanations in and for AI systems. Artists can make the boundaries of systems\nvisible and offer novel ways to make the reasoning of AI transparent and\ndecipherable. Beyond this, artistic practice can explore new configurations of\nhumans and algorithms, mapping the terrain of inter-agencies between people and\nmachines. This helps to viscerally understand the complex causal chains in\nenvironments with AI components, including questions about what data to collect\nor who to collect it about, how the algorithms are chosen, commissioned and\nconfigured or how humans are conditioned by their participation in algorithmic\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 12:56:17 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Hemment", "Drew", ""], ["Aylett", "Ruth", ""], ["Belle", "Vaishak", ""], ["Murray-Rust", "Dave", ""], ["Luger", "Ewa", ""], ["Hillston", "Jane", ""], ["Rovatsos", "Michael", ""], ["Broz", "Frank", ""]]}, {"id": "1908.02620", "submitter": "Yunxiang Zhang", "authors": "Yunxiang Zhang, Chenglong Zhao, Bingbing Ni, Jian Zhang, Haoran Deng", "title": "Exploiting Channel Similarity for Accelerating Deep Convolutional Neural\n  Networks", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the limitations of existing magnitude-based pruning algorithms in\ncases where model weights or activations are of large and similar magnitude, we\npropose a novel perspective to discover parameter redundancy among channels and\naccelerate deep CNNs via channel pruning. Precisely, we argue that channels\nrevealing similar feature information have functional overlap and that most\nchannels within each such similarity group can be removed without compromising\nmodel's representational power. After deriving an effective metric for\nevaluating channel similarity through probabilistic modeling, we introduce a\npruning algorithm via hierarchical clustering of channels. In particular, the\nproposed algorithm does not rely on sparsity training techniques or complex\ndata-driven optimization and can be directly applied to pre-trained models.\nExtensive experiments on benchmark datasets strongly demonstrate the superior\nacceleration performance of our approach over prior arts. On ImageNet, our\npruned ResNet-50 with 30% FLOPs reduced outperforms the baseline model.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 12:44:30 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Zhang", "Yunxiang", ""], ["Zhao", "Chenglong", ""], ["Ni", "Bingbing", ""], ["Zhang", "Jian", ""], ["Deng", "Haoran", ""]]}, {"id": "1908.02626", "submitter": "Marco Rudolph", "authors": "Marco Rudolph, Bastian Wandt and Bodo Rosenhahn", "title": "Structuring Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose Structuring AutoEncoders (SAE). SAEs are neural\nnetworks which learn a low dimensional representation of data which are\nadditionally enriched with a desired structure in this low dimensional space.\nWhile traditional Autoencoders have proven to structure data naturally they\nfail to discover semantic structure that is hard to recognize in the raw data.\nThe SAE solves the problem by enhancing a traditional Autoencoder using weak\nsupervision to form a structured latent space. In the experiments we\ndemonstrate, that the structured latent space allows for a much more efficient\ndata representation for further tasks such as classification for sparsely\nlabeled data, an efficient choice of data to label, and morphing between\nclasses. To demonstrate the general applicability of our method, we show\nexperiments on the benchmark image datasets MNIST, Fashion-MNIST, DeepFashion2\nand on a dataset of 3D human shapes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 13:29:11 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Rudolph", "Marco", ""], ["Wandt", "Bastian", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "1908.02641", "submitter": "Yair Horesh", "authors": "Yair Horesh, Noa Haas, Elhanan Mishraky, Yehezkel S. Resheff, Shir\n  Meir Lador", "title": "Paired-Consistency: An Example-Based Model-Agnostic Approach to Fairness\n  Regularization in Machine Learning", "comments": "ECML PKDD 2019, Data Science for social good workshop", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2019. Communications in Computer and Information Science, vol 1167. Springer,\n  Cham", "doi": "10.1007/978-3-030-43823-4_47", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI systems develop in complexity it is becoming increasingly hard to\nensure non-discrimination on the basis of protected attributes such as gender,\nage, and race. Many recent methods have been developed for dealing with this\nissue as long as the protected attribute is explicitly available for the\nalgorithm. We address the setting where this is not the case (with either no\nexplicit protected attribute, or a large set of them). Instead, we assume the\nexistence of a fair domain expert capable of generating an extension to the\nlabeled dataset - a small set of example pairs, each having a different value\non a subset of protected variables, but judged to warrant a similar model\nresponse. We define a performance metric - paired consistency. Paired\nconsistency measures how close the output (assigned by a classifier or a\nregressor) is on these carefully selected pairs of examples for which fairness\ndictates identical decisions. In some cases consistency can be embedded within\nthe loss function during optimization and serve as a fairness regularizer, and\nin others it is a tool for fair model selection. We demonstrate our method\nusing the well studied Income Census dataset.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 14:01:37 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 21:58:03 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Horesh", "Yair", ""], ["Haas", "Noa", ""], ["Mishraky", "Elhanan", ""], ["Resheff", "Yehezkel S.", ""], ["Lador", "Shir Meir", ""]]}, {"id": "1908.02646", "submitter": "Yang Zhang", "authors": "Jingyuan Wang, Yang Zhang, Ke Tang, Junjie Wu and Zhang Xiong", "title": "AlphaStock: A Buying-Winners-and-Selling-Losers Investment Strategy\n  using Interpretable Deep Reinforcement Attention Networks", "comments": "Accepted for POSTER presentation at KDD2019 Applied Data Science\n  Track", "journal-ref": null, "doi": "10.1145/3292500.3330647", "report-no": null, "categories": "q-fin.TR cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the successful marriage of finance innovations\nand AI techniques in various finance applications including quantitative\ntrading (QT). Despite great research efforts devoted to leveraging deep\nlearning (DL) methods for building better QT strategies, existing studies still\nface serious challenges especially from the side of finance, such as the\nbalance of risk and return, the resistance to extreme loss, and the\ninterpretability of strategies, which limit the application of DL-based\nstrategies in real-life financial markets. In this work, we propose AlphaStock,\na novel reinforcement learning (RL) based investment strategy enhanced by\ninterpretable deep attention networks, to address the above challenges. Our\nmain contributions are summarized as follows: i) We integrate deep attention\nnetworks with a Sharpe ratio-oriented reinforcement learning framework to\nachieve a risk-return balanced investment strategy; ii) We suggest modeling\ninterrelationships among assets to avoid selection bias and develop a\ncross-asset attention mechanism; iii) To our best knowledge, this work is among\nthe first to offer an interpretable investment strategy using deep\nreinforcement learning models. The experiments on long-periodic U.S. and\nChinese markets demonstrate the effectiveness and robustness of AlphaStock over\ndiverse market states. It turns out that AlphaStock tends to select the stocks\nas winners with high long-term growth, low volatility, high intrinsic value,\nand being undervalued recently.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 11:52:36 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Wang", "Jingyuan", ""], ["Zhang", "Yang", ""], ["Tang", "Ke", ""], ["Wu", "Junjie", ""], ["Xiong", "Zhang", ""]]}, {"id": "1908.02650", "submitter": "Antoine Pirovano", "authors": "Antoine Pirovano and Leandro G. Almeida and Said Ladjal", "title": "Regression Constraint for an Explainable Cervical Cancer Classifier", "comments": "5 pages, 9 figures, accepted at GRETSI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article adresses the problem of automatic squamous cells classification\nfor cervical cancer screening using Deep Learning methods. We study different\narchitectures on a public dataset called Herlev dataset, which consists in\nclassifying cells, obtained by cervical pap smear, regarding the severity of\nthe abnormalities they represent. Furthermore, we use an attribution method to\nunderstand which cytomorphological features are actually learned as\ndiscriminative to classify severity of the abnormalities. Through this paper,\nwe show how we trained a performant classifier: 74.5\\% accuracy on severity\nclassification and 94\\% accuracy on normal/abnormal classification.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 14:12:04 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 07:52:40 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Pirovano", "Antoine", ""], ["Almeida", "Leandro G.", ""], ["Ladjal", "Said", ""]]}, {"id": "1908.02658", "submitter": "Wenjian Luo", "authors": "Wenjian Luo, Chenwang Wu, Nan Zhou and Li Ni", "title": "Random Directional Attack for Fooling Deep Neural Networks", "comments": "13pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been widely used in many fields such as\nimages processing, speech recognition; however, they are vulnerable to\nadversarial examples, and this is a security issue worthy of attention. Because\nthe training process of DNNs converge the loss by updating the weights along\nthe gradient descent direction, many gradient-based methods attempt to destroy\nthe DNN model by adding perturbations in the gradient direction. Unfortunately,\nas the model is nonlinear in most cases, the addition of perturbations in the\ngradient direction does not necessarily increase loss. Thus, we propose a\nrandom directed attack (RDA) for generating adversarial examples in this paper.\nRather than limiting the gradient direction to generate an attack, RDA searches\nthe attack direction based on hill climbing and uses multiple strategies to\navoid local optima that cause attack failure. Compared with state-of-the-art\ngradient-based methods, the attack performance of RDA is very competitive.\nMoreover, RDA can attack without any internal knowledge of the model, and its\nperformance under black-box attack is similar to that of the white-box attack\nin most cases, which is difficult to achieve using existing gradient-based\nattack methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 03:48:29 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Luo", "Wenjian", ""], ["Wu", "Chenwang", ""], ["Zhou", "Nan", ""], ["Ni", "Li", ""]]}, {"id": "1908.02669", "submitter": "Cameron Trotter", "authors": "Cameron Trotter, Georgia Atkinson, Matthew Sharpe, A. Stephen McGough,\n  Nick Wright, Per Berggren", "title": "The Northumberland Dolphin Dataset: A Multimedia Individual Cetacean\n  Dataset for Fine-Grained Categorisation", "comments": "4 pages, 4 figures, submitted to FGVC6 Workshop at CVPR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for cetacean research include photo-identification (photo-id) and\npassive acoustic monitoring (PAM) which generate thousands of images per\nexpedition that are currently hand categorised by researchers into the\nindividual dolphins sighted. With the vast amount of data obtained it is\ncrucially important to develop a system that is able to categorise this\nquickly. The Northumberland Dolphin Dataset (NDD) is an on-going novel dataset\nproject made up of above and below water images of, and spectrograms of\nwhistles from, white-beaked dolphins. These are produced by photo-id and PAM\ndata collection methods applied off the coast of Northumberland, UK. This\ndataset will aid in building cetacean identification models, reducing the\nnumber of human-hours required to categorise images. Example use cases and\nareas identified for speed up are examined.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 15:00:27 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Trotter", "Cameron", ""], ["Atkinson", "Georgia", ""], ["Sharpe", "Matthew", ""], ["McGough", "A. Stephen", ""], ["Wright", "Nick", ""], ["Berggren", "Per", ""]]}, {"id": "1908.02686", "submitter": "J\\\"org Wagner", "authors": "J\\\"org Wagner, Jan Mathias K\\\"ohler, Tobias Gindele, Leon Hetzel,\n  Jakob Thadd\\\"aus Wiedemer, Sven Behnke", "title": "Interpretable and Fine-Grained Visual Explanations for Convolutional\n  Neural Networks", "comments": "In Proceedings of IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR), Long Beach, CA, USA, June 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To verify and validate networks, it is essential to gain insight into their\ndecisions, limitations as well as possible shortcomings of training data. In\nthis work, we propose a post-hoc, optimization based visual explanation method,\nwhich highlights the evidence in the input image for a specific prediction. Our\napproach is based on a novel technique to defend against adversarial evidence\n(i.e. faulty evidence due to artefacts) by filtering gradients during\noptimization. The defense does not depend on human-tuned parameters. It enables\nexplanations which are both fine-grained and preserve the characteristics of\nimages, such as edges and colors. The explanations are interpretable, suited\nfor visualizing detailed evidence and can be tested as they are valid model\ninputs. We qualitatively and quantitatively evaluate our approach on a\nmultitude of models and datasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 15:39:55 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Wagner", "J\u00f6rg", ""], ["K\u00f6hler", "Jan Mathias", ""], ["Gindele", "Tobias", ""], ["Hetzel", "Leon", ""], ["Wiedemer", "Jakob Thadd\u00e4us", ""], ["Behnke", "Sven", ""]]}, {"id": "1908.02718", "submitter": "Yan Shu", "authors": "Martin Mihelich, Charles Dognin, Yan Shu, Michael Blot", "title": "A Characterization of Mean Squared Error for Estimator with Bagging", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bagging can significantly improve the generalization performance of unstable\nmachine learning algorithms such as trees or neural networks. Though bagging is\nnow widely used in practice and many empirical studies have explored its\nbehavior, we still know little about the theoretical properties of bagged\npredictions. In this paper, we theoretically investigate how the bagging method\ncan reduce the Mean Squared Error (MSE) when applied on a statistical\nestimator. First, we prove that for any estimator, increasing the number of\nbagged estimators $N$ in the average can only reduce the MSE. This intuitive\nresult, observed empirically and discussed in the literature, has not yet been\nrigorously proved. Second, we focus on the standard estimator of variance\ncalled unbiased sample variance and we develop an exact analytical expression\nof the MSE for this estimator with bagging.\n  This allows us to rigorously discuss the number of iterations $N$ and the\nbatch size $m$ of the bagging method. From this expression, we state that only\nif the kurtosis of the distribution is greater than $\\frac{3}{2}$, the MSE of\nthe variance estimator can be reduced with bagging. This result is important\nbecause it demonstrates that for distribution with low kurtosis, bagging can\nonly deteriorate the performance of a statistical prediction. Finally, we\npropose a novel general-purpose algorithm to estimate with high precision the\nvariance of a sample.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 16:40:07 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Mihelich", "Martin", ""], ["Dognin", "Charles", ""], ["Shu", "Yan", ""], ["Blot", "Michael", ""]]}, {"id": "1908.02723", "submitter": "Ian Fox", "authors": "Ian Fox and Jenna Wiens", "title": "Advocacy Learning: Learning through Competition and Class-Conditional\n  Representations", "comments": "Accepted IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce advocacy learning, a novel supervised training scheme for\nattention-based classification problems. Advocacy learning relies on a\nframework consisting of two connected networks: 1) $N$ Advocates (one for each\nclass), each of which outputs an argument in the form of an attention map over\nthe input, and 2) a Judge, which predicts the class label based on these\narguments. Each Advocate produces a class-conditional representation with the\ngoal of convincing the Judge that the input example belongs to their class,\neven when the input belongs to a different class. Applied to several different\nclassification tasks, we show that advocacy learning can lead to small\nimprovements in classification accuracy over an identical supervised baseline.\nThough a series of follow-up experiments, we analyze when and how such\nclass-conditional representations improve discriminative performance. Though\nsomewhat counter-intuitive, a framework in which subnetworks are trained to\ncompetitively provide evidence in support of their class shows promise, in many\ncases performing on par with standard learning approaches. This provides a\nfoundation for further exploration into competition and class-conditional\nrepresentations in supervised learning.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 16:55:44 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Fox", "Ian", ""], ["Wiens", "Jenna", ""]]}, {"id": "1908.02725", "submitter": "Robert M. Gower", "authors": "Othmane Sebbouh and Nidham Gazagnadou and Samy Jelassi and Francis\n  Bach and Robert M. Gower", "title": "Towards closing the gap between the theory and practice of SVRG", "comments": "39 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the very first variance reduced stochastic methods for solving the\nempirical risk minimization problem was the SVRG method (Johnson & Zhang 2013).\nSVRG is an inner-outer loop based method, where in the outer loop a reference\nfull gradient is evaluated, after which $m \\in \\mathbb{N}$ steps of an inner\nloop are executed where the reference gradient is used to build a variance\nreduced estimate of the current gradient. The simplicity of the SVRG method and\nits analysis have led to multiple extensions and variants for even non-convex\noptimization. We provide a more general analysis of SVRG than had been\npreviously done by using arbitrary sampling, which allows us to analyse\nvirtually all forms of mini-batching through a single theorem. Furthermore, our\nanalysis is focused on more practical variants of SVRG including a new variant\nof the loopless SVRG (Hofman et al 2015, Kovalev et al 2019, Kulunchakov and\nMairal 2019) and a variant of k-SVRG (Raj and Stich 2018) where $m=n$ and where\n$n$ is the number of data points. Since our setup and analysis reflect what is\ndone in practice, we are able to set the parameters such as the mini-batch size\nand step size using our theory in such a way that produces a more efficient\nalgorithm in practice, as we show in extensive numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 10:12:53 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 13:14:23 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Sebbouh", "Othmane", ""], ["Gazagnadou", "Nidham", ""], ["Jelassi", "Samy", ""], ["Bach", "Francis", ""], ["Gower", "Robert M.", ""]]}, {"id": "1908.02728", "submitter": "Chonghuai Ma", "authors": "Chonghuai Ma, Floris Laporte, Joni Dambre, Peter Bienstman", "title": "Addressing Limited Weight Resolution in a Fully Optical Neuromorphic\n  Reservoir Computing Readout", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using optical hardware for neuromorphic computing has become more and more\npopular recently due to its efficient high-speed data processing capabilities\nand low power consumption. However, there are still some remaining obstacles to\nrealizing the vision of a completely optical neuromorphic computer. One of them\nis that, depending on the technology used, optical weighting elements may not\nshare the same resolution as in the electrical domain. Moreover, noise and\ndrift are important considerations as well. In this article, we investigate a\nnew method for improving the performance of optical weighting, even in the\npresence of noise and in the case of very low resolution. Even with only 8 to\n32 levels of resolution, the method can outperform the naive traditional\nlow-resolution weighting by several orders of magnitude in terms of bit error\nrate and can deliver performance very close to full-resolution weighting\nelements, also in noisy environments.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 12:55:37 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Ma", "Chonghuai", ""], ["Laporte", "Floris", ""], ["Dambre", "Joni", ""], ["Bienstman", "Peter", ""]]}, {"id": "1908.02729", "submitter": "Sho Yaida", "authors": "Judy Hoffman, Daniel A. Roberts, Sho Yaida", "title": "Robust Learning with Jacobian Regularization", "comments": "21 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of reliable systems must guarantee stability against input\nperturbations. In machine learning, such guarantee entails preventing\noverfitting and ensuring robustness of models against corruption of input data.\nIn order to maximize stability, we analyze and develop a computationally\nefficient implementation of Jacobian regularization that increases\nclassification margins of neural networks. The stabilizing effect of the\nJacobian regularizer leads to significant improvements in robustness, as\nmeasured against both random and adversarial input perturbations, without\nseverely degrading generalization properties on clean data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 17:04:26 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Hoffman", "Judy", ""], ["Roberts", "Daniel A.", ""], ["Yaida", "Sho", ""]]}, {"id": "1908.02734", "submitter": "Digvijay Boob", "authors": "Digvijay Boob, Qi Deng, Guanghui Lan", "title": "Stochastic First-order Methods for Convex and Nonconvex Functional\n  Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional constrained optimization is becoming more and more important in\nmachine learning and operations research. Such problems have potential\napplications in risk-averse machine learning, semisupervised learning and\nrobust optimization among others. In this paper, we first present a novel\nConstraint Extrapolation (ConEx) method for solving convex functional\nconstrained problems, which utilizes linear approximations of the constraint\nfunctions to define the extrapolation (or acceleration) step. We show that this\nmethod is a unified algorithm that achieves the best-known rate of convergence\nfor solving different functional constrained convex composite problems,\nincluding convex or strongly convex, and smooth or nonsmooth problems with\nstochastic objective and/or stochastic constraints. Many of these rates of\nconvergence were in fact obtained for the first time in the literature. In\naddition, ConEx is a single-loop algorithm that does not involve any penalty\nsubproblems. Contrary to existing dual methods, it does not require the\nprojection of Lagrangian multipliers into a (possibly unknown) bounded set.\nSecond, for nonconvex functional constrained problem, we introduce a new\nproximal point method which transforms the initial nonconvex problem into a\nsequence of convex functional constrained subproblems. We establish the\nconvergence and rate of convergence of this algorithm to KKT points under\ndifferent constraint qualifications. For practical use, we present inexact\nvariants of this algorithm, in which approximate solutions of the subproblems\nare computed using the aforementioned ConEx method and establish their\nassociated rate of convergence. To the best of our knowledge, most of these\nconvergence and complexity results of the proximal point method for nonconvex\nproblems also seem to be new in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 17:10:52 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 17:59:22 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 16:17:43 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Boob", "Digvijay", ""], ["Deng", "Qi", ""], ["Lan", "Guanghui", ""]]}, {"id": "1908.02738", "submitter": "Adrian Dalca", "authors": "Adrian V. Dalca, Marianne Rakic, John Guttag, Mert R. Sabuncu", "title": "Learning Conditional Deformable Templates with Convolutional Networks", "comments": "NeurIPS 2019: Neural Information Processing Systems. Keywords:\n  deformable templates, conditional atlases, diffeomorphic image registration,\n  probabilistic models, neuroimaging", "journal-ref": "NeurIPS: Thirty-third Conference on Neural Information Processing\n  Systems, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a learning framework for building deformable templates, which play\na fundamental role in many image analysis and computational anatomy tasks.\nConventional methods for template creation and image alignment to the template\nhave undergone decades of rich technical development. In these frameworks,\ntemplates are constructed using an iterative process of template estimation and\nalignment, which is often computationally very expensive. Due in part to this\nshortcoming, most methods compute a single template for the entire population\nof images, or a few templates for specific sub-groups of the data. In this\nwork, we present a probabilistic model and efficient learning strategy that\nyields either universal or conditional templates, jointly with a neural network\nthat provides efficient alignment of the images to these templates. We\ndemonstrate the usefulness of this method on a variety of domains, with a\nspecial focus on neuroimaging. This is particularly useful for clinical\napplications where a pre-existing template does not exist, or creating a new\none with traditional methods can be prohibitively expensive. Our code and\natlases are available online as part of the VoxelMorph library at\nhttp://voxelmorph.csail.mit.edu.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 17:29:36 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 16:04:22 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Dalca", "Adrian V.", ""], ["Rakic", "Marianne", ""], ["Guttag", "John", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1908.02750", "submitter": "Zhuoran Dang", "authors": "Zhuoran Dang, Mamoru Ishii", "title": "A physics-informed reinforcement learning approach for the interfacial\n  area transport in two-phase flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.GT cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of interfacial structure in two-phase flow systems is\ndifficult and challenging. In this paper, a novel physics-informed\nreinforcement learning-aided framework (PIRLF) for the interfacial area\ntransport is proposed. A Markov Decision Process that describes the bubble\ntransport is established by assuming that the development of two-phase flow is\na stochastic process with Markov property. The framework aims to capture the\ncomplexity of two-phase flow using the advantage of reinforcement learning (RL)\nin discovering complex patterns with the help of the physical model\n(Interfacial Area Transport Equation) as reference. The details of the\nframework design are described including the design of the environment and the\nalgorithm used in solving the RL problem. The performance of the PIRLF is\ntested through experiments using the experimental database for vertical upward\nbubbly air-water flows. The result shows a good performance of PIRLF with rRMSE\nof 6.556%. The case studies on the PIRLF performance also show that the type of\nreward function that is related to the physical model can affect the framework\nperformance. Based on the study, the optimal reward function is established.\nThe approaches to extending the capability of PIRLF are discussed, which can be\na reference for the further development of this methodology.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 19:50:56 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 04:18:43 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Dang", "Zhuoran", ""], ["Ishii", "Mamoru", ""]]}, {"id": "1908.02781", "submitter": "Amir Mosavi Prof", "authors": "Amir Mosavi, Pinar Ozturk, Kwok-wing Chau", "title": "Flood Prediction Using Machine Learning Models: Literature Review", "comments": "74 pages, 10 figures, 6 tables", "journal-ref": "Water 2018, 10, 1536", "doi": "10.3390/w10111536", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Floods are among the most destructive natural disasters, which are highly\ncomplex to model. The research on the advancement of flood prediction models\ncontributed to risk reduction, policy suggestion, minimization of the loss of\nhuman life, and reduction the property damage associated with floods. To mimic\nthe complex mathematical expressions of physical processes of floods, during\nthe past two decades, machine learning (ML) methods contributed highly in the\nadvancement of prediction systems providing better performance and\ncost-effective solutions. Due to the vast benefits and potential of ML, its\npopularity dramatically increased among hydrologists. Researchers through\nintroducing novel ML methods and hybridizing of the existing ones aim at\ndiscovering more accurate and efficient prediction models. The main\ncontribution of this paper is to demonstrate the state of the art of ML models\nin flood prediction and to give insight into the most suitable models. In this\npaper, the literature where ML models were benchmarked through a qualitative\nanalysis of robustness, accuracy, effectiveness, and speed are particularly\ninvestigated to provide an extensive overview on the various ML algorithms used\nin the field. The performance comparison of ML models presents an in-depth\nunderstanding of the different techniques within the framework of a\ncomprehensive evaluation and discussion. As a result, this paper introduces the\nmost promising prediction methods for both long-term and short-term floods.\nFurthermore, the major trends in improving the quality of the flood prediction\nmodels are investigated. Among them, hybridization, data decomposition,\nalgorithm ensemble, and model optimization are reported as the most effective\nstrategies for the improvement of ML methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 18:05:45 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Mosavi", "Amir", ""], ["Ozturk", "Pinar", ""], ["Chau", "Kwok-wing", ""]]}, {"id": "1908.02786", "submitter": "V\\'itor Louren\\c{c}o", "authors": "V\\'itor N. Louren\\c{c}o, Gabriela G. Silva, Leandro A. F. Fernandes", "title": "Hierarchy-of-Visual-Words: a Learning-based Approach for Trademark Image\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present the Hierarchy-of-Visual-Words (HoVW), a novel\ntrademark image retrieval (TIR) method that decomposes images into simpler\ngeometric shapes and defines a descriptor for binary trademark image\nrepresentation by encoding the hierarchical arrangement of component shapes.\nThe proposed hierarchical organization of visual data stores each component\nshape as a visual word. It is capable of representing the geometry of\nindividual elements and the topology of the trademark image, making the\ndescriptor robust against linear as well as to some level of nonlinear\ntransformation. Experiments show that HoVW outperforms previous TIR methods on\nthe MPEG-7 CE-1 and MPEG-7 CE-2 image databases.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 18:19:43 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Louren\u00e7o", "V\u00edtor N.", ""], ["Silva", "Gabriela G.", ""], ["Fernandes", "Leandro A. F.", ""]]}, {"id": "1908.02802", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh, Dianne P O'Leary", "title": "Investigating Decision Boundaries of Trained Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have been the subject of study from various\nperspectives, for example, their training process, interpretation,\ngeneralization error, robustness to adversarial attacks, etc. A trained model\nis defined by its decision boundaries, and therefore, many of the studies about\ndeep learning models speculate about the decision boundaries, and sometimes\nmake simplifying assumptions about them. So far, finding exact points on the\ndecision boundaries of trained deep models has been considered an intractable\nproblem. Here, we compute exact points on the decision boundaries of these\nmodels and provide mathematical tools to investigate the surfaces that define\nthe decision boundaries. Through numerical results, we confirm that some of the\nspeculations about the decision boundaries are accurate, some of the\ncomputational methods can be improved, and some of the simplifying assumptions\nmay be unreliable, for models with nonlinear activation functions. We advocate\nfor verification of simplifying assumptions and approximation methods, wherever\nthey are used. Finally, we demonstrate that the computational practices used\nfor finding adversarial examples can be improved and computing the closest\npoint on the decision boundary reveals the weakest vulnerability of a model\nagainst adversarial attack.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 19:09:22 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""], ["O'Leary", "Dianne P", ""]]}, {"id": "1908.02805", "submitter": "Dongsheng Ding", "authors": "Dongsheng Ding, Xiaohan Wei, Zhuoran Yang, Zhaoran Wang, and Mihailo\n  R. Jovanovi\\'c", "title": "Fast Multi-Agent Temporal-Difference Learning via Homotopy Stochastic\n  Primal-Dual Optimization", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed multi-agent policy evaluation problem in\nreinforcement learning. In our setup, a group of agents with jointly observed\nstates and private local actions and rewards collaborates to learn the value\nfunction of a given policy. When the dimension of state-action space is large,\nthe temporal-difference learning with linear function approximation is widely\nused. Under the assumption that the samples are i.i.d., the best-known\nconvergence rate for multi-agent temporal-difference learning is\n$O(1/\\sqrt{T})$ minimizing the mean square projected Bellman error. In this\npaper, we formulate the temporal-difference learning as a distributed\nstochastic saddle point problem, and propose a new homotopy primal-dual\nalgorithm by adaptively restarting the gradient update from the average of\nprevious iterations. We prove that our algorithm enjoys an $O(1/T)$ convergence\nrate up to logarithmic factors of $T$, thereby significantly improving the\npreviously-known convergence results on multi-agent temporal-difference\nlearning. Furthermore, since our result explicitly takes into account the\nMarkovian nature of the sampling in policy evaluation, it addresses a broader\nclass of problems than the commonly used i.i.d. sampling scenario. From a\nstochastic optimization perspective, to the best of our knowledge, the proposed\nhomotopy primal-dual algorithm is the first to achieve $O(1/T)$ convergence\nrate for distributed stochastic saddle point problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 19:25:37 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 19:43:07 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 05:57:16 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Ding", "Dongsheng", ""], ["Wei", "Xiaohan", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1908.02810", "submitter": "Nithum Thain", "authors": "Flavien Prost, Nithum Thain, Tolga Bolukbasi", "title": "Debiasing Embeddings for Reduced Gender Bias in Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Bolukbasi et al., 2016) demonstrated that pretrained word embeddings can\ninherit gender bias from the data they were trained on. We investigate how this\nbias affects downstream classification tasks, using the case study of\noccupation classification (De-Arteaga et al.,2019). We show that traditional\ntechniques for debiasing embeddings can actually worsen the bias of the\ndownstream classifier by providing a less noisy channel for communicating\ngender information. With a relatively minor adjustment, however, we show how\nthese same techniques can be used to simultaneously reduce bias and maintain\nhigh classification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 19:46:11 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Prost", "Flavien", ""], ["Thain", "Nithum", ""], ["Bolukbasi", "Tolga", ""]]}, {"id": "1908.02830", "submitter": "Raphael Brito", "authors": "Raphael C. Brito and Hansenclever F. Bassani", "title": "Self-Organizing Maps with Variable Input Length for Motif Discovery and\n  Word Segmentation", "comments": null, "journal-ref": "IEEE International Joint Conference on Neural Networks (IJCNN),\n  1-8, July 2018", "doi": "10.1109/IJCNN.2018.8489090", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Time Series Motif Discovery (TSMD) is defined as searching for patterns that\nare previously unknown and appear with a given frequency in time series.\nAnother problem strongly related with TSMD is Word Segmentation. This problem\nhas received much attention from the community that studies early language\nacquisition in babies and toddlers. The development of biologically plausible\nmodels for word segmentation could greatly advance this field. Therefore, in\nthis article, we propose the Variable Input Length Map (VILMAP) for Motif\nDiscovery and Word Segmentation. The model is based on the Self-Organizing Maps\nand can identify Motifs with different lengths in time series. In our\nexperiments, we show that VILMAP presents good results in finding Motifs in a\nstandard Motif discovery dataset and can avoid catastrophic forgetting when\ntrained with datasets with increasing values of input size. We also show that\nVILMAP achieves results similar or superior to other methods in the literature\ndeveloped for the task of word segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 20:52:19 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Brito", "Raphael C.", ""], ["Bassani", "Hansenclever F.", ""]]}, {"id": "1908.02831", "submitter": "Scott Gigante", "authors": "Scott Gigante, Adam S. Charles, Smita Krishnaswamy, Gal Mishne", "title": "Visualizing the PHATE of Neural Networks", "comments": null, "journal-ref": "Neural Information Processing Systems (2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding why and how certain neural networks outperform others is key to\nguiding future development of network architectures and optimization methods.\nTo this end, we introduce a novel visualization algorithm that reveals the\ninternal geometry of such networks: Multislice PHATE (M-PHATE), the first\nmethod designed explicitly to visualize how a neural network's hidden\nrepresentations of data evolve throughout the course of training. We\ndemonstrate that our visualization provides intuitive, detailed summaries of\nthe learning dynamics beyond simple global measures (i.e., validation loss and\naccuracy), without the need to access validation data. Furthermore, M-PHATE\nbetter captures both the dynamics and community structure of the hidden units\nas compared to visualization based on standard dimensionality reduction methods\n(e.g., ISOMAP, t-SNE). We demonstrate M-PHATE with two vignettes: continual\nlearning and generalization. In the former, the M-PHATE visualizations display\nthe mechanism of \"catastrophic forgetting\" which is a major challenge for\nlearning in task-switching contexts. In the latter, our visualizations reveal\nhow increased heterogeneity among hidden units correlates with improved\ngeneralization performance. An implementation of M-PHATE, along with scripts to\nreproduce the figures in this paper, is available at\nhttps://github.com/scottgigante/M-PHATE.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 20:53:30 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gigante", "Scott", ""], ["Charles", "Adam S.", ""], ["Krishnaswamy", "Smita", ""], ["Mishne", "Gal", ""]]}, {"id": "1908.02858", "submitter": "Tom Diethe", "authors": "Tom Diethe, Meelis Kull, Niall Twomey, Kacper Sokol, Hao Song, Miquel\n  Perello-Nieto, Emma Tonkin and Peter Flach", "title": "HyperStream: a Workflow Engine for Streaming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes HyperStream, a large-scale, flexible and robust software\npackage, written in the Python language, for processing streaming data with\nworkflow creation capabilities. HyperStream overcomes the limitations of other\ncomputational engines and provides high-level interfaces to execute complex\nnesting, fusion, and prediction both in online and offline forms in streaming\nenvironments. HyperStream is a general purpose tool that is well-suited for the\ndesign, development, and deployment of Machine Learning algorithms and\npredictive models in a wide space of sequential predictive problems.\n  Source code, installation instructions, examples, and documentation can be\nfound at: https://github.com/IRC-SPHERE/HyperStream.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 22:08:57 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Diethe", "Tom", ""], ["Kull", "Meelis", ""], ["Twomey", "Niall", ""], ["Sokol", "Kacper", ""], ["Song", "Hao", ""], ["Perello-Nieto", "Miquel", ""], ["Tonkin", "Emma", ""], ["Flach", "Peter", ""]]}, {"id": "1908.02876", "submitter": "Shabnam Ghaffarzadegan", "authors": "Bongjun Kim and Shabnam Ghaffarzadegan", "title": "Self-supervised Attention Model for Weakly Labeled Audio Event\n  Classification", "comments": null, "journal-ref": "European Signal Processing Conference, EUSIPCO 2019", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel weakly labeled Audio Event Classification approach based\non a self-supervised attention model. The weakly labeled framework is used to\neliminate the need for expensive data labeling procedure and self-supervised\nattention is deployed to help a model distinguish between relevant and\nirrelevant parts of a weakly labeled audio clip in a more effective manner\ncompared to prior attention models. We also propose a highly effective strongly\nsupervised attention model when strong labels are available. This model also\nserves as an upper bound for the self-supervised model. The performances of the\nmodel with self-supervised attention training are comparable to the strongly\nsupervised one which is trained using strong labels. We show that our\nself-supervised attention method is especially beneficial for short audio\nevents. We achieve 8.8% and 17.6% relative mean average precision improvements\nover the current state-of-the-art systems for SL-DCASE-17 and balanced\nAudioSet.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 23:48:34 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Kim", "Bongjun", ""], ["Ghaffarzadegan", "Shabnam", ""]]}, {"id": "1908.02877", "submitter": "Aaron Reite", "authors": "Aaron Reite, Scott Kangas, Zackery Steck, Steven Goley, Jonathan Von\n  Stroh, and Steven Forsyth", "title": "Unsupervised Feature Learning in Remote Sensing", "comments": null, "journal-ref": null, "doi": "10.1117/12.2529791", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for labeled data is among the most common and well-known practical\nobstacles to deploying deep learning algorithms to solve real-world problems.\nThe current generation of learning algorithms requires a large volume of data\nlabeled according to a static and pre-defined schema. Conversely, humans can\nquickly learn generalizations based on large quantities of unlabeled data, and\nturn these generalizations into classifications using spontaneous labels, often\nincluding labels not seen before. We apply a state-of-the-art unsupervised\nlearning algorithm to the noisy and extremely imbalanced xView data set to\ntrain a feature extractor that adapts to several tasks: visual similarity\nsearch that performs well on both common and rare classes; identifying outliers\nwithin a labeled data set; and learning a natural class hierarchy\nautomatically.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 23:48:49 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Reite", "Aaron", ""], ["Kangas", "Scott", ""], ["Steck", "Zackery", ""], ["Goley", "Steven", ""], ["Von Stroh", "Jonathan", ""], ["Forsyth", "Steven", ""]]}, {"id": "1908.02894", "submitter": "Ellen Vitercik", "authors": "Maria-Florina Balcan, Dan DeBlasio, Travis Dick, Carl Kingsford,\n  Tuomas Sandholm, Ellen Vitercik", "title": "How much data is sufficient to learn high-performing algorithms?\n  Generalization guarantees for data-driven algorithm design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms often have tunable parameters that impact performance metrics such\nas runtime and solution quality. For many algorithms used in practice, no\nparameter settings admit meaningful worst-case bounds, so the parameters are\nmade available for the user to tune. Alternatively, parameters may be tuned\nimplicitly within the proof of a worst-case approximation ratio or runtime\nbound. Worst-case instances, however, may be rare or nonexistent in practice. A\ngrowing body of research has demonstrated that data-driven algorithm design can\nlead to significant improvements in performance. This approach uses a training\nset of problem instances sampled from an unknown, application-specific\ndistribution and returns a parameter setting with strong average performance on\nthe training set.\n  We provide a broadly applicable theory for deriving generalization guarantees\nthat bound the difference between the algorithm's average performance over the\ntraining set and its expected performance. Our results apply no matter how the\nparameters are tuned, be it via an automated or manual approach. The challenge\nis that for many types of algorithms, performance is a volatile function of the\nparameters: slightly perturbing the parameters can cause large changes in\nbehavior. Prior research has proved generalization bounds by employing\ncase-by-case analyses of greedy algorithms, clustering algorithms, integer\nprogramming algorithms, and selling mechanisms. We uncover a unifying structure\nwhich we use to prove extremely general guarantees, yet we recover the bounds\nfrom prior research. Our guarantees apply whenever an algorithm's performance\nis a piecewise-constant, -linear, or -- more generally -- piecewise-structured\nfunction of its parameters. Our theory also implies novel bounds for voting\nmechanisms and dynamic programming algorithms from computational biology.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 01:08:08 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 14:37:55 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 18:41:19 GMT"}, {"version": "v4", "created": "Sun, 25 Apr 2021 22:01:32 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["DeBlasio", "Dan", ""], ["Dick", "Travis", ""], ["Kingsford", "Carl", ""], ["Sandholm", "Tuomas", ""], ["Vitercik", "Ellen", ""]]}, {"id": "1908.02910", "submitter": "Y. X. Rachel Wang", "authors": "Tung-Yu Wu, Y. X. Rachel Wang, Wing H. Wong", "title": "Mini-batch Metropolis-Hastings MCMC with Reversible SGLD Proposal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional MCMC algorithms are computationally intensive and do not scale\nwell to large data. In particular, the Metropolis-Hastings (MH) algorithm\nrequires passing over the entire dataset to evaluate the likelihood ratio in\neach iteration. We propose a general framework for performing MH-MCMC using\nmini-batches of the whole dataset and show that this gives rise to\napproximately a tempered stationary distribution. We prove that the algorithm\npreserves the modes of the original target distribution and derive an error\nbound on the approximation with mild assumptions on the likelihood. To further\nextend the utility of the algorithm to high dimensional settings, we construct\na proposal with forward and reverse moves using stochastic gradient and show\nthat the construction leads to reasonable acceptance probabilities. We\ndemonstrate the performance of our algorithm in both low dimensional models and\nhigh dimensional neural network applications. Particularly in the latter case,\ncompared to popular optimization methods, our method is more robust to the\nchoice of learning rate and improves testing accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 03:06:12 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 14:14:42 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Wu", "Tung-Yu", ""], ["Wang", "Y. X. Rachel", ""], ["Wong", "Wing H.", ""]]}, {"id": "1908.02947", "submitter": "Sourav Mukherjee", "authors": "Sourav Mukherjee, Tim Oates, Ryan Wright", "title": "Graph Node Embeddings using Domain-Aware Biased Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent proliferation of publicly available graph-structured data has\nsparked an interest in machine learning algorithms for graph data. Since most\ntraditional machine learning algorithms assume data to be tabular, embedding\nalgorithms for mapping graph data to real-valued vector spaces has become an\nactive area of research. Existing graph embedding approaches are based purely\non structural information and ignore any semantic information from the\nunderlying domain. In this paper, we demonstrate that semantic information can\nplay a useful role in computing graph embeddings. Specifically, we present a\nframework for devising embedding strategies aware of domain-specific\ninterpretations of graph nodes and edges, and use knowledge of downstream\nmachine learning tasks to identify relevant graph substructures. Using two\nreal-life domains, we show that our framework yields embeddings that are simple\nto implement and yet achieve equal or greater accuracy in machine learning\ntasks compared to domain independent approaches.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 06:45:05 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Mukherjee", "Sourav", ""], ["Oates", "Tim", ""], ["Wright", "Ryan", ""]]}, {"id": "1908.02974", "submitter": "Limei Cheng", "authors": "Tianhao Chen, Limei Cheng, Yang Liu, Wenchuan Jia and Shugen Ma", "title": "Incremental Reinforcement Learning --- a New Continuous Reinforcement\n  Learning Frame Based on Stochastic Differential Equation methods", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous reinforcement learning such as DDPG and A3C are widely used in\nrobot control and autonomous driving. However, both methods have theoretical\nweaknesses. While DDPG cannot control noises in the control process, A3C does\nnot satisfy the continuity conditions under the Gaussian policy. To address\nthese concerns, we propose a new continues reinforcement learning method based\non stochastic differential equations and we call it Incremental Reinforcement\nLearning (IRL). This method not only guarantees the continuity of actions\nwithin any time interval, but controls the variance of actions in the training\nprocess. In addition, our method does not assume Markov control in agents'\naction control and allows agents to predict scene changes for action selection.\nWith our method, agents no longer passively adapt to the environment. Instead,\nthey positively interact with the environment for maximum rewards.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 08:38:11 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Chen", "Tianhao", ""], ["Cheng", "Limei", ""], ["Liu", "Yang", ""], ["Jia", "Wenchuan", ""], ["Ma", "Shugen", ""]]}, {"id": "1908.02984", "submitter": "Seokil Hong", "authors": "Dongmin Park, Seokil Hong, Bohyung Han, Kyoung Mu Lee", "title": "Continual Learning by Asymmetric Loss Approximation with Single-Side\n  Overestimation", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting is a critical challenge in training deep neural\nnetworks. Although continual learning has been investigated as a countermeasure\nto the problem, it often suffers from the requirements of additional network\ncomponents and the limited scalability to a large number of tasks. We propose a\nnovel approach to continual learning by approximating a true loss function\nusing an asymmetric quadratic function with one of its sides overestimated. Our\nalgorithm is motivated by the empirical observation that the network parameter\nupdates affect the target loss functions asymmetrically. In the proposed\ncontinual learning framework, we estimate an asymmetric loss function for the\ntasks considered in the past through a proper overestimation of its unobserved\nsides in training new tasks, while deriving the accurate model parameter for\nthe observable sides. In contrast to existing approaches, our method is free\nfrom the side effects and achieves the state-of-the-art accuracy that is even\nclose to the upper-bound performance on several challenging benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 09:21:21 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 03:25:38 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Park", "Dongmin", ""], ["Hong", "Seokil", ""], ["Han", "Bohyung", ""], ["Lee", "Kyoung Mu", ""]]}, {"id": "1908.02995", "submitter": "Tatsuya Yokota", "authors": "Tatsuya Yokota, Hidekata Hontani, Qibin Zhao, Andrzej Cichocki", "title": "Manifold Modeling in Embedded Space: A Perspective for Interpreting Deep\n  Image Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep image prior (DIP), which utilizes a deep convolutional network (ConvNet)\nstructure itself as an image prior, has attracted attentions in computer vision\nand machine learning communities. It empirically shows the effectiveness of\nConvNet structure for various image restoration applications. However, why the\nDIP works so well is still unknown, and why convolution operation is useful for\nimage reconstruction or enhancement is not very clear. In this study, we tackle\nthese questions. The proposed approach is dividing the convolution into\n``delay-embedding'' and ``transformation (\\ie encoder-decoder)'', and proposing\na simple, but essential, image/tensor modeling method which is closely related\nto dynamical systems and self-similarity. The proposed method named as manifold\nmodeling in embedded space (MMES) is implemented by using a novel\ndenoising-auto-encoder in combination with multi-way delay-embedding transform.\nIn spite of its simplicity, the image/tensor completion, super-resolution,\ndeconvolution, and denoising results of MMES are quite similar even competitive\nto DIP in our extensive experiments, and these results would help us for\nreinterpreting/characterizing the DIP from a perspective of ``low-dimensional\npatch-manifold prior''.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 10:05:09 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 08:14:35 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yokota", "Tatsuya", ""], ["Hontani", "Hidekata", ""], ["Zhao", "Qibin", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1908.02997", "submitter": "Mahawaga Arachchige Pathum Chamikara", "authors": "M.A.P. Chamikara, P. Bertok, I. Khalil, D. Liu, S. Camtepe, M.\n  Atiquzzaman", "title": "Local Differential Privacy for Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2019.2952146", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The internet of things (IoT) is transforming major industries including but\nnot limited to healthcare, agriculture, finance, energy, and transportation.\nIoT platforms are continually improving with innovations such as the\namalgamation of software-defined networks (SDN) and network function\nvirtualization (NFV) in the edge-cloud interplay. Deep learning (DL) is\nbecoming popular due to its remarkable accuracy when trained with a massive\namount of data, such as generated by IoT. However, DL algorithms tend to leak\nprivacy when trained on highly sensitive crowd-sourced data such as medical\ndata. Existing privacy-preserving DL algorithms rely on the traditional\nserver-centric approaches requiring high processing powers. We propose a new\nlocal differentially private (LDP) algorithm named LATENT that redesigns the\ntraining process. LATENT enables a data owner to add a randomization layer\nbefore data leave the data owners' devices and reach a potentially untrusted\nmachine learning service. This feature is achieved by splitting the\narchitecture of a convolutional neural network (CNN) into three layers: (1)\nconvolutional module, (2) randomization module, and (3) fully connected module.\nHence, the randomization module can operate as an NFV privacy preservation\nservice in an SDN-controlled NFV, making LATENT more practical for IoT-driven\ncloud-based environments compared to existing approaches. The randomization\nmodule employs a newly proposed LDP protocol named utility enhancing\nrandomization, which allows LATENT to maintain high utility compared to\nexisting LDP protocols. Our experimental evaluation of LATENT on convolutional\ndeep neural networks demonstrates excellent accuracy (e.g. 91%- 96%) with high\nmodel quality even under low privacy budgets (e.g. $\\varepsilon=0.5$).\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 10:13:56 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 06:00:24 GMT"}, {"version": "v3", "created": "Sat, 9 Nov 2019 07:21:59 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Chamikara", "M. A. P.", ""], ["Bertok", "P.", ""], ["Khalil", "I.", ""], ["Liu", "D.", ""], ["Camtepe", "S.", ""], ["Atiquzzaman", "M.", ""]]}, {"id": "1908.02999", "submitter": "Fabian Schilling", "authors": "Fabian Schilling and Julien Lecoeur and Fabrizio Schiano and Dario\n  Floreano", "title": "Learning Vision-based Flight in Drone Swarms by Imitation", "comments": "8 pages, 8 figures, accepted for publication in the IEEE Robotics and\n  Automation Letters (RA-L) on July 28, 2019. arXiv admin note: substantial\n  text overlap with arXiv:1809.00543", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized drone swarms deployed today either rely on sharing of positions\namong agents or detecting swarm members with the help of visual markers. This\nwork proposes an entirely visual approach to coordinate markerless drone swarms\nbased on imitation learning. Each agent is controlled by a small and efficient\nconvolutional neural network that takes raw omnidirectional images as inputs\nand predicts 3D velocity commands that match those computed by a flocking\nalgorithm. We start training in simulation and propose a simple yet effective\nunsupervised domain adaptation approach to transfer the learned controller to\nthe real world. We further train the controller with data collected in our\nmotion capture hall. We show that the convolutional neural network trained on\nthe visual inputs of the drone can learn not only robust inter-agent collision\navoidance but also cohesion of the swarm in a sample-efficient manner. The\nneural controller effectively learns to localize other agents in the visual\ninput, which we show by visualizing the regions with the most influence on the\nmotion of an agent. We remove the dependence on sharing positions among swarm\nmembers by taking only local visual information into account for control. Our\nwork can therefore be seen as the first step towards a fully decentralized,\nvision-based swarm without the need for communication or visual markers.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 10:19:48 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Schilling", "Fabian", ""], ["Lecoeur", "Julien", ""], ["Schiano", "Fabrizio", ""], ["Floreano", "Dario", ""]]}, {"id": "1908.03000", "submitter": "Marcell Wolnitza", "authors": "Marcell Wolnitza and Babette Dellen", "title": "Feature selection of neural networks is skewed towards the less abstract\n  cue", "comments": "8 pages, 5 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs) have become an important tool for image\nclassification with many applications in research and industry. However, it\nremains largely unknown how relevant image features are selected and how data\nproperties affect this process. In particular, we are interested whether the\nabstraction level of image cues correlating with class membership influences\nfeature selection. We perform experiments with binary images that contain a\ncombination of cues, representing two different levels of abstractions: one is\na pattern drawn from a random distribution where class membership correlates\nwith the statistics of the pattern, the other a combination of symbol-like\nentities, where the symbolic code correlates with class membership. When the\nnetwork is trained with data in which both cues are equally significant, we\nobserve that the cues at the lower abstraction level, i.e., the pattern, is\nlearned, while the symbolic information is largely ignored, even in networks\nwith many layers. Symbol-like entities are only learned if the importance of\nlow-level cues is reduced compared to the high-level ones. These findings raise\nimportant questions about the relevance of features that are learned by deep\nANNs and how learning could be shifted towards symbolic features.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 10:24:37 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Wolnitza", "Marcell", ""], ["Dellen", "Babette", ""]]}, {"id": "1908.03006", "submitter": "Markus Haltmeier", "authors": "Daniel Obmann, Linh Nguyen, Johannes Schwab, Markus Haltmeier", "title": "Augmented NETT Regularization of Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose aNETT (augmented NETwork Tikhonov) regularization as a novel\ndata-driven reconstruction framework for solving inverse problems. An\nencoder-decoder type network defines a regularizer consisting of a penalty term\nthat enforces regularity in the encoder domain, augmented by a penalty that\npenalizes the distance to the data manifold. We present a rigorous convergence\nanalysis including stability estimates and convergence rates. For that purpose,\nwe prove the coercivity of the regularizer used without requiring explicit\ncoercivity assumptions for the networks involved. We propose a possible\nrealization together with a network architecture and a modular training\nstrategy. Applications to sparse-view and low-dose CT show that aNETT achieves\nresults comparable to state-of-the-art deep-learning-based reconstruction\nmethods. Unlike learned iterative methods, aNETT does not require repeated\napplication of the forward and adjoint models, which enables the use of aNETT\nfor inverse problems with numerically expensive forward models. Furthermore, we\nshow that aNETT trained on coarsely sampled data can leverage an increased\nsampling rate without the need for retraining.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 10:38:01 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 08:45:06 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 21:40:57 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Obmann", "Daniel", ""], ["Nguyen", "Linh", ""], ["Schwab", "Johannes", ""], ["Haltmeier", "Markus", ""]]}, {"id": "1908.03009", "submitter": "Danilo Comminiello", "authors": "Antonio Falvo, Danilo Comminiello, Simone Scardapane, Michele\n  Scarpiniti, Aurelio Uncini", "title": "A Multimodal Deep Network for the Reconstruction of T2W MR Images", "comments": "29th Italian Neural Networks Workshop (WIRN 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple sclerosis is one of the most common chronic neurological diseases\naffecting the central nervous system. Lesions produced by the MS can be\nobserved through two modalities of magnetic resonance (MR), known as T2W and\nFLAIR sequences, both providing useful information for formulating a diagnosis.\nHowever, long acquisition time makes the acquired MR image vulnerable to motion\nartifacts. This leads to the need of accelerating the execution of the MR\nanalysis. In this paper, we present a deep learning method that is able to\nreconstruct subsampled MR images obtained by reducing the k-space data, while\nmaintaining a high image quality that can be used to observe brain lesions. The\nproposed method exploits the multimodal approach of neural networks and it also\nfocuses on the data acquisition and processing stages to reduce execution time\nof the MR analysis. Results prove the effectiveness of the proposed method in\nreconstructing subsampled MR images while saving execution time.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 10:46:28 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 15:50:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Falvo", "Antonio", ""], ["Comminiello", "Danilo", ""], ["Scardapane", "Simone", ""], ["Scarpiniti", "Michele", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1908.03015", "submitter": "Felix Berkhahn", "authors": "Felix Berkhahn, Richard Keys, Wajih Ouertani, Nikhil Shetty, and\n  Dominik Gei{\\ss}ler", "title": "Augmenting Variational Autoencoders with Sparse Labels: A Unified\n  Framework for Unsupervised, Semi-(un)supervised, and Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a new flavor of Variational Autoencoder (VAE) that interpolates\nseamlessly between unsupervised, semi-supervised and fully supervised learning\ndomains. We show that unlabeled datapoints not only boost unsupervised tasks,\nbut also the classification performance. Vice versa, every label not only\nimproves classification, but also unsupervised tasks. The proposed architecture\nis simple: A classification layer is connected to the topmost encoder layer,\nand then combined with the resampled latent layer for the decoder. The usual\nevidence lower bound (ELBO) loss is supplemented with a supervised loss target\non this classification layer that is only applied for labeled datapoints. This\nsimplicity allows for extending any existing VAE model to our proposed\nsemi-supervised framework with minimal effort. In the context of\nclassification, we found that this approach even outperforms a direct\nsupervised setup.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 11:07:22 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 13:58:00 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Berkhahn", "Felix", ""], ["Keys", "Richard", ""], ["Ouertani", "Wajih", ""], ["Shetty", "Nikhil", ""], ["Gei\u00dfler", "Dominik", ""]]}, {"id": "1908.03020", "submitter": "Adam White Dr", "authors": "Adam White and Artur d'Avila Garcez", "title": "Measurable Counterfactual Local Explanations for Any Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel method for explaining the predictions of any classifier.\nIn our approach, local explanations are expected to explain both the outcome of\na prediction and how that prediction would change if 'things had been\ndifferent'. Furthermore, we argue that satisfactory explanations cannot be\ndissociated from a notion and measure of fidelity, as advocated in the early\ndays of neural networks' knowledge extraction. We introduce a definition of\nfidelity to the underlying classifier for local explanation models which is\nbased on distances to a target decision boundary. A system called CLEAR:\nCounterfactual Local Explanations via Regression, is introduced and evaluated.\nCLEAR generates w-counterfactual explanations that state minimum changes\nnecessary to flip a prediction's classification. CLEAR then builds local\nregression models, using the w-counterfactuals to measure and improve the\nfidelity of its regressions. By contrast, the popular LIME method, which also\nuses regression to generate local explanations, neither measures its own\nfidelity nor generates counterfactuals. CLEAR's regressions are found to have\nsignificantly higher fidelity than LIME's, averaging over 45% higher in this\npaper's four case studies.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 11:16:22 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 02:00:56 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["White", "Adam", ""], ["Garcez", "Artur d'Avila", ""]]}, {"id": "1908.03032", "submitter": "Michael Rapp", "authors": "Michael Rapp, Eneldo Loza Menc\\'ia, Johannes F\\\"urnkranz", "title": "On the Trade-off Between Consistency and Coverage in Multi-label Rule\n  Learning Heuristics", "comments": "Preprint version. To appear in Proceedings of the 22nd International\n  Conference on Discovery Science, 2019", "journal-ref": "Proc. DS 2019: 96-111", "doi": "10.1007/978-3-030-33778-0_9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several authors have advocated the use of rule learning algorithms\nto model multi-label data, as rules are interpretable and can be comprehended,\nanalyzed, or qualitatively evaluated by domain experts. Many rule learning\nalgorithms employ a heuristic-guided search for rules that model regularities\ncontained in the training data and it is commonly accepted that the choice of\nthe heuristic has a significant impact on the predictive performance of the\nlearner. Whereas the properties of rule learning heuristics have been studied\nin the realm of single-label classification, there is no such work taking into\naccount the particularities of multi-label classification. This is surprising,\nas the quality of multi-label predictions is usually assessed in terms of a\nvariety of different, potentially competing, performance measures that cannot\nall be optimized by a single learner at the same time. In this work, we show\nempirically that it is crucial to trade off the consistency and coverage of\nrules differently, depending on which multi-label measure should be optimized\nby a model. Based on these findings, we emphasize the need for configurable\nlearners that can flexibly use different heuristics. As our experiments reveal,\nthe choice of the heuristic is not straight-forward, because a search for rules\nthat optimize a measure locally does usually not result in a model that\nmaximizes that measure globally.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 12:13:18 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Rapp", "Michael", ""], ["Menc\u00eda", "Eneldo Loza", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1908.03054", "submitter": "Shruti Gupta", "authors": "Shruti Gupta, Md. Shah Fahad, Akshay Deepak", "title": "Pitch-Synchronous Single Frequency Filtering Spectrogram for Speech\n  Emotion Recognition", "comments": "11 pages and less than 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) are widely used for speech emotion\nrecognition (SER). In such cases, the short time fourier transform (STFT)\nspectrogram is the most popular choice for representing speech, which is fed as\ninput to the CNN. However, the uncertainty principles of the short-time Fourier\ntransform prevent it from capturing time and frequency resolutions\nsimultaneously. On the other hand, the recently proposed single frequency\nfiltering (SFF) spectrogram promises to be a better alternative because it\ncaptures both time and frequency resolutions simultaneously. In this work, we\nexplore the SFF spectrogram as an alternative representation of speech for SER.\nWe have modified the SFF spectrogram by taking the average of the amplitudes of\nall the samples between two successive glottal closure instants (GCI)\nlocations. The duration between two successive GCI locations gives the pitch,\nmotivating us to name the modified SFF spectrogram as pitch-synchronous SFF\nspectrogram. The GCI locations were detected using zero frequency filtering\napproach. The proposed pitch-synchronous SFF spectrogram produced accuracy\nvalues of 63.95% (unweighted) and 70.4% (weighted) on the IEMOCAP dataset.\nThese correspond to an improvement of +7.35% (unweighted) and +4.3% (weighted)\nover state-of-the-art result on the STFT sepctrogram using CNN. Specially, the\nproposed method recognized 22.7% of the happy emotion samples correctly,\nwhereas this number was 0% for state-of-the-art results. These results also\npromise a much wider use of the proposed pitch-synchronous SFF spectrogram for\nother speech-based applications.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 11:49:58 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Gupta", "Shruti", ""], ["Fahad", "Md. Shah", ""], ["Deepak", "Akshay", ""]]}, {"id": "1908.03072", "submitter": "Minsoo Rhu", "authors": "Youngeun Kwon, Yunjae Lee, Minsoo Rhu", "title": "TensorDIMM: A Practical Near-Memory Processing Architecture for\n  Embeddings and Tensor Operations in Deep Learning", "comments": "Accepted for publication at the 52nd IEEE/ACM International Symposium\n  on Microarchitecture (MICRO-52), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies from several hyperscalars pinpoint to embedding layers as the\nmost memory-intensive deep learning (DL) algorithm being deployed in today's\ndatacenters. This paper addresses the memory capacity and bandwidth challenges\nof embedding layers and the associated tensor operations. We present our\nvertically integrated hardware/software co-design, which includes a custom DIMM\nmodule enhanced with near-data processing cores tailored for DL tensor\noperations. These custom DIMMs are populated inside a GPU-centric system\ninterconnect as a remote memory pool, allowing GPUs to utilize for scalable\nmemory bandwidth and capacity expansion. A prototype implementation of our\nproposal on real DL systems shows an average 6.2-17.6x performance improvement\non state-of-the-art recommender systems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 13:45:33 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 11:15:05 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Kwon", "Youngeun", ""], ["Lee", "Yunjae", ""], ["Rhu", "Minsoo", ""]]}, {"id": "1908.03077", "submitter": "Selvaprabu Nadarajah", "authors": "Qihang Lin, Selvaprabu Nadarajah, Negar Soheili, Tianbao Yang", "title": "A Data Efficient and Feasible Level Set Method for Stochastic Convex\n  Optimization with Expectation Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic convex optimization problems with expectation constraints (SOECs)\nare encountered in statistics and machine learning, business, and engineering.\nIn data-rich environments, the SOEC objective and constraints contain\nexpectations defined with respect to large datasets. Therefore, efficient\nalgorithms for solving such SOECs need to limit the fraction of data points\nthat they use, which we refer to as algorithmic data complexity. Recent\nstochastic first order methods exhibit low data complexity when handling SOECs\nbut guarantee near-feasibility and near-optimality only at convergence. These\nmethods may thus return highly infeasible solutions when heuristically\nterminated, as is often the case, due to theoretical convergence criteria being\nhighly conservative. This issue limits the use of first order methods in\nseveral applications where the SOEC constraints encode implementation\nrequirements. We design a stochastic feasible level set method (SFLS) for SOECs\nthat has low data complexity and emphasizes feasibility before convergence.\nSpecifically, our level-set method solves a root-finding problem by calling a\nnovel first order oracle that computes a stochastic upper bound on the\nlevel-set function by extending mirror descent and online validation\ntechniques. We establish that SFLS maintains a high-probability feasible\nsolution at each root-finding iteration and exhibits favorable iteration\ncomplexity compared to state-of-the-art deterministic feasible level set and\nstochastic subgradient methods. Numerical experiments on three diverse\napplications validate the low data complexity of SFLS relative to the former\napproach and highlight how SFLS finds feasible solutions with small optimality\ngaps significantly faster than the latter method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 12:59:19 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 01:03:49 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Lin", "Qihang", ""], ["Nadarajah", "Selvaprabu", ""], ["Soheili", "Negar", ""], ["Yang", "Tianbao", ""]]}, {"id": "1908.03097", "submitter": "Minh-Ngoc Tran", "authors": "Minh-Ngoc Tran and Dang H. Nguyen and Duy Nguyen", "title": "Variational Bayes on Manifolds", "comments": "31 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayes (VB) has become a widely-used tool for Bayesian inference\nin statistics and machine learning. Nonetheless, the development of the\nexisting VB algorithms is so far generally restricted to the case where the\nvariational parameter space is Euclidean, which hinders the potential broad\napplication of VB methods. This paper extends the scope of VB to the case where\nthe variational parameter space is a Riemannian manifold. We develop an\nefficient manifold-based VB algorithm that exploits both the geometric\nstructure of the constraint parameter space and the information geometry of the\nmanifold of VB approximating probability distributions. Our algorithm is\nprovably convergent and achieves a convergence rate of order $\\mathcal\nO(1/\\sqrt{T})$ and $\\mathcal O(1/T^{2-2\\epsilon})$ for a non-convex evidence\nlower bound function and a strongly retraction-convex evidence lower bound\nfunction, respectively. We develop in particular two manifold VB algorithms,\nManifold Gaussian VB and Manifold Neural Net VB, and demonstrate through\nnumerical experiments that the proposed algorithms are stable, less sensitive\nto initialization and compares favourably to existing VB methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 14:38:31 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 00:48:23 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Tran", "Minh-Ngoc", ""], ["Nguyen", "Dang H.", ""], ["Nguyen", "Duy", ""]]}, {"id": "1908.03109", "submitter": "Rishiraj Saha Roy", "authors": "Azin Ghazimatin, Rishiraj Saha Roy, Gerhard Weikum", "title": "FAIRY: A Framework for Understanding Relationships between Users'\n  Actions and their Social Feeds", "comments": "WSDM 2019", "journal-ref": "WSDM 2019", "doi": "10.1145/3289600.3290990", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users increasingly rely on social media feeds for consuming daily\ninformation. The items in a feed, such as news, questions, songs, etc., usually\nresult from the complex interplay of a user's social contacts, her interests\nand her actions on the platform. The relationship of the user's own behavior\nand the received feed is often puzzling, and many users would like to have a\nclear explanation on why certain items were shown to them. Transparency and\nexplainability are key concerns in the modern world of cognitive overload,\nfilter bubbles, user tracking, and privacy risks. This paper presents FAIRY, a\nframework that systematically discovers, ranks, and explains relationships\nbetween users' actions and items in their social media feeds. We model the\nuser's local neighborhood on the platform as an interaction graph, a form of\nheterogeneous information network constructed solely from information that is\neasily accessible to the concerned user. We posit that paths in this\ninteraction graph connecting the user and her feed items can act as pertinent\nexplanations for the user. These paths are scored with a learning-to-rank model\nthat captures relevance and surprisal. User studies on two social platforms\ndemonstrate the practical viability and user benefits of the FAIRY method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 15:08:35 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:04:30 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Ghazimatin", "Azin", ""], ["Roy", "Rishiraj Saha", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1908.03129", "submitter": "Tom Edinburgh", "authors": "Tom Edinburgh, Peter Smielewski, Marek Czosnyka, Stephen J. Eglen, Ari\n  Ercole", "title": "DeepClean -- self-supervised artefact rejection for intensive care\n  waveform data using deep generative learning", "comments": "12 pages, 7 figures, 2 tables; typos corrected, minor changes\n  (results unchanged)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Waveform physiological data is important in the treatment of critically ill\npatients in the intensive care unit. Such recordings are susceptible to\nartefacts, which must be removed before the data can be re-used for alerting or\nreprocessed for other clinical or research purposes. Accurate removal of\nartefacts reduces bias and uncertainty in clinical assessment, as well as the\nfalse positive rate of intensive care unit alarms, and is therefore a key\ncomponent in providing optimal clinical care. In this work, we present\nDeepClean; a prototype self-supervised artefact detection system using a\nconvolutional variational autoencoder deep neural network that avoids costly\nand painstaking manual annotation, requiring only easily-obtained 'good' data\nfor training. For a test case with invasive arterial blood pressure, we\ndemonstrate that our algorithm can detect the presence of an artefact within a\n10-second sample of data with sensitivity and specificity around 90%.\nFurthermore, DeepClean was able to identify regions of artefact within such\nsamples with high accuracy and we show that it significantly outperforms a\nbaseline principle component analysis approach in both signal reconstruction\nand artefact detection. DeepClean learns a generative model and therefore may\nalso be used for imputation of missing data.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 15:41:04 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 10:16:14 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 15:55:53 GMT"}, {"version": "v4", "created": "Sun, 5 Jan 2020 18:16:39 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Edinburgh", "Tom", ""], ["Smielewski", "Peter", ""], ["Czosnyka", "Marek", ""], ["Eglen", "Stephen J.", ""], ["Ercole", "Ari", ""]]}, {"id": "1908.03142", "submitter": "Chen Ma", "authors": "Chen Ma", "title": "The Hitchhiker's Guide to LDA", "comments": "148 pages, in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet Allocation (LDA) model is a famous model in the topic model\nfield, it has been studied for years due to its extensive application value in\nindustry and academia. However, the mathematical derivation of LDA model is\nchallenging and difficult, which makes it difficult for the beginners to learn.\nTo help the beginners in learning LDA, this book analyzes the mathematical\nderivation of LDA in detail, and it also introduces all the knowledge\nbackground to make it easy for beginners to understand. Thus, this book\ncontains the author's unique insights. It should be noted that this book is\nwritten in Chinese.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 03:59:19 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 12:41:30 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ma", "Chen", ""]]}, {"id": "1908.03156", "submitter": "Jayadev Acharya", "authors": "Jayadev Acharya, Ananda Theertha Suresh", "title": "Optimal multiclass overfitting by sequence reconstruction from Hamming\n  queries", "comments": "extended the results to unknown test set case", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A primary concern of excessive reuse of test datasets in machine learning is\nthat it can lead to overfitting. Multiclass classification was recently shown\nto be more resistant to overfitting than binary classification. In an open\nproblem of COLT 2019, Feldman, Frostig, and Hardt ask to characterize the\ndependence of the amount of overfitting bias with the number of classes $m$,\nthe number of accuracy queries $k$, and the number of examples in the dataset\n$n$. We resolve this problem and determine the amount of overfitting possible\nin multi-class classification. We provide computationally efficient algorithms\nthat achieve overfitting bias of $\\tilde{\\Theta}(\\max\\{\\sqrt{{k}/{(mn)}},\nk/n\\})$, matching the known upper bounds.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 16:34:06 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 14:04:32 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Acharya", "Jayadev", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "1908.03173", "submitter": "Sajjad Abdoli", "authors": "Sajjad Abdoli, Luiz G. Hafemann, Jerome Rony, Ismail Ben Ayed, Patrick\n  Cardinal, Alessandro L. Koerich", "title": "Universal Adversarial Audio Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the existence of universal adversarial perturbations, which\ncan fool a family of audio classification architectures, for both targeted and\nuntargeted attack scenarios. We propose two methods for finding such\nperturbations. The first method is based on an iterative, greedy approach that\nis well-known in computer vision: it aggregates small perturbations to the\ninput so as to push it to the decision boundary. The second method, which is\nthe main contribution of this work, is a novel penalty formulation, which finds\ntargeted and untargeted universal adversarial perturbations. Differently from\nthe greedy approach, the penalty method minimizes an appropriate objective\nfunction on a batch of samples. Therefore, it produces more successful attacks\nwhen the number of training samples is limited. Moreover, we provide a proof\nthat the proposed penalty method theoretically converges to a solution that\ncorresponds to universal adversarial perturbations. We also demonstrate that it\nis possible to provide successful attacks using the penalty method when only\none sample from the target dataset is available for the attacker. Experimental\nresults on attacking various 1D CNN architectures have shown attack success\nrates higher than 85.0% and 83.1% for targeted and untargeted attacks,\nrespectively using the proposed penalty method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 17:07:30 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 15:52:28 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 21:51:14 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 21:16:48 GMT"}, {"version": "v5", "created": "Tue, 17 Nov 2020 00:42:45 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Abdoli", "Sajjad", ""], ["Hafemann", "Luiz G.", ""], ["Rony", "Jerome", ""], ["Ayed", "Ismail Ben", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro L.", ""]]}, {"id": "1908.03176", "submitter": "Sobhan Soleymani", "authors": "Sobhan Soleymani, Ali Dabouei, Jeremy Dawson, Nasser M. Nasrabadi", "title": "Defending Against Adversarial Iris Examples Using Wavelet Decomposition", "comments": "The Tenth IEEE International Conference on Biometrics: Theory,\n  Applications, and Systems (BTAS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have presented impressive performance in biometric\napplications. However, their performance is highly at risk when facing\ncarefully crafted input samples known as adversarial examples. In this paper,\nwe present three defense strategies to detect adversarial iris examples. These\ndefense strategies are based on wavelet domain denoising of the input examples\nby investigating each wavelet sub-band and removing the sub-bands that are most\naffected by the adversary. The first proposed defense strategy reconstructs\nmultiple denoised versions of the input example through manipulating the mid-\nand high-frequency components of the wavelet domain representation of the input\nexample and makes a decision upon the classification result of the majority of\nthe denoised examples. The second and third proposed defense strategies aim to\ndenoise each wavelet domain sub-band and determine the sub-bands that are most\nlikely affected by the adversary using the reconstruction error computed for\neach sub-band. We test the performance of the proposed defense strategies\nagainst several attack scenarios and compare the results with five state of the\nart defense strategies.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 17:08:25 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Soleymani", "Sobhan", ""], ["Dabouei", "Ali", ""], ["Dawson", "Jeremy", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "1908.03182", "submitter": "Evan Shelhamer", "authors": "Dequan Wang, Evan Shelhamer, Bruno Olshausen, Trevor Darrell", "title": "Dynamic Scale Inference by Entropy Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the variety of the visual world there is not one true scale for\nrecognition: objects may appear at drastically different sizes across the\nvisual field. Rather than enumerate variations across filter channels or\npyramid levels, dynamic models locally predict scale and adapt receptive fields\naccordingly. The degree of variation and diversity of inputs makes this a\ndifficult task. Existing methods either learn a feedforward predictor, which is\nnot itself totally immune to the scale variation it is meant to counter, or\nselect scales by a fixed algorithm, which cannot learn from the given task and\ndata. We extend dynamic scale inference from feedforward prediction to\niterative optimization for further adaptivity. We propose a novel entropy\nminimization objective for inference and optimize over task and structure\nparameters to tune the model to each input. Optimization during inference\nimproves semantic segmentation accuracy and generalizes better to extreme scale\nvariations that cause feedforward dynamic inference to falter.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 17:21:20 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Wang", "Dequan", ""], ["Shelhamer", "Evan", ""], ["Olshausen", "Bruno", ""], ["Darrell", "Trevor", ""]]}, {"id": "1908.03190", "submitter": "Hayden Schaeffer", "authors": "Yifan Sun, Linan Zhang, and Hayden Schaeffer", "title": "NeuPDE: Neural Network Based Ordinary and Partial Differential Equations\n  for Modeling Time-Dependent Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural network based approach for extracting models from dynamic\ndata using ordinary and partial differential equations. In particular, given a\ntime-series or spatio-temporal dataset, we seek to identify an accurate\ngoverning system which respects the intrinsic differential structure. The\nunknown governing model is parameterized by using both (shallow) multilayer\nperceptrons and nonlinear differential terms, in order to incorporate relevant\ncorrelations between spatio-temporal samples. We demonstrate the approach on\nseveral examples where the data is sampled from various dynamical systems and\ngive a comparison to recurrent networks and other data-discovery methods. In\naddition, we show that for MNIST and Fashion MNIST, our approach lowers the\nparameter cost as compared to other deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 17:50:22 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Sun", "Yifan", ""], ["Zhang", "Linan", ""], ["Schaeffer", "Hayden", ""]]}, {"id": "1908.03204", "submitter": "Wenshuai Zhao", "authors": "Wenshuai Zhao, Zengfeng Zeng", "title": "Multi Scale Supervised 3D U-Net for Kidney and Tumor Segmentation", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  U-Net has achieved huge success in various medical image segmentation\nchallenges. Kinds of new architectures with bells and whistles might succeed in\ncertain dataset when employed with optimal hyper-parameter, but their\ngeneralization always can't be guaranteed. Here, we focused on the basic U-Net\narchitecture and proposed a multi scale supervised 3D U-Net for the\nsegmentation task in KiTS19 challenge. To enhance the performance, our work can\nbe summarized as three folds: first, we used multi scale supervision in the\ndecoder pathway, which could encourage the network to predict right results\nfrom the deep layers; second, with the aim to alleviate the bad effect from the\nsample imbalance of kidney and tumor, we adopted exponential logarithmic loss;\nthird, a connected-component based post processing method was designed to\nremove the obviously wrong voxels. In the published KiTS19 training dataset\n(totally 210 patients), we divided 42 patients to be test dataset and finally\nobtained DICE scores of 0.969 and 0.805 for the kidney and tumor respectively.\nIn the challenge, we finally achieved the 7th place among 106 teams with the\nComposite Dice of 0.8961, namely 0.9741 for kidney and 0.8181 for tumor.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 02:41:55 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 15:46:23 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Zhao", "Wenshuai", ""], ["Zeng", "Zengfeng", ""]]}, {"id": "1908.03250", "submitter": "Fabrizio Ventola", "authors": "Fabrizio Ventola, Karl Stelzner, Alejandro Molina and Kristian\n  Kersting", "title": "Random Sum-Product Forests with Residual Links", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tractable yet expressive density estimators are a key building block of\nprobabilistic machine learning. While sum-product networks (SPNs) offer\nattractive inference capabilities, obtaining structures large enough to fit\ncomplex, high-dimensional data has proven challenging. In this paper, we\npresent random sum-product forests (RSPFs), an ensemble approach for mixing\nmultiple randomly generated SPNs. We also introduce residual links, which\nreference specialized substructures of other component SPNs in order to\nleverage the context-specific knowledge encoded within them. Our empirical\nevidence demonstrates that RSPFs provide better performance than their\nindividual components. Adding residual links improves the models further,\nallowing the resulting ResSPNs to be competitive with commonly used structure\nlearning methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 19:55:03 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Ventola", "Fabrizio", ""], ["Stelzner", "Karl", ""], ["Molina", "Alejandro", ""], ["Kersting", "Kristian", ""]]}, {"id": "1908.03263", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Xinyan Yan, Byron Boots", "title": "Trajectory-wise Control Variates for Variance Reduction in Policy\n  Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods have demonstrated success in reinforcement learning\ntasks that have high-dimensional continuous state and action spaces. However,\npolicy gradient methods are also notoriously sample inefficient. This can be\nattributed, at least in part, to the high variance in estimating the gradient\nof the task objective with Monte Carlo methods. Previous research has\nendeavored to contend with this problem by studying control variates (CVs) that\ncan reduce the variance of estimates without introducing bias, including the\nearly use of baselines, state dependent CVs, and the more recent state-action\ndependent CVs. In this work, we analyze the properties and drawbacks of\nprevious CV techniques and, surprisingly, we find that these works have\noverlooked an important fact that Monte Carlo gradient estimates are generated\nby trajectories of states and actions. We show that ignoring the correlation\nacross the trajectories can result in suboptimal variance reduction, and we\npropose a simple fix: a class of \"trajectory-wise\" CVs, that can further drive\ndown the variance. We show that constructing trajectory-wise CVs can be done\nrecursively and requires only learning state-action value functions like the\nprevious CVs for policy gradient. We further prove that the proposed\ntrajectory-wise CVs are optimal for variance reduction under reasonable\nassumptions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 20:35:53 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Cheng", "Ching-An", ""], ["Yan", "Xinyan", ""], ["Boots", "Byron", ""]]}, {"id": "1908.03264", "submitter": "Ruben Sanchez-Romero", "authors": "Ruben Sanchez-Romero, Joseph D. Ramsey, Kun Zhang, Clark Glymour", "title": "Identification of Effective Connectivity Subregions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard fMRI connectivity analyses depend on aggregating the time series of\nindividual voxels within regions of interest (ROIs). In certain cases, this\nspatial aggregation implies a loss of valuable functional and anatomical\ninformation about smaller subsets of voxels that drive the ROI level\nconnectivity. We use two recently published graphical search methods to\nidentify subsets of voxels that are highly responsible for the connectivity\nbetween larger ROIs. To illustrate the procedure, we apply both methods to\nlongitudinal high-resolution resting state fMRI data from regions in the medial\ntemporal lobe from a single individual. Both methods recovered similar subsets\nof voxels within larger ROIs of entorhinal cortex and hippocampus subfields\nthat also show spatial consistency across different scanning sessions and\nacross hemispheres. In contrast to standard functional connectivity methods,\nboth algorithms applied here are robust against false positive connections\nproduced by common causes and indirect paths (in contrast to Pearson's\ncorrelation) and common effect conditioning (in contrast to partial correlation\nbased approaches). These algorithms allow for identification of subregions of\nvoxels driving the connectivity between regions of interest, recovering\nvaluable anatomical and functional information that is lost when ROIs are\naggregated. Both methods are specially suited for voxelwise connectivity\nresearch, given their running times and scalability to big data problems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 20:43:22 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Sanchez-Romero", "Ruben", ""], ["Ramsey", "Joseph D.", ""], ["Zhang", "Kun", ""], ["Glymour", "Clark", ""]]}, {"id": "1908.03265", "submitter": "Liyuan Liu", "authors": "Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu,\n  Jianfeng Gao, Jiawei Han", "title": "On the Variance of the Adaptive Learning Rate and Beyond", "comments": "ICLR 2020. Fix several typos in the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning rate warmup heuristic achieves remarkable success in stabilizing\ntraining, accelerating convergence and improving generalization for adaptive\nstochastic optimization algorithms like RMSprop and Adam. Here, we study its\nmechanism in details. Pursuing the theory behind warmup, we identify a problem\nof the adaptive learning rate (i.e., it has problematically large variance in\nthe early stage), suggest warmup works as a variance reduction technique, and\nprovide both empirical and theoretical evidence to verify our hypothesis. We\nfurther propose RAdam, a new variant of Adam, by introducing a term to rectify\nthe variance of the adaptive learning rate. Extensive experimental results on\nimage classification, language modeling, and neural machine translation verify\nour intuition and demonstrate the effectiveness and robustness of our proposed\nmethod. All implementations are available at:\nhttps://github.com/LiyuanLucasLiu/RAdam.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 20:51:17 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 02:35:43 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 15:03:56 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Liu", "Liyuan", ""], ["Jiang", "Haoming", ""], ["He", "Pengcheng", ""], ["Chen", "Weizhu", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Han", "Jiawei", ""]]}, {"id": "1908.03270", "submitter": "Josh Payne", "authors": "Mustafa Canim, Ashish Kundu, Josh Payne", "title": "Uncheatable Machine Learning Inference", "comments": "Work-in-progress. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification-as-a-Service (CaaS) is widely deployed today in machine\nintelligence stacks for a vastly diverse set of applications including anything\nfrom medical prognosis to computer vision tasks to natural language processing\nto identity fraud detection. The computing power required for training complex\nmodels on large datasets to perform inference to solve these problems can be\nvery resource-intensive. A CaaS provider may cheat a customer by fraudulently\nbypassing expensive training procedures in favor of weaker, less\ncomputationally-intensive algorithms which yield results of reduced quality.\nGiven a classification service supplier $S$, intermediary CaaS provider $P$\nclaiming to use $S$ as a classification backend, and customer $C$, our work\naddresses the following questions: (i) how can $P$'s claim to be using $S$ be\nverified by $C$? (ii) how might $S$ make performance guarantees that may be\nverified by $C$? and (iii) how might one design a decentralized system that\nincentivizes service proofing and accountability? To this end, we propose a\nvariety of methods for $C$ to evaluate the service claims made by $P$ using\nprobabilistic performance metrics, instance seeding, and steganography. We also\npropose a method of measuring the robustness of a model using a blackbox\nadversarial procedure, which may then be used as a benchmark or comparison to a\nclaim made by $S$. Finally, we propose the design of a smart contract-based\ndecentralized system that incentivizes service accountability to serve as a\ntrusted Quality of Service (QoS) auditor.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 21:29:00 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Canim", "Mustafa", ""], ["Kundu", "Ashish", ""], ["Payne", "Josh", ""]]}, {"id": "1908.03299", "submitter": "Yuma Koizumi", "authors": "Yuma Koizumi, Shoichiro Saito, Hisashi Uematsu, Noboru Harada, and\n  Keisuke Imoto", "title": "ToyADMOS: A Dataset of Miniature-Machine Operating Sounds for Anomalous\n  Sound Detection", "comments": "5 pages, to appear in IEEE WASPAA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new dataset called \"ToyADMOS\" designed for anomaly\ndetection in machine operating sounds (ADMOS). To the best our knowledge, no\nlarge-scale datasets are available for ADMOS, although large-scale datasets\nhave contributed to recent advancements in acoustic signal processing. This is\nbecause anomalous sound data are difficult to collect. To build a large-scale\ndataset for ADMOS, we collected anomalous operating sounds of miniature\nmachines (toys) by deliberately damaging them. The released dataset consists of\nthree sub-datasets for machine-condition inspection, fault diagnosis of\nmachines with geometrically fixed tasks, and fault diagnosis of machines with\nmoving tasks. Each sub-dataset includes over 180 hours of normal\nmachine-operating sounds and over 4,000 samples of anomalous sounds collected\nwith four microphones at a 48-kHz sampling rate. The dataset is freely\navailable for download at https://github.com/YumaKoizumi/ToyADMOS-dataset\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 03:52:08 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Koizumi", "Yuma", ""], ["Saito", "Shoichiro", ""], ["Uematsu", "Hisashi", ""], ["Harada", "Noboru", ""], ["Imoto", "Keisuke", ""]]}, {"id": "1908.03309", "submitter": "Dongjun Kim", "authors": "Dongjun Kim, Tae-Sub Yun, Il-Chul Moon", "title": "Automatic Calibration of Dynamic and Heterogeneous Parameters in\n  Agent-based Model", "comments": "31 pages, 12 figures, Journal of Autonomous Agents and Multi-Agent\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While simulations have been utilized in diverse domains, such as urban growth\nmodeling, market dynamics modeling, etc; some of these applications may require\nvalidations based upon some real-world observations modeled in the simulation,\nas well. This validation has been categorized into either qualitative\nface-validation or quantitative empirical validation, but as the importance and\nthe accumulation of data grows, the importance of the quantitative validation\nhas been highlighted in the recent studies, i.e. digital twin. The key\ncomponent of quantitative validation is finding a calibrated set of parameters\nto regenerate the real-world observations with simulation models. While this\nparameter calibration has been fixed throughout a simulation execution, this\npaper expands the static parameter calibration in two dimensions: dynamic\ncalibration and heterogeneous calibration. First, dynamic calibration changes\nthe parameter values over the simulation period by reflecting the simulation\noutput trend. Second, heterogeneous calibration changes the parameter values\nper simulated entity clusters by considering the similarities of entity states.\nWe experimented the suggested calibrations on one hypothetical case and another\nreal-world case. As a hypothetical scenario, we use the Wealth Distribution\nModel to illustrate how our calibration works. As a real-world scenario, we\nselected Real Estate Market Model because of three reasons. First, the models\nhave heterogeneous entities as being agent-based models; second, they are\neconomic models with real-world trends over time; and third, they are\napplicable to the real-world scenarios where we can gather validation data.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 04:33:54 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Kim", "Dongjun", ""], ["Yun", "Tae-Sub", ""], ["Moon", "Il-Chul", ""]]}, {"id": "1908.03339", "submitter": "Parisa Beham Mohamed Gani", "authors": "D.Sabarinathan, M.Parisa Beham and S.M.Md.Mansoor Roomi", "title": "Hyper Vision Net: Kidney Tumor Segmentation Using Coordinate\n  Convolutional Layer and Attention Unit", "comments": "9 pages, 3 figures, KiTs19 challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KiTs19 challenge paves the way to haste the improvement of solid kidney tumor\nsemantic segmentation methodologies. Accurate segmentation of kidney tumor in\ncomputer tomography (CT) images is a challenging task due to the non-uniform\nmotion, similar appearance and various shape. Inspired by this fact, in this\nmanuscript, we present a novel kidney tumor segmentation method using deep\nlearning network termed as Hyper vision Net model. All the existing U-net\nmodels are using a modified version of U-net to segment the kidney tumor\nregion. In the proposed architecture, we introduced supervision layers in the\ndecoder part, and it refines even minimal regions in the output. A dataset\nconsists of real arterial phase abdominal CT scans of 300 patients, including\n45964 images has been provided from KiTs19 for training and validation of the\nproposed model. Compared with the state-of-the-art segmentation methods, the\nresults demonstrate the superiority of our approach on training dice value\nscore of 0.9552 and 0.9633 in tumor region and kidney region, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 07:05:34 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Sabarinathan", "D.", ""], ["Beham", "M. Parisa", ""], ["Roomi", "S. M. Md. Mansoor", ""]]}, {"id": "1908.03343", "submitter": "Yuka Ariki", "authors": "Yuka Ariki and Takuya Narihira", "title": "Fully Convolutional Search Heuristic Learning for Rapid Path Planners", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path-planning algorithms are an important part of a wide variety of robotic\napplications, such as mobile robot navigation and robot arm manipulation.\nHowever, in large search spaces in which local traps may exist, it remains\nchallenging to reliably find a path while satisfying real-time constraints.\nEfforts to speed up the path search have led to the development of many\npractical path-planning algorithms. These algorithms often define a search\nheuristic to guide the search towards the goal. The heuristics should be\ncarefully designed for each specific problem to ensure reliability in the\nvarious situations encountered in the problem. However, it is often difficult\nfor humans to craft such robust heuristics, and the search performance often\ndegrades under conditions that violate the heuristic assumption. Rather than\nmanually designing the heuristics, in this work, we propose a learning approach\nto acquire these search heuristics. Our method represents the environment\ncontaining the obstacles as an image, and this image is fed into fully\nconvolutional neural networks to produce a search heuristic image where every\npixel represents a heuristic value (cost-to-go value to a goal) in the form of\na vertex of a search graph. Training the heuristic is performed using\npreviously collected planning results. Our preliminary experiments (2D grid\nworld navigation experiments) demonstrate significant reduction in the search\ncosts relative to a hand-designed heuristic.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 07:27:28 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Ariki", "Yuka", ""], ["Narihira", "Takuya", ""]]}, {"id": "1908.03367", "submitter": "Pierre Humbert", "authors": "Pierre Humbert (CMLA), Julien Audiffren (CMLA), Laurent Oudre (L2TI),\n  Nicolas Vayatis (CMLA)", "title": "Multivariate Convolutional Sparse Coding with Low Rank Tensor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new multivariate convolutional sparse coding based on\ntensor algebra with a general model enforcing both element-wise sparsity and\nlow-rankness of the activations tensors. By using the CP decomposition, this\nmodel achieves a significantly more efficient encoding of the multivariate\nsignal-particularly in the high order/ dimension setting-resulting in better\nperformance. We prove that our model is closely related to the Kruskal tensor\nregression problem, offering interesting theoretical guarantees to our setting.\nFurthermore, we provide an efficient optimization algorithm based on\nalternating optimization to solve this model. Finally, we evaluate our\nalgorithm with a large range of experiments, highlighting its advantages and\nlimitations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 08:47:45 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Humbert", "Pierre", "", "CMLA"], ["Audiffren", "Julien", "", "CMLA"], ["Oudre", "Laurent", "", "L2TI"], ["Vayatis", "Nicolas", "", "CMLA"]]}, {"id": "1908.03385", "submitter": "Miaojun Bai", "authors": "Miaojun Bai, Yan Zheng and Yun Shen", "title": "Gradient Boosting Survival Tree with Applications in Credit Scoring", "comments": "26 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit scoring plays a vital role in the field of consumer finance. Survival\nanalysis provides an advanced solution to the credit-scoring problem by\nquantifying the probability of survival time. In order to deal with highly\nheterogeneous industrial data collected in Chinese market of consumer finance,\nwe propose a nonparametric ensemble tree model called gradient boosting\nsurvival tree (GBST) that extends the survival tree models with a gradient\nboosting algorithm. The survival tree ensemble is learned by minimizing the\nnegative log-likelihood in an additive manner. The proposed model optimizes the\nsurvival probability simultaneously for each time period, which can reduce the\noverall error significantly. Finally, as a test of the applicability, we apply\nthe GBST model to quantify the credit risk with large-scale real market\ndatasets. The results show that the GBST model outperforms the existing\nsurvival models measured by the concordance index (C-index), Kolmogorov-Smirnov\n(KS) index, as well as by the area under the receiver operating characteristic\ncurve (AUC) of each time period.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 09:37:28 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 09:54:06 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 23:35:53 GMT"}, {"version": "v4", "created": "Tue, 17 Nov 2020 05:45:16 GMT"}, {"version": "v5", "created": "Mon, 12 Apr 2021 06:51:35 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Bai", "Miaojun", ""], ["Zheng", "Yan", ""], ["Shen", "Yun", ""]]}, {"id": "1908.03405", "submitter": "Patrick Sch\\\"afer", "authors": "P. Sch\\\"afer and U. Leser", "title": "TEASER: Early and Accurate Time Series Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early time series classification (eTSC) is the problem of classifying a time\nseries after as few measurements as possible with the highest possible\naccuracy. The most critical issue of any eTSC method is to decide when enough\ndata of a time series has been seen to take a decision: Waiting for more data\npoints usually makes the classification problem easier but delays the time in\nwhich a classification is made; in contrast, earlier classification has to cope\nwith less input data, often leading to inferior accuracy. The state-of-the-art\neTSC methods compute a fixed optimal decision time assuming that every times\nseries has the same defined start time (like turning on a machine). However, in\nmany real-life applications measurements start at arbitrary times (like\nmeasuring heartbeats of a patient), implying that the best time for taking a\ndecision varies heavily between time series. We present TEASER, a novel\nalgorithm that models eTSC as a two two-tier classification problem: In the\nfirst tier, a classifier periodically assesses the incoming time series to\ncompute class probabilities. However, these class probabilities are only used\nas output label if a second-tier classifier decides that the predicted label is\nreliable enough, which can happen after a different number of measurements. In\nan evaluation using 45 benchmark datasets, TEASER is two to three times earlier\nat predictions than its competitors while reaching the same or an even higher\nclassification accuracy. We further show TEASER's superior performance using\nreal-life use cases, namely energy monitoring, and gait detection.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 10:49:07 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 10:19:56 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sch\u00e4fer", "P.", ""], ["Leser", "U.", ""]]}, {"id": "1908.03409", "submitter": "Eugene Ie", "authors": "Haoshuo Huang, Vihan Jain, Harsh Mehta, Alexander Ku, Gabriel\n  Magalhaes, Jason Baldridge, Eugene Ie", "title": "Transferable Representation Learning in Vision-and-Language Navigation", "comments": "To appear in ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vision-and-Language Navigation (VLN) tasks such as Room-to-Room (R2R) require\nmachine agents to interpret natural language instructions and learn to act in\nvisually realistic environments to achieve navigation goals. The overall task\nrequires competence in several perception problems: successful agents combine\nspatio-temporal, vision and language understanding to produce appropriate\naction sequences. Our approach adapts pre-trained vision and language\nrepresentations to relevant in-domain tasks making them more effective for VLN.\nSpecifically, the representations are adapted to solve both a cross-modal\nsequence alignment and sequence coherence task. In the sequence alignment task,\nthe model determines whether an instruction corresponds to a sequence of visual\nframes. In the sequence coherence task, the model determines whether the\nperceptual sequences are predictive sequentially in the instruction-conditioned\nlatent space. By transferring the domain-adapted representations, we improve\ncompetitive agents in R2R as measured by the success rate weighted by path\nlength (SPL) metric.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 10:58:01 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 22:00:55 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Huang", "Haoshuo", ""], ["Jain", "Vihan", ""], ["Mehta", "Harsh", ""], ["Ku", "Alexander", ""], ["Magalhaes", "Gabriel", ""], ["Baldridge", "Jason", ""], ["Ie", "Eugene", ""]]}, {"id": "1908.03440", "submitter": "Paolo Galeone", "authors": "Alessia Bertugli, Paolo Galeone", "title": "Learning to Grasp from 2.5D images: a Deep Reinforcement Learning\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a deep reinforcement learning (DRL) solution to the\ngrasping problem using 2.5D images as the only source of information. In\nparticular, we developed a simulated environment where a robot equipped with a\nvacuum gripper has the aim of reaching blocks with planar surfaces. These\nblocks can have different dimensions, shapes, position and orientation. Unity\n3D allowed us to simulate a real-world setup, where a depth camera is placed in\na fixed position and the stream of images is used by our policy network to\nlearn how to solve the task. We explored different DRL algorithms and problem\nconfigurations. The experiments demonstrated the effectiveness of the proposed\nDRL algorithm applied to grasp tasks guided by visual depth camera inputs. When\nusing the proper policy, the proposed method estimates a robot tool\nconfiguration that reaches the object surface with negligible position and\norientation errors. This is, to the best of our knowledge, the first successful\nattempt of using 2.5D images only as of the input of a DRL algorithm, to solve\nthe grasping problem regressing 3D world coordinates.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 07:53:24 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Bertugli", "Alessia", ""], ["Galeone", "Paolo", ""]]}, {"id": "1908.03442", "submitter": "Rafael Caba\\~nas", "authors": "Andr\\'es R. Masegosa, Rafael Caba\\~nas, Helge Langseth, Thomas D.\n  Nielsen, Antonio Salmer\\'on", "title": "Probabilistic Models with Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in statistical inference have significantly expanded the\ntoolbox of probabilistic modeling. Historically, probabilistic modeling has\nbeen constrained to (i) very restricted model classes where exact or\napproximate probabilistic inference were feasible, and (ii) small or\nmedium-sized data sets which fit within the main memory of the computer.\nHowever, developments in variational inference, a general form of approximate\nprobabilistic inference originated in statistical physics, are allowing\nprobabilistic modeling to overcome these restrictions: (i) Approximate\nprobabilistic inference is now possible over a broad class of probabilistic\nmodels containing a large number of parameters, and (ii) scalable inference\nmethods based on stochastic gradient descent and distributed computation\nengines allow to apply probabilistic modeling over massive data sets. One\nimportant practical consequence of these advances is the possibility to include\ndeep neural networks within a probabilistic model to capture complex non-linear\nstochastic relationships between random variables. These advances in\nconjunction with the release of novel probabilistic modeling toolboxes have\ngreatly expanded the scope of application of probabilistic models, and allow\nthese models to take advantage of the recent strides made by the deep learning\ncommunity. In this paper we review the main concepts, methods and tools needed\nto use deep neural networks within a probabilistic modeling framework.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 12:55:54 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 08:37:56 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 10:06:39 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Masegosa", "Andr\u00e9s R.", ""], ["Caba\u00f1as", "Rafael", ""], ["Langseth", "Helge", ""], ["Nielsen", "Thomas D.", ""], ["Salmer\u00f3n", "Antonio", ""]]}, {"id": "1908.03443", "submitter": "Arun Viswanathan", "authors": "Kapil Sinha, Arun Viswanathan, Julian Bunn", "title": "Tracking Temporal Evolution of Network Activity for Botnet Detection", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Botnets are becoming increasingly prevalent as the primary enabling\ntechnology in a variety of malicious campaigns such as email spam, click fraud,\ndistributed denial-of-service (DDoS) attacks, and cryptocurrency mining. Botnet\ntechnology has continued to evolve rapidly making detection a very challenging\nproblem. There is a fundamental need for robust detection methods that are\ninsensitive to characteristics of a specific botnet and are generalizable\nacross different botnet types. We propose a novel supervised approach to detect\nmalicious botnet hosts by tracking a host's network activity over time using a\nLong Short-Term Memory (LSTM) based neural network architecture. We build a\nprototype to demonstrate the feasibility of our approach, evaluate it on the\nCTU-13 dataset, and compare our performance against existing detection methods.\nWe show that our approach results in a more generalizable, botnet-agnostic\ndetection methodology, is amenable to real-time implementation, and performs\nwell compared to existing approaches, with an overall accuracy score of 96.2%.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 13:00:36 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Sinha", "Kapil", ""], ["Viswanathan", "Arun", ""], ["Bunn", "Julian", ""]]}, {"id": "1908.03447", "submitter": "Liang Wang", "authors": "Liang Wang, Hao Ye, Le Liang, Geoffrey Ye Li", "title": "Learn to Allocate Resources in Vehicular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource allocation has a direct and profound impact on the performance of\nvehicle-to-everything (V2X) networks. Considering the dynamic nature of\nvehicular environments, it is appealing to devise a decentralized strategy to\nperform effective resource sharing. In this paper, we exploit deep learning to\npromote coordination among multiple vehicles and propose a hybrid architecture\nconsisting of centralized decision making and distributed resource sharing to\nmaximize the long-term sum rate of all vehicles. To reduce the network\nsignaling overhead, each vehicle uses a deep neural network to compress its own\nobserved information that is thereafter fed back to the centralized\ndecision-making unit, which employs a deep Q-network to allocate resources and\nthen sends the decision results to all vehicles. We further adopt a\nquantization layer for each vehicle that learns to quantize the continuous\nfeedback. Extensive simulation results demonstrate that the proposed hybrid\narchitecture can achieve near-optimal performance. Meanwhile, there exists an\noptimal number of continuous feedback and binary feedback, respectively.\nBesides, this architecture is robust to different feedback intervals, input\nnoise, and feedback noise.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:41:33 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Wang", "Liang", ""], ["Ye", "Hao", ""], ["Liang", "Le", ""], ["Li", "Geoffrey Ye", ""]]}, {"id": "1908.03463", "submitter": "Chaithanya Kumar Mummadi", "authors": "Chaithanya Kumar Mummadi, Tim Genewein, Dan Zhang, Thomas Brox, Volker\n  Fischer", "title": "Group Pruning using a Bounded-Lp norm for Group Gating and\n  Regularization", "comments": "German Conference on Pattern Recognition (GCPR) 2019, 12 main pages,\n  3 pages of appendix, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks achieve state-of-the-art results on several tasks while\nincreasing in complexity. It has been shown that neural networks can be pruned\nduring training by imposing sparsity inducing regularizers. In this paper, we\ninvestigate two techniques for group-wise pruning during training in order to\nimprove network efficiency. We propose a gating factor after every\nconvolutional layer to induce channel level sparsity, encouraging insignificant\nchannels to become exactly zero. Further, we introduce and analyse a bounded\nvariant of the L1 regularizer, which interpolates between L1 and L0-norms to\nretain performance of the network at higher pruning rates. To underline\neffectiveness of the proposed methods,we show that the number of parameters of\nResNet-164, DenseNet-40 and MobileNetV2 can be reduced down by 30%, 69% and 75%\non CIFAR100 respectively without a significant drop in accuracy. We achieve\nstate-of-the-art pruning results for ResNet-50 with higher accuracy on\nImageNet. Furthermore, we show that the light weight MobileNetV2 can further be\ncompressed on ImageNet without a significant drop in performance.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 14:08:35 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Mummadi", "Chaithanya Kumar", ""], ["Genewein", "Tim", ""], ["Zhang", "Dan", ""], ["Brox", "Thomas", ""], ["Fischer", "Volker", ""]]}, {"id": "1908.03464", "submitter": "Zheng Wang", "authors": "Zheng Wang (1), Qiao Wang (2), Tingzhang Zhao (1), Xiaojun Ye (2) ((1)\n  Department of Computer Science, University of Science and Technology Beijing\n  (2) School of Software, Tsinghua University)", "title": "Zero-Shot Feature Selection via Transferring Supervised Knowledge", "comments": "Published in IJDWM21", "journal-ref": null, "doi": "10.4018/IJDWM.2021040101", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Feature selection, an effective technique for dimensionality reduction, plays\nan important role in many machine learning systems. Supervised knowledge can\nsignificantly improve the performance. However, faced with the rapid growth of\nnewly emerging concepts, existing supervised methods might easily suffer from\nthe scarcity and validity of labeled data for training. In this paper, the\nauthors study the problem of zero-shot feature selection (i.e., building a\nfeature selection model that generalizes well to \"unseen\" concepts with limited\ntraining data of \"seen\" concepts). Specifically, they adopt class-semantic\ndescriptions (i.e., attributes) as supervision for feature selection, so as to\nutilize the supervised knowledge transferred from the seen concepts. For more\nreliable discriminative features, they further propose the\ncenter-characteristic loss which encourages the selected features to capture\nthe central characteristics of seen concepts. Extensive experiments conducted\non various real-world datasets demonstrate the effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 14:09:40 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 01:26:41 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 12:57:06 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Wang", "Zheng", ""], ["Wang", "Qiao", ""], ["Zhao", "Tingzhang", ""], ["Ye", "Xiaojun", ""]]}, {"id": "1908.03491", "submitter": "Jonathan Heek", "authors": "Jonathan Heek and Nal Kalchbrenner", "title": "Bayesian Inference for Large Scale Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference promises to ground and improve the performance of deep\nneural networks. It promises to be robust to overfitting, to simplify the\ntraining procedure and the space of hyperparameters, and to provide a\ncalibrated measure of uncertainty that can enhance decision making, agent\nexploration and prediction fairness. Markov Chain Monte Carlo (MCMC) methods\nenable Bayesian inference by generating samples from the posterior distribution\nover model parameters. Despite the theoretical advantages of Bayesian inference\nand the similarity between MCMC and optimization methods, the performance of\nsampling methods has so far lagged behind optimization methods for large scale\ndeep learning tasks. We aim to fill this gap and introduce ATMC, an adaptive\nnoise MCMC algorithm that estimates and is able to sample from the posterior of\na neural network. ATMC dynamically adjusts the amount of momentum and noise\napplied to each parameter update in order to compensate for the use of\nstochastic gradients. We use a ResNet architecture without batch normalization\nto test ATMC on the Cifar10 benchmark and the large scale ImageNet benchmark\nand show that, despite the absence of batch normalization, ATMC outperforms a\nstrong optimization baseline in terms of both classification accuracy and test\nlog-likelihood. We show that ATMC is intrinsically robust to overfitting on the\ntraining data and that ATMC provides a better calibrated measure of uncertainty\ncompared to the optimization baseline.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 15:15:56 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Heek", "Jonathan", ""], ["Kalchbrenner", "Nal", ""]]}, {"id": "1908.03512", "submitter": "Gabriel Spadon", "authors": "Gabriel Spadon, Andre C. P. L. F. de Carvalho, Jose F. Rodrigues-Jr,\n  Luiz G. A. Alves", "title": "Reconstructing commuters network using machine learning and urban\n  indicators", "comments": "28 pages, 5 figures", "journal-ref": "Scientific Reports 9, Article number: 11801 (2019)", "doi": "10.1038/s41598-019-48295-x", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human mobility has a significant impact on several layers of society, from\ninfrastructural planning and economics to the spread of diseases and crime.\nRepresenting the system as a complex network, in which nodes are assigned to\nregions (e.g., a city) and links indicate the flow of people between two of\nthem, physics-inspired models have been proposed to quantify the number of\npeople migrating from one city to the other. Despite the advances made by these\nmodels, our ability to predict the number of commuters and reconstruct mobility\nnetworks remains limited. Here, we propose an alternative approach using\nmachine learning and 22 urban indicators to predict the flow of people and\nreconstruct the intercity commuters network. Our results reveal that\npredictions based on machine learning algorithms and urban indicators can\nreconstruct the commuters network with 90.4% of accuracy and describe 77.6% of\nthe variance observed in the flow of people between cities. We also identify\nessential features to recover the network structure and the urban indicators\nmostly related to commuting patterns. As previously reported, distance plays a\nsignificant role in commuting, but other indicators, such as Gross Domestic\nProduct (GDP) and unemployment rate, are also driven-forces for people to\ncommute. We believe that our results shed new lights on the modeling of\nmigration and reinforce the role of urban indicators on commuting patterns.\nAlso, because link-prediction and network reconstruction are still open\nchallenges in network science, our results have implications in other areas,\nlike economics, social sciences, and biology, where node attributes can give us\ninformation about the existence of links connecting entities in the network.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 16:02:43 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Spadon", "Gabriel", ""], ["de Carvalho", "Andre C. P. L. F.", ""], ["Rodrigues-Jr", "Jose F.", ""], ["Alves", "Luiz G. A.", ""]]}, {"id": "1908.03515", "submitter": "Chieh Wu T", "authors": "Chieh Wu, Zulqarnain Khan, Yale Chang, Stratis Ioannidis, Jennifer Dy", "title": "Deep Kernel Learning for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a deep learning approach for discovering kernels tailored to\nidentifying clusters over sample data. Our neural network produces sample\nembeddings that are motivated by--and are at least as expressive as--spectral\nclustering. Our training objective, based on the Hilbert Schmidt Information\nCriterion, can be optimized via gradient adaptations on the Stiefel manifold,\nleading to significant acceleration over spectral methods relying on\neigendecompositions. Finally, our trained embedding can be directly applied to\nout-of-sample data. We show experimentally that our approach outperforms\nseveral state-of-the-art deep clustering methods, as well as traditional\napproaches such as $k$-means and spectral clustering over a broad array of\nreal-life and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 16:14:47 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:59:58 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 15:32:36 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Wu", "Chieh", ""], ["Khan", "Zulqarnain", ""], ["Chang", "Yale", ""], ["Ioannidis", "Stratis", ""], ["Dy", "Jennifer", ""]]}, {"id": "1908.03548", "submitter": "Zongcheng Ji", "authors": "Zongcheng Ji, Qiang Wei, Hua Xu", "title": "BERT-based Ranking for Biomedical Entity Normalization", "comments": "9 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing high-performance entity normalization algorithms that can\nalleviate the term variation problem is of great interest to the biomedical\ncommunity. Although deep learning-based methods have been successfully applied\nto biomedical entity normalization, they often depend on traditional\ncontext-independent word embeddings. Bidirectional Encoder Representations from\nTransformers (BERT), BERT for Biomedical Text Mining (BioBERT) and BERT for\nClinical Text Mining (ClinicalBERT) were recently introduced to pre-train\ncontextualized word representation models using bidirectional Transformers,\nadvancing the state-of-the-art for many natural language processing tasks. In\nthis study, we proposed an entity normalization architecture by fine-tuning the\npre-trained BERT / BioBERT / ClinicalBERT models and conducted extensive\nexperiments to evaluate the effectiveness of the pre-trained models for\nbiomedical entity normalization using three different types of datasets. Our\nexperimental results show that the best fine-tuned models consistently\noutperformed previous methods and advanced the state-of-the-art for biomedical\nentity normalization, with up to 1.17% increase in accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 17:19:43 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Ji", "Zongcheng", ""], ["Wei", "Qiang", ""], ["Xu", "Hua", ""]]}, {"id": "1908.03557", "submitter": "Mark Yatskar", "authors": "Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang", "title": "VisualBERT: A Simple and Performant Baseline for Vision and Language", "comments": "Work in Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose VisualBERT, a simple and flexible framework for modeling a broad\nrange of vision-and-language tasks. VisualBERT consists of a stack of\nTransformer layers that implicitly align elements of an input text and regions\nin an associated input image with self-attention. We further propose two\nvisually-grounded language model objectives for pre-training VisualBERT on\nimage caption data. Experiments on four vision-and-language tasks including\nVQA, VCR, NLVR2, and Flickr30K show that VisualBERT outperforms or rivals with\nstate-of-the-art models while being significantly simpler. Further analysis\ndemonstrates that VisualBERT can ground elements of language to image regions\nwithout any explicit supervision and is even sensitive to syntactic\nrelationships, tracking, for example, associations between verbs and image\nregions corresponding to their arguments.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 17:57:13 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Li", "Liunian Harold", ""], ["Yatskar", "Mark", ""], ["Yin", "Da", ""], ["Hsieh", "Cho-Jui", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1908.03560", "submitter": "Mohamed Akrout", "authors": "Mohamed Akrout", "title": "On the Adversarial Robustness of Neural Networks without Weight\n  Transport", "comments": "Accepted for the workshop on Real Neurons & Hidden Units at NeurIPS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks trained with backpropagation, the standard algorithm of deep\nlearning which uses weight transport, are easily fooled by existing\ngradient-based adversarial attacks. This class of attacks are based on certain\nsmall perturbations of the inputs to make networks misclassify them. We show\nthat less biologically implausible deep neural networks trained with feedback\nalignment, which do not use weight transport, can be harder to fool, providing\nactual robustness. Tested on MNIST, deep neural networks trained without weight\ntransport (1) have an adversarial accuracy of 98% compared to 0.03% for neural\nnetworks trained with backpropagation and (2) generate non-transferable\nadversarial examples. However, this gap decreases on CIFAR-10 but is still\nsignificant particularly for small perturbation magnitude less than 1/2.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 17:59:35 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 00:21:17 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Akrout", "Mohamed", ""]]}, {"id": "1908.03566", "submitter": "Shuang Song", "authors": "\\'Ulfar Erlingsson and Ilya Mironov and Ananth Raghunathan and Shuang\n  Song", "title": "That which we call private", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The guarantees of security and privacy defenses are often strengthened by\nrelaxing the assumptions made about attackers or the context in which defenses\nare deployed. Such relaxations can be a highly worthwhile topic of\nexploration---even though they typically entail assuming a weaker, less\npowerful adversary---because there may indeed be great variability in both\nattackers' powers and their context.\n  However, no weakening or contextual discounting of attackers' power is\nassumed for what some have called \"relaxed definitions\" in the analysis of\ndifferential-privacy guarantees. Instead, the definitions so named are the\nbasis of refinements and more advanced analyses of the worst-case implications\nof attackers---without any change assumed in attackers' powers.\n  Because they more precisely bound the worst-case privacy loss, these improved\nanalyses can greatly strengthen the differential-privacy upper-bound\nguarantees---sometimes lowering the differential-privacy epsilon by\norders-of-magnitude. As such, to the casual eye, these analyses may appear to\nimply a reduced privacy loss. This is a false perception: the privacy loss of\nany concrete mechanism cannot change with the choice of a worst-case-loss\nupper-bound analysis technique. Practitioners must be careful not to equate\nreal-world privacy with differential-privacy epsilon values, at least not\nwithout full consideration of the context.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 22:09:52 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 18:39:55 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Erlingsson", "\u00dalfar", ""], ["Mironov", "Ilya", ""], ["Raghunathan", "Ananth", ""], ["Song", "Shuang", ""]]}, {"id": "1908.03568", "submitter": "Ian Osband", "authors": "Ian Osband, Yotam Doron, Matteo Hessel, John Aslanides, Eren Sezener,\n  Andre Saraiva, Katrina McKinney, Tor Lattimore, Csaba Szepesvari, Satinder\n  Singh, Benjamin Van Roy, Richard Sutton, David Silver, Hado Van Hasselt", "title": "Behaviour Suite for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Behaviour Suite for Reinforcement Learning, or\nbsuite for short. bsuite is a collection of carefully-designed experiments that\ninvestigate core capabilities of reinforcement learning (RL) agents with two\nobjectives. First, to collect clear, informative and scalable problems that\ncapture key issues in the design of general and efficient learning algorithms.\nSecond, to study agent behaviour through their performance on these shared\nbenchmarks. To complement this effort, we open source\ngithub.com/deepmind/bsuite, which automates evaluation and analysis of any\nagent on bsuite. This library facilitates reproducible and accessible research\non the core issues in RL, and ultimately the design of superior learning\nalgorithms. Our code is Python, and easy to use within existing projects. We\ninclude examples with OpenAI Baselines, Dopamine as well as new reference\nimplementations. Going forward, we hope to incorporate more excellent\nexperiments from the research community, and commit to a periodic review of\nbsuite from a committee of prominent researchers.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 08:34:08 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 12:48:44 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 15:18:17 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Osband", "Ian", ""], ["Doron", "Yotam", ""], ["Hessel", "Matteo", ""], ["Aslanides", "John", ""], ["Sezener", "Eren", ""], ["Saraiva", "Andre", ""], ["McKinney", "Katrina", ""], ["Lattimore", "Tor", ""], ["Szepesvari", "Csaba", ""], ["Singh", "Satinder", ""], ["Van Roy", "Benjamin", ""], ["Sutton", "Richard", ""], ["Silver", "David", ""], ["Van Hasselt", "Hado", ""]]}, {"id": "1908.03569", "submitter": "Isidro Cortes-Ciriano PhD", "authors": "Isidro Cort\\'es-Ciriano and Andreas Bender", "title": "Concepts and Applications of Conformal Prediction in Computational Drug\n  Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the reliability of individual predictions is key to increase the\nadoption of computational models and artificial intelligence in preclinical\ndrug discovery, as well as to foster its application to guide decision making\nin clinical settings. Among the large number of algorithms developed over the\nlast decades to compute prediction errors, Conformal Prediction (CP) has gained\nincreasing attention in the computational drug discovery community. A major\nreason for its recent popularity is the ease of interpretation of the computed\nprediction errors in both classification and regression tasks. For instance, at\na confidence level of 90% the true value will be within the predicted\nconfidence intervals in at least 90% of the cases. This so called validity of\nconformal predictors is guaranteed by the robust mathematical foundation\nunderlying CP. The versatility of CP relies on its minimal computational\nfootprint, as it can be easily coupled to any machine learning algorithm at\nlittle computational cost. In this review, we summarize underlying concepts and\npractical applications of CP with a particular focus on virtual screening and\nactivity modelling, and list open source implementations of relevant software.\nFinally, we describe the current limitations in the field, and provide a\nperspective on future opportunities for CP in preclinical and clinical drug\ndiscovery.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 11:17:05 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Cort\u00e9s-Ciriano", "Isidro", ""], ["Bender", "Andreas", ""]]}, {"id": "1908.03571", "submitter": "Hongzhi Wang", "authors": "Hongzhi Wang, Yang Song and Shihan Tang", "title": "LSTM-based Flow Prediction", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a method of prediction on continuous time series variables\nfrom the production or flow -- an LSTM algorithm based on multivariate tuning\n-- is proposed. The algorithm improves the traditional LSTM algorithm and\nconverts the time series data into supervised learning sequences regarding\nindustrial data's features. The main innovation of this paper consists in\nintroducing the concepts of periodic measurement and time window in the\nindustrial prediction problem, especially considering industrial data with time\nseries characteristics. Experiments using real-world datasets show that the\nprediction accuracy is improved, 54.05% higher than that of traditional LSTM\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 13:46:48 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Wang", "Hongzhi", ""], ["Song", "Yang", ""], ["Tang", "Shihan", ""]]}, {"id": "1908.03595", "submitter": "Chen Wang", "authors": "Chen Wang, Chengyuan Deng, Zhoulu Yu, Dafeng Hui, Xiaofeng Gong,\n  Ruisen Luo", "title": "Adaptive Ensemble of Classifiers with Regularization for Imbalanced Data\n  Classification", "comments": "Major revision; Change of authors due to contributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The dynamic ensemble selection of classifiers is an effective approach for\nprocessing label-imbalanced data classifications. However, such a technique is\nprone to overfitting, owing to the lack of regularization methods and the\ndependence of the aforementioned technique on local geometry. In this study,\nfocusing on binary imbalanced data classification, a novel dynamic ensemble\nmethod, namely adaptive ensemble of classifiers with regularization (AER), is\nproposed, to overcome the stated limitations. The method solves the overfitting\nproblem through implicit regularization. Specifically, it leverages the\nproperties of stochastic gradient descent to obtain the solution with the\nminimum norm, thereby achieving regularization; furthermore, it interpolates\nthe ensemble weights by exploiting the global geometry of data to further\nprevent overfitting. According to our theoretical proofs, the seemingly\ncomplicated AER paradigm, in addition to its regularization capabilities, can\nactually reduce the asymptotic time and memory complexities of several other\nalgorithms. We evaluate the proposed AER method on seven benchmark imbalanced\ndatasets from the UCI machine learning repository and one artificially\ngenerated GMM-based dataset with five variations. The results show that the\nproposed algorithm outperforms the major existing algorithms based on multiple\nmetrics in most cases, and two hypothesis tests (McNemar's and Wilcoxon tests)\nverify the statistical significance further. In addition, the proposed method\nhas other preferred properties such as special advantages in dealing with\nhighly imbalanced data, and it pioneers the research on the regularization for\ndynamic ensemble methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 18:52:03 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 01:57:24 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 00:10:02 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Wang", "Chen", ""], ["Deng", "Chengyuan", ""], ["Yu", "Zhoulu", ""], ["Hui", "Dafeng", ""], ["Gong", "Xiaofeng", ""], ["Luo", "Ruisen", ""]]}, {"id": "1908.03609", "submitter": "Ilya Gartseev", "authors": "Andrey Bayev, Ilya Gartseev, Ivan Chistyakov, Alexey Nikulin, Alexey\n  Derevyankin, and Mikhail Pikhletsky", "title": "RuDaCoP: The Dataset for Smartphone-based Intellectual Pedestrian\n  Navigation", "comments": null, "journal-ref": null, "doi": "10.1109/IPIN.2019.8911823", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the large and diverse dataset for development of\nsmartphone-based pedestrian navigation algorithms. This dataset consists of\nabout 1200 sets of inertial measurements from sensors of several smartphones.\nThe measurements are collected while walking through different trajectories up\nto 10 minutes long. The data are accompanied by the high accuracy ground truth\ncollected with two foot-mounted inertial measurement units and post-processed\nby the presented algorithms. The dataset suits both for training of\nintellectual pedestrian navigation algorithms based on learning techniques and\nfor development of pedestrian navigation algorithms based on classical\napproaches. The dataset is accessible at http://gartseev.ru/projects/ipin2019.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 19:43:27 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Bayev", "Andrey", ""], ["Gartseev", "Ilya", ""], ["Chistyakov", "Ivan", ""], ["Nikulin", "Alexey", ""], ["Derevyankin", "Alexey", ""], ["Pikhletsky", "Mikhail", ""]]}, {"id": "1908.03620", "submitter": "Boris Kramer", "authors": "Renee Swischuk and Boris Kramer and Cheng Huang and Karen Willcox", "title": "Learning physics-based reduced-order models for a single-injector\n  combustion process", "comments": null, "journal-ref": "AIAA Journal 58:6, 2658-2672, 2020", "doi": "10.2514/1.J058943", "report-no": null, "categories": "physics.comp-ph cs.LG cs.SY eess.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a physics-based data-driven method to learn predictive\nreduced-order models (ROMs) from high-fidelity simulations, and illustrates it\nin the challenging context of a single-injector combustion process. The method\ncombines the perspectives of model reduction and machine learning. Model\nreduction brings in the physics of the problem, constraining the ROM\npredictions to lie on a subspace defined by the governing equations. This is\nachieved by defining the ROM in proper orthogonal decomposition (POD)\ncoordinates, which embed the rich physics information contained in solution\nsnapshots of a high-fidelity computational fluid dynamics (CFD) model. The\nmachine learning perspective brings the flexibility to use transformed physical\nvariables to define the POD basis. This is in contrast to traditional model\nreduction approaches that are constrained to use the physical variables of the\nhigh-fidelity code. Combining the two perspectives, the approach identifies a\nset of transformed physical variables that expose quadratic structure in the\ncombustion governing equations and learns a quadratic ROM from transformed\nsnapshot data. This learning does not require access to the high-fidelity model\nimplementation. Numerical experiments show that the ROM accurately predicts\ntemperature, pressure, velocity, species concentrations, and the limit-cycle\namplitude, with speedups of more than five orders of magnitude over\nhigh-fidelity models. Our ROM simulation is shown to be predictive 200% past\nthe training interval. Moreover, ROM-predicted pressure traces accurately match\nthe phase of the pressure signal and yield good approximations of the\nlimit-cycle amplitude.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 20:44:20 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 12:23:06 GMT"}, {"version": "v3", "created": "Mon, 23 Dec 2019 16:30:02 GMT"}, {"version": "v4", "created": "Sat, 11 Jul 2020 21:19:05 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Swischuk", "Renee", ""], ["Kramer", "Boris", ""], ["Huang", "Cheng", ""], ["Willcox", "Karen", ""]]}, {"id": "1908.03625", "submitter": "Sebastian Kleis", "authors": "Sebastian Kleis, Max Rueckmann, Christian G. Schaeffer", "title": "Continuous-Variable Quantum Key Distribution with a Real Local\n  Oscillator and without Auxiliary Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.LG eess.SP physics.optics", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continuous-variable quantum key distribution (CV-QKD) is realized with\ncoherent detection and is therefore very suitable for a cost-efficient\nimplementation. The major challenge in CV-QKD is mitigation of laser phase\nnoise at a signal to noise ratio of much less than 0 dB. So far, this has been\nachieved with a remote local oscillator or with auxiliary signals. For the\nfirst time, we experimentally demonstrate that CV-QKD can be performed with a\nreal local oscillator and without auxiliary signals which is achieved by\napplying Machine Learning methods. It is shown that, with the most established\ndiscrete modulation protocol, the experimental system works down to a quantum\nchannel signal to noise ratio of -19.1 dB. The performance of the experimental\nsystem allows CV-QKD at a key rate of 9.2 Mbit/s over a fiber distance of 26\nkm. After remote local oscillator and auxiliary signal aided CV-QKD, this could\nmark a starting point for a third generation of CV-QKD systems that are even\nmore attractive for a wide implementation because they are almost identical to\nstandard coherent systems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 15:30:52 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Kleis", "Sebastian", ""], ["Rueckmann", "Max", ""], ["Schaeffer", "Christian G.", ""]]}, {"id": "1908.03627", "submitter": "Jon\\'a\\v{s} Kulh\\'anek", "authors": "Jon\\'a\\v{s} Kulh\\'anek and Erik Derner and Tim de Bruin and Robert\n  Babu\\v{s}ka", "title": "Vision-based Navigation Using Deep Reinforcement Learning", "comments": "ECMR 2019: European Conference on Mobile Robots", "journal-ref": "2019 European Conference on Mobile Robots (ECMR), 2019, p.1-8", "doi": "10.1109/ECMR.2019.8870964", "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has been successfully applied to a variety\nof game-like environments. However, the application of deep RL to visual\nnavigation with realistic environments is a challenging task. We propose a\nnovel learning architecture capable of navigating an agent, e.g. a mobile\nrobot, to a target given by an image. To achieve this, we have extended the\nbatched A2C algorithm with auxiliary tasks designed to improve visual\nnavigation performance. We propose three additional auxiliary tasks: predicting\nthe segmentation of the observation image and of the target image and\npredicting the depth-map. These tasks enable the use of supervised learning to\npre-train a large part of the network and to reduce the number of training\nsteps substantially. The training performance has been further improved by\nincreasing the environment complexity gradually over time. An efficient neural\nnetwork structure is proposed, which is capable of learning for multiple\ntargets in multiple environments. Our method navigates in continuous state\nspaces and on the AI2-THOR environment simulator outperforms state-of-the-art\ngoal-oriented visual navigation methods from the literature.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 13:22:22 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 12:49:43 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Kulh\u00e1nek", "Jon\u00e1\u0161", ""], ["Derner", "Erik", ""], ["de Bruin", "Tim", ""], ["Babu\u0161ka", "Robert", ""]]}, {"id": "1908.03628", "submitter": "Yash Mehta", "authors": "Yash Mehta, Navonil Majumder, Alexander Gelbukh, Erik Cambria", "title": "Recent Trends in Deep Learning Based Personality Detection", "comments": null, "journal-ref": "Artif Intell Rev 53 (2020) 2313-2339", "doi": "10.1007/s10462-019-09770-z", "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the automatic prediction of personality traits has received a lot\nof attention. Specifically, personality trait prediction from multimodal data\nhas emerged as a hot topic within the field of affective computing. In this\npaper, we review significant machine learning models which have been employed\nfor personality detection, with an emphasis on deep learning-based methods.\nThis review paper provides an overview of the most popular approaches to\nautomated personality detection, various computational datasets, its industrial\napplications, and state-of-the-art machine learning models for personality\ndetection with specific focus on multimodal approaches. Personality detection\nis a very broad and diverse topic: this survey only focuses on computational\napproaches and leaves out psychological studies on personality detection.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 19:16:50 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 19:46:57 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Mehta", "Yash", ""], ["Majumder", "Navonil", ""], ["Gelbukh", "Alexander", ""], ["Cambria", "Erik", ""]]}, {"id": "1908.03629", "submitter": "Michael Cochez", "authors": "Andrei Ionita, Andr\\'e Pomp, Michael Cochez, Tobias Meisen and Stefan\n  Decker", "title": "Transferring knowledge from monitored to unmonitored areas for\n  forecasting parking spaces", "comments": "Preprint of an article to be published in Int J. on Artificial\n  Intelligence Tools (IJAIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart cities around the world have begun monitoring parking areas in order to\nestimate available parking spots and help drivers looking for parking. The\ncurrent results are promising, indeed. However, existing approaches are limited\nby the high cost of sensors that need to be installed throughout the city in\norder to achieve an accurate estimation. This work investigates the extension\nof estimating parking information from areas equipped with sensors to areas\nwhere they are missing. To this end, the similarity between city neighborhoods\nis determined based on background data, i.e., from geographic information\nsystems. Using the derived similarity values, we analyze the adaptation of\noccupancy rates from monitored- to unmonitored parking areas.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 18:43:24 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Ionita", "Andrei", ""], ["Pomp", "Andr\u00e9", ""], ["Cochez", "Michael", ""], ["Meisen", "Tobias", ""], ["Decker", "Stefan", ""]]}, {"id": "1908.03632", "submitter": "Ranya Aloufi", "authors": "Ranya Aloufi, Hamed Haddadi, David Boyle", "title": "Emotionless: Privacy-Preserving Speech Analysis for Voice Assistants", "comments": "5 pages, 4 figures, privacy Preserving Machine Learning Workshop, CCS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-enabled interactions provide more human-like experiences in many\npopular IoT systems. Cloud-based speech analysis services extract useful\ninformation from voice input using speech recognition techniques. The voice\nsignal is a rich resource that discloses several possible states of a speaker,\nsuch as emotional state, confidence and stress levels, physical condition, age,\ngender, and personal traits. Service providers can build a very accurate\nprofile of a user's demographic category, personal preferences, and may\ncompromise privacy. To address this problem, a privacy-preserving intermediate\nlayer between users and cloud services is proposed to sanitize the voice input.\nIt aims to maintain utility while preserving user privacy. It achieves this by\ncollecting real time speech data and analyzes the signal to ensure privacy\nprotection prior to sharing of this data with services providers. Precisely,\nthe sensitive representations are extracted from the raw signal by using\ntransformation functions and then wrapped it via voice conversion technology.\nExperimental evaluation based on emotion recognition to assess the efficacy of\nthe proposed method shows that identification of sensitive emotional state of\nthe speaker is reduced by ~96 %.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 21:11:45 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Aloufi", "Ranya", ""], ["Haddadi", "Hamed", ""], ["Boyle", "David", ""]]}, {"id": "1908.03640", "submitter": "Jason R.C. Nurse Dr", "authors": "Lukas Halgas and Ioannis Agrafiotis and Jason R. C. Nurse", "title": "Catching the Phish: Detecting Phishing Attacks using Recurrent Neural\n  Networks (RNNs)", "comments": "13 pages", "journal-ref": "20th World Conference on Information Security Applications (WISA\n  2019)", "doi": "10.1007/978-3-030-39303-8_17", "report-no": null, "categories": "cs.CR cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of online services in our daily lives has been accompanied by a\nrange of malicious attempts to trick individuals into performing undesired\nactions, often to the benefit of the adversary. The most popular medium of\nthese attempts is phishing attacks, particularly through emails and websites.\nIn order to defend against such attacks, there is an urgent need for automated\nmechanisms to identify this malevolent content before it reaches users. Machine\nlearning techniques have gradually become the standard for such classification\nproblems. However, identifying common measurable features of phishing content\n(e.g., in emails) is notoriously difficult. To address this problem, we engage\nin a novel study into a phishing content classifier based on a recurrent neural\nnetwork (RNN), which identifies such features without human input. At this\nstage, we scope our research to emails, but our approach can be extended to\napply to websites. Our results show that the proposed system outperforms\nstate-of-the-art tools. Furthermore, our classifier is efficient and takes into\naccount only the text and, in particular, the textual structure of the email.\nSince these features are rarely considered in email classification, we argue\nthat our classifier can complement existing classifiers with high information\ngain.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 21:37:42 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Halgas", "Lukas", ""], ["Agrafiotis", "Ioannis", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "1908.03669", "submitter": "Yunan Wu", "authors": "Yunan Wu and Lan Wang", "title": "A Survey of Tuning Parameter Selection for High-dimensional Regression", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penalized (or regularized) regression, as represented by Lasso and its\nvariants, has become a standard technique for analyzing high-dimensional data\nwhen the number of variables substantially exceeds the sample size. The\nperformance of penalized regression relies crucially on the choice of the\ntuning parameter, which determines the amount of regularization and hence the\nsparsity level of the fitted model. The optimal choice of tuning parameter\ndepends on both the structure of the design matrix and the unknown random error\ndistribution (variance, tail behavior, etc). This article reviews the current\nliterature of tuning parameter selection for high-dimensional regression from\nboth theoretical and practical perspectives. We discuss various strategies that\nchoose the tuning parameter to achieve prediction accuracy or support recovery.\nWe also review several recently proposed methods for tuning-free\nhigh-dimensional regression.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 02:22:42 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Wu", "Yunan", ""], ["Wang", "Lan", ""]]}, {"id": "1908.03673", "submitter": "Xiongwei Wu", "authors": "Xiongwei Wu, Doyen Sahoo, Steven C.H. Hoi", "title": "Recent Advances in Deep Learning for Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is a fundamental visual recognition problem in computer\nvision and has been widely studied in the past decades. Visual object detection\naims to find objects of certain target classes with precise localization in a\ngiven image and assign each object instance a corresponding class label. Due to\nthe tremendous successes of deep learning based image classification, object\ndetection techniques using deep learning have been actively studied in recent\nyears. In this paper, we give a comprehensive survey of recent advances in\nvisual object detection with deep learning. By reviewing a large body of recent\nrelated work in literature, we systematically analyze the existing object\ndetection frameworks and organize the survey into three major parts: (i)\ndetection components, (ii) learning strategies, and (iii) applications &\nbenchmarks. In the survey, we cover a variety of factors affecting the\ndetection performance in detail, such as detector architectures, feature\nlearning, proposal generation, sampling strategies, etc. Finally, we discuss\nseveral future directions to facilitate and spur future research for visual\nobject detection with deep learning. Keywords: Object Detection, Deep Learning,\nDeep Convolutional Neural Networks\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 02:54:17 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Wu", "Xiongwei", ""], ["Sahoo", "Doyen", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "1908.03679", "submitter": "Francesco Caliva PhD", "authors": "Francesco Caliva, Claudia Iriondo, Alejandro Morales Martinez,\n  Sharmila Majumdar, Valentina Pedoia", "title": "Distance Map Loss Penalty Term for Semantic Segmentation", "comments": "Medical Imaging with Deep Learning (MIDL2019) Conference\n  [arXiv:1907.08612], Extended Abstract", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/B1eIcvS45V", "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Convolutional neural networks for semantic segmentation suffer from low\nperformance at object boundaries. In medical imaging, accurate representation\nof tissue surfaces and volumes is important for tracking of disease biomarkers\nsuch as tissue morphology and shape features. In this work, we propose a novel\ndistance map derived loss penalty term for semantic segmentation. We propose to\nuse distance maps, derived from ground truth masks, to create a penalty term,\nguiding the network's focus towards hard-to-segment boundary regions. We\ninvestigate the effects of this penalizing factor against cross-entropy, Dice,\nand focal loss, among others, evaluating performance on a 3D MRI bone\nsegmentation task from the publicly available Osteoarthritis Initiative\ndataset. We observe a significant improvement in the quality of segmentation,\nwith better shape preservation at bone boundaries and areas affected by partial\nvolume. We ultimately aim to use our loss penalty term to improve the\nextraction of shape biomarkers and derive metrics to quantitatively evaluate\nthe preservation of shape.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 03:37:18 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Caliva", "Francesco", ""], ["Iriondo", "Claudia", ""], ["Martinez", "Alejandro Morales", ""], ["Majumdar", "Sharmila", ""], ["Pedoia", "Valentina", ""]]}, {"id": "1908.03682", "submitter": "Yang Liu", "authors": "Yang Liu, Jianpeng Zhang, Chao Gao, Jinghua Qu, Lixin Ji", "title": "Natural-Logarithm-Rectified Activation Function in Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation functions play a key role in providing remarkable performance in\ndeep neural networks, and the rectified linear unit (ReLU) is one of the most\nwidely used activation functions. Various new activation functions and\nimprovements on ReLU have been proposed, but each carry performance drawbacks.\nIn this paper, we propose an improved activation function, which we name the\nnatural-logarithm-rectified linear unit (NLReLU). This activation function uses\nthe parametric natural logarithmic transform to improve ReLU and is simply\ndefined as. NLReLU not only retains the sparse activation characteristic of\nReLU, but it also alleviates the \"dying ReLU\" and vanishing gradient problems\nto some extent. It also reduces the bias shift effect and heteroscedasticity of\nneuron data distributions among network layers in order to accelerate the\nlearning process. The proposed method was verified across ten convolutional\nneural networks with different depths for two essential datasets. Experiments\nillustrate that convolutional neural networks with NLReLU exhibit higher\naccuracy than those with ReLU, and that NLReLU is comparable to other\nwell-known activation functions. NLReLU provides 0.16% and 2.04% higher\nclassification accuracy on average compared to ReLU when used in shallow\nconvolutional neural networks with the MNIST and CIFAR-10 datasets,\nrespectively. The average accuracy of deep convolutional neural networks with\nNLReLU is 1.35% higher on average with the CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 03:51:36 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 02:24:49 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Liu", "Yang", ""], ["Zhang", "Jianpeng", ""], ["Gao", "Chao", ""], ["Qu", "Jinghua", ""], ["Ji", "Lixin", ""]]}, {"id": "1908.03692", "submitter": "Guanghao Yin", "authors": "Guanghao Yin, Shouqian Sun, Hui Zhang, Dian Yu, Chao Li, Kejun Zhang,\n  Ning Zou", "title": "User independent Emotion Recognition with Residual Signal-Image Network", "comments": null, "journal-ref": "ICIP2019", "doi": "10.1109/ICIP.2019.8803627", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User independent emotion recognition with large scale physiological signals\nis a tough problem. There exist many advanced methods but they are conducted\nunder relatively small datasets with dozens of subjects. Here, we propose\nRes-SIN, a novel end-to-end framework using Electrodermal Activity(EDA) signal\nimages to classify human emotion. We first apply convex optimization-based EDA\n(cvxEDA) to decompose signals and mine the static and dynamic emotion changes.\nThen, we transform decomposed signals to images so that they can be effectively\nprocessed by CNN frameworks. The Res-SIN combines individual emotion features\nand external emotion benchmarks to accelerate convergence. We evaluate our\napproach on the PMEmo dataset, the currently largest emotional dataset\ncontaining music and EDA signals. To the best of author's knowledge, our method\nis the first attempt to classify large scale subject-independent emotion with\n7962 pieces of EDA signals from 457 subjects. Experimental results demonstrate\nthe reliability of our model and the binary classification accuracy of 73.65%\nand 73.43% on arousal and valence dimension can be used as a baseline.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 05:18:21 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 01:28:18 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yin", "Guanghao", ""], ["Sun", "Shouqian", ""], ["Zhang", "Hui", ""], ["Yu", "Dian", ""], ["Li", "Chao", ""], ["Zhang", "Kejun", ""], ["Zou", "Ning", ""]]}, {"id": "1908.03731", "submitter": "Miroslav Bogdanovic", "authors": "Miroslav Bogdanovic, Ludovic Righetti", "title": "Learning to Explore in Motion and Interaction Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model free reinforcement learning suffers from the high sampling complexity\ninherent to robotic manipulation or locomotion tasks. Most successful\napproaches typically use random sampling strategies which leads to slow policy\nconvergence. In this paper we present a novel approach for efficient\nexploration that leverages previously learned tasks. We exploit the fact that\nthe same system is used across many tasks and build a generative model for\nexploration based on data from previously solved tasks to improve learning new\ntasks. The approach also enables continuous learning of improved exploration\nstrategies as novel tasks are learned. Extensive simulations on a robot\nmanipulator performing a variety of motion and contact interaction tasks\ndemonstrate the capabilities of the approach. In particular, our experiments\nsuggest that the exploration strategy can more than double learning speed,\nespecially when rewards are sparse. Moreover, the algorithm is robust to task\nvariations and parameter tuning, making it beneficial for complex robotic\nproblems.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 11:04:42 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Bogdanovic", "Miroslav", ""], ["Righetti", "Ludovic", ""]]}, {"id": "1908.03735", "submitter": "Bin Zhao", "authors": "Bin Zhao, Shuxue Ding, Hong Wu, Guohua Liu, Chen Cao, Song Jin,\n  Zhiyang Liu", "title": "Automatic acute ischemic stroke lesion segmentation using\n  semi-supervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ischemic stroke is a common disease in the elderly population, which can\ncause long-term disability and even death. However, the time window for\ntreatment of ischemic stroke in its acute stage is very short. To fast localize\nand quantitively evaluate the acute ischemic stroke (AIS) lesions, many\ndeep-learning-based lesion segmentation methods have been proposed in the\nliterature, where a deep convolutional neural network (CNN) was trained on\nhundreds of fully labeled subjects with accurate annotations of AIS lesions.\nDespite that high segmentation accuracy can be achieved, the accurate labels\nshould be annotated by experienced clinicians, and it is therefore very\ntime-consuming to obtain a large number of fully labeled subjects. In this\npaper, we propose a semi-supervised method to automatically segment AIS lesions\nin diffusion weighted images and apparent diffusion coefficient maps. By using\na large number of weakly labeled subjects and a small number of fully labeled\nsubjects, our proposed method is able to accurately detect and segment the AIS\nlesions. In particular, our proposed method consists of three parts: 1) a\ndouble-path classification net (DPC-Net) trained in a weakly-supervised way is\nused to detect the suspicious regions of AIS lesions; 2) a pixel-level K-Means\nclustering algorithm is used to identify the hyperintensive regions on the\nDWIs; and 3) a region-growing algorithm combines the outputs of the DPC-Net and\nthe K-Means to obtain the final precise lesion segmentation. In our experiment,\nwe use 460 weakly labeled subjects and 15 fully labeled subjects to train and\nfine-tune the proposed method. By evaluating on a clinical dataset with 150\nfully labeled subjects, our proposed method achieves a mean dice coefficient of\n0.642, and a lesion-wise F1 score of 0.822.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 11:48:02 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 02:53:45 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 13:20:00 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhao", "Bin", ""], ["Ding", "Shuxue", ""], ["Wu", "Hong", ""], ["Liu", "Guohua", ""], ["Cao", "Chen", ""], ["Jin", "Song", ""], ["Liu", "Zhiyang", ""]]}, {"id": "1908.03738", "submitter": "Donghuo Zeng", "authors": "Haoting Liang, Donghuo Zeng, Yi Yu, Keizo Oyama", "title": "Personalized Music Recommendation with Triplet Network", "comments": "1 figure; 1 table", "journal-ref": "DEIM 2019", "doi": null, "report-no": "SU-4240-720", "categories": "cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since many online music services emerged in recent years so that effective\nmusic recommendation systems are desirable. Some common problems in\nrecommendation system like feature representations, distance measure and cold\nstart problems are also challenges for music recommendation. In this paper, I\nproposed a triplet neural network, exploiting both positive and negative\nsamples to learn the representation and distance measure between users and\nitems, to solve the recommendation task.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 12:03:55 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Liang", "Haoting", ""], ["Zeng", "Donghuo", ""], ["Yu", "Yi", ""], ["Oyama", "Keizo", ""]]}, {"id": "1908.03747", "submitter": "Sioan Zohar", "authors": "Sioan Zohar and Chun-Hong Yoon", "title": "Bi-cross validation for estimating spectral clustering hyper parameters", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": "10.1017/S0885715620000214", "report-no": null, "categories": "stat.ML cs.LG physics.acc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One challenge impeding the analysis of terabyte scale x-ray scattering data\nfrom the Linac Coherent Light Source LCLS, is determining the number of\nclusters required for the execution of traditional clustering algorithms. Here\nwe demonstrate that previous work using bi-cross validation (BCV) to determine\nthe number of singular vectors directly maps to the spectral clustering problem\nof estimating both the number of clusters and hyper parameter values. These\nresults indicate that the process of estimating the number of clusters should\nnot be divorced from the process of estimating other hyper parameters. Applying\nthis method to LCLS x-ray scattering data enables the identification of dropped\nshots without manually setting boundaries on detector fluence and provides a\npath towards identifying rare and anomalous events.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 13:14:33 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 15:50:22 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 18:34:15 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Zohar", "Sioan", ""], ["Yoon", "Chun-Hong", ""]]}, {"id": "1908.03748", "submitter": "Huy Kang Kim", "authors": "Kyung Ho Park, Eunjo Lee, Huy Kang Kim", "title": "Show Me Your Account: Detecting MMORPG Game Bot Leveraging Financial\n  Analysis with LSTM", "comments": "10 pages, 1 figure, 5 tables, In Proceedings of the 20th World\n  Conference on Information Security and Applications (WISA) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of MMORPG market, game bot detection has become an\nessential task for maintaining stable in-game ecosystem. To classify bots from\nnormal users, detection methods are proposed in both game client and\nserver-side. Among various classification methods, data mining method in\nserver-side captured unique characteristics of bots efficiently. For features\nused in data mining, behavioral and social actions of character are analyzed\nwith numerous algorithms. However, bot developers can evade the previous\ndetection methods by changing bot's activities continuously. Eventually,\noverall maintenance cost increases because the selected features need to be\nupdated along with the change of bot's behavior. To overcome this limitation,\nwe propose improved bot detection method with financial analysis. As bot's\nactivity absolutely necessitates the change of financial status, analyzing\nfinancial fluctuation effectively captures bots as a key feature. We trained\nand tested model with actual data of Aion, a leading MMORPG in Asia. Leveraging\nthat LSTM efficiently recognizes time-series movement of data, we achieved\nmeaningful detection performance. Further on this model, we expect sustainable\nbot detection system in the near future.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 13:20:32 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Park", "Kyung Ho", ""], ["Lee", "Eunjo", ""], ["Kim", "Huy Kang", ""]]}, {"id": "1908.03761", "submitter": "Xiaoqiang Wang", "authors": "Xiaoqiang Wang, Liangjun Ke, Zhimin Qiao, and Xinghua Chai", "title": "Large-Scale Traffic Signal Control Using a Novel Multi-Agent\n  Reinforcement Learning", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": "10.1109/TCYB.2020.3015811", "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the optimal signal timing strategy is a difficult task for the\nproblem of large-scale traffic signal control (TSC). Multi-Agent Reinforcement\nLearning (MARL) is a promising method to solve this problem. However, there is\nstill room for improvement in extending to large-scale problems and modeling\nthe behaviors of other agents for each individual agent. In this paper, a new\nMARL, called Cooperative double Q-learning (Co-DQL), is proposed, which has\nseveral prominent features. It uses a highly scalable independent double\nQ-learning method based on double estimators and the UCB policy, which can\neliminate the over-estimation problem existing in traditional independent\nQ-learning while ensuring exploration. It uses mean field approximation to\nmodel the interaction among agents, thereby making agents learn a better\ncooperative strategy. In order to improve the stability and robustness of the\nlearning process, we introduce a new reward allocation mechanism and a local\nstate sharing method. In addition, we analyze the convergence properties of the\nproposed algorithm. Co-DQL is applied on TSC and tested on a multi-traffic\nsignal simulator. According to the results obtained on several traffic\nscenarios, Co- DQL outperforms several state-of-the-art decentralized MARL\nalgorithms. It can effectively shorten the average waiting time of the vehicles\nin the whole road system.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 14:19:21 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 12:01:34 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Wang", "Xiaoqiang", ""], ["Ke", "Liangjun", ""], ["Qiao", "Zhimin", ""], ["Chai", "Xinghua", ""]]}, {"id": "1908.03770", "submitter": "Subhabrata Dutta", "authors": "Subhabrata Dutta, Dipankar Das and Tanmoy Chakraborty", "title": "Modeling Engagement Dynamics of Online Discussions using Relativistic\n  Gravitational Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online discussions are valuable resources to study user behaviour on a\ndiverse set of topics. Unlike previous studies which model a discussion in a\nstatic manner, in the present study, we model it as a time-varying process and\nsolve two inter-related problems -- predict which user groups will get engaged\nwith an ongoing discussion, and forecast the growth rate of a discussion in\nterms of the number of comments. We propose RGNet (Relativistic Gravitational\nNerwork), a novel algorithm that uses Einstein Field Equations of gravity to\nmodel online discussions as `cloud of dust' hovering over a user spacetime\nmanifold, attracting users of different groups at different rates over time. We\nalso propose GUVec, a global user embedding method for an online discussion,\nwhich is used by RGNet to predict temporal user engagement. RGNet leverages\ndifferent textual and network-based features to learn the dust distribution for\ndiscussions.\n  We employ four baselines -- first two using LSTM architecture, third one\nusing Newtonian model of gravity, and fourth one using a logistic regression\nadopted from a previous work on engagement prediction. Experiments on Reddit\ndataset show that RGNet achieves 0.72 Micro F1 score and 6.01% average error\nfor temporal engagement prediction of user groups and growth rate forecasting,\nrespectively, outperforming all the baselines significantly. We further employ\nRGNet to predict non-temporal engagement -- whether users will comment to a\ngiven post or not. RGNet achieves 0.62 AUC for this task, outperforming\nexisting baseline by 8.77% AUC.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 15:00:29 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Dutta", "Subhabrata", ""], ["Das", "Dipankar", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "1908.03781", "submitter": "Arthur Franz", "authors": "Arthur Franz, Oleksandr Antonenko, Roman Soletskyi", "title": "A theory of incremental compression", "comments": "24 pages, 3 figures", "journal-ref": "Information Sciences, Volume 547, Pages 28-48, 2021", "doi": "10.1016/j.ins.2020.08.035", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to find short representations, i.e. to compress data, is crucial\nfor many intelligent systems. We present a theory of incremental compression\nshowing that arbitrary data strings, that can be described by a set of\nfeatures, can be compressed by searching for those features incrementally,\nwhich results in a partition of the information content of the string into a\ncomplete set of pairwise independent pieces. The description length of this\npartition turns out to be close to optimal in terms of the Kolmogorov\ncomplexity of the string. Exploiting this decomposition, we introduce ALICE - a\ncomputable ALgorithm for Incremental ComprEssion - and derive an expression for\nits time complexity. Finally, we show that our concept of a feature is closely\nrelated to Martin-L\\\"of randomness tests, thereby formalizing the meaning of\n\"property\" for computable objects.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 16:55:42 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 12:11:05 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Franz", "Arthur", ""], ["Antonenko", "Oleksandr", ""], ["Soletskyi", "Roman", ""]]}, {"id": "1908.03782", "submitter": "Li Zhong", "authors": "Tiantian Zhang, Li Zhong, Bo Yuan", "title": "A Critical Note on the Evaluation of Clustering Algorithms", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental evaluation is a major research methodology for investigating\nclustering algorithms and many other machine learning algorithms. For this\npurpose, a number of benchmark datasets have been widely used in the literature\nand their quality plays a key role on the value of the research work. However,\nin most of the existing studies, little attention has been paid to the\nproperties of the datasets and they are often regarded as black-box problems.\nFor example, it is common to use datasets intended for classification in\nclustering research and assume class la-bels as the ground truth for judging\nthe quality of cluster-ing. In our work, with the help of advanced\nvisualization and dimension reduction techniques, we show that this practice\nmay seriously compromise the research quality and produce misleading results.\nWe suggest that the applicability of existing benchmark datasets should be\ncarefully revisited and significant efforts need to be devoted to improving the\ncurrent practice of experimental evaluation of clustering algorithms to ensure\nan essential match between algorithms and problems.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 16:58:52 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 14:40:41 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Zhang", "Tiantian", ""], ["Zhong", "Li", ""], ["Yuan", "Bo", ""]]}, {"id": "1908.03809", "submitter": "Jonathan Howe", "authors": "Jonathan Howe, Kyle Pula, Aaron A. Reite", "title": "Conditional Generative Adversarial Networks for Data Augmentation and\n  Adaptation in Remotely Sensed Imagery", "comments": null, "journal-ref": null, "doi": "10.1117/12.2529586", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty in obtaining labeled data relevant to a given task is among\nthe most common and well-known practical obstacles to applying deep learning\ntechniques to new or even slightly modified domains. The data volumes required\nby the current generation of supervised learning algorithms typically far\nexceed what a human needs to learn and complete a given task. We investigate\nways to expand a given labeled corpus of remote sensed imagery into a larger\ncorpus using Generative Adversarial Networks (GANs). We then measure how these\nadditional synthetic data affect supervised machine learning performance on an\nobject detection task.\n  Our data driven strategy is to train GANs to (1) generate synthetic\nsegmentation masks and (2) generate plausible synthetic remote sensing imagery\ncorresponding to these segmentation masks. Run sequentially, these GANs allow\nthe generation of synthetic remote sensing imagery complete with segmentation\nlabels. We apply this strategy to the data set from ISPRS' 2D Semantic Labeling\nContest - Potsdam, with a follow on vehicle detection task. We find that in\nscenarios with limited training data, augmenting the available data with such\nsynthetically generated data can improve detector performance.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 21:26:54 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Howe", "Jonathan", ""], ["Pula", "Kyle", ""], ["Reite", "Aaron A.", ""]]}, {"id": "1908.03825", "submitter": "Manojkumar Rangasamy Kannadasan", "authors": "Saratchandra Indrakanti, Svetlana Strunjas, Shubhangi Tandon,\n  Manojkumar Rangasamy Kannadasan", "title": "Influence of Neighborhood on the Preference of an Item in eCommerce\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surfacing a ranked list of items for a search query to help buyers discover\ninventory and make purchase decisions is a critical problem in eCommerce\nsearch. Typically, items are independently predicted with a probability of sale\nwith respect to a given search query. But in a dynamic marketplace like eBay,\neven for a single product, there are various different factors distinguishing\none item from another which can influence the purchase decision for the user.\nUsers have to make a purchase decision by considering all of these options.\nMajority of the existing learning to rank algorithms model the relative\nrelevance between labeled items only at the loss functions like pairwise or\nlist-wise losses. But they are limited to point-wise scoring functions where\nitems are ranked independently based on the features of the item itself. In\nthis paper, we study the influence of an item's neighborhood to its purchase\ndecision. Here, we consider the neighborhood as the items ranked above and\nbelow the current item in search results. By adding delta features comparing\nitems within a neighborhood and learning a ranking model, we are able to\nexperimentally show that the new ranker with delta features outperforms our\nbaseline ranker in terms of Mean Reciprocal Rank (MRR). The ranking models with\nproposed delta features result in $3-5\\%$ improvement in MRR over the baseline\nmodel. We also study impact of different sizes for neighborhood. Experimental\nresults show that neighborhood size $3$ perform the best based on MRR with an\nimprovement of $4-5\\%$ over the baseline model.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 23:21:56 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 17:15:31 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Indrakanti", "Saratchandra", ""], ["Strunjas", "Svetlana", ""], ["Tandon", "Shubhangi", ""], ["Kannadasan", "Manojkumar Rangasamy", ""]]}, {"id": "1908.03826", "submitter": "Junru Wu", "authors": "Orest Kupyn, Tetiana Martyniuk, Junru Wu, Zhangyang Wang", "title": "DeblurGAN-v2: Deblurring (Orders-of-Magnitude) Faster and Better", "comments": "Accepted in ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new end-to-end generative adversarial network (GAN) for single\nimage motion deblurring, named DeblurGAN-v2, which considerably boosts\nstate-of-the-art deblurring efficiency, quality, and flexibility. DeblurGAN-v2\nis based on a relativistic conditional GAN with a double-scale discriminator.\nFor the first time, we introduce the Feature Pyramid Network into deblurring,\nas a core building block in the generator of DeblurGAN-v2. It can flexibly work\nwith a wide range of backbones, to navigate the balance between performance and\nefficiency. The plug-in of sophisticated backbones (e.g., Inception-ResNet-v2)\ncan lead to solid state-of-the-art deblurring. Meanwhile, with light-weight\nbackbones (e.g., MobileNet and its variants), DeblurGAN-v2 reaches 10-100 times\nfaster than the nearest competitors, while maintaining close to\nstate-of-the-art results, implying the option of real-time video deblurring. We\ndemonstrate that DeblurGAN-v2 obtains very competitive performance on several\npopular benchmarks, in terms of deblurring quality (both objective and\nsubjective), as well as efficiency. Besides, we show the architecture to be\neffective for general image restoration tasks too. Our codes, models and data\nare available at: https://github.com/KupynOrest/DeblurGANv2\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 23:28:09 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Kupyn", "Orest", ""], ["Martyniuk", "Tetiana", ""], ["Wu", "Junru", ""], ["Wang", "Zhangyang", ""]]}, {"id": "1908.03830", "submitter": "Kiran Byadarhaly", "authors": "Harish Kashyap K, Kiran Byadarhaly and Saumya Shah", "title": "Supervised Negative Binomial Classifier for Probabilistic Record Linkage", "comments": null, "journal-ref": null, "doi": null, "report-no": "03a", "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need of the linking records across various databases, we\npropose a novel graphical model based classifier that uses a mixture of Poisson\ndistributions with latent variables. The idea is to derive insight into each\npair of hypothesis records that match by inferring its underlying latent rate\nof error using Bayesian Modeling techniques. The novel approach of using gamma\npriors for learning the latent variables along with supervised labels is unique\nand allows for active learning. The naive assumption is made deliberately as to\nthe independence of the fields to propose a generalized theory for this class\nof problems and not to undermine the hierarchical dependencies that could be\npresent in different scenarios. This classifier is able to work with sparse and\nstreaming data. The application to record linkage is able to meet several\nchallenges of sparsity, data streams and varying nature of the data-sets.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 00:25:13 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["K", "Harish Kashyap", ""], ["Byadarhaly", "Kiran", ""], ["Shah", "Saumya", ""]]}, {"id": "1908.03833", "submitter": "Philipp Zimmermann", "authors": "Philipp Grohs, Fabian Hornung, Arnulf Jentzen, Philipp Zimmermann", "title": "Space-time error estimates for deep neural network approximations for\n  differential equations", "comments": "86 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years deep artificial neural networks (DNNs) have very\nsuccessfully been used in numerical simulations for a wide variety of\ncomputational problems including computer vision, image classification, speech\nrecognition, natural language processing, as well as computational\nadvertisement. In addition, it has recently been proposed to approximate\nsolutions of partial differential equations (PDEs) by means of stochastic\nlearning problems involving DNNs. There are now also a few rigorous\nmathematical results in the scientific literature which provide error estimates\nfor such deep learning based approximation methods for PDEs. All of these\narticles provide spatial error estimates for neural network approximations for\nPDEs but do not provide error estimates for the entire space-time error for the\nconsidered neural network approximations. It is the subject of the main result\nof this article to provide space-time error estimates for DNN approximations of\nEuler approximations of certain perturbed differential equations. Our proof of\nthis result is based (i) on a certain artificial neural network (ANN) calculus\nand (ii) on ANN approximation results for products of the form $[0,T]\\times\n\\mathbb{R}^d\\ni (t,x)\\mapsto tx\\in \\mathbb{R}^d$ where $T\\in (0,\\infty)$, $d\\in\n\\mathbb{N}$, which we both develop within this article.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 00:40:43 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Grohs", "Philipp", ""], ["Hornung", "Fabian", ""], ["Jentzen", "Arnulf", ""], ["Zimmermann", "Philipp", ""]]}, {"id": "1908.03835", "submitter": "Xinyu Gong", "authors": "Xinyu Gong, Shiyu Chang, Yifan Jiang, Zhangyang Wang", "title": "AutoGAN: Neural Architecture Search for Generative Adversarial Networks", "comments": "accepted by ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has witnessed prevailing success in image\nclassification and (very recently) segmentation tasks. In this paper, we\npresent the first preliminary study on introducing the NAS algorithm to\ngenerative adversarial networks (GANs), dubbed AutoGAN. The marriage of NAS and\nGANs faces its unique challenges. We define the search space for the generator\narchitectural variations and use an RNN controller to guide the search, with\nparameter sharing and dynamic-resetting to accelerate the process. Inception\nscore is adopted as the reward, and a multi-level search strategy is introduced\nto perform NAS in a progressive way. Experiments validate the effectiveness of\nAutoGAN on the task of unconditional image generation. Specifically, our\ndiscovered architectures achieve highly competitive performance compared to\ncurrent state-of-the-art hand-crafted GANs, e.g., setting new state-of-the-art\nFID scores of 12.42 on CIFAR-10, and 31.01 on STL-10, respectively. We also\nconclude with a discussion of the current limitations and future potential of\nAutoGAN. The code is available at https://github.com/TAMU-VITA/AutoGAN\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 00:52:30 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Gong", "Xinyu", ""], ["Chang", "Shiyu", ""], ["Jiang", "Yifan", ""], ["Wang", "Zhangyang", ""]]}, {"id": "1908.03840", "submitter": "Dilini Rajapaksha", "authors": "Dilini Rajapaksha, Christoph Bergmeir, Wray Buntine", "title": "LoRMIkA: Local rule-based model interpretability with k-optimal\n  associations", "comments": "26 pages, 3 figures", "journal-ref": "journal={Information Sciences}, volume={540}, pages={221--241},\n  year={2020}, publisher={Elsevier}", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As we rely more and more on machine learning models for real-life\ndecision-making, being able to understand and trust the predictions becomes\never more important. Local explainer models have recently been introduced to\nexplain the predictions of complex machine learning models at the instance\nlevel. In this paper, we propose Local Rule-based Model Interpretability with\nk-optimal Associations (LoRMIkA), a novel model-agnostic approach that obtains\nk-optimal association rules from a neighbourhood of the instance to be\nexplained. Compared with other rule-based approaches in the literature, we\nargue that the most predictive rules are not necessarily the rules that provide\nthe best explanations. Consequently, the LoRMIkA framework provides a flexible\nway to obtain predictive and interesting rules. It uses an efficient search\nalgorithm guaranteed to find the k-optimal rules with respect to objectives\nsuch as confidence, lift, leverage, coverage, and support. It also provides\nmultiple rules which explain the decision and counterfactual rules, which give\nindications for potential changes to obtain different outputs for given\ninstances. We compare our approach to other state-of-the-art approaches in\nlocal model interpretability on three different datasets and achieve\ncompetitive results in terms of local accuracy and interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 02:42:27 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 02:44:10 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Rajapaksha", "Dilini", ""], ["Bergmeir", "Christoph", ""], ["Buntine", "Wray", ""]]}, {"id": "1908.03841", "submitter": "Carolyn Talcott", "authors": "Akos Vertes, Albert-Baskar Arul, Peter Avar, Andrew R. Korte, Lida\n  Parvin, Ziad J. Sahab, Deborah I. Bunin, Merrill Knapp, Denise Nishita,\n  Andrew Poggio, Mark-Oliver Stehr, Carolyn L. Talcott, Brian M. Davis,\n  Christine A. Morton, Christopher J. Sevinsky and Maria I. Zavodszky", "title": "Transcriptional Response of SK-N-AS Cells to Methamidophos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG q-bio.CB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcriptomics response of SK-N-AS cells to methamidophos (an acetylcholine\nesterase inhibitor) exposure was measured at 10 time points between 0.5 and 48\nh. The data was analyzed using a combination of traditional statistical methods\nand novel machine learning algorithms for detecting anomalous behavior and\ninfer causal relations between time profiles. We identified several processes\nthat appeared to be upregulated in cells treated with methamidophos including:\nunfolded protein response, response to cAMP, calcium ion response, and\ncell-cell signaling. The data confirmed the expected consequence of\nacetylcholine buildup. In addition, transcripts with potentially key roles were\nidentified and causal networks relating these transcripts were inferred using\ntwo different computational methods: Siamese convolutional networks and time\nwarp causal inference. Two types of anomaly detection algorithms, one based on\nAutoencoders and the other one based on Generative Adversarial Networks (GANs),\nwere applied to narrow down the set of relevant transcripts.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 02:53:56 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Vertes", "Akos", ""], ["Arul", "Albert-Baskar", ""], ["Avar", "Peter", ""], ["Korte", "Andrew R.", ""], ["Parvin", "Lida", ""], ["Sahab", "Ziad J.", ""], ["Bunin", "Deborah I.", ""], ["Knapp", "Merrill", ""], ["Nishita", "Denise", ""], ["Poggio", "Andrew", ""], ["Stehr", "Mark-Oliver", ""], ["Talcott", "Carolyn L.", ""], ["Davis", "Brian M.", ""], ["Morton", "Christine A.", ""], ["Sevinsky", "Christopher J.", ""], ["Zavodszky", "Maria I.", ""]]}, {"id": "1908.03848", "submitter": "Yuening Li", "authors": "Yuening Li, Ninghao Liu, Jundong Li, Mengnan Du, Xia Hu", "title": "Deep Structured Cross-Modal Anomaly Detection", "comments": "8 pages, in Proceedings of the 2019 International Joint Conference on\n  Neural Networks (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a fundamental problem in data mining field with many\nreal-world applications. A vast majority of existing anomaly detection methods\npredominately focused on data collected from a single source. In real-world\napplications, instances often have multiple types of features, such as images\n(ID photos, finger prints) and texts (bank transaction histories, user online\nsocial media posts), resulting in the so-called multi-modal data. In this\npaper, we focus on identifying anomalies whose patterns are disparate across\ndifferent modalities, i.e., cross-modal anomalies. Some of the data instances\nwithin a multi-modal context are often not anomalous when they are viewed\nseparately in each individual modality, but contains inconsistent patterns when\nmultiple sources are jointly considered. The existence of multi-modal data in\nmany real-world scenarios brings both opportunities and challenges to the\ncanonical task of anomaly detection. On the one hand, in multi-modal data,\ninformation of different modalities may complement each other in improving the\ndetection performance. On the other hand, complicated distributions across\ndifferent modalities call for a principled framework to characterize their\ninherent and complex correlations, which is often difficult to capture with\nconventional linear models. To this end, we propose a novel deep structured\nanomaly detection framework to identify the cross-modal anomalies embedded in\nthe data. Experiments on real-world datasets demonstrate the effectiveness of\nthe proposed framework comparing with the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 04:03:14 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Li", "Yuening", ""], ["Liu", "Ninghao", ""], ["Li", "Jundong", ""], ["Du", "Mengnan", ""], ["Hu", "Xia", ""]]}, {"id": "1908.03849", "submitter": "Yuening Li", "authors": "Yuening Li, Xiao Huang, Jundong Li, Mengnan Du, Na Zou", "title": "SpecAE: Spectral AutoEncoder for Anomaly Detection in Attributed\n  Networks", "comments": "7 pages, in proceedings of the 28th ACM International Conference on\n  Information and Knowledge Management (CIKM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection aims to distinguish observations that are rare and\ndifferent from the majority. While most existing algorithms assume that\ninstances are i.i.d., in many practical scenarios, links describing\ninstance-to-instance dependencies and interactions are available. Such systems\nare called attributed networks. Anomaly detection in attributed networks has\nvarious applications such as monitoring suspicious accounts in social media and\nfinancial fraud in transaction networks. However, it remains a challenging task\nsince the definition of anomaly becomes more complicated and topological\nstructures are heterogeneous with nodal attributes. In this paper, we propose a\nspectral convolution and deconvolution based framework -- SpecAE, to project\nthe attributed network into a tailored space to detect global and community\nanomalies. SpecAE leverages Laplacian sharpening to amplify the distances\nbetween representations of anomalies and the ones of the majority. The learned\nrepresentations along with reconstruction errors are combined with a density\nestimation model to perform the detection. They are trained jointly as an\nend-to-end framework. Experiments on real-world datasets demonstrate the\neffectiveness of SpecAE.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 04:04:29 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 06:41:16 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 05:37:43 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Li", "Yuening", ""], ["Huang", "Xiao", ""], ["Li", "Jundong", ""], ["Du", "Mengnan", ""], ["Zou", "Na", ""]]}, {"id": "1908.03883", "submitter": "Stanislav Morozov", "authors": "Stanislav Morozov, Artem Babenko", "title": "Unsupervised Neural Quantization for Compressed-Domain Similarity Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We tackle the problem of unsupervised visual descriptors compression, which\nis a key ingredient of large-scale image retrieval systems. While the deep\nlearning machinery has benefited literally all computer vision pipelines, the\nexisting state-of-the-art compression methods employ shallow architectures, and\nwe aim to close this gap by our paper. In more detail, we introduce a DNN\narchitecture for the unsupervised compressed-domain retrieval, based on\nmulti-codebook quantization. The proposed architecture is designed to\nincorporate both fast data encoding and efficient distances computation via\nlookup tables. We demonstrate the exceptional advantage of our scheme over\nexisting quantization approaches on several datasets of visual descriptors via\noutperforming the previous state-of-the-art by a large margin.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 10:46:16 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Morozov", "Stanislav", ""], ["Babenko", "Artem", ""]]}, {"id": "1908.03888", "submitter": "Anbang Yao", "authors": "Duo Li, Aojun Zhou, Anbang Yao", "title": "HBONet: Harmonious Bottleneck on Two Orthogonal Dimensions", "comments": "Accepted by ICCV 2019. Code and pretrained models are available at\n  https://github.com/d-li14/HBONet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MobileNets, a class of top-performing convolutional neural network\narchitectures in terms of accuracy and efficiency trade-off, are increasingly\nused in many resourceaware vision applications. In this paper, we present\nHarmonious Bottleneck on two Orthogonal dimensions (HBO), a novel architecture\nunit, specially tailored to boost the accuracy of extremely lightweight\nMobileNets at the level of less than 40 MFLOPs. Unlike existing bottleneck\ndesigns that mainly focus on exploring the interdependencies among the channels\nof either groupwise or depthwise convolutional features, our HBO improves\nbottleneck representation while maintaining similar complexity via jointly\nencoding the feature interdependencies across both spatial and channel\ndimensions. It has two reciprocal components, namely spatial\ncontraction-expansion and channel expansion-contraction, nested in a\nbilaterally symmetric structure. The combination of two interdependent\ntransformations performing on orthogonal dimensions of feature maps enhances\nthe representation and generalization ability of our proposed module,\nguaranteeing compelling performance with limited computational resource and\npower. By replacing the original bottlenecks in MobileNetV2 backbone with HBO\nmodules, we construct HBONets which are evaluated on ImageNet classification,\nPASCAL VOC object detection and Market-1501 person re-identification. Extensive\nexperiments show that with the severe constraint of computational budget our\nmodels outperform MobileNetV2 counterparts by remarkable margins of at most\n6.6%, 6.3% and 5.0% on the above benchmarks respectively. Code and pretrained\nmodels are available at https://github.com/d-li14/HBONet.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 11:37:39 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Li", "Duo", ""], ["Zhou", "Aojun", ""], ["Yao", "Anbang", ""]]}, {"id": "1908.03891", "submitter": "Gregorz Dudek", "authors": "Grzegorz Dudek", "title": "Data-Driven Randomized Learning of Feedforward Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized methods of neural network learning suffer from a problem with the\ngeneration of random parameters as they are difficult to set optimally to\nobtain a good projection space. The standard method draws the parameters from a\nfixed interval which is independent of the data scope and activation function\ntype. This does not lead to good results in the approximation of the strongly\nnonlinear functions. In this work, a method which adjusts the random\nparameters, representing the slopes and positions of the sigmoids, to the\ntarget function features is proposed. The method randomly selects the input\nspace regions, places the sigmoids in these regions and then adjusts the\nsigmoid slopes to the local fluctuations of the target function. This brings\nvery good results in the approximation of the complex target functions when\ncompared to the standard fixed interval method and other methods recently\nproposed in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 12:07:31 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1908.03901", "submitter": "Tomohiro Hayase", "authors": "Tomohiro Hayase", "title": "Almost Sure Asymptotic Freeness of Neural Network Jacobian with\n  Orthogonal Weights", "comments": "The proof of main theorem use the orthogonal invariance of joint\n  distribution, which need further non-trivial discussion. Thus we withdraw\n  this", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-conditioned Jacobian spectrum has a vital role in preventing exploding\nor vanishing gradients and speeding up learning of deep neural networks. Free\nprobability theory helps us to understand and handle the Jacobian spectrum. We\nrigorously show almost sure asymptotic freeness of layer-wise Jacobians of deep\nneural networks as the wide limit. In particular, we treat the case that\nweights are initialized as Haar distributed orthogonal matrices.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 13:05:26 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 04:33:36 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 17:33:58 GMT"}, {"version": "v4", "created": "Wed, 12 Feb 2020 08:36:48 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Hayase", "Tomohiro", ""]]}, {"id": "1908.03918", "submitter": "Changhao Chen", "authors": "Changhao Chen, Chris Xiaoxuan Lu, Bing Wang, Niki Trigoni, Andrew\n  Markham", "title": "DynaNet: Neural Kalman Dynamical Model for Motion Estimation and\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamical models estimate and predict the temporal evolution of physical\nsystems. State Space Models (SSMs) in particular represent the system dynamics\nwith many desirable properties, such as being able to model uncertainty in both\nthe model and measurements, and optimal (in the Bayesian sense) recursive\nformulations e.g. the Kalman Filter. However, they require significant domain\nknowledge to derive the parametric form and considerable hand-tuning to\ncorrectly set all the parameters. Data driven techniques e.g. Recurrent Neural\nNetworks have emerged as compelling alternatives to SSMs with wide success\nacross a number of challenging tasks, in part due to their ability to extract\nrelevant features from rich inputs. They however lack interpretability and\nrobustness to unseen conditions. In this work, we present DynaNet, a hybrid\ndeep learning and time-varying state-space model which can be trained\nend-to-end. Our neural Kalman dynamical model allows us to exploit the relative\nmerits of each approach. We demonstrate state-of-the-art estimation and\nprediction on a number of physically challenging tasks, including visual\nodometry, sensor fusion for visual-inertial navigation and pendulum control. In\naddition we show how DynaNet can indicate failures through investigation of\nproperties such as the rate of innovation (Kalman Gain).\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 15:03:24 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 16:58:17 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Chen", "Changhao", ""], ["Lu", "Chris Xiaoxuan", ""], ["Wang", "Bing", ""], ["Trigoni", "Niki", ""], ["Markham", "Andrew", ""]]}, {"id": "1908.03919", "submitter": "Jogendra Nath Kundu", "authors": "Jogendra Nath Kundu, Maharshi Gor, Dakshit Agrawal, R. Venkatesh Babu", "title": "GAN-Tree: An Incrementally Learned Hierarchical Generative Framework for\n  Multi-Modal Data Distributions", "comments": "ICCV 2019 (code available at https://github.com/val-iisc/GANTree)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the remarkable success of generative adversarial networks, their\nperformance seems less impressive for diverse training sets, requiring learning\nof discontinuous mapping functions. Though multi-mode prior or multi-generator\nmodels have been proposed to alleviate this problem, such approaches may fail\ndepending on the empirically chosen initial mode components. In contrast to\nsuch bottom-up approaches, we present GAN-Tree, which follows a hierarchical\ndivisive strategy to address such discontinuous multi-modal data. Devoid of any\nassumption on the number of modes, GAN-Tree utilizes a novel mode-splitting\nalgorithm to effectively split the parent mode to semantically cohesive\nchildren modes, facilitating unsupervised clustering. Further, it also enables\nincremental addition of new data modes to an already trained GAN-Tree, by\nupdating only a single branch of the tree structure. As compared to prior\napproaches, the proposed framework offers a higher degree of flexibility in\nchoosing a large variety of mutually exclusive and exhaustive tree nodes called\nGAN-Set. Extensive experiments on synthetic and natural image datasets\nincluding ImageNet demonstrate the superiority of GAN-Tree against the prior\nstate-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 15:15:49 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 03:42:52 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 11:56:58 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kundu", "Jogendra Nath", ""], ["Gor", "Maharshi", ""], ["Agrawal", "Dakshit", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "1908.03930", "submitter": "Xiaohan Ding", "authors": "Xiaohan Ding, Yuchen Guo, Guiguang Ding, Jungong Han", "title": "ACNet: Strengthening the Kernel Skeletons for Powerful CNN via\n  Asymmetric Convolution Blocks", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As designing appropriate Convolutional Neural Network (CNN) architecture in\nthe context of a given application usually involves heavy human works or\nnumerous GPU hours, the research community is soliciting the\narchitecture-neutral CNN structures, which can be easily plugged into multiple\nmature architectures to improve the performance on our real-world applications.\nWe propose Asymmetric Convolution Block (ACB), an architecture-neutral\nstructure as a CNN building block, which uses 1D asymmetric convolutions to\nstrengthen the square convolution kernels. For an off-the-shelf architecture,\nwe replace the standard square-kernel convolutional layers with ACBs to\nconstruct an Asymmetric Convolutional Network (ACNet), which can be trained to\nreach a higher level of accuracy. After training, we equivalently convert the\nACNet into the same original architecture, thus requiring no extra computations\nanymore. We have observed that ACNet can improve the performance of various\nmodels on CIFAR and ImageNet by a clear margin. Through further experiments, we\nattribute the effectiveness of ACB to its capability of enhancing the model's\nrobustness to rotational distortions and strengthening the central skeleton\nparts of square convolution kernels.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 16:06:58 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 09:24:11 GMT"}, {"version": "v3", "created": "Sat, 31 Aug 2019 12:50:35 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ding", "Xiaohan", ""], ["Guo", "Yuchen", ""], ["Ding", "Guiguang", ""], ["Han", "Jungong", ""]]}, {"id": "1908.03932", "submitter": "Saber Salehkaleybar", "authors": "Saber Salehkaleybar, AmirEmad Ghassami, Negar Kiyavash, Kun Zhang", "title": "Learning Linear Non-Gaussian Causal Models in the Presence of Latent\n  Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning causal models from observational data\ngenerated by linear non-Gaussian acyclic causal models with latent variables.\nWithout considering the effect of latent variables, one usually infers wrong\ncausal relationships among the observed variables. Under faithfulness\nassumption, we propose a method to check whether there exists a causal path\nbetween any two observed variables. From this information, we can obtain the\ncausal order among them. The next question is then whether or not the causal\neffects can be uniquely identified as well. It can be shown that causal effects\namong observed variables cannot be identified uniquely even under the\nassumptions of faithfulness and non-Gaussianity of exogenous noises. However,\nwe will propose an efficient method to identify the set of all possible causal\neffects that are compatible with the observational data. Furthermore, we\npresent some structural conditions on the causal graph under which we can learn\ncausal effects among observed variables uniquely. We also provide necessary and\nsufficient graphical conditions for unique identification of the number of\nvariables in the system. Experiments on synthetic data and real-world data show\nthe effectiveness of our proposed algorithm on learning causal models.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 16:28:55 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Salehkaleybar", "Saber", ""], ["Ghassami", "AmirEmad", ""], ["Kiyavash", "Negar", ""], ["Zhang", "Kun", ""]]}, {"id": "1908.03935", "submitter": "Vanderson Martins do Rosario", "authors": "Vanderson M. do Rosario, Mauricio Breternitz Jr. and Edson Borin", "title": "Efficiency and Scalability of Multi-Lane Capsule Networks (MLCN)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some Deep Neural Networks (DNN) have what we call lanes, or they can be\nreorganized as such. Lanes are paths in the network which are data-independent\nand typically learn different features or add resilience to the network. Given\ntheir data-independence, lanes are amenable for parallel processing. The\nMulti-lane CapsNet (MLCN) is a proposed reorganization of the Capsule Network\nwhich is shown to achieve better accuracy while bringing highly-parallel lanes.\nHowever, the efficiency and scalability of MLCN had not been systematically\nexamined. In this work, we study the MLCN network with multiple GPUs finding\nthat it is 2x more efficient than the original CapsNet when using\nmodel-parallelism. Further, we present the load balancing problem of\ndistributing heterogeneous lanes in homogeneous or heterogeneous accelerators\nand show that a simple greedy heuristic can be almost 50% faster than a naive\nrandom approach.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 17:04:14 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Rosario", "Vanderson M. do", ""], ["Breternitz", "Mauricio", "Jr."], ["Borin", "Edson", ""]]}, {"id": "1908.03936", "submitter": "Svenja Stark", "authors": "Svenja Stark, Jan Peters and Elmar Rueckert", "title": "Experience Reuse with Probabilistic Movement Primitives", "comments": "8 pages, 5 figures, IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring new robot motor skills is cumbersome, as learning a skill from\nscratch and without prior knowledge requires the exploration of a large space\nof motor configurations. Accordingly, for learning a new task, time could be\nsaved by restricting the parameter search space by initializing it with the\nsolution of a similar task. We present a framework which is able of such\nknowledge transfer from already learned movement skills to a new learning task.\nThe framework combines probabilistic movement primitives with descriptions of\ntheir effects for skill representation. New skills are first initialized with\nparameters inferred from related movement primitives and thereafter adapted to\nthe new task through relative entropy policy search. We compare two different\ntransfer approaches to initialize the search space distribution with data of\nknown skills with a similar effect. We show the different benefits of the two\nknowledge transfer approaches on an object pushing task for a simulated 3-DOF\nrobot. We can show that the quality of the learned skills improves and the\nrequired iterations to learn a new task can be reduced by more than 60% when\npast experiences are utilized.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 17:04:48 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 14:49:09 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Stark", "Svenja", ""], ["Peters", "Jan", ""], ["Rueckert", "Elmar", ""]]}, {"id": "1908.03958", "submitter": "Nishant Kumar", "authors": "Nishant Kumar, Nico Hoffmann, Martin Oelschl\\\"agel, Edmund Koch,\n  Matthias Kirsch, and Stefan Gumhold", "title": "Structural Similarity based Anatomical and Functional Brain Imaging\n  Fusion", "comments": "Accepted at MICCAI-MBIA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal medical image fusion helps in combining contrasting features from\ntwo or more input imaging modalities to represent fused information in a single\nimage. One of the pivotal clinical applications of medical image fusion is the\nmerging of anatomical and functional modalities for fast diagnosis of malignant\ntissues. In this paper, we present a novel end-to-end unsupervised\nlearning-based Convolutional Neural Network (CNN) for fusing the high and low\nfrequency components of MRI-PET grayscale image pairs, publicly available at\nADNI, by exploiting Structural Similarity Index (SSIM) as the loss function\nduring training. We then apply color coding for the visualization of the fused\nimage by quantifying the contribution of each input image in terms of the\npartial derivatives of the fused image. We find that our fusion and\nvisualization approach results in better visual perception of the fused image,\nwhile also comparing favorably to previous methods when applying various\nquantitative assessment metrics.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 20:44:52 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 14:33:49 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 07:45:31 GMT"}, {"version": "v4", "created": "Wed, 18 Sep 2019 20:20:35 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Kumar", "Nishant", ""], ["Hoffmann", "Nico", ""], ["Oelschl\u00e4gel", "Martin", ""], ["Koch", "Edmund", ""], ["Kirsch", "Matthias", ""], ["Gumhold", "Stefan", ""]]}, {"id": "1908.03963", "submitter": "Afshin Oroojlooy", "authors": "Afshin OroojlooyJadid and Davood Hajinezhad", "title": "A Review of Cooperative Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has made significant progress in multi-agent\nsystems in recent years. In this review article, we have focused on presenting\nrecent approaches on Multi-Agent Reinforcement Learning (MARL) algorithms. In\nparticular, we have focused on five common approaches on modeling and solving\ncooperative multi-agent reinforcement learning problems: (I) independent\nlearners, (II) fully observable critic, (III) value function factorization,\n(IV) consensus, and (IV) learn to communicate. First, we elaborate on each of\nthese methods, possible challenges, and how these challenges were mitigated in\nthe relevant papers. If applicable, we further make a connection among\ndifferent papers in each category. Next, we cover some new emerging research\nareas in MARL along with the relevant recent papers. Due to the recent success\nof MARL in real-world applications, we assign a section to provide a review of\nthese applications and corresponding articles.\n  Also, a list of available environments for MARL research is provided in this\nsurvey. Finally, the paper is concluded with proposals on the possible research\ndirections.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 21:40:11 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 02:59:54 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 03:06:48 GMT"}, {"version": "v4", "created": "Fri, 30 Apr 2021 04:14:28 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["OroojlooyJadid", "Afshin", ""], ["Hajinezhad", "Davood", ""]]}, {"id": "1908.03971", "submitter": "Sajad Darabi", "authors": "Sajad Darabi, Mohammad Kachuee, Shayan Fazeli, and Majid Sarrafzadeh", "title": "TAPER: Time-Aware Patient EHR Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective representation learning of electronic health records is a\nchallenging task and is becoming more important as the availability of such\ndata is becoming pervasive. The data contained in these records are irregular\nand contain multiple modalities such as notes, and medical codes. They are\npreempted by medical conditions the patient may have, and are typically jotted\ndown by medical staff. Accompanying codes are notes containing valuable\ninformation about patients beyond the structured information contained in\nelectronic health records. We use transformer networks and the recently\nproposed BERT language model to embed these data streams into a unified vector\nrepresentation. The presented approach effectively encodes a patient's visit\ndata into a single distributed representation, which can be used for downstream\ntasks. Our model demonstrates superior performance and generalization on\nmortality, readmission and length of stay tasks using the publicly available\nMIMIC-III ICU dataset. Code avaialble at\nhttps://github.com/sajaddarabi/TAPER-EHR\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 23:15:23 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 02:36:35 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 06:00:56 GMT"}, {"version": "v4", "created": "Sun, 3 May 2020 10:32:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Darabi", "Sajad", ""], ["Kachuee", "Mohammad", ""], ["Fazeli", "Shayan", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1908.03973", "submitter": "Ping Lu", "authors": "Ping Lu, Yanyan Zhang, Jianxiong Chen, Yuan Xiao, George Zhao", "title": "Enhanced Seismic Imaging with Predictive Neural Networks for Geophysics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a predictive neural network architecture that can be utilized to\nupdate reference velocity models as inputs to the full waveform inversion. Deep\nlearning models are explored to augment velocity model building workflows\nduring processing the 3D seismic volume in salt-prone environments.\nSpecifically, a neural network architecture, with 3D convolutional,\nde-convolutional layers, and 3D max-pooling, is designed to take standard\namplitude 3D seismic volumes as an input. Enhanced data augmentations through\ngenerative adversarial networks and a weighted loss function enable the network\nto train with few sparsely annotated slices. Batch normalization is also\napplied for faster convergence. A 3D probability cube for salt bodies and\ninclusions is generated through ensembles of predictions from multiple models\nin order to reduce variance. Velocity models inferred from the proposed\nnetworks provide opportunities for FWI forward models to converge faster with\nan initial condition closer to the true model. In addition, in each iteration\nstep, the probability cubes of salt bodies and inclusions inferred from the\nproposed networks can be used as a regularization term within the FWI forward\nmodelling, which may result in an improved velocity model estimation while the\noutput of seismic migration can be utilized as an input of the 3D neural\nnetwork for subsequent iterations.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 23:46:05 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 22:32:06 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Lu", "Ping", ""], ["Zhang", "Yanyan", ""], ["Chen", "Jianxiong", ""], ["Xiao", "Yuan", ""], ["Zhao", "George", ""]]}, {"id": "1908.03983", "submitter": "Chuanxing Geng", "authors": "Chuanxing Geng, Lue Tao and Songcan Chen", "title": "Visual and Semantic Prototypes-Jointly Guided CNN for Generalized\n  Zero-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the process of exploring the world, the curiosity constantly drives humans\nto cognize new things. Supposing you are a zoologist, for a presented animal\nimage, you can recognize it immediately if you know its class. Otherwise, you\nwould more likely attempt to cognize it by exploiting the side-information\n(e.g., semantic information, etc.) you have accumulated. Inspired by this, this\npaper decomposes the generalized zero-shot learning (G-ZSL) task into an open\nset recognition (OSR) task and a zero-shot learning (ZSL) task, where OSR\nrecognizes seen classes (if we have seen (or known) them) and rejects unseen\nclasses (if we have never seen (or known) them before), while ZSL identifies\nthe unseen classes rejected by the former. Simultaneously, without violating\nOSR's assumptions (only known class knowledge is available in training), we\nalso first attempt to explore a new generalized open set recognition (G-OSR) by\nintroducing the accumulated side-information from known classes to OSR. For\nG-ZSL, such a decomposition effectively solves the class overfitting problem\nwith easily misclassifying unseen classes as seen classes. The problem is\nubiquitous in most existing G-ZSL methods. On the other hand, for G-OSR,\nintroducing such semantic information of known classes not only improves the\nrecognition performance but also endows OSR with the cognitive ability of\nunknown classes. Specifically, a visual and semantic prototypes-jointly guided\nconvolutional neural network (VSG-CNN) is proposed to fulfill these two tasks\n(G-ZSL and G-OSR) in a unified end-to-end learning framework. Extensive\nexperiments on benchmark datasets demonstrate the advantages of our learning\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 02:29:16 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 12:58:23 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Geng", "Chuanxing", ""], ["Tao", "Lue", ""], ["Chen", "Songcan", ""]]}, {"id": "1908.03990", "submitter": "Zhiyong Chen", "authors": "Zhiyong Chen, Zongze Ren and Shugong Xu", "title": "A Study on Angular Based Embedding Learning for Text-independent Speaker\n  Verification", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a good speaker embedding is important for many automatic speaker\nrecognition tasks, including verification, identification and diarization. The\nembeddings learned by softmax are not discriminative enough for open-set\nverification tasks. Angular based embedding learning target can achieve such\ndiscriminativeness by optimizing angular distance and adding margin penalty. We\napply several different popular angular margin embedding learning strategies in\nthis work and explicitly compare their performance on Voxceleb speaker\nrecognition dataset. Observing the fact that encouraging inter-class\nseparability is important when applying angular based embedding learning, we\npropose an exclusive inter-class regularization as a complement for angular\nbased loss. We verify the effectiveness of these methods for learning a\ndiscriminative embedding space on ASV task with several experiments. These\nmethods together, we manage to achieve an impressive result with 16.5%\nimprovement on equal error rate (EER) and 18.2% improvement on minimum\ndetection cost function comparing with baseline softmax systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 04:02:41 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Chen", "Zhiyong", ""], ["Ren", "Zongze", ""], ["Xu", "Shugong", ""]]}, {"id": "1908.04000", "submitter": "Priyanga Dilini Talagala", "authors": "Priyanga Dilini Talagala and Rob J. Hyndman and Kate Smith-Miles", "title": "Anomaly Detection in High Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The HDoutliers algorithm is a powerful unsupervised algorithm for detecting\nanomalies in high-dimensional data, with a strong theoretical foundation.\nHowever, it suffers from some limitations that significantly hinder its\nperformance level, under certain circumstances. In this article, we propose an\nalgorithm that addresses these limitations. We define an anomaly as an\nobservation that deviates markedly from the majority with a large distance gap.\nAn approach based on extreme value theory is used for the anomalous threshold\ncalculation. Using various synthetic and real datasets, we demonstrate the wide\napplicability and usefulness of our algorithm, which we call the stray\nalgorithm. We also demonstrate how this algorithm can assist in detecting\nanomalies present in other data structures using feature engineering. We show\nthe situations where the stray algorithm outperforms the HDoutliers algorithm\nboth in accuracy and computational time. This framework is implemented in the\nopen source R package stray.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 04:48:03 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Talagala", "Priyanga Dilini", ""], ["Hyndman", "Rob J.", ""], ["Smith-Miles", "Kate", ""]]}, {"id": "1908.04003", "submitter": "Vaibhav Vaibhav", "authors": "Vaibhav, Po-Yao Huang, Robert Frederking", "title": "RWR-GAE: Random Walk Regularization for Graph Auto Encoders", "comments": "6 pages, Empirical paper on improving Graph Embeddings using Random\n  Walk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Node embeddings have become an ubiquitous technique for representing graph\ndata in a low dimensional space. Graph autoencoders, as one of the widely\nadapted deep models, have been proposed to learn graph embeddings in an\nunsupervised way by minimizing the reconstruction error for the graph data.\nHowever, its reconstruction loss ignores the distribution of the latent\nrepresentation, and thus leading to inferior embeddings. To mitigate this\nproblem, we propose a random walk based method to regularize the\nrepresentations learnt by the encoder. We show that the proposed novel\nenhancement beats the existing state-of-the-art models by a large margin (upto\n7.5\\%) for node clustering task, and achieves state-of-the-art accuracy on the\nlink prediction task for three standard datasets, cora, citeseer and pubmed.\nCode available at https://github.com/MysteryVaibhav/DW-GAE.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 05:02:33 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Vaibhav", "", ""], ["Huang", "Po-Yao", ""], ["Frederking", "Robert", ""]]}, {"id": "1908.04007", "submitter": "Jianan Guo", "authors": "Jia-Nan Guo, Xian-Ling Mao, Xiao-Jian Jiang, Ying-Xiang Sun, Wei Wei\n  and He-Yan Huang", "title": "Deep Hashing for Signed Social Network Embedding", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding is a promising way of network representation, facilitating\nmany signed social network processing and analysis tasks such as link\nprediction and node classification. Recently, feature hashing has been adopted\nin several existing embedding algorithms to improve the efficiency, which has\nobtained a great success. However, the existing feature hashing based embedding\nalgorithms only consider the positive links in signed social networks.\nIntuitively, negative links can also help improve the performance. Thus, in\nthis paper, we propose a novel deep hashing method for signed social network\nembedding by considering simultaneously positive and negative links. Extensive\nexperiments show that the proposed method performs better than several\nstate-of-the-art baselines through link prediction task over two real-world\nsigned social networks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 05:31:12 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 03:45:20 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 02:54:48 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Guo", "Jia-Nan", ""], ["Mao", "Xian-Ling", ""], ["Jiang", "Xiao-Jian", ""], ["Sun", "Ying-Xiang", ""], ["Wei", "Wei", ""], ["Huang", "He-Yan", ""]]}, {"id": "1908.04008", "submitter": "Senwei Liang", "authors": "Senwei Liang, Zhongzhan Huang, Mingfu Liang, Haizhao Yang", "title": "Instance Enhancement Batch Normalization: an Adaptive Regulator of Batch\n  Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN)(Ioffe and Szegedy 2015) normalizes the features of\nan input image via statistics of a batch of images and hence BN will bring the\nnoise to the gradient of the training loss. Previous works indicate that the\nnoise is important for the optimization and generalization of deep neural\nnetworks, but too much noise will harm the performance of networks. In our\npaper, we offer a new point of view that self-attention mechanism can help to\nregulate the noise by enhancing instance-specific information to obtain a\nbetter regularization effect. Therefore, we propose an attention-based BN\ncalled Instance Enhancement Batch Normalization (IEBN) that recalibrates the\ninformation of each channel by a simple linear transformation. IEBN has a good\ncapacity of regulating noise and stabilizing network training to improve\ngeneralization even in the presence of two kinds of noise attacks during\ntraining. Finally, IEBN outperforms BN with only a light parameter increment in\nimage classification tasks for different network structures and benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 05:42:09 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 02:52:32 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Liang", "Senwei", ""], ["Huang", "Zhongzhan", ""], ["Liang", "Mingfu", ""], ["Yang", "Haizhao", ""]]}, {"id": "1908.04015", "submitter": "YoungJoon Yoo", "authors": "YoungJoon Yoo, Sangdoo Yun, Hyung Jin Chang, Yiannis Demiris and Jin\n  Young Choi", "title": "Variational Autoencoded Regression: High Dimensional Regression of\n  Visual Data on Complex Manifold", "comments": "Published in CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new high dimensional regression method by merging\nGaussian process regression into a variational autoencoder framework. In\ncontrast to other regression methods, the proposed method focuses on the case\nwhere output responses are on a complex high dimensional manifold, such as\nimages. Our contributions are summarized as follows: (i) A new regression\nmethod estimating high dimensional image responses, which is not handled by\nexisting regression algorithms, is proposed. (ii) The proposed regression\nmethod introduces a strategy to learn the latent space as well as the encoder\nand decoder so that the result of the regressed response in the latent space\ncoincide with the corresponding response in the data space. (iii) The proposed\nregression is embedded into a generative model, and the whole procedure is\ndeveloped by the variational autoencoder framework. We demonstrate the\nrobustness and effectiveness of our method through a number of experiments on\nvarious visual data regression problems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 06:06:59 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Yoo", "YoungJoon", ""], ["Yun", "Sangdoo", ""], ["Chang", "Hyung Jin", ""], ["Demiris", "Yiannis", ""], ["Choi", "Jin Young", ""]]}, {"id": "1908.04027", "submitter": "Oliver Mothes O.M.", "authors": "Oliver Mothes and Joachim Denzler", "title": "Self-supervised Data Bootstrapping for Deep Optical Character\n  Recognition of Identity Documents", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The essential task of verifying person identities at airports and national\nborders is very time consuming. To accelerate it, optical character recognition\nfor identity documents (IDs) using dictionaries is not appropriate due to high\nvariability of the text content in IDs, e.g., individual street names or\nsurnames. Additionally, no properties of the used fonts in IDs are known.\nTherefore, we propose an iterative self-supervised bootstrapping approach using\na smart strategy to mine real character data from IDs. In combination with\nsynthetically generated character data, the real data is used to train\nefficient convolutional neural networks for character classification serving a\npractical runtime as well as a high accuracy. On a dataset with 74 character\nclasses, we achieve an average class-wise accuracy of 99.4 %. In contrast, if\nwe would apply a classifier trained only using synthetic data, the accuracy is\nreduced to 58.1 %. Finally, we show that our whole proposed pipeline\noutperforms an established open-source framework\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 07:02:24 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Mothes", "Oliver", ""], ["Denzler", "Joachim", ""]]}, {"id": "1908.04030", "submitter": "Ronny Hug", "authors": "Ronny Hug, Wolfgang H\\\"ubner, and Michael Arens", "title": "Modeling continuous-time stochastic processes using $\\mathcal{N}$-Curve\n  mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations of sequential data are commonly based on the assumption that\nobserved sequences are realizations of an unknown underlying stochastic\nprocess, where the learning problem includes determination of the model\nparameters. In this context the model must be able to capture the multi-modal\nnature of the data, without blurring between modes. This property is essential\nfor applications like trajectory prediction or human motion modeling. Towards\nthis end, a neural network model for continuous-time stochastic processes\nusable for sequence prediction is proposed. The model is based on Mixture\nDensity Networks using B\\'ezier curves with Gaussian random variables as\ncontrol points (abbrev.: $\\mathcal{N}$-Curves). Key advantages of the model\ninclude the ability of generating smooth multi-mode predictions in a single\ninference step which reduces the need for Monte Carlo simulation, as required\nin many multi-step prediction models, based on state-of-the-art neural\nnetworks. Essential properties of the proposed approach are illustrated by\nseveral toy examples and the task of multi-step sequence prediction. Further,\nthe model performance is evaluated on two real world use-cases, i.e. human\ntrajectory prediction and human motion modeling, outperforming different\nstate-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 07:12:08 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 14:00:57 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 09:40:11 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 09:14:49 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Hug", "Ronny", ""], ["H\u00fcbner", "Wolfgang", ""], ["Arens", "Michael", ""]]}, {"id": "1908.04087", "submitter": "Elena Sibirtseva", "authors": "Yuan Gao, Elena Sibirtseva, Ginevra Castellano and Danica Kragic", "title": "Fast Adaptation with Meta-Reinforcement Learning for Trust Modelling in\n  Human-Robot Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In socially assistive robotics, an important research area is the development\nof adaptation techniques and their effect on human-robot interaction. We\npresent a meta-learning based policy gradient method for addressing the problem\nof adaptation in human-robot interaction and also investigate its role as a\nmechanism for trust modelling. By building an escape room scenario in mixed\nreality with a robot, we test our hypothesis that bi-directional trust can be\ninfluenced by different adaptation algorithms. We found that our proposed model\nincreased the perceived trustworthiness of the robot and influenced the\ndynamics of gaining human's trust. Additionally, participants evaluated that\nthe robot perceived them as more trustworthy during the interactions with the\nmeta-learning based adaptation compared to the previously studied statistical\nadaptation model.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 11:06:28 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Gao", "Yuan", ""], ["Sibirtseva", "Elena", ""], ["Castellano", "Ginevra", ""], ["Kragic", "Danica", ""]]}, {"id": "1908.04092", "submitter": "Federico Marinelli", "authors": "Federico Marinelli, Alessandra Cervone, Giuliano Tortoreto, Evgeny A.\n  Stepanov, Giuseppe Di Fabbrizio, Giuseppe Riccardi", "title": "Active Annotation: bootstrapping annotation lexicon and guidelines for\n  supervised NLU learning", "comments": "4 pages", "journal-ref": "INTERSPEECH 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Natural Language Understanding (NLU) models are typically trained in a\nsupervised learning framework. In the case of intent classification, the\npredicted labels are predefined and based on the designed annotation schema\nwhile the labelling process is based on a laborious task where annotators\nmanually inspect each utterance and assign the corresponding label. We propose\nan Active Annotation (AA) approach where we combine an unsupervised learning\nmethod in the embedding space, a human-in-the-loop verification process, and\nlinguistic insights to create lexicons that can be open categories and adapted\nover time. In particular, annotators define the y-label space on-the-fly during\nthe annotation using an iterative process and without the need for prior\nknowledge about the input data. We evaluate the proposed annotation paradigm in\na real use-case NLU scenario. Results show that our Active Annotation paradigm\nachieves accurate and higher quality training data, with an annotation speed of\nan order of magnitude higher with respect to the traditional human-only driven\nbaseline annotation methodology.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 11:20:29 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Marinelli", "Federico", ""], ["Cervone", "Alessandra", ""], ["Tortoreto", "Giuliano", ""], ["Stepanov", "Evgeny A.", ""], ["Di Fabbrizio", "Giuseppe", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "1908.04109", "submitter": "Nicolas Gillis", "authors": "Nicolas Gillis", "title": "Successive Projection Algorithm Robust to Outliers", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NA eess.IV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successive projection algorithm (SPA) is a fast algorithm to tackle\nseparable nonnegative matrix factorization (NMF). Given a nonnegative data\nmatrix $X$, SPA identifies an index set $\\mathcal{K}$ such that there exists a\nnonnegative matrix $H$ with $X \\approx X(:,\\mathcal{K})H$. SPA has been\nsuccessfully used as a pure-pixel search algorithm in hyperspectral unmixing\nand for anchor word selection in document classification. Moreover, SPA is\nprovably robust in low-noise settings. The main drawbacks of SPA are that it is\nnot robust to outliers and does not take the data fitting term into account\nwhen selecting the indices in $\\mathcal{K}$. In this paper, we propose a new\nSPA variant, dubbed Robust SPA (RSPA), that is robust to outliers while still\nbeing provably robust in low-noise settings, and that takes into account the\nreconstruction error for selecting the indices in $\\mathcal{K}$. We illustrate\nthe effectiveness of RSPA on synthetic data sets and hyperspectral images.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 12:21:50 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Gillis", "Nicolas", ""]]}, {"id": "1908.04127", "submitter": "Jonathan Viquerat", "authors": "Paul Garnier and Jonathan Viquerat and Jean Rabault and Aur\\'elien\n  Larcher and Alexander Kuhnle and Elie Hachem", "title": "A review on Deep Reinforcement Learning for Fluid Mechanics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has recently been adopted in a wide range\nof physics and engineering domains for its ability to solve decision-making\nproblems that were previously out of reach due to a combination of\nnon-linearity and high dimensionality. In the last few years, it has spread in\nthe field of computational mechanics, and particularly in fluid dynamics, with\nrecent applications in flow control and shape optimization. In this work, we\nconduct a detailed review of existing DRL applications to fluid mechanics\nproblems. In addition, we present recent results that further illustrate the\npotential of DRL in Fluid Mechanics. The coupling methods used in each case are\ncovered, detailing their advantages and limitations. Our review also focuses on\nthe comparison with classical methods for optimal control and optimization.\nFinally, several test cases are described that illustrate recent progress made\nin this field. The goal of this publication is to provide an understanding of\nDRL capabilities along with state-of-the-art applications in fluid dynamics to\nresearchers wishing to address new problems with these methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 12:51:14 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 16:48:30 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Garnier", "Paul", ""], ["Viquerat", "Jonathan", ""], ["Rabault", "Jean", ""], ["Larcher", "Aur\u00e9lien", ""], ["Kuhnle", "Alexander", ""], ["Hachem", "Elie", ""]]}, {"id": "1908.04207", "submitter": "Shigang Li", "authors": "Shigang Li, Tal Ben-Nun, Salvatore Di Girolamo, Dan Alistarh, Torsten\n  Hoefler", "title": "Taming Unbalanced Training Workloads in Deep Learning with Partial\n  Collective Operations", "comments": "Published in Proceedings of the 25th ACM SIGPLAN Symposium on\n  Principles and Practice of Parallel Programming (PPoPP'20), pp. 45-61. 2020", "journal-ref": null, "doi": "10.1145/3332466.3374528", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Load imbalance pervasively exists in distributed deep learning training\nsystems, either caused by the inherent imbalance in learned tasks or by the\nsystem itself. Traditional synchronous Stochastic Gradient Descent (SGD)\nachieves good accuracy for a wide variety of tasks, but relies on global\nsynchronization to accumulate the gradients at every training step. In this\npaper, we propose eager-SGD, which relaxes the global synchronization for\ndecentralized accumulation. To implement eager-SGD, we propose to use two\npartial collectives: solo and majority. With solo allreduce, the faster\nprocesses contribute their gradients eagerly without waiting for the slower\nprocesses, whereas with majority allreduce, at least half of the participants\nmust contribute gradients before continuing, all without using a central\nparameter server. We theoretically prove the convergence of the algorithms and\ndescribe the partial collectives in detail. Experimental results on\nload-imbalanced environments (CIFAR-10, ImageNet, and UCF101 datasets) show\nthat eager-SGD achieves 1.27x speedup over the state-of-the-art synchronous\nSGD, without losing accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 15:37:51 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 07:35:30 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 23:13:50 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Li", "Shigang", ""], ["Ben-Nun", "Tal", ""], ["Di Girolamo", "Salvatore", ""], ["Alistarh", "Dan", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1908.04209", "submitter": "Ye Xue", "authors": "Ye Xue, Diego Klabjan, Yuan Luo", "title": "Mixture-based Multiple Imputation Model for Clinical Data with a\n  Temporal Dimension", "comments": null, "journal-ref": null, "doi": "10.1109/BigData47090.2019.9005672", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of missing values in multivariable time series is a key challenge\nin many applications such as clinical data mining. Although many imputation\nmethods show their effectiveness in many applications, few of them are designed\nto accommodate clinical multivariable time series. In this work, we propose a\nmultiple imputation model that capture both cross-sectional information and\ntemporal correlations. We integrate Gaussian processes with mixture models and\nintroduce individualized mixing weights to handle the variance of predictive\nconfidence of Gaussian process models. The proposed model is compared with\nseveral state-of-the-art imputation algorithms on both real-world and synthetic\ndatasets. Experiments show that our best model can provide more accurate\nimputation than the benchmarks on all of our datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 15:47:10 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 18:51:54 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 22:11:55 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Xue", "Ye", ""], ["Klabjan", "Diego", ""], ["Luo", "Yuan", ""]]}, {"id": "1908.04211", "submitter": "Damian Pascual", "authors": "Gino Brunner, Yang Liu, Dami\\'an Pascual, Oliver Richter, Massimiliano\n  Ciaramita, Roger Wattenhofer", "title": "On Identifiability in Transformers", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we delve deep in the Transformer architecture by investigating\ntwo of its core components: self-attention and contextual embeddings. In\nparticular, we study the identifiability of attention weights and token\nembeddings, and the aggregation of context into hidden tokens. We show that,\nfor sequences longer than the attention head dimension, attention weights are\nnot identifiable. We propose effective attention as a complementary tool for\nimproving explanatory interpretations based on attention. Furthermore, we show\nthat input tokens retain to a large degree their identity across the model. We\nalso find evidence suggesting that identity information is mainly encoded in\nthe angle of the embeddings and gradually decreases with depth. Finally, we\ndemonstrate strong mixing of input information in the generation of contextual\nembeddings by means of a novel quantification method based on gradient\nattribution. Overall, we show that self-attention distributions are not\ndirectly interpretable and present tools to better understand and further\ninvestigate Transformer models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 15:48:34 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 13:04:40 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 16:59:31 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 17:44:52 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Brunner", "Gino", ""], ["Liu", "Yang", ""], ["Pascual", "Dami\u00e1n", ""], ["Richter", "Oliver", ""], ["Ciaramita", "Massimiliano", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1908.04240", "submitter": "F\\'abio Pinto", "authors": "F\\'abio Pinto, Marco O. P. Sampaio, Pedro Bizarro", "title": "Automatic Model Monitoring for Data Streams", "comments": "9 pages, 9 figures, 2 tables", "journal-ref": "KDD-ADF-2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting concept drift is a well known problem that affects production\nsystems. However, two important issues that are frequently not addressed in the\nliterature are 1) the detection of drift when the labels are not immediately\navailable; and 2) the automatic generation of explanations to identify possible\ncauses for the drift. For example, a fraud detection model in online payments\ncould show a drift due to a hot sale item (with an increase in false positives)\nor due to a true fraud attack (with an increase in false negatives) before\nlabels are available. In this paper we propose SAMM, an automatic model\nmonitoring system for data streams. SAMM detects concept drift using a time and\nspace efficient unsupervised streaming algorithm and it generates alarm reports\nwith a summary of the events and features that are important to explain it.\nSAMM was evaluated in five real world fraud detection datasets, each spanning\nperiods up to eight months and totaling more than 22 million online\ntransactions. We evaluated SAMM using human feedback from domain experts, by\nsending them 100 reports generated by the system. Our results show that SAMM is\nable to detect anomalous events in a model life cycle that are considered\nuseful by the domain experts. Given these results, SAMM will be rolled out in a\nnext version of Feedzai's Fraud Detection solution.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 16:47:14 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Pinto", "F\u00e1bio", ""], ["Sampaio", "Marco O. P.", ""], ["Bizarro", "Pedro", ""]]}, {"id": "1908.04267", "submitter": "Amir Mosavi Prof", "authors": "Sevda Shabani, Saeed Samadianfard, Mohammad Taghi Sattari, Shahab\n  Shamshirband, Amir Mosavi, Tibor Kmet, Annamaria R. Varkonyi-Koczy", "title": "Modeling Daily Pan Evaporation in Humid Climates Using Gaussian Process\n  Regression", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": "10.20944/preprints201907.0351.v1", "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evaporation is one of the main processes in the hydrological cycle, and it is\none of the most critical factors in agricultural, hydrological, and\nmeteorological studies. Due to the interactions of multiple climatic factors,\nthe evaporation is a complex and nonlinear phenomenon; therefore, the\ndata-based methods can be used to have precise estimations of it. In this\nregard, in the present study, Gaussian Process Regression, Nearest-Neighbor,\nRandom Forest and Support Vector Regression were used to estimate the pan\nevaporation in the meteorological stations of Golestan Province, Iran. For this\npurpose, meteorological data including PE, temperature, relative humidity, wind\nspeed and sunny hours collected from the Gonbad-e Kavus, Gorgan and Bandar\nTorkman stations from 2011 through 2017. The accuracy of the studied methods\nwas determined using the statistical indices of Root Mean Squared Error,\ncorrelation coefficient and Mean Absolute Error. Furthermore, the Taylor charts\nutilized for evaluating the accuracy of the mentioned models. We report that\nGPR for Gonbad-e Kavus Station with input parameters of T, W and S and GPR for\nGorgan and Bandar Torkmen stations with input parameters of T, RH, W, and S had\nthe most accurate performances and proposed for precise estimation of PE. Due\nto the high rate of evaporation in Iran and the lack of measurement\ninstruments, the findings of the current study indicated that the PE values\nmight be estimated with few easily measured meteorological parameters\naccurately.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 10:43:36 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Shabani", "Sevda", ""], ["Samadianfard", "Saeed", ""], ["Sattari", "Mohammad Taghi", ""], ["Shamshirband", "Shahab", ""], ["Mosavi", "Amir", ""], ["Kmet", "Tibor", ""], ["Varkonyi-Koczy", "Annamaria R.", ""]]}, {"id": "1908.04284", "submitter": "Quan Wang", "authors": "Shaojin Ding, Quan Wang, Shuo-yiin Chang, Li Wan, Ignacio Lopez Moreno", "title": "Personal VAD: Speaker-Conditioned Voice Activity Detection", "comments": "Speaker Odyssey 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose \"personal VAD\", a system to detect the voice\nactivity of a target speaker at the frame level. This system is useful for\ngating the inputs to a streaming on-device speech recognition system, such that\nit only triggers for the target user, which helps reduce the computational cost\nand battery consumption, especially in scenarios where a keyword detector is\nunpreferable. We achieve this by training a VAD-alike neural network that is\nconditioned on the target speaker embedding or the speaker verification score.\nFor each frame, personal VAD outputs the probabilities for three classes:\nnon-speech, target speaker speech, and non-target speaker speech. Under our\noptimal setup, we are able to train a model with only 130K parameters that\noutperforms a baseline system where individually trained standard VAD and\nspeaker recognition networks are combined to perform the same task.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 17:54:31 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 18:04:42 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 19:06:18 GMT"}, {"version": "v4", "created": "Wed, 8 Apr 2020 15:41:16 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ding", "Shaojin", ""], ["Wang", "Quan", ""], ["Chang", "Shuo-yiin", ""], ["Wan", "Li", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1908.04293", "submitter": "Umit Rusen Aktas", "authors": "Umit Rusen Aktas, Chao Zhao, Marek Kopicki, Ales Leonardis, Jeremy L.\n  Wyatt", "title": "Deep Dexterous Grasping of Novel Objects from a Single View", "comments": "Submitted for IEEE Transactions on Robotics (T-RO). 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dexterous grasping of a novel object given a single view is an open problem.\nThis paper makes several contributions to its solution. First, we present a\nsimulator for generating and testing dexterous grasps. Second we present a data\nset, generated by this simulator, of 2.4 million simulated dexterous grasps of\nvariations of 294 base objects drawn from 20 categories. Third, we present a\nbasic architecture for generation and evaluation of dexterous grasps that may\nbe trained in a supervised manner. Fourth, we present three different\nevaluative architectures, employing ResNet-50 or VGG16 as their visual\nbackbone. Fifth, we train, and evaluate seventeen variants of\ngenerative-evaluative architectures on this simulated data set, showing\nimprovement from 69.53% grasp success rate to 90.49%. Finally, we present a\nreal robot implementation and evaluate the four most promising variants,\nexecuting 196 real robot grasps in total. We show that our best architectural\nvariant achieves a grasp success rate of 87.8% on real novel objects seen from\na single view, improving on a baseline of 57.1%.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 18:31:35 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Aktas", "Umit Rusen", ""], ["Zhao", "Chao", ""], ["Kopicki", "Marek", ""], ["Leonardis", "Ales", ""], ["Wyatt", "Jeremy L.", ""]]}, {"id": "1908.04297", "submitter": "Aakanksha Rana", "authors": "Cagri Ozcinar, Aakanksha Rana, and Aljosa Smolic", "title": "Super-resolution of Omnidirectional Images Using Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An omnidirectional image (ODI) enables viewers to look in every direction\nfrom a fixed point through a head-mounted display providing an immersive\nexperience compared to that of a standard image. Designing immersive virtual\nreality systems with ODIs is challenging as they require high resolution\ncontent. In this paper, we study super-resolution for ODIs and propose an\nimproved generative adversarial network based model which is optimized to\nhandle the artifacts obtained in the spherical observational space.\nSpecifically, we propose to use a fast PatchGAN discriminator, as it needs\nfewer parameters and improves the super-resolution at a fine scale. We also\nexplore the generative models with adversarial learning by introducing a\nspherical-content specific loss function, called 360-SS. To train and test the\nperformance of our proposed model we prepare a dataset of 4500 ODIs. Our\nresults demonstrate the efficacy of the proposed method and identify new\nchallenges in ODI super-resolution for future investigations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 16:05:59 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Ozcinar", "Cagri", ""], ["Rana", "Aakanksha", ""], ["Smolic", "Aljosa", ""]]}, {"id": "1908.04319", "submitter": "Sean Welleck", "authors": "Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun\n  Cho, Jason Weston", "title": "Neural Text Generation with Unlikelihood Training", "comments": "Sean Welleck and Ilia Kulikov contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text generation is a key tool in natural language applications, but it\nis well known there are major problems at its core. In particular, standard\nlikelihood training and decoding leads to dull and repetitive outputs. While\nsome post-hoc fixes have been proposed, in particular top-$k$ and nucleus\nsampling, they do not address the fact that the token-level probabilities\npredicted by the model are poor. In this paper we show that the likelihood\nobjective itself is at fault, resulting in a model that assigns too much\nprobability to sequences containing repeats and frequent words, unlike those\nfrom the human training distribution. We propose a new objective, unlikelihood\ntraining, which forces unlikely generations to be assigned lower probability by\nthe model. We show that both token and sequence level unlikelihood training\ngive less repetitive, less dull text while maintaining perplexity, giving\nsuperior generations using standard greedy or beam search. According to human\nevaluations, our approach with standard beam search also outperforms the\ncurrently popular decoding methods of nucleus sampling or beam blocking, thus\nproviding a strong alternative to existing techniques.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 18:09:04 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 23:57:44 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Welleck", "Sean", ""], ["Kulikov", "Ilia", ""], ["Roller", "Stephen", ""], ["Dinan", "Emily", ""], ["Cho", "Kyunghyun", ""], ["Weston", "Jason", ""]]}, {"id": "1908.04332", "submitter": "Sanidhya Mangal", "authors": "Sanidhya Mangal, Poorva Joshi and Rahul Modak", "title": "LSTM vs. GRU vs. Bidirectional RNN for script generation", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scripts are an important part of any TV series. They narrate movements,\nactions and expressions of characters. In this paper, a case study is presented\non how different sequence to sequence deep learning models perform in the task\nof generating new conversations between characters as well as new scenarios on\nthe basis of a script (previous conversations). A comprehensive comparison\nbetween these models, namely, LSTM, GRU and Bidirectional RNN is presented. All\nthe models are designed to learn the sequence of recurring characters from the\ninput sequence. Each input sequence will contain, say \"n\" characters, and the\ncorresponding targets will contain the same number of characters, except, they\nwill be shifted one character to the right. In this manner, input and output\nsequences are generated and used to train the models. A closer analysis of\nexplored models performance and efficiency is delineated with the help of graph\nplots and generated texts by taking some input string. These graphs describe\nboth, intraneural performance and interneural model performance for each model.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 18:39:10 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Mangal", "Sanidhya", ""], ["Joshi", "Poorva", ""], ["Modak", "Rahul", ""]]}, {"id": "1908.04339", "submitter": "Alejandro Newell", "authors": "Alejandro Newell, Lu Jiang, Chong Wang, Li-Jia Li, Jia Deng", "title": "Feature Partitioning for Efficient Multi-Task Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning holds the promise of less data, parameters, and time than\ntraining of separate models. We propose a method to automatically search over\nmulti-task architectures while taking resource constraints into consideration.\nWe propose a search space that compactly represents different parameter sharing\nstrategies. This provides more effective coverage and sampling of the space of\nmulti-task architectures. We also present a method for quick evaluation of\ndifferent architectures by using feature distillation. Together these\ncontributions allow us to quickly optimize for efficient multi-task models. We\nbenchmark on Visual Decathlon, demonstrating that we can automatically search\nfor and identify multi-task architectures that effectively make trade-offs\nbetween task resource requirements while achieving a high level of final\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 19:06:32 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Newell", "Alejandro", ""], ["Jiang", "Lu", ""], ["Wang", "Chong", ""], ["Li", "Li-Jia", ""], ["Deng", "Jia", ""]]}, {"id": "1908.04342", "submitter": "Nilavra Bhattacharya", "authors": "Nilavra Bhattacharya, Qing Li, Danna Gurari", "title": "Why Does a Visual Question Have Different Answers?", "comments": null, "journal-ref": "The IEEE International Conference on Computer Vision (ICCV) 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering is the task of returning the answer to a question\nabout an image. A challenge is that different people often provide different\nanswers to the same visual question. To our knowledge, this is the first work\nthat aims to understand why. We propose a taxonomy of nine plausible reasons,\nand create two labelled datasets consisting of ~45,000 visual questions\nindicating which reasons led to answer differences. We then propose a novel\nproblem of predicting directly from a visual question which reasons will cause\nanswer differences as well as a novel algorithm for this purpose. Experiments\ndemonstrate the advantage of our approach over several related baselines on two\ndiverse datasets. We publicly share the datasets and code at\nhttps://vizwiz.org.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 19:19:48 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 18:55:01 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Bhattacharya", "Nilavra", ""], ["Li", "Qing", ""], ["Gurari", "Danna", ""]]}, {"id": "1908.04345", "submitter": "Guo-Hua Wang", "authors": "Guo-Hua Wang, Jianxin Wu", "title": "Repetitive Reprediction Deep Decipher for Semi-Supervised Learning", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent semi-supervised deep learning (deep SSL) methods used a similar\nparadigm: use network predictions to update pseudo-labels and use pseudo-labels\nto update network parameters iteratively. However, they lack theoretical\nsupport and cannot explain why predictions are good candidates for\npseudo-labels. In this paper, we propose a principled end-to-end framework\nnamed deep decipher (D2) for SSL. Within the D2 framework, we prove that\npseudo-labels are related to network predictions by an exponential link\nfunction, which gives a theoretical support for using predictions as\npseudo-labels. Furthermore, we demonstrate that updating pseudo-labels by\nnetwork predictions will make them uncertain. To mitigate this problem, we\npropose a training strategy called repetitive reprediction (R2). Finally, the\nproposed R2-D2 method is tested on the large-scale ImageNet dataset and\noutperforms state-of-the-art methods by 5 percentage points.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 11:57:16 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 01:59:50 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Wang", "Guo-Hua", ""], ["Wu", "Jianxin", ""]]}, {"id": "1908.04347", "submitter": "Alexander Hepburn", "authors": "Alexander Hepburn, Valero Laparra, Ryan McConville, Raul\n  Santos-Rodriguez", "title": "Enforcing Perceptual Consistency on Generative Adversarial Networks by\n  Using the Normalised Laplacian Pyramid Distance", "comments": null, "journal-ref": "Proceedings of the Northern Lights Deep Learning Workshop. Vol. 1.\n  2020", "doi": "10.7557/18.5124", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a growing interest in image generation through\ndeep learning. While an important part of the evaluation of the generated\nimages usually involves visual inspection, the inclusion of human perception as\na factor in the training process is often overlooked. In this paper we propose\nan alternative perceptual regulariser for image-to-image translation using\nconditional generative adversarial networks (cGANs). To do so automatically\n(avoiding visual inspection), we use the Normalised Laplacian Pyramid Distance\n(NLPD) to measure the perceptual similarity between the generated image and the\noriginal image. The NLPD is based on the principle of normalising the value of\ncoefficients with respect to a local estimate of mean energy at different\nscales and has already been successfully tested in different experiments\ninvolving human perception. We compare this regulariser with the originally\nproposed L1 distance and note that when using NLPD the generated images contain\nmore realistic values for both local and global contrast. We found that using\nNLPD as a regulariser improves image segmentation accuracy on generated images\nas well as improving two no-reference image quality metrics.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 08:33:51 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 10:48:29 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hepburn", "Alexander", ""], ["Laparra", "Valero", ""], ["McConville", "Ryan", ""], ["Santos-Rodriguez", "Raul", ""]]}, {"id": "1908.04348", "submitter": "Francesco Ventura", "authors": "Francesco Ventura, Tania Cerquitelli", "title": "What's in the box? Explaining the black-box model through an evaluation\n  of its interpretable features", "comments": "5 pages, 5 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Algorithms are powerful and necessary tools behind a large part of the\ninformation we use every day. However, they may introduce new sources of bias,\ndiscrimination and other unfair practices that affect people who are unaware of\nit. Greater algorithm transparency is indispensable to provide more credible\nand reliable services. Moreover, requiring developers to design transparent\nalgorithm-driven applications allows them to keep the model accessible and\nhuman understandable, increasing the trust of end users. In this paper we\npresent EBAnO, a new engine able to produce prediction-local explanations for a\nblack-box model exploiting interpretable feature perturbations. EBAnO exploits\nthe hypercolumns representation together with the cluster analysis to identify\na set of interpretable features of images. Furthermore two indices have been\nproposed to measure the influence of input features on the final prediction\nmade by a CNN model. EBAnO has been preliminarily tested on a set of\nheterogeneous images. The results highlight the effectiveness of EBAnO in\nexplaining the CNN classification through the evaluation of interpretable\nfeatures influence.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 15:05:06 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Ventura", "Francesco", ""], ["Cerquitelli", "Tania", ""]]}, {"id": "1908.04349", "submitter": "Richard Cobos", "authors": "Richard Cobos, Jefferson Hernandez and Andres G. Abad", "title": "A fast multi-object tracking system using an object detector ensemble", "comments": "5 pages, 4 figures, 1 table, published in 2019 IEEE Colombian\n  Conference on Applications in Computational Intelligence (ColCACI)", "journal-ref": null, "doi": "10.1109/ColCACI.2019.8781972", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-Object Tracking (MOT) is of crucial importance for applications such\nas retail video analytics and video surveillance. Object detectors are often\nthe computational bottleneck of modern MOT systems, limiting their use for\nreal-time applications. In this paper, we address this issue by leveraging on\nan ensemble of detectors, each running every f frames. We measured the\nperformance of our system in the MOT16 benchmark. The proposed model surpassed\nother online entries of the MOT16 challenge in speed, while maintaining an\nacceptable accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 20:23:31 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Cobos", "Richard", ""], ["Hernandez", "Jefferson", ""], ["Abad", "Andres G.", ""]]}, {"id": "1908.04351", "submitter": "Brian Kenji Iwana", "authors": "Brian Kenji Iwana, Ryohei Kuroki, Seiichi Uchida", "title": "Explaining Convolutional Neural Networks using Softmax Gradient\n  Layer-wise Relevance Propagation", "comments": "Published at ICCV 2019 Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have become state-of-the-art in the field\nof image classification. However, not everything is understood about their\ninner representations. This paper tackles the interpretability and\nexplainability of the predictions of CNNs for multi-class classification\nproblems. Specifically, we propose a novel visualization method of pixel-wise\ninput attribution called Softmax-Gradient Layer-wise Relevance Propagation\n(SGLRP). The proposed model is a class discriminate extension to Deep Taylor\nDecomposition (DTD) using the gradient of softmax to back propagate the\nrelevance of the output probability to the input image. Through qualitative and\nquantitative analysis, we demonstrate that SGLRP can successfully localize and\nattribute the regions on input images which contribute to a target object's\nclassification. We show that the proposed method excels at discriminating the\ntarget objects class from the other possible objects in the images. We confirm\nthat SGLRP performs better than existing Layer-wise Relevance Propagation (LRP)\nbased methods and can help in the understanding of the decision process of\nCNNs.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 13:05:04 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 07:48:59 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2019 07:48:43 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Iwana", "Brian Kenji", ""], ["Kuroki", "Ryohei", ""], ["Uchida", "Seiichi", ""]]}, {"id": "1908.04354", "submitter": "Shahriar Sefati", "authors": "Shahriar Sefati, Shahin Sefati, Iulian Iordachita, Russell H. Taylor,\n  Mehran Armand", "title": "Learning to Detect Collisions for Continuum Manipulators without a Prior\n  Model", "comments": "Accepted for publication in International Conference on Medical Image\n  Computing and Computer Assisted Intervention (MICCAI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their flexibility, dexterity, and compact size, Continuum Manipulators\n(CMs) can enhance minimally invasive interventions. In these procedures, the CM\nmay be operated in proximity of sensitive organs; therefore, requiring accurate\nand appropriate feedback when colliding with their surroundings. Conventional\nCM collision detection algorithms rely on a combination of exact CM constrained\nkinematics model, geometrical assumptions such as constant curvature behavior,\na priori knowledge of the environmental constraint geometry, and/or additional\nsensors to scan the environment or sense contacts. In this paper, we propose a\ndata-driven machine learning approach using only the available sensory\ninformation, without requiring any prior geometrical assumptions, model of the\nCM or the surrounding environment. The proposed algorithm is implemented and\nevaluated on a non-constant curvature CM, equipped with Fiber Bragg Grating\n(FBG) optical sensors for shape sensing purposes. Results demonstrate\nsuccessful detection of collisions in constrained environments with soft and\nhard obstacles with unknown stiffness and location.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 19:33:15 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Sefati", "Shahriar", ""], ["Sefati", "Shahin", ""], ["Iordachita", "Iulian", ""], ["Taylor", "Russell H.", ""], ["Armand", "Mehran", ""]]}, {"id": "1908.04355", "submitter": "Divyam Madaan", "authors": "Divyam Madaan, Jinwoo Shin, Sung Ju Hwang", "title": "Adversarial Neural Pruning with Latent Vulnerability Suppression", "comments": "Accepted to ICML 2020. Code available at\n  https://github.com/divyam3897/ANP_VS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the remarkable performance of deep neural networks on various\ncomputer vision tasks, they are known to be susceptible to adversarial\nperturbations, which makes it challenging to deploy them in real-world\nsafety-critical applications. In this paper, we conjecture that the leading\ncause of adversarial vulnerability is the distortion in the latent feature\nspace, and provide methods to suppress them effectively. Explicitly, we define\n\\emph{vulnerability} for each latent feature and then propose a new loss for\nadversarial learning, \\emph{Vulnerability Suppression (VS)} loss, that aims to\nminimize the feature-level vulnerability during training. We further propose a\nBayesian framework to prune features with high vulnerability to reduce both\nvulnerability and loss on adversarial samples. We validate our\n\\emph{Adversarial Neural Pruning with Vulnerability Suppression (ANP-VS)}\nmethod on multiple benchmark datasets, on which it not only obtains\nstate-of-the-art adversarial robustness but also improves the performance on\nclean examples, using only a fraction of the parameters used by the full\nnetwork. Further qualitative analysis suggests that the improvements come from\nthe suppression of feature-level vulnerability.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 19:33:58 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 08:48:00 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 07:14:39 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 13:47:36 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Madaan", "Divyam", ""], ["Shin", "Jinwoo", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1908.04384", "submitter": "Ameer Pasha Hosseinbor", "authors": "A. Pasha Hosseinbor, R. Zhdanov, and A. Ushveridze", "title": "An Unsupervised, Iterative N-Dimensional Point-Set Registration\n  Algorithm", "comments": "arXiv admin note: text overlap with arXiv:1702.01870", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unsupervised, iterative point-set registration algorithm for an unlabeled\n(i.e. correspondence between points is unknown) N-dimensional Euclidean\npoint-cloud is proposed. It is based on linear least squares, and considers all\npossible point pairings and iteratively aligns the two sets until the number of\npoint pairs does not exceed the maximum number of allowable one-to-one\npairings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 17:03:53 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Hosseinbor", "A. Pasha", ""], ["Zhdanov", "R.", ""], ["Ushveridze", "A.", ""]]}, {"id": "1908.04385", "submitter": "Zheng Liu", "authors": "Zheng Liu, Zidong Jiang, Wei Feng, Hui Feng", "title": "OD-GCN: Object Detection Boosted by Knowledge GCN", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical CNN based object detection methods only extract the objects' image\nfeatures, but do not consider the high-level relationship among objects in\ncontext. In this article, the graph convolutional networks (GCN) is integrated\ninto the object detection framework to exploit the benefit of category\nrelationship among objects, which is able to provide extra confidence for any\npre-trained object detection model in our framework. In experiments, we test\nseveral popular base detection models on COCO dataset. The results show\npromising improvement on mAP by 1-5pp. In addition, visualized analysis reveals\nthe benchmark improvement is quite reasonable in human's opinion.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 02:23:29 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 03:17:40 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 03:27:23 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Liu", "Zheng", ""], ["Jiang", "Zidong", ""], ["Feng", "Wei", ""], ["Feng", "Hui", ""]]}, {"id": "1908.04387", "submitter": "Muhammad Hamdan", "authors": "Muhammad K A Hamdan, Daine T. Rover, Matthew J. Darr, and John Just", "title": "Mass Estimation from Images using Deep Neural Network and Sparse Ground\n  Truth", "comments": "9 pages, 19 figures, pre-print NIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Supervised learning is the workhorse for regression and classification tasks,\nbut the standard approach presumes ground truth for every measurement. In real\nworld applications, limitations due to expense or general in-feasibility due to\nthe specific application are common. In the context of agriculture\napplications, yield monitoring is one such example where simple-physics based\nmeasurements such as volume or force-impact have been used to quantify mass\nflow, which incur error due to sensor calibration. By utilizing semi-supervised\ndeep learning with gradient aggregation and a sequence of images, in this work\nwe can accurately estimate a physical quantity (mass) with complex data\nstructures and sparse ground truth. Using a vision system capturing images of a\nsugarcane elevator and running bamboo under controlled testing as a surrogate\nmaterial to harvesting sugarcane, mass is accurately predicted from images by\ntraining a DNN using only final load weights. The DNN succeeds in capturing the\ncomplex density physics of random stacking of slender rods internally as part\nof the mass prediction model, and surpasses older volumetric-based methods for\nmass prediction. Furthermore, by incorporating knowledge about the system\nphysics through the DNN architecture and penalty terms, improvements in\nprediction accuracy and stability, as well as faster learning are obtained. It\nis shown that the classic nonlinear regression optimization can be reformulated\nwith an aggregation term with some independence assumptions to achieve this\nfeat. Since the number of images for any given run are too large to fit on\ntypical GPU vRAM, an implementation is shown that compensates for the limited\nmemory but still achieve fast training times. The same approach presented\nherein could be applied to other applications like yield monitoring on grain\ncombines or other harvesters using vision or other instrumentation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 02:59:18 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 21:08:43 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 17:46:09 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Hamdan", "Muhammad K A", ""], ["Rover", "Daine T.", ""], ["Darr", "Matthew J.", ""], ["Just", "John", ""]]}, {"id": "1908.04388", "submitter": "Faruk Ahmed", "authors": "Faruk Ahmed and Aaron Courville", "title": "Detecting semantic anomalies", "comments": "Preprint for AAAI '20 publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We critically appraise the recent interest in out-of-distribution (OOD)\ndetection and question the practical relevance of existing benchmarks. While\nthe currently prevalent trend is to consider different datasets as OOD, we\nargue that out-distributions of practical interest are ones where the\ndistinction is semantic in nature for a specified context, and that evaluative\ntasks should reflect this more closely. Assuming a context of object\nrecognition, we recommend a set of benchmarks, motivated by practical\napplications. We make progress on these benchmarks by exploring a multi-task\nlearning based approach, showing that auxiliary objectives for improved\nsemantic awareness result in improved semantic anomaly detection, with\naccompanying generalization benefits.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 14:56:40 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 16:35:16 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 20:48:53 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Ahmed", "Faruk", ""], ["Courville", "Aaron", ""]]}, {"id": "1908.04389", "submitter": "Moustafa Alzantot", "authors": "Moustafa Alzantot, Amy Widdicombe, Simon Julier, Mani Srivastava", "title": "NeuroMask: Explaining Predictions of Deep Neural Networks through Mask\n  Learning", "comments": null, "journal-ref": "Published in the DAIS 2019 - Workshop on Distributed Analytics\n  InfraStructure and Algorithms for Multi-Organization Federations", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) deliver state-of-the-art performance in many\nimage recognition and understanding applications. However, despite their\noutstanding performance, these models are black-boxes and it is hard to\nunderstand how they make their decisions. Over the past few years, researchers\nhave studied the problem of providing explanations of why DNNs predicted their\nresults. However, existing techniques are either obtrusive, requiring changes\nin model training, or suffer from low output quality. In this paper, we present\na novel method, NeuroMask, for generating an interpretable explanation of\nclassification model results. When applied to image classification models,\nNeuroMask identifies the image parts that are most important to classifier\nresults by applying a mask that hides/reveals different parts of the image,\nbefore feeding it back into the model. The mask values are tuned by minimizing\na properly designed cost function that preserves the classification result and\nencourages producing an interpretable mask. Experiments using state-of-the-art\nConvolutional Neural Networks for image recognition on different datasets\n(CIFAR-10 and ImageNet) show that NeuroMask successfully localizes the parts of\nthe input image which are most relevant to the DNN decision. By showing a\nvisual quality comparison between NeuroMask explanations and those of other\nmethods, we find NeuroMask to be both accurate and interpretable.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 07:33:30 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Alzantot", "Moustafa", ""], ["Widdicombe", "Amy", ""], ["Julier", "Simon", ""], ["Srivastava", "Mani", ""]]}, {"id": "1908.04390", "submitter": "Stefan Langer", "authors": "Stefan Langer, Robert M\\\"uller, Kyrill Schmid and Claudia\n  Linnhoff-Popien", "title": "Difficulty Classification of Mountainbike Downhill Trails utilizing Deep\n  Neural Networks", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty of mountainbike downhill trails is a subjective perception.\nHowever, sports-associations and mountainbike park operators attempt to group\ntrails into different levels of difficulty with scales like the\nSingletrail-Skala (S0-S5) or colored scales (blue, red, black, ...) as proposed\nby The International Mountain Bicycling Association. Inconsistencies in\ndifficulty grading occur due to the various scales, different people grading\nthe trails, differences in topography, and more. We propose an end-to-end deep\nlearning approach to classify trails into three difficulties easy, medium, and\nhard by using sensor data. With mbientlab Meta Motion r0.2 sensor units, we\nrecord accelerometer- and gyroscope data of one rider on multiple trail\nsegments. A 2D convolutional neural network is trained with a stacked and\nconcatenated representation of the aforementioned data as its input. We run\nexperiments with five different sample- and five different kernel sizes and\nachieve a maximum Sparse Categorical Accuracy of 0.9097. To the best of our\nknowledge, this is the first work targeting computational difficulty\nclassification of mountainbike downhill trails.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 08:11:07 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Langer", "Stefan", ""], ["M\u00fcller", "Robert", ""], ["Schmid", "Kyrill", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1908.04392", "submitter": "Amir Mosavi Prof", "authors": "Husein Perez, Joseph H. M. Tah, Amir Mosavi", "title": "Deep Learning for Detecting Building Defects Using Convolutional Neural\n  Networks", "comments": "29 pages, 11 figures", "journal-ref": null, "doi": "10.20944/preprints201908.0068.v1", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clients are increasingly looking for fast and effective means to quickly and\nfrequently survey and communicate the condition of their buildings so that\nessential repairs and maintenance work can be done in a proactive and timely\nmanner before it becomes too dangerous and expensive. Traditional methods for\nthis type of work commonly comprise of engaging building surveyors to undertake\na condition assessment which involves a lengthy site inspection to produce a\nsystematic recording of the physical condition of the building elements,\nincluding cost estimates of immediate and projected long-term costs of renewal,\nrepair and maintenance of the building. Current asset condition assessment\nprocedures are extensively time consuming, laborious, and expensive and pose\nhealth and safety threats to surveyors, particularly at height and roof levels\nwhich are difficult to access. This paper aims at evaluating the application of\nconvolutional neural networks (CNN) towards an automated detection and\nlocalisation of key building defects, e.g., mould, deterioration, and stain,\nfrom images. The proposed model is based on pre-trained CNN classifier of\nVGG-16 (later compaired with ResNet-50, and Inception models), with class\nactivation mapping (CAM) for object localisation. The challenges and\nlimitations of the model in real-life applications have been identified. The\nproposed model has proven to be robust and able to accurately detect and\nlocalise building defects. The approach is being developed with the potential\nto scale-up and further advance to support automated detection of defects and\ndeterioration of buildings in real-time using mobile devices and drones.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 16:21:10 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Perez", "Husein", ""], ["Tah", "Joseph H. M.", ""], ["Mosavi", "Amir", ""]]}, {"id": "1908.04412", "submitter": "Alexei Novikov", "authors": "Miguel Moscoso, Alexei Novikov, George Papanicolaou, and Chrysoula\n  Tsogka", "title": "The Noise Collector for sparse recovery in high dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect sparse signals from noisy high-dimensional data is a\ntop priority in modern science and engineering. A sparse solution of the linear\nsystem $A \\rho = b_0$ can be found efficiently with an $l_1$-norm minimization\napproach if the data is noiseless. Detection of the signal's support from data\ncorrupted by noise is still a challenging problem, especially if the level of\nnoise must be estimated. We propose a new efficient approach that does not\nrequire any parameter estimation. We introduce the Noise Collector (NC) matrix\n$C$ and solve an augmented system $A \\rho + C \\eta = b_0 + e$, where $ e$ is\nthe noise. We show that the $l_1$-norm minimal solution of the augmented system\nhas zero false discovery rate for any level of noise and with probability that\ntends to one as the dimension of $ b_0$ increases to infinity. We also obtain\nexact support recovery if the noise is not too large, and develop a Fast Noise\nCollector Algorithm which makes the computational cost of solving the augmented\nsystem comparable to that of the original one. Finally, we demonstrate the\neffectiveness of the method in applications to passive array imaging.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:13:42 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Moscoso", "Miguel", ""], ["Novikov", "Alexei", ""], ["Papanicolaou", "George", ""], ["Tsogka", "Chrysoula", ""]]}, {"id": "1908.04433", "submitter": "Hossein Taheri", "authors": "Hossein Taheri, Ramtin Pedarsani and Christos Thrampoulidis", "title": "Sharp Guarantees for Solving Random Equations with One-Bit Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG eess.SP math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of a wide class of convex optimization-based\nestimators for recovering a signal from corrupted one-bit measurements in\nhigh-dimensions. Our general result predicts sharply the performance of such\nestimators in the linear asymptotic regime when the measurement vectors have\nentries IID Gaussian. This includes, as a special case, the previously studied\nleast-squares estimator and various novel results for other popular estimators\nsuch as least-absolute deviations, hinge-loss and logistic-loss. Importantly,\nwe exploit the fact that our analysis holds for generic convex loss functions\nto prove a bound on the best achievable performance across the entire class of\nestimators. Numerical simulations corroborate our theoretical findings and\nsuggest they are accurate even for relatively small problem dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 22:51:06 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 19:54:10 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Taheri", "Hossein", ""], ["Pedarsani", "Ramtin", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "1908.04436", "submitter": "Philip Bontrager", "authors": "Philip Bontrager, Ahmed Khalifa, Damien Anderson, Matthew Stephenson,\n  Christoph Salge, Julian Togelius", "title": "Superstition in the Network: Deep Reinforcement Learning Plays Deceptive\n  Games", "comments": "7 pages, 4 figures, Accepted at the 15th AAAI Conference on\n  Artificial Intelligence and Interactive Digital Entertainment (AIIDE 19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has learned to play many games well, but failed\non others. To better characterize the modes and reasons of failure of deep\nreinforcement learners, we test the widely used Asynchronous Actor-Critic (A2C)\nalgorithm on four deceptive games, which are specially designed to provide\nchallenges to game-playing agents. These games are implemented in the General\nVideo Game AI framework, which allows us to compare the behavior of\nreinforcement learning-based agents with planning agents based on tree search.\nWe find that several of these games reliably deceive deep reinforcement\nlearners, and that the resulting behavior highlights the shortcomings of the\nlearning algorithm. The particular ways in which agents fail differ from how\nplanning-based agents fail, further illuminating the character of these\nalgorithms. We propose an initial typology of deceptions which could help us\nbetter understand pitfalls and failure modes of (deep) reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 23:27:26 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Bontrager", "Philip", ""], ["Khalifa", "Ahmed", ""], ["Anderson", "Damien", ""], ["Stephenson", "Matthew", ""], ["Salge", "Christoph", ""], ["Togelius", "Julian", ""]]}, {"id": "1908.04457", "submitter": "Pedro Savarese", "authors": "Pedro Savarese", "title": "On the Convergence of AdaBound and its Connection to SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient methods such as Adam have gained extreme popularity due to\ntheir success in training complex neural networks and less sensitivity to\nhyperparameter tuning compared to SGD. However, it has been recently shown that\nAdam can fail to converge and might cause poor generalization -- this lead to\nthe design of new, sophisticated adaptive methods which attempt to generalize\nwell while being theoretically reliable. In this technical report we focus on\nAdaBound, a promising, recently proposed optimizer. We present a stochastic\nconvex problem for which AdaBound can provably take arbitrarily long to\nconverge in terms of a factor which is not accounted for in the convergence\nrate guarantee of Luo et al. (2019). We present a new $O(\\sqrt T)$ regret\nguarantee under different assumptions on the bound functions, and provide\nempirical results on CIFAR suggesting that a specific form of momentum SGD can\nmatch AdaBound's performance while having less hyperparameters and lower\ncomputational costs.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 02:00:21 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 06:34:54 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Savarese", "Pedro", ""]]}, {"id": "1908.04463", "submitter": "Haibin Chang", "authors": "Hao Xu, Haibin Chang, Dongxiao Zhang", "title": "DL-PDE: Deep-learning based data-driven discovery of partial\n  differential equations from discrete and noisy data", "comments": null, "journal-ref": "Communications in Computational Physics. 2021, 29, 698-728", "doi": "10.4208/cicp.OA-2020-0142", "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, data-driven methods have been developed to learn dynamical\nsystems and partial differential equations (PDE). The goal of such work is\ndiscovering unknown physics and the corresponding equations. However, prior to\nachieving this goal, major challenges remain to be resolved, including learning\nPDE under noisy data and limited discrete data. To overcome these challenges,\nin this work, a deep-learning based data-driven method, called DL-PDE, is\ndeveloped to discover the governing PDEs of underlying physical processes. The\nDL-PDE method combines deep learning via neural networks and data-driven\ndiscovery of PDE via sparse regressions. In the DL-PDE, a neural network is\nfirst trained, and then a large amount of meta-data is generated, and the\nrequired derivatives are calculated by automatic differentiation. Finally, the\nform of PDE is discovered by sparse regression. The proposed method is tested\nwith physical processes, governed by groundwater flow equation,\nconvection-diffusion equation, Burgers equation and Korteweg-de Vries (KdV)\nequation, for proof-of-concept and applications in real-world engineering\nsettings. The proposed method achieves satisfactory results when data are noisy\nand limited.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 02:26:14 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 12:17:35 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Xu", "Hao", ""], ["Chang", "Haibin", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "1908.04468", "submitter": "Fred Zhang", "authors": "Zhixian Lei, Kyle Luh, Prayaag Venkat, Fred Zhang", "title": "A Fast Spectral Algorithm for Mean Estimation with Sub-Gaussian Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the algorithmic problem of estimating the mean of heavy-tailed\nrandom vector in $\\mathbb{R}^d$, given $n$ i.i.d. samples. The goal is to\ndesign an efficient estimator that attains the optimal sub-gaussian error\nbound, only assuming that the random vector has bounded mean and covariance.\nPolynomial-time solutions to this problem are known but have high runtime due\nto their use of semi-definite programming (SDP). Conceptually, it remains open\nwhether convex relaxation is truly necessary for this problem.\n  In this work, we show that it is possible to go beyond SDP and achieve better\ncomputational efficiency. In particular, we provide a spectral algorithm that\nachieves the optimal statistical performance and runs in time $\\widetilde\nO\\left(n^2 d \\right)$, improving upon the previous fastest runtime $\\widetilde\nO\\left(n^{3.5}+ n^2d\\right)$ by Cherapanamjeri el al. (COLT '19). Our algorithm\nis spectral in that it only requires (approximate) eigenvector computations,\nwhich can be implemented very efficiently by, for example, power iteration or\nthe Lanczos method.\n  At the core of our algorithm is a novel connection between the furthest\nhyperplane problem introduced by Karnin et al. (COLT '12) and a structural\nlemma on heavy-tailed distributions by Lugosi and Mendelson (Ann. Stat. '19).\nThis allows us to iteratively reduce the estimation error at a geometric rate\nusing only the information derived from the top singular vector of the data\nmatrix, leading to a significantly faster running time.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 02:56:01 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 22:56:41 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Lei", "Zhixian", ""], ["Luh", "Kyle", ""], ["Venkat", "Prayaag", ""], ["Zhang", "Fred", ""]]}, {"id": "1908.04469", "submitter": "Chaowei Tan", "authors": "Chaowei Tan, Zhennan Yan, Shaoting Zhang, Kang Li, and Dimitris N.\n  Metaxas", "title": "Collaborative Multi-agent Learning for MR Knee Articular Cartilage\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The 3D morphology and quantitative assessment of knee articular cartilages\n(i.e., femoral, tibial, and patellar cartilage) in magnetic resonance (MR)\nimaging is of great importance for knee radiographic osteoarthritis (OA)\ndiagnostic decision making. However, effective and efficient delineation of all\nthe knee articular cartilages in large-sized and high-resolution 3D MR knee\ndata is still an open challenge. In this paper, we propose a novel framework to\nsolve the MR knee cartilage segmentation task. The key contribution is the\nadversarial learning based collaborative multi-agent segmentation network. In\nthe proposed network, we use three parallel segmentation agents to label\ncartilages in their respective region of interest (ROI), and then fuse the\nthree cartilages by a novel ROI-fusion layer. The collaborative learning is\ndriven by an adversarial sub-network. The ROI-fusion layer not only fuses the\nindividual cartilages from multiple agents, but also backpropagates the\ntraining loss from the adversarial sub-network to each agent to enable joint\nlearning of shape and spatial constraints. Extensive evaluations are conducted\non a dataset including hundreds of MR knee volumes with diverse populations,\nand the proposed method shows superior performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 02:58:17 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Tan", "Chaowei", ""], ["Yan", "Zhennan", ""], ["Zhang", "Shaoting", ""], ["Li", "Kang", ""], ["Metaxas", "Dimitris N.", ""]]}, {"id": "1908.04470", "submitter": "Daohong Xiang", "authors": "Jun Fan and Dao-Hong Xiang", "title": "Comparison theorems on large-margin learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies binary classification problem associated with a family of\nloss functions called large-margin unified machines (LUM), which offers a\nnatural bridge between distribution-based likelihood approaches and\nmargin-based approaches. It also can overcome the so-called data piling issue\nof support vector machine in the high-dimension and low-sample size setting. In\nthis paper we establish some new comparison theorems for all LUM loss functions\nwhich play a key role in the further error analysis of large-margin learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:06:39 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Fan", "Jun", ""], ["Xiang", "Dao-Hong", ""]]}, {"id": "1908.04471", "submitter": "Kohei Hayashi", "authors": "Kohei Hayashi, Taiki Yamaguchi, Yohei Sugawara, Shin-ichi Maeda", "title": "Einconv: Exploring Unexplored Tensor Network Decompositions for\n  Convolutional Neural Networks", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decomposition methods are widely used for model compression and fast\ninference in convolutional neural networks (CNNs). Although many decompositions\nare conceivable, only CP decomposition and a few others have been applied in\npractice, and no extensive comparisons have been made between available\nmethods. Previous studies have not determined how many decompositions are\navailable, nor which of them is optimal. In this study, we first characterize a\ndecomposition class specific to CNNs by adopting a flexible graphical notation.\nThe class includes such well-known CNN modules as depthwise separable\nconvolution layers and bottleneck layers, but also previously unknown modules\nwith nonlinear activations. We also experimentally compare the tradeoff between\nprediction accuracy and time/space complexity for modules found by enumerating\nall possible decompositions, or by using a neural architecture search. We find\nsome nonlinear decompositions outperform existing ones.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:11:46 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 09:08:40 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Hayashi", "Kohei", ""], ["Yamaguchi", "Taiki", ""], ["Sugawara", "Yohei", ""], ["Maeda", "Shin-ichi", ""]]}, {"id": "1908.04473", "submitter": "Mohammad Shojafar", "authors": "Rahim Taheri, Reza Javidan, Mohammad Shojafar, Zahra Pooranian, Ali\n  Miri, Mauro Conti", "title": "On Defending Against Label Flipping Attacks on Malware Detection Systems", "comments": "21 pages, 6 figures, 4 tables, NCAA Springer Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Label manipulation attacks are a subclass of data poisoning attacks in\nadversarial machine learning used against different applications, such as\nmalware detection. These types of attacks represent a serious threat to\ndetection systems in environments having high noise rate or uncertainty, such\nas complex networks and Internet of Thing (IoT). Recent work in the literature\nhas suggested using the $K$-Nearest Neighboring (KNN) algorithm to defend\nagainst such attacks. However, such an approach can suffer from low to wrong\ndetection accuracy. In this paper, we design an architecture to tackle the\nAndroid malware detection problem in IoT systems. We develop an attack\nmechanism based on Silhouette clustering method, modified for mobile Android\nplatforms. We proposed two Convolutional Neural Network (CNN)-type deep\nlearning algorithms against this \\emph{Silhouette Clustering-based Label\nFlipping Attack (SCLFA)}. We show the effectiveness of these two defense\nalgorithms - \\emph{Label-based Semi-supervised Defense (LSD)} and\n\\emph{clustering-based Semi-supervised Defense (CSD)} - in correcting labels\nbeing attacked. We evaluate the performance of the proposed algorithms by\nvarying the various machine learning parameters on three Android datasets:\nDrebin, Contagio, and Genome and three types of features: API, intent, and\npermission. Our evaluation shows that using random forest feature selection and\nvarying ratios of features can result in an improvement of up to 19\\% accuracy\nwhen compared with the state-of-the-art method in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:31:33 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 13:19:50 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 08:35:34 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Taheri", "Rahim", ""], ["Javidan", "Reza", ""], ["Shojafar", "Mohammad", ""], ["Pooranian", "Zahra", ""], ["Miri", "Ali", ""], ["Conti", "Mauro", ""]]}, {"id": "1908.04475", "submitter": "Alexander Zlokapa", "authors": "Alexander Zlokapa, Abhishek Anand, Jean-Roch Vlimant, Javier M.\n  Duarte, Joshua Job, Daniel Lidar, Maria Spiropulu", "title": "Charged particle tracking with quantum annealing-inspired optimization", "comments": "18 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the High Luminosity Large Hadron Collider (HL-LHC), traditional track\nreconstruction techniques that are critical for analysis are expected to face\nchallenges due to scaling with track density. Quantum annealing has shown\npromise in its ability to solve combinatorial optimization problems amidst an\nongoing effort to establish evidence of a quantum speedup. As a step towards\nexploiting such potential speedup, we investigate a track reconstruction\napproach by adapting the existing geometric Denby-Peterson (Hopfield) network\nmethod to the quantum annealing framework and to HL-LHC conditions.\nFurthermore, we develop additional techniques to embed the problem onto\nexisting and near-term quantum annealing hardware. Results using simulated\nannealing and quantum annealing with the D-Wave 2X system on the TrackML\ndataset are presented, demonstrating the successful application of a quantum\nannealing-inspired algorithm to the track reconstruction challenge. We find\nthat combinatorial optimization problems can effectively reconstruct tracks,\nsuggesting possible applications for fast hardware-specific implementations at\nthe LHC while leaving open the possibility of a quantum speedup for tracking.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:41:40 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Zlokapa", "Alexander", ""], ["Anand", "Abhishek", ""], ["Vlimant", "Jean-Roch", ""], ["Duarte", "Javier M.", ""], ["Job", "Joshua", ""], ["Lidar", "Daniel", ""], ["Spiropulu", "Maria", ""]]}, {"id": "1908.04480", "submitter": "Alexander Zlokapa", "authors": "Alexander Zlokapa, Alex Mott, Joshua Job, Jean-Roch Vlimant, Daniel\n  Lidar, Maria Spiropulu", "title": "Quantum adiabatic machine learning with zooming", "comments": "9 pages, 5 figures", "journal-ref": "Phys. Rev. A 102, 062405 (2020)", "doi": "10.1103/PhysRevA.102.062405", "report-no": null, "categories": "quant-ph cs.LG hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that quantum annealing for machine learning, referred\nto as QAML, can perform comparably to state-of-the-art machine learning methods\nwith a specific application to Higgs boson classification. We propose QAML-Z, a\nnovel algorithm that iteratively zooms in on a region of the energy surface by\nmapping the problem to a continuous space and sequentially applying quantum\nannealing to an augmented set of weak classifiers. Results on a programmable\nquantum annealer show that QAML-Z matches classical deep neural network\nperformance at small training set sizes and reduces the performance margin\nbetween QAML and classical deep neural networks by almost 50% at large training\nset sizes, as measured by area under the ROC curve. The significant improvement\nof quantum annealing algorithms for machine learning and the use of a discrete\nquantum algorithm on a continuous optimization problem both opens a new class\nof problems that can be solved by quantum annealers and suggests the approach\nin performance of near-term quantum machine learning towards classical\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 04:11:51 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 12:30:44 GMT"}], "update_date": "2021-01-04", "authors_parsed": [["Zlokapa", "Alexander", ""], ["Mott", "Alex", ""], ["Job", "Joshua", ""], ["Vlimant", "Jean-Roch", ""], ["Lidar", "Daniel", ""], ["Spiropulu", "Maria", ""]]}, {"id": "1908.04484", "submitter": "C. H. Huck Yang", "authors": "Sheng-Chun Kao, Chao-Han Huck Yang, Pin-Yu Chen, Xiaoli Ma, Tushar\n  Krishna", "title": "Reinforcement Learning based Interconnection Routing for Adaptive\n  Traffic Optimization", "comments": null, "journal-ref": null, "doi": "10.1145/3313231.335236", "report-no": null, "categories": "cs.NI cs.AI cs.AR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Machine Learning (ML) techniques to design and optimize computer\narchitectures is a promising research direction. Optimizing the runtime\nperformance of a Network-on-Chip (NoC) necessitates a continuous learning\nframework. In this work, we demonstrate the promise of applying reinforcement\nlearning (RL) to optimize NoC runtime performance. We present three RL-based\nmethods for learning optimal routing algorithms. The experimental results show\nthe algorithms can successfully learn a near-optimal solution across different\nenvironment states. Reproducible Code:\ngithub.com/huckiyang/interconnect-routing-gym\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 04:35:40 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Kao", "Sheng-Chun", ""], ["Yang", "Chao-Han Huck", ""], ["Chen", "Pin-Yu", ""], ["Ma", "Xiaoli", ""], ["Krishna", "Tushar", ""]]}, {"id": "1908.04494", "submitter": "Mike Wu", "authors": "Mike Wu, Sonali Parbhoo, Michael Hughes, Ryan Kindle, Leo Celi,\n  Maurizio Zazzi, Volker Roth, and Finale Doshi-Velez", "title": "Regional Tree Regularization for Interpretability in Black Box Models", "comments": "AAAI 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of interpretability remains a barrier to the adoption of deep neural\nnetworks. Recently, tree regularization has been proposed to encourage deep\nneural networks to resemble compact, axis-aligned decision trees without\nsignificant compromises in accuracy. However, it may be unreasonable to expect\nthat a single tree can predict well across all possible inputs. In this work,\nwe propose regional tree regularization, which encourages a deep model to be\nwell-approximated by several separate decision trees specific to predefined\nregions of the input space. Practitioners can define regions based on domain\nknowledge of contexts where different decision-making logic is needed. Across\nmany datasets, our approach delivers more accurate predictions than simply\ntraining separate decision trees for each region, while producing simpler\nexplanations than other neural net regularization schemes without sacrificing\npredictive power. Two healthcare case studies in critical care and HIV\ndemonstrate how experts can improve understanding of deep models via our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 05:32:00 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 18:39:11 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 17:23:07 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Wu", "Mike", ""], ["Parbhoo", "Sonali", ""], ["Hughes", "Michael", ""], ["Kindle", "Ryan", ""], ["Celi", "Leo", ""], ["Zazzi", "Maurizio", ""], ["Roth", "Volker", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1908.04518", "submitter": "Usama Naseer", "authors": "Usama Naseer, Theophilus Benson", "title": "ConfigTron: Tackling network diversity with heterogeneous configurations", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web serving protocol stack is constantly changing and evolving to tackle\ntechnological shifts in networking infrastructure and website complexity. As a\nresult of this evolution, the web serving stack includes a plethora of\nprotocols and configuration parameters that enable the web serving stack to\naddress a variety of realistic network conditions. Yet, today, most content\nproviders have adopted a \"one-size-fits-all\" approach to configuring the\nnetworking stack of their user facing web servers (or at best employ moderate\ntuning), despite the significant diversity in end-user networks and devices. In\nthis paper, we revisit this problem and ask a more fundamental question: Are\nthere benefits to tuning the network stack? If so, what system design choices\nand algorithmic ensembles are required to enable modern content provider to\ndynamically and flexibly tune their protocol stacks. We demonstrate through\nsubstantial empirical evidence that this \"one-size-fits-all\" approach results\nin sub-optimal performance and argue for a novel framework that extends\nexisting CDN architectures to provide programmatic control over the\nconfiguration options of the CDN serving stack. We designed ConfigTron a\ndata-driven framework that leverages data from all connections to identify\ntheir network characteristics and learn the optimal configuration parameters to\nimprove end-user performance. ConfigTron uses contextual multi-arm bandit-based\nlearning algorithm to find optimal configurations in minimal time, enabling a\ncontent providers to systematically explore heterogeneous configurations while\nimproving end-user page load time by as much as 19% (upto 750ms) on median.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 07:16:59 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Naseer", "Usama", ""], ["Benson", "Theophilus", ""]]}, {"id": "1908.04537", "submitter": "Wenbo Gong", "authors": "Wenbo Gong, Sebastian Tschiatschek, Richard Turner, Sebastian Nowozin,\n  Jos\\'e Miguel Hern\\'andez-Lobato, Cheng Zhang", "title": "Icebreaker: Element-wise Active Information Acquisition with Bayesian\n  Deep Latent Gaussian Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the ice-start problem, i.e., the challenge of\ndeploying machine learning models when only little or no training data is\ninitially available, and acquiring each feature element of data is associated\nwith costs. This setting is representative for the real-world machine learning\napplications. For instance, in the health-care domain, when training an AI\nsystem for predicting patient metrics from lab tests, obtaining every single\nmeasurement comes with a high cost. Active learning, where only the label is\nassociated with a cost does not apply to such problem, because performing all\npossible lab tests to acquire a new training datum would be costly, as well as\nunnecessary due to redundancy. We propose Icebreaker, a principled framework to\napproach the ice-start problem. Icebreaker uses a full Bayesian Deep Latent\nGaussian Model (BELGAM) with a novel inference method. Our proposed method\ncombines recent advances in amortized inference and stochastic gradient MCMC to\nenable fast and accurate posterior inference. By utilizing BELGAM's ability to\nfully quantify model uncertainty, we also propose two information acquisition\nfunctions for imputation and active prediction problems. We demonstrate that\nBELGAM performs significantly better than the previous VAE (Variational\nautoencoder) based models, when the data set size is small, using both machine\nlearning benchmarks and real-world recommender systems and health-care\napplications. Moreover, based on BELGAM, Icebreaker further improves the\nperformance and demonstrate the ability to use minimum amount of the training\ndata to obtain the highest test time performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 08:49:33 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 09:20:57 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Gong", "Wenbo", ""], ["Tschiatschek", "Sebastian", ""], ["Turner", "Richard", ""], ["Nowozin", "Sebastian", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Zhang", "Cheng", ""]]}, {"id": "1908.04538", "submitter": "Esther Puyol-Anton Miss", "authors": "Esther Puyol-Ant\\'on, Bram Ruijsink, James R. Clough, Ilkay Oksuz,\n  Daniel Rueckert, Reza Razavi, Andrew P. King", "title": "Assessing the Impact of Blood Pressure on Cardiac Function Using\n  Interpretable Biomarkers and Variational Autoencoders", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-39074-7_3", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintaining good cardiac function for as long as possible is a major concern\nfor healthcare systems worldwide and there is much interest in learning more\nabout the impact of different risk factors on cardiac health. The aim of this\nstudy is to analyze the impact of systolic blood pressure (SBP) on cardiac\nfunction while preserving the interpretability of the model using known\nclinical biomarkers in a large cohort of the UK Biobank population. We propose\na novel framework that combines deep learning based estimation of interpretable\nclinical biomarkers from cardiac cine MR data with a variational autoencoder\n(VAE). The VAE architecture integrates a regression loss in the latent space,\nwhich enables the progression of cardiac health with SBP to be learnt. Results\non 3,600 subjects from the UK Biobank show that the proposed model allows us to\ngain important insight into the deterioration of cardiac function with\nincreasing SBP, identify key interpretable factors involved in this process,\nand lastly exploit the model to understand patterns of positive and adverse\nadaptation of cardiac function.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 08:49:58 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Puyol-Ant\u00f3n", "Esther", ""], ["Ruijsink", "Bram", ""], ["Clough", "James R.", ""], ["Oksuz", "Ilkay", ""], ["Rueckert", "Daniel", ""], ["Razavi", "Reza", ""], ["King", "Andrew P.", ""]]}, {"id": "1908.04562", "submitter": "Jenni Raitoharju", "authors": "Jenni Raitoharju and Alexandros Iosifidis", "title": "Null Space Analysis for Class-Specific Discriminant Learning", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we carry out null space analysis for Class-Specific\nDiscriminant Analysis (CSDA) and formulate a number of solutions based on the\nanalysis. We analyze both theoretically and experimentally the significance of\neach algorithmic step. The innate subspace dimensionality resulting from the\nproposed solutions is typically quite high and we discuss how the need for\nfurther dimensionality reduction changes the situation. Experimental evaluation\nof the proposed solutions shows that the straightforward extension of null\nspace analysis approaches to the class-specific setting can outperform the\nstandard CSDA method. Furthermore, by exploiting a recently proposed\nout-of-class scatter definition encoding the multi-modality of the negative\nclass naturally appearing in class-specific problems, null space projections\ncan lead to a performance comparable to or outperforming the most recent CSDA\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 09:34:15 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Raitoharju", "Jenni", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1908.04573", "submitter": "Yue Wang", "authors": "Yue Wang, Yao Wan, Chenwei Zhang, Lixin Cui, Lu Bai, and Philip S. Yu", "title": "Competitive Multi-Agent Deep Reinforcement Learning with Counterfactual\n  Thinking", "comments": "This paper is accepted by ICDM'19 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual thinking describes a psychological phenomenon that people\nre-infer the possible results with different solutions about things that have\nalready happened. It helps people to gain more experience from mistakes and\nthus to perform better in similar future tasks. This paper investigates the\ncounterfactual thinking for agents to find optimal decision-making strategies\nin multi-agent reinforcement learning environments. In particular, we propose a\nmulti-agent deep reinforcement learning model with a structure which mimics the\nhuman-psychological counterfactual thinking process to improve the competitive\nabilities for agents. To this end, our model generates several possible actions\n(intent actions) with a parallel policy structure and estimates the rewards and\nregrets for these intent actions based on its current understanding of the\nenvironment. Our model incorporates a scenario-based framework to link the\nestimated regrets with its inner policies. During the iterations, our model\nupdates the parallel policies and the corresponding scenario-based regrets for\nagents simultaneously. To verify the effectiveness of our proposed model, we\nconduct extensive experiments on two different environments with real-world\napplications. Experimental results show that counterfactual thinking can\nactually benefit the agents to obtain more accumulative rewards from the\nenvironments with fair information by comparing to their opponents while\nkeeping high performing efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 10:55:24 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 13:40:16 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Wang", "Yue", ""], ["Wan", "Yao", ""], ["Zhang", "Chenwei", ""], ["Cui", "Lixin", ""], ["Bai", "Lu", ""], ["Yu", "Philip S.", ""]]}, {"id": "1908.04628", "submitter": "Xindi Wang", "authors": "Xindi Wang, Onur Varol, Tina Eliassi-Rad", "title": "L2P: An Algorithm for Estimating Heavy-tailed Outcomes", "comments": "9 pages, 6 figures, 2 tables Nature of changes from previous version:\n  1. Added complexity analysis in Section 2.2 2. Datasets change 3. Added\n  LambdaMART in the baseline methods, also a brief discussion on why LambdaMart\n  failed in our problem. 4. Figure updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world prediction tasks have outcome variables that have\ncharacteristic heavy-tail distributions. Examples include copies of books sold,\nauction prices of art pieces, demand for commodities in warehouses, etc. By\nlearning heavy-tailed distributions, \"big and rare\" instances (e.g., the\nbest-sellers) will have accurate predictions. Most existing approaches are not\ndedicated to learning heavy-tailed distribution; thus, they heavily\nunder-predict such instances. To tackle this problem, we introduce Learning to\nPlace (L2P), which exploits the pairwise relationships between instances for\nlearning. In its training phase, L2P learns a pairwise preference classifier:\nis instance A > instance B? In its placing phase, L2P obtains a prediction by\nplacing the new instance among the known instances. Based on its placement, the\nnew instance is then assigned a value for its outcome variable. Experiments on\nreal data show that L2P outperforms competing approaches in terms of accuracy\nand ability to reproduce heavy-tailed outcome distribution. In addition, L2P\nprovides an interpretable model by placing each predicted instance in relation\nto its comparable neighbors. Interpretable models are highly desirable when\nlives and treasure are at stake.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:20:50 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 13:15:46 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Xindi", ""], ["Varol", "Onur", ""], ["Eliassi-Rad", "Tina", ""]]}, {"id": "1908.04674", "submitter": "Andreas Vogelsang", "authors": "Andreas Vogelsang and Markus Borg", "title": "Requirements Engineering for Machine Learning: Perspectives from Data\n  Scientists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is used increasingly in real-world applications. In\nthis paper, we describe our ongoing endeavor to define characteristics and\nchallenges unique to Requirements Engineering (RE) for ML-based systems. As a\nfirst step, we interviewed four data scientists to understand how ML experts\napproach elicitation, specification, and assurance of requirements and\nexpectations. The results show that changes in the development paradigm, i.e.,\nfrom coding to training, also demands changes in RE. We conclude that\ndevelopment of ML systems demands requirements engineers to: (1) understand ML\nperformance measures to state good functional requirements, (2) be aware of new\nquality requirements such as explainability, freedom from discrimination, or\nspecific legal requirements, and (3) integrate ML specifics in the RE process.\nOur study provides a first contribution towards an RE methodology for ML\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 14:47:35 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Vogelsang", "Andreas", ""], ["Borg", "Markus", ""]]}, {"id": "1908.04682", "submitter": "Amit Mishra", "authors": "Amit Mishra, Pranath Reddy, Rahul Nigam", "title": "CMB-GAN: Fast Simulations of Cosmic Microwave background anisotropy maps\n  using Deep Learning", "comments": "9 pages, cosmic microwave background radiation, deep learning,\n  generative adversarial network. arXiv admin note: text overlap with\n  arXiv:1903.12253", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cosmic Microwave Background (CMB) has been a cornerstone in many cosmology\nexperiments and studies since it was discovered back in 1964. Traditional\ncomputational models like CAMB that are used for generating CMB temperature\nanisotropy maps are extremely resource intensive and act as a bottleneck in\ncosmology experiments that require a large amount of CMB data for analysis. In\nthis paper, we present a new approach to the generation of CMB temperature maps\nusing a specific class of neural networks called Generative Adversarial Network\n(GAN). We train our deep generative model to learn the complex distribution of\nCMB maps and efficiently generate new sets of CMB data in the form of 2D\npatches of anisotropy maps without losing much accuracy. We limit our\nexperiment to the generation of 56$^{\\circ}$ and 112$^{\\circ}$ square patches\nof CMB maps. We have also trained a Multilayer perceptron model for estimation\nof baryon density from a CMB map, we will be using this model for the\nperformance evaluation of our generative model using diagnostic measures like\nHistogram of pixel intensities, the standard deviation of pixel intensity\ndistribution, Power Spectrum, Cross power spectrum, Correlation matrix of the\npower spectrum and Peak count. We show that the GAN model is able to\nefficiently generate CMB samples of multiple sizes and is sensitive to the\ncosmological parameters corresponding to the underlying distribution of the\ndata. The primiary advantage of this method is the exponential reduction in the\ncomputational time needed to generate the CMB data, the GAN model is able to\ngenerate the samples within seconds as opposed to hours required by the CAMB\npackage with an acceptable value to error and loss of information. We hope that\nfuture iterations of this methodology will replace traditional statistical\nmethods of CMB data generation and help in large scale cosmological\nexperiments.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 07:23:41 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 06:21:51 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 12:40:08 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Mishra", "Amit", ""], ["Reddy", "Pranath", ""], ["Nigam", "Rahul", ""]]}, {"id": "1908.04685", "submitter": "Liang Wang", "authors": "Liang Wang, Hao Ye, Le Liang, Geoffrey Ye Li", "title": "Learn to Compress CSI and Allocate Resources in Vehicular Networks", "comments": "arXiv admin note: text overlap with arXiv:1908.03447", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource allocation has a direct and profound impact on the performance of\nvehicle-to-everything (V2X) networks. In this paper, we develop a hybrid\narchitecture consisting of centralized decision making and distributed resource\nsharing (the C-Decision scheme) to maximize the long-term sum rate of all\nvehicles. To reduce the network signaling overhead, each vehicle uses a deep\nneural network to compress its observed information that is thereafter fed back\nto the centralized decision making unit. The centralized decision unit employs\na deep Q-network to allocate resources and then sends the decision results to\nall vehicles. We further adopt a quantization layer for each vehicle that\nlearns to quantize the continuous feedback. In addition, we devise a mechanism\nto balance the transmission of vehicle-to-vehicle (V2V) links and\nvehicle-to-infrastructure (V2I) links. To further facilitate distributed\nspectrum sharing, we also propose a distributed decision making and spectrum\nsharing architecture (the D-Decision scheme) for each V2V link. Through\nextensive simulation results, we demonstrate that the proposed C-Decision and\nD-Decision schemes can both achieve near-optimal performance and are robust to\nfeedback interval variations, input noise, and feedback noise.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 02:55:00 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Wang", "Liang", ""], ["Ye", "Hao", ""], ["Liang", "Le", ""], ["Li", "Geoffrey Ye", ""]]}, {"id": "1908.04694", "submitter": "Shih-Chieh Su", "authors": "Shih-Chieh Su", "title": "Channel Decomposition into Painting Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a method to decompose a convolutional layer of the deep\nneural network into painting actions. To behave like the human painter, these\nactions are driven by the cost simulating the hand movement, the paint color\nchange, the stroke shape and the stroking style. To help planning, the Mask\nR-CNN is applied to detect the object areas and decide the painting order. The\nproposed painting system introduces a variety of extensions in artistic styles,\nbased on the chosen parameters. Further experiments are performed to evaluate\nthe channel penetration and the channel sensitivity on the strokes.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 06:58:55 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 18:38:21 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 07:59:10 GMT"}, {"version": "v4", "created": "Tue, 12 Nov 2019 06:24:11 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Su", "Shih-Chieh", ""]]}, {"id": "1908.04700", "submitter": "Emile Van Krieken", "authors": "Emile van Krieken, Erman Acar, Frank van Harmelen", "title": "Semi-Supervised Learning using Differentiable Reasoning", "comments": null, "journal-ref": "IFCoLog Journal of Logic and its Applications 6 (2019) 633-653", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Differentiable Reasoning (DR), a novel semi-supervised learning\ntechnique which uses relational background knowledge to benefit from unlabeled\ndata. We apply it to the Semantic Image Interpretation (SII) task and show that\nbackground knowledge provides significant improvement. We find that there is a\nstrong but interesting imbalance between the contributions of updates from\nModus Ponens (MP) and its logical equivalent Modus Tollens (MT) to the learning\nprocess, suggesting that our approach is very sensitive to a phenomenon called\nthe Raven Paradox. We propose a solution to overcome this situation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:21:37 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["van Krieken", "Emile", ""], ["Acar", "Erman", ""], ["van Harmelen", "Frank", ""]]}, {"id": "1908.04705", "submitter": "Yu Emma Wang", "authors": "Yu Emma Wang, Carole-Jean Wu, Xiaodong Wang, Kim Hazelwood, David\n  Brooks", "title": "Exploiting Parallelism Opportunities with Deep Learning Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  State-of-the-art machine learning frameworks support a wide variety of design\nfeatures to enable a flexible machine learning programming interface and to\nease the programmability burden on machine learning developers. Identifying and\nusing a performance-optimal setting in feature-rich frameworks, however,\ninvolves a non-trivial amount of performance profiling efforts and often relies\non domain-specific knowledge. This paper takes a deep dive into analyzing the\nperformance impact of key design features in a machine learning framework and\nquantifies the role of parallelism. The observations and insights distill into\na simple set of guidelines that one can use to achieve much higher training and\ninference speedup. Across a diverse set of real-world deep learning models, the\nevaluation results show that the proposed performance tuning guidelines\noutperform the Intel and TensorFlow recommended settings by 1.29x and 1.34x,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:41:14 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 23:37:48 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Wang", "Yu Emma", ""], ["Wu", "Carole-Jean", ""], ["Wang", "Xiaodong", ""], ["Hazelwood", "Kim", ""], ["Brooks", "David", ""]]}, {"id": "1908.04710", "submitter": "Aur\\'elien Bellet", "authors": "William de Vazelhes and CJ Carey and Yuan Tang and Nathalie Vauquier\n  and Aur\\'elien Bellet", "title": "metric-learn: Metric Learning Algorithms in Python", "comments": "GitHub repository:\n  https://github.com/scikit-learn-contrib/metric-learn", "journal-ref": "Journal of Machine Learning Research (JMLR), 21(138):1-6, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  metric-learn is an open source Python package implementing supervised and\nweakly-supervised distance metric learning algorithms. As part of\nscikit-learn-contrib, it provides a unified interface compatible with\nscikit-learn which allows to easily perform cross-validation, model selection,\nand pipelining with other machine learning estimators. metric-learn is\nthoroughly tested and available on PyPi under the MIT licence.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:52:31 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 14:33:38 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 14:47:52 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["de Vazelhes", "William", ""], ["Carey", "CJ", ""], ["Tang", "Yuan", ""], ["Vauquier", "Nathalie", ""], ["Bellet", "Aur\u00e9lien", ""]]}, {"id": "1908.04729", "submitter": "Zewen Chi", "authors": "Zewen Chi, Heyan Huang, Heng-Da Xu, Houjin Yu, Wanxuan Yin and\n  Xian-Ling Mao", "title": "Complicated Table Structure Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of table structure recognition aims to recognize the internal\nstructure of a table, which is a key step to make machines understand tables.\nCurrently, there are lots of studies on this task for different file formats\nsuch as ASCII text and HTML. It also attracts lots of attention to recognize\nthe table structures in PDF files. However, it is hard for the existing methods\nto accurately recognize the structure of complicated tables in PDF files. The\ncomplicated tables contain spanning cells which occupy at least two columns or\nrows. To address the issue, we propose a novel graph neural network for\nrecognizing the table structure in PDF files, named GraphTSR. Specifically, it\ntakes table cells as input, and then recognizes the table structures by\npredicting relations among cells. Moreover, to evaluate the task better, we\nconstruct a large-scale table structure recognition dataset from scientific\npapers, named SciTSR, which contains 15,000 tables from PDF files and their\ncorresponding structure labels. Extensive experiments demonstrate that our\nproposed model is highly effective for complicated tables and outperforms\nstate-of-the-art baselines over a benchmark dataset and our new constructed\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:47:08 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 16:24:53 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Chi", "Zewen", ""], ["Huang", "Heyan", ""], ["Xu", "Heng-Da", ""], ["Yu", "Houjin", ""], ["Yin", "Wanxuan", ""], ["Mao", "Xian-Ling", ""]]}, {"id": "1908.04734", "submitter": "Tom Everitt", "authors": "Tom Everitt, Marcus Hutter, Ramana Kumar, Victoria Krakovna", "title": "Reward Tampering Problems and Solutions in Reinforcement Learning: A\n  Causal Influence Diagram Perspective", "comments": "Accepted to Synthese, March 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can humans get arbitrarily capable reinforcement learning (RL) agents to do\ntheir bidding? Or will sufficiently capable RL agents always find ways to\nbypass their intended objectives by shortcutting their reward signal? This\nquestion impacts how far RL can be scaled, and whether alternative paradigms\nmust be developed in order to build safe artificial general intelligence. In\nthis paper, we study when an RL agent has an instrumental goal to tamper with\nits reward process, and describe design principles that prevent instrumental\ngoals for two different types of reward tampering (reward function tampering\nand RF-input tampering). Combined, the design principles can prevent both types\nof reward tampering from being instrumental goals. The analysis benefits from\ncausal influence diagrams to provide intuitive yet precise formalizations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:50:00 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 17:04:39 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 15:47:55 GMT"}, {"version": "v4", "created": "Thu, 18 Feb 2021 17:55:25 GMT"}, {"version": "v5", "created": "Fri, 26 Mar 2021 11:13:59 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Everitt", "Tom", ""], ["Hutter", "Marcus", ""], ["Kumar", "Ramana", ""], ["Krakovna", "Victoria", ""]]}, {"id": "1908.04737", "submitter": "Pavel Denisov", "authors": "Pavel Denisov, Ngoc Thang Vu", "title": "End-to-End Multi-Speaker Speech Recognition using Speaker Embeddings and\n  Transfer Learning", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our latest investigation on end-to-end automatic speech\nrecognition (ASR) for overlapped speech. We propose to train an end-to-end\nsystem conditioned on speaker embeddings and further improved by transfer\nlearning from clean speech. This proposed framework does not require any\nparallel non-overlapped speech materials and is independent of the number of\nspeakers. Our experimental results on overlapped speech datasets show that\njoint conditioning on speaker embeddings and transfer learning significantly\nimproves the ASR performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:56:41 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Denisov", "Pavel", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1908.04741", "submitter": "Stefan Klus", "authors": "Feliks N\\\"uske, Patrick Gel{\\ss}, Stefan Klus, Cecilia Clementi", "title": "Tensor-based computation of metastable and coherent sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.DS physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen rapid advances in the data-driven analysis of\ndynamical systems based on Koopman operator theory -- with extended dynamic\nmode decomposition (EDMD) being a cornerstone of the field. On the other hand,\nlow-rank tensor product approximations -- in particular the tensor train (TT)\nformat -- have become a valuable tool for the solution of large-scale problems\nin a number of fields. In this work, we combine EDMD and the TT format,\nenabling the application of EDMD to high-dimensional problems in conjunction\nwith a large set of features. We derive efficient algorithms to solve the EDMD\neigenvalue problem based on tensor representations of the data, and to project\nthe data into a low-dimensional representation defined by the eigenvectors. We\nextend this method to perform canonical correlation analysis (CCA) of\nnon-reversible or time-dependent systems. We prove that there is a physical\ninterpretation of the procedure and demonstrate its capabilities by applying\nthe method to several benchmark data sets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 15:53:14 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 08:12:55 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["N\u00fcske", "Feliks", ""], ["Gel\u00df", "Patrick", ""], ["Klus", "Stefan", ""], ["Clementi", "Cecilia", ""]]}, {"id": "1908.04742", "submitter": "Massimo Caccia", "authors": "Rahaf Aljundi, Lucas Caccia, Eugene Belilovsky, Massimo Caccia, Min\n  Lin, Laurent Charlin, Tinne Tuytelaars", "title": "Online Continual Learning with Maximally Interfered Retrieval", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning, the setting where a learning agent is faced with a never\nending stream of data, continues to be a great challenge for modern machine\nlearning systems. In particular the online or \"single-pass through the data\"\nsetting has gained attention recently as a natural setting that is difficult to\ntackle. Methods based on replay, either generative or from a stored memory,\nhave been shown to be effective approaches for continual learning, matching or\nexceeding the state of the art in a number of standard benchmarks. These\napproaches typically rely on randomly selecting samples from the replay memory\nor from a generative model, which is suboptimal. In this work, we consider a\ncontrolled sampling of memories for replay. We retrieve the samples which are\nmost interfered, i.e. whose prediction will be most negatively impacted by the\nforeseen parameters update. We show a formulation for this sampling criterion\nin both the generative replay and the experience replay setting, producing\nconsistent gains in performance and greatly reduced forgetting. We release an\nimplementation of our method at\nhttps://github.com/optimass/Maximally_Interfered_Retrieval.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 21:16:44 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 20:15:04 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 18:45:10 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Aljundi", "Rahaf", ""], ["Caccia", "Lucas", ""], ["Belilovsky", "Eugene", ""], ["Caccia", "Massimo", ""], ["Lin", "Min", ""], ["Charlin", "Laurent", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "1908.04751", "submitter": "Ali Abavisani", "authors": "Ali Abavisani and Mark A Hasegawa-Johnson", "title": "The role of cue enhancement and frequency fine-tuning in hearing\n  impaired phone recognition", "comments": "16 pages, 10 figures, proceedings of the Acoustical Society of\n  America meeting, May 2019, Louisville, KY", "journal-ref": null, "doi": "10.1121/1.5101104", "report-no": null, "categories": "q-bio.QM cs.LG cs.SD eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A speech-based hearing test is designed to identify the susceptible\nerror-prone phones for individual hearing impaired (HI) ear. Only robust tokens\nin the experiment noise levels had been chosen for the test. The\nnoise-robustness of tokens is measured as SNR90 of the token, which is the\nsignal to the speech-weighted noise ratio where a normal hearing (NH) listener\nwould recognize the token with an accuracy of 90% on average. Two sets of\ntokens T1 and T2 having the same consonant-vowels but different talkers with\ndistinct SNR90 had been presented with flat gain at listeners' most comfortable\nlevel. We studied the effects of frequency fine-tuning of the primary cue by\npresenting tokens of the same consonant but different vowels with similar\nSNR90. Additionally, we investigated the role of changing the intensity of\nprimary cue in HI phone recognition, by presenting tokens from both sets T1 and\nT2. On average, 92% of tokens are improved when we replaced the CV with the\nsame CV but with a more robust talker. Additionally, using CVs with similar\nSNR90, on average, tokens are improved by 75%, 71%, 63%, and 72%, when we\nreplaced vowels /A, ae, I, E/, respectively. The confusion pattern in each case\nprovides insight into how these changes affect the phone recognition in each HI\near. We propose to prescribe hearing aid amplification tailored to individual\nHI ears, based on the confusion pattern, the response from cue enhancement, and\nthe response from frequency fine-tuning of the cue.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 20:38:41 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Abavisani", "Ali", ""], ["Hasegawa-Johnson", "Mark A", ""]]}, {"id": "1908.04752", "submitter": "Xiyan Cai", "authors": "Tongda Xu, Xiyan Cai, Yao Wang, Xiuyuan Wang, Sohae Chung, Els\n  Fieremans, Joseph Rath, Steven Flanagan, Yvonne W Lui", "title": "Identification of relevant diffusion MRI metrics impacting cognitive\n  functions using a novel feature selection method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mild Traumatic Brain Injury (mTBI) is a significant public health problem.\nThe most troubling symptoms after mTBI are cognitive complaints. Studies show\nmeasurable differences between patients with mTBI and healthy controls with\nrespect to tissue microstructure using diffusion MRI. However, it remains\nunclear which diffusion measures are the most informative with regard to\ncognitive functions in both the healthy state as well as after injury. In this\nstudy, we use diffusion MRI to formulate a predictive model for performance on\nworking memory based on the most relevant MRI features. The key challenge is to\nidentify relevant features over a large feature space with high accuracy in an\nefficient manner. To tackle this challenge, we propose a novel improvement of\nthe best first search approach with crossover operators inspired by genetic\nalgorithm. Compared against other heuristic feature selection algorithms, the\nproposed method achieves significantly more accurate predictions and yields\nclinically interpretable selected features.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 04:08:04 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 13:23:34 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Xu", "Tongda", ""], ["Cai", "Xiyan", ""], ["Wang", "Yao", ""], ["Wang", "Xiuyuan", ""], ["Chung", "Sohae", ""], ["Fieremans", "Els", ""], ["Rath", "Joseph", ""], ["Flanagan", "Steven", ""], ["Lui", "Yvonne W", ""]]}, {"id": "1908.04758", "submitter": "Philippe Terrier PhD", "authors": "Philippe Terrier", "title": "Gait recognition via deep learning of the center-of-pressure trajectory", "comments": "A revised and augmented version of this preprint has been published\n  in the journal Applied Sciences in January 2020", "journal-ref": "Appl. Sci. 2020, 10, 774", "doi": "10.3390/app10030774", "report-no": null, "categories": "q-bio.QM cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The fact that every human has a distinctive walking style has prompted a\nproposal to use gait recognition as an identification criterion. Using\nend-to-end learning, I investigated whether the center-of-pressure trajectory\nis sufficiently unique to identify a person with a high certainty. Thirty-six\nadults walked on a treadmill equipped with a force platform that recorded the\npositions of the center of pressure. The raw two-dimensional signals were\nsliced into segments of two gait cycles. A set of 20,250 segments from 30\nsubjects was used to configure and train convolutional neural networks (CNNs).\nThe best CNN classified a separate set containing 2,250 segments with 99.9%\noverall accuracy. A second set of 4,500 segments from the six remaining\nsubjects was then used for transfer learning. Several small subsamples of this\nset were selected randomly and used for fine tuning. Training with two segments\nper subject was sufficient to achieve 100% accuracy. The results suggest that\nevery person produces a unique trajectory of underfoot pressures and that CNNs\ncan learn the distinctive features of these trajectories. Using transfer\nlearning, a few strides could be sufficient to learn and identify new gaits.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:49:57 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 13:47:44 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 13:06:26 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Terrier", "Philippe", ""]]}, {"id": "1908.04759", "submitter": "Supreeth Prajwal Shashikumar", "authors": "Supreeth P. Shashikumar, Christopher Josef, Ashish Sharma and Shamim\n  Nemati", "title": "DeepAISE -- An End-to-End Development and Deployment of a Recurrent\n  Neural Survival Model for Early Prediction of Sepsis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis, a dysregulated immune system response to infection, is among the\nleading causes of morbidity, mortality, and cost overruns in the Intensive Care\nUnit (ICU). Early prediction of sepsis can improve situational awareness\namongst clinicians and facilitate timely, protective interventions. While the\napplication of predictive analytics in ICU patients has shown early promising\nresults, much of the work has been encumbered by high false-alarm rates.\nEfforts to improve specificity have been limited by several factors, most\nnotably the difficulty of labeling sepsis onset time and the low prevalence of\nseptic-events in the ICU. Here, we present DeepAISE (Deep Artificial\nIntelligence Sepsis Expert), a recurrent neural survival model for the early\nprediction of sepsis. We show that by coupling a clinical criterion for\ndefining sepsis onset time with a treatment policy (e.g., initiation of\nantibiotics within one hour of meeting the criterion), one may rank the\nrelative utility of various criteria through offline policy evaluation. Given\nthe optimal criterion, DeepAISE automatically learns predictive features\nrelated to higher-order interactions and temporal patterns among clinical risk\nfactors that maximize the data likelihood of observed time to septic events.\nDeepAISE has been incorporated into a clinical workflow, which provides\nreal-time hourly sepsis risk scores. A comparative study of four baseline\nmodels indicates that DeepAISE produces the most accurate predictions (AUC=0.90\nand 0.87) and the lowest false alarm rates (FAR=0.20 and 0.26) in two separate\ncohorts (internal and external, respectively), while simultaneously producing\ninterpretable representations of the clinical time series and risk factors.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 19:36:39 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Shashikumar", "Supreeth P.", ""], ["Josef", "Christopher", ""], ["Sharma", "Ashish", ""], ["Nemati", "Shamim", ""]]}, {"id": "1908.04766", "submitter": "Zhaohong Deng", "authors": "Zhaohong Deng, Ruixiu Liu, Te Zhang, Peng Xu, Kup-Sze Choi, Bin Qin,\n  Shitong Wang", "title": "Multi-view Clustering with the Cooperation of Visible and Hidden Views", "comments": "This paper has been submitted to IEEE TKDE in Jun. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view data are becoming common in real-world modeling tasks and many\nmulti-view data clustering algorithms have thus been proposed. The existing\nalgorithms usually focus on the cooperation of different views in the original\nspace but neglect the influence of the hidden information among these different\nvisible views, or they only consider the hidden information between the views.\nThe algorithms are therefore not efficient since the available information is\nnot fully excavated, particularly the otherness information in different views\nand the consistency information between them. In practice, the otherness and\nconsistency information in multi-view data are both very useful for effective\nclustering analyses. In this study, a Multi-View clustering algorithm developed\nwith the Cooperation of Visible and Hidden views, i.e., MV-Co-VH, is proposed.\nThe MV-Co-VH algorithm first projects the multiple views from different visible\nspaces to the common hidden space by using the non-negative matrix\nfactorization (NMF) strategy to obtain the common hidden view data.\nCollaborative learning is then implemented in the clustering procedure based on\nthe visible views and the shared hidden view. The results of extensive\nexperiments on UCI multi-view datasets and real-world image multi-view datasets\nshow that the clustering performance of the proposed algorithm is competitive\nwith or even better than that of the existing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 14:55:22 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Deng", "Zhaohong", ""], ["Liu", "Ruixiu", ""], ["Zhang", "Te", ""], ["Xu", "Peng", ""], ["Choi", "Kup-Sze", ""], ["Qin", "Bin", ""], ["Wang", "Shitong", ""]]}, {"id": "1908.04767", "submitter": "Christian Marzahl", "authors": "Christian Marzahl, Marc Aubreville, Christof A. Bertram, Jason Stayt,\n  Anne-Katherine Jasensky, Florian Bartenschlager, Marco Fragoso-Garcia, Ann K.\n  Barton, Svenja Elsemann, Samir Jabari, Jens Krauth, Prathmesh Madhu, J\\\"orn\n  Voigt, Jenny Hill, Robert Klopfleisch and Andreas Maier", "title": "Deep Learning-Based Quantification of Pulmonary Hemosiderophages in\n  Cytology Slides", "comments": null, "journal-ref": "Sci Rep 10, 9795 (2020)", "doi": "10.1038/s41598-020-65958-2", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Exercise-induced pulmonary hemorrhage (EIPH) is a common syndrome in\nsport horses with negative impact on performance. Cytology of bronchoalveolar\nlavage fluid by use of a scoring system is considered the most sensitive\ndiagnostic method. Macrophages are classified depending on the degree of\ncytoplasmic hemosiderin content. The current gold standard is manual grading,\nwhich is however monotonous and time-consuming. Methods: We evaluated\nstate-of-the-art deep learning-based methods for single cell macrophage\nclassification and compared them against the performance of nine cytology\nexperts and evaluated inter- and intra-observer variability. Additionally, we\nevaluated object detection methods on a novel data set of 17 completely\nannotated cytology whole slide images (WSI) containing 78,047 hemosiderophages.\nResultsf: Our deep learning-based approach reached a concordance of 0.85,\npartially exceeding human expert concordance (0.68 to 0.86, $\\mu$=0.73,\n$\\sigma$ =0.04). Intra-observer variability was high (0.68 to 0.88) and\ninter-observer concordance was moderate (Fleiss kappa = 0.67). Our object\ndetection approach has a mean average precision of 0.66 over the five classes\nfrom the whole slide gigapixel image and a computation time of below two\nminutes. Conclusion: To mitigate the high inter- and intra-rater variability,\nwe propose our automated object detection pipeline, enabling accurate,\nreproducible and quick EIPH scoring in WSI.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 15:16:30 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Marzahl", "Christian", ""], ["Aubreville", "Marc", ""], ["Bertram", "Christof A.", ""], ["Stayt", "Jason", ""], ["Jasensky", "Anne-Katherine", ""], ["Bartenschlager", "Florian", ""], ["Fragoso-Garcia", "Marco", ""], ["Barton", "Ann K.", ""], ["Elsemann", "Svenja", ""], ["Jabari", "Samir", ""], ["Krauth", "Jens", ""], ["Madhu", "Prathmesh", ""], ["Voigt", "J\u00f6rn", ""], ["Hill", "Jenny", ""], ["Klopfleisch", "Robert", ""], ["Maier", "Andreas", ""]]}, {"id": "1908.04769", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li, Nicha C. Dvornek, Juntang Zhuang, Pamela Ventola, and\n  James Duncan", "title": "Graph Embedding Using Infomax for ASD Classification and Brain\n  Functional Difference Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant progress has been made using fMRI to characterize the brain\nchanges that occur in ASD, a complex neuro-developmental disorder. However, due\nto the high dimensionality and low signal-to-noise ratio of fMRI, embedding\ninformative and robust brain regional fMRI representations for both graph-level\nclassification and region-level functional difference detection tasks between\nASD and healthy control (HC) groups is difficult. Here, we model the whole\nbrain fMRI as a graph, which preserves geometrical and temporal information and\nuse a Graph Neural Network (GNN) to learn from the graph-structured fMRI data.\nWe investigate the potential of including mutual information (MI) loss\n(Infomax), which is an unsupervised term encouraging large MI of each nodal\nrepresentation and its corresponding graph-level summarized representation to\nlearn a better graph embedding. Specifically, this work developed a pipeline\nincluding a GNN encoder, a classifier and a discriminator, which forces the\nencoded nodal representations to both benefit classification and reveal the\ncommon nodal patterns in a graph. We simultaneously optimize graph-level\nclassification loss and Infomax. We demonstrated that Infomax graph embedding\nimproves classification performance as a regularization term. Furthermore, we\nfound separable nodal representations of ASD and HC groups in prefrontal\ncortex, cingulate cortex, visual regions, and other social, emotional and\nexecution related brain regions. In contrast with GNN with classification loss\nonly, the proposed pipeline can facilitate training more robust ASD\nclassification models. Moreover, the separable nodal representations can detect\nthe functional differences between the two groups and contribute to revealing\nnew ASD biomarkers.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 05:25:46 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 00:22:03 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Dvornek", "Nicha C.", ""], ["Zhuang", "Juntang", ""], ["Ventola", "Pamela", ""], ["Duncan", "James", ""]]}, {"id": "1908.04771", "submitter": "Zhaohong Deng", "authors": "Zhaohong Deng, Chen Cui, Peng Xu, Ling Liang, Haoran Chen, Te Zhang,\n  Shitong Wang", "title": "Multi-View Fuzzy Clustering with The Alternative Learning between Shared\n  Hidden Space and Partition", "comments": "This paper has been submitted to IEEE Transactions on Cybnetics in\n  Apr. 8th 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the multi-view data grows in the real world, multi-view clus-tering has\nbecome a prominent technique in data mining, pattern recognition, and machine\nlearning. How to exploit the relation-ship between different views effectively\nusing the characteristic of multi-view data has become a crucial challenge.\nAiming at this, a hidden space sharing multi-view fuzzy clustering (HSS-MVFC)\nmethod is proposed in the present study. This method is based on the classical\nfuzzy c-means clustering model, and obtains associ-ated information between\ndifferent views by introducing shared hidden space. Especially, the shared\nhidden space and the fuzzy partition can be learned alternatively and\ncontribute to each other. Meanwhile, the proposed method uses maximum entropy\nstrategy to control the weights of different views while learning the shared\nhidden space. The experimental result shows that the proposed multi-view\nclustering method has better performance than many related clustering methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 14:44:07 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Deng", "Zhaohong", ""], ["Cui", "Chen", ""], ["Xu", "Peng", ""], ["Liang", "Ling", ""], ["Chen", "Haoran", ""], ["Zhang", "Te", ""], ["Wang", "Shitong", ""]]}, {"id": "1908.04772", "submitter": "Fotis Savva", "authors": "Fotis Savva, Christos Anagnostopoulos, Peter Triantafillou", "title": "Adaptive Learning of Aggregate Analytics under Dynamic Workloads", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9006267", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large organizations have seamlessly incorporated data-driven decision making\nin their operations. However, as data volumes increase, expensive big data\ninfrastructures are called to rescue. In this setting, analytics tasks become\nvery costly in terms of query response time, resource consumption, and money in\ncloud deployments, especially when base data are stored across geographically\ndistributed data centers. Therefore, we introduce an adaptive Machine Learning\nmechanism which is light-weight, stored client-side, can estimate the answers\nof a variety of aggregate queries and can avoid the big data backend. The\nestimations are performed in milliseconds are inexpensive and accurate as the\nmechanism learns from past analytical-query patterns. However, as analytic\nqueries are ad-hoc and analysts' interests change over time we develop\nsolutions that can swiftly and accurately detect such changes and adapt to new\nquery patterns. The capabilities of our approach are demonstrated using\nextensive evaluation with real and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 17:32:39 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 12:01:17 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Savva", "Fotis", ""], ["Anagnostopoulos", "Christos", ""], ["Triantafillou", "Peter", ""]]}, {"id": "1908.04784", "submitter": "Jordan J. Bird", "authors": "Jordan J. Bird, Diego R. Faria, Luis J. Manso, Anik\\'o Ek\\'art,\n  Christopher D. Buckingham", "title": "A Deep Evolutionary Approach to Bioinspired Classifier Optimisation for\n  Brain-Machine Interaction", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": "10.1155/2019/4316548", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study suggests a new approach to EEG data classification by exploring\nthe idea of using evolutionary computation to both select useful discriminative\nEEG features and optimise the topology of Artificial Neural Networks. An\nevolutionary algorithm is applied to select the most informative features from\nan initial set of 2550 EEG statistical features. Optimisation of a Multilayer\nPerceptron (MLP) is performed with an evolutionary approach before\nclassification to estimate the best hyperparameters of the network. Deep\nlearning and tuning with Long Short-Term Memory (LSTM) are also explored, and\nAdaptive Boosting of the two types of models is tested for each problem. Three\nexperiments are provided for comparison using different classifiers: one for\nattention state classification, one for emotional sentiment classification, and\na third experiment in which the goal is to guess the number a subject is\nthinking of. The obtained results show that an Adaptive Boosted LSTM can\nachieve an accuracy of 84.44%, 97.06%, and 9.94% on the attentional, emotional,\nand number datasets, respectively. An evolutionary-optimised MLP achieves\nresults close to the Adaptive Boosted LSTM for the two first experiments and\nsignificantly higher for the number-guessing experiment with an Adaptive\nBoosted DEvo MLP reaching 31.35%, while being significantly quicker to train\nand classify. In particular, the accuracy of the nonboosted DEvo MLP was of\n79.81%, 96.11%, and 27.07% in the same benchmarks. Two datasets for the\nexperiments were gathered using a Muse EEG headband with four electrodes\ncorresponding to TP9, AF7, AF8, and TP10 locations of the international EEG\nplacement standard. The EEG MindBigData digits dataset was gathered from the\nTP9, FP1, FP2, and TP10 locations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:49:30 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Bird", "Jordan J.", ""], ["Faria", "Diego R.", ""], ["Manso", "Luis J.", ""], ["Ek\u00e1rt", "Anik\u00f3", ""], ["Buckingham", "Christopher D.", ""]]}, {"id": "1908.04812", "submitter": "Taesun Whang", "authors": "Taesun Whang, Dongyub Lee, Chanhee Lee, Kisu Yang, Dongsuk Oh,\n  HeuiSeok Lim", "title": "An Effective Domain Adaptive Post-Training Method for BERT in Response\n  Selection", "comments": "INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on multi-turn response selection in a retrieval-based dialog system.\nIn this paper, we utilize the powerful pre-trained language model\nBi-directional Encoder Representations from Transformer (BERT) for a multi-turn\ndialog system and propose a highly effective post-training method on\ndomain-specific corpus. Although BERT is easily adopted to various NLP tasks\nand outperforms previous baselines of each task, it still has limitations if a\ntask corpus is too focused on a certain domain. Post-training on\ndomain-specific corpus (e.g., Ubuntu Corpus) helps the model to train\ncontextualized representations and words that do not appear in general corpus\n(e.g., English Wikipedia). Experimental results show that our approach achieves\nnew state-of-the-art on two response selection benchmarks (i.e., Ubuntu Corpus\nV1, Advising Corpus) performance improvement by 5.9% and 6% on R@1.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 18:24:29 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 02:37:49 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Whang", "Taesun", ""], ["Lee", "Dongyub", ""], ["Lee", "Chanhee", ""], ["Yang", "Kisu", ""], ["Oh", "Dongsuk", ""], ["Lim", "HeuiSeok", ""]]}, {"id": "1908.04839", "submitter": "Freddy Lecue", "authors": "Xochitl Watts and Freddy Lecue", "title": "Local Score Dependent Model Explanation for Time Dependent Covariates", "comments": "Work accepted as full paper for presentation at XAI (Explainable AI)\n  workshop at Twenty-Eighth International Joint Conference on Artificial\n  Intelligence (IJCAI) 2019 in Macao, China - August 10-16, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep neural networks to make high risk decisions creates a need\nfor global and local explanations so that users and experts have confidence in\nthe modeling algorithms. We introduce a novel technique to find global and\nlocal explanations for time series data used in binary classification machine\nlearning systems. We identify the most salient of the original features used by\na black box model to distinguish between classes. The explanation can be made\non categorical, continuous, and time series data and can be generalized to any\nbinary classification model. The analysis is conducted on time series data to\ntrain a long short-term memory deep neural network and uses the time dependent\nstructure of the underlying features in the explanation. The proposed technique\nattributes weights to features to explain an observations risk of belonging to\na class as a multiplicative factor of a base hazard rate. We use a variation of\nthe Cox Proportional Hazards regression, a Generalized Additive Model, to\nexplain the effect of variables upon the probability of an in-class response\nfor a score output from the black box model. The covariates incorporate time\ndependence structure in the features so the explanation is inclusive of the\nunderlying time series data structure.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 19:46:26 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Watts", "Xochitl", ""], ["Lecue", "Freddy", ""]]}, {"id": "1908.04847", "submitter": "Badr-Eddine Ch\\'erief-Abdellatif", "authors": "Badr-Eddine Ch\\'erief-Abdellatif", "title": "Convergence Rates of Variational Inference in Sparse Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference is becoming more and more popular for approximating\nintractable posterior distributions in Bayesian statistics and machine\nlearning. Meanwhile, a few recent works have provided theoretical justification\nand new insights on deep neural networks for estimating smooth functions in\nusual settings such as nonparametric regression. In this paper, we show that\nvariational inference for sparse deep learning retains the same generalization\nproperties than exact Bayesian inference. In particular, we highlight the\nconnection between estimation and approximation theories via the classical\nbias-variance trade-off and show that it leads to near-minimax rates of\nconvergence for H\\\"older smooth functions. Additionally, we show that the model\nselection framework over the neural network architecture via ELBO maximization\ndoes not overfit and adaptively achieves the optimal rate of convergence.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 18:50:09 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 21:27:21 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Ch\u00e9rief-Abdellatif", "Badr-Eddine", ""]]}, {"id": "1908.04849", "submitter": "Abir De", "authors": "Abir De and Soumen Chakrabarti", "title": "Differentially Private Link Prediction With Protected Connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction (LP) algorithms propose to each node a ranked list of nodes\nthat are currently non-neighbors, as the most likely candidates for future\nlinkage. Owing to increasing concerns about privacy, users (nodes) may prefer\nto keep some of their connections protected or private. Motivated by this\nobservation, our goal is to design a differentially private LP algorithm, which\ntrades off between privacy of the protected node-pairs and the link prediction\naccuracy. More specifically, we first propose a form of differential privacy on\ngraphs, which models the privacy loss only of those node-pairs which are marked\nas protected. Next, we develop DPLP , a learning to rank algorithm, which\napplies a monotone transform to base scores from a non-private LP system, and\nthen adds noise. DPLP is trained with a privacy induced ranking loss, which\noptimizes the ranking utility for a given maximum allowed level of privacy\nleakage of the protected node-pairs. Under a recently-introduced latent node\nembedding model, we present a formal trade-off between privacy and LP utility.\nExtensive experiments with several real-life graphs and several LP heuristics\nshow that DPLP can trade off between privacy and predictive performance more\neffectively than several alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 16:06:10 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 09:48:04 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["De", "Abir", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "1908.04851", "submitter": "Sensong An", "authors": "Sensong An, Bowen Zheng, Hong Tang, Mikhail Y. Shalaginov, Li Zhou,\n  Hang Li, Tian Gu, Juejun Hu, Clayton Fowler and Hualiang Zhang", "title": "Multifunctional Metasurface Design with a Generative Adversarial Network", "comments": "30 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metasurfaces have enabled precise electromagnetic wave manipulation with\nstrong potential to obtain unprecedented functionalities and multifunctional\nbehavior in flat optical devices. These advantages in precision and\nfunctionality come at the cost of tremendous difficulty in finding individual\nmeta-atom structures based on specific requirements (commonly formulated in\nterms of electromagnetic responses), which makes the design of multifunctional\nmetasurfaces a key challenge in this field. In this paper, we present a\nGenerative Adversarial Networks (GAN) that can tackle this problem and generate\nmeta-atom/metasurface designs to meet multifunctional design goals. Unlike\nconventional trial-and-error or iterative optimization design methods, this new\nmethodology produces on-demand free-form structures involving only a single\ndesign iteration. More importantly, the network structure and the robust\ntraining process are independent of the complexity of design objectives, making\nthis approach ideal for multifunctional device design. Additionally, the\nability of the network to generate distinct classes of structures with similar\nelectromagnetic responses but different physical features could provide added\nlatitude to accommodate other considerations such as fabrication constraints\nand tolerances. We demonstrate the network's ability to produce a variety of\nmultifunctional metasurface designs by presenting a bifocal metalens, a\npolarization-multiplexed beam deflector, a polarization-multiplexed metalens\nand a polarization-independent metalens.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 20:41:53 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 00:21:17 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["An", "Sensong", ""], ["Zheng", "Bowen", ""], ["Tang", "Hong", ""], ["Shalaginov", "Mikhail Y.", ""], ["Zhou", "Li", ""], ["Li", "Hang", ""], ["Gu", "Tian", ""], ["Hu", "Juejun", ""], ["Fowler", "Clayton", ""], ["Zhang", "Hualiang", ""]]}, {"id": "1908.04858", "submitter": "Zeliang Liu", "authors": "Zeliang Liu", "title": "Deep material network with cohesive layers: Multi-stage training and\n  interfacial failure analysis", "comments": "26 pages, 14 figures, 4 tables", "journal-ref": null, "doi": "10.1016/j.cma.2020.112913", "report-no": null, "categories": "cond-mat.mtrl-sci cs.CE cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental issue in multiscale materials modeling and design is the\nconsideration of traction-separation behavior at the interface. By enriching\nthe deep material network (DMN) with cohesive layers, the paper presents a\nnovel data-driven material model which enables accurate and efficient\nprediction of multiscale responses for heterogeneous materials with interfacial\neffect. In the newly invoked cohesive building block, the fitting parameters\nhave physical meanings related to the length scale and orientation of the\ncohesive layer. It is shown that the enriched material network can be\neffectively optimized via a multi-stage training strategy, with training data\ngenerated only from linear elastic direct numerical simulation (DNS). The\nextrapolation capability of the method to unknown material and loading spaces\nis demonstrated through the debonding analysis of a unidirectional\nfiber-reinforced composite, where the interface behavior is governed by an\nirreversible softening mixed-mode cohesive law. Its predictive accuracy is\nvalidated against the nonlinear path-dependent DNS results, and the reduction\nin computational time is particularly significant.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 22:02:31 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 22:25:40 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Liu", "Zeliang", ""]]}, {"id": "1908.04904", "submitter": "Feng Li", "authors": "Xuening Zhu, Feng Li, Hansheng Wang", "title": "Least Squares Approximation for a Distributed System", "comments": null, "journal-ref": "Journal of Computational and Graphical Statistics 2021", "doi": "10.1080/10618600.2021.1923517", "report-no": null, "categories": "stat.ME cs.DC cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a distributed least squares approximation (DLSA)\nmethod that is able to solve a large family of regression problems (e.g.,\nlinear regression, logistic regression, and Cox's model) on a distributed\nsystem. By approximating the local objective function using a local quadratic\nform, we are able to obtain a combined estimator by taking a weighted average\nof local estimators. The resulting estimator is proved to be statistically as\nefficient as the global estimator. Moreover, it requires only one round of\ncommunication. We further conduct a shrinkage estimation based on the DLSA\nestimation using an adaptive Lasso approach. The solution can be easily\nobtained by using the LARS algorithm on the master node. It is theoretically\nshown that the resulting estimator possesses the oracle property and is\nselection consistent by using a newly designed distributed Bayesian information\ncriterion (DBIC). The finite sample performance and computational efficiency\nare further illustrated by an extensive numerical study and an airline dataset.\nThe airline dataset is 52 GB in size. The entire methodology has been\nimplemented in Python for a {\\it de-facto} standard Spark system. The proposed\nDLSA algorithm on the Spark system takes 26 minutes to obtain a logistic\nregression estimator, which is more efficient and memory friendly than\nconventional methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:05:21 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 01:46:47 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 07:11:52 GMT"}, {"version": "v4", "created": "Tue, 13 Apr 2021 09:53:50 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhu", "Xuening", ""], ["Li", "Feng", ""], ["Wang", "Hansheng", ""]]}, {"id": "1908.04909", "submitter": "Yan Xu", "authors": "Steven Gardner, Oleg Golovidov, Joshua Griffin, Patrick Koch, Wayne\n  Thompson, Brett Wujek and Yan Xu", "title": "Constrained Multi-Objective Optimization for Automated Machine Learning", "comments": "10 pages, 8 figures, accepted at DSAA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning has gained a lot of attention recently. Building\nand selecting the right machine learning models is often a multi-objective\noptimization problem. General purpose machine learning software that\nsimultaneously supports multiple objectives and constraints is scant, though\nthe potential benefits are great. In this work, we present a framework called\nAutotune that effectively handles multiple objectives and constraints that\narise in machine learning problems. Autotune is built on a suite of\nderivative-free optimization methods, and utilizes multi-level parallelism in a\ndistributed computing environment for automatically training, scoring, and\nselecting good models. Incorporation of multiple objectives and constraints in\nthe model exploration and selection process provides the flexibility needed to\nsatisfy trade-offs necessary in practical machine learning applications.\nExperimental results from standard multi-objective optimization benchmark\nproblems show that Autotune is very efficient in capturing Pareto fronts. These\nbenchmark results also show how adding constraints can guide the search to more\npromising regions of the solution space, ultimately producing more desirable\nPareto fronts. Results from two real-world case studies demonstrate the\neffectiveness of the constrained multi-objective optimization capability\noffered by Autotune.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:31:45 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Gardner", "Steven", ""], ["Golovidov", "Oleg", ""], ["Griffin", "Joshua", ""], ["Koch", "Patrick", ""], ["Thompson", "Wayne", ""], ["Wujek", "Brett", ""], ["Xu", "Yan", ""]]}, {"id": "1908.04913", "submitter": "Jungseock Joo", "authors": "Kimmo K\\\"arkk\\\"ainen, Jungseock Joo", "title": "FairFace: Face Attribute Dataset for Balanced Race, Gender, and Age", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing public face datasets are strongly biased toward Caucasian faces, and\nother races (e.g., Latino) are significantly underrepresented. This can lead to\ninconsistent model accuracy, limit the applicability of face analytic systems\nto non-White race groups, and adversely affect research findings based on such\nskewed data. To mitigate the race bias in these datasets, we construct a novel\nface image dataset, containing 108,501 images, with an emphasis of balanced\nrace composition in the dataset. We define 7 race groups: White, Black, Indian,\nEast Asian, Southeast Asian, Middle East, and Latino. Images were collected\nfrom the YFCC-100M Flickr dataset and labeled with race, gender, and age\ngroups. Evaluations were performed on existing face attribute datasets as well\nas novel image datasets to measure generalization performance. We find that the\nmodel trained from our dataset is substantially more accurate on novel datasets\nand the accuracy is consistent between race and gender groups.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:42:41 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["K\u00e4rkk\u00e4inen", "Kimmo", ""], ["Joo", "Jungseock", ""]]}, {"id": "1908.04920", "submitter": "Shaowei Wang", "authors": "Shaowei Wang, Jiachun Du, Wei Yang, Xinrong Diao, Zichun Liu, Yiwen\n  Nie, Liusheng Huang, Hongli Xu", "title": "Aggregating Votes with Local Differential Privacy: Usefulness, Soundness\n  vs. Indistinguishability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voting plays a central role in bringing crowd wisdom to collective decision\nmaking, meanwhile data privacy has been a common ethical/legal issue in\neliciting preferences from individuals. This work studies the problem of\naggregating individual's voting data under the local differential privacy\nsetting, where usefulness and soundness of the aggregated scores are of major\nconcern. One naive approach to the problem is adding Laplace random noises,\nhowever, it makes aggregated scores extremely fragile to new types of strategic\nbehaviors tailored to the local privacy setting: data amplification attack and\nview disguise attack. The data amplification attack means an attacker's\nmanipulation power is amplified by the privacy-preserving procedure when\ncontributing a fraud vote. The view disguise attack happens when an attacker\ncould disguise malicious data as valid private views to manipulate the voting\nresult.\n  In this work, after theoretically quantifying the estimation error bound and\nthe manipulating risk bound of the Laplace mechanism, we propose two mechanisms\nimproving the usefulness and soundness simultaneously: the weighted sampling\nmechanism and the additive mechanism. The former one interprets the score\nvector as probabilistic data. Compared to the Laplace mechanism for Borda\nvoting rule with $d$ candidates, it reduces the mean squared error bound by\nhalf and lowers the maximum magnitude risk bound from $+\\infty$ to\n$O(\\frac{d^3}{n\\epsilon})$. The latter one randomly outputs a subset of\ncandidates according to their total scores. Its mean squared error bound is\noptimized from $O(\\frac{d^5}{n\\epsilon^2})$ to $O(\\frac{d^4}{n\\epsilon^2})$,\nand its maximum magnitude risk bound is reduced to $O(\\frac{d^2}{n\\epsilon})$.\nExperimental results validate that our proposed approaches averagely reduce\nestimation error by $50\\%$ and are more robust to adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:53:48 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Wang", "Shaowei", ""], ["Du", "Jiachun", ""], ["Yang", "Wei", ""], ["Diao", "Xinrong", ""], ["Liu", "Zichun", ""], ["Nie", "Yiwen", ""], ["Huang", "Liusheng", ""], ["Xu", "Hongli", ""]]}, {"id": "1908.04924", "submitter": "Mingyuan Bai", "authors": "Mingyuan Bai, S.T. Boris Choy, Xin Song, Junbin Gao", "title": "Tensor-Train Parameterization for Ultra Dimensionality Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locality preserving projections (LPP) are a classical dimensionality\nreduction method based on data graph information. However, LPP is still\nresponsive to extreme outliers. LPP aiming for vectorial data may undermine\ndata structural information when it is applied to multidimensional data.\nBesides, it assumes the dimension of data to be smaller than the number of\ninstances, which is not suitable for high-dimensional data. For\nhigh-dimensional data analysis, the tensor-train decomposition is proved to be\nable to efficiently and effectively capture the spatial relations. Thus, we\npropose a tensor-train parameterization for ultra dimensionality reduction\n(TTPUDR) in which the traditional LPP mapping is tensorized in terms of\ntensor-trains and the LPP objective is replaced with the Frobenius norm to\nincrease the robustness of the model. The manifold optimization technique is\nutilized to solve the new model. The performance of TTPUDR is assessed on\nclassification problems and TTPUDR significantly outperforms the past methods\nand the several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 02:04:34 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Bai", "Mingyuan", ""], ["Choy", "S. T. Boris", ""], ["Song", "Xin", ""], ["Gao", "Junbin", ""]]}, {"id": "1908.04950", "submitter": "C\\u{a}t\\u{a}lina Cangea", "authors": "C\\u{a}t\\u{a}lina Cangea, Eugene Belilovsky, Pietro Li\\`o, Aaron\n  Courville", "title": "VideoNavQA: Bridging the Gap between Visual and Embodied Question\n  Answering", "comments": "To appear at BMVC 2019. 15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embodied Question Answering (EQA) is a recently proposed task, where an agent\nis placed in a rich 3D environment and must act based solely on its egocentric\ninput to answer a given question. The desired outcome is that the agent learns\nto combine capabilities such as scene understanding, navigation and language\nunderstanding in order to perform complex reasoning in the visual world.\nHowever, initial advancements combining standard vision and language methods\nwith imitation and reinforcement learning algorithms have shown EQA might be\ntoo complex and challenging for these techniques. In order to investigate the\nfeasibility of EQA-type tasks, we build the VideoNavQA dataset that contains\npairs of questions and videos generated in the House3D environment. The goal of\nthis dataset is to assess question-answering performance from nearly-ideal\nnavigation paths, while considering a much more complete variety of questions\nthan current instantiations of the EQA task. We investigate several models,\nadapted from popular VQA methods, on this new benchmark. This establishes an\ninitial understanding of how well VQA-style methods can perform within this\nnovel EQA paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 04:44:26 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Cangea", "C\u0103t\u0103lina", ""], ["Belilovsky", "Eugene", ""], ["Li\u00f2", "Pietro", ""], ["Courville", "Aaron", ""]]}, {"id": "1908.04955", "submitter": "Joseph Campbell", "authors": "Joseph Campbell, Simon Stepputtis, Heni Ben Amor", "title": "Probabilistic Multimodal Modeling for Human-Robot Interaction Tasks", "comments": "Project website:\n  http://interactive-robotics.engineering.asu.edu/interaction-primitives\n  Accompanying video: https://youtu.be/r5AqfxTDfLA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-robot interaction benefits greatly from multimodal sensor inputs as\nthey enable increased robustness and generalization accuracy. Despite this\nobservation, few HRI methods are capable of efficiently performing inference\nfor multimodal systems. In this work, we introduce a reformulation of\nInteraction Primitives which allows for learning from demonstration of\ninteraction tasks, while also gracefully handling nonlinearities inherent to\nmultimodal inference in such scenarios. We also empirically show that our\nmethod results in more accurate, more robust, and faster inference than\nstandard Interaction Primitives and other common methods in challenging HRI\nscenarios.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 04:58:20 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Campbell", "Joseph", ""], ["Stepputtis", "Simon", ""], ["Amor", "Heni Ben", ""]]}, {"id": "1908.04964", "submitter": "Anbang Yao", "authors": "Jiahui Zhang, Dawei Sun, Zixin Luo, Anbang Yao, Lei Zhou, Tianwei\n  Shen, Yurong Chen, Long Quan, Hongen Liao", "title": "Learning Two-View Correspondences and Geometry Using Order-Aware Network", "comments": "Accepted to ICCV 2019, and Winner solution to both tracks of CVPR IMW\n  2019 Challenge. Code will be available soon at\n  https://github.com/zjhthu/OANet.git", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing correspondences between two images requires both local and\nglobal spatial context. Given putative correspondences of feature points in two\nviews, in this paper, we propose Order-Aware Network, which infers the\nprobabilities of correspondences being inliers and regresses the relative pose\nencoded by the essential matrix. Specifically, this proposed network is built\nhierarchically and comprises three novel operations. First, to capture the\nlocal context of sparse correspondences, the network clusters unordered input\ncorrespondences by learning a soft assignment matrix. These clusters are in a\ncanonical order and invariant to input permutations. Next, the clusters are\nspatially correlated to form the global context of correspondences. After that,\nthe context-encoded clusters are recovered back to the original size through a\nproposed upsampling operator. We intensively experiment on both outdoor and\nindoor datasets. The accuracy of the two-view geometry and correspondences are\nsignificantly improved over the state-of-the-arts. Code will be available at\nhttps://github.com/zjhthu/OANet.git.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 05:42:18 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Zhang", "Jiahui", ""], ["Sun", "Dawei", ""], ["Luo", "Zixin", ""], ["Yao", "Anbang", ""], ["Zhou", "Lei", ""], ["Shen", "Tianwei", ""], ["Chen", "Yurong", ""], ["Quan", "Long", ""], ["Liao", "Hongen", ""]]}, {"id": "1908.04970", "submitter": "My Phan", "authors": "My Phan, Yasin Abbasi-Yadkori, Justin Domke", "title": "Thompson Sampling with Approximate Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effects of approximate inference on the performance of Thompson\nsampling in the $k$-armed bandit problems. Thompson sampling is a successful\nalgorithm for online decision-making but requires posterior inference, which\noften must be approximated in practice. We show that even small constant\ninference error (in $\\alpha$-divergence) can lead to poor performance (linear\nregret) due to under-exploration (for $\\alpha<1$) or over-exploration (for\n$\\alpha>0$) by the approximation. While for $\\alpha > 0$ this is unavoidable,\nfor $\\alpha \\leq 0$ the regret can be improved by adding a small amount of\nforced exploration even when the inference error is a large constant.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 06:09:15 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 02:56:12 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Phan", "My", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Domke", "Justin", ""]]}, {"id": "1908.04976", "submitter": "Sanjay Subramanian", "authors": "Barna Saha and Sanjay Subramanian", "title": "Correlation Clustering with Same-Cluster Queries Bounded by Optimal Cost", "comments": "ESA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several clustering frameworks with interactive (semi-supervised) queries have\nbeen studied in the past. Recently, clustering with same-cluster queries has\nbecome popular. An algorithm in this setting has access to an oracle with full\nknowledge of an optimal clustering, and the algorithm can ask the oracle\nqueries of the form, \"Does the optimal clustering put vertices $ u $ and $ v $\nin the same cluster?\" Due to its simplicity, this querying model can easily be\nimplemented in real crowd-sourcing platforms and has attracted a lot of recent\nwork. In this paper, we study the popular correlation clustering problem\n(Bansal et al., 2002) under this framework. Given a complete graph $G=(V,E)$\nwith positive and negative edge labels, correlation clustering objective aims\nto compute a graph clustering that minimizes the total number of disagreements,\nthat is the negative intra-cluster edges and positive inter-cluster edges. Let\n$ C_{OPT} $ be the number of disagreements made by the optimal clustering. We\npresent algorithms for correlation clustering whose error and query bounds are\nparameterized by $C_{OPT}$ rather than by the number of clusters. Indeed, a\ngood clustering must have small $C_{OPT}$. Specifically, we present an\nefficient algorithm that recovers an exact optimal clustering using at most\n$2C_{OPT} $ queries and an efficient algorithm that outputs a $2$-approximation\nusing at most $C_{OPT} $ queries. In addition, we show under a plausible\ncomplexity assumption, there does not exist any polynomial time algorithm that\nhas an approximation ratio better than $1+\\alpha$ for an absolute constant\n$\\alpha >0$ with $o(C_{OPT})$ queries. We extensively evaluate our methods on\nseveral synthetic and real-world datasets using real crowd-sourced oracles.\nMoreover, we compare our approach against several known correlation clustering\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 06:26:15 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Saha", "Barna", ""], ["Subramanian", "Sanjay", ""]]}, {"id": "1908.04979", "submitter": "Guoli Song", "authors": "Guoli Song, Shuhui Wang, Qingming Huang, Qi Tian", "title": "Harmonized Multimodal Learning with Gaussian Process Latent Variable\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal learning aims to discover the relationship between multiple\nmodalities. It has become an important research topic due to extensive\nmultimodal applications such as cross-modal retrieval. This paper attempts to\naddress the modality heterogeneity problem based on Gaussian process latent\nvariable models (GPLVMs) to represent multimodal data in a common space.\nPrevious multimodal GPLVM extensions generally adopt individual learning\nschemes on latent representations and kernel hyperparameters, which ignore\ntheir intrinsic relationship. To exploit strong complementarity among different\nmodalities and GPLVM components, we develop a novel learning scheme called\nHarmonization, where latent model parameters are jointly learned from each\nother. Beyond the correlation fitting or intra-modal structure preservation\nparadigms widely used in existing studies, the harmonization is derived in a\nmodel-driven manner to encourage the agreement between modality-specific GP\nkernels and the similarity of latent representations. We present a range of\nmultimodal learning models by incorporating the harmonization mechanism into\nseveral representative GPLVM-based approaches. Experimental results on four\nbenchmark datasets show that the proposed models outperform the strong\nbaselines for cross-modal retrieval tasks, and that the harmonized multimodal\nlearning method is superior in discovering semantically consistent latent\nrepresentation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 06:40:28 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Song", "Guoli", ""], ["Wang", "Shuhui", ""], ["Huang", "Qingming", ""], ["Tian", "Qi", ""]]}, {"id": "1908.04992", "submitter": "Suichan Li", "authors": "Suichan Li, Dapeng Chen, Bin Liu, Nenghai Yu, Rui Zhao", "title": "Memory-Based Neighbourhood Embedding for Visual Recognition", "comments": "Accepted by ICCV2019 for oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning discriminative image feature embeddings is of great importance to\nvisual recognition. To achieve better feature embeddings, most current methods\nfocus on designing different network structures or loss functions, and the\nestimated feature embeddings are usually only related to the input images. In\nthis paper, we propose Memory-based Neighbourhood Embedding (MNE) to enhance a\ngeneral CNN feature by considering its neighbourhood. The method aims to solve\ntwo critical problems, i.e., how to acquire more relevant neighbours in the\nnetwork training and how to aggregate the neighbourhood information for a more\ndiscriminative embedding. We first augment an episodic memory module into the\nnetwork, which can provide more relevant neighbours for both training and\ntesting. Then the neighbours are organized in a tree graph with the target\ninstance as the root node. The neighbourhood information is gradually\naggregated to the root node in a bottom-up manner, and aggregation weights are\nsupervised by the class relationships between the nodes. We apply MNE on image\nsearch and few shot learning tasks. Extensive ablation studies demonstrate the\neffectiveness of each component, and our method significantly outperforms the\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 07:19:12 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Li", "Suichan", ""], ["Chen", "Dapeng", ""], ["Liu", "Bin", ""], ["Yu", "Nenghai", ""], ["Zhao", "Rui", ""]]}, {"id": "1908.04998", "submitter": "Kai Chen", "authors": "Kai Chen and Zhongrui Lin and Jian Wan and Chungen Xu", "title": "Interpretable Encrypted Searchable Neural Networks", "comments": "The Second International Conference on Machine Learning for Cyber\n  Security (ML4CS 2019). Keyword: Searchable Encryption; Searchable Neural\n  Networks; Probabilistic Learning; Adversarial Learning; Automatic Weight\n  Update", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud security, traditional searchable encryption (SE) requires high\ncomputation and communication overhead for dynamic search and update. The\nclever combination of machine learning (ML) and SE may be a new way to solve\nthis problem. This paper proposes interpretable encrypted searchable neural\nnetworks (IESNN) to explore probabilistic query, balanced index tree\nconstruction and automatic weight update in an encrypted cloud environment. In\nIESNN, probabilistic learning is used to obtain search ranking for searchable\nindex, and probabilistic query is performed based on ciphertext index, which\nreduces the computational complexity of query significantly. Compared to\ntraditional SE, it is proposed that adversarial learning and automatic weight\nupdate in response to user's timely query of the latest data set without\nexpensive communication overhead. The proposed IESNN performs better than the\nprevious works, bringing the query complexity closer to $O(\\log N)$ and\nintroducing low overhead on computation and communication.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 07:37:03 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Chen", "Kai", ""], ["Lin", "Zhongrui", ""], ["Wan", "Jian", ""], ["Xu", "Chungen", ""]]}, {"id": "1908.05006", "submitter": "Jake Lee", "authors": "Jake H. Lee, Kiri L. Wagstaff", "title": "Visualizing Image Content to Explain Novel Image Discovery", "comments": "Under Review", "journal-ref": null, "doi": "10.1007/s10618-020-00700-0", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The initial analysis of any large data set can be divided into two phases:\n(1) the identification of common trends or patterns and (2) the identification\nof anomalies or outliers that deviate from those trends. We focus on the goal\nof detecting observations with novel content, which can alert us to artifacts\nin the data set or, potentially, the discovery of previously unknown phenomena.\nTo aid in interpreting and diagnosing the novel aspect of these selected\nobservations, we recommend the use of novelty detection methods that generate\nexplanations. In the context of large image data sets, these explanations\nshould highlight what aspect of a given image is new (color, shape, texture,\ncontent) in a human-comprehensible form. We propose DEMUD-VIS, the first method\nfor providing visual explanations of novel image content by employing a\nconvolutional neural network (CNN) to extract image features, a method that\nuses reconstruction error to detect novel content, and an up-convolutional\nnetwork to convert CNN feature representations back into image space. We\ndemonstrate this approach on diverse images from ImageNet, freshwater streams,\nand the surface of Mars.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 07:53:05 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Lee", "Jake H.", ""], ["Wagstaff", "Kiri L.", ""]]}, {"id": "1908.05033", "submitter": "Ruihao Gong", "authors": "Ruihao Gong, Xianglong Liu, Shenghu Jiang, Tianxiang Li, Peng Hu,\n  Jiazhen Lin, Fengwei Yu, Junjie Yan", "title": "Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit\n  Neural Networks", "comments": "IEEE ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware-friendly network quantization (e.g., binary/uniform quantization)\ncan efficiently accelerate the inference and meanwhile reduce memory\nconsumption of the deep neural networks, which is crucial for model deployment\non resource-limited devices like mobile phones. However, due to the\ndiscreteness of low-bit quantization, existing quantization methods often face\nthe unstable training process and severe performance degradation. To address\nthis problem, in this paper we propose Differentiable Soft Quantization (DSQ)\nto bridge the gap between the full-precision and low-bit networks. DSQ can\nautomatically evolve during training to gradually approximate the standard\nquantization. Owing to its differentiable property, DSQ can help pursue the\naccurate gradients in backward propagation, and reduce the quantization loss in\nforward process with an appropriate clipping range. Extensive experiments over\nseveral popular network structures show that training low-bit neural networks\nwith DSQ can consistently outperform state-of-the-art quantization methods.\nBesides, our first efficient implementation for deploying 2 to 4-bit DSQ on\ndevices with ARM architecture achieves up to 1.7$\\times$ speed up, compared\nwith the open-source 8-bit high-performance inference framework NCNN. [31]\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 09:22:41 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Gong", "Ruihao", ""], ["Liu", "Xianglong", ""], ["Jiang", "Shenghu", ""], ["Li", "Tianxiang", ""], ["Hu", "Peng", ""], ["Lin", "Jiazhen", ""], ["Yu", "Fengwei", ""], ["Yan", "Junjie", ""]]}, {"id": "1908.05054", "submitter": "Chris Alberti", "authors": "Chris Alberti, Jeffrey Ling, Michael Collins, David Reitter", "title": "Fusion of Detected Objects in Text for Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To advance models of multimodal context, we introduce a simple yet powerful\nneural architecture for data that combines vision and natural language. The\n\"Bounding Boxes in Text Transformer\" (B2T2) also leverages referential\ninformation binding words to portions of the image in a single unified\narchitecture. B2T2 is highly effective on the Visual Commonsense Reasoning\nbenchmark (https://visualcommonsense.com), achieving a new state-of-the-art\nwith a 25% relative reduction in error rate compared to published baselines and\nobtaining the best performance to date on the public leaderboard (as of May 22,\n2019). A detailed ablation analysis shows that the early integration of the\nvisual features into the text analysis is key to the effectiveness of the new\narchitecture. A reference implementation of our models is provided\n(https://github.com/google-research/language/tree/master/language/question_answering/b2t2).\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 10:03:12 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 05:04:09 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Alberti", "Chris", ""], ["Ling", "Jeffrey", ""], ["Collins", "Michael", ""], ["Reitter", "David", ""]]}, {"id": "1908.05081", "submitter": "Ke Sun", "authors": "Ke Sun, Zhanxing Zhu, Zhouchen Lin", "title": "AdaGCN: Adaboosting Graph Convolutional Networks into Deep Models", "comments": "Published on International Conference on Learning Representations\n  (ICLR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of deep graph models still remains to be investigated and the\ncrucial part is how to explore and exploit the knowledge from different hops of\nneighbors in an efficient way. In this paper, we propose a novel RNN-like deep\ngraph neural network architecture by incorporating AdaBoost into the\ncomputation of network; and the proposed graph convolutional network called\nAdaGCN~(Adaboosting Graph Convolutional Network) has the ability to efficiently\nextract knowledge from high-order neighbors of current nodes and then\nintegrates knowledge from different hops of neighbors into the network in an\nAdaboost way. Different from other graph neural networks that directly stack\nmany graph convolution layers, AdaGCN shares the same base neural network\narchitecture among all ``layers'' and is recursively optimized, which is\nsimilar to an RNN. Besides, We also theoretically established the connection\nbetween AdaGCN and existing graph convolutional methods, presenting the\nbenefits of our proposal. Finally, extensive experiments demonstrate the\nconsistent state-of-the-art prediction performance on graphs across different\nlabel rates and the computational advantage of our approach\nAdaGCN~\\footnote{Code is available at \\url{https://github.com/datake/AdaGCN}.}\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 11:41:09 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 08:08:04 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 10:19:52 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Sun", "Ke", ""], ["Zhu", "Zhanxing", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1908.05085", "submitter": "Grigorios G. Anagnostopoulos Dr.", "authors": "Grigorios G. Anagnostopoulos, Alexandros Kalousis", "title": "A Reproducible Comparison of RSSI Fingerprinting Localization Methods\n  Using LoRaWAN", "comments": null, "journal-ref": null, "doi": "10.1109/WPNC47567.2019.8970177", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of fingerprinting localization techniques in outdoor IoT settings has\nstarted to gain popularity over the recent years. Communication signals of Low\nPower Wide Area Networks (LPWAN), such as LoRaWAN, are used to estimate the\nlocation of low power mobile devices. In this study, a publicly available\ndataset of LoRaWAN RSSI measurements is utilized to compare different machine\nlearning methods and their accuracy in producing location estimates. The tested\nmethods are: the k Nearest Neighbours method, the Extra Trees method and a\nneural network approach using a Multilayer Perceptron. To facilitate the\nreproducibility of tests and the comparability of results, the code and the\ntrain/validation/test split of the dataset used in this study have become\navailable. The neural network approach was the method with the highest\naccuracy, achieving a mean error of 358 meters and a median error of 204\nmeters.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 11:59:08 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Anagnostopoulos", "Grigorios G.", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1908.05103", "submitter": "Lucas May Petry", "authors": "Lucas May Petry, Amilcar Soares, Vania Bogorny, Stan Matwin", "title": "Unsupervised Behavior Change Detection in Multidimensional Data Streams\n  for Maritime Traffic Monitoring", "comments": "Extended abstract submitted to the 2019 Montreal Artificial\n  Intelligence Symposium (MAIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The worldwide growth of maritime traffic and the development of the Automatic\nIdentification System (AIS) has led to advances in monitoring systems for\npreventing vessel accidents and detecting illegal activities. In this work, we\ndescribe research gaps and challenges in machine learning for vessel behavior\nchange and event detection, considering several constraints imposed by\nreal-time data streams and the maritime monitoring domain. As a starting point,\nwe investigate how unsupervised and semi-supervised change detection methods\nmay be employed for identifying shifts in vessel behavior, aiming to detect and\nlabel unusual events.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 12:53:20 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Petry", "Lucas May", ""], ["Soares", "Amilcar", ""], ["Bogorny", "Vania", ""], ["Matwin", "Stan", ""]]}, {"id": "1908.05138", "submitter": "Yifu Chen", "authors": "Yifu Chen, Zongsheng Wang, Bowen Wu, Mengyuan Li, Huan Zhang, Lin Ma,\n  Feng Liu, Qihang Feng, Baoxun Wang", "title": "MemeFaceGenerator: Adversarial Synthesis of Chinese Meme-face from\n  Natural Sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese meme-face is a special kind of internet subculture widely spread in\nChinese Social Community Networks. It usually consists of a template image\nmodified by some amusing details and a text caption. In this paper, we present\nMemeFaceGenerator, a Generative Adversarial Network with the attention module\nand template information as supplementary signals, to automatically generate\nmeme-faces from text inputs. We also develop a web service as system\ndemonstration of meme-face synthesis. MemeFaceGenerator has been shown to be\ncapable of generating high-quality meme-faces from random text inputs.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:15:24 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Chen", "Yifu", ""], ["Wang", "Zongsheng", ""], ["Wu", "Bowen", ""], ["Li", "Mengyuan", ""], ["Zhang", "Huan", ""], ["Ma", "Lin", ""], ["Liu", "Feng", ""], ["Feng", "Qihang", ""], ["Wang", "Baoxun", ""]]}, {"id": "1908.05161", "submitter": "Oren Barkan", "authors": "Oren Barkan, Noam Razin, Itzik Malkiel, Ori Katz, Avi Caciularu, Noam\n  Koenigstein", "title": "Scalable Attentive Sentence-Pair Modeling via Distilled Sentence\n  Embedding", "comments": "In Proceedings of AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art natural language understanding models, such as BERT\nand XLNet, score a pair of sentences (A and B) using multiple cross-attention\noperations - a process in which each word in sentence A attends to all words in\nsentence B and vice versa. As a result, computing the similarity between a\nquery sentence and a set of candidate sentences, requires the propagation of\nall query-candidate sentence-pairs throughout a stack of cross-attention\nlayers. This exhaustive process becomes computationally prohibitive when the\nnumber of candidate sentences is large. In contrast, sentence embedding\ntechniques learn a sentence-to-vector mapping and compute the similarity\nbetween the sentence vectors via simple elementary operations. In this paper,\nwe introduce Distilled Sentence Embedding (DSE) - a model that is based on\nknowledge distillation from cross-attentive models, focusing on sentence-pair\ntasks. The outline of DSE is as follows: Given a cross-attentive teacher model\n(e.g. a fine-tuned BERT), we train a sentence embedding based student model to\nreconstruct the sentence-pair scores obtained by the teacher model. We\nempirically demonstrate the effectiveness of DSE on five GLUE sentence-pair\ntasks. DSE significantly outperforms several ELMO variants and other sentence\nembedding methods, while accelerating computation of the query-candidate\nsentence-pairs similarities by several orders of magnitude, with an average\nrelative degradation of 4.6% compared to BERT. Furthermore, we show that DSE\nproduces sentence embeddings that reach state-of-the-art performance on\nuniversal sentence representation benchmarks. Our code is made publicly\navailable at https://github.com/microsoft/Distilled-Sentence-Embedding.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 15:06:48 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 17:57:57 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 06:38:18 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Barkan", "Oren", ""], ["Razin", "Noam", ""], ["Malkiel", "Itzik", ""], ["Katz", "Ori", ""], ["Caciularu", "Avi", ""], ["Koenigstein", "Noam", ""]]}, {"id": "1908.05164", "submitter": "Antoine Wehenkel", "authors": "Antoine Wehenkel and Gilles Louppe", "title": "Unconstrained Monotonic Neural Networks", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotonic neural networks have recently been proposed as a way to define\ninvertible transformations. These transformations can be combined into powerful\nautoregressive flows that have been shown to be universal approximators of\ncontinuous probability distributions. Architectures that ensure monotonicity\ntypically enforce constraints on weights and activation functions, which\nenables invertibility but leads to a cap on the expressiveness of the resulting\ntransformations. In this work, we propose the Unconstrained Monotonic Neural\nNetwork (UMNN) architecture based on the insight that a function is monotonic\nas long as its derivative is strictly positive. In particular, this latter\ncondition can be enforced with a free-form neural network whose only constraint\nis the positiveness of its output. We evaluate our new invertible building\nblock within a new autoregressive flow (UMNN-MAF) and demonstrate its\neffectiveness on density estimation experiments. We also illustrate the ability\nof UMNNs to improve variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 15:11:31 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 14:25:18 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 10:01:36 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Wehenkel", "Antoine", ""], ["Louppe", "Gilles", ""]]}, {"id": "1908.05168", "submitter": "Pablo Navarrete Michelini", "authors": "Pablo Navarrete Michelini, Hanwen Liu, Yunhua Lu, Xingqun Jiang", "title": "A Tour of Convolutional Networks Guided by Linear Interpreters", "comments": "To appear in ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NA eess.IV math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional networks are large linear systems divided into layers and\nconnected by non-linear units. These units are the \"articulations\" that allow\nthe network to adapt to the input. To understand how a network manages to solve\na problem we must look at the articulated decisions in entirety. If we could\ncapture the actions of non-linear units for a particular input, we would be\nable to replay the whole system back and forth as if it was always linear. It\nwould also reveal the actions of non-linearities because the resulting linear\nsystem, a Linear Interpreter, depends on the input image. We introduce a\nhooking layer, called a LinearScope, which allows us to run the network and the\nlinear interpreter in parallel. Its implementation is simple, flexible and\nefficient. From here we can make many curious inquiries: how do these linear\nsystems look like? When the rows and columns of the transformation matrix are\nimages, how do they look like? What type of basis do these linear\ntransformations rely on? The answers depend on the problems presented, through\nwhich we take a tour to some popular architectures used for classification,\nsuper-resolution (SR) and image-to-image translation (I2I). For classification\nwe observe that popular networks use a pixel-wise vote per class strategy and\nheavily rely on bias parameters. For SR and I2I we find that CNNs use\nwavelet-type basis similar to the human visual system. For I2I we reveal\ncopy-move and template-creation strategies to generate outputs.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 15:18:45 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Michelini", "Pablo Navarrete", ""], ["Liu", "Hanwen", ""], ["Lu", "Yunhua", ""], ["Jiang", "Xingqun", ""]]}, {"id": "1908.05182", "submitter": "Clement S. J. Doire", "authors": "Clement S. J. Doire and Olumide Okubadejo", "title": "Interleaved Multitask Learning for Audio Source Separation with\n  Independent Databases", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network-based source separation methods usually train independent\nmodels to optimize for the separation of individual sources. Although this can\nlead to good performance for well-defined targets, it can also be\ncomputationally expensive. The multitask alternative of a single network\njointly optimizing for all targets simultaneously usually requires the\navailability of all target sources for each input. This requirement hampers the\nability to create large training databases. In this paper, we present a model\nthat decomposes the learnable parameters into a shared parametric model\n(encoder) and independent components (decoders) specific to each source. We\npropose an interleaved training procedure that optimizes the sub-task decoders\nindependently and thus does not require each sample to possess a ground truth\nfor all of its composing sources. Experimental results on MUSDB18 with the\nproposed method show comparable performance to independently trained models,\nwith less trainable parameters, more efficient inference, and an encoder\ntransferable to future target objectives. The results also show that using the\nproposed interleaved training procedure leads to better Source-to-Interference\nenergy ratios when compared to the simultaneous optimization of all training\nobjectives, even when all composing sources are available.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 15:56:34 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Doire", "Clement S. J.", ""], ["Okubadejo", "Olumide", ""]]}, {"id": "1908.05185", "submitter": "Jiangfan Han", "authors": "Jiangfan Han, Xiaoyi Dong, Ruimao Zhang, Dongdong Chen, Weiming Zhang,\n  Nenghai Yu, Ping Luo, Xiaogang Wang", "title": "Once a MAN: Towards Multi-Target Attack via Learning Multi-Target\n  Adversarial Network Once", "comments": "Accepted by ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural networks are often vulnerable to adversarial samples.\nBased on the first optimization-based attacking method, many following methods\nare proposed to improve the attacking performance and speed. Recently,\ngeneration-based methods have received much attention since they directly use\nfeed-forward networks to generate the adversarial samples, which avoid the\ntime-consuming iterative attacking procedure in optimization-based and\ngradient-based methods. However, current generation-based methods are only able\nto attack one specific target (category) within one model, thus making them not\napplicable to real classification systems that often have hundreds/thousands of\ncategories. In this paper, we propose the first Multi-target Adversarial\nNetwork (MAN), which can generate multi-target adversarial samples with a\nsingle model. By incorporating the specified category information into the\nintermediate features, it can attack any category of the target classification\nmodel during runtime. Experiments show that the proposed MAN can produce\nstronger attack results and also have better transferability than previous\nstate-of-the-art methods in both multi-target attack task and single-target\nattack task. We further use the adversarial samples generated by our MAN to\nimprove the robustness of the classification model. It can also achieve better\nclassification accuracy than other methods when attacked by various methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 15:59:21 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Han", "Jiangfan", ""], ["Dong", "Xiaoyi", ""], ["Zhang", "Ruimao", ""], ["Chen", "Dongdong", ""], ["Zhang", "Weiming", ""], ["Yu", "Nenghai", ""], ["Luo", "Ping", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1908.05192", "submitter": "Siobhan Grayson", "authors": "Siobhan Grayson and Derek Greene", "title": "Temporal Analysis of Reddit Networks via Role Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Inspired by diachronic word analysis from the field of natural language\nprocessing, we propose an approach for uncovering temporal insights regarding\nuser roles from social networks using graph embedding methods. Specifically, we\napply the role embedding algorithm, struc2vec, to a collection of social\nnetworks exhibiting either \"loyal\" or \"vagrant\" characteristics derived from\nthe popular online social news aggregation website Reddit. For each subreddit,\nwe extract nine months of data and create network role embeddings on\nconsecutive time windows. We are then able to compare and contrast how user\nroles change over time by aligning the resulting temporal embeddings spaces. In\nparticular, we analyse temporal role embeddings from an individual and a\ncommunity-level perspective for both loyal and vagrant communities present on\nReddit.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 16:09:41 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Grayson", "Siobhan", ""], ["Greene", "Derek", ""]]}, {"id": "1908.05209", "submitter": "Anirudha Majumdar", "authors": "Anirudha Majumdar, Georgina Hall, and Amir Ali Ahmadi", "title": "A Survey of Recent Scalability Improvements for Semidefinite Programming\n  with Applications in Machine Learning, Control, and Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historically, scalability has been a major challenge to the successful\napplication of semidefinite programming in fields such as machine learning,\ncontrol, and robotics. In this paper, we survey recent approaches for\naddressing this challenge including (i) approaches for exploiting structure\n(e.g., sparsity and symmetry) in a problem, (ii) approaches that produce\nlow-rank approximate solutions to semidefinite programs, (iii) more scalable\nalgorithms that rely on augmented Lagrangian techniques and the alternating\ndirection method of multipliers, and (iv) approaches that trade off scalability\nwith conservatism (e.g., by approximating semidefinite programs with linear and\nsecond-order cone programs). For each class of approaches we provide a\nhigh-level exposition, an entry-point to the corresponding literature, and\nexamples drawn from machine learning, control, or robotics. We also present a\nlist of software packages that implement many of the techniques discussed in\nthe paper. Our hope is that this paper will serve as a gateway to the rich and\nexciting literature on scalable semidefinite programming for both theorists and\npractitioners.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 16:37:42 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 21:58:02 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 19:18:32 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Majumdar", "Anirudha", ""], ["Hall", "Georgina", ""], ["Ahmadi", "Amir Ali", ""]]}, {"id": "1908.05224", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Michael Ahn, Hugo Ponte, Shixiang Gu, Vikash Kumar", "title": "Multi-Agent Manipulation via Locomotion using Hierarchical Sim2Real", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulation and locomotion are closely related problems that are often\nstudied in isolation. In this work, we study the problem of coordinating\nmultiple mobile agents to exhibit manipulation behaviors using a reinforcement\nlearning (RL) approach. Our method hinges on the use of hierarchical sim2real\n-- a simulated environment is used to learn low-level goal-reaching skills,\nwhich are then used as the action space for a high-level RL controller, also\ntrained in simulation. The full hierarchical policy is then transferred to the\nreal world in a zero-shot fashion. The application of domain randomization\nduring training enables the learned behaviors to generalize to real-world\nsettings, while the use of hierarchy provides a modular paradigm for learning\nand transferring increasingly complex behaviors. We evaluate our method on a\nnumber of real-world tasks, including coordinated object manipulation in a\nmulti-agent setting. See videos at\nhttps://sites.google.com/view/manipulation-via-locomotion\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:12:02 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 21:26:34 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Nachum", "Ofir", ""], ["Ahn", "Michael", ""], ["Ponte", "Hugo", ""], ["Gu", "Shixiang", ""], ["Kumar", "Vikash", ""]]}, {"id": "1908.05227", "submitter": "Subhadeep Dey", "authors": "Subhadeep Dey, Petr Motlicek, Trung Bui and Franck Dernoncourt", "title": "Exploiting semi-supervised training through a dropout regularization in\n  end-to-end speech recognition", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore various approaches for semi supervised learning in\nan end to end automatic speech recognition (ASR) framework. The first step in\nour approach involves training a seed model on the limited amount of labelled\ndata. Additional unlabelled speech data is employed through a data selection\nmechanism to obtain the best hypothesized output, further used to retrain the\nseed model. However, uncertainties of the model may not be well captured with a\nsingle hypothesis. As opposed to this technique, we apply a dropout mechanism\nto capture the uncertainty by obtaining multiple hypothesized text transcripts\nof an speech recording. We assume that the diversity of automatically generated\ntranscripts for an utterance will implicitly increase the reliability of the\nmodel. Finally, the data selection process is also applied on these\nhypothesized transcripts to reduce the uncertainty. Experiments on freely\navailable TEDLIUM corpus and proprietary Adobe's internal dataset show that the\nproposed approach significantly reduces ASR errors, compared to the baseline\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 19:21:49 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Dey", "Subhadeep", ""], ["Motlicek", "Petr", ""], ["Bui", "Trung", ""], ["Dernoncourt", "Franck", ""]]}, {"id": "1908.05254", "submitter": "Mike Wu", "authors": "Mike Wu, Sonali Parbhoo, Michael C. Hughes, Volker Roth, Finale\n  Doshi-Velez", "title": "Optimizing for Interpretability in Deep Neural Networks with Tree\n  Regularization", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.04494,\n  arXiv:1711.06178", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models have advanced prediction in many domains, but their lack of\ninterpretability remains a key barrier to the adoption in many real world\napplications. There exists a large body of work aiming to help humans\nunderstand these black box functions to varying levels of granularity -- for\nexample, through distillation, gradients, or adversarial examples. These\nmethods however, all tackle interpretability as a separate process after\ntraining. In this work, we take a different approach and explicitly regularize\ndeep models so that they are well-approximated by processes that humans can\nstep-through in little time. Specifically, we train several families of deep\nneural networks to resemble compact, axis-aligned decision trees without\nsignificant compromises in accuracy. The resulting axis-aligned decision\nfunctions uniquely make tree regularized models easy for humans to interpret.\nMoreover, for situations in which a single, global tree is a poor estimator, we\nintroduce a regional tree regularizer that encourages the deep model to\nresemble a compact, axis-aligned decision tree in predefined,\nhuman-interpretable contexts. Using intuitive toy examples as well as medical\ntasks for patients in critical care and with HIV, we demonstrate that this new\nfamily of tree regularizers yield models that are easier for humans to simulate\nthan simpler L1 or L2 penalties without sacrificing predictive power.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:35:03 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Wu", "Mike", ""], ["Parbhoo", "Sonali", ""], ["Hughes", "Michael C.", ""], ["Roth", "Volker", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1908.05256", "submitter": "Rodrigo P\\'erez Dattari", "authors": "Rodrigo P\\'erez-Dattari, Carlos Celemin, Javier Ruiz-del-Solar, Jens\n  Kober", "title": "Continuous Control for High-Dimensional State Spaces: An Interactive\n  Learning Approach", "comments": "7 pages, 8 figures, IEEE International Conference on Robotics and\n  Automation (ICRA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has become a powerful methodology to solve\ncomplex decision-making problems. However, DRL has several limitations when\nused in real-world problems (e.g., robotics applications). For instance, long\ntraining times are required and cannot be accelerated in contrast to simulated\nenvironments, and reward functions may be hard to specify/model and/or to\ncompute. Moreover, the transfer of policies learned in a simulator to the\nreal-world has limitations (reality gap). On the other hand, machine learning\nmethods that rely on the transfer of human knowledge to an agent have shown to\nbe time efficient for obtaining well performing policies and do not require a\nreward function. In this context, we analyze the use of human corrective\nfeedback during task execution to learn policies with high-dimensional state\nspaces, by using the D-COACH framework, and we propose new variants of this\nframework. D-COACH is a Deep Learning based extension of COACH (COrrective\nAdvice Communicated by Humans), where humans are able to shape policies through\ncorrective advice. The enhanced version of D-COACH, which is proposed in this\npaper, largely reduces the time and effort of a human for training a policy.\nExperimental results validate the efficiency of the D-COACH framework in three\ndifferent problems (simulated and with real robots), and show that its enhanced\nversion reduces the human training effort considerably, and makes it feasible\nto learn policies within periods of time in which a DRL agent do not reach any\nimprovement.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:36:33 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["P\u00e9rez-Dattari", "Rodrigo", ""], ["Celemin", "Carlos", ""], ["Ruiz-del-Solar", "Javier", ""], ["Kober", "Jens", ""]]}, {"id": "1908.05265", "submitter": "Yang Hu", "authors": "Yang Hu and Giovanni Montana", "title": "Skill Transfer in Deep Reinforcement Learning under Morphological\n  Heterogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning methods for reinforcement learning (RL) domains facilitate\nthe acquisition of new skills using previously acquired knowledge. The vast\nmajority of existing approaches assume that the agents have the same design,\ne.g. same shape and action spaces. In this paper we address the problem of\ntransferring previously acquired skills amongst morphologically different\nagents (MDAs). For instance, assuming that a bipedal agent has been trained to\nmove forward, could this skill be transferred on to a one-leg hopper so as to\nmake its training process for the same task more sample efficient? We frame\nthis problem as one of subspace learning whereby we aim to infer latent factors\nrepresenting the control mechanism that is common between MDAs. We propose a\nnovel paired variational encoder-decoder model, PVED, that disentangles the\ncontrol of MDAs into shared and agent-specific factors. The shared factors are\nthen leveraged for skill transfer using RL. Theoretically, we derive a theorem\nindicating how the performance of PVED depends on the shared factors and agent\nmorphologies. Experimentally, PVED has been extensively validated on four\nMuJoCo environments. We demonstrate its performance compared to a\nstate-of-the-art approach and several ablation cases, visualize and interpret\nthe hidden factors, and identify avenues for future improvements.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:42:43 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 14:31:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Hu", "Yang", ""], ["Montana", "Giovanni", ""]]}, {"id": "1908.05287", "submitter": "Mohsen Shahhosseini", "authors": "Mohsen Shahhosseini, Guiping Hu, Hieu Pham", "title": "Optimizing Ensemble Weights and Hyperparameters of Machine Learning\n  Models for Regression Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregating multiple learners through an ensemble of models aim to make\nbetter predictions by capturing the underlying distribution of the data more\naccurately. Different ensembling methods, such as bagging, boosting, and\nstacking/blending, have been studied and adopted extensively in research and\npractice. While bagging and boosting focus more on reducing variance and bias,\nrespectively, stacking approaches target both by finding the optimal way to\ncombine base learners. In stacking with the weighted average, ensembles are\ncreated from weighted averages of multiple base learners. It is known that\ntuning hyperparameters of each base learner inside the ensemble weight\noptimization process can produce better performing ensembles. To this end, an\noptimization-based nested algorithm that considers tuning hyperparameters as\nwell as finding the optimal weights to combine ensembles (Generalized Weighted\nEnsemble with Internally Tuned Hyperparameters (GEM-ITH)) is designed. Besides,\nBayesian search was used to speed-up the optimizing process, and a heuristic\nwas implemented to generate diverse and well-performing base learners. The\nalgorithm is shown to be generalizable to real data sets through analyses with\nten publicly available data sets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 18:01:02 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 18:10:57 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 17:50:15 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 22:50:29 GMT"}, {"version": "v5", "created": "Sun, 19 Jan 2020 20:26:46 GMT"}, {"version": "v6", "created": "Sat, 31 Oct 2020 20:28:35 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Shahhosseini", "Mohsen", ""], ["Hu", "Guiping", ""], ["Pham", "Hieu", ""]]}, {"id": "1908.05304", "submitter": "Jiue-An Yang", "authors": "Jiayi Wang (1), Jiue-An Yang (2), Supun Nakandala (1), Arun Kumar (1),\n  Marta M. Jankowska (2) ((1) Computer Science and Engineering, University of\n  California San Diego, San Diego, USA (2) Qualcomm Institute/Calit2,\n  University of California San Diego, San Diego, USA)", "title": "Predicting Eating Events in Free Living Individuals -- A Technical\n  Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report records the experiments of applying multiple machine\nlearning algorithms for predicting eating and food purchasing behaviors of\nfree-living individuals. Data was collected with accelerometer, global\npositioning system (GPS), and body-worn cameras called SenseCam over a one week\nperiod in 81 individuals from a variety of ages and demographic backgrounds.\nThese data were turned into minute-level features from sensors as well as\nengineered features that included time (e.g., time since last eating) and\nenvironmental context (e.g., distance to nearest grocery store). Algorithms\ninclude Logistic Regression, RBF-SVM, Random Forest, and Gradient Boosting. Our\nresults show that the Gradient Boosting model has the highest mean accuracy\nscore (0.7289) for predicting eating events before 0 to 4 minutes. For\npredicting food purchasing events, the RBF-SVM model (0.7395) outperforms\nothers. For both prediction models, temporal and spatial features were\nimportant contributors to predicting eating and food purchasing events.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 18:46:21 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Wang", "Jiayi", ""], ["Yang", "Jiue-An", ""], ["Nakandala", "Supun", ""], ["Kumar", "Arun", ""], ["Jankowska", "Marta M.", ""]]}, {"id": "1908.05339", "submitter": "Hyunji Moon", "authors": "Hyunji Moon, Bomi Song, Hyeonseop Lee", "title": "Mixed pooling of seasonality for time series forecasting: An application\n  to pallet transport data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple seasonal patterns play a key role in time series forecasting,\nespecially for business time series where seasonal effects are often dramatic.\nPrevious approaches including Fourier decomposition, exponential smoothing, and\nseasonal autoregressive integrated moving average (SARIMA) models do not\nreflect the distinct characteristics of each period in seasonal patterns. We\npropose a mixed hierarchical seasonality (MHS) model. Intermediate parameters\nfor each seasonal period are first estimated, and a mixture of intermediate\nparameters is taken. This results in a model that automatically learns the\nrelative importance of each seasonality and addresses the interactions between\nthem. The model is implemented with Stan, a probabilistic language, and was\ncompared with three existing models on a real-world dataset of pallet transport\nfrom a logistic network. Our new model achieved considerable improvements in\nterms of out of sample prediction error (MAPE) and predictive density (ELPD)\ncompared to complete pooling, Fourier decomposition, and SARIMA model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 20:29:41 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 14:10:51 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Moon", "Hyunji", ""], ["Song", "Bomi", ""], ["Lee", "Hyeonseop", ""]]}, {"id": "1908.05344", "submitter": "Liyuan Liu", "authors": "Liyuan Liu, Zihan Wang, Jingbo Shang, Dandong Yin, Heng Ji, Xiang Ren,\n  Shaowen Wang and Jiawei Han", "title": "Raw-to-End Name Entity Recognition in Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking word sequences as the input, typical named entity recognition (NER)\nmodels neglect errors from pre-processing (e.g., tokenization). However, these\nerrors can influence the model performance greatly, especially for noisy texts\nlike tweets. Here, we introduce Neural-Char-CRF, a raw-to-end framework that is\nmore robust to pre-processing errors. It takes raw character sequences as\ninputs and makes end-to-end predictions. Word embedding and contextualized\nrepresentation models are further tailored to capture textual signals for each\ncharacter instead of each word. Our model neither requires the conversion from\ncharacter sequences to word sequences, nor assumes tokenizer can correctly\ndetect all word boundaries. Moreover, we observe our model performance remains\nunchanged after replacing tokenization with string matching, which demonstrates\nits potential to be tokenization-free. Extensive experimental results on two\npublic datasets demonstrate the superiority of our proposed method over the\nstate of the art. The implementations and datasets are made available at:\nhttps://github.com/LiyuanLucasLiu/Raw-to-End.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 20:50:14 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Liu", "Liyuan", ""], ["Wang", "Zihan", ""], ["Shang", "Jingbo", ""], ["Yin", "Dandong", ""], ["Ji", "Heng", ""], ["Ren", "Xiang", ""], ["Wang", "Shaowen", ""], ["Han", "Jiawei", ""]]}, {"id": "1908.05348", "submitter": "Malte Schilling", "authors": "Malte Schilling, Helge Ritter, Frank W. Ohl", "title": "From Crystallized Adaptivity to Fluid Adaptivity in Deep Reinforcement\n  Learning -- Insights from Biological Systems on Adaptive Flexibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in machine-learning algorithms have led to impressive\nperformance increases in many traditional application scenarios of artificial\nintelligence research. In the area of deep reinforcement learning, deep\nlearning functional architectures are combined with incremental learning\nschemes for sequential tasks that include interaction-based, but often delayed\nfeedback. Despite their impressive successes, modern machine-learning\napproaches, including deep reinforcement learning, still perform weakly when\ncompared to flexibly adaptive biological systems in certain naturally occurring\nscenarios. Such scenarios include transfers to environments different than the\nones in which the training took place or environments that dynamically change,\nboth of which are often mastered by biological systems through a capability\nthat we here term \"fluid adaptivity\" to contrast it from the much slower\nadaptivity (\"crystallized adaptivity\") of the prior learning from which the\nbehavior emerged. In this article, we derive and discuss research strategies,\nbased on analyzes of fluid adaptivity in biological systems and its neuronal\nmodeling, that might aid in equipping future artificially intelligent systems\nwith capabilities of fluid adaptivity more similar to those seen in some\nbiologically intelligent systems. A key component of this research strategy is\nthe dynamization of the problem space itself and the implementation of this\ndynamization by suitably designed flexibly interacting modules.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 07:28:41 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Schilling", "Malte", ""], ["Ritter", "Helge", ""], ["Ohl", "Frank W.", ""]]}, {"id": "1908.05349", "submitter": "Wei Liu", "authors": "Wei Liu, Jie-Lin Qiu, Wei-Long Zheng, and Bao-Liang Lu", "title": "Multimodal Emotion Recognition Using Deep Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal signals are more powerful than unimodal data for emotion\nrecognition since they can represent emotions more comprehensively. In this\npaper, we introduce deep canonical correlation analysis (DCCA) to multimodal\nemotion recognition. The basic idea behind DCCA is to transform each modality\nseparately and coordinate different modalities into a hyperspace by using\nspecified canonical correlation analysis constraints. We evaluate the\nperformance of DCCA on five multimodal datasets: the SEED, SEED-IV, SEED-V,\nDEAP, and DREAMER datasets. Our experimental results demonstrate that DCCA\nachieves state-of-the-art recognition accuracy rates on all five datasets:\n94.58% on the SEED dataset, 87.45% on the SEED-IV dataset, 84.33% and 85.62%\nfor two binary classification tasks and 88.51% for a four-category\nclassification task on the DEAP dataset, 83.08% on the SEED-V dataset, and\n88.99%, 90.57%, and 90.67% for three binary classification tasks on the DREAMER\ndataset. We also compare the noise robustness of DCCA with that of existing\nmethods when adding various amounts of noise to the SEED-V dataset. The\nexperimental results indicate that DCCA has greater robustness. By visualizing\nfeature distributions with t-SNE and calculating the mutual information between\ndifferent modalities before and after using DCCA, we find that the features\ntransformed by DCCA from different modalities are more homogeneous and\ndiscriminative across emotions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 09:22:23 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Liu", "Wei", ""], ["Qiu", "Jie-Lin", ""], ["Zheng", "Wei-Long", ""], ["Lu", "Bao-Liang", ""]]}, {"id": "1908.05357", "submitter": "Hao Chen Dr.", "authors": "Hao Chen and William J. Welch", "title": "Sequential Computer Experimental Design for Estimating an Extreme\n  Probability or Quantile", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computer code can simulate a system's propagation of variation from random\ninputs to output measures of quality. Our aim here is to estimate a critical\noutput tail probability or quantile without a large Monte Carlo experiment.\nInstead, we build a statistical surrogate for the input-output relationship\nwith a modest number of evaluations and then sequentially add further runs,\nguided by a criterion to improve the estimate. We compare two criteria in the\nliterature. Moreover, we investigate two practical questions: how to design the\ninitial code runs and how to model the input distribution. Hence, we close the\ngap between the theory of sequential design and its application.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 21:40:13 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Chen", "Hao", ""], ["Welch", "William J.", ""]]}, {"id": "1908.05365", "submitter": "Floris Hermsen", "authors": "Floris Hermsen, Peter Bloem, Fabian Jansen, Wolf Vos", "title": "End-to-End Learning from Complex Multigraphs with Latent-Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of end-to-end learning from complex multigraphs with\npotentially very large numbers of edges between two vertices, each edge labeled\nwith rich information. Examples range from communication networks to flights\nbetween airports or financial transaction graphs. We propose Latent-Graph\nConvolutional Networks (L-GCNs), which propagate information from these complex\nedges to a latent adjacency tensor, after which further downstream tasks can be\nperformed, such as node classification. We evaluate the performance of several\nvariations of the model on two synthetic datasets simulating fraud in financial\ntransaction networks, ensuring the model must make use of edge labels in order\nto achieve good classification performance. We find that allowing for nonlinear\ninteractions on a per-neighbor basis boosts performance significantly, while\nshowing promising results in an inductive setting. Finally, we demonstrate the\nuse of L-GCNs on real-world data in the form of an urban transportation\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 22:38:18 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 20:28:53 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Hermsen", "Floris", ""], ["Bloem", "Peter", ""], ["Jansen", "Fabian", ""], ["Vos", "Wolf", ""]]}, {"id": "1908.05368", "submitter": "Shuang Qiu", "authors": "Shuang Qiu, Xiaohan Wei, Zhuoran Yang", "title": "Robust One-Bit Recovery via ReLU Generative Networks: Near-Optimal\n  Statistical Rate and Global Landscape Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the robust one-bit compressed sensing problem whose goal is to\ndesign an algorithm that faithfully recovers any sparse target vector\n$\\theta_0\\in\\mathbb{R}^d$ \\textit{uniformly} via $m$ quantized noisy\nmeasurements. Specifically, we consider a new framework for this problem where\nthe sparsity is implicitly enforced via mapping a low dimensional\nrepresentation $x_0 \\in \\mathbb{R}^k$ through a known $n$-layer ReLU generative\nnetwork $G:\\mathbb{R}^k\\rightarrow\\mathbb{R}^d$ such that $\\theta_0 = G(x_0)$.\nSuch a framework poses low-dimensional priors on $\\theta_0$ without a known\nsparsity basis. We propose to recover the target $G(x_0)$ solving an\nunconstrained empirical risk minimization (ERM). Under a weak\n\\textit{sub-exponential measurement assumption}, we establish a joint\nstatistical and computational analysis. In particular, we prove that the ERM\nestimator in this new framework achieves a statistical rate of\n$m=\\widetilde{\\mathcal{O}}(kn \\log d /\\varepsilon^2)$ recovering any $G(x_0)$\nuniformly up to an error $\\varepsilon$. When the network is shallow (i.e., $n$\nis small), we show this rate matches the information-theoretic lower bound up\nto logarithm factors of $\\varepsilon^{-1}$. From the lens of computation, we\nprove that under proper conditions on the network weights, our proposed\nempirical risk, despite non-convexity, has no stationary point outside of small\nneighborhoods around the true representation $x_0$ and its negative multiple;\nfurthermore, we show that the global minimizer of the empirical risk stays\nwithin the neighborhood around $x_0$ rather than its negative multiple under\nfurther assumptions on the network weights.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 22:56:34 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 20:12:04 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 06:44:50 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Qiu", "Shuang", ""], ["Wei", "Xiaohan", ""], ["Yang", "Zhuoran", ""]]}, {"id": "1908.05372", "submitter": "Zhenyu Zhao", "authors": "Zhenyu Zhao and Totte Harinen", "title": "Uplift Modeling for Multiple Treatments with Cost Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift modeling is an emerging machine learning approach for estimating the\ntreatment effect at an individual or subgroup level. It can be used for\noptimizing the performance of interventions such as marketing campaigns and\nproduct designs. Uplift modeling can be used to estimate which users are likely\nto benefit from a treatment and then prioritize delivering or promoting the\npreferred experience to those users. An important but so far neglected use case\nfor uplift modeling is an experiment with multiple treatment groups that have\ndifferent costs, such as for example when different communication channels and\npromotion types are tested simultaneously. In this paper, we extend standard\nuplift models to support multiple treatment groups with different costs. We\nevaluate the performance of the proposed models using both synthetic and real\ndata. We also describe a production implementation of the approach.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 23:35:25 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 03:55:31 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 17:49:57 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zhao", "Zhenyu", ""], ["Harinen", "Totte", ""]]}, {"id": "1908.05376", "submitter": "Zhenyu Zhao", "authors": "Zhenyu Zhao, Radhika Anand, Mallory Wang", "title": "Maximum Relevance and Minimum Redundancy Feature Selection Methods for a\n  Marketing Machine Learning Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning applications for online product offerings and marketing\nstrategies, there are often hundreds or thousands of features available to\nbuild such models. Feature selection is one essential method in such\napplications for multiple objectives: improving the prediction accuracy by\neliminating irrelevant features, accelerating the model training and prediction\nspeed, reducing the monitoring and maintenance workload for feature data\npipeline, and providing better model interpretation and diagnosis capability.\nHowever, selecting an optimal feature subset from a large feature space is\nconsidered as an NP-complete problem. The mRMR (Minimum Redundancy and Maximum\nRelevance) feature selection framework solves this problem by selecting the\nrelevant features while controlling for the redundancy within the selected\nfeatures. This paper describes the approach to extend, evaluate, and implement\nthe mRMR feature selection methods for classification problem in a marketing\nmachine learning platform at Uber that automates creation and deployment of\ntargeting and personalization models at scale. This study first extends the\nexisting mRMR methods by introducing a non-linear feature redundancy measure\nand a model-based feature relevance measure. Then an extensive empirical\nevaluation is performed for eight different feature selection methods, using\none synthetic dataset and three real-world marketing datasets at Uber to cover\ndifferent use cases. Based on the empirical results, the selected mRMR method\nis implemented in production for the marketing machine learning platform. A\ndescription of the production implementation is provided and an online\nexperiment deployed through the platform is discussed.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 00:06:23 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Zhao", "Zhenyu", ""], ["Anand", "Radhika", ""], ["Wang", "Mallory", ""]]}, {"id": "1908.05377", "submitter": "Oindrila Chatterjee", "authors": "Oindrila Chatterjee and Shantanu Chakrabartty", "title": "Resonant Machine Learning Based on Complex Growth Transform Dynamical\n  Systems", "comments": "Version3, accepted in IEEE TNNLS, March 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional energy-based learning models associate a single energy metric to\neach configuration of variables involved in the underlying optimization\nprocess. Such models associate the lowest energy state to the optimal\nconfiguration of variables under consideration, and are thus inherently\ndissipative. In this paper we propose an energy-efficient learning framework\nthat exploits structural and functional similarities between a machine learning\nnetwork and a general electrical network satisfying the Tellegen's theorem. In\ncontrast to the standard energy-based models, the proposed formulation\nassociates two energy components, namely, active and reactive energy to the\nnetwork. This ensures that the network's active-power is dissipated only during\nthe process of learning, whereas the reactive-power is maintained to be zero at\nall times. As a result, in steady-state, the learned parameters are stored and\nself-sustained by electrical resonance determined by the network's nodal\ninductances and capacitances. Based on this approach, this paper introduces\nthree novel concepts: (a) A learning framework where the network's active-power\ndissipation is used as a regularization for a learning objective function that\nis subjected to zero total reactive-power constraint; (b) A dynamical system\nbased on complex-domain, continuous-time growth transforms which optimizes the\nlearning objective function and drives the network towards electrical resonance\nunder steady-state operation; and (c) An annealing procedure that controls the\ntrade-off between active-power dissipation and the speed of convergence. As a\nrepresentative example, we show how the proposed framework can be used for\ndesigning resonant support vector machines (SVMs), where we show that the\nsupport-vectors correspond to an LC network with self-sustained oscillations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 00:20:48 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 20:15:19 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 13:57:11 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Chatterjee", "Oindrila", ""], ["Chakrabartty", "Shantanu", ""]]}, {"id": "1908.05387", "submitter": "Mandana Saebi", "authors": "Mandana Saebi, Giovanni Luca Ciampaglia, Lance M Kaplan, Nitesh V\n  Chawla", "title": "HONEM: Learning Embedding for Higher Order Networks", "comments": null, "journal-ref": "Big Data 8, no. 4 (2020): 255-269", "doi": "10.1089/big.2019.0169", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning on networks offers a powerful alternative to the oft\npainstaking process of manual feature engineering, and as a result, has enjoyed\nconsiderable success in recent years. However, all the existing representation\nlearning methods are based on the first-order network (FON), that is, the\nnetwork that only captures the pairwise interactions between the nodes. As a\nresult, these methods may fail to incorporate non-Markovian higher-order\ndependencies in the network. Thus, the embeddings that are generated may not\naccurately represent of the underlying phenomena in a network, resulting in\ninferior performance in different inductive or transductive learning tasks. To\naddress this challenge, this paper presents HONEM, a higher-order network\nembedding method that captures the non-Markovian higher-order dependencies in a\nnetwork. HONEM is specifically designed for the higher-order network structure\n(HON) and outperforms other state-of-the-art methods in node classification,\nnetwork re-construction, link prediction, and visualization for networks that\ncontain non-Markovian higher-order dependencies.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 01:22:27 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 17:10:31 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Saebi", "Mandana", ""], ["Ciampaglia", "Giovanni Luca", ""], ["Kaplan", "Lance M", ""], ["Chawla", "Nitesh V", ""]]}, {"id": "1908.05389", "submitter": "Junkun Jiang", "authors": "Junkun Jiang, Ruomei Wang, Shujin Lin, Fei Wang", "title": "SFSegNet: Parse Freehand Sketches using Deep Fully Convolutional\n  Networks", "comments": "Accepted for the 2019 International Joint Conference on Neural\n  Networks (IJCNN-19)", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8851974", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsing sketches via semantic segmentation is attractive but challenging,\nbecause (i) free-hand drawings are abstract with large variances in depicting\nobjects due to different drawing styles and skills; (ii) distorting lines drawn\non the touchpad make sketches more difficult to be recognized; (iii) the\nhigh-performance image segmentation via deep learning technologies needs\nenormous annotated sketch datasets during the training stage. In this paper, we\npropose a Sketch-target deep FCN Segmentation Network(SFSegNet) for automatic\nfree-hand sketch segmentation, labeling each sketch in a single object with\nmultiple parts. SFSegNet has an end-to-end network process between the input\nsketches and the segmentation results, composed of 2 parts: (i) a modified deep\nFully Convolutional Network(FCN) using a reweighting strategy to ignore\nbackground pixels and classify which part each pixel belongs to; (ii) affine\ntransform encoders that attempt to canonicalize the shaking strokes. We train\nour network with the dataset that consists of 10,000 annotated sketches, to\nfind an extensively applicable model to segment stokes semantically in one\nground truth. Extensive experiments are carried out and segmentation results\nshow that our method outperforms other state-of-the-art networks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 01:35:36 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Jiang", "Junkun", ""], ["Wang", "Ruomei", ""], ["Lin", "Shujin", ""], ["Wang", "Fei", ""]]}, {"id": "1908.05391", "submitter": "Qibin Chen", "authors": "Qibin Chen, Junyang Lin, Yichang Zhang, Ming Ding, Yukuo Cen, Hongxia\n  Yang, Jie Tang", "title": "Towards Knowledge-Based Recommender Dialog System", "comments": "To appear in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel end-to-end framework called KBRD, which\nstands for Knowledge-Based Recommender Dialog System. It integrates the\nrecommender system and the dialog generation system. The dialog system can\nenhance the performance of the recommendation system by introducing\nknowledge-grounded information about users' preferences, and the recommender\nsystem can improve that of the dialog generation system by providing\nrecommendation-aware vocabulary bias. Experimental results demonstrate that our\nproposed model has significant advantages over the baselines in both the\nevaluation of dialog generation and recommendation. A series of analyses show\nthat the two systems can bring mutual benefits to each other, and the\nintroduced knowledge contributes to both their performances.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 01:49:19 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 04:38:02 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Chen", "Qibin", ""], ["Lin", "Junyang", ""], ["Zhang", "Yichang", ""], ["Ding", "Ming", ""], ["Cen", "Yukuo", ""], ["Yang", "Hongxia", ""], ["Tang", "Jie", ""]]}, {"id": "1908.05426", "submitter": "Yuze Gao", "authors": "Yuze Gao and Yu Yuan", "title": "Feature-Less End-to-End Nested Term Extraction", "comments": null, "journal-ref": "NLPCC XAI 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a deep learning-based end-to-end method on the\ndomain specified automatic term extraction (ATE), it considers possible term\nspans within a fixed length in the sentence and predicts them whether they can\nbe conceptual terms. In comparison with current ATE methods, the model supports\nnested term extraction and does not crucially need extra (extracted) features.\nResults show that it can achieve high recall and a comparable precision on term\nextraction task with inputting segmented raw text.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 05:38:14 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gao", "Yuze", ""], ["Yuan", "Yu", ""]]}, {"id": "1908.05429", "submitter": "Xin Li", "authors": "Huiting Hong, Xin Li, Yuangang Pan, Ivor Tsang", "title": "Domain-adversarial Network Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network alignment is a critical task to a wide variety of fields. Many\nexisting works leverage on representation learning to accomplish this task\nwithout eliminating domain representation bias induced by domain-dependent\nfeatures, which yield inferior alignment performance. This paper proposes a\nunified deep architecture (DANA) to obtain a domain-invariant representation\nfor network alignment via an adversarial domain classifier. Specifically, we\nemploy the graph convolutional networks to perform network embedding under the\ndomain adversarial principle, given a small set of observed anchors. Then, the\nsemi-supervised learning framework is optimized by maximizing a posterior\nprobability distribution of observed anchors and the loss of a domain\nclassifier simultaneously. We also develop a few variants of our model, such\nas, direction-aware network alignment, weight-sharing for directed networks and\nsimplification of parameter space. Experiments on three real-world social\nnetwork datasets demonstrate that our proposed approaches achieve\nstate-of-the-art alignment results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 05:56:25 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Hong", "Huiting", ""], ["Li", "Xin", ""], ["Pan", "Yuangang", ""], ["Tsang", "Ivor", ""]]}, {"id": "1908.05434", "submitter": "Longshaokan Wang", "authors": "Longshaokan Wang, Eric Laber, Yeng Saanchi, Sherrie Caltagirone", "title": "Sex Trafficking Detection with Ordinal Regression Neural Networks", "comments": "AAAI-20 workshop on Artificial Intelligence for Cyber Security (AICS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sex trafficking is a global epidemic. Escort websites are a primary vehicle\nfor selling the services of such trafficking victims and thus a major driver of\ntrafficker revenue. Many law enforcement agencies do not have the resources to\nmanually identify leads from the millions of escort ads posted across dozens of\npublic websites. We propose an ordinal regression neural network to identify\nescort ads that are likely linked to sex trafficking. Our model uses a modified\ncost function to mitigate inconsistencies in predictions often associated with\nnonparametric ordinal regression and leverages recent advancements in deep\nlearning to improve prediction accuracy. The proposed method significantly\nimproves on the previous state-of-the-art on Trafficking-10K, an\nexpert-annotated dataset of escort ads. Additionally, because traffickers use\nacronyms, deliberate typographical errors, and emojis to replace explicit\nkeywords, we demonstrate how to expand the lexicon of trafficking flags through\nword embeddings and t-SNE.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 06:25:46 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 02:17:39 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Wang", "Longshaokan", ""], ["Laber", "Eric", ""], ["Saanchi", "Yeng", ""], ["Caltagirone", "Sherrie", ""]]}, {"id": "1908.05435", "submitter": "Liwei Wu", "authors": "Liwei Wu, Shuqing Li, Cho-Jui Hsieh, James Sharpnack", "title": "Temporal Collaborative Ranking Via Personalized Transformer", "comments": "plan to submit for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The collaborative ranking problem has been an important open research\nquestion as most recommendation problems can be naturally formulated as ranking\nproblems. While much of collaborative ranking methodology assumes static\nranking data, the importance of temporal information to improving ranking\nperformance is increasingly apparent. Recent advances in deep learning,\nespecially the discovery of various attention mechanisms and newer\narchitectures in addition to widely used RNN and CNN in natural language\nprocessing, have allowed us to make better use of the temporal ordering of\nitems that each user has engaged with. In particular, the SASRec model,\ninspired by the popular Transformer model in natural languages processing, has\nachieved state-of-art results in the temporal collaborative ranking problem and\nenjoyed more than 10x speed-up when compared to earlier CNN/RNN-based methods.\nHowever, SASRec is inherently an un-personalized model and does not include\npersonalized user embeddings. To overcome this limitation, we propose a\nPersonalized Transformer (SSE-PT) model, outperforming SASRec by almost 5% in\nterms of NDCG@10 on 5 real-world datasets. Furthermore, after examining some\nrandom users' engagement history and corresponding attention heat maps used\nduring the inference stage, we find our model is not only more interpretable\nbut also able to focus on recent engagement patterns for each user. Moreover,\nour SSE-PT model with a slight modification, which we call SSE-PT++, can handle\nextremely long sequences and outperform SASRec in ranking results with\ncomparable training speed, striking a balance between performance and speed\nrequirements. Code and data are open sourced at\nhttps://github.com/wuliwei9278/SSE-PT.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 06:35:04 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Wu", "Liwei", ""], ["Li", "Shuqing", ""], ["Hsieh", "Cho-Jui", ""], ["Sharpnack", "James", ""]]}, {"id": "1908.05451", "submitter": "Fangchen Liu", "authors": "Zhiao Huang, Fangchen Liu, Hao Su", "title": "Mapping State Space using Landmarks for Universal Goal Reaching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent that has well understood the environment should be able to apply its\nskills for any given goals, leading to the fundamental problem of learning the\nUniversal Value Function Approximator (UVFA). A UVFA learns to predict the\ncumulative rewards between all state-goal pairs. However, empirically, the\nvalue function for long-range goals is always hard to estimate and may\nconsequently result in failed policy. This has presented challenges to the\nlearning process and the capability of neural networks. We propose a method to\naddress this issue in large MDPs with sparse rewards, in which exploration and\nrouting across remote states are both extremely challenging. Our method\nexplicitly models the environment in a hierarchical manner, with a high-level\ndynamic landmark-based map abstracting the visited state space, and a low-level\nvalue network to derive precise local decisions. We use farthest point sampling\nto select landmark states from past experience, which has improved exploration\ncompared with simple uniform sampling. Experimentally we showed that our method\nenables the agent to reach long-range goals at the early training stage, and\nachieve better performance than standard RL algorithms for a number of\nchallenging tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 08:01:56 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Huang", "Zhiao", ""], ["Liu", "Fangchen", ""], ["Su", "Hao", ""]]}, {"id": "1908.05460", "submitter": "Sree Harsha Nelaturu", "authors": "Ziheng Wang, Sree Harsha Nelaturu", "title": "Accelerated CNN Training Through Gradient Approximation", "comments": "An abridged version was presented at EMC^2 : Workshop On Energy\n  Efficient Machine Learning And Cognitive Computing For Embedded Applications\n  at ISCA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep convolutional neural networks such as VGG and ResNet by\ngradient descent is an expensive exercise requiring specialized hardware such\nas GPUs. Recent works have examined the possibility of approximating the\ngradient computation while maintaining the same convergence properties. While\npromising, the approximations only work on relatively small datasets such as\nMNIST. They also fail to achieve real wall-clock speedups due to lack of\nefficient GPU implementations of the proposed approximation methods. In this\nwork, we explore three alternative methods to approximate gradients, with an\nefficient GPU kernel implementation for one of them. We achieve wall-clock\nspeedup with ResNet-20 and VGG-19 on the CIFAR-10 dataset upwards of 7%, with a\nminimal loss in validation accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 09:11:31 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Wang", "Ziheng", ""], ["Nelaturu", "Sree Harsha", ""]]}, {"id": "1908.05474", "submitter": "Qianggang Ding", "authors": "Qianggang Ding, Sifan Wu, Hao Sun, Jiadong Guo, Shu-Tao Xia", "title": "Adaptive Regularization of Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a variety of regularization techniques have been widely applied in\ndeep neural networks, such as dropout, batch normalization, data augmentation,\nand so on. These methods mainly focus on the regularization of weight\nparameters to prevent overfitting effectively. In addition, label\nregularization techniques such as label smoothing and label disturbance have\nalso been proposed with the motivation of adding a stochastic perturbation to\nlabels. In this paper, we propose a novel adaptive label regularization method,\nwhich enables the neural network to learn from the erroneous experience and\nupdate the optimal label representation online. On the other hand, compared\nwith knowledge distillation, which learns the correlation of categories using\nteacher network, our proposed method requires only a minuscule increase in\nparameters without cumbersome teacher network. Furthermore, we evaluate our\nmethod on CIFAR-10/CIFAR-100/ImageNet datasets for image recognition tasks and\nAGNews/Yahoo/Yelp-Full datasets for text classification tasks. The empirical\nresults show significant improvement under all experimental settings.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 09:58:24 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Ding", "Qianggang", ""], ["Wu", "Sifan", ""], ["Sun", "Hao", ""], ["Guo", "Jiadong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "1908.05480", "submitter": "Evgeny Burnaev", "authors": "Anna Kuzina and Evgenii Egorov and Evgeny Burnaev", "title": "Bayesian Generative Models for Knowledge Transfer in MRI Semantic\n  Segmentation Problems", "comments": "24 page, 6 figures, 6 tabels", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic segmentation methods based on deep learning have recently\ndemonstrated state-of-the-art performance, outperforming the ordinary methods.\nNevertheless, these methods are inapplicable for small datasets, which are very\ncommon in medical problems. To this end, we propose a knowledge transfer method\nbetween diseases via the Generative Bayesian Prior network. Our approach is\ncompared to a pre-train approach and random initialization and obtains the best\nresults in terms of Dice Similarity Coefficient metric for the small subsets of\nthe Brain Tumor Segmentation 2018 database (BRATS2018).\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 10:27:32 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Kuzina", "Anna", ""], ["Egorov", "Evgenii", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1908.05519", "submitter": "Nathanael Perraudin N. P.", "authors": "Nathana\\\"el Perraudin, Ankit Srivastava, Aurelien Lucchi, Tomasz\n  Kacprzak, Thomas Hofmann and Alexandre R\\'efr\\'egier", "title": "Cosmological N-body simulations: a challenge for scalable generative\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph astro-ph.CO cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models, such as Generative Adversarial Networks (GANs) or\nVariational Autoencoders (VAs) have been demonstrated to produce images of high\nvisual quality. However, the existing hardware severely limits the size of the\nimages that can be generated. The rapid growth of high dimensional data in many\nfields of science therefore poses a significant challenge for generative\nmodels. In cosmology, the large-scale, three-dimensional matter distribution,\nmodeled with N-body simulations, plays a crucial role in understanding the\nevolution of the universe. As these simulations are computationally very\nexpensive, GANs have recently generated interest as a possible method to\nemulate these datasets, but they have been, so far, mostly limited to two\ndimensional data. In this work, we introduce a new benchmark for the generation\nof three dimensional N-body simulations, in order to stimulate new ideas in the\nmachine learning community and move closer to the practical use of generative\nmodels in cosmology. As a first benchmark result, we propose a scalable GAN\napproach for training a generator of N-body three-dimensional cubes. Our\ntechnique relies on two key building blocks, (i) splitting the generation of\nthe high-dimensional data into smaller parts, and (ii) using a multi-scale\napproach that efficiently captures global image features that might otherwise\nbe lost in the splitting process. We evaluate the performance of our model for\nthe generation of N-body samples using various statistical measures commonly\nused in cosmology. Our results show that the proposed model produces samples of\nhigh visual quality, although the statistical analysis reveals that capturing\nrare features in the data poses significant problems for the generative models.\nWe make the data, quality evaluation routines, and the proposed GAN\narchitecture publicly available at https://github.com/nperraud/3DcosmoGAN\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 12:47:38 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 08:12:31 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Perraudin", "Nathana\u00ebl", ""], ["Srivastava", "Ankit", ""], ["Lucchi", "Aurelien", ""], ["Kacprzak", "Tomasz", ""], ["Hofmann", "Thomas", ""], ["R\u00e9fr\u00e9gier", "Alexandre", ""]]}, {"id": "1908.05540", "submitter": "Amir Atapour Abarghouei", "authors": "Amir Atapour-Abarghouei and Toby P. Breckon", "title": "To complete or to estimate, that is the question: A Multi-Task Approach\n  to Depth Completion and Monocular Depth Estimation", "comments": "International Conference on 3D Vision (3DV) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust three-dimensional scene understanding is now an ever-growing area of\nresearch highly relevant in many real-world applications such as autonomous\ndriving and robotic navigation. In this paper, we propose a multi-task\nlearning-based model capable of performing two tasks:- sparse depth completion\n(i.e. generating complete dense scene depth given a sparse depth image as the\ninput) and monocular depth estimation (i.e. predicting scene depth from a\nsingle RGB image) via two sub-networks jointly trained end to end using data\nrandomly sampled from a publicly available corpus of synthetic and real-world\nimages. The first sub-network generates a sparse depth image by learning lower\nlevel features from the scene and the second predicts a full dense depth image\nof the entire scene, leading to a better geometric and contextual understanding\nof the scene and, as a result, superior performance of the approach. The entire\nmodel can be used to infer complete scene depth from a single RGB image or the\nsecond network can be used alone to perform depth completion given a sparse\ndepth input. Using adversarial training, a robust objective function, a deep\narchitecture relying on skip connections and a blend of synthetic and\nreal-world training data, our approach is capable of producing superior high\nquality scene depth. Extensive experimental evaluation demonstrates the\nefficacy of our approach compared to contemporary state-of-the-art techniques\nacross both problem domains.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 13:50:50 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Atapour-Abarghouei", "Amir", ""], ["Breckon", "Toby P.", ""]]}, {"id": "1908.05541", "submitter": "Felix Hamann", "authors": "Felix Hamann, Nadja Kurz, Adrian Ulges", "title": "Hamming Sentence Embeddings for Information Retrieval", "comments": "4 Pages, 9 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In retrieval applications, binary hashes are known to offer significant\nimprovements in terms of both memory and speed. We investigate the compression\nof sentence embeddings using a neural encoder-decoder architecture, which is\ntrained by minimizing reconstruction error. Instead of employing the original\nreal-valued embeddings, we use latent representations in Hamming space produced\nby the encoder for similarity calculations.\n  In quantitative experiments on several benchmarks for semantic similarity\ntasks, we show that our compressed hamming embeddings yield a comparable\nperformance to uncompressed embeddings (Sent2Vec, InferSent, Glove-BoW), at\ncompression ratios of up to 256:1. We further demonstrate that our model\nstrongly decorrelates input features, and that the compressor generalizes well\nwhen pre-trained on Wikipedia sentences. We publish the source code on Github\nand all experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 13:51:12 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Hamann", "Felix", ""], ["Kurz", "Nadja", ""], ["Ulges", "Adrian", ""]]}, {"id": "1908.05542", "submitter": "Gregorz Dudek", "authors": "Grzegorz Dudek", "title": "Improving Randomized Learning of Feedforward Neural Networks by\n  Appropriate Generation of Random Parameters", "comments": null, "journal-ref": "15th International Work-Conference on Artificial Neural Networks\n  IWANN 2019. LNCS, vol 11506. Springer, Cham", "doi": "10.1007/978-3-030-20521-8_43", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a method of random parameters generation for randomized\nlearning of a single-hidden-layer feedforward neural network is proposed. The\nmethod firstly, randomly selects the slope angles of the hidden neurons\nactivation functions from an interval adjusted to the target function, then\nrandomly rotates the activation functions, and finally distributes them across\nthe input space. For complex target functions the proposed method gives better\nresults than the approach commonly used in practice, where the random\nparameters are selected from the fixed interval. This is because it introduces\nthe steepest fragments of the activation functions into the input hypercube,\navoiding their saturation fragments.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 13:52:22 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1908.05546", "submitter": "Mohammad Thabet", "authors": "Mohammad Thabet, Massimiliano Patacchiola, and Angelo Cangelosi", "title": "Sample-efficient Deep Reinforcement Learning with Imaginary Rollouts for\n  Human-Robot Interaction", "comments": "Accepted for IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has proven to be a great success in allowing\nagents to learn complex tasks. However, its application to actual robots can be\nprohibitively expensive. Furthermore, the unpredictability of human behavior in\nhuman-robot interaction tasks can hinder convergence to a good policy. In this\npaper, we present an architecture that allows agents to learn models of\nstochastic environments and use them to accelerate learning. We descirbe how an\nenvironment model can be learned online and used to generate synthetic\ntransitions, as well as how an agent can leverage these synthetic data to\naccelerate learning. We validate our approach using an experiment in which a\nrobotic arm has to complete a task composed of a series of actions based on\nhuman gestures. Results show that our approach leads to significantly faster\nlearning, requiring much less interaction with the environment. Furthermore, we\ndemonstrate how learned models can be used by a robot to produce optimal plans\nin real world applications.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 13:56:12 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Thabet", "Mohammad", ""], ["Patacchiola", "Massimiliano", ""], ["Cangelosi", "Angelo", ""]]}, {"id": "1908.05552", "submitter": "Joseph Campbell", "authors": "Joseph Campbell, Arne Hitzmann, Simon Stepputtis, Shuhei Ikemoto, Koh\n  Hosoda, Heni Ben Amor", "title": "Learning Interactive Behaviors for Musculoskeletal Robots Using Bayesian\n  Interaction Primitives", "comments": "Accompanying video: https://youtu.be/2fxOn3lIdvo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Musculoskeletal robots that are based on pneumatic actuation have a variety\nof properties, such as compliance and back-drivability, that render them\nparticularly appealing for human-robot collaboration. However, programming\ninteractive and responsive behaviors for such systems is extremely challenging\ndue to the nonlinearity and uncertainty inherent to their control. In this\npaper, we propose an approach for learning Bayesian Interaction Primitives for\nmusculoskeletal robots given a limited set of example demonstrations. We show\nthat this approach is capable of real-time state estimation and response\ngeneration for interaction with a robot for which no analytical model exists.\nHuman-robot interaction experiments on a 'handshake' task show that the\napproach generalizes to new positions, interaction partners, and movement\nvelocities.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 14:04:29 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Campbell", "Joseph", ""], ["Hitzmann", "Arne", ""], ["Stepputtis", "Simon", ""], ["Ikemoto", "Shuhei", ""], ["Hosoda", "Koh", ""], ["Amor", "Heni Ben", ""]]}, {"id": "1908.05557", "submitter": "Anh Truong", "authors": "Anh Truong, Austin Walters, Jeremy Goodsitt, Keegan Hines, C. Bayan\n  Bruss, Reza Farivar", "title": "Towards Automated Machine Learning: Evaluation and Comparison of AutoML\n  Approaches and Tools", "comments": null, "journal-ref": null, "doi": "10.1109/ICTAI.2019.00209", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable growth and interest in industrial applications of\nmachine learning (ML) in recent years. ML engineers, as a consequence, are in\nhigh demand across the industry, yet improving the efficiency of ML engineers\nremains a fundamental challenge. Automated machine learning (AutoML) has\nemerged as a way to save time and effort on repetitive tasks in ML pipelines,\nsuch as data pre-processing, feature engineering, model selection,\nhyperparameter optimization, and prediction result analysis. In this paper, we\ninvestigate the current state of AutoML tools aiming to automate these tasks.\nWe conduct various evaluations of the tools on many datasets, in different data\nsegments, to examine their performance, and compare their advantages and\ndisadvantages on different test cases.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 14:16:09 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 19:31:52 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Truong", "Anh", ""], ["Walters", "Austin", ""], ["Goodsitt", "Jeremy", ""], ["Hines", "Keegan", ""], ["Bruss", "C. Bayan", ""], ["Farivar", "Reza", ""]]}, {"id": "1908.05567", "submitter": "Felix Strnad", "authors": "Felix M. Strnad, Wolfram Barfuss, Jonathan F. Donges, Jobst Heitzig", "title": "Deep reinforcement learning in World-Earth system models to discover\n  sustainable management strategies", "comments": "16 pages, 8 figures", "journal-ref": "Chaos 29, 123122 (2019)", "doi": "10.1063/1.5124673", "report-no": null, "categories": "physics.soc-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly complex, non-linear World-Earth system models are used for\ndescribing the dynamics of the biophysical Earth system and the socio-economic\nand socio-cultural World of human societies and their interactions. Identifying\npathways towards a sustainable future in these models for informing policy\nmakers and the wider public, e.g. pathways leading to a robust mitigation of\ndangerous anthropogenic climate change, is a challenging and widely\ninvestigated task in the field of climate research and broader Earth system\nscience. This problem is particularly difficult when constraints on avoiding\ntransgressions of planetary boundaries and social foundations need to be taken\ninto account. In this work, we propose to combine recently developed machine\nlearning techniques, namely deep reinforcement learning (DRL), with classical\nanalysis of trajectories in the World-Earth system. Based on the concept of the\nagent-environment interface, we develop an agent that is generally able to act\nand learn in variable manageable environment models of the Earth system. We\ndemonstrate the potential of our framework by applying DRL algorithms to two\nstylized World-Earth system models. Conceptually, we explore thereby the\nfeasibility of finding novel global governance policies leading into a safe and\njust operating space constrained by certain planetary and socio-economic\nboundaries. The artificially intelligent agent learns that the timing of a\nspecific mix of taxing carbon emissions and subsidies on renewables is of\ncrucial relevance for finding World-Earth system trajectories that are\nsustainable on the long term.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 14:48:31 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Strnad", "Felix M.", ""], ["Barfuss", "Wolfram", ""], ["Donges", "Jonathan F.", ""], ["Heitzig", "Jobst", ""]]}, {"id": "1908.05569", "submitter": "David Mac\\^edo", "authors": "David Mac\\^edo, Tsang Ing Ren, Cleber Zanchettin, Adriano L. I.\n  Oliveira, Teresa Ludermir", "title": "Entropic Out-of-Distribution Detection", "comments": "Accepted for publication in The International Joint Conference on\n  Neural Networks (IJCNN), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-distribution (OOD) detection approaches usually present special\nrequirements (e.g., hyperparameter validation, collection of outlier data) and\nproduce side effects (e.g., classification accuracy drop, slower\nenergy-inefficient inferences). We argue that these issues are a consequence of\nthe SoftMax loss anisotropy and disagreement with the maximum entropy\nprinciple. Thus, we propose the IsoMax loss and the entropic score. The\nseamless drop-in replacement of the SoftMax loss by IsoMax loss requires\nneither additional data collection nor hyperparameter validation. The trained\nmodels do not exhibit classification accuracy drop and produce fast\nenergy-efficient inferences. Moreover, our experiments show that training\nneural networks with IsoMax loss significantly improves their OOD detection\nperformance. The IsoMax loss exhibits state-of-the-art performance under the\nmentioned conditions (fast energy-efficient inference, no classification\naccuracy drop, no collection of outlier data, and no hyperparameter\nvalidation), which we call the seamless OOD detection task. In future work,\ncurrent OOD detection methods may replace the SoftMax loss with the IsoMax loss\nto improve their performance on the commonly studied non-seamless OOD detection\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 14:54:52 GMT"}, {"version": "v10", "created": "Thu, 26 Nov 2020 22:47:49 GMT"}, {"version": "v11", "created": "Mon, 30 Nov 2020 01:55:08 GMT"}, {"version": "v12", "created": "Sun, 11 Apr 2021 23:32:49 GMT"}, {"version": "v13", "created": "Mon, 24 May 2021 23:15:23 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 02:22:46 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 00:58:03 GMT"}, {"version": "v4", "created": "Wed, 5 Feb 2020 01:18:56 GMT"}, {"version": "v5", "created": "Tue, 18 Feb 2020 23:06:49 GMT"}, {"version": "v6", "created": "Sun, 7 Jun 2020 06:54:51 GMT"}, {"version": "v7", "created": "Thu, 11 Jun 2020 05:59:13 GMT"}, {"version": "v8", "created": "Thu, 23 Jul 2020 17:03:57 GMT"}, {"version": "v9", "created": "Mon, 3 Aug 2020 06:37:15 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Mac\u00eado", "David", ""], ["Ren", "Tsang Ing", ""], ["Zanchettin", "Cleber", ""], ["Oliveira", "Adriano L. I.", ""], ["Ludermir", "Teresa", ""]]}, {"id": "1908.05571", "submitter": "Ola Spjuth", "authors": "Ola Spjuth, Robin Carri\\'on Br\\\"annstr\\\"om, Lars Carlsson, Niharika\n  Gauraha", "title": "Combining Prediction Intervals on Multi-Source Non-Disclosed Regression\n  Datasets", "comments": "Accepted to 8th Symposium on Conformal and Probabilistic Prediction\n  with Applications, Golden Sands, Bulgaria, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conformal Prediction is a framework that produces prediction intervals based\non the output from a machine learning algorithm. In this paper we explore the\ncase when training data is made up of multiple parts available in different\nsources that cannot be pooled. We here consider the regression case and propose\na method where a conformal predictor is trained on each data source\nindependently, and where the prediction intervals are then combined into a\nsingle interval. We call the approach Non-Disclosed Conformal Prediction\n(NDCP), and we evaluate it on a regression dataset from the UCI machine\nlearning repository using support vector regression as the underlying machine\nlearning algorithm, with varying number of data sources and sizes. The results\nshow that the proposed method produces conservatively valid prediction\nintervals, and while we cannot retain the same efficiency as when all data is\nused, efficiency is improved through the proposed approach as compared to\npredicting using a single arbitrarily chosen source.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 15:01:55 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Spjuth", "Ola", ""], ["Br\u00e4nnstr\u00f6m", "Robin Carri\u00f3n", ""], ["Carlsson", "Lars", ""], ["Gauraha", "Niharika", ""]]}, {"id": "1908.05596", "submitter": "Timothy Miller", "authors": "Dianbo Liu, Dmitriy Dligach, Timothy Miller", "title": "Two-stage Federated Phenotyping and Patient Representation Learning", "comments": "9 pages; Proceedings of the 18th BioNLP Workshop and Shared Task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large percentage of medical information is in unstructured text format in\nelectronic medical record systems. Manual extraction of information from\nclinical notes is extremely time consuming. Natural language processing has\nbeen widely used in recent years for automatic information extraction from\nmedical texts. However, algorithms trained on data from a single healthcare\nprovider are not generalizable and error-prone due to the heterogeneity and\nuniqueness of medical documents. We develop a two-stage federated natural\nlanguage processing method that enables utilization of clinical notes from\ndifferent hospitals or clinics without moving the data, and demonstrate its\nperformance using obesity and comorbities phenotyping as medical task. This\napproach not only improves the quality of a specific clinical task but also\nfacilitates knowledge progression in the whole healthcare system, which is an\nessential part of learning health system. To the best of our knowledge, this is\nthe first application of federated machine learning in clinical NLP.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:06:11 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Liu", "Dianbo", ""], ["Dligach", "Dmitriy", ""], ["Miller", "Timothy", ""]]}, {"id": "1908.05601", "submitter": "Mengnan Du", "authors": "Mengnan Du, Ninghao Liu, Fan Yang, Xia Hu", "title": "Learning Credible Deep Neural Networks with Rationale Regularization", "comments": "ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent explainability related studies have shown that state-of-the-art DNNs\ndo not always adopt correct evidences to make decisions. It not only hampers\ntheir generalization but also makes them less likely to be trusted by\nend-users. In pursuit of developing more credible DNNs, in this paper we\npropose CREX, which encourages DNN models to focus more on evidences that\nactually matter for the task at hand, and to avoid overfitting to\ndata-dependent bias and artifacts. Specifically, CREX regularizes the training\nprocess of DNNs with rationales, i.e., a subset of features highlighted by\ndomain experts as justifications for predictions, to enforce DNNs to generate\nlocal explanations that conform with expert rationales. Even when rationales\nare not available, CREX still could be useful by requiring the generated\nexplanations to be sparse. Experimental results on two text classification\ndatasets demonstrate the increased credibility of DNNs trained with CREX.\nComprehensive analysis further shows that while CREX does not always improve\nprediction accuracy on the held-out test set, it significantly increases DNN\naccuracy on new and previously unseen data beyond test set, highlighting the\nadvantage of the increased credibility.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 12:57:26 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Du", "Mengnan", ""], ["Liu", "Ninghao", ""], ["Yang", "Fan", ""], ["Hu", "Xia", ""]]}, {"id": "1908.05602", "submitter": "Heikki Arponen Dr", "authors": "Heikki Arponen, Tom E Bishop", "title": "SHREWD: Semantic Hierarchy-based Relational Embeddings for\n  Weakly-supervised Deep Hashing", "comments": "4 pages, Published in ICLR LLD Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using class labels to represent class similarity is a typical approach to\ntraining deep hashing systems for retrieval; samples from the same or different\nclasses take binary 1 or 0 similarity values. This similarity does not model\nthe full rich knowledge of semantic relations that may be present between data\npoints. In this work we build upon the idea of using semantic hierarchies to\nform distance metrics between all available sample labels; for example cat to\ndog has a smaller distance than cat to guitar. We combine this type of semantic\ndistance into a loss function to promote similar distances between the deep\nneural network embeddings. We also introduce an empirical Kullback-Leibler\ndivergence loss term to promote binarization and uniformity of the embeddings.\nWe test the resulting SHREWD method and demonstrate improvements in\nhierarchical retrieval scores using compact, binary hash codes instead of real\nvalued ones, and show that in a weakly supervised hashing setting we are able\nto learn competitively without explicitly relying on class labels, but instead\non similarities between labels.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 08:24:40 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Arponen", "Heikki", ""], ["Bishop", "Tom E", ""]]}, {"id": "1908.05611", "submitter": "Chang-You Tai", "authors": "Chang-You Tai, Meng-Ru Wu, Yun-Wei Chu, Shao-Yu Chu", "title": "GraphSW: a training protocol based on stage-wise training for GNN-based\n  Recommender Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers utilize Knowledge Graph (KG) as side information in\nrecommendation system to address cold start and sparsity issue and improve the\nrecommendation performance. Existing KG-aware recommendation model use the\nfeature of neighboring entities and structural information to update the\nembedding of currently located entity. Although the fruitful information is\nbeneficial to the following task, the cost of exploring the entire graph is\nmassive and impractical. In order to reduce the computational cost and maintain\nthe pattern of extracting features, KG-aware recommendation model usually\nutilize fixed-size and random set of neighbors rather than complete information\nin KG. Nonetheless, there are two critical issues in these approaches: First of\nall, fixed-size and randomly selected neighbors restrict the view of graph. In\naddition, as the order of graph feature increases, the growth of parameter\ndimensionality of the model may lead the training process hard to converge. To\nsolve the aforementioned limitations, we propose GraphSW, a strategy based on\nstage-wise training framework which would only access to a subset of the\nentities in KG in every stage. During the following stages, the learned\nembedding from previous stages is provided to the network in the next stage and\nthe model can learn the information gradually from the KG. We apply stage-wise\ntraining on two SOTA recommendation models, RippleNet and Knowledge Graph\nConvolutional Networks (KGCN). Moreover, we evaluate the performance on six\nreal world datasets, Last.FM 2011, Book-Crossing,movie, LFM-1b 2015,\nAmazon-book and Yelp 2018. The result of our experiments shows that proposed\nstrategy can help both models to collect more information from the KG and\nimprove the performance. Furthermore, it is observed that GraphSW can assist\nKGCN to converge effectively in high-order graph feature.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 05:50:50 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 15:31:49 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Tai", "Chang-You", ""], ["Wu", "Meng-Ru", ""], ["Chu", "Yun-Wei", ""], ["Chu", "Shao-Yu", ""]]}, {"id": "1908.05612", "submitter": "Xue Yang", "authors": "Xue Yang, Junchi Yan, Ziming Feng, Tao He", "title": "R3Det: Refined Single-Stage Detector with Feature Refinement for\n  Rotating Object", "comments": "13 pages, 12 figures, 9 tables", "journal-ref": "Thirty-Five AAAI Conference on Artificial Intelligence (AAAI2021)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rotation detection is a challenging task due to the difficulties of locating\nthe multi-angle objects and separating them effectively from the background.\nThough considerable progress has been made, for practical settings, there still\nexist challenges for rotating objects with large aspect ratio, dense\ndistribution and category extremely imbalance. In this paper, we propose an\nend-to-end refined single-stage rotation detector for fast and accurate object\ndetection by using a progressive regression approach from coarse to fine\ngranularity. Considering the shortcoming of feature misalignment in existing\nrefined single-stage detector, we design a feature refinement module to improve\ndetection performance by getting more accurate features. The key idea of\nfeature refinement module is to re-encode the position information of the\ncurrent refined bounding box to the corresponding feature points through\npixel-wise feature interpolation to realize feature reconstruction and\nalignment. For more accurate rotation estimation, an approximate SkewIoU loss\nis proposed to solve the problem that the calculation of SkewIoU is not\nderivable. Experiments on three popular remote sensing public datasets DOTA,\nHRSC2016, UCAS-AOD as well as one scene text dataset ICDAR2015 show the\neffectiveness of our approach. Tensorflow and Pytorch version codes are\navailable at https://github.com/Thinklab-SJTU/R3Det_Tensorflow and\nhttps://github.com/SJTU-Thinklab-Det/r3det-on-mmdetection, and R3Det is also\nintegrated in our open source rotation detection benchmark:\nhttps://github.com/yangxue0827/RotationDetection.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 15:56:37 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 10:13:30 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 07:00:27 GMT"}, {"version": "v4", "created": "Sat, 30 Nov 2019 14:55:45 GMT"}, {"version": "v5", "created": "Fri, 21 Feb 2020 12:57:03 GMT"}, {"version": "v6", "created": "Tue, 8 Dec 2020 05:52:52 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Yang", "Xue", ""], ["Yan", "Junchi", ""], ["Feng", "Ziming", ""], ["He", "Tao", ""]]}, {"id": "1908.05620", "submitter": "Li Dong", "authors": "Yaru Hao, Li Dong, Furu Wei, Ke Xu", "title": "Visualizing and Understanding the Effectiveness of BERT", "comments": "Accepted by EMNLP-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language model pre-training, such as BERT, has achieved remarkable results in\nmany NLP tasks. However, it is unclear why the pre-training-then-fine-tuning\nparadigm can improve performance and generalization capability across different\ntasks. In this paper, we propose to visualize loss landscapes and optimization\ntrajectories of fine-tuning BERT on specific datasets. First, we find that\npre-training reaches a good initial point across downstream tasks, which leads\nto wider optima and easier optimization compared with training from scratch. We\nalso demonstrate that the fine-tuning procedure is robust to overfitting, even\nthough BERT is highly over-parameterized for downstream tasks. Second, the\nvisualization results indicate that fine-tuning BERT tends to generalize better\nbecause of the flat and wide optima, and the consistency between the training\nloss surface and the generalization error surface. Third, the lower layers of\nBERT are more invariant during fine-tuning, which suggests that the layers that\nare close to input learn more transferable representations of language.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 16:11:45 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Hao", "Yaru", ""], ["Dong", "Li", ""], ["Wei", "Furu", ""], ["Xu", "Ke", ""]]}, {"id": "1908.05635", "submitter": "Jennifer Hoyal Cuthill", "authors": "Jennifer F. Hoyal Cuthill, Nicholas Guttenberg, Sophie Ledger, Robyn\n  Crowther, Blanca Huertas", "title": "Deep learning on butterfly phenotypes tests evolution's oldest\n  mathematical model", "comments": "Manuscript and combined supplementary information", "journal-ref": "Sci Adv 5, eaaw4967 (2019)", "doi": "10.1126/sciadv.aaw4967", "report-no": null, "categories": "q-bio.PE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional anatomical analyses captured only a fraction of real phenomic\ninformation. Here, we apply deep learning to quantify total phenotypic\nsimilarity across 2468 butterfly photographs, covering 38 subspecies from the\npolymorphic mimicry complex of $\\textit{Heliconius erato}$ and\n$\\textit{Heliconius melpomene}$. Euclidean phenotypic distances, calculated\nusing a deep convolutional triplet network, demonstrate significant convergence\nbetween interspecies co-mimics. This quantitatively validates a key prediction\nof M\\\"ullerian mimicry theory, evolutionary biology's oldest mathematical\nmodel. Phenotypic neighbor-joining trees are significantly correlated with wing\npattern gene phylogenies, demonstrating objective, phylogenetically informative\nphenome capture. Comparative analyses indicate frequency-dependent, mutual\nconvergence with coevolutionary exchange of wing pattern features. Therefore,\nphenotypic analysis supports reciprocal coevolution, predicted by classical\nmimicry theory but since disputed, and reveals mutual convergence as an\nintrinsic generator for the surprising diversity of M\\\"ullerian mimicry. This\ndemonstrates that deep learning can generate phenomic spatial embeddings which\nenable quantitative tests of evolutionary hypotheses previously only testable\nsubjectively.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 16:55:27 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Cuthill", "Jennifer F. Hoyal", ""], ["Guttenberg", "Nicholas", ""], ["Ledger", "Sophie", ""], ["Crowther", "Robyn", ""], ["Huertas", "Blanca", ""]]}, {"id": "1908.05640", "submitter": "G\\\"okhan \\c{C}apan", "authors": "G\\\"okhan \\c{C}apan, Ilker G\\\"undo\\u{g}du, Ali Caner T\\\"urkmen,\n  \\c{C}a\\u{g}r{\\i} Sofuo\\u{g}lu, Ali Taylan Cemgil", "title": "A Bayesian Choice Model for Eliminating Feedback Loops", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-reinforcing feedback loops in personalization systems are typically\ncaused by users choosing from a limited set of alternatives presented\nsystematically based on previous choices. We propose a Bayesian choice model\nbuilt on Luce axioms that explicitly accounts for users' limited exposure to\nalternatives. Our model is fair---it does not impose negative bias towards\nunpresented alternatives, and practical---preference estimates are accurately\ninferred upon observing a small number of interactions. It also allows\nefficient sampling, leading to a straightforward online presentation mechanism\nbased on Thompson sampling. Our approach achieves low regret in learning to\npresent upon exploration of only a small fraction of possible presentations.\nThe proposed structure can be reused as a building block in interactive\nsystems, e.g., recommender systems, free of feedback loops.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 17:02:25 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 14:18:50 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["\u00c7apan", "G\u00f6khan", ""], ["G\u00fcndo\u011fdu", "Ilker", ""], ["T\u00fcrkmen", "Ali Caner", ""], ["Sofuo\u011flu", "\u00c7a\u011fr\u0131", ""], ["Cemgil", "Ali Taylan", ""]]}, {"id": "1908.05646", "submitter": "Yoav Levine", "authors": "Yoav Levine, Barak Lenz, Or Dagan, Ori Ram, Dan Padnos, Or Sharir,\n  Shai Shalev-Shwartz, Amnon Shashua, Yoav Shoham", "title": "SenseBERT: Driving Some Sense into BERT", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn from large unlabeled corpora has allowed neural language\nmodels to advance the frontier in natural language understanding. However,\nexisting self-supervision techniques operate at the word form level, which\nserves as a surrogate for the underlying semantic content. This paper proposes\na method to employ weak-supervision directly at the word sense level. Our\nmodel, named SenseBERT, is pre-trained to predict not only the masked words but\nalso their WordNet supersenses. Accordingly, we attain a lexical-semantic level\nlanguage model, without the use of human annotation. SenseBERT achieves\nsignificantly improved lexical understanding, as we demonstrate by\nexperimenting on SemEval Word Sense Disambiguation, and by attaining a state of\nthe art result on the Word in Context task.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 17:20:20 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 16:40:41 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Levine", "Yoav", ""], ["Lenz", "Barak", ""], ["Dagan", "Or", ""], ["Ram", "Ori", ""], ["Padnos", "Dan", ""], ["Sharir", "Or", ""], ["Shalev-Shwartz", "Shai", ""], ["Shashua", "Amnon", ""], ["Shoham", "Yoav", ""]]}, {"id": "1908.05656", "submitter": "Ross Girshick", "authors": "Anton Bakhtin, Laurens van der Maaten, Justin Johnson, Laura\n  Gustafson, Ross Girshick", "title": "PHYRE: A New Benchmark for Physical Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and reasoning about physics is an important ability of\nintelligent agents. We develop the PHYRE benchmark for physical reasoning that\ncontains a set of simple classical mechanics puzzles in a 2D physical\nenvironment. The benchmark is designed to encourage the development of learning\nalgorithms that are sample-efficient and generalize well across puzzles. We\ntest several modern learning algorithms on PHYRE and find that these algorithms\nfall short in solving the puzzles efficiently. We expect that PHYRE will\nencourage the development of novel sample-efficient agents that learn efficient\nbut useful models of physics. For code and to play PHYRE for yourself, please\nvisit https://player.phyre.ai.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 17:58:32 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Bakhtin", "Anton", ""], ["van der Maaten", "Laurens", ""], ["Johnson", "Justin", ""], ["Gustafson", "Laura", ""], ["Girshick", "Ross", ""]]}, {"id": "1908.05659", "submitter": "Hamed Rahimian", "authors": "Hamed Rahimian and Sanjay Mehrotra", "title": "Distributionally Robust Optimization: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concepts of risk-aversion, chance-constrained optimization, and robust\noptimization have developed significantly over the last decade. Statistical\nlearning community has also witnessed a rapid theoretical and applied growth by\nrelying on these concepts. A modeling framework, called distributionally robust\noptimization (DRO), has recently received significant attention in both the\noperations research and statistical learning communities. This paper surveys\nmain concepts and contributions to DRO, and its relationships with robust\noptimization, risk-aversion, chance-constrained optimization, and function\nregularization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 00:43:41 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Rahimian", "Hamed", ""], ["Mehrotra", "Sanjay", ""]]}, {"id": "1908.05660", "submitter": "Abhishek Panigrahi", "authors": "Abhishek Panigrahi, Abhishek Shetty and Navin Goyal", "title": "Effect of Activation Functions on the Training of Overparametrized\n  Neural Nets", "comments": "Major update: Several new results, some reorganization and rewriting\n  of previous results, new references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that overparametrized neural networks trained using\ngradient-based methods quickly achieve small training error with appropriate\nhyperparameter settings. Recent papers have proved this statement theoretically\nfor highly overparametrized networks under reasonable assumptions. These\nresults either assume that the activation function is ReLU or they crucially\ndepend on the minimum eigenvalue of a certain Gram matrix depending on the\ndata, random initialization and the activation function. In the later case,\nexisting works only prove that this minimum eigenvalue is non-zero and do not\nprovide quantitative bounds. On the empirical side, a contemporary line of\ninvestigations has proposed a number of alternative activation functions which\ntend to perform better than ReLU at least in some settings but no clear\nunderstanding has emerged. This state of affairs underscores the importance of\ntheoretically understanding the impact of activation functions on training. In\nthe present paper, we provide theoretical results about the effect of\nactivation function on the training of highly overparametrized 2-layer neural\nnetworks. A crucial property that governs the performance of an activation is\nwhether or not it is smooth. For non-smooth activations such as ReLU, SELU and\nELU, all eigenvalues of the associated Gram matrix are large under minimal\nassumptions on the data. For smooth activations such as tanh, swish and\npolynomials, the situation is more complex. If the subspace spanned by the data\nhas small dimension then the minimum eigenvalue of the Gram matrix can be small\nleading to slow training. But if the dimension is large and the data satisfies\nanother mild condition, then the eigenvalues are large. If we allow deep\nnetworks, then the small data dimension is not a limitation provided that the\ndepth is sufficient. We discuss a number of extensions and applications of\nthese results.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 16:22:07 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 14:37:14 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 09:39:17 GMT"}, {"version": "v4", "created": "Fri, 10 Apr 2020 13:22:00 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Panigrahi", "Abhishek", ""], ["Shetty", "Abhishek", ""], ["Goyal", "Navin", ""]]}, {"id": "1908.05663", "submitter": "Yigal Shenkman", "authors": "Yigal Shenkman, Bilal Qutteineh, Leo Joskowicz, Adi Szeskin, Yusef\n  Azraq, Arnaldo Mayer, Iris Eshed", "title": "Automatic detection and diagnosis of sacroiliitis in CT scans as\n  incidental findings", "comments": null, "journal-ref": null, "doi": "10.1016/j.media.2019.07.007", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early diagnosis of sacroiliitis may lead to preventive treatment which can\nsignificantly improve the patient's quality of life in the long run.\nOftentimes, a CT scan of the lower back or abdomen is acquired for suspected\nback pain. However, since the differences between a healthy and an inflamed\nsacroiliac joint in the early stages are subtle, the condition may be missed.\nWe have developed a new automatic algorithm for the diagnosis and grading of\nsacroiliitis CT scans as incidental findings, for patients who underwent CT\nscanning as part of their lower back pain workout. The method is based on\nsupervised machine and deep learning techniques. The input is a CT scan that\nincludes the patient's pelvis. The output is a diagnosis for each sacroiliac\njoint. The algorithm consists of four steps: 1) computation of an initial\nregion of interest (ROI) that includes the pelvic joints region using\nheuristics and a U-Net classifier; 2) refinement of the ROI to detect both\nsacroiliac joints using a four-tree random forest; 3) individual sacroiliitis\ngrading of each sacroiliac joint in each CT slice with a custom slice CNN\nclassifier, and; 4) sacroiliitis diagnosis and grading by combining the\nindividual slice grades using a random forest. Experimental results on 484\nsacroiliac joints yield a binary and a 3-class case classification accuracy of\n91.9% and 86%, a sensitivity of 95% and 82%, and an Area-Under-the-Curve of\n0.97 and 0.57, respectively. Automatic computer-based analysis of CT scans has\nthe potential of being a useful method for the diagnosis and grading of\nsacroiliitis as an incidental finding.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 18:51:34 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Shenkman", "Yigal", ""], ["Qutteineh", "Bilal", ""], ["Joskowicz", "Leo", ""], ["Szeskin", "Adi", ""], ["Azraq", "Yusef", ""], ["Mayer", "Arnaldo", ""], ["Eshed", "Iris", ""]]}, {"id": "1908.05666", "submitter": "Konstantinos Konstantinidis", "authors": "Konstantinos Konstantinidis and Aditya Ramamoorthy", "title": "Resolvable Designs for Speeding up Distributed Computing", "comments": "14 pages, 3 figures, full paper for IEEE TON submission. arXiv admin\n  note: substantial text overlap with arXiv:1802.03049, arXiv:1901.07418", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed computing frameworks such as MapReduce are often used to process\nlarge computational jobs. They operate by partitioning each job into smaller\ntasks executed on different servers. The servers also need to exchange\nintermediate values to complete the computation. Experimental evidence suggests\nthat this so-called Shuffle phase can be a significant part of the overall\nexecution time for several classes of jobs. Prior work has demonstrated a\nnatural tradeoff between computation and communication whereby running\nredundant copies of jobs can reduce the Shuffle traffic load, thereby leading\nto reduced overall execution times. For a single job, the main drawback of this\napproach is that it requires the original job to be split into a number of\nfiles that grows exponentially in the system parameters. When extended to\nmultiple jobs (with specific function types), these techniques suffer from a\nlimitation of a similar flavor, i.e., they require an exponentially large\nnumber of jobs to be executed. In practical scenarios, these requirements can\nsignificantly reduce the promised gains of the method. In this work, we show\nthat a class of combinatorial structures called resolvable designs can be used\nto develop efficient coded distributed computing schemes for both the single\nand multiple job scenarios considered in prior work. We present both\ntheoretical analysis and exhaustive experimental results (on Amazon EC2\nclusters) that demonstrate the performance advantages of our method. For the\nsingle and multiple job cases, we obtain speed-ups of 4.69x (and 2.6x over\nprior work) and 4.31x over the baseline approach, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 20:02:28 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 18:14:16 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 00:36:27 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Konstantinidis", "Konstantinos", ""], ["Ramamoorthy", "Aditya", ""]]}, {"id": "1908.05672", "submitter": "Mingxuan Wang", "authors": "Jiacheng Yang, Mingxuan Wang, Hao Zhou, Chengqi Zhao, Yong Yu, Weinan\n  Zhang, Lei Li", "title": "Towards Making the Most of BERT in Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPT-2 and BERT demonstrate the effectiveness of using pre-trained language\nmodels (LMs) on various natural language processing tasks. However, LM\nfine-tuning often suffers from catastrophic forgetting when applied to\nresource-rich tasks. In this work, we introduce a concerted training framework\n(\\method) that is the key to integrate the pre-trained LMs to neural machine\ntranslation (NMT). Our proposed Cnmt consists of three techniques: a)\nasymptotic distillation to ensure that the NMT model can retain the previous\npre-trained knowledge; b) a dynamic switching gate to avoid catastrophic\nforgetting of pre-trained knowledge; and c) a strategy to adjust the learning\npaces according to a scheduled policy. Our experiments in machine translation\nshow \\method gains of up to 3 BLEU score on the WMT14 English-German language\npair which even surpasses the previous state-of-the-art pre-training aided NMT\nby 1.4 BLEU score. While for the large WMT14 English-French task with 40\nmillions of sentence-pairs, our base model still significantly improves upon\nthe state-of-the-art Transformer big model by more than 1 BLEU score.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 03:33:50 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 04:36:18 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 11:26:20 GMT"}, {"version": "v4", "created": "Thu, 26 Mar 2020 12:12:56 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Yang", "Jiacheng", ""], ["Wang", "Mingxuan", ""], ["Zhou", "Hao", ""], ["Zhao", "Chengqi", ""], ["Yu", "Yong", ""], ["Zhang", "Weinan", ""], ["Li", "Lei", ""]]}, {"id": "1908.05674", "submitter": "Dong Cao", "authors": "Dong Cao, Lisha Xu", "title": "Bypass Enhancement RGB Stream Model for Pedestrian Action Recognition of\n  Autonomous Vehicles", "comments": "Accepted to ACPR 2019 - Workshop on Computer Vision for Modern\n  Vehicles", "journal-ref": null, "doi": "10.1007/978-981-15-3651-9_2", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pedestrian action recognition and intention prediction is one of the core\nissues in the field of autonomous driving. In this research field, action\nrecognition is one of the key technologies. A large number of scholars have\ndone a lot of work to im-prove the accuracy of the algorithm for the task.\nHowever, there are relatively few studies and improvements in the computational\ncomplexity of algorithms and sys-tem real-time. In the autonomous driving\napplication scenario, the real-time per-formance and ultra-low latency of the\nalgorithm are extremely important evalua-tion indicators, which are directly\nrelated to the availability and safety of the au-tonomous driving system. To\nthis end, we construct a bypass enhanced RGB flow model, which combines the\nprevious two-branch algorithm to extract RGB feature information and optical\nflow feature information respectively. In the train-ing phase, the two branches\nare merged by distillation method, and the bypass enhancement is combined in\nthe inference phase to ensure accuracy. The real-time behavior of the behavior\nrecognition algorithm is significantly improved on the premise that the\naccuracy does not decrease. Experiments confirm the superiority and\neffectiveness of our algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 07:37:14 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 07:02:31 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Cao", "Dong", ""], ["Xu", "Lisha", ""]]}, {"id": "1908.05679", "submitter": "WonKee Lee", "authors": "WonKee Lee, Junsu Park, Byung-Hyun Go, Jong-Hyeok Lee", "title": "Transformer-based Automatic Post-Editing with a Context-Aware Encoding\n  Approach for Multi-Source Inputs", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to the Automatic Post-Editing (APE) research have shown\nthat better results are obtained by multi-source models, which jointly encode\nboth source (src) and machine translation output (mt) to produce post-edited\nsentence (pe). Along this trend, we present a new multi-source APE model based\non the Transformer. To construct effective joint representations, our model\ninternally learns to incorporate src context into mt representation. With this\napproach, we achieve a significant improvement over baseline systems, as well\nas the state-of-the-art multi-source APE model. Moreover, to demonstrate the\ncapability of our model to incorporate src context, we show that the word\nalignment of the unknown MT system is successfully captured in our encoding\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 14:08:24 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Lee", "WonKee", ""], ["Park", "Junsu", ""], ["Go", "Byung-Hyun", ""], ["Lee", "Jong-Hyeok", ""]]}, {"id": "1908.05699", "submitter": "Guojun Zhang", "authors": "Guojun Zhang and Yaoliang Yu", "title": "Convergence of Gradient Methods on Bilinear Zero-Sum Games", "comments": null, "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Min-max formulations have attracted great attention in the ML community due\nto the rise of deep generative models and adversarial methods, while\nunderstanding the dynamics of gradient algorithms for solving such formulations\nhas remained a grand challenge. As a first step, we restrict to bilinear\nzero-sum games and give a systematic analysis of popular gradient updates, for\nboth simultaneous and alternating versions. We provide exact conditions for\ntheir convergence and find the optimal parameter setup and convergence rates.\nIn particular, our results offer formal evidence that alternating updates\nconverge \"better\" than simultaneous ones.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 18:27:14 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 22:07:30 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 03:20:37 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 21:10:54 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Zhang", "Guojun", ""], ["Yu", "Yaoliang", ""]]}, {"id": "1908.05715", "submitter": "Vyacheslav Olshevsky", "authors": "Vyacheslav Olshevsky, Yuri V. Khotyaintsev, Ahmad Lalti, Andrey Divin,\n  Gian Luca Delzanno, Sven Anderzen, Pawel Herman, Steven W.D. Chien, Levon\n  Avanov, Andrew P. Dimmock, Stefano Markidis", "title": "Automated classification of plasma regions using 3D particle energy\n  distributions", "comments": "Submitted to JGR: Space Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.space-ph cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the properties of the ion sky maps produced by the Dual Ion\nSpectrometers (DIS) from the Fast Plasma Investigation (FPI). We have trained a\nconvolutional neural network classifier to predict four regions crossed by the\nMMS on the dayside magnetosphere: solar wind, ion foreshock, magnetosheath, and\nmagnetopause using solely DIS spectrograms. The accuracy of the classifier is\n>98%. We use the classifier to detect mixed plasma regions, in particular to\nfind the bow shock regions. A similar approach can be used to identify the\nmagnetopause crossings and reveal regions prone to magnetic reconnection. Data\nprocessing through the trained classifier is fast and efficient and thus can be\nused for classification for the whole MMS database.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 19:16:13 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 13:33:05 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 08:12:08 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Olshevsky", "Vyacheslav", ""], ["Khotyaintsev", "Yuri V.", ""], ["Lalti", "Ahmad", ""], ["Divin", "Andrey", ""], ["Delzanno", "Gian Luca", ""], ["Anderzen", "Sven", ""], ["Herman", "Pawel", ""], ["Chien", "Steven W. D.", ""], ["Avanov", "Levon", ""], ["Dimmock", "Andrew P.", ""], ["Markidis", "Stefano", ""]]}, {"id": "1908.05717", "submitter": "Jakub Tomczak Ph.D.", "authors": "Amirhossein Habibian, Ties van Rozendaal, Jakub M. Tomczak, Taco S.\n  Cohen", "title": "Video Compression With Rate-Distortion Autoencoders", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": "10.1109/ICCV.2019.00713", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a a deep generative model for lossy video\ncompression. We employ a model that consists of a 3D autoencoder with a\ndiscrete latent space and an autoregressive prior used for entropy coding. Both\nautoencoder and prior are trained jointly to minimize a rate-distortion loss,\nwhich is closely related to the ELBO used in variational autoencoders. Despite\nits simplicity, we find that our method outperforms the state-of-the-art\nlearned video compression networks based on motion compensation or\ninterpolation. We systematically evaluate various design choices, such as the\nuse of frame-based or spatio-temporal autoencoders, and the type of\nautoregressive prior. In addition, we present three extensions of the basic\nmethod that demonstrate the benefits over classical approaches to compression.\nFirst, we introduce semantic compression, where the model is trained to\nallocate more bits to objects of interest. Second, we study adaptive\ncompression, where the model is adapted to a domain with limited variability,\ne.g., videos taken from an autonomous car, to achieve superior compression on\nthat domain. Finally, we introduce multimodal compression, where we demonstrate\nthe effectiveness of our model in joint compression of multiple modalities\ncaptured by non-standard imaging sensors, such as quad cameras. We believe that\nthis opens up novel video compression applications, which have not been\nfeasible with classical codecs.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 15:37:23 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 16:42:58 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Habibian", "Amirhossein", ""], ["van Rozendaal", "Ties", ""], ["Tomczak", "Jakub M.", ""], ["Cohen", "Taco S.", ""]]}, {"id": "1908.05725", "submitter": "Tao Wang", "authors": "Tao Wang, Xinmin Wu, Taiping He", "title": "Trustable and Automated Machine Learning Running with Blockchain and Its\n  Applications", "comments": "10 pages, KDD 2019 AutoML workshop. arXiv admin note: text overlap\n  with arXiv:1903.08801", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms learn from data and use data from databases that\nare mutable; therefore, the data and the results of machine learning cannot be\nfully trusted. Also, the machine learning process is often difficult to\nautomate. A unified analytical framework for trustable machine learning has\nbeen presented in the literature. It proposed building a trustable machine\nlearning system by using blockchain technology, which can store data in a\npermanent and immutable way. In addition, smart contracts on blockchain are\nused to automate the machine learning process. In the proposed framework, a\ncore machine learning algorithm can have three implementations: server layer\nimplementation, streaming layer implementation, and smart contract\nimplementation. However, there are still open questions. First, the streaming\nlayer usually deploys on edge devices and therefore has limited memory and\ncomputing power. How can we run machine learning on the streaming layer?\nSecond, most data that are stored on blockchain are financial transactions, for\nwhich fraud detection is often needed. However, in some applications, training\ndata are hard to obtain. Can we build good machine learning models to do fraud\ndetection with limited training data? These questions motivated this paper;\nwhich makes two contributions. First, it proposes training a machine learning\nmodel on the server layer and saving the model with a special binary data\nformat. Then, the streaming layer can take this blob of binary data as input\nand score incoming data online. The blob of binary data is very compact and can\nbe deployed on edge devices. Second, the paper presents a new method of\nsynthetic data generation that can enrich the training data set. Experiments\nshow that this synthetic data generation is very effective in applications such\nas fraud detection in financial data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 00:09:12 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Wang", "Tao", ""], ["Wu", "Xinmin", ""], ["He", "Taiping", ""]]}, {"id": "1908.05730", "submitter": "Redha Ali", "authors": "Redha Ali, Russell C. Hardie, Manawaduge Supun De Silva, and Temesguen\n  Messay Kebede", "title": "Skin Lesion Segmentation and Classification for ISIC 2018 by Combining\n  Deep CNN and Handcrafted Features", "comments": "4 pages and 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short report describes our submission to the ISIC 2018 Challenge in Skin\nLesion Analysis Towards Melanoma Detection for Task1 and Task 3. This work has\nbeen accomplished by a team of researchers at the University of Dayton Signal\nand Image Processing Lab. Our proposed approach is computationally efficient\nare combines information from both deep learning and handcrafted features. For\nTask3, we form a new type of image features, called hybrid features, which has\nstronger discrimination ability than single method features. These features are\nutilized as inputs to a decision-making model that is based on a multiclass\nSupport Vector Machine (SVM) classifier. The proposed technique is evaluated on\nonline validation databases. Our score was 0.841 with SVM classifier on the\nvalidation dataset.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 02:48:49 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Ali", "Redha", ""], ["Hardie", "Russell C.", ""], ["De Silva", "Manawaduge Supun", ""], ["Kebede", "Temesguen Messay", ""]]}, {"id": "1908.05744", "submitter": "Sepehr Saadatmand", "authors": "Sepehr Saadatmand, Mohammad Saleh Sanjarinia, Pourya Shamsi, Mehdi\n  Ferdowsi, and Donald C. Wunsch", "title": "Heuristic Dynamic Programming for Adaptive Virtual Synchronous\n  Generators", "comments": "NAPS 2019 Conference. arXiv admin note: substantial text overlap with\n  arXiv:1908.05191; text overlap with arXiv:1908.05199", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a neural network heuristic dynamic programing (HDP) is used for\noptimal control of the virtual inertia based control of grid connected three\nphase inverters. It is shown that the conventional virtual inertia controllers\nare not suited for non inductive grids. A neural network based controller is\nproposed to adapt to any impedance angle. Applying an adaptive dynamic\nprogramming controller instead of a supervised controlled method enables the\nsystem to adjust itself to different conditions. The proposed HDP consists of\ntwo subnetworks, critic network and action network. These networks can be\ntrained during the same training cycle to decrease the training time. The\nsimulation results confirm that the proposed neural network HDP controller\nperforms better than the traditional direct fed voltage and reactive power\ncontrollers in virtual inertia control schemes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 16:12:58 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Saadatmand", "Sepehr", ""], ["Sanjarinia", "Mohammad Saleh", ""], ["Shamsi", "Pourya", ""], ["Ferdowsi", "Mehdi", ""], ["Wunsch", "Donald C.", ""]]}, {"id": "1908.05750", "submitter": "Neeraj Battan", "authors": "Neeraj Battan, Abbhinav Venkat and Avinash Sharma", "title": "DeepHuMS: Deep Human Motion Signature for 3D Skeletal Sequences", "comments": "Under Review, Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D Human Motion Indexing and Retrieval is an interesting problem due to the\nrise of several data-driven applications aimed at analyzing and/or re-utilizing\n3D human skeletal data, such as data-driven animation, analysis of sports\nbio-mechanics, human surveillance etc. Spatio-temporal articulations of humans,\nnoisy/missing data, different speeds of the same motion etc. make it\nchallenging and several of the existing state of the art methods use hand-craft\nfeatures along with optimization based or histogram based comparison in order\nto perform retrieval. Further, they demonstrate it only for very small datasets\nand few classes. We make a case for using a learned representation that should\nrecognize the motion as well as enforce a discriminative ranking. To that end,\nwe propose, a 3D human motion descriptor learned using a deep network. Our\nlearned embedding is generalizable and applicable to real-world data -\naddressing the aforementioned challenges and further enables sub-motion\nsearching in its embedding space using another network. Our model exploits the\ninter-class similarity using trajectory cues, and performs far superior in a\nself-supervised setting. State of the art results on all these fronts is shown\non two large scale 3D human motion datasets - NTU RGB+D and HDM05.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 20:34:22 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 20:08:12 GMT"}, {"version": "v3", "created": "Sun, 8 Dec 2019 04:18:14 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Battan", "Neeraj", ""], ["Venkat", "Abbhinav", ""], ["Sharma", "Avinash", ""]]}, {"id": "1908.05751", "submitter": "Johannes G\\\"unther", "authors": "Johannes G\\\"unther, Nadia M. Ady, Alex Kearney, Michael R. Dawson,\n  Patrick M. Pilarski", "title": "Examining the Use of Temporal-Difference Incremental Delta-Bar-Delta for\n  Real-World Predictive Knowledge Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictions and predictive knowledge have seen recent success in improving\nnot only robot control but also other applications ranging from industrial\nprocess control to rehabilitation. A property that makes these predictive\napproaches well suited for robotics is that they can be learned online and\nincrementally through interaction with the environment. However, a remaining\nchallenge for many prediction-learning approaches is an appropriate choice of\nprediction-learning parameters, especially parameters that control the\nmagnitude of a learning machine's updates to its predictions (the learning rate\nor step size). To begin to address this challenge, we examine the use of online\nstep-size adaptation using a sensor-rich robotic arm. Our method of choice,\nTemporal-Difference Incremental Delta-Bar-Delta (TIDBD), learns and adapts step\nsizes on a feature level; importantly, TIDBD allows step-size tuning and\nrepresentation learning to occur at the same time. We show that TIDBD is a\npractical alternative for classic Temporal-Difference (TD) learning via an\nextensive parameter search. Both approaches perform comparably in terms of\npredicting future aspects of a robotic data stream. Furthermore, the use of a\nstep-size adaptation method like TIDBD appears to allow a system to\nautomatically detect and characterize common sensor failures in a robotic\napplication. Together, these results promise to improve the ability of robotic\ndevices to learn from interactions with their environments in a robust way,\nproviding key capabilities for autonomous agents and robots.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 20:42:19 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 18:45:15 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["G\u00fcnther", "Johannes", ""], ["Ady", "Nadia M.", ""], ["Kearney", "Alex", ""], ["Dawson", "Michael R.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1908.05759", "submitter": "Mohammad Shojafar", "authors": "Rahim Taheri, Meysam Ghahramani, Reza Javidan, Mohammad Shojafar,\n  Zahra Pooranian, Mauro Conti", "title": "Similarity-based Android Malware Detection Using Hamming Distance of\n  Static Binary Features", "comments": "20 pages, 8 figures, 11 tables, FGCS Elsevier journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we develop four malware detection methods using Hamming\ndistance to find similarity between samples which are first nearest neighbors\n(FNN), all nearest neighbors (ANN), weighted all nearest neighbors (WANN), and\nk-medoid based nearest neighbors (KMNN). In our proposed methods, we can\ntrigger the alarm if we detect an Android app is malicious. Hence, our\nsolutions help us to avoid the spread of detected malware on a broader scale.\nWe provide a detailed description of the proposed detection methods and related\nalgorithms. We include an extensive analysis to asses the suitability of our\nproposed similarity-based detection methods. In this way, we perform our\nexperiments on three datasets, including benign and malware Android apps like\nDrebin, Contagio, and Genome. Thus, to corroborate the actual effectiveness of\nour classifier, we carry out performance comparisons with some state-of-the-art\nclassification and malware detection algorithms, namely Mixed and Separated\nsolutions, the program dissimilarity measure based on entropy (PDME) and the\nFalDroid algorithms. We test our experiments in a different type of features:\nAPI, intent, and permission features on these three datasets. The results\nconfirm that accuracy rates of proposed algorithms are more than 90% and in\nsome cases (i.e., considering API features) are more than 99%, and are\ncomparable with existing state-of-the-art solutions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:53:54 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 07:26:15 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Taheri", "Rahim", ""], ["Ghahramani", "Meysam", ""], ["Javidan", "Reza", ""], ["Shojafar", "Mohammad", ""], ["Pooranian", "Zahra", ""], ["Conti", "Mauro", ""]]}, {"id": "1908.05762", "submitter": "Hamed Shahbazi", "authors": "Hamed Shahbazi, Xiaoli Z. Fern, Reza Ghaeini, Rasha Obeidat and Prasad\n  Tadepalli", "title": "Entity-aware ELMo: Learning Contextual Entity Representation for Entity\n  Disambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new local entity disambiguation system. The key to our system is\na novel approach for learning entity representations. In our approach we learn\nan entity aware extension of Embedding for Language Model (ELMo) which we call\nEntity-ELMo (E-ELMo). Given a paragraph containing one or more named entity\nmentions, each mention is first defined as a function of the entire paragraph\n(including other mentions), then they predict the referent entities. Utilizing\nE-ELMo for local entity disambiguation, we outperform all of the\nstate-of-the-art local and global models on the popular benchmarks by improving\nabout 0.5\\% on micro average accuracy for AIDA test-b with Yago candidate set.\nThe evaluation setup of the training data and candidate set are the same as our\nbaselines for fair comparison.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 03:51:25 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 16:49:24 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Shahbazi", "Hamed", ""], ["Fern", "Xiaoli Z.", ""], ["Ghaeini", "Reza", ""], ["Obeidat", "Rasha", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1908.05763", "submitter": "Chinnadhurai Sankar", "authors": "Chinnadhurai Sankar, Sujith Ravi, Zornitsa Kozareva", "title": "On-Device Text Representations Robust To Misspellings via Projections", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a strong interest in developing natural language\napplications that live on personal devices such as mobile phones, watches and\nIoT with the objective to preserve user privacy and have low memory. Advances\nin Locality-Sensitive Hashing (LSH)-based projection networks have demonstrated\nstate-of-the-art performance in various classification tasks without explicit\nword (or word-piece) embedding lookup tables by computing on-the-fly text\nrepresentations. In this paper, we show that the projection based neural\nclassifiers are inherently robust to misspellings and perturbations of the\ninput text. We empirically demonstrate that the LSH projection based\nclassifiers are more robust to common misspellings compared to BiLSTMs (with\nboth word-piece & word-only tokenization) and fine-tuned BERT based methods.\nWhen subject to misspelling attacks, LSH projection based classifiers had a\nsmall average accuracy drop of 2.94% across multiple classifications tasks,\nwhile the fine-tuned BERT model accuracy had a significant drop of 11.44%.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:48:07 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 08:20:32 GMT"}, {"version": "v3", "created": "Sat, 24 Apr 2021 00:34:01 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Sankar", "Chinnadhurai", ""], ["Ravi", "Sujith", ""], ["Kozareva", "Zornitsa", ""]]}, {"id": "1908.05764", "submitter": "Iris Huijben", "authors": "Iris A.M. Huijben, Bastiaan S. Veeling, Kees Janse, Massimo Mischi,\n  and Ruud J.G. van Sloun", "title": "Learning Sub-Sampling and Signal Recovery with Applications in\n  Ultrasound Imaging", "comments": null, "journal-ref": "in IEEE Transactions on Medical Imaging, vol. 39, pp. 3955-3966,\n  Dec. 2020", "doi": "10.1109/TMI.2020.3008501", "report-no": "12", "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limitations on bandwidth and power consumption impose strict bounds on data\nrates of diagnostic imaging systems. Consequently, the design of suitable (i.e.\ntask- and data-aware) compression and reconstruction techniques has attracted\nconsiderable attention in recent years. Compressed sensing emerged as a popular\nframework for sparse signal reconstruction from a small set of compressed\nmeasurements. However, typical compressed sensing designs measure a\n(non)linearly weighted combination of all input signal elements, which poses\npractical challenges. These designs are also not necessarily task-optimal. In\naddition, real-time recovery is hampered by the iterative and time-consuming\nnature of sparse recovery algorithms. Recently, deep learning methods have\nshown promise for fast recovery from compressed measurements, but the design of\nadequate and practical sensing strategies remains a challenge. Here, we propose\na deep learning solution termed Deep Probabilistic Sub-sampling (DPS), that\nlearns a task-driven sub-sampling pattern, while jointly training a subsequent\ntask model. Once learned, the task-based sub-sampling patterns are fixed and\nstraightforwardly implementable, e.g. by non-uniform analog-to-digital\nconversion, sparse array design, or slow-time ultrasound pulsing schemes. The\neffectiveness of our framework is demonstrated in-silico for sparse signal\nrecovery from partial Fourier measurements, and in-vivo for both anatomical\nimage and tissue-motion (Doppler) reconstruction from sub-sampled medical\nultrasound imaging data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 21:03:42 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 09:21:15 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 08:12:36 GMT"}, {"version": "v4", "created": "Tue, 12 May 2020 08:23:04 GMT"}, {"version": "v5", "created": "Fri, 23 Oct 2020 10:45:37 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Huijben", "Iris A. M.", ""], ["Veeling", "Bastiaan S.", ""], ["Janse", "Kees", ""], ["Mischi", "Massimo", ""], ["van Sloun", "Ruud J. G.", ""]]}, {"id": "1908.05767", "submitter": "Weichi Yao", "authors": "Weichi Yao, Afonso S. Bandeira, Soledad Villar", "title": "Experimental performance of graph neural networks on random instances of\n  max-cut", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note explores the applicability of unsupervised machine learning\ntechniques towards hard optimization problems on random inputs. In particular\nwe consider Graph Neural Networks (GNNs) -- a class of neural networks designed\nto learn functions on graphs -- and we apply them to the max-cut problem on\nrandom regular graphs. We focus on the max-cut problem on random regular graphs\nbecause it is a fundamental problem that has been widely studied. In\nparticular, even though there is no known explicit solution to compare the\noutput of our algorithm to, we can leverage the known asymptotics of the\noptimal max-cut value in order to evaluate the performance of the GNNs.\n  In order to put the performance of the GNNs in context, we compare it with\nthe classical semidefinite relaxation approach by Goemans and Williamson~(SDP),\nand with extremal optimization, which is a local optimization heuristic from\nthe statistical physics literature. The numerical results we obtain indicate\nthat, surprisingly, Graph Neural Networks attain comparable performance to the\nGoemans and Williamson SDP. We also observe that extremal optimization\nconsistently outperforms the other two methods. Furthermore, the performances\nof the three methods present similar patterns, that is, for sparser, and for\nlarger graphs, the size of the found cuts are closer to the asymptotic optimal\nmax-cut value.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 21:15:49 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Yao", "Weichi", ""], ["Bandeira", "Afonso S.", ""], ["Villar", "Soledad", ""]]}, {"id": "1908.05783", "submitter": "Laurent Risser", "authors": "Laurent Risser, Quentin Vincenot, Jean-Michel Loubes", "title": "Tackling Algorithmic Bias in Neural-Network Classifiers using\n  Wasserstein-2 Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasingly common use of neural network classifiers in industrial and\nsocial applications of image analysis has allowed impressive progress these\nlast years. Such methods are however sensitive to algorithmic bias, i.e. to an\nunder- or an over-representation of positive predictions or to higher\nprediction errors in specific subgroups of images. We then introduce in this\npaper a new method to temper the algorithmic bias in Neural-Network based\nclassifiers. Our method is Neural-Network architecture agnostic and scales well\nto massive training sets of images. It indeed only overloads the loss function\nwith a Wasserstein-2 based regularization term whose gradient can be computed\nat a reasonable algorithmic cost. This makes it possible to use our regularised\nloss with standard stochastic gradient-descent strategies. The good behavior of\nour method is assessed on the Adult census, MNIST, and CelebA datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 22:27:29 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:20:46 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Risser", "Laurent", ""], ["Vincenot", "Quentin", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "1908.05787", "submitter": "E M Wasifur Rahman Chowdhury", "authors": "Wasifur Rahman, Md. Kamrul Hasan, Sangwu Lee, Amir Zadeh, Chengfeng\n  Mao, Louis-Philippe Morency, Ehsan Hoque", "title": "Integrating Multimodal Information in Large Pretrained Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent Transformer-based contextual word representations, including BERT and\nXLNet, have shown state-of-the-art performance in multiple disciplines within\nNLP. Fine-tuning the trained contextual models on task-specific datasets has\nbeen the key to achieving superior performance downstream. While fine-tuning\nthese pre-trained models is straightforward for lexical applications\n(applications with only language modality), it is not trivial for multimodal\nlanguage (a growing area in NLP focused on modeling face-to-face\ncommunication). Pre-trained models don't have the necessary components to\naccept two extra modalities of vision and acoustic. In this paper, we proposed\nan attachment to BERT and XLNet called Multimodal Adaptation Gate (MAG). MAG\nallows BERT and XLNet to accept multimodal nonverbal data during fine-tuning.\nIt does so by generating a shift to internal representation of BERT and XLNet;\na shift that is conditioned on the visual and acoustic modalities. In our\nexperiments, we study the commonly used CMU-MOSI and CMU-MOSEI datasets for\nmultimodal sentiment analysis. Fine-tuning MAG-BERT and MAG-XLNet significantly\nboosts the sentiment analysis performance over previous baselines as well as\nlanguage-only fine-tuning of BERT and XLNet. On the CMU-MOSI dataset, MAG-XLNet\nachieves human-level multimodal sentiment analysis performance for the first\ntime in the NLP community.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 22:51:21 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 16:50:11 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 13:52:22 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Rahman", "Wasifur", ""], ["Hasan", "Md. Kamrul", ""], ["Lee", "Sangwu", ""], ["Zadeh", "Amir", ""], ["Mao", "Chengfeng", ""], ["Morency", "Louis-Philippe", ""], ["Hoque", "Ehsan", ""]]}, {"id": "1908.05792", "submitter": "Wissam Sid-Lakhdar", "authors": "Wissam M. Sid-Lakhdar, Mohsen Mahmoudi Aznaveh, Xiaoye S. Li, James W.\n  Demmel", "title": "Multitask and Transfer Learning for Autotuning Exascale Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning and transfer learning have proven to be useful in the\nfield of machine learning when additional knowledge is available to help a\nprediction task. We aim at deriving methods following these paradigms for use\nin autotuning, where the goal is to find the optimal performance parameters of\nan application treated as a black-box function. We show comparative results\nwith state-of-the-art autotuning techniques. For instance, we observe an\naverage $1.5x$ improvement of the application runtime compared to the OpenTuner\nand HpBandSter autotuners. We explain how our approaches can be more suitable\nthan some state-of-the-art autotuners for the tuning of any application in\ngeneral and of expensive exascale applications in particular.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 23:14:54 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sid-Lakhdar", "Wissam M.", ""], ["Aznaveh", "Mohsen Mahmoudi", ""], ["Li", "Xiaoye S.", ""], ["Demmel", "James W.", ""]]}, {"id": "1908.05814", "submitter": "Sanae Amani", "authors": "Sanae Amani, Mahnoosh Alizadeh, Christos Thrampoulidis", "title": "Linear Stochastic Bandits Under Safety Constraints", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit algorithms have various application in safety-critical systems, where\nit is important to respect the system constraints that rely on the bandit's\nunknown parameters at every round. In this paper, we formulate a linear\nstochastic multi-armed bandit problem with safety constraints that depend\n(linearly) on an unknown parameter vector. As such, the learner is unable to\nidentify all safe actions and must act conservatively in ensuring that her\nactions satisfy the safety constraint at all rounds (at least with high\nprobability). For these bandits, we propose a new UCB-based algorithm called\nSafe-LUCB, which includes necessary modifications to respect safety\nconstraints. The algorithm has two phases. During the pure exploration phase\nthe learner chooses her actions at random from a restricted set of safe actions\nwith the goal of learning a good approximation of the entire unknown safe set.\nOnce this goal is achieved, the algorithm begins a safe\nexploration-exploitation phase where the learner gradually expands their\nestimate of the set of safe actions while controlling the growth of regret. We\nprovide a general regret bound for the algorithm, as well as a problem\ndependent bound that is connected to the location of the optimal action within\nthe safe set. We then propose a modified heuristic that exploits our problem\ndependent analysis to improve the regret.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 02:08:24 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Amani", "Sanae", ""], ["Alizadeh", "Mahnoosh", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "1908.05818", "submitter": "Bharath Sriperumbudur", "authors": "Samory Kpotufe and Bharath K. Sriperumbudur", "title": "Gaussian Sketching yields a J-L Lemma in RKHS", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution of the paper is to show that Gaussian sketching of a\nkernel-Gram matrix $\\boldsymbol K$ yields an operator whose counterpart in an\nRKHS $\\mathcal H$, is a \\emph{random projection} operator---in the spirit of\nJohnson-Lindenstrauss (J-L) lemma. To be precise, given a random matrix $Z$\nwith i.i.d. Gaussian entries, we show that a sketch $Z\\boldsymbol{K}$\ncorresponds to a particular random operator in (infinite-dimensional) Hilbert\nspace $\\mathcal H$ that maps functions $f \\in \\mathcal H$ to a low-dimensional\nspace $\\mathbb R^d$, while preserving a weighted RKHS inner-product of the form\n$\\langle f, g \\rangle_{\\Sigma} \\doteq \\langle f, \\Sigma^3 g \\rangle_{\\mathcal\nH}$, where $\\Sigma$ is the \\emph{covariance} operator induced by the data\ndistribution. In particular, under similar assumptions as in kernel PCA (KPCA),\nor kernel $k$-means (K-$k$-means), well-separated subsets of feature-space\n$\\{K(\\cdot, x): x \\in \\cal X\\}$ remain well-separated after such operation,\nwhich suggests similar benefits as in KPCA and/or K-$k$-means, albeit at the\nmuch cheaper cost of a random projection. In particular, our convergence rates\nsuggest that, given a large dataset $\\{X_i\\}_{i=1}^N$ of size $N$, we can build\nthe Gram matrix $\\boldsymbol K$ on a much smaller subsample of size $n\\ll N$,\nso that the sketch $Z\\boldsymbol K$ is very cheap to obtain and subsequently\napply as a projection operator on the original data $\\{X_i\\}_{i=1}^N$. We\nverify these insights empirically on synthetic data, and on real-world\nclustering applications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 02:36:25 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 01:58:48 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Kpotufe", "Samory", ""], ["Sriperumbudur", "Bharath K.", ""]]}, {"id": "1908.05823", "submitter": "Meng Tang S", "authors": "Meng Tang, Yimin Liu, Louis J. Durlofsky", "title": "A deep-learning-based surrogate model for data assimilation in dynamic\n  subsurface flow problems", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109456", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep-learning-based surrogate model is developed and applied for predicting\ndynamic subsurface flow in channelized geological models. The surrogate model\nis based on deep convolutional and recurrent neural network architectures,\nspecifically a residual U-Net and a convolutional long short term memory\nrecurrent network. Training samples entail global pressure and saturation maps,\nat a series of time steps, generated by simulating oil-water flow in many (1500\nin our case) realizations of a 2D channelized system. After training, the\n`recurrent R-U-Net' surrogate model is shown to be capable of accurately\npredicting dynamic pressure and saturation maps and well rates (e.g.,\ntime-varying oil and water rates at production wells) for new geological\nrealizations. Assessments demonstrating high surrogate-model accuracy are\npresented for an individual geological realization and for an ensemble of 500\ntest geomodels. The surrogate model is then used for the challenging problem of\ndata assimilation (history matching) in a channelized system. For this study,\nposterior reservoir models are generated using the randomized maximum\nlikelihood method, with the permeability field represented using the recently\ndeveloped CNN-PCA parameterization. The flow responses required during the data\nassimilation procedure are provided by the recurrent R-U-Net. The overall\napproach is shown to lead to substantial reduction in prediction uncertainty.\nHigh-fidelity numerical simulation results for the posterior geomodels\n(generated by the surrogate-based data assimilation procedure) are shown to be\nin essential agreement with the recurrent R-U-Net predictions. The accuracy and\ndramatic speedup provided by the surrogate model suggest that it may eventually\nenable the application of more formal posterior sampling methods in realistic\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 03:02:34 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Tang", "Meng", ""], ["Liu", "Yimin", ""], ["Durlofsky", "Louis J.", ""]]}, {"id": "1908.05825", "submitter": "Riddhish Bhalodia", "authors": "Riddhish Bhalodia and Shireen Y. Elhabian and Ladislav Kavan and Ross\n  T. Whitaker", "title": "A Cooperative Autoencoder for Population-Based Regularization of CNN\n  Image Registration", "comments": "To appear in MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial transformations are enablers in a variety of medical image analysis\napplications that entail aligning images to a common coordinate systems.\nPopulation analysis of such transformations is expected to capture the\nunderlying image and shape variations, and hence these transformations are\nrequired to produce anatomically feasible correspondences. This is usually\nenforced through some smoothness-based generic regularization on deformation\nfield. Alternatively, population-based regularization has been shown to produce\nanatomically accurate correspondences in cases where anatomically unaware\n(i.e., data independent) fail. Recently, deep networks have been for\nunsupervised image registration, these methods are computationally faster and\nmaintains the accuracy of state of the art methods. However, these networks use\nsmoothness penalty on deformation fields and ignores population-level\nstatistics of the transformations. We propose a novel neural network\narchitecture that simultaneously learns and uses the population-level\nstatistics of the spatial transformations to regularize the neural networks for\nunsupervised image registration. This regularization is in the form of a\nbottleneck autoencoder, which encodes the population level information of the\ndeformation fields in a low-dimensional manifold. The proposed architecture\nproduces deformation fields that describe the population-level features and\nassociated correspondences in an anatomically relevant manner and are\nstatistically compact relative to the state-of-the-art approaches while\nmaintaining computational efficiency. We demonstrate the efficacy of the\nproposed architecture on synthetic data sets, as well as 2D and 3D medical\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 03:06:19 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 14:44:47 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Bhalodia", "Riddhish", ""], ["Elhabian", "Shireen Y.", ""], ["Kavan", "Ladislav", ""], ["Whitaker", "Ross T.", ""]]}, {"id": "1908.05840", "submitter": "Ho Young Jhoo", "authors": "Hyunsu Kim, Ho Young Jhoo, Eunhyeok Park, and Sungjoo Yoo", "title": "Tag2Pix: Line Art Colorization Using Text Tag With SECat and Changing\n  Loss", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Line art colorization is expensive and challenging to automate. A GAN\napproach is proposed, called Tag2Pix, of line art colorization which takes as\ninput a grayscale line art and color tag information and produces a quality\ncolored image. First, we present the Tag2Pix line art colorization dataset. A\ngenerator network is proposed which consists of convolutional layers to\ntransform the input line art, a pre-trained semantic extraction network, and an\nencoder for input color information. The discriminator is based on an auxiliary\nclassifier GAN to classify the tag information as well as genuineness. In\naddition, we propose a novel network structure called SECat, which makes the\ngenerator properly colorize even small features such as eyes, and also suggest\na novel two-step training method where the generator and discriminator first\nlearn the notion of object and shape and then, based on the learned notion,\nlearn colorization, such as where and how to place which color. We present both\nquantitative and qualitative evaluations which prove the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 04:24:38 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Kim", "Hyunsu", ""], ["Jhoo", "Ho Young", ""], ["Park", "Eunhyeok", ""], ["Yoo", "Sungjoo", ""]]}, {"id": "1908.05841", "submitter": "Tai-Long He", "authors": "Tai-Long He, Dylan B. A. Jones, Binxuan Huang, Yuyang Liu, Kazuyuki\n  Miyazaki, Zhe Jiang, E. Charlie White, Helen M. Worden, John R. Worden", "title": "Recurrent U-net: Deep learning to predict daily summertime ozone in the\n  United States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.CV cs.LG physics.chem-ph physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a hybrid deep learning model to predict June-July-August (JJA) daily\nmaximum 8-h average (MDA8) surface ozone concentrations in the US. A set of\nmeteorological fields from the ERA-Interim reanalysis as well as monthly mean\nNO$_x$ emissions from the Community Emissions Data System (CEDS) inventory are\nselected as predictors. Ozone measurements from the US Environmental Protection\nAgency (EPA) Air Quality System (AQS) from 1980 to 2009 are used to train the\nmodel, whereas data from 2010 to 2014 are used to evaluate the performance of\nthe model. The model captures well daily, seasonal and interannual variability\nin MDA8 ozone across the US. Feature maps show that the model captures\nteleconnections between MDA8 ozone and the meteorological fields, which are\nresponsible for driving the ozone dynamics. We used the model to evaluate\nrecent trends in NO$_x$ emissions in the US and found that the trend in the EPA\nemission inventory produced the largest negative bias in MDA8 ozone between\n2010-2016. The top-down emission trends from the Tropospheric Chemistry\nReanalysis (TCR-2), which is based on satellite observations, produced\npredictions in best agreement with observations. In urban regions, the trend in\nAQS NO$_2$ observations provided ozone predictions in agreement with\nobservations, whereas in rural regions the satellite-derived trends produced\nthe best agreement. In both rural and urban regions the EPA trend resulted in\nthe largest negative bias in predicted ozone. Our results suggest that the EPA\ninventory is overestimating the reductions in NO$_x$ emissions and that the\nsatellite-derived trend reflects the influence of reductions in NO$_x$\nemissions as well as changes in background NO$_x$. Our results demonstrate the\nsignificantly greater predictive capability that the deep learning model\nprovides over conventional atmospheric chemical transport models for air\nquality analyses.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 04:32:00 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["He", "Tai-Long", ""], ["Jones", "Dylan B. A.", ""], ["Huang", "Binxuan", ""], ["Liu", "Yuyang", ""], ["Miyazaki", "Kazuyuki", ""], ["Jiang", "Zhe", ""], ["White", "E. Charlie", ""], ["Worden", "Helen M.", ""], ["Worden", "John R.", ""]]}, {"id": "1908.05863", "submitter": "Tianhao Qiao", "authors": "Tianhao Qiao, Shunqing Zhang, Zhichao Zhang, Shan Cao, Shugong Xu", "title": "Sub-Spectrogram Segmentation for Environmental Sound Classification via\n  Convolutional Recurrent Neural Network and Score Level Fusion", "comments": "accepted in the 2019 IEEE International Workshop on Signal Processing\n  Systems (SiPS2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environmental Sound Classification (ESC) is an important and challenging\nproblem, and feature representation is a critical and even decisive factor in\nESC. Feature representation ability directly affects the accuracy of sound\nclassification. Therefore, the ESC performance is heavily dependent on the\neffectiveness of representative features extracted from the environmental\nsounds. In this paper, we propose a subspectrogram segmentation based ESC\nclassification framework. In addition, we adopt the proposed Convolutional\nRecurrent Neural Network (CRNN) and score level fusion to jointly improve the\nclassification accuracy. Extensive truncation schemes are evaluated to find the\noptimal number and the corresponding band ranges of sub-spectrograms. Based on\nthe numerical experiments, the proposed framework can achieve 81.9% ESC\nclassification accuracy on the public dataset ESC-50, which provides 9.1%\naccuracy improvement over traditional baseline schemes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 06:39:31 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Qiao", "Tianhao", ""], ["Zhang", "Shunqing", ""], ["Zhang", "Zhichao", ""], ["Cao", "Shan", ""], ["Xu", "Shugong", ""]]}, {"id": "1908.05864", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "Generating Random Parameters in Feedforward Neural Networks with Random\n  Hidden Nodes: Drawbacks of the Standard Method and How to Improve It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard method of generating random weights and biases in feedforward\nneural networks with random hidden nodes, selects them both from the uniform\ndistribution over the same fixed interval. In this work, we show the drawbacks\nof this approach and propose a new method of generating random parameters. This\nmethod ensures the most nonlinear fragments of sigmoids, which are most useful\nin modeling target function nonlinearity, are kept in the input hypercube. In\naddition, we show how to generate activation functions with uniformly\ndistributed slope angles.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 06:43:33 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 12:26:38 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1908.05867", "submitter": "Zhaoyang Zhang", "authors": "Zhaoyang Zhang, Jingyu Li, Wenqi Shao, Zhanglin Peng, Ruimao Zhang,\n  Xiaogang Wang, Ping Luo", "title": "Differentiable Learning-to-Group Channels via Groupable Convolutional\n  Neural Networks", "comments": "accepted by ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group convolution, which divides the channels of ConvNets into groups, has\nachieved impressive improvement over the regular convolution operation.\nHowever, existing models, eg. ResNeXt, still suffers from the sub-optimal\nperformance due to manually defining the number of groups as a constant over\nall of the layers. Toward addressing this issue, we present Groupable ConvNet\n(GroupNet) built by using a novel dynamic grouping convolution (DGConv)\noperation, which is able to learn the number of groups in an end-to-end manner.\nThe proposed approach has several appealing benefits. (1) DGConv provides a\nunified convolution representation and covers many existing convolution\noperations such as regular dense convolution, group convolution, and depthwise\nconvolution. (2) DGConv is a differentiable and flexible operation which learns\nto perform various convolutions from training data. (3) GroupNet trained with\nDGConv learns different number of groups for different convolution layers.\nExtensive experiments demonstrate that GroupNet outperforms its counterparts\nsuch as ResNet and ResNeXt in terms of accuracy and computational complexity.\nWe also present introspection and reproducibility study, for the first time,\nshowing the learning dynamics of training group numbers.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 06:50:33 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 08:06:53 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Zhang", "Zhaoyang", ""], ["Li", "Jingyu", ""], ["Shao", "Wenqi", ""], ["Peng", "Zhanglin", ""], ["Zhang", "Ruimao", ""], ["Wang", "Xiaogang", ""], ["Luo", "Ping", ""]]}, {"id": "1908.05874", "submitter": "Dan Nguyen", "authors": "Dan Nguyen, Rafe McBeth, Azar Sadeghnejad Barkousaraie, Gyanendra\n  Bohara, Chenyang Shen, Xun Jia, Steve Jiang", "title": "Incorporating human and learned domain knowledge into training deep\n  neural networks: A differentiable dose volume histogram and adversarial\n  inspired framework for generating Pareto optimal dose distributions in\n  radiation therapy", "comments": null, "journal-ref": null, "doi": "10.1002/mp.13955", "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel domain specific loss, which is a differentiable loss\nfunction based on the dose volume histogram, and combine it with an adversarial\nloss for the training of deep neural networks to generate Pareto optimal dose\ndistributions. The mean squared error (MSE) loss, dose volume histogram (DVH)\nloss, and adversarial (ADV) loss were used to train 4 instances of the neural\nnetwork model: 1) MSE, 2) MSE+ADV, 3) MSE+DVH, and 4) MSE+DVH+ADV. 70 prostate\npatients were acquired, and the dose influence arrays were calculated for each\npatient. 1200 Pareto surface plans per patient were generated by\npseudo-randomizing the tradeoff weights (84,000 plans total). We divided the\ndata into 54 training, 6 validation, and 10 testing patients. Each model was\ntrained for 100,000 iterations, with a batch size of 2. The prediction time of\neach model is 0.052 seconds. Quantitatively, the MSE+DVH+ADV model had the\nlowest prediction error of 0.038 (conformation), 0.026 (homogeneity), 0.298\n(R50), 1.65% (D95), 2.14% (D98), 2.43% (D99). The MSE model had the worst\nprediction error of 0.134 (conformation), 0.041 (homogeneity), 0.520 (R50),\n3.91% (D95), 4.33% (D98), 4.60% (D99). For both the mean dose PTV error and the\nmax dose PTV, Body, Bladder and rectum error, the MSE+DVH+ADV outperformed all\nother models. All model's predictions have an average mean and max dose error\nless than 2.8% and 4.2%, respectively. Expert human domain specific knowledge\ncan be the largest driver in the performance improvement, and adversarial\nlearning can be used to further capture nuanced features. The real-time\nprediction capabilities allow for a physician to quickly navigate the tradeoff\nspace, and produce a dose distribution as a tangible endpoint for the\ndosimetrist to use for planning. This can considerably reduce the treatment\nplanning time, allowing for clinicians to focus their efforts on challenging\ncases.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 07:45:38 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 12:19:23 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Nguyen", "Dan", ""], ["McBeth", "Rafe", ""], ["Barkousaraie", "Azar Sadeghnejad", ""], ["Bohara", "Gyanendra", ""], ["Shen", "Chenyang", ""], ["Jia", "Xun", ""], ["Jiang", "Steve", ""]]}, {"id": "1908.05885", "submitter": "Rasmus Br{\\o}ndum", "authors": "Rasmus Froberg Br{\\o}ndum, Thomas Yssing Michaelsen, Martin B{\\o}gsted", "title": "Regression on imperfect class labels derived by unsupervised clustering", "comments": null, "journal-ref": null, "doi": "10.1093/bib/bbaa014", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outcome regressed on class labels identified by unsupervised clustering is\ncustom in many applications. However, it is common to ignore the\nmisclassification of class labels caused by the learning algorithm, which\npotentially leads to serious bias of the estimated effect parameters. Due to\nits generality we suggest to redress the situation by use of the simulation and\nextrapolation method. Performance is illustrated by simulated data from\nGaussian mixture models. Finally, we apply our method to a study which\nregressed overall survival on class labels derived from unsupervised clustering\nof gene expression data from bone marrow samples of multiple myeloma patients.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 08:26:03 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Br\u00f8ndum", "Rasmus Froberg", ""], ["Michaelsen", "Thomas Yssing", ""], ["B\u00f8gsted", "Martin", ""]]}, {"id": "1908.05891", "submitter": "Xin Yao", "authors": "Xin Yao, Tianchi Huang, Chenglei Wu, Rui-Xiao Zhang, Lifeng Sun", "title": "Federated Learning with Additional Mechanisms on Clients to Reduce\n  Communication Costs", "comments": "This is a combination version of our papers in VCIP 2018 and ICIP\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) enables on-device training over distributed networks\nconsisting of a massive amount of modern smart devices, such as smartphones and\nIoT (Internet of Things) devices. However, the leading optimization algorithm\nin such settings, i.e., federated averaging (FedAvg), suffers from heavy\ncommunication costs and the inevitable performance drop, especially when the\nlocal data is distributed in a non-IID way. To alleviate this problem, we\npropose two potential solutions by introducing additional mechanisms to the\non-device training.\n  The first (FedMMD) is adopting a two-stream model with the MMD (Maximum Mean\nDiscrepancy) constraint instead of a single model in vanilla FedAvg to be\ntrained on devices. Experiments show that the proposed method outperforms\nbaselines, especially in non-IID FL settings, with a reduction of more than 20%\nin required communication rounds.\n  The second is FL with feature fusion (FedFusion). By aggregating the features\nfrom both the local and global models, we achieve higher accuracy at fewer\ncommunication costs. Furthermore, the feature fusion modules offer better\ninitialization for newly incoming clients and thus speed up the process of\nconvergence. Experiments in popular FL scenarios show that our FedFusion\noutperforms baselines in both accuracy and generalization ability while\nreducing the number of required communication rounds by more than 60%.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 08:51:27 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 16:33:58 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yao", "Xin", ""], ["Huang", "Tianchi", ""], ["Wu", "Chenglei", ""], ["Zhang", "Rui-Xiao", ""], ["Sun", "Lifeng", ""]]}, {"id": "1908.05895", "submitter": "Jihong Park", "authors": "Jihong Park, Shiqiang Wang, Anis Elgabli, Seungeun Oh, Eunjeong Jeong,\n  Han Cha, Hyesung Kim, Seong-Lyun Kim, Mehdi Bennis", "title": "Distilling On-Device Intelligence at the Network Edge", "comments": "7 pages, 6 figures; This work has been submitted to the IEEE for\n  possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Devices at the edge of wireless networks are the last mile data sources for\nmachine learning (ML). As opposed to traditional ready-made public datasets,\nthese user-generated private datasets reflect the freshest local environments\nin real time. They are thus indispensable for enabling mission-critical\nintelligent systems, ranging from fog radio access networks (RANs) to\ndriverless cars and e-Health wearables. This article focuses on how to distill\nhigh-quality on-device ML models using fog computing, from such user-generated\nprivate data dispersed across wirelessly connected devices. To this end, we\nintroduce communication-efficient and privacy-preserving distributed ML\nframeworks, termed fog ML (FML), wherein on-device ML models are trained by\nexchanging model parameters, model outputs, and surrogate data. We then present\nadvanced FML frameworks addressing wireless RAN characteristics, limited\non-device resources, and imbalanced data distributions. Our study suggests that\nthe full potential of FML can be reached by co-designing communication and\ndistributed ML operations while accounting for heterogeneous hardware\nspecifications, data characteristics, and user requirements.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 09:01:26 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Park", "Jihong", ""], ["Wang", "Shiqiang", ""], ["Elgabli", "Anis", ""], ["Oh", "Seungeun", ""], ["Jeong", "Eunjeong", ""], ["Cha", "Han", ""], ["Kim", "Hyesung", ""], ["Kim", "Seong-Lyun", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1908.05902", "submitter": "Sanchari Das", "authors": "Sanchari Das, Bingxing Wang, and L. Jean Camp", "title": "MFA is a Waste of Time! Understanding Negative Connotation Towards MFA\n  Applications via User Generated Content", "comments": "Proceedings of the Thirteenth International Symposium on Human\n  Aspects of Information Security & Assurance (HAISA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional single-factor authentication possesses several critical security\nvulnerabilities due to single-point failure feature. Multi-factor\nauthentication (MFA), intends to enhance security by providing additional\nverification steps. However, in practical deployment, users often experience\ndissatisfaction while using MFA, which leads to non-adoption. In order to\nunderstand the current design and usability issues with MFA, we analyze\naggregated user generated comments (N = 12,500) about application-based MFA\ntools from major distributors, such as, Amazon, Google Play, Apple App Store,\nand others. While some users acknowledge the security benefits of MFA, majority\nof them still faced problems with initial configuration, system design\nunderstanding, limited device compatibility, and risk trade-offs leading to\nnon-adoption of MFA. Based on these results, we provide actionable\nrecommendations in technological design, initial training, and risk\ncommunication to improve the adoption and user experience of MFA.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 09:15:56 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Das", "Sanchari", ""], ["Wang", "Bingxing", ""], ["Camp", "L. Jean", ""]]}, {"id": "1908.05915", "submitter": "Carolin Lawrence", "authors": "Carolin Lawrence, Bhushan Kotnis, Mathias Niepert", "title": "Attending to Future Tokens For Bidirectional Sequence Generation", "comments": "Conference on Empirical Methods in Natural Language Processing\n  (EMNLP), 2019, Hong Kong, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence generation is typically performed token-by-token and\nleft-to-right. Whenever a token is generated only previously produced tokens\nare taken into consideration. In contrast, for problems such as sequence\nclassification, bidirectional attention, which takes both past and future\ntokens into consideration, has been shown to perform much better. We propose to\nmake the sequence generation process bidirectional by employing special\nplaceholder tokens. Treated as a node in a fully connected graph, a placeholder\ntoken can take past and future tokens into consideration when generating the\nactual output token. We verify the effectiveness of our approach experimentally\non two conversational tasks where the proposed bidirectional model outperforms\ncompetitive baselines by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 10:00:45 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 13:50:11 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Lawrence", "Carolin", ""], ["Kotnis", "Bhushan", ""], ["Niepert", "Mathias", ""]]}, {"id": "1908.05932", "submitter": "Yuval Nirkin", "authors": "Yuval Nirkin, Yosi Keller and Tal Hassner", "title": "FSGAN: Subject Agnostic Face Swapping and Reenactment", "comments": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Face Swapping GAN (FSGAN) for face swapping and reenactment.\nUnlike previous work, FSGAN is subject agnostic and can be applied to pairs of\nfaces without requiring training on those faces. To this end, we describe a\nnumber of technical contributions. We derive a novel recurrent neural network\n(RNN)-based approach for face reenactment which adjusts for both pose and\nexpression variations and can be applied to a single image or a video sequence.\nFor video sequences, we introduce continuous interpolation of the face views\nbased on reenactment, Delaunay Triangulation, and barycentric coordinates.\nOccluded face regions are handled by a face completion network. Finally, we use\na face blending network for seamless blending of the two faces while preserving\ntarget skin color and lighting conditions. This network uses a novel Poisson\nblending loss which combines Poisson optimization with perceptual loss. We\ncompare our approach to existing state-of-the-art systems and show our results\nto be both qualitatively and quantitatively superior.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 11:16:22 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Nirkin", "Yuval", ""], ["Keller", "Yosi", ""], ["Hassner", "Tal", ""]]}, {"id": "1908.05959", "submitter": "Mauricio Orbes Arteaga", "authors": "Mauricio Orbes-Arteaga and Thomas Varsavsky and Carole H. Sudre and\n  Zach Eaton-Rosen and Lewis J. Haddow and Lauge S{\\o}rensen and Mads Nielsen\n  and Akshay Pai and S\\'ebastien Ourselin and Marc Modat and Parashkev Nachev\n  and M. Jorge Cardoso", "title": "Multi-Domain Adaptation in Brain MRI through Paired Consistency and\n  Adversarial Learning", "comments": "Accepted at 1st International Workshop on Domain Adaptation and\n  Representation Transfer held at MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning algorithms trained on medical images will often fail to\ngeneralize across changes in acquisition parameters. Recent work in domain\nadaptation addresses this challenge and successfully leverages labeled data in\na source domain to perform well on an unlabeled target domain. Inspired by\nrecent work in semi-supervised learning we introduce a novel method to adapt\nfrom one source domain to $n$ target domains (as long as there is paired data\ncovering all domains). Our multi-domain adaptation method utilises a\nconsistency loss combined with adversarial learning. We provide results on\nwhite matter lesion hyperintensity segmentation from brain MRIs using the\nMICCAI 2017 challenge data as the source domain and two target domains. The\nproposed method significantly outperforms other domain adaptation baselines.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:06:18 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 09:31:53 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Orbes-Arteaga", "Mauricio", ""], ["Varsavsky", "Thomas", ""], ["Sudre", "Carole H.", ""], ["Eaton-Rosen", "Zach", ""], ["Haddow", "Lewis J.", ""], ["S\u00f8rensen", "Lauge", ""], ["Nielsen", "Mads", ""], ["Pai", "Akshay", ""], ["Ourselin", "S\u00e9bastien", ""], ["Modat", "Marc", ""], ["Nachev", "Parashkev", ""], ["Cardoso", "M. Jorge", ""]]}, {"id": "1908.05968", "submitter": "Ryan McConville", "authors": "Ryan McConville, Raul Santos-Rodriguez, Robert J Piechocki, Ian\n  Craddock", "title": "N2D: (Not Too) Deep Clustering via Clustering the Local Manifold of an\n  Autoencoded Embedding", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep clustering has increasingly been demonstrating superiority over\nconventional shallow clustering algorithms. Deep clustering algorithms usually\ncombine representation learning with deep neural networks to achieve this\nperformance, typically optimizing a clustering and non-clustering loss. In such\ncases, an autoencoder is typically connected with a clustering network, and the\nfinal clustering is jointly learned by both the autoencoder and clustering\nnetwork. Instead, we propose to learn an autoencoded embedding and then search\nthis further for the underlying manifold. For simplicity, we then cluster this\nwith a shallow clustering algorithm, rather than a deeper network. We study a\nnumber of local and global manifold learning methods on both the raw data and\nautoencoded embedding, concluding that UMAP in our framework is best able to\nfind the most clusterable manifold in the embedding, suggesting local manifold\nlearning on an autoencoded embedding is effective for discovering higher\nquality discovering clusters. We quantitatively show across a range of image\nand time-series datasets that our method has competitive performance against\nthe latest deep clustering algorithms, including out-performing current\nstate-of-the-art on several. We postulate that these results show a promising\nresearch direction for deep clustering. The code can be found at\nhttps://github.com/rymc/n2d\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:34:18 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 16:08:13 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 11:02:36 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 15:57:51 GMT"}, {"version": "v5", "created": "Wed, 25 Sep 2019 15:33:08 GMT"}, {"version": "v6", "created": "Tue, 30 Jun 2020 07:57:15 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["McConville", "Ryan", ""], ["Santos-Rodriguez", "Raul", ""], ["Piechocki", "Robert J", ""], ["Craddock", "Ian", ""]]}, {"id": "1908.05972", "submitter": "Henrietta Rose Baker Mrs", "authors": "Henrietta Baker, Matthew R. Hallowell and Antoine J.-P. Tixier", "title": "AI-based Prediction of Independent Construction Safety Outcomes from\n  Universal Attributes", "comments": "Accepted for publication in Automation in Construction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper significantly improves on, and finishes to validate, an approach\nproposed in previous research in which safety outcomes were predicted from\nattributes with machine learning. Like in the original study, we use Natural\nLanguage Processing (NLP) to extract fundamental attributes from raw incident\nreports and machine learning models are trained to predict safety outcomes. The\noutcomes predicted here are injury severity, injury type, body part impacted,\nand incident type. However, unlike in the original study, safety outcomes were\nnot extracted via NLP but were provided by independent human annotations,\neliminating any potential source of artificial correlation between predictors\nand predictands. Results show that attributes are still highly predictive,\nconfirming the validity of the original approach. Other improvements brought by\nthe current study include the use of (1) a much larger dataset featuring more\nthan 90,000 reports, (2) two new models, XGBoost and linear SVM (Support Vector\nMachines), (3) model stacking, (4) a more straightforward experimental setup\nwith more appropriate performance metrics, and (5) an analysis of per-category\nattribute importance scores. Finally, the injury severity outcome is well\npredicted, which was not the case in the original study. This is a significant\nadvancement.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:50:15 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 11:19:42 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Baker", "Henrietta", ""], ["Hallowell", "Matthew R.", ""], ["Tixier", "Antoine J. -P.", ""]]}, {"id": "1908.05976", "submitter": "Vincenzo Perri", "authors": "Vincenzo Perri, Ingo Scholtes", "title": "HOTVis: Higher-Order Time-Aware Visualisation of Dynamic Graphs", "comments": "Appears in the Proceedings of the 28th International Symposium on\n  Graph Drawing and Network Visualization (GD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.GR cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network visualisation techniques are important tools for the exploratory\nanalysis of complex systems. While these methods are regularly applied to\nvisualise data on complex networks, we increasingly have access to time series\ndata that can be modelled as temporal networks or dynamic graphs. In dynamic\ngraphs, the temporal ordering of time-stamped edges determines the causal\ntopology of a system, i.e., which nodes can, directly and indirectly, influence\neach other via a so-called causal path. This causal topology is crucial to\nunderstand dynamical processes, assess the role of nodes, or detect clusters.\nHowever, we lack graph drawing techniques that incorporate this information\ninto static visualisations. Addressing this gap, we present a novel dynamic\ngraph visualisation algorithm that utilises higher-order graphical models of\ncausal paths in time series data to compute time-aware static graph\nvisualisations. These visualisations combine the simplicity and\ninterpretability of static graphs with a time-aware layout algorithm that\nhighlights patterns in the causal topology that result from the temporal\ndynamics of edges.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:57:52 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 07:01:16 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Perri", "Vincenzo", ""], ["Scholtes", "Ingo", ""]]}, {"id": "1908.05978", "submitter": "Sandra Ortega-Martorell", "authors": "Paulo J. G. Lisboa, Sandra Ortega-Martorell, Sadie Cashman, and Ivan\n  Olier", "title": "The Partial Response Network: a neural network nomogram", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among interpretable machine learning methods, the class of Generalised\nAdditive Neural Networks (GANNs) is referred to as Self-Explaining Neural\nNetworks (SENN) because of the linear dependence on explicit functions of the\ninputs. In binary classification this shows the precise weight that each input\ncontributes towards the logit. The nomogram is a graphical representation of\nthese weights. We show that functions of individual and pairs of variables can\nbe derived from a functional Analysis of Variance (ANOVA) representation,\nenabling an efficient feature selection to be carried by application of the\nlogistic Lasso. This process infers the structure of GANNs which otherwise\nneeds to be predefined. As this method is particularly suited for tabular data,\nit starts by fitting a generic flexible model, in this case a Multi-layer\nPerceptron (MLP) to which the ANOVA decomposition is applied. This has the\nfurther advantage that the resulting GANN can be replicated as a SENN, enabling\nfurther refinement of the univariate and bivariate component functions to take\nplace. The component functions are partial responses hence the SENN is a\npartial response network. The Partial Response Network (PRN) is equally as\ntransparent as a traditional logistic regression model, but capable of\nnon-linear classification with comparable or superior performance to the\noriginal MLP. In other words, the PRN is a fully interpretable representation\nof the MLP, at the level of univariate and bivariate effects. The performance\nof the PRN is shown to be competitive for benchmark data, against\nstate-of-the-art machine learning methods including GBM, SVM and Random\nForests. It is also compared with spline-based Sparse Additive Models (SAM)\nshowing that a semi-parametric representation of the GAM as a neural network\ncan be as effective as the SAM though less constrained by the need to set\nspline nodes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 14:02:19 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:52:26 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 08:45:37 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lisboa", "Paulo J. G.", ""], ["Ortega-Martorell", "Sandra", ""], ["Cashman", "Sadie", ""], ["Olier", "Ivan", ""]]}, {"id": "1908.05982", "submitter": "Tomasz Piotrowski", "authors": "Tomasz Piotrowski and Krzysztof Rykaczewski", "title": "Iterative Neural Networks with Bounded Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent analysis of a model of iterative neural network in Hilbert spaces\nestablished fundamental properties of such networks, such as existence of the\nfixed points sets, convergence analysis, and Lipschitz continuity. Building on\nthese results, we show that under a single mild condition on the weights of the\nnetwork, one is guaranteed to obtain a neural network converging to its unique\nfixed point. We provide a bound on the norm of this fixed point in terms of\nnorms of weights and biases of the network. We also show why this model of a\nfeed-forward neural network is not able to accomodate Hopfield networks under\nour assumption.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 14:16:55 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 13:32:03 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Piotrowski", "Tomasz", ""], ["Rykaczewski", "Krzysztof", ""]]}, {"id": "1908.06006", "submitter": "Jean-Baptiste Remy", "authors": "Jean-Baptiste Remy and Antoine Jean-Pierre Tixier and Michalis\n  Vazirgiannis", "title": "Bidirectional Context-Aware Hierarchical Attention Network for Document\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hierarchical Attention Network (HAN) has made great strides, but it\nsuffers a major limitation: at level 1, each sentence is encoded in complete\nisolation. In this work, we propose and compare several modifications of HAN in\nwhich the sentence encoder is able to make context-aware attentional decisions\n(CAHAN). Furthermore, we propose a bidirectional document encoder that\nprocesses the document forwards and backwards, using the preceding and\nfollowing sentences as context. Experiments on three large-scale sentiment and\ntopic classification datasets show that the bidirectional version of CAHAN\noutperforms HAN everywhere, with only a modest increase in computation time.\nWhile results are promising, we expect the superiority of CAHAN to be even more\nevident on tasks requiring a deeper understanding of the input documents, such\nas abstractive summarization. Code is publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:20:04 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Remy", "Jean-Baptiste", ""], ["Tixier", "Antoine Jean-Pierre", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1908.06008", "submitter": "Soujanya Poria", "authors": "Navonil Majumder, Soujanya Poria, Gangeshwar Krishnamurthy, Niyati\n  Chhaya, Rada Mihalcea, Alexander Gelbukh", "title": "Variational Fusion for Multimodal Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multimodal fusion is considered a key step in multimodal tasks such as\nsentiment analysis, emotion detection, question answering, and others. Most of\nthe recent work on multimodal fusion does not guarantee the fidelity of the\nmultimodal representation with respect to the unimodal representations. In this\npaper, we propose a variational autoencoder-based approach for modality fusion\nthat minimizes information loss between unimodal and multimodal\nrepresentations. We empirically show that this method outperforms the\nstate-of-the-art methods by a significant margin on several popular datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:39:19 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Majumder", "Navonil", ""], ["Poria", "Soujanya", ""], ["Krishnamurthy", "Gangeshwar", ""], ["Chhaya", "Niyati", ""], ["Mihalcea", "Rada", ""], ["Gelbukh", "Alexander", ""]]}, {"id": "1908.06010", "submitter": "Dmitri Kvasov", "authors": "Yaroslav D. Sergeyev (1 and 2), Antonio Candelieri (3), Dmitri E.\n  Kvasov (1 and 2), Riccardo Perego (3) ((1) University of Calabria, Rende,\n  Italy (2) Lobachevsky University, Nizhni Novgorod, Russia (3) University of\n  Milano-Bicocca, Milan, Italy)", "title": "Safe global optimization of expensive noisy black-box functions in the\n  $\\delta$-Lipschitz framework", "comments": "Published paper (37 pages, 44 figures, 4 tables): Yaroslav D.\n  Sergeyev - corresponding author. Soft Computing (2020)", "journal-ref": null, "doi": "10.1007/s00500-020-05030-3", "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of safe global maximization (it should not be\nconfused with robust optimization) of expensive noisy black-box functions\nsatisfying the Lipschitz condition is considered. The notion \"safe\" means that\nthe objective function $f(x)$ during optimization should not violate a \"safety\"\nthreshold, for instance, a certain a priori given value $h$ in a maximization\nproblem. Thus, any new function evaluation (possibly corrupted by noise) must\nbe performed at \"safe points\" only, namely, at points $y$ for which it is known\nthat the objective function $f(y) > h$. The main difficulty here consists in\nthe fact that the used optimization algorithm should ensure that the safety\nconstraint will be satisfied at a point $y$ before evaluation of $f(y)$ will be\nexecuted. Thus, it is required both to determine the safe region $\\Omega$\nwithin the search domain~$D$ and to find the global maximum within $\\Omega$. An\nadditional difficulty consists in the fact that these problems should be solved\nin the presence of the noise. This paper starts with a theoretical study of the\nproblem and it is shown that even though the objective function $f(x)$\nsatisfies the Lipschitz condition, traditional Lipschitz minorants and\nmajorants cannot be used due to the presence of the noise. Then, a\n$\\delta$-Lipschitz framework and two algorithms using it are proposed to solve\nthe safe global maximization problem. The first method determines the safe area\nwithin the search domain and the second one executes the global maximization\nover the found safe region. For both methods a number of theoretical results\nrelated to their functioning and convergence is established. Finally, numerical\nexperiments confirming the reliability of the proposed procedures are\nperformed.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 16:20:55 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 14:31:46 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sergeyev", "Yaroslav D.", "", "1 and 2"], ["Candelieri", "Antonio", "", "1 and 2"], ["Kvasov", "Dmitri E.", "", "1 and 2"], ["Perego", "Riccardo", ""]]}, {"id": "1908.06012", "submitter": "Zhang-Wei Hong", "authors": "Zhang-Wei Hong, Joni Pajarinen, Jan Peters", "title": "Model-based Lookahead Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based Reinforcement Learning (MBRL) allows data-efficient learning\nwhich is required in real world applications such as robotics. However, despite\nthe impressive data-efficiency, MBRL does not achieve the final performance of\nstate-of-the-art Model-free Reinforcement Learning (MFRL) methods. We leverage\nthe strengths of both realms and propose an approach that obtains high\nperformance with a small amount of data. In particular, we combine MFRL and\nModel Predictive Control (MPC). While MFRL's strength in exploration allows us\nto train a better forward dynamics model for MPC, MPC improves the performance\nof the MFRL policy by sampling-based planning. The experimental results in\nstandard continuous control benchmarks show that our approach can achieve\nMFRL`s level of performance while being as data-efficient as MBRL.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 04:10:13 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Hong", "Zhang-Wei", ""], ["Pajarinen", "Joni", ""], ["Peters", "Jan", ""]]}, {"id": "1908.06013", "submitter": "Maxim Osipov", "authors": "Maxim Osipov", "title": "Towards automated symptoms assessment in mental health", "comments": "This thesis is submitted to the Department of Engineering Science,\n  University of Oxford, in partial fulfilment of the requirements for the\n  degree of Doctor of Philosophy; please find the original submission at\n  https://ora.ox.ac.uk/objects/uuid:42111684-8801-440e-8fbb-00f779d806ee", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity and motion analysis has the potential to be used as a diagnostic\ntool for mental disorders. However, to-date, little work has been performed in\nturning stratification measures of activity into useful symptom markers. The\nresearch presented in this thesis has focused on the identification of\nobjective activity and behaviour metrics that could be useful for the analysis\nof mental health symptoms in the above mentioned dimensions. Particular\nattention is given to the analysis of objective differences between disorders,\nas well as identification of clinical episodes of mania and depression in\nbipolar patients, and deterioration in borderline personality disorder\npatients. A principled framework is proposed for mHealth monitoring of\npsychiatric patients, based on measurable changes in behaviour, represented in\nphysical activity time series, collected via mobile and wearable devices. The\nframework defines methods for direct computational analysis of symptoms in\ndisorganisation and psychomotor dimensions, as well as measures for indirect\nassessment of mood, using patterns of physical activity, sleep and circadian\nrhythms. The approach of computational behaviour analysis, proposed in this\nthesis, has the potential for early identification of clinical deterioration in\nambulatory patients, and allows for the specification of distinct and\nmeasurable behavioural phenotypes, thus enabling better understanding and\ntreatment of mental disorders.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 20:27:51 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Osipov", "Maxim", ""]]}, {"id": "1908.06021", "submitter": "Zhaohong Deng", "authors": "Yingzhong Shi, Zhaohong Deng, Haoran Chen, Kup-Sze Choi, Shitong Wang", "title": "Double-Coupling Learning for Multi-Task Data Stream Classification", "comments": "This work has been accepted conditionally by IEEE Computational\n  Intelligence Magazine in July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data stream classification methods demonstrate promising performance on a\nsingle data stream by exploring the cohesion in the data stream. However,\nmultiple data streams that involve several correlated data streams are common\nin many practical scenarios, which can be viewed as multi-task data streams.\nInstead of handling them separately, it is beneficial to consider the\ncorrelations among the multi-task data streams for data stream modeling tasks.\nIn this regard, a novel classification method called double-coupling support\nvector machines (DC-SVM), is proposed for classifying them simultaneously.\nDC-SVM considers the external correlations between multiple data streams, while\nhandling the internal relationship within the individual data stream.\nExperimental results on artificial and real-world multi-task data streams\ndemonstrate that the proposed method outperforms traditional data stream\nclassification methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 02:59:56 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Shi", "Yingzhong", ""], ["Deng", "Zhaohong", ""], ["Chen", "Haoran", ""], ["Choi", "Kup-Sze", ""], ["Wang", "Shitong", ""]]}, {"id": "1908.06022", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu, Bo Zhang, Jixiang Li, Qingyuan Li, Ruijun Xu", "title": "SCARLET-NAS: Bridging the gap between Stability and Scalability in\n  Weight-sharing Neural Architecture Search", "comments": "Make one shot nas scalable", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To discover powerful yet compact models is an important goal of neural\narchitecture search. Previous two-stage one-shot approaches are limited by\nsearch space with a fixed depth. It seems handy to include an additional skip\nconnection in the search space to make depths variable. However, it creates a\nlarge range of perturbation during supernet training and it has difficulty\ngiving a confident ranking for subnetworks. In this paper, we discover that\nskip connections bring about significant feature inconsistency compared with\nother operations, which potentially degrades the supernet performance. Based on\nthis observation, we tackle the problem by imposing an equivariant learnable\nstabilizer to homogenize such disparities. Experiments show that our proposed\nstabilizer helps to improve the supernet's convergence as well as ranking\nperformance. With an evolutionary search backend that incorporates the\nstabilized supernet as an evaluator, we derive a family of state-of-the-art\narchitectures, the SCARLET series of several depths, especially SCARLET-A\nobtains 76.9% top-1 accuracy on ImageNet. The models and evaluation code are\nreleased online https://github.com/xiaomi-automl/ScarletNAS.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:31:08 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 10:42:54 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 14:57:13 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 09:04:13 GMT"}, {"version": "v5", "created": "Thu, 2 Apr 2020 03:54:03 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhang", "Bo", ""], ["Li", "Jixiang", ""], ["Li", "Qingyuan", ""], ["Xu", "Ruijun", ""]]}, {"id": "1908.06037", "submitter": "Nick Pawlowski", "authors": "Nick Pawlowski, Suvrat Bhooshan, Nicolas Ballas, Francesco Ciompi, Ben\n  Glocker, Michal Drozdzal", "title": "Needles in Haystacks: On Classifying Tiny Objects in Large Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some important computer vision domains, such as medical or hyperspectral\nimaging, we care about the classification of tiny objects in large images.\nHowever, most Convolutional Neural Networks (CNNs) for image classification\nwere developed using biased datasets that contain large objects, in mostly\ncentral image positions. To assess whether classical CNN architectures work\nwell for tiny object classification we build a comprehensive testbed containing\ntwo datasets: one derived from MNIST digits and one from histopathology images.\nThis testbed allows controlled experiments to stress-test CNN architectures\nwith a broad spectrum of signal-to-noise ratios. Our observations indicate\nthat: (1) There exists a limit to signal-to-noise below which CNNs fail to\ngeneralize and that this limit is affected by dataset size - more data leading\nto better performances; however, the amount of training data required for the\nmodel to generalize scales rapidly with the inverse of the object-to-image\nratio (2) in general, higher capacity models exhibit better generalization; (3)\nwhen knowing the approximate object sizes, adapting receptive field is\nbeneficial; and (4) for very small signal-to-noise ratio the choice of global\npooling operation affects optimization, whereas for relatively large\nsignal-to-noise values, all tested global pooling operations exhibit similar\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:42:55 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 13:13:07 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Pawlowski", "Nick", ""], ["Bhooshan", "Suvrat", ""], ["Ballas", "Nicolas", ""], ["Ciompi", "Francesco", ""], ["Glocker", "Ben", ""], ["Drozdzal", "Michal", ""]]}, {"id": "1908.06039", "submitter": "Yujia Bao", "authors": "Yujia Bao, Menghua Wu, Shiyu Chang, Regina Barzilay", "title": "Few-shot Text Classification with Distributional Signatures", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore meta-learning for few-shot text classification.\nMeta-learning has shown strong performance in computer vision, where low-level\npatterns are transferable across learning tasks. However, directly applying\nthis approach to text is challenging--lexical features highly informative for\none task may be insignificant for another. Thus, rather than learning solely\nfrom words, our model also leverages their distributional signatures, which\nencode pertinent word occurrence patterns. Our model is trained within a\nmeta-learning framework to map these signatures into attention scores, which\nare then used to weight the lexical representations of words. We demonstrate\nthat our model consistently outperforms prototypical networks learned on\nlexical knowledge (Snell et al., 2017) in both few-shot text classification and\nrelation classification by a significant margin across six benchmark datasets\n(20.0% on average in 1-shot classification).\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:46:14 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 19:14:03 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 17:47:46 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Bao", "Yujia", ""], ["Wu", "Menghua", ""], ["Chang", "Shiyu", ""], ["Barzilay", "Regina", ""]]}, {"id": "1908.06040", "submitter": "Felipe Moreno-Vera", "authors": "Felipe Moreno-Vera", "title": "Performing Deep Recurrent Double Q-Learning for Atari Games", "comments": "Accepted paper on LatinXinAI Workshop co-located with the\n  International Conference on Machine Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, many applications in Machine Learning are based on define new\nmodels to extract more information about data, In this case Deep Reinforcement\nLearning with the most common application in video games like Atari, Mario, and\nothers causes an impact in how to computers can learning by himself with only\ninformation called rewards obtained from any action. There is a lot of\nalgorithms modeled and implemented based on Deep Recurrent Q-Learning proposed\nby DeepMind used in AlphaZero and Go. In this document, We proposed Deep\nRecurrent Double Q-Learning that is an implementation of Deep Reinforcement\nLearning using Double Q-Learning algorithms and Recurrent Networks like LSTM\nand DRQN.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:56:16 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 21:45:01 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Moreno-Vera", "Felipe", ""]]}, {"id": "1908.06049", "submitter": "Renzhi Wu", "authors": "Renzhi Wu, Sanya Chaba, Saurabh Sawlani, Xu Chu, Saravanan\n  Thirumuruganathan", "title": "ZeroER: Entity Resolution using Zero Labeled Examples", "comments": "Published at 2020 ACM SIGMOD International Conference on Management\n  of Data", "journal-ref": null, "doi": "10.1145/3318464.3389743", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity resolution (ER) refers to the problem of matching records in one or\nmore relations that refer to the same real-world entity. While supervised\nmachine learning (ML) approaches achieve the state-of-the-art results, they\nrequire a large amount of labeled examples that are expensive to obtain and\noften times infeasible. We investigate an important problem that vexes\npractitioners: is it possible to design an effective algorithm for ER that\nrequires Zero labeled examples, yet can achieve performance comparable to\nsupervised approaches? In this paper, we answer in the affirmative through our\nproposed approach dubbed ZeroER. Our approach is based on a simple observation\n-- the similarity vectors for matches should look different from that of\nunmatches. Operationalizing this insight requires a number of technical\ninnovations. First, we propose a simple yet powerful generative model based on\nGaussian Mixture Models for learning the match and unmatch distributions.\nSecond, we propose an adaptive regularization technique customized for ER that\nameliorates the issue of feature overfitting. Finally, we incorporate the\ntransitivity property into the generative model in a novel way resulting in\nimproved accuracy. On five benchmark ER datasets, we show that ZeroER greatly\noutperforms existing unsupervised approaches and achieves comparable\nperformance to supervised approaches.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 16:30:05 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 08:34:54 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wu", "Renzhi", ""], ["Chaba", "Sanya", ""], ["Sawlani", "Saurabh", ""], ["Chu", "Xu", ""], ["Thirumuruganathan", "Saravanan", ""]]}, {"id": "1908.06052", "submitter": "Yu-Jhe Li", "authors": "Yu-Jhe Li, Yun-Chun Chen, Yen-Yu Lin, Xiaofei Du, Yu-Chiang Frank Wang", "title": "Recover and Identify: A Generative Dual Model for Cross-Resolution\n  Person Re-Identification", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification (re-ID) aims at matching images of the same identity\nacross camera views. Due to varying distances between cameras and persons of\ninterest, resolution mismatch can be expected, which would degrade person re-ID\nperformance in real-world scenarios. To overcome this problem, we propose a\nnovel generative adversarial network to address cross-resolution person re-ID,\nallowing query images with varying resolutions. By advancing adversarial\nlearning techniques, our proposed model learns resolution-invariant image\nrepresentations while being able to recover the missing details in\nlow-resolution input images. The resulting features can be jointly applied for\nimproving person re-ID performance due to preserving resolution invariance and\nrecovering re-ID oriented discriminative details. Our experiments on five\nbenchmark datasets confirm the effectiveness of our approach and its\nsuperiority over the state-of-the-art methods, especially when the input\nresolutions are unseen during training.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 16:39:20 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Li", "Yu-Jhe", ""], ["Chen", "Yun-Chun", ""], ["Lin", "Yen-Yu", ""], ["Du", "Xiaofei", ""], ["Wang", "Yu-Chiang Frank", ""]]}, {"id": "1908.06062", "submitter": "Daniel Liu", "authors": "Daniel Liu, Ronald Yu, Hao Su", "title": "Adversarial shape perturbations on 3D point clouds", "comments": "18 pages, accepted to the 2020 ECCV workshop on Adversarial\n  Robustness in the Real World, source code available at this https url:\n  https://github.com/Daniel-Liu-c0deb0t/Adversarial-point-perturbations-on-3D-objects", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of training robust neural network grows as 3D data is\nincreasingly utilized in deep learning for vision tasks in robotics, drone\ncontrol, and autonomous driving. One commonly used 3D data type is 3D point\nclouds, which describe shape information. We examine the problem of creating\nrobust models from the perspective of the attacker, which is necessary in\nunderstanding how 3D neural networks can be exploited. We explore two\ncategories of attacks: distributional attacks that involve imperceptible\nperturbations to the distribution of points, and shape attacks that involve\ndeforming the shape represented by a point cloud. We explore three possible\nshape attacks for attacking 3D point cloud classification and show that some of\nthem are able to be effective even against preprocessing steps, like the\npreviously proposed point-removal defenses.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:19:34 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 00:04:59 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 04:55:16 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Liu", "Daniel", ""], ["Yu", "Ronald", ""], ["Su", "Hao", ""]]}, {"id": "1908.06065", "submitter": "Mohammed Rayyan Sheriff", "authors": "Mohammed Rayyan Sheriff, Debasish Chatterjee", "title": "On Convex Duality in Linear Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we dwell into the class of so called ill posed Linear Inverse\nProblems (LIP) in machine learning, which has become almost a classic in recent\ntimes. The fundamental task in an LIP is to recover the entire signal / data\nfrom its relatively few random linear measurements. Such problems arise in\nvariety of settings with applications ranging from medical image processing,\nrecommender systems etc. We provide an exposition to the convex duality of the\nlinear inverse problems, and obtain a novel and equivalent convex-concave\nmin-max reformulation that gives rise to simple ascend-descent type algorithms\nto solve an LIP. Moreover, such a reformulation is crucial in developing\nmethods to solve the dictionary learning problem with almost sure recovery\nconstraints.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:25:15 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 19:49:07 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 19:48:26 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Sheriff", "Mohammed Rayyan", ""], ["Chatterjee", "Debasish", ""]]}, {"id": "1908.06075", "submitter": "Xueying Tang", "authors": "Xueying Tang, Zhi Wang, Jingchen Liu, and Zhiliang Ying", "title": "An Exploratory Analysis of the Latent Structure of Process Data via\n  Action Sequence Autoencoder", "comments": "28 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer simulations have become a popular tool of assessing complex skills\nsuch as problem-solving skills. Log files of computer-based items record the\nentire human-computer interactive processes for each respondent. The response\nprocesses are very diverse, noisy, and of nonstandard formats. Few generic\nmethods have been developed for exploiting the information contained in process\ndata. In this article, we propose a method to extract latent variables from\nprocess data. The method utilizes a sequence-to-sequence autoencoder to\ncompress response processes into standard numerical vectors. It does not\nrequire prior knowledge of the specific items and human-computers interaction\npatterns. The proposed method is applied to both simulated and real process\ndata to demonstrate that the resulting latent variables extract useful\ninformation from the response processes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:55:20 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Tang", "Xueying", ""], ["Wang", "Zhi", ""], ["Liu", "Jingchen", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1908.06077", "submitter": "Ali Ramezani-Kebrya", "authors": "Ali Ramezani-Kebrya, Fartash Faghri, Ilya Markov, Vitalii Aksenov, Dan\n  Alistarh, Daniel M. Roy", "title": "NUQSGD: Provably Communication-efficient Data-parallel SGD via\n  Nonuniform Quantization", "comments": "42 pages, 21 figures. To appear in the Journal of Machine Learning\n  Research (JMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the size and complexity of models and datasets grow, so does the need for\ncommunication-efficient variants of stochastic gradient descent that can be\ndeployed to perform parallel model training. One popular\ncommunication-compression method for data-parallel SGD is QSGD (Alistarh et\nal., 2017), which quantizes and encodes gradients to reduce communication\ncosts. The baseline variant of QSGD provides strong theoretical guarantees,\nhowever, for practical purposes, the authors proposed a heuristic variant which\nwe call QSGDinf, which demonstrated impressive empirical gains for distributed\ntraining of large neural networks. In this paper, we build on this work to\npropose a new gradient quantization scheme, and show that it has both stronger\ntheoretical guarantees than QSGD, and matches and exceeds the empirical\nperformance of the QSGDinf heuristic and of other compression methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:59:01 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 21:39:42 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Ramezani-Kebrya", "Ali", ""], ["Faghri", "Fartash", ""], ["Markov", "Ilya", ""], ["Aksenov", "Vitalii", ""], ["Alistarh", "Dan", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1908.06081", "submitter": "Michael Thrun PhD", "authors": "Michael C. Thrun, Tino Gehlert, Alfred Ultsch", "title": "Analyzing the Fine Structure of Distributions", "comments": "66 pages, 81 figures, accepted in PLOS ONE", "journal-ref": null, "doi": "10.1371/journal.pone.0238835", "report-no": "PONE-D-19-19081R4", "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One aim of data mining is the identification of interesting structures in\ndata. For better analytical results, the basic properties of an empirical\ndistribution, such as skewness and eventual clipping, i.e. hard limits in value\nranges, need to be assessed. Of particular interest is the question of whether\nthe data originate from one process or contain subsets related to different\nstates of the data producing process. Data visualization tools should deliver a\nclear picture of the univariate probability density distribution (PDF) for each\nfeature. Visualization tools for PDFs typically use kernel density estimates\nand include both the classical histogram, as well as the modern tools like\nridgeline plots, bean plots and violin plots. If density estimation parameters\nremain in a default setting, conventional methods pose several problems when\nvisualizing the PDF of uniform, multimodal, skewed distributions and\ndistributions with clipped data, For that reason, a new visualization tool\ncalled the mirrored density plot (MD plot), which is specifically designed to\ndiscover interesting structures in continuous features, is proposed. The MD\nplot does not require adjusting any parameters of density estimation, which is\nwhat may make the use of this plot compelling particularly to non-experts. The\nvisualization tools in question are evaluated against statistical tests with\nregard to typical challenges of explorative distribution analysis. The results\nof the evaluation are presented using bimodal Gaussian, skewed distributions\nand several features with already published PDFs. In an exploratory data\nanalysis of 12 features describing quarterly financial statements, when\nstatistical testing poses a great difficulty, only the MD plots can identify\nthe structure of their PDFs. In sum, the MD plot outperforms the above\nmentioned methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 19:24:32 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 07:01:09 GMT"}, {"version": "v3", "created": "Sat, 5 Sep 2020 08:59:10 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Thrun", "Michael C.", ""], ["Gehlert", "Tino", ""], ["Ultsch", "Alfred", ""]]}, {"id": "1908.06082", "submitter": "Prathusha Kameswara Sarma", "authors": "Prathusha K Sarma, Yingyu Liang, William A Sethares", "title": "Shallow Domain Adaptive Embeddings for Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a way to improve the performance of existing algorithms\nfor text classification in domains with strong language semantics. We propose a\ndomain adaptation layer learns weights to combine a generic and a domain\nspecific (DS) word embedding into a domain adapted (DA) embedding. The DA word\nembeddings are then used as inputs to a generic encoder + classifier framework\nto perform a downstream task such as classification. This adaptation layer is\nparticularly suited to datasets that are modest in size, and which are,\ntherefore, not ideal candidates for (re)training a deep neural network\narchitecture. Results on binary and multi-class classification tasks using\npopular encoder architectures, including current state-of-the-art methods (with\nand without the shallow adaptation layer) show the effectiveness of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 20:25:13 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Sarma", "Prathusha K", ""], ["Liang", "Yingyu", ""], ["Sethares", "William A", ""]]}, {"id": "1908.06112", "submitter": "Yisen Wang", "authors": "Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, James Bailey", "title": "Symmetric Cross Entropy for Robust Learning with Noisy Labels", "comments": "ICCV2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training accurate deep neural networks (DNNs) in the presence of noisy labels\nis an important and challenging task. Though a number of approaches have been\nproposed for learning with noisy labels, many open issues remain. In this\npaper, we show that DNN learning with Cross Entropy (CE) exhibits overfitting\nto noisy labels on some classes (\"easy\" classes), but more surprisingly, it\nalso suffers from significant under learning on some other classes (\"hard\"\nclasses). Intuitively, CE requires an extra term to facilitate learning of hard\nclasses, and more importantly, this term should be noise tolerant, so as to\navoid overfitting to noisy labels. Inspired by the symmetric KL-divergence, we\npropose the approach of \\textbf{Symmetric cross entropy Learning} (SL),\nboosting CE symmetrically with a noise robust counterpart Reverse Cross Entropy\n(RCE). Our proposed SL approach simultaneously addresses both the under\nlearning and overfitting problem of CE in the presence of noisy labels. We\nprovide a theoretical analysis of SL and also empirically show, on a range of\nbenchmark and real-world datasets, that SL outperforms state-of-the-art\nmethods. We also show that SL can be easily incorporated into existing methods\nin order to further enhance their performance.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 18:01:32 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Wang", "Yisen", ""], ["Ma", "Xingjun", ""], ["Chen", "Zaiyi", ""], ["Luo", "Yuan", ""], ["Yi", "Jinfeng", ""], ["Bailey", "James", ""]]}, {"id": "1908.06130", "submitter": "Matthew Brennan", "authors": "Matthew Brennan, Guy Bresler", "title": "Average-Case Lower Bounds for Learning Sparse Mixtures, Robust\n  Estimation and Semirandom Adversaries", "comments": "Preliminary version (subsumed by expanded version at\n  arXiv:2005.08099), 65 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops several average-case reduction techniques to show new\nhardness results for three central high-dimensional statistics problems,\nimplying a statistical-computational gap induced by robustness, a\ndetection-recovery gap and a universality principle for these gaps. A main\nfeature of our approach is to map to these problems via a common intermediate\nproblem that we introduce, which we call Imbalanced Sparse Gaussian Mixtures.\nWe assume the planted clique conjecture for a version of the planted clique\nproblem where the position of the planted clique is mildly constrained, and\nfrom this obtain the following computational lower bounds: (1) a $k$-to-$k^2$\nstatistical-computational gap for robust sparse mean estimation, providing the\nfirst average-case evidence for a conjecture of Li (2017) and Balakrishnan et\nal. (2017); (2) a tight lower bound for semirandom planted dense subgraph,\nwhich shows that a semirandom adversary shifts the detection threshold in\nplanted dense subgraph to the conjectured recovery threshold; and (3) a\nuniversality principle for $k$-to-$k^2$ gaps in a broad class of sparse mixture\nproblems that includes many natural formulations such as the spiked covariance\nmodel.\n  Our main approach is to introduce several average-case techniques to produce\nstructured and Gaussianized versions of an input graph problem, and then to\nrotate these high-dimensional Gaussians by matrices carefully constructed from\nhyperplanes in $\\mathbb{F}_r^t$. For our universality result, we introduce a\nnew method to perform an algorithmic change of measure tailored to sparse\nmixtures. We also provide evidence that the mild promise in our variant of\nplanted clique does not change the complexity of the problem.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 22:14:09 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 01:20:43 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""]]}, {"id": "1908.06132", "submitter": "Rodrigo Nogueira", "authors": "Rodrigo Nogueira", "title": "Learning Representations and Agents for Information Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A goal shared by artificial intelligence and information retrieval is to\ncreate an oracle, that is, a machine that can answer our questions, no matter\nhow difficult they are. A more limited, but still instrumental, version of this\noracle is a question-answering system, in which an open-ended question is given\nto the machine, and an answer is produced based on the knowledge it has access\nto. Such systems already exist and are increasingly capable of answering\ncomplicated questions. This progress can be partially attributed to the recent\nsuccess of machine learning and to the efficient methods for storing and\nretrieving information, most notably through web search engines. One can\nimagine that this general-purpose question-answering system can be built as a\nbillion-parameters neural network trained end-to-end with a large number of\npairs of questions and answers. We argue, however, that although this approach\nhas been very successful for tasks such as machine translation, storing the\nworld's knowledge as parameters of a learning machine can be very hard. A more\nefficient way is to train an artificial agent on how to use an external\nretrieval system to collect relevant information. This agent can leverage the\neffort that has been put into designing and running efficient storage and\nretrieval systems by learning how to best utilize them to accomplish a task.\n...\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 19:07:07 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Nogueira", "Rodrigo", ""]]}, {"id": "1908.06134", "submitter": "Taku Yamagata", "authors": "Taku Yamagata, Ra\\'ul Santos-Rodr\\'iguez, Ryan McConville, Atis Elsts\n  (University of Bristol)", "title": "Online Feature Selection for Activity Recognition using Reinforcement\n  Learning with Multiple Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in both machine learning and Internet-of-Things have\nattracted attention to automatic Activity Recognition, where users wear a\ndevice with sensors and their outputs are mapped to a predefined set of\nactivities. However, few studies have considered the balance between wearable\npower consumption and activity recognition accuracy. This is particularly\nimportant when part of the computational load happens on the wearable device.\nIn this paper, we present a new methodology to perform feature selection on the\ndevice based on Reinforcement Learning (RL) to find the optimum balance between\npower consumption and accuracy. To accelerate the learning speed, we extend the\nRL algorithm to address multiple sources of feedback, and use them to tailor\nthe policy in conjunction with estimating the feedback accuracy. We evaluated\nour system on the SPHERE challenge dataset, a publicly available research\ndataset. The results show that our proposed method achieves a good trade-off\nbetween wearable power consumption and activity recognition accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 19:20:31 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Yamagata", "Taku", "", "University of Bristol"], ["Santos-Rodr\u00edguez", "Ra\u00fal", "", "University of Bristol"], ["McConville", "Ryan", "", "University of Bristol"], ["Elsts", "Atis", "", "University of Bristol"]]}, {"id": "1908.06137", "submitter": "Hugo Abreu Mendes", "authors": "Joelle Feij\\'o de Fran\\c{c}a, Hugo Abreu Mendes, Lucas Gallindo Costa,\n  Andrea Tavares Dantas, Angela Luzia Branco Pinto Duarte, Anderson Stevens\n  Le\\^onidas Gomes and Emery Cleiton Cabral Correia Lins", "title": "Using Near Infrared Spectroscopy and Machine Learning to diagnose\n  Systemic Sclerosis", "comments": "9 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The motivation of this work is the use of non-invasive and low cost\ntechniques to obtain a faster and more accurate diagnosis of systemic sclerosis\n(SSc), rheumatic, autoimmune, chronic and rare disease. The technique in\nquestion is Near Infrared Spectroscopy (NIRS). Spectra were acquired from three\ndifferent regions of hand's volunteers. Machine learning algorithms are used to\nclassify and search for the best optical wavelength. The results demonstrate\nthat it is easy to obtain wavelength bands more important for the diagnosis. We\nuse the algorithm RFECV and SVC. The results suggests that the most important\nwavelength band is at 1270 nm, referring to the luminescence of Singlet Oxygen.\nThe results indicates that the Proximal Interphalangeal Joints region returns\nbetter accuracy's scores. Optical spectrometers can be found at low prices and\ncan be easily used in clinical evaluations, while the algorithms used are\ncompletely diffused on open source platforms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 19:34:54 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["de Fran\u00e7a", "Joelle Feij\u00f3", ""], ["Mendes", "Hugo Abreu", ""], ["Costa", "Lucas Gallindo", ""], ["Dantas", "Andrea Tavares", ""], ["Duarte", "Angela Luzia Branco Pinto", ""], ["Gomes", "Anderson Stevens Le\u00f4nidas", ""], ["Lins", "Emery Cleiton Cabral Correia", ""]]}, {"id": "1908.06158", "submitter": "Meisam Hejazi Nia", "authors": "Meisam Hejazinia, Kyler Eastman, Shuqin Ye, Abbas Amirabadi, Ravi\n  Divvela", "title": "Accelerated learning from recommender systems using multi-armed bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems are a vital component of many online marketplaces,\nwhere there are often millions of items to potentially present to users who\nhave a wide variety of wants or needs. Evaluating recommender system algorithms\nis a hard task, given all the inherent bias in the data, and successful\ncompanies must be able to rapidly iterate on their solution to maintain their\ncompetitive advantage. The gold standard for evaluating recommendation\nalgorithms has been the A/B test since it is an unbiased way to estimate how\nwell one or more algorithms compare in the real world. However, there are a\nnumber of issues with A/B testing that make it impractical to be the sole\nmethod of testing, including long lead time, and high cost of exploration. We\nargue that multi armed bandit (MAB) testing as a solution to these issues. We\nshowcase how we implemented a MAB solution as an extra step between offline and\nonline A/B testing in a production system. We present the result of our\nexperiment and compare all the offline, MAB, and online A/B tests metrics for\nour use case.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 20:44:01 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Hejazinia", "Meisam", ""], ["Eastman", "Kyler", ""], ["Ye", "Shuqin", ""], ["Amirabadi", "Abbas", ""], ["Divvela", "Ravi", ""]]}, {"id": "1908.06168", "submitter": "Meenakshi Khosla", "authors": "Meenakshi Khosla, Keith Jamison, Amy Kuceyeski and Mert R. Sabuncu", "title": "Detecting abnormalities in resting-state dynamics: An unsupervised\n  learning approach", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resting-state functional MRI (rs-fMRI) is a rich imaging modality that\ncaptures spontaneous brain activity patterns, revealing clues about the\nconnectomic organization of the human brain. While many rs-fMRI studies have\nfocused on static measures of functional connectivity, there has been a recent\nsurge in examining the temporal patterns in these data. In this paper, we\nexplore two strategies for capturing the normal variability in resting-state\nactivity across a healthy population: (a) an autoencoder approach on the\nrs-fMRI sequence, and (b) a next frame prediction strategy. We show that both\napproaches can learn useful representations of rs-fMRI data and demonstrate\ntheir novel application for abnormality detection in the context of\ndiscriminating autism patients from healthy controls.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:03:08 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Khosla", "Meenakshi", ""], ["Jamison", "Keith", ""], ["Kuceyeski", "Amy", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1908.06169", "submitter": "Dimitrios Rafailidis Dr", "authors": "Dimitrios Rafailidis", "title": "Cross-Domain Collaborative Filtering via Translation-based Learning", "comments": "arXiv admin note: text overlap with arXiv:1907.01645", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of social media platforms and e-commerce sites,\nseveral cross-domain collaborative filtering strategies have been recently\nintroduced to transfer the knowledge of user preferences across domains. The\nmain challenge of cross-domain recommendation is to weigh and learn users'\ndifferent behaviors in multiple domains. In this paper, we propose a\nCross-Domain collaborative filtering model following a Translation-based\nstrategy, namely CDT. In our model, we learn the embedding space with\ntranslation vectors and capture high-order feature interactions in users'\nmultiple preferences across domains. In doing so, we efficiently compute the\ntransitivity between feature latent embeddings, that is if feature pairs have\nhigh interaction weights in the latent space, then feature embeddings with no\nobserved interactions across the domains will be closely related as well. We\nformulate our objective function as a ranking problem in factorization machines\nand learn the model's parameters via gradient descent. In addition, to better\ncapture the non-linearity in user preferences across domains we extend the\nproposed CDT model by using a deep learning strategy, namely DeepCDT. Our\nexperiments on six publicly available cross-domain tasks demonstrate the\neffectiveness of the proposed models, outperforming other state-of-the-art\ncross-domain strategies.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 15:23:35 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Rafailidis", "Dimitrios", ""]]}, {"id": "1908.06170", "submitter": "Nathan Hurley", "authors": "Nathan C. Hurley and Erica S. Spatz and Harlan M. Krumholz and Roozbeh\n  Jafari and Bobak J. Mortazavi", "title": "A Survey of Challenges and Opportunities in Sensing and Analytics for\n  Cardiovascular Disorders", "comments": "32 pages, 3 figures, to be submitted to ACM Transactions on Computing\n  for Healthcare (HEALTH), Special Issue on Wearable Technologies for Smart\n  Health 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cardiovascular disorders account for nearly 1 in 3 deaths in the United\nStates. Care for these disorders are often determined during visits to acute\ncare facilities, such as hospitals. While the length of stay in these settings\nrepresents just a small proportion of patients' lives, they account for a\ndisproportionately large amount of decision making. To overcome this bias\ntowards data from acute care settings, there is a need for longitudinal\nmonitoring in patients with cardiovascular disorders. Longitudinal monitoring\ncan provide a more comprehensive picture of patient health, allowing for more\ninformed decision making. This work surveys the current field of sensing\ntechnologies and machine learning analytics that exist in the field of remote\nmonitoring for cardiovascular disorders. We highlight three primary needs in\nthe design of new smart health technologies: 1) the need for sensing technology\nthat can track longitudinal trends in signs and symptoms of the cardiovascular\ndisorder despite potentially infrequent, noisy, or missing data measurements;\n2) the need for new analytic techniques that model data captured in a\nlongitudinal, continual fashion to aid in the development of new risk\nprediction techniques and in tracking disease progression; and 3) the need for\nmachine learning techniques that are personalized and interpretable, allowing\nfor advancements in shared clinical decision making. We highlight these needs\nbased upon the current state-of-the-art in smart health technologies and\nanalytics and discuss the ample opportunities that exist in addressing all\nthree needs in the development of smart health technologies and analytics\napplied to the field of cardiovascular disorders and care.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 03:07:05 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Hurley", "Nathan C.", ""], ["Spatz", "Erica S.", ""], ["Krumholz", "Harlan M.", ""], ["Jafari", "Roozbeh", ""], ["Mortazavi", "Bobak J.", ""]]}, {"id": "1908.06173", "submitter": "Emilio Ferrara", "authors": "Emilio Ferrara", "title": "The History of Digital Spam", "comments": null, "journal-ref": "Communications of the ACM, August 2019, Vol. 62 No. 8, Pages\n  82-91, 2019", "doi": "10.1145/3299768", "report-no": null, "categories": "cs.CY cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spam!: that's what Lorrie Faith Cranor and Brian LaMacchia exclaimed in the\ntitle of a popular call-to-action article that appeared twenty years ago on\nCommunications of the ACM. And yet, despite the tremendous efforts of the\nresearch community over the last two decades to mitigate this problem, the\nsense of urgency remains unchanged, as emerging technologies have brought new\ndangerous forms of digital spam under the spotlight. Furthermore, when spam is\ncarried out with the intent to deceive or influence at scale, it can alter the\nvery fabric of society and our behavior. In this article, I will briefly review\nthe history of digital spam: starting from its quintessential incarnation, spam\nemails, to modern-days forms of spam affecting the Web and social media, the\nsurvey will close by depicting future risks associated with spam and abuse of\nnew technologies, including Artificial Intelligence (e.g., Digital Humans).\nAfter providing a taxonomy of spam, and its most popular applications emerged\nthroughout the last two decades, I will review technological and regulatory\napproaches proposed in the literature, and suggest some possible solutions to\ntackle this ubiquitous digital epidemic moving forward.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 00:14:54 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ferrara", "Emilio", ""]]}, {"id": "1908.06177", "submitter": "Koustuv Sinha", "authors": "Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, William L.\n  Hamilton", "title": "CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text", "comments": "Accepted at EMNLP 2019, 9 page content + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of natural language understanding (NLU) systems has been\ntroubled by results highlighting the failure of these models to generalize in a\nsystematic and robust way. In this work, we introduce a diagnostic benchmark\nsuite, named CLUTRR, to clarify some key issues related to the robustness and\nsystematicity of NLU systems. Motivated by classic work on inductive logic\nprogramming, CLUTRR requires that an NLU system infer kinship relations between\ncharacters in short stories. Successful performance on this task requires both\nextracting relationships between entities, as well as inferring the logical\nrules governing these relationships. CLUTRR allows us to precisely measure a\nmodel's ability for systematic generalization by evaluating on held-out\ncombinations of logical rules, and it allows us to evaluate a model's\nrobustness by adding curated noise facts. Our empirical results highlight a\nsubstantial performance gap between state-of-the-art NLU models (e.g., BERT and\nMAC) and a graph neural network model that works directly with symbolic\ninputs---with the graph-based model exhibiting both stronger generalization and\ngreater robustness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:12:15 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 00:14:56 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Sinha", "Koustuv", ""], ["Sodhani", "Shagun", ""], ["Dong", "Jin", ""], ["Pineau", "Joelle", ""], ["Hamilton", "William L.", ""]]}, {"id": "1908.06178", "submitter": "Sarthak Dash", "authors": "Sarthak Dash, Alfio Gliozzo", "title": "Distributional Negative Sampling for Knowledge Base Completion", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art approaches for Knowledge Base Completion (KBC) exploit deep\nneural networks trained with both false and true assertions: positive\nassertions are explicitly taken from the knowledge base, whereas negative ones\nare generated by random sampling of entities. In this paper, we argue that\nrandom sampling is not a good training strategy since it is highly likely to\ngenerate a huge number of nonsensical assertions during training, which does\nnot provide relevant training signal to the system. Hence, it slows down the\nlearning process and decreases accuracy. To address this issue, we propose an\nalternative approach called Distributional Negative Sampling that generates\nmeaningful negative examples which are highly likely to be false. Our approach\nachieves a significant improvement in Mean Reciprocal Rank values amongst two\ndifferent KBC algorithms in three standard academic benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:12:37 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Dash", "Sarthak", ""], ["Gliozzo", "Alfio", ""]]}, {"id": "1908.06180", "submitter": "Dongrui Wu", "authors": "Zhenhua Shi, Xiaomo Chen, Changming Zhao, He He, Veit Stuphorn and\n  Dongrui Wu", "title": "Multi-View Broad Learning System for Primate Oculomotor Decision\n  Decoding", "comments": null, "journal-ref": "IEEE Transactions on Neural Systems and Rehabilitation\n  Engineering, 2020", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view learning improves the learning performance by utilizing multi-view\ndata: data collected from multiple sources, or feature sets extracted from the\nsame data source. This approach is suitable for primate brain state decoding\nusing cortical neural signals. This is because the complementary components of\nsimultaneously recorded neural signals, local field potentials (LFPs) and\naction potentials (spikes), can be treated as two views. In this paper, we\nextended broad learning system (BLS), a recently proposed wide neural network\narchitecture, from single-view learning to multi-view learning, and validated\nits performance in decoding monkeys' oculomotor decision from medial frontal\nLFPs and spikes. We demonstrated that medial frontal LFPs and spikes in\nnon-human primate do contain complementary information about the oculomotor\ndecision, and that the proposed multi-view BLS is a more effective approach for\ndecoding the oculomotor decision than several classical and state-of-the-art\nsingle-view and multi-view learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:23:20 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 16:18:49 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 22:53:26 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Shi", "Zhenhua", ""], ["Chen", "Xiaomo", ""], ["Zhao", "Changming", ""], ["He", "He", ""], ["Stuphorn", "Veit", ""], ["Wu", "Dongrui", ""]]}, {"id": "1908.06194", "submitter": "Sharib Ali Dr.", "authors": "Sharib Ali and Jens Rittscher", "title": "Conv2Warp: An unsupervised deformable image registration with continuous\n  convolution and warping", "comments": "8 pages (accepted at 10th International Workshop on Machine Learning\n  in Medical Imaging, in conjunction with MICCAI2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes in deep learning based deformable image registration (DIR)\nmethods have demonstrated that complex deformation can be learnt directly from\ndata while reducing computation time when compared to traditional methods.\nHowever, the reliance on fully linear convolutional layers imposes a uniform\nsampling of pixel/voxel locations which ultimately limits their performance. To\naddress this problem, we propose a novel approach of learning a continuous warp\nof the source image. Here, the required deformation vector fields are obtained\nfrom a concatenated linear and non-linear convolution layers and a learnable\nbicubic Catmull-Rom spline resampler. This allows to compute smooth deformation\nfield and more accurate alignment compared to using only linear convolutions\nand linear resampling. In addition, the continuous warping technique penalizes\ndisagreements that are due to topological changes. Our experiments demonstrate\nthat this approach manages to capture large non-linear deformations and\nminimizes the propagation of interpolation errors. While improving accuracy the\nmethod is computationally efficient. We present comparative results on a range\nof public 4D CT lung (POPI) and brain datasets (CUMC12, MGH10).\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 22:21:07 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ali", "Sharib", ""], ["Rittscher", "Jens", ""]]}, {"id": "1908.06209", "submitter": "Jonas Geiping", "authors": "Jonas Geiping and Michael Moeller", "title": "Parametric Majorization for Data-Driven Energy Minimization Methods", "comments": "16 pages, 5 figures, accepted for ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy minimization methods are a classical tool in a multitude of computer\nvision applications. While they are interpretable and well-studied, their\nregularity assumptions are difficult to design by hand. Deep learning\ntechniques on the other hand are purely data-driven, often provide excellent\nresults, but are very difficult to constrain to predefined physical or\nsafety-critical models. A possible combination between the two approaches is to\ndesign a parametric energy and train the free parameters in such a way that\nminimizers of the energy correspond to desired solution on a set of training\nexamples. Unfortunately, such formulations typically lead to bi-level\noptimization problems, on which common optimization algorithms are difficult to\nscale to modern requirements in data processing and efficiency. In this work,\nwe present a new strategy to optimize these bi-level problems. We investigate\nsurrogate single-level problems that majorize the target problems and can be\nimplemented with existing tools, leading to efficient algorithms without\ncollapse of the energy function. This framework of strategies enables new\navenues to the training of parameterized energy minimization models from large\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 00:10:41 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Geiping", "Jonas", ""], ["Moeller", "Michael", ""]]}, {"id": "1908.06210", "submitter": "Fuwei Li", "authors": "Fuwei Li, Lifeng Lai, and Shuguang Cui", "title": "On the Adversarial Robustness of Subspace Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.2974676", "report-no": null, "categories": "eess.SP cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the adversarial robustness of subspace learning\nproblems. Different from the assumptions made in existing work on robust\nsubspace learning where data samples are contaminated by gross sparse outliers\nor small dense noises, we consider a more powerful adversary who can first\nobserve the data matrix and then intentionally modify the whole data matrix. We\nfirst characterize the optimal rank-one attack strategy that maximizes the\nsubspace distance between the subspace learned from the original data matrix\nand that learned from the modified data matrix. We then generalize the study to\nthe scenario without the rank constraint and characterize the corresponding\noptimal attack strategy. Our analysis shows that the optimal strategies depend\non the singular values of the original data matrix and the adversary's energy\nbudget. Finally, we provide numerical experiments and practical applications to\ndemonstrate the efficiency of the attack strategies.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 00:20:42 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Li", "Fuwei", ""], ["Lai", "Lifeng", ""], ["Cui", "Shuguang", ""]]}, {"id": "1908.06213", "submitter": "Avinash Kori", "authors": "Avinash Kori, Ganapathi Krishnamurthi", "title": "Zero Shot Learning for Multi-Modal Real Time Image Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this report we present an unsupervised image registration framework, using\na pre-trained deep neural network as a feature extractor. We refer this to\nzero-shot learning, due to nonoverlap between training and testing dataset\n(none of the network modules in the processing pipeline were trained\nspecifically for the task of medical image registration). Highlights of our\ntechnique are: (a) No requirement of a training dataset (b) Keypoints\ni.e.locations of important features are automatically estimated (c) The number\nof key points in this model is fixed and can possibly be tuned as a\nhyperparameter. (d) Uncertaintycalculation of the proposed, transformation\nestimates (e) Real-time registration of images. Our technique was evaluated on\nBraTS, ALBERT, and collaborative hospital Brain MRI data. Results suggest that\nthe method proved to be robust for affine transformation models and the results\nare practically instantaneous, irrespective of the size of the input image\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 00:37:25 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Kori", "Avinash", ""], ["Krishnamurthi", "Ganapathi", ""]]}, {"id": "1908.06214", "submitter": "Matthew Sotoudeh", "authors": "Matthew Sotoudeh and Aditya V. Thakur", "title": "Computing Linear Restrictions of Neural Networks", "comments": "Conference paper at the Conference on Neural Information Processing\n  Systems (NeurIPS) 2019. Code is available at\n  https://github.com/95616ARG/SyReNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A linear restriction of a function is the same function with its domain\nrestricted to points on a given line. This paper addresses the problem of\ncomputing a succinct representation for a linear restriction of a\npiecewise-linear neural network. This primitive, which we call ExactLine,\nallows us to exactly characterize the result of applying the network to all of\nthe infinitely many points on a line. In particular, ExactLine computes a\npartitioning of the given input line segment such that the network is affine on\neach partition. We present an efficient algorithm for computing ExactLine for\nnetworks that use ReLU, MaxPool, batch normalization, fully-connected,\nconvolutional, and other layers, along with several applications. First, we\nshow how to exactly determine decision boundaries of an ACAS Xu neural network,\nproviding significantly improved confidence in the results compared to prior\nwork that sampled finitely many points in the input space. Next, we demonstrate\nhow to exactly compute integrated gradients, which are commonly used for neural\nnetwork attributions, allowing us to show that the prior heuristic-based\nmethods had relative errors of 25-45% and show that a better sampling method\ncan achieve higher accuracy with less computation. Finally, we use ExactLine to\nempirically falsify the core assumption behind a well-known hypothesis about\nadversarial examples, and in the process identify interesting properties of\nadversarially-trained networks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 00:42:34 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 01:09:15 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Sotoudeh", "Matthew", ""], ["Thakur", "Aditya V.", ""]]}, {"id": "1908.06223", "submitter": "Aditya Thakur", "authors": "Matthew Sotoudeh and Aditya V. Thakur", "title": "A Symbolic Neural Network Representation and its Application to\n  Understanding, Verifying, and Patching Networks", "comments": "Code is available at https://github.com/95616ARG/SyReNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis and manipulation of trained neural networks is a challenging and\nimportant problem. We propose a symbolic representation for piecewise-linear\nneural networks and discuss its efficient computation. With this\nrepresentation, one can translate the problem of analyzing a complex neural\nnetwork into that of analyzing a finite set of affine functions. We demonstrate\nthe use of this representation for three applications. First, we apply the\nsymbolic representation to computing weakest preconditions on network inputs,\nwhich we use to exactly visualize the advisories made by a network meant to\noperate an aircraft collision avoidance system. Second, we use the symbolic\nrepresentation to compute strongest postconditions on the network outputs,\nwhich we use to perform bounded model checking on standard neural network\ncontrollers. Finally, we show how the symbolic representation can be combined\nwith a new form of neural network to perform patching; i.e., correct\nuser-specified behavior of the network.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 01:48:50 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 03:22:57 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Sotoudeh", "Matthew", ""], ["Thakur", "Aditya V.", ""]]}, {"id": "1908.06256", "submitter": "Junwei Pan", "authors": "Yizhi Mao, Miao Chen, Abhinav Wagle, Junwei Pan, Michael Natkovich,\n  Don Matheson", "title": "A Batched Multi-Armed Bandit Approach to News Headline Testing", "comments": "IEEE BigData, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing news headlines is important for publishers and media sites. A\ncompelling headline will increase readership, user engagement and social\nshares. At Yahoo Front Page, headline testing is carried out using a\ntest-rollout strategy: we first allocate equal proportion of the traffic to\neach headline variation for a defined testing period, and then shift all future\ntraffic to the best-performing variation. In this paper, we introduce a\nmulti-armed bandit (MAB) approach with batched Thompson Sampling (bTS) to\ndynamically test headlines for news articles. This method is able to gradually\nallocate traffic towards optimal headlines while testing. We evaluate the bTS\nmethod based on empirical impressions/clicks data and simulated user responses.\nThe result shows that the bTS method is robust, converges accurately and\nquickly to the optimal headline, and outperforms the test-rollout strategy by\n3.69% in terms of clicks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 07:39:19 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 05:34:26 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Mao", "Yizhi", ""], ["Chen", "Miao", ""], ["Wagle", "Abhinav", ""], ["Pan", "Junwei", ""], ["Natkovich", "Michael", ""], ["Matheson", "Don", ""]]}, {"id": "1908.06263", "submitter": "Yang Liu", "authors": "Yang Liu, Jianpeng Zhang, Chao Gao, Jinghua Qu, Lixin Ji", "title": "A Sensitivity Analysis of Attention-Gated Convolutional Neural Networks\n  for Sentence Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the effect of different hyperparameters as well\nas different combinations of hyperparameters settings on the performance of the\nAttention-Gated Convolutional Neural Networks (AGCNNs), e.g., the kernel window\nsize, the number of feature maps, the keep rate of the dropout layer, and the\nactivation function. We draw practical advice from a wide range of empirical\nresults. Through the sensitivity analysis, we further improve the\nhyperparameters settings of AGCNNs. Experiments show that our proposals could\nachieve an average of 0.81% and 0.67% improvements on AGCNN-NLReLU-rand and\nAGCNN-SELU-rand, respectively; and an average of 0.47% and 0.45% improvements\non AGCNN-NLReLU-static and AGCNN-SELU-static, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 08:40:18 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 02:22:44 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 02:30:43 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Liu", "Yang", ""], ["Zhang", "Jianpeng", ""], ["Gao", "Chao", ""], ["Qu", "Jinghua", ""], ["Ji", "Lixin", ""]]}, {"id": "1908.06277", "submitter": "Lior Wolf", "authors": "Gidi Littwin and Lior Wolf", "title": "Deep Meta Functionals for Shape Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for 3D shape reconstruction from a single image, in\nwhich a deep neural network directly maps an image to a vector of network\nweights. The network \\textcolor{black}{parametrized by} these weights\nrepresents a 3D shape by classifying every point in the volume as either within\nor outside the shape. The new representation has virtually unlimited capacity\nand resolution, and can have an arbitrary topology. Our experiments show that\nit leads to more accurate shape inference from a 2D projection than the\nexisting methods, including voxel-, silhouette-, and mesh-based methods. The\ncode is available at: https://github.com/gidilittwin/Deep-Meta\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 09:47:47 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Littwin", "Gidi", ""], ["Wolf", "Lior", ""]]}, {"id": "1908.06278", "submitter": "Xiaoyu Zhang", "authors": "Xiaoyu Zhang, Jingqing Zhang, Kai Sun, Xian Yang, Chengliang Dai, Yike\n  Guo", "title": "Integrated Multi-omics Analysis Using Variational Autoencoders:\n  Application to Pan-cancer Classification", "comments": "7 pages, 4 figures", "journal-ref": "2019 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM)", "doi": "10.1109/BIBM47256.2019.8983228", "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different aspects of a clinical sample can be revealed by multiple types of\nomics data. Integrated analysis of multi-omics data provides a comprehensive\nview of patients, which has the potential to facilitate more accurate clinical\ndecision making. However, omics data are normally high dimensional with large\nnumber of molecular features and relatively small number of available samples\nwith clinical labels. The \"dimensionality curse\" makes it challenging to train\na machine learning model using high dimensional omics data like DNA methylation\nand gene expression profiles. Here we propose an end-to-end deep learning model\ncalled OmiVAE to extract low dimensional features and classify samples from\nmulti-omics data. OmiVAE combines the basic structure of variational\nautoencoders with a classification network to achieve task-oriented feature\nextraction and multi-class classification. The training procedure of OmiVAE is\ncomprised of an unsupervised phase without the classifier and a supervised\nphase with the classifier. During the unsupervised phase, a hierarchical\ncluster structure of samples can be automatically formed without the need for\nlabels. And in the supervised phase, OmiVAE achieved an average classification\naccuracy of 97.49% after 10-fold cross-validation among 33 tumour types and\nnormal samples, which shows better performance than other existing methods. The\nOmiVAE model learned from multi-omics data outperformed that using only one\ntype of omics data, which indicates that the complementary information from\ndifferent omics datatypes provides useful insights for biomedical tasks like\ncancer classification.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 09:48:06 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhang", "Xiaoyu", ""], ["Zhang", "Jingqing", ""], ["Sun", "Kai", ""], ["Yang", "Xian", ""], ["Dai", "Chengliang", ""], ["Guo", "Yike", ""]]}, {"id": "1908.06281", "submitter": "Jiadong Lin", "authors": "Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, John E. Hopcroft", "title": "Nesterov Accelerated Gradient and Scale Invariance for Adversarial\n  Attacks", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are vulnerable to adversarial examples crafted by\napplying human-imperceptible perturbations on benign inputs. However, under the\nblack-box setting, most existing adversaries often have a poor transferability\nto attack other defense models. In this work, from the perspective of regarding\nthe adversarial example generation as an optimization process, we propose two\nnew methods to improve the transferability of adversarial examples, namely\nNesterov Iterative Fast Gradient Sign Method (NI-FGSM) and Scale-Invariant\nattack Method (SIM). NI-FGSM aims to adapt Nesterov accelerated gradient into\nthe iterative attacks so as to effectively look ahead and improve the\ntransferability of adversarial examples. While SIM is based on our discovery on\nthe scale-invariant property of deep learning models, for which we leverage to\noptimize the adversarial perturbations over the scale copies of the input\nimages so as to avoid \"overfitting\" on the white-box model being attacked and\ngenerate more transferable adversarial examples. NI-FGSM and SIM can be\nnaturally integrated to build a robust gradient-based attack to generate more\ntransferable adversarial examples against the defense models. Empirical results\non ImageNet dataset demonstrate that our attack methods exhibit higher\ntransferability and achieve higher attack success rates than state-of-the-art\ngradient-based attacks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 10:03:05 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 15:28:34 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 09:03:02 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 13:47:15 GMT"}, {"version": "v5", "created": "Mon, 3 Feb 2020 02:58:31 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Lin", "Jiadong", ""], ["Song", "Chuanbiao", ""], ["He", "Kun", ""], ["Wang", "Liwei", ""], ["Hopcroft", "John E.", ""]]}, {"id": "1908.06306", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Mayank Lunayach, Shivansh Patel and Vinay P.\n  Namboodiri", "title": "U-CAM: Visual Explanation using Uncertainty based Class Activation Maps", "comments": "ICCV 2019 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding and explaining deep learning models is an imperative task.\nTowards this, we propose a method that obtains gradient-based certainty\nestimates that also provide visual attention maps. Particularly, we solve for\nvisual question answering task. We incorporate modern probabilistic deep\nlearning methods that we further improve by using the gradients for these\nestimates. These have two-fold benefits: a) improvement in obtaining the\ncertainty estimates that correlate better with misclassified samples and b)\nimproved attention maps that provide state-of-the-art results in terms of\ncorrelation with human attention regions. The improved attention maps result in\nconsistent improvement for various methods for visual question answering.\nTherefore, the proposed technique can be thought of as a recipe for obtaining\nimproved certainty estimates and explanation for deep learning models. We\nprovide detailed empirical analysis for the visual question answering task on\nall standard benchmarks and comparison with state of the art methods.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 14:39:36 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 19:07:15 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 15:04:57 GMT"}, {"version": "v4", "created": "Thu, 17 Oct 2019 07:20:32 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Patro", "Badri N.", ""], ["Lunayach", "Mayank", ""], ["Patel", "Shivansh", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1908.06309", "submitter": "Felix Neutatz", "authors": "Felix Neutatz and Mohammad Mahdavi and Ziawasch Abedjan", "title": "ED2: Two-stage Active Learning for Error Detection -- Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional error detection approaches require user-defined parameters and\nrules. Thus, the user has to know both the error detection system and the data.\nHowever, we can also formulate error detection as a semi-supervised\nclassification problem that only requires domain expertise. The challenges for\nsuch an approach are twofold: (1) to represent the data in a way that enables a\nclassification model to identify various kinds of data errors, and (2) to pick\nthe most promising data values for learning. In this paper, we address these\nchallenges with ED2, our new example-driven error detection method. First, we\npresent a new two-dimensional multi-classifier sampling strategy for active\nlearning. Second, we propose novel multi-column features. The combined\napplication of these techniques provides fast convergence of the classification\ntask with high detection accuracy. On several real-world datasets, ED2\nrequires, on average, less than 1% labels to outperform existing error\ndetection approaches. This report extends the peer-reviewed paper \"ED2: A Case\nfor Active Learning in Error Detection\". All source code related to this\nproject is available on GitHub.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 15:13:12 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Neutatz", "Felix", ""], ["Mahdavi", "Mohammad", ""], ["Abedjan", "Ziawasch", ""]]}, {"id": "1908.06315", "submitter": "Laurent El Ghaoui", "authors": "Laurent El Ghaoui and Fangda Gu and Bertrand Travacca and Armin Askari\n  and Alicia Y. Tsai", "title": "Implicit Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit deep learning prediction rules generalize the recursive rules of\nfeedforward neural networks. Such rules are based on the solution of a\nfixed-point equation involving a single vector of hidden features, which is\nthus only implicitly defined. The implicit framework greatly simplifies the\nnotation of deep learning, and opens up many new possibilities, in terms of\nnovel architectures and algorithms, robustness analysis and design,\ninterpretability, sparsity, and network architecture optimization.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 15:36:37 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 18:55:41 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 17:35:06 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 22:10:43 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ghaoui", "Laurent El", ""], ["Gu", "Fangda", ""], ["Travacca", "Bertrand", ""], ["Askari", "Armin", ""], ["Tsai", "Alicia Y.", ""]]}, {"id": "1908.06319", "submitter": "Gagan Sidhu", "authors": "Gagan Sidhu", "title": "Locally Linear Embedding and fMRI feature selection in psychiatric\n  classification", "comments": "Main article is 10 pages. Supplementary Information is 15 pages, and\n  includes figures/results for six additional datasets, w/ performance plots\n  (as a function of dimensionality 'd'), proportion(s) of brain regions defined\n  by the respective atlases, subject ID partitioning for all eleven datasets.\n  Statistical Volumes and GraphVizModel are included in 8_statmaps.rar and\n  9_graphviz_model.rar", "journal-ref": "IEEE Journal of Translational Engineering in Health & Medicine\n  7:10, 2019", "doi": "10.1109/JTEHM.2019.2936348 10.21227/zkkm-es92", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Background:\n  Functional magnetic resonance imaging (fMRI) provides non-invasive measures\nof neuronal activity using an endogenous Blood Oxygenation-Level Dependent\n(BOLD) contrast. This article introduces a nonlinear dimensionality reduction\n(Locally Linear Embedding) to extract informative measures of the underlying\nneuronal activity from BOLD time-series. The method is validated using the\nLeave-One-Out-Cross-Validation (LOOCV) accuracy of classifying psychiatric\ndiagnoses using resting-state and task-related fMRI.\n  Methods:\n  Locally Linear Embedding of BOLD time-series (into each voxel's respective\ntensor) was used to optimise feature selection. This uses Gau\\ss' Principle of\nLeast Constraint to conserve quantities over both space and time. This\nconservation was assessed using LOOCV to greedily select time points in an\nincremental fashion on training data that was categorised in terms of\npsychiatric diagnoses.\n  Findings:\n  The embedded fMRI gave highly diagnostic performances (> 80%) on eleven\npublicly-available datasets containing healthy controls and patients with\neither Schizophrenia, Attention-Deficit Hyperactivity Disorder (ADHD), or\nAutism Spectrum Disorder (ASD). Furthermore, unlike the original fMRI data\nbefore or after using Principal Component Analysis (PCA) for artefact\nreduction, the embedded fMRI furnished significantly better than chance\nclassification (defined as the majority class proportion) on ten of eleven\ndatasets\n  Interpretation:\n  Locally Linear Embedding appears to be a useful feature extraction procedure\nthat retains important information about patterns of brain activity\ndistinguishing among psychiatric cohorts.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 17:02:17 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 20:11:25 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 14:45:08 GMT"}, {"version": "v4", "created": "Fri, 23 Aug 2019 14:11:26 GMT"}, {"version": "v5", "created": "Wed, 4 Sep 2019 23:15:36 GMT"}, {"version": "v6", "created": "Fri, 6 Sep 2019 16:47:27 GMT"}, {"version": "v7", "created": "Mon, 23 Sep 2019 18:52:48 GMT"}, {"version": "v8", "created": "Thu, 26 Sep 2019 01:17:34 GMT"}, {"version": "v9", "created": "Thu, 7 Nov 2019 04:06:49 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Sidhu", "Gagan", ""]]}, {"id": "1908.06326", "submitter": "Rahul Vashisht", "authors": "Rahul Vashisht, H.Viji, T.Sundararajan, D.Mohankumar, S.Sumitra", "title": "Structural Health Monitoring of Cantilever Beam, a Case Study -- Using\n  Bayesian Neural Network AND Deep Learning", "comments": "10 Pages", "journal-ref": null, "doi": "10.1007/978-981-13-8767-8_64", "report-no": "11", "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of machine learning algorithms has opened a wide scope for\nvibration-based SHM (Structural Health Monitoring). Vibration-based SHM is\nbased on the fact that damage will alter the dynamic properties viz.,\nstructural response, frequencies, mode shapes, etc of the structure. The\nresponses measured using sensors, which are high dimensional in nature, can be\nintelligently analyzed using machine learning techniques for damage assessment.\nNeural networks employing multilayer architectures are expressive models\ncapable of capturing complex relationships between input-output pairs but do\nnot account for uncertainty in network outputs. A BNN (Bayesian Neural Network)\nrefers to extending standard networks with posterior inference. It is a neural\nnetwork with a prior distribution on its weights. Deep learning architectures\nlike CNN (Convolutional neural network) and LSTM(Long Short Term Memory) are\ngood candidates for representation learning from high dimensional data. The\nadvantage of using CNN over multi-layer neural networks is that they are good\nfeature extractors as well as classifiers, which eliminates the need for\ngenerating hand-engineered features. LSTM networks are mainly used for sequence\nmodeling. This paper presents both a Bayesian multi-layer perceptron and deep\nlearning-based approach for damage detection and location identification in\nbeam-like structures. Raw frequency response data simulated using finite\nelement analysis is fed as the input of the network. As part of this, frequency\nresponse was generated for a series of simulations in the cantilever beam\ninvolving different damage scenarios. This case study shows the effectiveness\nof the above approaches to predict bending rigidity with an acceptable error\nrate.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 17:47:24 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Vashisht", "Rahul", ""], ["Viji", "H.", ""], ["Sundararajan", "T.", ""], ["Mohankumar", "D.", ""], ["Sumitra", "S.", ""]]}, {"id": "1908.06335", "submitter": "Jurriaan Parie", "authors": "Frank Phillipson, Jurriaan Parie, Ron Weikamp", "title": "Prune Sampling: a MCMC inference technique for discrete and\n  deterministic Bayesian networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and characterise the performance of the Markov chain Monte Carlo\n(MCMC) inference method Prune Sampling for discrete and deterministic Bayesian\nnetworks (BNs). We developed a procedure to obtain the performance of a MCMC\nsampling method in the limit of infinite simulation time, extrapolated from\nrelatively short simulations. This approach was used to conduct a study to\ncompare the accuracy, rate of convergence and the time consumption of Prune\nSampling with two conventional MCMC sampling methods: Gibbs- and Metropolis\nsampling. We show that Markov chains created by Prune Sampling always converge\nto the desired posterior distribution, also for networks where conventional\nGibbs sampling fails. Beside this, we demonstrate that pruning outperforms\nGibbs sampling, at least for a certain class of BNs. Though, this tempting\nfeature comes at a price. In the first version of Prune Sampling, for large BNs\nthe procedure to choose the next iteration step uniformly is rather time\nintensive. Our conclusion is that Prune Sampling is a competitive method for\nall types of small and medium sized BNs, but (for now) standard methods still\nperform better for all types of large BNs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 20:05:23 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Phillipson", "Frank", ""], ["Parie", "Jurriaan", ""], ["Weikamp", "Ron", ""]]}, {"id": "1908.06336", "submitter": "Alexander Kuhnle", "authors": "Alexander Kuhnle, Ann Copestake", "title": "What is needed for simple spatial language capabilities in VQA?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering (VQA) comprises a variety of language capabilities.\nThe diagnostic benchmark dataset CLEVR has fueled progress by helping to better\nassess and distinguish models in basic abilities like counting, comparing and\nspatial reasoning in vitro. Following this approach, we focus on spatial\nlanguage capabilities and investigate the question: what are the key\ningredients to handle simple visual-spatial relations? We look at the SAN,\nRelNet, FiLM and MC models and evaluate their learning behavior on diagnostic\ndata which is solely focused on spatial relations. Via comparative analysis and\ntargeted model modification we identify what really is required to\nsubstantially improve upon the CNN-LSTM baseline.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 20:12:39 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 19:03:21 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Kuhnle", "Alexander", ""], ["Copestake", "Ann", ""]]}, {"id": "1908.06337", "submitter": "Bilwaj Gaonkar", "authors": "Bilwaj Gaonkar, Joel Beckett, Mark Attiah, Christine Ahn, Matthew\n  Edwards, Bayard Wilson, Azim Laiwalla, Banafsheh Salehi, Bryan Yoo, Alex Bui,\n  Luke Macyszyn", "title": "EigenRank by Committee: A Data Subset Selection and Failure Prediction\n  paradigm for Robust Deep Learning based Medical Image Segmentation", "comments": null, "journal-ref": "Medical Image Analysis, Volume 67, 2021, Medical Image Analysis,\n  Volume 67,2021,101834,ISSN 1361-8415,", "doi": "10.1016/j.media.2020.101834", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Translation of fully automated deep learning based medical image segmentation\ntechnologies to clinical workflows face two main algorithmic challenges. The\nfirst, is the collection and archival of large quantities of manually annotated\nground truth data for both training and validation. The second is the relative\ninability of the majority of deep learning based segmentation techniques to\nalert physicians to a likely segmentation failure. Here we propose a novel\nalgorithm, named `Eigenrank' which addresses both of these challenges.\nEigenrank can select for manual labeling, a subset of medical images from a\nlarge database, such that a U-Net trained on this subset is superior to one\ntrained on a randomly selected subset of the same size. Eigenrank can also be\nused to pick out, cases in a large database, where deep learning segmentation\nwill fail. We present our algorithm, followed by results and a discussion of\nhow Eigenrank exploits the Von Neumann information to perform both data subset\nselection and failure prediction for medical image segmentation using deep\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 20:16:07 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 19:40:32 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Gaonkar", "Bilwaj", ""], ["Beckett", "Joel", ""], ["Attiah", "Mark", ""], ["Ahn", "Christine", ""], ["Edwards", "Matthew", ""], ["Wilson", "Bayard", ""], ["Laiwalla", "Azim", ""], ["Salehi", "Banafsheh", ""], ["Yoo", "Bryan", ""], ["Bui", "Alex", ""], ["Macyszyn", "Luke", ""]]}, {"id": "1908.06347", "submitter": "Trong Nguyen Nguyen", "authors": "Trong Nguyen Nguyen, Jean Meunier", "title": "Hybrid Deep Network for Anomaly Detection", "comments": "Paper accepted for BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep convolutional neural network (CNN) for\nanomaly detection in surveillance videos. The model is adapted from a typical\nauto-encoder working on video patches under the perspective of sparse\ncombination learning. Our CNN focuses on (unsupervisedly) learning common\ncharacteristics of normal events with the emphasis of their spatial locations\n(by supervised losses). To our knowledge, this is the first work that directly\nadapts the patch position as the target of a classification sub-network. The\nmodel is capable to provide a score of anomaly assessment for each video frame.\nOur experiments were performed on 4 benchmark datasets with various anomalous\nevents and the obtained results were competitive with state-of-the-art studies.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 23:08:30 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Nguyen", "Trong Nguyen", ""], ["Meunier", "Jean", ""]]}, {"id": "1908.06351", "submitter": "Trong Nguyen Nguyen", "authors": "Trong Nguyen Nguyen, Jean Meunier", "title": "Anomaly Detection in Video Sequence with Appearance-Motion\n  Correspondence", "comments": "Paper accepted for ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in surveillance videos is currently a challenge because of\nthe diversity of possible events. We propose a deep convolutional neural\nnetwork (CNN) that addresses this problem by learning a correspondence between\ncommon object appearances (e.g. pedestrian, background, tree, etc.) and their\nassociated motions. Our model is designed as a combination of a reconstruction\nnetwork and an image translation model that share the same encoder. The former\nsub-network determines the most significant structures that appear in video\nframes and the latter one attempts to associate motion templates to such\nstructures. The training stage is performed using only videos of normal events\nand the model is then capable to estimate frame-level scores for an unknown\ninput. The experiments on 6 benchmark datasets demonstrate the competitive\nperformance of the proposed approach with respect to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 23:52:22 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Nguyen", "Trong Nguyen", ""], ["Meunier", "Jean", ""]]}, {"id": "1908.06353", "submitter": "Yuh-Shyang Wang", "authors": "Yuh-Shyang Wang, Tsui-Wei Weng, Luca Daniel", "title": "Verification of Neural Network Control Policy Under Persistent\n  Adversarial Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are known to be fragile to small adversarial\nperturbations. This issue becomes more critical when a neural network is\ninterconnected with a physical system in a closed loop. In this paper, we show\nhow to combine recent works on neural network certification tools (which are\nmainly used in static settings such as image classification) with robust\ncontrol theory to certify a neural network policy in a control loop.\nSpecifically, we give a sufficient condition and an algorithm to ensure that\nthe closed loop state and control constraints are satisfied when the persistent\nadversarial perturbation is l-infinity norm bounded. Our method is based on\nfinding a positively invariant set of the closed loop dynamical system, and\nthus we do not require the differentiability or the continuity of the neural\nnetwork policy. Along with the verification result, we also develop an\neffective attack strategy for neural network control systems that outperforms\nexhaustive Monte-Carlo search significantly. We show that our certification\nalgorithm works well on learned models and achieves 5 times better result than\nthe traditional Lipschitz-based method to certify the robustness of a neural\nnetwork policy on a cart pole control problem.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 00:23:21 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Wang", "Yuh-Shyang", ""], ["Weng", "Tsui-Wei", ""], ["Daniel", "Luca", ""]]}, {"id": "1908.06369", "submitter": "Rodrigo de Lamare", "authors": "Y. Yu, L. Lu, Z. Zheng, W. Wang, Y. Zakharov and R. C. de Lamare", "title": "Robust DCD-Based Recursive Adaptive Algorithms", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dichotomous coordinate descent (DCD) algorithm has been successfully used\nfor significant reduction in the complexity of recursive least squares (RLS)\nalgorithms. In this work, we generalize the application of the DCD algorithm to\nRLS adaptive filtering in impulsive noise scenarios and derive a unified update\nformula. By employing different robust strategies against impulsive noise, we\ndevelop novel computationally efficient DCD-based robust recursive algorithms.\nFurthermore, to equip the proposed algorithms with the ability to track abrupt\nchanges in unknown systems, a simple variable forgetting factor mechanism is\nalso developed. Simulation results for channel identification scenarios in\nimpulsive noise demonstrate the effectiveness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 03:41:25 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Yu", "Y.", ""], ["Lu", "L.", ""], ["Zheng", "Z.", ""], ["Wang", "W.", ""], ["Zakharov", "Y.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "1908.06376", "submitter": "Denys Matthies", "authors": "Shamane Siriwardhana, Rivindu Weerasakera, Denys J.C. Matthies,\n  Suranga Nanayakkara", "title": "VUSFA:Variational Universal Successor Features Approximator to Improve\n  Transfer DRL for Target Driven Visual Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how novel transfer reinforcement learning techniques\ncan be applied to the complex task of target driven navigation using the\nphotorealistic AI2THOR simulator. Specifically, we build on the concept of\nUniversal Successor Features with an A3C agent. We introduce the novel\narchitectural contribution of a Successor Feature Dependant Policy (SFDP) and\nadopt the concept of Variational Information Bottlenecks to achieve state of\nthe art performance. VUSFA, our final architecture, is a straightforward\napproach that can be implemented using our open source repository. Our approach\nis generalizable, showed greater stability in training, and outperformed recent\napproaches in terms of transfer learning ability.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 04:24:08 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Siriwardhana", "Shamane", ""], ["Weerasakera", "Rivindu", ""], ["Matthies", "Denys J. C.", ""], ["Nanayakkara", "Suranga", ""]]}, {"id": "1908.06378", "submitter": "Wenrui Zhang", "authors": "Wenrui Zhang, Peng Li", "title": "Spike-Train Level Backpropagation for Training Deep Recurrent Spiking\n  Neural Networks", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": "In Advances in Neural Information Processing Systems, pp. 7800-7811.\n  2019", "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) well support spatiotemporal learning and\nenergy-efficient event-driven hardware neuromorphic processors. As an important\nclass of SNNs, recurrent spiking neural networks (RSNNs) possess great\ncomputational power. However, the practical application of RSNNs is severely\nlimited by challenges in training. Biologically-inspired unsupervised learning\nhas limited capability in boosting the performance of RSNNs. On the other hand,\nexisting backpropagation (BP) methods suffer from high complexity of unrolling\nin time, vanishing and exploding gradients, and approximate differentiation of\ndiscontinuous spiking activities when applied to RSNNs. To enable supervised\ntraining of RSNNs under a well-defined loss function, we present a novel\nSpike-Train level RSNNs Backpropagation (ST-RSBP) algorithm for training deep\nRSNNs. The proposed ST-RSBP directly computes the gradient of a rated-coded\nloss function defined at the output layer of the network w.r.t tunable\nparameters. The scalability of ST-RSBP is achieved by the proposed spike-train\nlevel computation during which temporal effects of the SNN is captured in both\nthe forward and backward pass of BP. Our ST-RSBP algorithm can be broadly\napplied to RSNNs with a single recurrent layer or deep RSNNs with multiple\nfeed-forward and recurrent layers. Based upon challenging speech and image\ndatasets including TI46, N-TIDIGITS, Fashion-MNIST and MNIST, ST-RSBP is able\nto train RSNNs with an accuracy surpassing that of the current state-of-art SNN\nBP algorithms and conventional non-spiking deep learning models.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 04:57:46 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 08:51:34 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 04:35:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhang", "Wenrui", ""], ["Li", "Peng", ""]]}, {"id": "1908.06379", "submitter": "Junru Zhou", "authors": "Junru Zhou, Shuailiang Zhang, Hai Zhao", "title": "Concurrent Parsing of Constituency and Dependency", "comments": "arXiv admin note: text overlap with arXiv:1907.02684", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constituent and dependency representation for syntactic structure share a lot\nof linguistic and computational characteristics, this paper thus makes the\nfirst attempt by introducing a new model that is capable of parsing constituent\nand dependency at the same time, so that lets either of the parsers enhance\neach other. Especially, we evaluate the effect of different shared network\ncomponents and empirically verify that dependency parsing may be much more\nbeneficial from constituent parsing structure.\n  The proposed parser achieves new state-of-the-art performance for both\nparsing tasks, constituent and dependency on PTB and CTB benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 05:10:59 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 03:54:49 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zhou", "Junru", ""], ["Zhang", "Shuailiang", ""], ["Zhao", "Hai", ""]]}, {"id": "1908.06386", "submitter": "Tristan Aumentado-Armstrong", "authors": "Tristan Aumentado-Armstrong, Stavros Tsogkas, Allan Jepson, Sven\n  Dickinson", "title": "Geometric Disentanglement for Generative Latent Shape Models", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing 3D shape is a fundamental problem in artificial intelligence,\nwhich has numerous applications within computer vision and graphics. One avenue\nthat has recently begun to be explored is the use of latent representations of\ngenerative models. However, it remains an open problem to learn a generative\nmodel of shape that is interpretable and easily manipulated, particularly in\nthe absence of supervised labels. In this paper, we propose an unsupervised\napproach to partitioning the latent space of a variational autoencoder for 3D\npoint clouds in a natural way, using only geometric information. Our method\nmakes use of tools from spectral differential geometry to separate intrinsic\nand extrinsic shape information, and then considers several hierarchical\ndisentanglement penalties for dividing the latent space in this manner,\nincluding a novel one that penalizes the Jacobian of the latent representation\nof the decoded output with respect to the latent encoding. We show that the\nresulting representation exhibits intuitive and interpretable behavior,\nenabling tasks such as pose transfer and pose-aware shape retrieval that cannot\neasily be performed by models with an entangled representation.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 07:05:39 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Aumentado-Armstrong", "Tristan", ""], ["Tsogkas", "Stavros", ""], ["Jepson", "Allan", ""], ["Dickinson", "Sven", ""]]}, {"id": "1908.06395", "submitter": "Hao Jin", "authors": "Hao Jin, Dachao Lin, Zhihua Zhang", "title": "Towards Better Generalization: BP-SVRG in Training Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variance-reduced gradient (SVRG) is a classical optimization\nmethod. Although it is theoretically proved to have better convergence\nperformance than stochastic gradient descent (SGD), the generalization\nperformance of SVRG remains open. In this paper we investigate the effects of\nsome training techniques, mini-batching and learning rate decay, on the\ngeneralization performance of SVRG, and verify the generalization performance\nof Batch-SVRG (B-SVRG). In terms of the relationship between optimization and\ngeneralization, we believe that the average norm of gradients on each training\nsample as well as the norm of average gradient indicate how flat the landscape\nis and how well the model generalizes. Based on empirical observations of such\nmetrics, we perform a sign switch on B-SVRG and derive a practical algorithm,\nBatchPlus-SVRG (BP-SVRG), which is numerically shown to enjoy better\ngeneralization performance than B-SVRG, even SGD in some scenarios of deep\nneural networks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 08:12:03 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Jin", "Hao", ""], ["Lin", "Dachao", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1908.06416", "submitter": "Rohan Ghosh", "authors": "Rohan Ghosh, Anupam K. Gupta, Mehul Motani", "title": "Investigating Convolutional Neural Networks using Spatial Orderness", "comments": "Presented at BMVC 2019: Workshop on Interpretable and Explainable\n  Machine Vision, Cardiff, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have been pivotal to the success of many\nstate-of-the-art classification problems, in a wide variety of domains (for\ne.g. vision, speech, graphs and medical imaging). A commonality within those\ndomains is the presence of hierarchical, spatially agglomerative\nlocal-to-global interactions within the data. For two-dimensional images, such\ninteractions may induce an a priori relationship between the pixel data and the\nunderlying spatial ordering of the pixels. For instance in natural images,\nneighboring pixels are more likely contain similar values than non-neighboring\npixels which are further apart. To that end, we propose a statistical metric\ncalled spatial orderness, which quantifies the extent to which the input data\n(2D) obeys the underlying spatial ordering at various scales. In our\nexperiments, we mainly find that adding convolutional layers to a CNN could be\ncounterproductive for data bereft of spatial order at higher scales. We also\nobserve, quite counter-intuitively, that the spatial orderness of CNN feature\nmaps show a synchronized increase during the intial stages of training, and\nvalidation performance only improves after spatial orderness of feature maps\nstart decreasing. Lastly, we present a theoretical analysis (and empirical\nvalidation) of the spatial orderness of network weights, where we find that\nusing smaller kernel sizes leads to kernels of greater spatial orderness and\nvice-versa.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 10:05:24 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 16:35:10 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ghosh", "Rohan", ""], ["Gupta", "Anupam K.", ""], ["Motani", "Mehul", ""]]}, {"id": "1908.06435", "submitter": "Gabriele Pergola", "authors": "Gabriele Pergola, Lin Gui, Yulan He", "title": "TDAM: a Topic-Dependent Attention Model for Sentiment Analysis", "comments": null, "journal-ref": "Information Processing & Management, 56 (6), 102084, July 2019", "doi": "10.1016/j.ipm.2019.102084", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a topic-dependent attention model for sentiment classification and\ntopic extraction. Our model assumes that a global topic embedding is shared\nacross documents and employs an attention mechanism to derive local topic\nembedding for words and sentences. These are subsequently incorporated in a\nmodified Gated Recurrent Unit (GRU) for sentiment classification and extraction\nof topics bearing different sentiment polarities. Those topics emerge from the\nwords' local topic embeddings learned by the internal attention of the GRU\ncells in the context of a multi-task learning framework. In this paper, we\npresent the hierarchical architecture, the new GRU unit and the experiments\nconducted on users' reviews which demonstrate classification performance on a\npar with the state-of-the-art methodologies for sentiment classification and\ntopic coherence outperforming the current approaches for supervised topic\nextraction. In addition, our model is able to extract coherent aspect-sentiment\nclusters despite using no aspect-level annotations for training.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 12:50:47 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Pergola", "Gabriele", ""], ["Gui", "Lin", ""], ["He", "Yulan", ""]]}, {"id": "1908.06449", "submitter": "Chuan Meng", "authors": "Chuan Meng, Pengjie Ren, Zhumin Chen, Christof Monz, Jun Ma, Maarten\n  de Rijke", "title": "RefNet: A Reference-aware Network for Background Based Conversation", "comments": "Accepted to AAAI 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing conversational systems tend to generate generic responses. Recently,\nBackground Based Conversations (BBCs) have been introduced to address this\nissue. Here, the generated responses are grounded in some background\ninformation. The proposed methods for BBCs are able to generate more\ninformative responses, they either cannot generate natural responses or have\ndifficulty in locating the right background information. In this paper, we\npropose a Reference-aware Network (RefNet) to address the two issues. Unlike\nexisting methods that generate responses token by token, RefNet incorporates a\nnovel reference decoder that provides an alternative way to learn to directly\ncite a semantic unit (e.g., a span containing complete semantic information)\nfrom the background. Experimental results show that RefNet significantly\noutperforms state-of-the-art methods in terms of both automatic and human\nevaluations, indicating that RefNet can generate more appropriate and\nhuman-like responses.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 14:49:16 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 07:56:45 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Meng", "Chuan", ""], ["Ren", "Pengjie", ""], ["Chen", "Zhumin", ""], ["Monz", "Christof", ""], ["Ma", "Jun", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1908.06468", "submitter": "Kai Zhen", "authors": "Kai Zhen, Mi Suk Lee, Minje Kim", "title": "A Dual-Staged Context Aggregation Method Towards Efficient End-To-End\n  Speech Enhancement", "comments": "Accepted in Proceedings of the ICASSP, Barcelona, Spain, May 4-8,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In speech enhancement, an end-to-end deep neural network converts a noisy\nspeech signal to a clean speech directly in time domain without time-frequency\ntransformation or mask estimation. However, aggregating contextual information\nfrom a high-resolution time domain signal with an affordable model complexity\nstill remains challenging. In this paper, we propose a densely connected\nconvolutional and recurrent network (DCCRN), a hybrid architecture, to enable\ndual-staged temporal context aggregation. With the dense connectivity and\ncross-component identical shortcut, DCCRN consistently outperforms competing\nconvolutional baselines with an average STOI improvement of 0.23 and PESQ of\n1.38 at three SNR levels. The proposed method is computationally efficient with\nonly 1.38 million parameters. The generalizability performance on the unseen\nnoise types is still decent considering its low complexity, although it is\nrelatively weaker comparing to Wave-U-Net with 7.25 times more parameters.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 15:53:09 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 15:17:57 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 20:32:36 GMT"}, {"version": "v4", "created": "Thu, 6 Feb 2020 23:28:51 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Zhen", "Kai", ""], ["Lee", "Mi Suk", ""], ["Kim", "Minje", ""]]}, {"id": "1908.06472", "submitter": "Andreas Kamilaris", "authors": "Andreas Kamilaris, Corjan van den Brink and Savvas Karatsiolis", "title": "Training Deep Learning Models via Synthetic Data: Application in\n  Unmanned Aerial Vehicles", "comments": "Workshop on Deep-learning based computer vision for UAV in\n  conjunction with CAIP 2019, Salerno, italy, September 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes preliminary work in the recent promising approach of\ngenerating synthetic training data for facilitating the learning procedure of\ndeep learning (DL) models, with a focus on aerial photos produced by unmanned\naerial vehicles (UAV). The general concept and methodology are described, and\npreliminary results are presented, based on a classification problem of fire\nidentification in forests as well as a counting problem of estimating number of\nhouses in urban areas. The proposed technique constitutes a new possibility for\nthe DL community, especially related to UAV-based imagery analysis, with much\npotential, promising results, and unexplored ground for further research.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 16:25:14 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Kamilaris", "Andreas", ""], ["Brink", "Corjan van den", ""], ["Karatsiolis", "Savvas", ""]]}, {"id": "1908.06475", "submitter": "John Klein", "authors": "Mahmoud Albardan, John Klein and Olivier Colot", "title": "SPOCC: Scalable POssibilistic Classifier Combination -- toward robust\n  aggregation of classifiers", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2020.113332", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a problem in which each member of a group of learners is\ntrained separately to solve the same classification task. Each learner has\naccess to a training dataset (possibly with overlap across learners) but each\ntrained classifier can be evaluated on a validation dataset. We propose a new\napproach to aggregate the learner predictions in the possibility theory\nframework. For each classifier prediction, we build a possibility distribution\nassessing how likely the classifier prediction is correct using frequentist\nprobabilities estimated on the validation set. The possibility distributions\nare aggregated using an adaptive t-norm that can accommodate dependency and\npoor accuracy of the classifier predictions. We prove that the proposed\napproach possesses a number of desirable classifier combination robustness\nproperties.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 16:48:37 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 22:19:29 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Albardan", "Mahmoud", ""], ["Klein", "John", ""], ["Colot", "Olivier", ""]]}, {"id": "1908.06477", "submitter": "Yanzhao Wu", "authors": "Yanzhao Wu, Ling Liu, Juhyun Bae, Ka-Ho Chow, Arun Iyengar, Calton Pu,\n  Wenqi Wei, Lei Yu, Qi Zhang", "title": "Demystifying Learning Rate Policies for High Accuracy Training of Deep\n  Neural Networks", "comments": "To appear on IEEE Big Data 2019. LRBench\n  (https://github.com/git-disl/LRBench)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning Rate (LR) is an important hyper-parameter to tune for effective\ntraining of deep neural networks (DNNs). Even for the baseline of a constant\nlearning rate, it is non-trivial to choose a good constant value for training a\nDNN. Dynamic learning rates involve multi-step tuning of LR values at various\nstages of the training process and offer high accuracy and fast convergence.\nHowever, they are much harder to tune. In this paper, we present a\ncomprehensive study of 13 learning rate functions and their associated LR\npolicies by examining their range parameters, step parameters, and value update\nparameters. We propose a set of metrics for evaluating and selecting LR\npolicies, including the classification confidence, variance, cost, and\nrobustness, and implement them in LRBench, an LR benchmarking system. LRBench\ncan assist end-users and DNN developers to select good LR policies and avoid\nbad LR policies for training their DNNs. We tested LRBench on Caffe, an open\nsource deep learning framework, to showcase the tuning optimization of LR\npolicies. Evaluated through extensive experiments, we attempt to demystify the\ntuning of LR policies by identifying good LR policies with effective LR value\nranges and step sizes for LR update schedules.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 16:58:52 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 20:45:08 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wu", "Yanzhao", ""], ["Liu", "Ling", ""], ["Bae", "Juhyun", ""], ["Chow", "Ka-Ho", ""], ["Iyengar", "Arun", ""], ["Pu", "Calton", ""], ["Wei", "Wenqi", ""], ["Yu", "Lei", ""], ["Zhang", "Qi", ""]]}, {"id": "1908.06482", "submitter": "Chao Chen", "authors": "Chao Chen, Yifei Liu, Xi Zhang, Sihong Xie", "title": "Scalable Explanation of Inferences on Large Graphs", "comments": "Accepted to ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic inferences distill knowledge from graphs to aid human make\nimportant decisions. Due to the inherent uncertainty in the model and the\ncomplexity of the knowledge, it is desirable to help the end-users understand\nthe inference outcomes. Different from deep or high-dimensional parametric\nmodels, the lack of interpretability in graphical models is due to the cyclic\nand long-range dependencies and the byzantine inference procedures. Prior works\ndid not tackle cycles and make \\textit{the} inferences interpretable. To close\nthe gap, we formulate the problem of explaining probabilistic inferences as a\nconstrained cross-entropy minimization problem to find simple subgraphs that\nfaithfully approximate the inferences to be explained. We prove that the\noptimization is NP-hard, while the objective is not monotonic and submodular to\nguarantee efficient greedy approximation. We propose a general beam search\nalgorithm to find simple trees to enhance the interpretability and diversity in\nthe explanations, with parallelization and a pruning strategy to allow\nefficient search on large and dense graphs without hurting faithfulness. We\ndemonstrate superior performance on 10 networks from 4 distinct applications,\ncomparing favorably to other explanation methods. Regarding the usability of\nthe explanation, we visualize the explanation in an interface that allows the\nend-users to explore the diverse search results and find more personalized and\nsensible explanations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:17:00 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 01:36:08 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Chen", "Chao", ""], ["Liu", "Yifei", ""], ["Zhang", "Xi", ""], ["Xie", "Sihong", ""]]}, {"id": "1908.06486", "submitter": "Ronak Mehta", "authors": "Ronak Mehta, Jaewon Chung, Cencheng Shen, Ting Xu, Joshua T.\n  Vogelstein", "title": "Independence Testing for Multivariate Time Series", "comments": "21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex data structures such as time series are increasingly present in\nmodern data science problems. A fundamental question is whether two such\ntime-series are statistically dependent. Many current approaches make\nparametric assumptions on the random processes, only detect linear association,\nrequire multiple tests, or forfeit power in high-dimensional, nonlinear\nsettings. Estimating the distribution of any test statistic under the null is\nnon-trivial, as the permutation test is invalid. This work juxtaposes distance\ncorrelation (Dcorr) and multiscale graph correlation (MGC) from independence\ntesting literature and block permutation from time series analysis to address\nthese challenges. The proposed nonparametric procedure is valid and consistent,\nbuilding upon prior work by characterizing the geometry of the relationship,\nestimating the time lag at which dependence is maximized, avoiding the need for\nmultiple testing, and exhibiting superior power in high-dimensional, low sample\nsize, nonlinear settings. Neural connectivity is analyzed via fMRI data,\nrevealing linear dependence of signals within the visual network and default\nmode network, and nonlinear relationships in other networks. This work uncovers\na first-resort data analysis tool with open-source code available, directly\nimpacting a wide range of scientific disciplines.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 17:19:16 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 23:29:57 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 00:50:32 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Mehta", "Ronak", ""], ["Chung", "Jaewon", ""], ["Shen", "Cencheng", ""], ["Xu", "Ting", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1908.06487", "submitter": "M. Sohel Rahman", "authors": "Md. Adnan Arefeen, Sumaiya Tabassum Nimi, and M Sohel Rahman", "title": "Neural Network Based Undersampling Techniques", "comments": "8 pages in IEEE format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance problem is commonly faced while developing machine learning\nmodels for real-life issues. Due to this problem, the fitted model tends to be\nbiased towards the majority class data, which leads to lower precision, recall,\nAUC, F1, G-mean score. Several researches have been done to tackle this\nproblem, most of which employed resampling, i.e. oversampling and undersampling\ntechniques to bring the required balance in the data. In this paper, we propose\nneural network based algorithms for undersampling. Then we resampled several\nclass imbalanced data using our algorithms and also some other popular\nresampling techniques. Afterwards we classified these undersampled data using\nsome common classifier. We found out that our resampling approaches outperform\nmost other resampling techniques in terms of both AUC, F1 and G-mean score.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 17:38:53 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Arefeen", "Md. Adnan", ""], ["Nimi", "Sumaiya Tabassum", ""], ["Rahman", "M Sohel", ""]]}, {"id": "1908.06491", "submitter": "Chengxi Zang", "authors": "Chengxi Zang, Fei Wang", "title": "Neural Dynamics on Complex Networks", "comments": "Department of Population Health Sciences, Weill Cornell Medicine,\n  Cornell University; chz4001@med.cornell.edu, few2001@med.cornell.edu", "journal-ref": null, "doi": "10.1145/3292500.3330842", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning continuous-time dynamics on complex networks is crucial for\nunderstanding, predicting and controlling complex systems in science and\nengineering. However, this task is very challenging due to the combinatorial\ncomplexities in the structures of high dimensional systems, their elusive\ncontinuous-time nonlinear dynamics, and their structural-dynamic dependencies.\nTo address these challenges, we propose to combine Ordinary Differential\nEquation Systems (ODEs) and Graph Neural Networks (GNNs) to learn\ncontinuous-time dynamics on complex networks in a data-driven manner. We model\ndifferential equation systems by GNNs. Instead of mapping through a discrete\nnumber of neural layers in the forward process, we integrate GNN layers over\ncontinuous time numerically, leading to capturing continuous-time dynamics on\ngraphs. Our model can be interpreted as a Continuous-time GNN model or a Graph\nNeural ODEs model. Our model can be utilized for continuous-time network\ndynamics prediction, structured sequence prediction (a regularly-sampled case),\nand node semi-supervised classification tasks (a one-snapshot case) in a\nunified framework. We validate our model by extensive experiments in the above\nthree scenarios. The promising experimental results demonstrate our model's\ncapability of jointly capturing the structure and dynamics of complex systems\nin a unified framework.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 18:03:53 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 20:08:48 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Zang", "Chengxi", ""], ["Wang", "Fei", ""]]}, {"id": "1908.06493", "submitter": "Fernando Benites De Azevedo E Souza", "authors": "Fernando Benites", "title": "TwistBytes -- Hierarchical Classification at GermEval 2019: walking the\n  fine line (of recall and precision)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here our approach to the GermEval 2019 Task 1 - Shared Task on\nhierarchical classification of German blurbs. We achieved first place in the\nhierarchical subtask B and second place on the root node, flat classification\nsubtask A. In subtask A, we applied a simple multi-feature TF-IDF extraction\nmethod using different n-gram range and stopword removal, on each feature\nextraction module. The classifier on top was a standard linear SVM. For the\nhierarchical classification, we used a local approach, which was more\nlight-weighted but was similar to the one used in subtask A. The key point of\nour approach was the application of a post-processing to cope with the\nmulti-label aspect of the task, increasing the recall but not surpassing the\nprecision measure score.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 18:09:19 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Benites", "Fernando", ""]]}, {"id": "1908.06498", "submitter": "Aliasghar Mortazi", "authors": "Aliasghar Mortazi, Naji Khosravan, Drew A. Torigian, Sila Kurugol,\n  Ulas Bagci", "title": "Weakly Supervised Segmentation by A Deep Geodesic Prior", "comments": "Accepted to Machine Learning in Medical Imaging (MLMI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of the state-of-the-art image segmentation methods heavily\nrelies on the high-quality annotations, which are not easily affordable,\nparticularly for medical data. To alleviate this limitation, in this study, we\npropose a weakly supervised image segmentation method based on a deep geodesic\nprior. We hypothesize that integration of this prior information can reduce the\nadverse effects of weak labels in segmentation accuracy. Our proposed algorithm\nis based on a prior information, extracted from an auto-encoder, trained to map\nobjects geodesic maps to their corresponding binary maps. The obtained\ninformation is then used as an extra term in the loss function of the\nsegmentor. In order to show efficacy of the proposed strategy, we have\nexperimented segmentation of cardiac substructures with clean and two levels of\nnoisy labels (L1, L2). Our experiments showed that the proposed algorithm\nboosted the performance of baseline deep learning-based segmentation for both\nclean and noisy labels by 4.4%, 4.6%(L1), and 6.3%(L2) in dice score,\nrespectively. We also showed that the proposed method was more robust in the\npresence of high-level noise due to the existence of shape priors.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 18:43:44 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Mortazi", "Aliasghar", ""], ["Khosravan", "Naji", ""], ["Torigian", "Drew A.", ""], ["Kurugol", "Sila", ""], ["Bagci", "Ulas", ""]]}, {"id": "1908.06512", "submitter": "Harvineet Singh", "authors": "Moumita Sinha, Vishwa Vinay, Harvineet Singh", "title": "Modeling Time to Open of Emails with a Latent State for User Engagement\n  Level", "comments": "9 pages, 5 figures, WSDM'18, February 5-9, 2018, Marina Del Rey, CA,\n  USA, https://dl.acm.org/citation.cfm?id=3159683", "journal-ref": "Proceedings of the Eleventh ACM International Conference on Web\n  Search and Data Mining (WSDM 2018). ACM, New York, NY, USA, 531-539", "doi": "10.1145/3159652.3159683", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Email messages have been an important mode of communication, not only for\nwork, but also for social interactions and marketing. When messages have time\nsensitive information, it becomes relevant for the sender to know what is the\nexpected time within which the email will be read by the recipient. In this\npaper we use a survival analysis framework to predict the time to open an email\nonce it has been received. We use the Cox Proportional Hazards (CoxPH) model\nthat offers a way to combine various features that might affect the event of\nopening an email. As an extension, we also apply a mixture model (MM) approach\nto CoxPH that distinguishes between recipients, based on a latent state of how\nprone to opening the messages each individual is. We compare our approach with\nstandard classification and regression models. While the classification model\nprovides predictions on the likelihood of an email being opened, the regression\nmodel provides prediction of the real-valued time to open. The use of survival\nanalysis based methods allows us to jointly model both the open event as well\nas the time-to-open. We experimented on a large real-world dataset of marketing\nemails sent in a 3-month time duration. The mixture model achieves the best\naccuracy on our data where a high proportion of email messages go unopened.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 20:55:27 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Sinha", "Moumita", ""], ["Vinay", "Vishwa", ""], ["Singh", "Harvineet", ""]]}, {"id": "1908.06543", "submitter": "Palash Goyal", "authors": "Palash Goyal, Di Huang, Ankita Goswami, Sujit Rokka Chhetri,\n  Arquimedes Canedo and Emilio Ferrara", "title": "Benchmarks for Graph Embedding Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding is the task of representing nodes of a graph in a\nlow-dimensional space and its applications for graph tasks have gained\nsignificant traction in academia and industry. The primary difference among the\nmany recently proposed graph embedding methods is the way they preserve the\ninherent properties of the graphs. However, in practice, comparing these\nmethods is very challenging. The majority of methods report performance boosts\non few selected real graphs. Therefore, it is difficult to generalize these\nperformance improvements to other types of graphs. Given a graph, it is\ncurrently impossible to quantify the advantages of one approach over another.\nIn this work, we introduce a principled framework to compare graph embedding\nmethods. Our goal is threefold: (i) provide a unifying framework for comparing\nthe performance of various graph embedding methods, (ii) establish a benchmark\nwith real-world graphs that exhibit different structural properties, and (iii)\nprovide users with a tool to identify the best graph embedding method for their\ndata. This paper evaluates 4 of the most influential graph embedding methods\nand 4 traditional link prediction methods against a corpus of 100 real-world\nnetworks with varying properties. We organize the 100 networks in terms of\ntheir properties to get a better understanding of the embedding performance of\nthese popular methods. We use the comparisons on our 100 benchmark graphs to\ndefine GFS-score, that can be applied to any embedding method to quantify its\nperformance. We rank the state-of-the-art embedding approaches using the\nGFS-score and show that it can be used to understand and evaluate novel\nembedding approaches. We envision that the proposed framework\n(https://www.github.com/palash1992/GEM-Benchmark) will serve the community as a\nbenchmarking platform to test and compare the performance of future graph\nembedding techniques.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 00:19:57 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 21:20:57 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 22:30:07 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Goyal", "Palash", ""], ["Huang", "Di", ""], ["Goswami", "Ankita", ""], ["Chhetri", "Sujit Rokka", ""], ["Canedo", "Arquimedes", ""], ["Ferrara", "Emilio", ""]]}, {"id": "1908.06556", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu and Mark O. Riedl", "title": "Transfer in Deep Reinforcement Learning using Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text adventure games, in which players must make sense of the world through\ntext descriptions and declare actions through text descriptions, provide a\nstepping stone toward grounding action in language. Prior work has demonstrated\nthat using a knowledge graph as a state representation and question-answering\nto pre-train a deep Q-network facilitates faster control policy transfer. In\nthis paper, we explore the use of knowledge graphs as a representation for\ndomain knowledge transfer for training text-adventure playing reinforcement\nlearning agents. Our methods are tested across multiple computer generated and\nhuman authored games, varying in domain and complexity, and demonstrate that\nour transfer learning methods let us learn a higher-quality control policy\nfaster.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 01:52:00 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1908.06559", "submitter": "Liang Ding", "authors": "Liang Ding, Dacheng Tao", "title": "Recurrent Graph Syntax Encoder for Neural Machine Translation", "comments": "Work in Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntax-incorporated machine translation models have been proven successful in\nimproving the model's reasoning and meaning preservation ability. In this\npaper, we propose a simple yet effective graph-structured encoder, the\nRecurrent Graph Syntax Encoder, dubbed \\textbf{RGSE}, which enhances the\nability to capture useful syntactic information. The RGSE is done over a\nstandard encoder (recurrent or self-attention encoder), regarding recurrent\nnetwork units as graph nodes and injects syntactic dependencies as edges, such\nthat RGSE models syntactic dependencies and sequential information\n(\\textit{i.e.}, word order) simultaneously. Our approach achieves considerable\nimprovements over several syntax-aware NMT models in English$\\Rightarrow$German\nand English$\\Rightarrow$Czech translation tasks. And RGSE-equipped big model\nobtains competitive result compared with the state-of-the-art model in WMT14\nEn-De task. Extensive analysis further verifies that RGSE could benefit long\nsentence modeling, and produces better translations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 02:10:39 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ding", "Liang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1908.06566", "submitter": "Zhendong Zhang", "authors": "Zhendong Zhang, Cheolkon Jung and Xiaolong Liang", "title": "Adversarial Defense by Suppressing High-frequency Components", "comments": "3 pages. This paper is a technical report of the 5th place solution\n  in the IJCAI-2019 Alibaba Adversarial AI Challenge. This paper has been\n  accepted by the corresponding workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works show that deep neural networks trained on image classification\ndataset bias towards textures. Those models are easily fooled by applying small\nhigh-frequency perturbations to clean images. In this paper, we learn robust\nimage classification models by removing high-frequency components.\nSpecifically, we develop a differentiable high-frequency suppression module\nbased on discrete Fourier transform (DFT). Combining with adversarial training,\nwe won the 5th place in the IJCAI-2019 Alibaba Adversarial AI Challenge. Our\ncode is available online.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 02:43:35 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 15:49:51 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 09:00:46 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhang", "Zhendong", ""], ["Jung", "Cheolkon", ""], ["Liang", "Xiaolong", ""]]}, {"id": "1908.06571", "submitter": "Grigorios Chrysos", "authors": "Grigorios Chrysos, Stylianos Moschoglou, Yannis Panagakis, Stefanos\n  Zafeiriou", "title": "PolyGAN: High-Order Polynomial Generators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have become the gold standard when it\ncomes to learning generative models for high-dimensional distributions. Since\ntheir advent, numerous variations of GANs have been introduced in the\nliterature, primarily focusing on utilization of novel loss functions,\noptimization/regularization strategies and network architectures. In this\npaper, we turn our attention to the generator and investigate the use of\nhigh-order polynomials as an alternative class of universal function\napproximators. Concretely, we propose PolyGAN, where we model the data\ngenerator by means of a high-order polynomial whose unknown parameters are\nnaturally represented by high-order tensors. We introduce two tensor\ndecompositions that significantly reduce the number of parameters and show how\nthey can be efficiently implemented by hierarchical neural networks that only\nemploy linear/convolutional blocks. We exhibit for the first time that by using\nour approach a GAN generator can approximate the data distribution without\nusing any activation functions. Thorough experimental evaluation on both\nsynthetic and real data (images and 3D point clouds) demonstrates the merits of\nPolyGAN against the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 03:14:00 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 15:37:29 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Chrysos", "Grigorios", ""], ["Moschoglou", "Stylianos", ""], ["Panagakis", "Yannis", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1908.06599", "submitter": "Yongli Zhu", "authors": "Yongli Zhu, Chengxi Liu", "title": "Mitigating Multi-Stage Cascading Failure by Reinforcement Learning", "comments": "This paper has been accepted and presented in the IEEE ISGT-Asia\n  conference in 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a cascading failure mitigation strategy based on\nReinforcement Learning (RL) method. Firstly, the principles of RL are\nintroduced. Then, the Multi-Stage Cascading Failure (MSCF) problem is presented\nand its challenges are investigated. The problem is then tackled by the RL\nbased on DC-OPF (Optimal Power Flow). Designs of the key elements of the RL\nframework (rewards, states, etc.) are also discussed in detail. Experiments on\nthe IEEE 118-bus system by both shallow and deep neural networks demonstrate\npromising results in terms of reduced system collapse rates.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 05:41:23 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Zhu", "Yongli", ""], ["Liu", "Chengxi", ""]]}, {"id": "1908.06603", "submitter": "Huaipei Wang", "authors": "Yanshan Xiao, HuaiPei Wang, Bo Liu", "title": "Transfer Learning-Based Label Proportions Method with Data of\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with label proportions (LLP), which is a learning task that only\nprovides unlabeled data in bags and each bag's label proportion, has widespread\nsuccessful applications in practice. However, most of the existing LLP methods\ndon't consider the knowledge transfer for uncertain data. This paper presents a\ntransfer learning-based approach for the problem of learning with label\nproportions(TL-LLP) to transfer knowledge from source task to target task where\nboth the source and target tasks contain uncertain data. Our approach first\nformulates objective model for the uncertain data and deals with transfer\nlearning at the same time, and then proposes an iterative framework to build an\naccurate classifier for the target task. Extensive experiments have shown that\nthe proposed TL-LLP method can obtain the better accuracies and is less\nsensitive to noise compared with the existing LLP methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 05:56:25 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Xiao", "Yanshan", ""], ["Wang", "HuaiPei", ""], ["Liu", "Bo", ""]]}, {"id": "1908.06605", "submitter": "Zhihong Shao", "authors": "Zhihong Shao, Minlie Huang, Jiangtao Wen, Wenfei Xu, Xiaoyan Zhu", "title": "Long and Diverse Text Generation with Planning-based Hierarchical\n  Variational Model", "comments": "To appear in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural methods for data-to-text generation are still struggling to\nproduce long and diverse texts: they are insufficient to model input data\ndynamically during generation, to capture inter-sentence coherence, or to\ngenerate diversified expressions. To address these issues, we propose a\nPlanning-based Hierarchical Variational Model (PHVM). Our model first plans a\nsequence of groups (each group is a subset of input items to be covered by a\nsentence) and then realizes each sentence conditioned on the planning result\nand the previously generated context, thereby decomposing long text generation\ninto dependent sentence generation sub-tasks. To capture expression diversity,\nwe devise a hierarchical latent structure where a global planning latent\nvariable models the diversity of reasonable planning and a sequence of local\nlatent variables controls sentence realization. Experiments show that our model\noutperforms state-of-the-art baselines in long and diverse text generation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 06:20:38 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 01:57:50 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Shao", "Zhihong", ""], ["Huang", "Minlie", ""], ["Wen", "Jiangtao", ""], ["Xu", "Wenfei", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1908.06612", "submitter": "Kyle Young Mr", "authors": "Kyle Young, Gareth Booth, Becks Simpson, Reuben Dutton and Sally\n  Shrapnel", "title": "Deep neural network or dermatologist?", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-33850-3_6", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have proven high accuracy for identifying melanoma\nin digitised dermoscopic images. A strength is that these methods are not\nconstrained by features that are pre-defined by human semantics. A down-side is\nthat it is difficult to understand the rationale of the model predictions and\nto identify potential failure modes. This is a major barrier to adoption of\ndeep learning in clinical practice. In this paper we ask if two existing local\ninterpretability methods, Grad-CAM and Kernel SHAP, can shed light on\nconvolutional neural networks trained in the context of melanoma detection. Our\ncontributions are (i) we first explore the domain space via a reproducible,\nend-to-end learning framework that creates a suite of 30 models, all trained on\na publicly available data set (HAM10000), (ii) we next explore the reliability\nof GradCAM and Kernel SHAP in this context via some basic sanity check\nexperiments (iii) finally, we investigate a random selection of models from our\nsuite using GradCAM and Kernel SHAP. We show that despite high accuracy, the\nmodels will occasionally assign importance to features that are not relevant to\nthe diagnostic task. We also show that models of similar accuracy will produce\ndifferent explanations as measured by these methods. This work represents first\nsteps in bridging the gap between model accuracy and interpretability in the\ndomain of skin cancer classification.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 06:40:52 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Young", "Kyle", ""], ["Booth", "Gareth", ""], ["Simpson", "Becks", ""], ["Dutton", "Reuben", ""], ["Shrapnel", "Sally", ""]]}, {"id": "1908.06625", "submitter": "Joel Ruben Antony Moniz", "authors": "Barun Patra, Joel Ruben Antony Moniz, Sarthak Garg, Matthew R.\n  Gormley, Graham Neubig", "title": "Bilingual Lexicon Induction with Semi-supervision in Non-Isometric\n  Embedding Spaces", "comments": "ACL 2019", "journal-ref": "Proceedings of the 57th Conference of the Association for\n  Computational Linguistics (2019) 184-193", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on bilingual lexicon induction (BLI) has frequently depended\neither on aligned bilingual lexicons or on distribution matching, often with an\nassumption about the isometry of the two spaces. We propose a technique to\nquantitatively estimate this assumption of the isometry between two embedding\nspaces and empirically show that this assumption weakens as the languages in\nquestion become increasingly etymologically distant. We then propose Bilingual\nLexicon Induction with Semi-Supervision (BLISS) --- a semi-supervised approach\nthat relaxes the isometric assumption while leveraging both limited aligned\nbilingual lexicons and a larger set of unaligned word embeddings, as well as a\nnovel hubness filtering technique. Our proposed method obtains state of the art\nresults on 15 of 18 language pairs on the MUSE dataset, and does particularly\nwell when the embedding spaces don't appear to be isometric. In addition, we\nalso show that adding supervision stabilizes the learning procedure, and is\neffective even with minimal supervision.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 07:36:19 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Patra", "Barun", ""], ["Moniz", "Joel Ruben Antony", ""], ["Garg", "Sarthak", ""], ["Gormley", "Matthew R.", ""], ["Neubig", "Graham", ""]]}, {"id": "1908.06649", "submitter": "Francesco Silvestri", "authors": "Rezaul Chowdhury and Francesco Silvestri and Flavio Vella", "title": "A Computational Model for Tensor Core Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To respond to the need of efficient training and inference of deep neural\nnetworks, a plethora of domain-specific hardware architectures have been\nintroduced, such as Google Tensor Processing Units and NVIDIA Tensor Cores. A\ncommon feature of these architectures is a hardware circuit for efficiently\ncomputing a dense matrix multiplication of a given small size. In order to\nbroaden the class of algorithms that exploit these systems, we propose a\ncomputational model, named the TCU model, that captures the ability to natively\nmultiply small matrices. We then use the TCU model for designing fast\nalgorithms for several problems, including matrix operations (dense and sparse\nmultiplication, Gaussian Elimination), graph algorithms (transitive closure,\nall pairs shortest distances), Discrete Fourier Transform, stencil\ncomputations, integer multiplication, and polynomial evaluation. We finally\nhighlight a relation between the TCU model and the external memory model.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 08:59:46 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 07:25:17 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Chowdhury", "Rezaul", ""], ["Silvestri", "Francesco", ""], ["Vella", "Flavio", ""]]}, {"id": "1908.06655", "submitter": "Hideyuki Miyahara", "authors": "Hideyuki Miyahara, Kazuyuki Aihara, and Wolfgang Lechner", "title": "Quantum Expectation-Maximization Algorithm", "comments": "10 pages, 9 figures", "journal-ref": "Phys. Rev. A 101, 012326 (2020)", "doi": "10.1103/PhysRevA.101.012326", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms are a cornerstone of machine learning applications.\nRecently, a quantum algorithm for clustering based on the k-means algorithm has\nbeen proposed by Kerenidis, Landman, Luongo and Prakash. Based on their work,\nwe propose a quantum expectation-maximization (EM) algorithm for Gaussian\nmixture models (GMMs). The robustness and quantum speedup of the algorithm is\ndemonstrated. We also show numerically the advantage of GMM over k-means for\nnon-trivial cluster data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:19:54 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Miyahara", "Hideyuki", ""], ["Aihara", "Kazuyuki", ""], ["Lechner", "Wolfgang", ""]]}, {"id": "1908.06657", "submitter": "Alessandro Luongo", "authors": "Iordanis Kerenidis, Alessandro Luongo, Anupam Prakash", "title": "Quantum Expectation-Maximization for Gaussian Mixture Models", "comments": "As to appear in ICML2020 conference - with improved algorithms and\n  runtimes", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization (EM) algorithm is a fundamental tool in\nunsupervised machine learning. It is often used as an efficient way to solve\nMaximum Likelihood (ML) estimation problems, especially for models with latent\nvariables. It is also the algorithm of choice to fit mixture models: generative\nmodels that represent unlabelled points originating from $k$ different\nprocesses, as samples from $k$ multivariate distributions. In this work we\ndefine and use a quantum version of EM to fit a Gaussian Mixture Model. Given\nquantum access to a dataset of $n$ vectors of dimension $d$, our algorithm has\nconvergence and precision guarantees similar to the classical algorithm, but\nthe runtime is only polylogarithmic in the number of elements in the training\nset, and is polynomial in other parameters - as the dimension of the feature\nspace, and the number of components in the mixture. We generalize further the\nalgorithm in two directions. First, we show how to fit any mixture model of\nprobability distributions in the exponential family. Then, we show how to use\nthis algorithm to compute the Maximum a Posteriori (MAP) estimate of a mixture\nmodel: the Bayesian approach to likelihood estimation problems. We discuss the\nperformance of the algorithm on a dataset that is expected to be classified\nsuccessfully by this algorithm, arguing that on those cases we can give strong\nguarantees on the runtime.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:21:45 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 14:49:27 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kerenidis", "Iordanis", ""], ["Luongo", "Alessandro", ""], ["Prakash", "Anupam", ""]]}, {"id": "1908.06660", "submitter": "Johannes Czech", "authors": "Johannes Czech, Moritz Willig, Alena Beyer, Kristian Kersting,\n  Johannes F\\\"urnkranz", "title": "Learning to play the Chess Variant Crazyhouse above World Champion Level\n  with Deep Neural Networks and Human Data", "comments": "35 pages, 19 figures, 14 tables", "journal-ref": "Frontiers in Artificial Intelligence, Machine Learning and\n  Artificial Intelligence, Volume 3 (2020)", "doi": "10.3389/frai.2020.00024", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been successfully applied in learning the board\ngames Go, chess and shogi without prior knowledge by making use of\nreinforcement learning. Although starting from zero knowledge has been shown to\nyield impressive results, it is associated with high computationally costs\nespecially for complex games. With this paper, we present CrazyAra which is a\nneural network based engine solely trained in supervised manner for the chess\nvariant crazyhouse. Crazyhouse is a game with a higher branching factor than\nchess and there is only limited data of lower quality available compared to\nAlphaGo. Therefore, we focus on improving efficiency in multiple aspects while\nrelying on low computational resources. These improvements include\nmodifications in the neural network design and training configuration, the\nintroduction of a data normalization step and a more sample efficient\nMonte-Carlo tree search which has a lower chance to blunder. After training on\n569,537 human games for 1.5 days we achieve a move prediction accuracy of\n60.4%. During development, versions of CrazyAra played professional human\nplayers. Most notably, CrazyAra achieved a four to one win over 2017 crazyhouse\nworld champion Justin Tan (aka LM Jann Lee) who is more than 400 Elo higher\nrated compared to the average player in our training set. Furthermore, we test\nthe playing strength of CrazyAra on CPU against all participants of the second\nCrazyhouse Computer Championships 2017, winning against twelve of the thirteen\nparticipants. Finally, for CrazyAraFish we continue training our model on\ngenerated engine games. In ten long-time control matches playing Stockfish 10,\nCrazyAraFish wins three games and draws one out of ten matches.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:31:47 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 15:56:56 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Czech", "Johannes", ""], ["Willig", "Moritz", ""], ["Beyer", "Alena", ""], ["Kersting", "Kristian", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1908.06661", "submitter": "Nils Kriege", "authors": "Nils M. Kriege", "title": "Deep Weisfeiler-Lehman Assignment Kernels via Multiple Kernel Learning", "comments": "ESANN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernels for structured data are commonly obtained by decomposing objects into\ntheir parts and adding up the similarities between all pairs of parts measured\nby a base kernel. Assignment kernels are based on an optimal bijection between\nthe parts and have proven to be an effective alternative to the established\nconvolution kernels. We explore how the base kernel can be learned as part of\nthe classification problem. We build on the theory of valid assignment kernels\nderived from hierarchies defined on the parts. We show that the weights of this\nhierarchy can be optimized via multiple kernel learning. We apply this result\nto learn vertex similarities for the Weisfeiler-Lehman optimal assignment\nkernel for graph classification. We present first experimental results which\ndemonstrate the feasibility and effectiveness of the approach.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:32:27 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Kriege", "Nils M.", ""]]}, {"id": "1908.06663", "submitter": "Chris Reinke", "authors": "Chris Reinke, Mayalen Etcheverry, Pierre-Yves Oudeyer", "title": "Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing\n  Systems", "comments": "29 pages, 19 figure, ICLR 2020 conference paper, associated website:\n  https://automated-discovery.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many complex dynamical systems, artificial or natural, one can observe\nself-organization of patterns emerging from local rules. Cellular automata,\nlike the Game of Life (GOL), have been widely used as abstract models enabling\nthe study of various aspects of self-organization and morphogenesis, such as\nthe emergence of spatially localized patterns. However, findings of\nself-organized patterns in such models have so far relied on manual tuning of\nparameters and initial states, and on the human eye to identify interesting\npatterns. In this paper, we formulate the problem of automated discovery of\ndiverse self-organized patterns in such high-dimensional complex dynamical\nsystems, as well as a framework for experimentation and evaluation. Using a\ncontinuous GOL as a testbed, we show that recent intrinsically-motivated\nmachine learning algorithms (POP-IMGEPs), initially developed for learning of\ninverse models in robotics, can be transposed and used in this novel\napplication area. These algorithms combine intrinsically-motivated goal\nexploration and unsupervised learning of goal space representations. Goal space\nrepresentations describe the interesting features of patterns for which diverse\nvariations should be discovered. In particular, we compare various approaches\nto define and learn goal space representations from the perspective of\ndiscovering diverse spatially localized patterns. Moreover, we introduce an\nextension of a state-of-the-art POP-IMGEP algorithm which incrementally learns\na goal representation using a deep auto-encoder, and the use of CPPN primitives\nfor generating initialization parameters. We show that it is more efficient\nthan several baselines and equally efficient as a system pre-trained on a\nhand-made database of patterns identified by human experts.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:32:46 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 16:40:53 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 14:43:54 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Reinke", "Chris", ""], ["Etcheverry", "Mayalen", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1908.06674", "submitter": "Marius Lindauer", "authors": "Marius Lindauer, Matthias Feurer, Katharina Eggensperger, Andr\\'e\n  Biedenkapp, Frank Hutter", "title": "Towards Assessing the Impact of Bayesian Optimization's Own\n  Hyperparameters", "comments": "Accepted at DSO workshop (as part of IJCAI'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization (BO) is a common approach for hyperparameter\noptimization (HPO) in automated machine learning. Although it is well-accepted\nthat HPO is crucial to obtain well-performing machine learning models, tuning\nBO's own hyperparameters is often neglected. In this paper, we empirically\nstudy the impact of optimizing BO's own hyperparameters and the transferability\nof the found settings using a wide range of benchmarks, including artificial\nfunctions, HPO and HPO combined with neural architecture search. In particular,\nwe show (i) that tuning can improve the any-time performance of different BO\napproaches, that optimized BO settings also perform well (ii) on similar\nproblems and (iii) partially even on problems from other problem families, and\n(iv) which BO hyperparameters are most important.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:59:49 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Lindauer", "Marius", ""], ["Feurer", "Matthias", ""], ["Eggensperger", "Katharina", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Hutter", "Frank", ""]]}, {"id": "1908.06698", "submitter": "Dagui Chen", "authors": "Dagui Chen, Junqi Jin, Weinan Zhang, Fei Pan, Lvyin Niu, Chuan Yu, Jun\n  Wang, Han Li, Jian Xu, Kun Gai", "title": "Learning to Advertise for Organic Traffic Maximization in E-Commerce\n  Product Feeds", "comments": "accepted by CIKM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most e-commerce product feeds provide blended results of advertised products\nand recommended products to consumers. The underlying advertising and\nrecommendation platforms share similar if not exactly the same set of candidate\nproducts. Consumers' behaviors on the advertised results constitute part of the\nrecommendation model's training data and therefore can influence the\nrecommended results. We refer to this process as Leverage. Considering this\nmechanism, we propose a novel perspective that advertisers can strategically\nbid through the advertising platform to optimize their recommended organic\ntraffic. By analyzing the real-world data, we first explain the principles of\nLeverage mechanism, i.e., the dynamic models of Leverage. Then we introduce a\nnovel Leverage optimization problem and formulate it with a Markov Decision\nProcess. To deal with the sample complexity challenge in model-free\nreinforcement learning, we propose a novel Hybrid Training Leverage Bidding\n(HTLB) algorithm which combines the real-world samples and the\nemulator-generated samples to boost the learning speed and stability. Our\noffline experiments as well as the results from the online deployment\ndemonstrate the superior performance of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 11:16:33 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Chen", "Dagui", ""], ["Jin", "Junqi", ""], ["Zhang", "Weinan", ""], ["Pan", "Fei", ""], ["Niu", "Lvyin", ""], ["Yu", "Chuan", ""], ["Wang", "Jun", ""], ["Li", "Han", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "1908.06699", "submitter": "Jinglin Xu", "authors": "Jinglin Xu, Junwei Han, Mingliang Xu, Feiping Nie, Xuelong Li", "title": "Robust and Efficient Fuzzy C-Means Clustering Constrained on Flexible\n  Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is an effective technique in data mining to group a set of objects\nin terms of some attributes. Among various clustering approaches, the family of\nK-Means algorithms gains popularity due to simplicity and efficiency. However,\nmost of existing K-Means based clustering algorithms cannot deal with outliers\nwell and are difficult to efficiently solve the problem embedded the $L_0$-norm\nconstraint. To address the above issues and improve the performance of\nclustering significantly, we propose a novel clustering algorithm, named\nREFCMFS, which develops a $L_{2,1}$-norm robust loss as the data-driven item\nand imposes a $L_0$-norm constraint on the membership matrix to make the model\nmore robust and sparse flexibly. In particular, REFCMFS designs a new way to\nsimplify and solve the $L_0$-norm constraint without any approximate\ntransformation by absorbing $\\|\\cdot\\|_0$ into the objective function through a\nranking function. These improvements not only make REFCMFS efficiently obtain\nmore promising performance but also provide a new tractable and skillful\noptimization method to solve the problem embedded the $L_0$-norm constraint.\nTheoretical analyses and extensive experiments on several public datasets\ndemonstrate the effectiveness and rationality of our proposed REFCMFS method.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 11:17:42 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 02:24:07 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 03:02:13 GMT"}, {"version": "v4", "created": "Thu, 5 Sep 2019 02:51:49 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Xu", "Jinglin", ""], ["Han", "Junwei", ""], ["Xu", "Mingliang", ""], ["Nie", "Feiping", ""], ["Li", "Xuelong", ""]]}, {"id": "1908.06724", "submitter": "Shreyas Kolala Venkataramanaiah", "authors": "Shreyas Kolala Venkataramanaiah, Yufei Ma, Shihui Yin, Eriko\n  Nurvithadhi, Aravind Dasu, Yu Cao, Jae-sun Seo", "title": "Automatic Compiler Based FPGA Accelerator for CNN Training", "comments": "6 pages, 9 figures, paper accepted at FPL2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training of convolutional neural networks (CNNs)on embedded platforms to\nsupport on-device learning is earning vital importance in recent days.\nDesigning flexible training hard-ware is much more challenging than inference\nhardware, due to design complexity and large computation/memory requirement. In\nthis work, we present an automatic compiler-based FPGA accelerator with 16-bit\nfixed-point precision for complete CNNtraining, including Forward Pass (FP),\nBackward Pass (BP) and Weight Update (WU). We implemented an optimized RTL\nlibrary to perform training-specific tasks and developed an RTL compiler to\nautomatically generate FPGA-synthesizable RTL based on user-defined\nconstraints. We present a new cyclic weight storage/access scheme for on-chip\nBRAM and off-chip DRAMto efficiently implement non-transpose and transpose\noperations during FP and BP phases, respectively. Representative CNNs for\nCIFAR-10 dataset are implemented and trained on Intel Stratix 10-GX FPGA using\nproposed hardware architecture, demonstrating up to 479 GOPS performance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 18:49:38 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Venkataramanaiah", "Shreyas Kolala", ""], ["Ma", "Yufei", ""], ["Yin", "Shihui", ""], ["Nurvithadhi", "Eriko", ""], ["Dasu", "Aravind", ""], ["Cao", "Yu", ""], ["Seo", "Jae-sun", ""]]}, {"id": "1908.06729", "submitter": "Hongzhi Wang", "authors": "Xi Chen, Hongzhi Wang, Yanjie Wei, Jianzhong Li and Hong Gao", "title": "Autoregressive-Model-Based Methods for Online Time Series Prediction\n  with Missing Values: an Experimental Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series prediction with missing values is an important problem of time\nseries analysis since complete data is usually hard to obtain in many\nreal-world applications. To model the generation of time series, autoregressive\n(AR) model is a basic and widely used one, which assumes that each observation\nin the time series is a noisy linear combination of some previous observations\nalong with a constant shift. To tackle the problem of prediction with missing\nvalues, a number of methods were proposed based on various data models. For\nreal application scenarios, how do these methods perform over different types\nof time series with different levels of data missing remains to be\ninvestigated. In this paper, we focus on online methods for AR-model-based time\nseries prediction with missing values. We adapted five mainstream methods to\nfit in such a scenario. We make detailed discussion on each of them by\nintroducing their core ideas about how to estimate the AR coefficients and\ntheir different strategies to deal with missing values. We also present\nalgorithmic implementations for better understanding. In order to\ncomprehensively evaluate these methods and do the comparison, we conduct\nexperiments with various configurations of relative parameters over both\nsynthetic and real data. From the experimental results, we derived several\nnoteworthy conclusions and shows that imputation is a simple but reliable\nstrategy to handle missing values in online prediction tasks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 13:58:54 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 01:59:09 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Chen", "Xi", ""], ["Wang", "Hongzhi", ""], ["Wei", "Yanjie", ""], ["Li", "Jianzhong", ""], ["Gao", "Hong", ""]]}, {"id": "1908.06746", "submitter": "Mohsen Shahhosseini", "authors": "Mohsen Shahhosseini, Rafael A. Martinez-Feria, Guiping Hu, Sotirios V.\n  Archontoulis", "title": "Maize Yield and Nitrate Loss Prediction with Machine Learning Algorithms", "comments": null, "journal-ref": "Environmental Research Letters 14(12) (2019) 124026", "doi": "10.1088/1748-9326/ab5268", "report-no": null, "categories": "q-bio.OT cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-season prediction of crop production outcomes such as grain yields and N\nlosses can provide insights to stakeholders when making decisions. Simulation\nmodels can assist in scenario planning, but their use is limited because of\ndata requirements and long run times. Thus, there is a need for more\ncomputationally expedient approaches to scale up predictions. We evaluated the\npotential of five machine learning (ML) algorithms as meta-models for a\ncropping systems simulator (APSIM) to inform future decision-support tool\ndevelopment. We asked: 1) How well do ML meta-models predict maize yield and N\nlosses using pre-season information? 2) How many data are needed to train ML\nalgorithms to achieve acceptable predictions?; 3) Which input data variables\nare most important for accurate prediction?; and 4) Do ensembles of ML\nmeta-models improve prediction? The simulated dataset included more than 3\nmillion genotype, environment and management scenarios. Random forests most\naccurately predicted maize yield and N loss at planting time, with a RRMSE of\n14% and 55%, respectively. ML meta-models reasonably reproduced simulated maize\nyields but not N loss. They also differed in their sensitivities to the size of\nthe training dataset. Across all ML models, yield prediction error decreased by\n10-40% as the training dataset increased from 0.5 to 1.8 million data points,\nwhereas N loss prediction error showed no consistent pattern. ML models also\ndiffered in their sensitivities to input variables. Averaged across all ML\nmodels, weather conditions, soil properties, management information and initial\nconditions were roughly equally important when predicting yields. Modest\nprediction improvements resulted from ML ensembles. These results can help\naccelerate progress in coupling simulation models and ML toward developing\ndynamic decision support tools for pre-season management.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 18:43:24 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 18:23:37 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 17:48:56 GMT"}, {"version": "v4", "created": "Thu, 19 Sep 2019 15:12:00 GMT"}, {"version": "v5", "created": "Fri, 6 Nov 2020 18:18:11 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Shahhosseini", "Mohsen", ""], ["Martinez-Feria", "Rafael A.", ""], ["Hu", "Guiping", ""], ["Archontoulis", "Sotirios V.", ""]]}, {"id": "1908.06750", "submitter": "Amir Atapour Abarghouei", "authors": "Amir Atapour-Abarghouei and Stephen Bonner and Andrew Stephen McGough", "title": "A Kings Ransom for Encryption: Ransomware Classification using Augmented\n  One-Shot Learning and Bayesian Approximation", "comments": "Submitted to 2019 IEEE International Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Newly emerging variants of ransomware pose an ever-growing threat to computer\nsystems governing every aspect of modern life through the handling and analysis\nof big data. While various recent security-based approaches have focused on\ndetecting and classifying ransomware at the network or system level,\neasy-to-use post-infection ransomware classification for the lay user has not\nbeen attempted before. In this paper, we investigate the possibility of\nclassifying the ransomware a system is infected with simply based on a\nscreenshot of the splash screen or the ransom note captured using a consumer\ncamera commonly found in any modern mobile device. To train and evaluate our\nsystem, we create a sample dataset of the splash screens of 50 well-known\nransomware variants. In our dataset, only a single training image is available\nper ransomware. Instead of creating a large training dataset of ransomware\nscreenshots, we simulate screenshot capture conditions via carefully designed\ndata augmentation techniques, enabling simple and efficient one-shot learning.\nMoreover, using model uncertainty obtained via Bayesian approximation, we\nensure special input cases such as unrelated non-ransomware images and\npreviously-unseen ransomware variants are correctly identified for special\nhandling and not mis-classified. Extensive experimental evaluation demonstrates\nthe efficacy of our work, with accuracy levels of up to 93.6% for ransomware\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 12:38:38 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Atapour-Abarghouei", "Amir", ""], ["Bonner", "Stephen", ""], ["McGough", "Andrew Stephen", ""]]}, {"id": "1908.06752", "submitter": "Aakanksha Rana", "authors": "Aakanksha Rana, Cagri Ozcinar, Aljoscha Smolic", "title": "Towards Generating Ambisonics Using Audio-Visual Cue for Virtual Reality", "comments": "ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech\n  and Signal Processing (ICASSP)", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8683318", "report-no": null, "categories": "cs.SD cs.CV cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambisonics i.e., a full-sphere surround sound, is quintessential with\n360-degree visual content to provide a realistic virtual reality (VR)\nexperience. While 360-degree visual content capture gained a tremendous boost\nrecently, the estimation of corresponding spatial sound is still challenging\ndue to the required sound-field microphones or information about the\nsound-source locations. In this paper, we introduce a novel problem of\ngenerating Ambisonics in 360-degree videos using the audio-visual cue. With\nthis aim, firstly, a novel 360-degree audio-visual video dataset of 265 videos\nis introduced with annotated sound-source locations. Secondly, a pipeline is\ndesigned for an automatic Ambisonic estimation problem. Benefiting from the\ndeep learning-based audio-visual feature-embedding and prediction modules, our\npipeline estimates the 3D sound-source locations and further use such locations\nto encode to the B-format. To benchmark our dataset and pipeline, we\nadditionally propose evaluation criteria to investigate the performance using\ndifferent 360-degree input representations. Our results demonstrate the\nefficacy of the proposed pipeline and open up a new area of research in\n360-degree audio-visual analysis for future investigations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 14:49:30 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Rana", "Aakanksha", ""], ["Ozcinar", "Cagri", ""], ["Smolic", "Aljoscha", ""]]}, {"id": "1908.06754", "submitter": "Daniel Rivero", "authors": "Daniel Rivero, Enrique Fernandez-Blanco", "title": "A New Deterministic Technique for Symbolic Regression", "comments": "29 pages. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new method for Symbolic Regression that allows to find\nmathematical expressions from a dataset. This method has a strong mathematical\nbasis. As opposed to other methods such as Genetic Programming, this method is\ndeterministic, and does not involve the creation of a population of initial\nsolutions. Instead of it, a simple expression is being grown until it fits the\ndata. The experiments performed show that the results are as good as other\nMachine Learning methods, in a very low computational time. Another advantage\nof this technique is that the complexity of the expressions can be limited, so\nthe system can return mathematical expressions that can be easily analysed by\nthe user, in opposition to other techniques like GSGP.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 10:58:11 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 07:57:31 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 11:47:12 GMT"}, {"version": "v4", "created": "Fri, 15 Nov 2019 09:38:36 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Rivero", "Daniel", ""], ["Fernandez-Blanco", "Enrique", ""]]}, {"id": "1908.06756", "submitter": "Marius Lindauer", "authors": "Marius Lindauer, Katharina Eggensperger, Matthias Feurer, Andr\\'e\n  Biedenkapp, Joshua Marben, Philipp M\\\"uller and Frank Hutter", "title": "BOAH: A Tool Suite for Multi-Fidelity Bayesian Optimization & Analysis\n  of Hyperparameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization and neural architecture search can become\nprohibitively expensive for regular black-box Bayesian optimization because the\ntraining and evaluation of a single model can easily take several hours. To\novercome this, we introduce a comprehensive tool suite for effective\nmulti-fidelity Bayesian optimization and the analysis of its runs. The suite,\nwritten in Python, provides a simple way to specify complex design spaces, a\nrobust and efficient combination of Bayesian optimization and HyperBand, and a\ncomprehensive analysis of the optimization process and its outcomes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 10:01:03 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Lindauer", "Marius", ""], ["Eggensperger", "Katharina", ""], ["Feurer", "Matthias", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Marben", "Joshua", ""], ["M\u00fcller", "Philipp", ""], ["Hutter", "Frank", ""]]}, {"id": "1908.06758", "submitter": "Jiancheng Long", "authors": "Jiancheng Long, Hongming Zhang, Tianyang Yu, Bo Xu", "title": "Iterative Update and Unified Representation for Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent systems have a wide range of applications in cooperative and\ncompetitive tasks. As the number of agents increases, nonstationarity gets more\nserious in multi-agent reinforcement learning (MARL), which brings great\ndifficulties to the learning process. Besides, current mainstream algorithms\nconfigure each agent an independent network,so that the memory usage increases\nlinearly with the number of agents which greatly slows down the interaction\nwith the environment. Inspired by Generative Adversarial Networks (GAN), this\npaper proposes an iterative update method (IU) to stabilize the nonstationary\nenvironment. Further, we add first-person perspective and represent all agents\nby only one network which can change agents' policies from sequential compute\nto batch compute. Similar to continual lifelong learning, we realize the\niterative update method in this unified representative network (IUUR). In this\nmethod, iterative update can greatly alleviate the nonstationarity of the\nenvironment, unified representation can speed up the interaction with\nenvironment and avoid the linear growth of memory usage. Besides, this method\ndoes not bother decentralized execution and distributed deployment. Experiments\nshow that compared with MADDPG, our algorithm achieves state-of-the-art\nperformance and saves wall-clock time by a large margin especially with more\nagents.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 07:39:59 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Long", "Jiancheng", ""], ["Zhang", "Hongming", ""], ["Yu", "Tianyang", ""], ["Xu", "Bo", ""]]}, {"id": "1908.06760", "submitter": "Bonggun Shin", "authors": "Bonggun Shin, Sungsoo Park, Keunsoo Kang, Joyce C. Ho", "title": "Self-Attention Based Molecule Representation for Predicting Drug-Target\n  Interaction", "comments": "18 pages, Proceedings of Machine Learning for Healthcare, 2019\n  (MLHC'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting drug-target interactions (DTI) is an essential part of the drug\ndiscovery process, which is an expensive process in terms of time and cost.\nTherefore, reducing DTI cost could lead to reduced healthcare costs for a\npatient. In addition, a precisely learned molecule representation in a DTI\nmodel could contribute to developing personalized medicine, which will help\nmany patient cohorts. In this paper, we propose a new molecule representation\nbased on the self-attention mechanism, and a new DTI model using our molecule\nrepresentation. The experiments show that our DTI model outperforms the state\nof the art by up to 4.9% points in terms of area under the precision-recall\ncurve. Moreover, a study using the DrugBank database proves that our model\neffectively lists all known drugs targeting a specific cancer biomarker in the\ntop-30 candidate list.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 21:39:15 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Shin", "Bonggun", ""], ["Park", "Sungsoo", ""], ["Kang", "Keunsoo", ""], ["Ho", "Joyce C.", ""]]}, {"id": "1908.06767", "submitter": "Shirin Seyedsalehi", "authors": "Shirin Seyedsalehi, Vahid Pourahmadi, Hamid Sheikhzadeh, Ali Hossein\n  Gharari Foumani", "title": "Propagation Channel Modeling by Deep learning Techniques", "comments": "11 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel, as the medium for the propagation of electromagnetic waves, is one\nof the most important parts of a communication system. Being aware of how the\nchannel affects the propagation waves is essential for designing, optimization\nand performance analysis of a communication system. For this purpose, a proper\nchannel model is needed. This paper presents a novel propagation channel model\nwhich considers the time-frequency response of the channel as an image. It\nmodels the distribution of these channel images using Deep Convolutional\nGenerative Adversarial Networks. Moreover, for the measurements with different\nuser speeds, the user speed is considered as an auxiliary parameter for the\nmodel. StarGAN as an image-to-image translation technique is used to change the\ngenerated channel images with respect to the desired user speed. The\nperformance of the proposed model is evaluated using existing metrics.\nFurthermore, to capture 2D similarity in both time and frequency, a new metric\nis introduced. Using this metric, the generated channels show significant\nstatistical similarity to the measurement data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 12:51:57 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Seyedsalehi", "Shirin", ""], ["Pourahmadi", "Vahid", ""], ["Sheikhzadeh", "Hamid", ""], ["Foumani", "Ali Hossein Gharari", ""]]}, {"id": "1908.06769", "submitter": "De-An Huang", "authors": "De-An Huang, Danfei Xu, Yuke Zhu, Animesh Garg, Silvio Savarese, Li\n  Fei-Fei, Juan Carlos Niebles", "title": "Continuous Relaxation of Symbolic Planner for One-Shot Imitation\n  Learning", "comments": "IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address one-shot imitation learning, where the goal is to execute a\npreviously unseen task based on a single demonstration. While there has been\nexciting progress in this direction, most of the approaches still require a few\nhundred tasks for meta-training, which limits the scalability of the\napproaches. Our main contribution is to formulate one-shot imitation learning\nas a symbolic planning problem along with the symbol grounding problem. This\nformulation disentangles the policy execution from the inter-task\ngeneralization and leads to better data efficiency. The key technical challenge\nis that the symbol grounding is prone to error with limited training data and\nleads to subsequent symbolic planning failures. We address this challenge by\nproposing a continuous relaxation of the discrete symbolic planner that\ndirectly plans on the probabilistic outputs of the symbol grounding model. Our\ncontinuous relaxation of the planner can still leverage the information\ncontained in the probabilistic symbol grounding and significantly improve over\nthe baseline planner for the one-shot imitation learning tasks without using\nlarge training data.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 16:28:12 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 02:58:19 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Huang", "De-An", ""], ["Xu", "Danfei", ""], ["Zhu", "Yuke", ""], ["Garg", "Animesh", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""], ["Niebles", "Juan Carlos", ""]]}, {"id": "1908.06792", "submitter": "Yixing Huang", "authors": "Yixing Huang, Alexander Preuhs, Guenter Lauritsch, Michael Manhart,\n  Xiaolin Huang, and Andreas Maier", "title": "Data Consistent Artifact Reduction for Limited Angle Tomography with\n  Deep Learning Prior", "comments": "Accepted by MICCAI MLMIR workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of deep learning methods for limited angle tomography is\nchallenged by two major factors: a) due to insufficient training data the\nnetwork may not generalize well to unseen data; b) deep learning methods are\nsensitive to noise. Thus, generating reconstructed images directly from a\nneural network appears inadequate. We propose to constrain the reconstructed\nimages to be consistent with the measured projection data, while the unmeasured\ninformation is complemented by learning based methods. For this purpose, a data\nconsistent artifact reduction (DCAR) method is introduced: First, a prior image\nis generated from an initial limited angle reconstruction via deep learning as\na substitute for missing information. Afterwards, a conventional iterative\nreconstruction algorithm is applied, integrating the data consistency in the\nmeasured angular range and the prior information in the missing angular range.\nThis ensures data integrity in the measured area, while inaccuracies\nincorporated by the deep learning prior lie only in areas where no information\nis acquired. The proposed DCAR method achieves significant image quality\nimprovement: for 120-degree cone-beam limited angle tomography more than 10%\nRMSE reduction in noise-free case and more than 24% RMSE reduction in noisy\ncase compared with a state-of-the-art U-Net based method.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 13:28:35 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 08:47:31 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Huang", "Yixing", ""], ["Preuhs", "Alexander", ""], ["Lauritsch", "Guenter", ""], ["Manhart", "Michael", ""], ["Huang", "Xiaolin", ""], ["Maier", "Andreas", ""]]}, {"id": "1908.06801", "submitter": "Yoshitaka Kameya", "authors": "Yoshitaka Kameya", "title": "Towards Efficient Discriminative Pattern Mining in Hybrid Domains", "comments": "This paper is an English version of the paper originally presented in\n  the 17th Forum on Information Technology (FIT 2018), a Japanese domestic\n  conference held during September 19-21, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminative pattern mining is a data mining task in which we find patterns\nthat distinguish transactions in the class of interest from those in other\nclasses, and is also called emerging pattern mining or subgroup discovery. One\npractical problem in discriminative pattern mining is how to handle numeric\nvalues in the input dataset. In this paper, we propose an algorithm for\ndiscriminative pattern mining that can deal with a transactional dataset in a\nhybrid domain, i.e. the one that includes both symbolic and numeric values. We\nalso show the execution results of a prototype implementation of the proposed\nalgorithm for two standard benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 13:28:50 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Kameya", "Yoshitaka", ""]]}, {"id": "1908.06802", "submitter": "Binhang Yuan", "authors": "Binhang Yuan and Wenhui Xing", "title": "Diagnosing Cardiac Abnormalities from 12-Lead Electrocardiograms Using\n  Enhanced Deep Convolutional Neural Networks", "comments": "Accepted by MLMECH-MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train an enhanced deep convolutional neural network in order to identify\neight cardiac abnormalities from the standard 12-lead electrocardiograms (ECGs)\nusing the dataset of 14000 ECGs. Instead of straightforwardly applying an\nend-to-end deep learning approach, we find that deep convolutional neural\nnetworks enhanced with sophisticated hand crafted features show advantages in\nreducing generalization errors. Additionally, data preprocessing and\naugmentation are essential since the distribution of eight cardiac\nabnormalities are highly biased in the given dataset. Our approach achieves\npromising generalization performance in the First China ECG Intelligent\nCompetition; an empirical evaluation is also provided to validate the efficacy\nof our design on the competition ECG dataset.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 15:20:12 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Yuan", "Binhang", ""], ["Xing", "Wenhui", ""]]}, {"id": "1908.06803", "submitter": "Md Tamzeed Islam", "authors": "Md Tamzeed Islam, Shahriar Nirjon", "title": "Wi-Fringe: Leveraging Text Semantics in WiFi CSI-Based Device-Free Named\n  Gesture Recognition", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of adequate training data is one of the major hurdles in WiFi-based\nactivity recognition systems. In this paper, we propose Wi-Fringe, which is a\nWiFi CSI-based device-free human gesture recognition system that recognizes\nnamed gestures, i.e., activities and gestures that have a semantically\nmeaningful name in English language, as opposed to arbitrary free-form\ngestures. Given a list of activities (only their names in English text), along\nwith zero or more training examples (WiFi CSI values) per activity, Wi-Fringe\nis able to detect all activities at runtime. In other words, a subset of\nactivities that Wi-Fringe detects do not require any training examples at all.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:42:29 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Islam", "Md Tamzeed", ""], ["Nirjon", "Shahriar", ""]]}, {"id": "1908.06809", "submitter": "Ivan P Yamshchikov", "authors": "Alexey Tikhonov, Viacheslav Shibaev, Aleksander Nagaev, Aigul\n  Nugmanova, Ivan P. Yamshchikov", "title": "Style Transfer for Texts: Retrain, Report Errors, Compare with Rewrites", "comments": null, "journal-ref": null, "doi": "10.18653/v1/D19-1406", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that standard assessment methodology for style transfer has\nseveral significant problems. First, the standard metrics for style accuracy\nand semantics preservation vary significantly on different re-runs. Therefore\none has to report error margins for the obtained results. Second, starting with\ncertain values of bilingual evaluation understudy (BLEU) between input and\noutput and accuracy of the sentiment transfer the optimization of these two\nstandard metrics diverge from the intuitive goal of the style transfer task.\nFinally, due to the nature of the task itself, there is a specific dependence\nbetween these two metrics that could be easily manipulated. Under these\ncircumstances, we suggest taking BLEU between input and human-written\nreformulations into consideration for benchmarks. We also propose three new\narchitectures that outperform state of the art in terms of this metric.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 14:01:18 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 20:16:09 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Tikhonov", "Alexey", ""], ["Shibaev", "Viacheslav", ""], ["Nagaev", "Aleksander", ""], ["Nugmanova", "Aigul", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "1908.06817", "submitter": "Sterling Ramroach", "authors": "Sterling Ramroach, Melford John, and Ajay Joshi", "title": "The efficacy of various machine learning models for multi-class\n  classification of RNA-seq expression data", "comments": "12 pages, 4 figures, 3 tables, conference paper: Computing Conference\n  2019, published at\n  https://link.springer.com/chapter/10.1007/978-3-030-22871-2_65", "journal-ref": null, "doi": "10.1007/978-3-030-22871-2_65", "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Late diagnosis and high costs are key factors that negatively impact the care\nof cancer patients worldwide. Although the availability of biological markers\nfor the diagnosis of cancer type is increasing, costs and reliability of tests\ncurrently present a barrier to the adoption of their routine use. There is a\npressing need for accurate methods that enable early diagnosis and cover a\nbroad range of cancers. The use of machine learning and RNA-seq expression\nanalysis has shown promise in the classification of cancer type. However,\nresearch is inconclusive about which type of machine learning models are\noptimal. The suitability of five algorithms were assessed for the\nclassification of 17 different cancer types. Each algorithm was fine-tuned and\ntrained on the full array of 18,015 genes per sample, for 4,221 samples (75 %\nof the dataset). They were then tested with 1,408 samples (25 % of the dataset)\nfor which cancer types were withheld to determine the accuracy of prediction.\nThe results show that ensemble algorithms achieve 100% accuracy in the\nclassification of 14 out of 17 types of cancer. The clustering and\nclassification models, while faster than the ensembles, performed poorly due to\nthe high level of noise in the dataset. When the features were reduced to a\nlist of 20 genes, the ensemble algorithms maintained an accuracy above 95% as\nopposed to the clustering and classification models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 14:10:44 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ramroach", "Sterling", ""], ["John", "Melford", ""], ["Joshi", "Ajay", ""]]}, {"id": "1908.06818", "submitter": "Michal Moshkovitz", "authors": "Michal Moshkovitz", "title": "Unexpected Effects of Online no-Substitution k-means Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline k-means clustering was studied extensively, and algorithms with a\nconstant approximation are available. However, online clustering is still\nuncharted. New factors come into play: the ordering of the dataset and whether\nthe number of points, n, is known in advance or not. Their exact effects are\nunknown. In this paper we focus on the online setting where the decisions are\nirreversible: after a point arrives, the algorithm needs to decide whether to\ntake the point as a center or not, and this decision is final. How many centers\nare needed and sufficient to achieve constant approximation in this setting? We\nshow upper and lower bounds for all the different cases. These bounds are\nexactly the same up to a constant, thus achieving optimal bounds. For example,\nfor k-means cost with constant k>1 and random order, Theta(log n) centers are\nenough to achieve a constant approximation, while the mere a priori knowledge\nof n reduces the number of centers to a constant. These bounds hold for any\ndistance function that obeys a triangle-type inequality.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 18:21:00 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 03:13:45 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Moshkovitz", "Michal", ""]]}, {"id": "1908.06830", "submitter": "Nicholas Heller", "authors": "Nicholas Heller, Jack Rickman, Christopher Weight, and Nikolaos\n  Papanikolopoulos", "title": "The Role of Publicly Available Data in MICCAI Papers from 2014 to 2018", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Widely-used public benchmarks are of huge importance to computer vision and\nmachine learning research, especially with the computational resources required\nto reproduce state of the art results quickly becoming untenable. In medical\nimage computing, the wide variety of image modalities and problem formulations\nyields a huge task-space for benchmarks to cover, and thus the widespread\nadoption of standard benchmarks has been slow, and barriers to releasing\nmedical data exacerbate this issue. In this paper, we examine the role that\npublicly available data has played in MICCAI papers from the past five years.\nWe find that more than half of these papers are based on private data alone,\nalthough this proportion seems to be decreasing over time. Additionally, we\nobserved that after controlling for open access publication and the release of\ncode, papers based on public data were cited over 60% more per year than their\nprivate-data counterparts. Further, we found that more than 20% of papers using\npublic data did not provide a citation to the dataset or associated manuscript,\nhighlighting the \"second-rate\" status that data contributions often take\ncompared to theoretical ones. We conclude by making recommendations for MICCAI\npolicies which could help to better incentivise data sharing and move the field\ntoward more efficient and reproducible science.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 16:28:29 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Heller", "Nicholas", ""], ["Rickman", "Jack", ""], ["Weight", "Christopher", ""], ["Papanikolopoulos", "Nikolaos", ""]]}, {"id": "1908.06843", "submitter": "Georgios Exarchakis", "authors": "Georgios Exarchakis, J\\\"org Bornschein, Abdul-Saboor Sheikh, Zhenwen\n  Dai, Marc Henniges, Jakob Drefs, J\\\"org L\\\"ucke", "title": "ProSper -- A Python Library for Probabilistic Sparse Coding with\n  Non-Standard Priors and Superpositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ProSper is a python library containing probabilistic algorithms to learn\ndictionaries. Given a set of data points, the implemented algorithms seek to\nlearn the elementary components that have generated the data. The library\nwidens the scope of dictionary learning approaches beyond implementations of\nstandard approaches such as ICA, NMF or standard L1 sparse coding. The\nimplemented algorithms are especially well-suited in cases when data consist of\ncomponents that combine non-linearly and/or for data requiring flexible prior\ndistributions. Furthermore, the implemented algorithms go beyond standard\napproaches by inferring prior and noise parameters of the data, and they\nprovide rich a-posteriori approximations for inference. The library is designed\nto be extendable and it currently includes: Binary Sparse Coding (BSC), Ternary\nSparse Coding (TSC), Discrete Sparse Coding (DSC), Maximal Causes Analysis\n(MCA), Maximum Magnitude Causes Analysis (MMCA), and Gaussian Sparse Coding\n(GSC, a recent spike-and-slab sparse coding approach). The algorithms are\nscalable due to a combination of variational approximations and\nparallelization. Implementations of all algorithms allow for parallel execution\non multiple CPUs and multiple machines for medium to large-scale applications.\nTypical large-scale runs of the algorithms can use hundreds of CPUs to learn\nhundreds of dictionary elements from data with tens of millions of\nfloating-point numbers such that models with several hundred thousand\nparameters can be optimized. The library is designed to have minimal\ndependencies and to be easy to use. It targets users of dictionary learning\nalgorithms and Machine Learning researchers.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 14:55:45 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Exarchakis", "Georgios", ""], ["Bornschein", "J\u00f6rg", ""], ["Sheikh", "Abdul-Saboor", ""], ["Dai", "Zhenwen", ""], ["Henniges", "Marc", ""], ["Drefs", "Jakob", ""], ["L\u00fccke", "J\u00f6rg", ""]]}, {"id": "1908.06845", "submitter": "Nir Shlezinger", "authors": "Nir Shlezinger and Yonina C. Eldar", "title": "Deep Task-Based Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantizers play a critical role in digital signal processing systems. Recent\nworks have shown that the performance of quantization systems acquiring\nmultiple analog signals using scalar analog-to-digital converters (ADCs) can be\nsignificantly improved by properly processing the analog signals prior to\nquantization. However, the design of such hybrid quantizers is quite complex,\nand their implementation requires complete knowledge of the statistical model\nof the analog signal, which may not be available in practice. In this work we\ndesign data-driven task-oriented quantization systems with scalar ADCs, which\ndetermine how to map an analog signal into its digital representation using\ndeep learning tools. These representations are designed to facilitate the task\nof recovering underlying information from the quantized signals, which can be a\nset of parameters to estimate, or alternatively, a classification task. By\nutilizing deep learning, we circumvent the need to explicitly recover the\nsystem model and to find the proper quantization rule for it. Our main target\napplication is multiple-input multiple-output (MIMO) communication receivers,\nwhich simultaneously acquire a set of analog signals, and are commonly subject\nto constraints on the number of bits. Our results indicate that, in a MIMO\nchannel estimation setup, the proposed deep task-bask quantizer is capable of\napproaching the optimal performance limits dictated by indirect rate-distortion\ntheory, achievable using vector quantizers and requiring complete knowledge of\nthe underlying statistical model. Furthermore, for a symbol detection scenario,\nit is demonstrated that the proposed approach can realize reliable\nbit-efficient hybrid MIMO receivers capable of setting their quantization rule\nin light of the task, e.g., to minimize the bit error rate.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 10:03:42 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Shlezinger", "Nir", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1908.06847", "submitter": "Solmaz Niknam", "authors": "Solmaz Niknam, Harpreet S. Dhillon, and Jeffery H. Reed", "title": "Federated Learning for Wireless Communications: Motivation,\n  Opportunities and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in the wireless communications community to\ncomplement the traditional model-based design approaches with data-driven\nmachine learning (ML)-based solutions. While conventional ML approaches rely on\nthe assumption of having the data and processing heads in a central entity,\nthis is not always feasible in wireless communications applications because of\nthe inaccessibility of private data and large communication overhead required\nto transmit raw data to central ML processors. As a result, decentralized ML\napproaches that keep the data where it is generated are much more appealing.\nOwing to its privacy-preserving nature, federated learning is particularly\nrelevant for many wireless applications, especially in the context of fifth\ngeneration (5G) networks. In this article, we provide an accessible\nintroduction to the general idea of federated learning, discuss several\npossible applications in 5G networks, and describe key technical challenges and\nopen problems for future research on federated learning in the context of\nwireless communications.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 21:30:23 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 15:09:48 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 17:33:41 GMT"}, {"version": "v4", "created": "Sun, 3 May 2020 01:05:37 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Niknam", "Solmaz", ""], ["Dhillon", "Harpreet S.", ""], ["Reed", "Jeffery H.", ""]]}, {"id": "1908.06848", "submitter": "Vassilios Dallas", "authors": "Nicolas Boull\\'e, Vassilios Dallas, Yuji Nakatsukasa, D. Samaddar", "title": "Classification of chaotic time series with deep learning", "comments": "15 pages, 13 figures, accepted in Physica D: Nonlinear Phenomena", "journal-ref": null, "doi": "10.1016/j.physd.2019.132261", "report-no": null, "categories": "eess.SP cs.LG math.DS nlin.CD physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use standard deep neural networks to classify univariate time series\ngenerated by discrete and continuous dynamical systems based on their chaotic\nor non-chaotic behaviour. Our approach to circumvent the lack of precise models\nfor some of the most challenging real-life applications is to train different\nneural networks on a data set from a dynamical system with a basic or\nlow-dimensional phase space and then use these networks to classify univariate\ntime series of a dynamical system with more intricate or high-dimensional phase\nspace. We illustrate this generalisation approach using the logistic map, the\nsine-circle map, the Lorenz system, and the Kuramoto--Sivashinsky equation. We\nobserve that a convolutional neural network without batch normalization layers\noutperforms state-of-the-art neural networks for time series classification and\nis able to generalise and classify time series as chaotic or not with high\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 20:54:40 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 21:58:04 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 21:28:06 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Boull\u00e9", "Nicolas", ""], ["Dallas", "Vassilios", ""], ["Nakatsukasa", "Yuji", ""], ["Samaddar", "D.", ""]]}, {"id": "1908.06851", "submitter": "Grigorios G. Anagnostopoulos Dr.", "authors": "Grigorios G. Anagnostopoulos, Alexandros Kalousis", "title": "A Reproducible Analysis of RSSI Fingerprinting for Outdoor Localization\n  Using Sigfox: Preprocessing and Hyperparameter Tuning", "comments": "Preprint of a paper to be presented in IPIN2019", "journal-ref": null, "doi": "10.1109/IPIN.2019.8911792", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fingerprinting techniques, which are a common method for indoor localization,\nhave been recently applied with success into outdoor settings. Particularly,\nthe communication signals of Low Power Wide Area Networks (LPWAN) such as\nSigfox, have been used for localization. In this rather recent field of study,\nnot many publicly available datasets, which would facilitate the consistent\ncomparison of different positioning systems, exist so far. In the current\nstudy, a published dataset of RSSI measurements on a Sigfox network deployed in\nAntwerp, Belgium is used to analyse the appropriate selection of preprocessing\nsteps and to tune the hyperparameters of a kNN fingerprinting method.\nInitially, the tuning of hyperparameter k for a variety of distance metrics,\nand the selection of efficient data transformation schemes, proposed by\nrelevant works, is presented. In addition, accuracy improvements are achieved\nin this study, by a detailed examination of the appropriate adjustment of the\nparameters of the data transformation schemes tested, and of the handling of\nout of range values. With the appropriate tuning of these factors, the achieved\nmean localization error was 298 meters, and the median error was 109 meters. To\nfacilitate the reproducibility of tests and comparability of results, the code\nand train/validation/test split used in this study are available.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 09:16:40 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Anagnostopoulos", "Grigorios G.", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1908.06852", "submitter": "Clement Benard", "authors": "Cl\\'ement B\\'enard (LPSM (UMR\\_8001)), G\\'erard Biau (LPSM\n  (UMR\\_8001)), S\\'ebastien da Veiga, Erwan Scornet (CMAP)", "title": "SIRUS: Stable and Interpretable RUle Set for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art learning algorithms, such as random forests or neural\nnetworks, are often qualified as \"black-boxes\" because of the high number and\ncomplexity of operations involved in their prediction mechanism. This lack of\ninterpretability is a strong limitation for applications involving critical\ndecisions, typically the analysis of production processes in the manufacturing\nindustry. In such critical contexts, models have to be interpretable, i.e.,\nsimple, stable, and predictive. To address this issue, we design SIRUS (Stable\nand Interpretable RUle Set), a new classification algorithm based on random\nforests, which takes the form of a short list of rules. While simple models are\nusually unstable with respect to data perturbation, SIRUS achieves a remarkable\nstability improvement over cutting-edge methods. Furthermore, SIRUS inherits a\npredictive accuracy close to random forests, combined with the simplicity of\ndecision trees. These properties are assessed both from a theoretical and\nempirical point of view, through extensive numerical experiments based on our\nR/C++ software implementation sirus available from CRAN.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 14:55:47 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 13:16:57 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 08:09:14 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 12:51:34 GMT"}, {"version": "v5", "created": "Wed, 16 Dec 2020 10:52:20 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["B\u00e9nard", "Cl\u00e9ment", "", "LPSM"], ["Biau", "G\u00e9rard", "", "LPSM"], ["da Veiga", "S\u00e9bastien", "", "CMAP"], ["Scornet", "Erwan", "", "CMAP"]]}, {"id": "1908.06856", "submitter": "Hau-tieng Wu", "authors": "Yu-Min Chung, Chuan-Shen Hu, Yu-Lun Lo, Hau-Tieng Wu", "title": "A persistent homology approach to heart rate variability analysis with\n  an application to sleep-wake classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent homology (PH) is a recently developed theory in the field of\nalgebraic topology to study shapes of datasets. It is an effective data\nanalysis tool that is robust to noise and has been widely applied. We\ndemonstrate a general pipeline to apply PH to study time series; particularly\nthe instantaneous heart rate time series for the heart rate variability (HRV)\nanalysis. The first step is capturing the shapes of time series from two\ndifferent aspects -- {the PH's and hence persistence diagrams of its} sub-level\nset and Taken's lag map. Second, we propose a systematic {and computationally\nefficient} approach to summarize persistence diagrams, which we coined {\\em\npersistence statistics}. To demonstrate our proposed method, we apply these\ntools to the HRV analysis and the sleep-wake, REM-NREM (rapid eyeball movement\nand non rapid eyeball movement) and sleep-REM-NREM classification problems. The\nproposed algorithm is evaluated on three different datasets via the\ncross-database validation scheme. The performance of our approach is better\nthan the state-of-the-art algorithms, and the result is consistent throughout\ndifferent datasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 05:02:03 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 02:42:51 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Chung", "Yu-Min", ""], ["Hu", "Chuan-Shen", ""], ["Lo", "Yu-Lun", ""], ["Wu", "Hau-Tieng", ""]]}, {"id": "1908.06865", "submitter": "Anup Das", "authors": "Anup Das and Francky Catthoor and Siebren Schaafsma", "title": "Heartbeat Classification in Wearables Using Multi-layer Perceptron and\n  Time-Frequency Joint Distribution of ECG", "comments": "6 pages, 7 figures, published in IEEE/ACM International Conference on\n  Connected Health: Applications, Systems and Engineering Technologies (CHASE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Heartbeat classification using electrocardiogram (ECG) data is a vital\nassistive technology for wearable health solutions. We propose heartbeat\nfeature classification based on a novel sparse representation using\ntime-frequency joint distribution of ECG. Fundamental to this is a multi-layer\nperceptron, which incorporates these signatures to detect cardiac arrhythmia.\nThis approach is validated with ECG data from MIT-BIH arrhythmia database.\nResults show that our approach has an average 95.7% accuracy, an improvement of\n22% over state-of-the-art approaches. Additionally, ECG sparse distributed\nrepresentations generates only 3.7% false negatives, reduction of 89% with\nrespect to existing ECG signal classification techniques.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 23:07:06 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Das", "Anup", ""], ["Catthoor", "Francky", ""], ["Schaafsma", "Siebren", ""]]}, {"id": "1908.06868", "submitter": "Myriam Bontonou", "authors": "Myriam Bontonou (IMT Atlantique - ELEC, MILA), Carlos Lassance (IMT\n  Atlantique - ELEC, MILA), Vincent Gripon (IMT Atlantique - ELEC, MILA),\n  Nicolas Farrugia (IMT Atlantique - ELEC)", "title": "Comparing linear structure-based and data-driven latent spatial\n  representations for sequence prediction", "comments": null, "journal-ref": "Wavelets and Sparsity XVIII, Aug 2019, San Diego, United States", "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the future of Graph-supported Time Series (GTS) is a key challenge\nin many domains, such as climate monitoring, finance or neuroimaging. Yet it is\na highly difficult problem as it requires to account jointly for time and graph\n(spatial) dependencies. To simplify this process, it is common to use a\ntwo-step procedure in which spatial and time dependencies are dealt with\nseparately. In this paper, we are interested in comparing various linear\nspatial representations, namely structure-based ones and data-driven ones, in\nterms of how they help predict the future of GTS. To that end, we perform\nexperiments with various datasets including spontaneous brain activity and raw\nvideos.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:05:20 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Bontonou", "Myriam", "", "IMT Atlantique - ELEC, MILA"], ["Lassance", "Carlos", "", "IMT\n  Atlantique - ELEC, MILA"], ["Gripon", "Vincent", "", "IMT Atlantique - ELEC, MILA"], ["Farrugia", "Nicolas", "", "IMT Atlantique - ELEC"]]}, {"id": "1908.06869", "submitter": "Cheng Li", "authors": "Cheng Li, Abdul Dakkak, Jinjun Xiong, Wei Wei, Lingjie Xu, Wen-mei Hwu", "title": "XSP: Across-Stack Profiling and Analysis of Machine Learning Models on\n  GPUs", "comments": null, "journal-ref": null, "doi": "10.1109/IPDPS47924.2020.00042", "report-no": null, "categories": "cs.LG cs.AR cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been a rapid proliferation of machine learning/deep learning (ML)\nmodels and wide adoption of them in many application domains. This has made\nprofiling and characterization of ML model performance an increasingly pressing\ntask for both hardware designers and system providers, as they would like to\noffer the best possible system to serve ML models with the target latency,\nthroughput, cost, and energy requirements while maximizing resource\nutilization. Such an endeavor is challenging as the characteristics of an ML\nmodel depend on the interplay between the model, framework, system libraries,\nand the hardware (or the HW/SW stack). Existing profiling tools are disjoint,\nhowever, and only focus on profiling within a particular level of the stack,\nwhich limits the thoroughness and usefulness of the profiling results.\n  This paper proposes XSP - an across-stack profiling design that gives a\nholistic and hierarchical view of ML model execution. XSP leverages distributed\ntracing to aggregate and correlates profile data from different sources. XSP\nintroduces a leveled and iterative measurement approach that accurately\ncaptures the latencies at all levels of the HW/SW stack in spite of the\nprofiling overhead. We couple the profiling design with an automated analysis\npipeline to systematically analyze 65 state-of-the-art ML models. We\ndemonstrate that XSP provides insights which would be difficult to discern\notherwise.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:05:29 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:42:42 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 01:31:35 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Li", "Cheng", ""], ["Dakkak", "Abdul", ""], ["Xiong", "Jinjun", ""], ["Wei", "Wei", ""], ["Xu", "Lingjie", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "1908.06871", "submitter": "Steve Jeffrey Tueno Fotso", "authors": "Steve Tueno", "title": "Towards Linearization Machine Learning Algorithms", "comments": "Study report - 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is about a machine learning approach based on the multilinear\nprojection of an unknown function (or probability distribution) to be estimated\ntowards a linear (or multilinear) dimensional space E'. The proposal transforms\nthe problem of predicting the target of an observation x into a problem of\ndetermining a consensus among the k nearest neighbors of x's image within the\ndimensional space E'. The algorithms that concretize it allow both regression\nand binary classification. Implementations carried out using Scala/Spark and\nassessed on a dozen LIBSVM datasets have demonstrated improvements in\nprediction accuracies in comparison with other prediction algorithms\nimplemented within Spark MLLib such as multilayer perceptrons, logistic\nregression classifiers and random forests.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 12:01:46 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Tueno", "Steve", ""]]}, {"id": "1908.06874", "submitter": "Michael Rapp", "authors": "Yannik Klein, Michael Rapp and Eneldo Loza Menc\\'ia", "title": "Efficient Discovery of Expressive Multi-label Rules using Relaxed\n  Pruning", "comments": "Preprint version. To appear in Proceedings of the 22nd International\n  Conference on Discovery Science, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to model correlations between labels is considered crucial in\nmulti-label classification. Rule-based models enable to expose such\ndependencies, e.g., implications, subsumptions, or exclusions, in an\ninterpretable and human-comprehensible manner. Albeit the number of possible\nlabel combinations increases exponentially with the number of available labels,\nit has been shown that rules with multiple labels in their heads, which are a\nnatural form to model local label dependencies, can be induced efficiently by\nexploiting certain properties of rule evaluation measures and pruning the label\nsearch space accordingly. However, experiments have revealed that multi-label\nheads are unlikely to be learned by existing methods due to their\nrestrictiveness. To overcome this limitation, we propose a plug-in approach\nthat relaxes the search space pruning used by existing methods in order to\nintroduce a bias towards larger multi-label heads resulting in more expressive\nrules. We further demonstrate the effectiveness of our approach empirically and\nshow that it does not come with drawbacks in terms of training time or\npredictive performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:22:23 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Klein", "Yannik", ""], ["Rapp", "Michael", ""], ["Menc\u00eda", "Eneldo Loza", ""]]}, {"id": "1908.06884", "submitter": "Hyo-Sang Shin PhD", "authors": "Hyo-Sang Shin, Shaoming He and Antonios Tsourdos", "title": "A Domain-Knowledge-Aided Deep Reinforcement Learning Approach for Flight\n  Control Design", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to examine the potential of using the emerging deep\nreinforcement learning techniques in flight control. Instead of learning from\nscratch, we suggest to leverage domain knowledge available in learning to\nimprove learning efficiency and generalisability. More specifically, the\nproposed approach fixes the autopilot structure as typical three-loop autopilot\nand deep reinforcement learning is utilised to learn the autopilot gains. To\nsolve the flight control problem, we then formulate a Markovian decision\nprocess with a proper reward function that enable the application of\nreinforcement learning theory. Another type of domain knowledge is exploited\nfor defining the reward function, by shaping reference inputs in consideration\nof important control objectives and using the shaped reference inputs in the\nreward function. The state-of-the-art deep deterministic policy gradient\nalgorithm is utilised to learn an action policy that maps the observed states\nto the autopilot gains. Extensive empirical numerical simulations are performed\nto validate the proposed computational control algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:41:33 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 14:52:13 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shin", "Hyo-Sang", ""], ["He", "Shaoming", ""], ["Tsourdos", "Antonios", ""]]}, {"id": "1908.06886", "submitter": "Anton Muravev", "authors": "Anton Muravev, Jenni Raitoharju and Moncef Gabbouj", "title": "Neural Architecture Search by Estimation of Network Structure\n  Distributions", "comments": "16 pages, 4 figures, 3 tables", "journal-ref": "in IEEE Access, vol. 9, pp. 15304-15319, 2021", "doi": "10.1109/ACCESS.2021.3052996", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The influence of deep learning is continuously expanding across different\ndomains, and its new applications are ubiquitous. The question of neural\nnetwork design thus increases in importance, as traditional empirical\napproaches are reaching their limits. Manual design of network architectures\nfrom scratch relies heavily on trial and error, while using existing pretrained\nmodels can introduce redundancies or vulnerabilities. Automated neural\narchitecture design is able to overcome these problems, but the most successful\nalgorithms operate on significantly constrained design spaces, assuming the\ntarget network to consist of identical repeating blocks. While such approach\nallows for faster search, it does so at the cost of expressivity. We instead\npropose an alternative probabilistic representation of a whole neural network\nstructure under the assumption of independence between layer types. Our matrix\nof probabilities is equivalent to the population of models, but allows for\ndiscovery of structural irregularities, while being simple to interpret and\nanalyze. We construct an architecture search algorithm, inspired by the\nestimation of distribution algorithms, to take advantage of this\nrepresentation. The probability matrix is tuned towards generating\nhigh-performance models by repeatedly sampling the architectures and evaluating\nthe corresponding networks, while gradually increasing the model depth. Our\nalgorithm is shown to discover non-regular models which cannot be expressed via\nblocks, but are competitive both in accuracy and computational cost, while not\nutilizing complex dataflows or advanced training techniques, as well as\nremaining conceptually simple and highly extensible.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:43:22 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 14:26:33 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 16:01:20 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Muravev", "Anton", ""], ["Raitoharju", "Jenni", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1908.06923", "submitter": "Pritam Anand South Asian University", "authors": "Pritam Anand, Reshma Rastogi (nee Khemchandani) and Suresh Chandra", "title": "A new asymmetric $\\epsilon$-insensitive pinball loss function based\n  support vector quantile regression model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel asymmetric $\\epsilon$-insensitive pinball\nloss function for quantile estimation. There exists some pinball loss functions\nwhich attempt to incorporate the $\\epsilon$-insensitive zone approach in it\nbut, they fail to extend the $\\epsilon$-insensitive approach for quantile\nestimation in true sense. The proposed asymmetric $\\epsilon$-insensitive\npinball loss function can make an asymmetric $\\epsilon$- insensitive zone of\nfixed width around the data and divide it using $\\tau$ value for the estimation\nof the $\\tau$th quantile. The use of the proposed asymmetric\n$\\epsilon$-insensitive pinball loss function in Support Vector Quantile\nRegression (SVQR) model improves its prediction ability significantly. It also\nbrings the sparsity back in SVQR model. Further, the numerical results obtained\nby several experiments carried on artificial and real world datasets\nempirically show the efficacy of the proposed `$\\epsilon$-Support Vector\nQuantile Regression' ($\\epsilon$-SVQR) model over other existing SVQR models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:48:54 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Anand", "Pritam", "", "nee Khemchandani"], ["Rastogi", "Reshma", "", "nee Khemchandani"], ["Chandra", "Suresh", ""]]}, {"id": "1908.06926", "submitter": "Milan Straka", "authors": "Jana Strakov\\'a, Milan Straka, Jan Haji\\v{c}", "title": "Neural Architectures for Nested NER through Linearization", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two neural network architectures for nested named entity\nrecognition (NER), a setting in which named entities may overlap and also be\nlabeled with more than one label. We encode the nested labels using a\nlinearized scheme. In our first proposed approach, the nested labels are\nmodeled as multilabels corresponding to the Cartesian product of the nested\nlabels in a standard LSTM-CRF architecture. In the second one, the nested NER\nis viewed as a sequence-to-sequence problem, in which the input sequence\nconsists of the tokens and output sequence of the labels, using hard attention\non the word whose label is being predicted. The proposed methods outperform the\nnested NER state of the art on four corpora: ACE-2004, ACE-2005, GENIA and\nCzech CNEC. We also enrich our architectures with the recently published\ncontextual embeddings: ELMo, BERT and Flair, reaching further improvements for\nthe four nested entity corpora. In addition, we report flat NER\nstate-of-the-art results for CoNLL-2002 Dutch and Spanish and for CoNLL-2003\nEnglish.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:54:53 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Strakov\u00e1", "Jana", ""], ["Straka", "Milan", ""], ["Haji\u010d", "Jan", ""]]}, {"id": "1908.06933", "submitter": "Ali Hatamizadeh", "authors": "Ali Hatamizadeh, Assaf Hoogi, Debleena Sengupta, Wuyue Lu, Brian\n  Wilcox, Daniel Rubin and Demetri Terzopoulos", "title": "Deep Active Lesion Segmentation", "comments": "Accepted to Machine Learning in Medical Imaging (MLMI 2019). Link to\n  source code added", "journal-ref": "MLMI 2019", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lesion segmentation is an important problem in computer-assisted diagnosis\nthat remains challenging due to the prevalence of low contrast, irregular\nboundaries that are unamenable to shape priors. We introduce Deep Active Lesion\nSegmentation (DALS), a fully automated segmentation framework for that\nleverages the powerful nonlinear feature extraction abilities of fully\nConvolutional Neural Networks (CNNs) and the precise boundary delineation\nabilities of Active Contour Models (ACMs). Our DALS framework benefits from an\nimproved level-set ACM formulation with a per-pixel-parameterized energy\nfunctional and a novel multiscale encoder-decoder CNN that learns an\ninitialization probability map along with parameter maps for the ACM. We\nevaluate our lesion segmentation model on a new Multiorgan Lesion Segmentation\n(MLS) dataset that contains images of various organs, including brain, liver,\nand lung, across different imaging modalities---MR and CT. Our results\ndemonstrate favorable performance compared to competing methods, especially for\nsmall training datasets. Source code :\n$\\text{https://github.com/ahatamiz/dals}$\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:12:00 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 18:35:36 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 09:15:48 GMT"}, {"version": "v4", "created": "Sun, 30 Aug 2020 16:31:13 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hatamizadeh", "Ali", ""], ["Hoogi", "Assaf", ""], ["Sengupta", "Debleena", ""], ["Lu", "Wuyue", ""], ["Wilcox", "Brian", ""], ["Rubin", "Daniel", ""], ["Terzopoulos", "Demetri", ""]]}, {"id": "1908.06940", "submitter": "Makan Arastuie", "authors": "Makan Arastuie, Subhadeep Paul, Kevin S. Xu", "title": "CHIP: A Hawkes Process Model for Continuous-time Networks with Scalable\n  and Consistent Estimation", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada. Source code is available at\n  https://github.com/IdeasLabUT/CHIP-Network-Model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many application settings involving networks, such as messages between\nusers of an on-line social network or transactions between traders in financial\nmarkets, the observed data consist of timestamped relational events, which form\na continuous-time network. We propose the Community Hawkes Independent Pairs\n(CHIP) generative model for such networks. We show that applying spectral\nclustering to an aggregated adjacency matrix constructed from the CHIP model\nprovides consistent community detection for a growing number of nodes and time\nduration. We also develop consistent and computationally efficient estimators\nfor the model parameters. We demonstrate that our proposed CHIP model and\nestimation procedure scales to large networks with tens of thousands of nodes\nand provides superior fits than existing continuous-time network models on\nseveral real networks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:24:58 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 00:37:44 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 06:19:42 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Arastuie", "Makan", ""], ["Paul", "Subhadeep", ""], ["Xu", "Kevin S.", ""]]}, {"id": "1908.06951", "submitter": "Zhiyuan He", "authors": "Zhiyuan He, Danchen Lin, Thomas Lau, and Mike Wu", "title": "Gradient Boosting Machine: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this survey, we discuss several different types of gradient boosting\nalgorithms and illustrate their mathematical frameworks in detail: 1.\nintroduction of gradient boosting leads to 2. objective function optimization,\n3. loss function estimations, and 4. model constructions. 5. application of\nboosting in ranking.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:38:33 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["He", "Zhiyuan", ""], ["Lin", "Danchen", ""], ["Lau", "Thomas", ""], ["Wu", "Mike", ""]]}, {"id": "1908.06955", "submitter": "Li Zhang", "authors": "Li Zhang, Dan Xu, Anurag Arnab, Philip H.S. Torr", "title": "Dynamic Graph Message Passing Networks", "comments": "CVPR 2020 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling long-range dependencies is critical for complex scene understanding\ntasks such as semantic segmentation and object detection. Although CNNs have\nexcelled in many computer vision tasks, they are still limited in capturing\nlong-range structured relationships as they typically consist of layers of\nlocal kernels. A fully-connected graph is beneficial for such modelling,\nhowever, its computational overhead is prohibitive. We propose a dynamic graph\nmessage passing network, based on the message passing neural network framework,\nthat significantly reduces the computational complexity compared to related\nworks modelling a fully-connected graph. This is achieved by adaptively\nsampling nodes in the graph, conditioned on the input, for message passing.\nBased on the sampled nodes, we then dynamically predict node-dependent filter\nweights and the affinity matrix for propagating information between them. Using\nthis model, we show significant improvements with respect to strong,\nstate-of-the-art baselines on three different tasks and backbone architectures.\nOur approach also outperforms fully-connected graphs while using substantially\nfewer floating point operations and parameters.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:46:34 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 13:37:21 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 10:35:58 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zhang", "Li", ""], ["Xu", "Dan", ""], ["Arnab", "Anurag", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1908.06966", "submitter": "Yao Li", "authors": "Yao Li", "title": "Improve variational autoEncoder with auxiliary softmax multiclassifier", "comments": "15 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a general-purpose generative model architecture, VAE has been widely used\nin the field of image and natural language processing. VAE maps high\ndimensional sample data into continuous latent variables with unsupervised\nlearning. Sampling in the latent variable space of the feature, VAE can\nconstruct new image or text data. As a general-purpose generation model, the\nvanilla VAE can not fit well with various data sets and neural networks with\ndifferent structures. Because of the need to balance the accuracy of\nreconstruction and the convenience of latent variable sampling in the training\nprocess, VAE often has problems known as \"posterior collapse\". images\nreconstructed by VAE are also often blurred. In this paper, we analyze the main\ncause of these problem, which is the lack of mutual information between the\nsample variable and the latent feature variable during the training process. To\nmaintain mutual information in model training, we propose to use the auxiliary\nsoftmax multi-classification network structure to improve the training effect\nof VAE, named VAE-AS. We use MNIST and Omniglot data sets to test the VAE-AS\nmodel. Based on the test results, It can be show that VAE-AS has obvious\neffects on the mutual information adjusting and solving the posterior collapse\nproblem.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 14:36:13 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 06:59:42 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 07:26:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Li", "Yao", ""]]}, {"id": "1908.06969", "submitter": "Eita Nakamura", "authors": "Eita Nakamura and Kazuyoshi Yoshii", "title": "Musical Rhythm Transcription Based on Bayesian Piece-Specific Score\n  Models Capturing Repetitions", "comments": "Title changed; change in organizations of sections; appendix added;\n  some explanations added; 14 pages, 9 figures (supplemental material: 11\n  pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work on musical score models (a.k.a. musical language models) for music\ntranscription has focused on describing the local sequential dependence of\nnotes in musical scores and failed to capture their global repetitive\nstructure, which can be a useful guide for transcribing music. Focusing on\nrhythm, we formulate several classes of Bayesian Markov models of musical\nscores that describe repetitions indirectly using the sparse transition\nprobabilities of notes or note patterns. This enables us to construct\npiece-specific models for unseen scores with an unfixed repetitive structure\nand to derive tractable inference algorithms. Moreover, to describe approximate\nrepetitions, we explicitly incorporate a process for modifying the repeated\nnotes/note patterns. We apply these models as prior musical score models for\nrhythm transcription, where piece-specific score models are inferred from\nperformed MIDI data by Bayesian learning, in contrast to the conventional\nsupervised construction of score models. Evaluations using the vocal melodies\nof popular music showed that the Bayesian models improved the transcription\naccuracy for most of the tested model types, indicating the universal efficacy\nof the proposed approach. Moreover, we found an effective data representation\nfor modelling rhythms that maximizes the transcription accuracy and\ncomputational efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 14:26:59 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 18:27:17 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Nakamura", "Eita", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1908.06971", "submitter": "Cuneyt Gurcan Akcora", "authors": "Nazmiye Ceren Abay, Cuneyt Gurcan Akcora, Yulia R. Gel, Umar D.\n  Islambekov, Murat Kantarcioglu, Yahui Tian, Bhavani Thuraisingham", "title": "ChainNet: Learning on Blockchain Graphs with Topological Features", "comments": "To Appear in the 2019 IEEE International Conference on Data Mining\n  (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With emergence of blockchain technologies and the associated\ncryptocurrencies, such as Bitcoin, understanding network dynamics behind\nBlockchain graphs has become a rapidly evolving research direction. Unlike\nother financial networks, such as stock and currency trading, blockchain based\ncryptocurrencies have the entire transaction graph accessible to the public\n(i.e., all transactions can be downloaded and analyzed). A natural question is\nthen to ask whether the dynamics of the transaction graph impacts the price of\nthe underlying cryptocurrency. We show that standard graph features such as\ndegree distribution of the transaction graph may not be sufficient to capture\nnetwork dynamics and its potential impact on fluctuations of Bitcoin price. In\ncontrast, the new graph associated topological features computed using the\ntools of persistent homology, are found to exhibit a high utility for\npredicting Bitcoin price dynamics. %explain higher order interactions among the\nnodes in Blockchain graphs and can be used to build much more accurate price\nprediction models. Using the proposed persistent homology-based techniques, we\noffer a new elegant, easily extendable and computationally light approach for\ngraph representation learning on Blockchain.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 18:55:16 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Abay", "Nazmiye Ceren", ""], ["Akcora", "Cuneyt Gurcan", ""], ["Gel", "Yulia R.", ""], ["Islambekov", "Umar D.", ""], ["Kantarcioglu", "Murat", ""], ["Tian", "Yahui", ""], ["Thuraisingham", "Bhavani", ""]]}, {"id": "1908.06972", "submitter": "Ahmad Al Badawi", "authors": "Ahmad Al Badawi, Luong Hoang, Chan Fook Mun, Kim Laine, Khin Mi Mi\n  Aung", "title": "PrivFT: Private and Fast Text Classification with Homomorphic Encryption", "comments": "13 pages, 3 figures, 4 tables, 5 Algorithms", "journal-ref": "IEEE Access, 2020", "doi": "10.1109/ACCESS.2020.3045465", "report-no": "2169-3536", "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for privacy-preserving analytics is higher than ever due to the\nseverity of privacy risks and to comply with new privacy regulations leading to\nan amplified interest in privacy-preserving techniques that try to balance\nbetween privacy and utility. In this work, we present an efficient method for\nText Classification while preserving the privacy of the content using Fully\nHomomorphic Encryption (FHE). Our system (named \\textbf{Priv}ate \\textbf{F}ast\n\\textbf{T}ext (PrivFT)) performs two tasks: 1) making inference of encrypted\nuser inputs using a plaintext model and 2) training an effective model using an\nencrypted dataset. For inference, we train a supervised model and outline a\nsystem for homomorphic inference on encrypted user inputs with zero loss to\nprediction accuracy. In the second part, we show how to train a model using\nfully encrypted data to generate an encrypted model. We provide a GPU\nimplementation of the Cheon-Kim-Kim-Song (CKKS) FHE scheme and compare it with\nexisting CPU implementations to achieve 1 to 2 orders of magnitude speedup at\nvarious parameter settings. We implement PrivFT in GPUs to achieve a run time\nper inference of less than 0.66 seconds. Training on a relatively large\nencrypted dataset is more computationally intensive requiring 5.04 days.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 03:44:57 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 10:12:16 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Badawi", "Ahmad Al", ""], ["Hoang", "Luong", ""], ["Mun", "Chan Fook", ""], ["Laine", "Kim", ""], ["Aung", "Khin Mi Mi", ""]]}, {"id": "1908.06973", "submitter": "Yuxi Li", "authors": "Yuxi Li", "title": "Reinforcement Learning Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We start with a brief introduction to reinforcement learning (RL), about its\nsuccessful stories, basics, an example, issues, the ICML 2019 Workshop on RL\nfor Real Life, how to use it, study material and an outlook. Then we discuss a\nselection of RL applications, including recommender systems, computer systems,\nenergy, finance, healthcare, robotics, and transportation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:47:22 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Li", "Yuxi", ""]]}, {"id": "1908.06976", "submitter": "Arthur Aubret", "authors": "Arthur Aubret, Laetitia Matignon, Salima Hassas", "title": "A survey on intrinsic motivation in reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reinforcement learning (RL) research area is very active, with an\nimportant number of new contributions; especially considering the emergent\nfield of deep RL (DRL). However a number of scientific and technical challenges\nstill need to be addressed, amongst which we can mention the ability to\nabstract actions or the difficulty to explore the environment which can be\naddressed by intrinsic motivation (IM). In this article, we provide a survey on\nthe role of intrinsic motivation in DRL. We categorize the different kinds of\nintrinsic motivations and detail for each category, its advantages and\nlimitations with respect to the mentioned challenges. Additionnally, we conduct\nan in-depth investigation of substantial current research questions, that are\ncurrently under study or not addressed at all in the considered research area\nof DRL. We choose to survey these research works, from the perspective of\nlearning how to achieve tasks. We suggest then, that solving current challenges\ncould lead to a larger developmental architecture which may tackle most of the\ntasks. We describe this developmental architecture on the basis of several\nbuilding blocks composed of a RL algorithm and an IM module compressing\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:22:20 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 14:40:14 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Aubret", "Arthur", ""], ["Matignon", "Laetitia", ""], ["Hassas", "Salima", ""]]}, {"id": "1908.07005", "submitter": "Karol Antczak", "authors": "Karol Antczak", "title": "On Regularization Properties of Artificial Datasets for Deep Learning", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper discusses regularization properties of artificial data for deep\nlearning. Artificial datasets allow to train neural networks in the case of a\nreal data shortage. It is demonstrated that the artificial data generation\nprocess, described as injecting noise to high-level features, bears several\nsimilarities to existing regularization methods for deep neural networks. One\ncan treat this property of artificial data as a kind of \"deep\" regularization.\nIt is thus possible to regularize hidden layers of the network by generating\nthe training data in a certain way.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 18:09:07 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Antczak", "Karol", ""]]}, {"id": "1908.07009", "submitter": "Yi Sun", "authors": "Yi Sun, Ivan Ramirez, Alfredo Cuesta-Infante, Kalyan Veeramachaneni", "title": "Towards Reducing Biases in Combining Multiple Experts Online", "comments": "Accepted to IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real life situations, including job and loan applications,\ngatekeepers must make justified and fair real-time decisions about a person's\nfitness for a particular opportunity. In this paper, we aim to accomplish\napproximate group fairness in an online stochastic decision-making process,\nwhere the fairness metric we consider is equalized odds. Our work follows from\nthe classical learning-from-experts scheme, assuming a finite set of\nclassifiers (human experts, rules, options, etc) that cannot be modified. We\nrun separate instances of the algorithm for each label class as well as\nsensitive groups, where the probability of choosing each instance is optimized\nfor both fairness and regret. Our theoretical results show that approximately\nequalized odds can be achieved without sacrificing much regret. We also\ndemonstrate the performance of the algorithm on real data sets commonly used by\nthe fairness community.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 18:17:51 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 20:02:18 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 18:33:53 GMT"}, {"version": "v4", "created": "Mon, 24 May 2021 22:32:26 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Sun", "Yi", ""], ["Ramirez", "Ivan", ""], ["Cuesta-Infante", "Alfredo", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "1908.07013", "submitter": "Peter Turney", "authors": "Peter D. Turney and Saif M. Mohammad", "title": "The Natural Selection of Words: Finding the Features of Fitness", "comments": null, "journal-ref": "Published in PLOS ONE, 14(1), e0211512, January 28, 2019", "doi": "10.1371/journal.pone.0211512", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a dataset for studying the evolution of words, constructed from\nWordNet and the Google Books Ngram Corpus. The dataset tracks the evolution of\n4,000 synonym sets (synsets), containing 9,000 English words, from 1800 AD to\n2000 AD. We present a supervised learning algorithm that is able to predict the\nfuture leader of a synset: the word in the synset that will have the highest\nfrequency. The algorithm uses features based on a word's length, the characters\nin the word, and the historical frequencies of the word. It can predict change\nof leadership (including the identity of the new leader) fifty years in the\nfuture, with an F-score considerably above random guessing. Analysis of the\nlearned models provides insight into the causes of change in the leader of a\nsynset. The algorithm confirms observations linguists have made, such as the\ntrend to replace the -ise suffix with -ize, the rivalry between the -ity and\n-ness suffixes, and the struggle between economy (shorter words are easier to\nremember and to write) and clarity (longer words are more distinctive and less\nlikely to be confused with one another). The results indicate that integration\nof the Google Books Ngram Corpus with WordNet has significant potential for\nimproving our understanding of how language evolves.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 18:28:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Turney", "Peter D.", ""], ["Mohammad", "Saif M.", ""]]}, {"id": "1908.07018", "submitter": "Ayush Maheshwari", "authors": "Ayush Maheshwari, Hrishikesh Patel, Nandan Rathod, Ritesh Kumar,\n  Ganesh Ramakrishnan and Pushpak Bhattacharyya", "title": "Tale of tails using rule augmented sequence labeling for event\n  extraction", "comments": "9 pages, 4 figures, 6 tables", "journal-ref": "StarAI Workshop at AAAI 2020", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of event extraction is a relatively difficult task for low\nresource languages due to the non-availability of sufficient annotated data.\nMoreover, the task becomes complex for tail (rarely occurring) labels wherein\nextremely less data is available. In this paper, we present a new dataset\n(InDEE-2019) in the disaster domain for multiple Indic languages, collected\nfrom news websites. Using this dataset, we evaluate several rule-based\nmechanisms to augment deep learning based models. We formulate our problem of\nevent extraction as a sequence labeling task and perform extensive experiments\nto study and understand the effectiveness of different approaches. We further\nshow that tail labels can be easily incorporated by creating new rules without\nthe requirement of large annotated data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 18:43:06 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 06:10:02 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 07:36:09 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Maheshwari", "Ayush", ""], ["Patel", "Hrishikesh", ""], ["Rathod", "Nandan", ""], ["Kumar", "Ritesh", ""], ["Ramakrishnan", "Ganesh", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1908.07023", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski, Ali H. Sayed", "title": "Second-Order Guarantees of Stochastic Gradient Descent in Non-Convex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen increased interest in performance guarantees of\ngradient descent algorithms for non-convex optimization. A number of works have\nuncovered that gradient noise plays a critical role in the ability of gradient\ndescent recursions to efficiently escape saddle-points and reach second-order\nstationary points. Most available works limit the gradient noise component to\nbe bounded with probability one or sub-Gaussian and leverage concentration\ninequalities to arrive at high-probability results. We present an alternate\napproach, relying primarily on mean-square arguments and show that a more\nrelaxed relative bound on the gradient noise variance is sufficient to ensure\nefficient escape from saddle-points without the need to inject additional\nnoise, employ alternating step-sizes or rely on a global dispersive noise\nassumption, as long as a gradient noise component is present in a descent\ndirection for every saddle-point.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 18:56:40 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1908.07026", "submitter": "Melissa Ailem", "authors": "Melissa Ailem, Bowen Zhang, Fei Sha", "title": "Topic Augmented Generator for Abstractive Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steady progress has been made in abstractive summarization with\nattention-based sequence-to-sequence learning models. In this paper, we propose\na new decoder where the output summary is generated by conditioning on both the\ninput text and the latent topics of the document. The latent topics, identified\nby a topic model such as LDA, reveals more global semantic information that can\nbe used to bias the decoder to generate words. In particular, they enable the\ndecoder to have access to additional word co-occurrence statistics captured at\ndocument corpus level. We empirically validate the advantage of the proposed\napproach on both the CNN/Daily Mail and the WikiHow datasets. Concretely, we\nattain strongly improved ROUGE scores when compared to state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:02:14 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Ailem", "Melissa", ""], ["Zhang", "Bowen", ""], ["Sha", "Fei", ""]]}, {"id": "1908.07031", "submitter": "Weipeng Huang", "authors": "Weipeng Huang, Guangyuan Piao, Raul Moreno, Neil J. Hurley", "title": "Partially Observable Markov Decision Process Modelling for Assessing\n  Hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering has been shown to be valuable in many scenarios.\nDespite its usefulness to many situations, there is no agreed methodology on\nhow to properly evaluate the hierarchies produced from different techniques,\nparticularly in the case where ground-truth labels are unavailable. This\nmotivates us to propose a framework for assessing the quality of hierarchical\nclustering allocations which covers the case of no ground-truth information.\nThis measurement is useful, e.g., to assess the hierarchical structures used by\nonline retailer websites to display their product catalogues. Our framework is\none of the few attempts for the hierarchy evaluation from a decision-theoretic\nperspective. We model the process as a bot searching stochastically for items\nin the hierarchy and establish a measure representing the degree to which the\nhierarchy supports this search. We employ Partially Observable Markov Decision\nProcesses (POMDP) to model the uncertainty, the decision making, and the\ncognitive return for searchers in such a scenario.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:13:27 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 13:56:23 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 17:20:36 GMT"}, {"version": "v4", "created": "Tue, 30 Jun 2020 01:31:59 GMT"}, {"version": "v5", "created": "Tue, 13 Oct 2020 20:35:41 GMT"}, {"version": "v6", "created": "Wed, 4 Nov 2020 13:28:16 GMT"}, {"version": "v7", "created": "Tue, 8 Dec 2020 09:07:39 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Huang", "Weipeng", ""], ["Piao", "Guangyuan", ""], ["Moreno", "Raul", ""], ["Hurley", "Neil J.", ""]]}, {"id": "1908.07061", "submitter": "Mohsen Farhadloo", "authors": "Mohsen Farhadloo (John Molson School of Business Concordia University)", "title": "Twitter Sentiment on Affordable Care Act using Score Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce score embedding, a neural network based model to\nlearn interpretable vector representations for words. Score embedding is a\nsupervised method that takes advantage of the labeled training data and the\nneural network architecture to learn interpretable representations for words.\nHealth care has been a controversial issue between political parties in the\nUnited States. In this paper we use the discussions on Twitter regarding\ndifferent issues of affordable care act to identify the public opinion about\nthe existing health care plans using the proposed score embedding. Our results\nindicate our approach effectively incorporates the sentiment information and\noutperforms or is at least comparable to the state-of-the-art methods and the\nnegative sentiment towards \"TrumpCare\" was consistently greater than neutral\nand positive sentiment over time.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 20:55:52 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Farhadloo", "Mohsen", "", "John Molson School of Business Concordia University"]]}, {"id": "1908.07063", "submitter": "Xuanlin Liu", "authors": "Xuanlin Liu, Mingzhe Chen, Changchuan Yin, Walid Saad", "title": "Analysis of Memory Capacity for Deep Echo State Networks", "comments": "6 pages, 8 figures, Published in 2018 17th IEEE International\n  Conference on Machine Learning and Applications (ICMLA)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00072", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the echo state network (ESN) memory capacity, which represents\nthe amount of input data an ESN can store, is analyzed for a new type of deep\nESNs. In particular, two deep ESN architectures are studied. First, a parallel\ndeep ESN is proposed in which multiple reservoirs are connected in parallel\nallowing them to average outputs of multiple ESNs, thus decreasing the\nprediction error. Then, a series architecture ESN is proposed in which ESN\nreservoirs are placed in cascade that the output of each ESN is the input of\nthe next ESN in the series. This series ESN architecture can capture more\nfeatures between the input sequence and the output sequence thus improving the\noverall prediction accuracy. Fundamental analysis shows that the memory\ncapacity of parallel ESNs is equivalent to that of a traditional shallow ESN,\nwhile the memory capacity of series ESNs is smaller than that of a traditional\nshallow ESN.In terms of normalized root mean square error, simulation results\nshow that the parallel deep ESN achieves 38.5% reduction compared to the\ntraditional shallow ESN while the series deep ESN achieves 16.8% reduction.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 09:16:54 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Liu", "Xuanlin", ""], ["Chen", "Mingzhe", ""], ["Yin", "Changchuan", ""], ["Saad", "Walid", ""]]}, {"id": "1908.07064", "submitter": "Praveen Kumar Bodigutla", "authors": "Praveen Kumar Bodigutla, Longshaokan Wang, Kate Ridgeway, Joshua Levy,\n  Swanand Joshi, Alborz Geramifard, Spyros Matsoukas", "title": "Domain-Independent turn-level Dialogue Quality Evaluation via User\n  Satisfaction Estimation", "comments": "Implications of Deep Learning for Dialog Modeling - Special session\n  at SIGdial 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automated metric to evaluate dialogue quality is vital for optimizing data\ndriven dialogue management. The common approach of relying on explicit user\nfeedback during a conversation is intrusive and sparse. Current models to\nestimate user satisfaction use limited feature sets and rely on annotation\nschemes with low inter-rater reliability, limiting generalizability to\nconversations spanning multiple domains. To address these gaps, we created a\nnew Response Quality annotation scheme, based on which we developed turn-level\nUser Satisfaction metric. We introduced five new domain-independent feature\nsets and experimented with six machine learning models to estimate the new\nsatisfaction metric.\n  Using Response Quality annotation scheme, across randomly sampled single and\nmulti-turn conversations from 26 domains, we achieved high inter-annotator\nagreement (Spearman's rho 0.94). The Response Quality labels were highly\ncorrelated (0.76) with explicit turn-level user ratings. Gradient boosting\nregression achieved best correlation of ~0.79 between predicted and annotated\nuser satisfaction labels. Multi Layer Perceptron and Gradient Boosting\nregression models generalized to an unseen domain better (linear correlation\n0.67) than other models. Finally, our ablation study verified that our novel\nfeatures significantly improved model performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 20:58:24 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Bodigutla", "Praveen Kumar", ""], ["Wang", "Longshaokan", ""], ["Ridgeway", "Kate", ""], ["Levy", "Joshua", ""], ["Joshi", "Swanand", ""], ["Geramifard", "Alborz", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1908.07069", "submitter": "Zulfat Miftahutdinov", "authors": "Sergey Nikolenko and Elena Tutubalina and Zulfat Miftahutdinov and\n  Eugene Beloded", "title": "CommentsRadar: Dive into Unique Data on All Comments on the Web", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an entity-centric search engineCommentsRadarthatpairs entity\nqueries with articles and user opinions covering a widerange of topics from top\ncommented sites. The engine aggregatesarticles and comments for these articles,\nextracts named entities,links them together and with knowledge base entries,\nperformssentiment analysis, and aggregates the results, aiming to mine\nfortemporal trends and other insights. In this work, we present thegeneral\nengine, discuss the models used for all steps of this pipeline,and introduce\nseveral case studies that discover important insightsfrom online commenting\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:01:30 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Nikolenko", "Sergey", ""], ["Tutubalina", "Elena", ""], ["Miftahutdinov", "Zulfat", ""], ["Beloded", "Eugene", ""]]}, {"id": "1908.07078", "submitter": "Arman Hasanzadeh Moghimi", "authors": "Arman Hasanzadeh, Ehsan Hajiramezanali, Nick Duffield, Krishna R.\n  Narayanan, Mingyuan Zhou, Xiaoning Qian", "title": "Semi-Implicit Graph Variational Auto-Encoders", "comments": "Accepted to Advances in Neural Information Processing Systems\n  (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-implicit graph variational auto-encoder (SIG-VAE) is proposed to expand\nthe flexibility of variational graph auto-encoders (VGAE) to model graph data.\nSIG-VAE employs a hierarchical variational framework to enable neighboring node\nsharing for better generative modeling of graph dependency structure, together\nwith a Bernoulli-Poisson link decoder. Not only does this hierarchical\nconstruction provide a more flexible generative graph model to better capture\nreal-world graph properties, but also does SIG-VAE naturally lead to\nsemi-implicit hierarchical variational inference that allows faithful modeling\nof implicit posteriors of given graph data, which may exhibit heavy tails,\nmultiple modes, skewness, and rich dependency structures. Compared to VGAE, the\nderived graph latent representations by SIG-VAE are more interpretable, due to\nmore expressive generative model and more faithful inference enabled by the\nflexible semi-implicit construction. Extensive experiments with a variety of\ngraph data show that SIG-VAE significantly outperforms state-of-the-art methods\non several different graph analytic tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 21:33:37 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 22:06:14 GMT"}, {"version": "v3", "created": "Sat, 7 Sep 2019 16:55:49 GMT"}, {"version": "v4", "created": "Wed, 22 Apr 2020 06:03:58 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Hasanzadeh", "Arman", ""], ["Hajiramezanali", "Ehsan", ""], ["Duffield", "Nick", ""], ["Narayanan", "Krishna R.", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1908.07087", "submitter": "Hamed Nilforoshan", "authors": "Hamed Nilforoshan, Neil Shah", "title": "SliceNDice: Mining Suspicious Multi-attribute Entity Groups with\n  Multi-view Graphs", "comments": "Published in Proceedings of 2019 IEEE 6th International Conference on\n  Data Science and Advanced Analytics (DSAA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the reach of web platforms, bad actors have considerable incentives to\nmanipulate and defraud users at the expense of platform integrity. This has\nspurred research in numerous suspicious behavior detection tasks, including\ndetection of sybil accounts, false information, and payment scams/fraud. In\nthis paper, we draw the insight that many such initiatives can be tackled in a\ncommon framework by posing a detection task which seeks to find groups of\nentities which share too many properties with one another across multiple\nattributes (sybil accounts created at the same time and location, propaganda\nspreaders broadcasting articles with the same rhetoric and with similar\nreshares, etc.) Our work makes four core contributions: Firstly, we posit a\nnovel formulation of this task as a multi-view graph mining problem, in which\ndistinct views reflect distinct attribute similarities across entities, and\ncontextual similarity and attribute importance are respected. Secondly, we\npropose a novel suspiciousness metric for scoring entity groups given the\nabnormality of their synchronicity across multiple views, which obeys intuitive\ndesiderata that existing metrics do not. Finally, we propose the SliceNDice\nalgorithm which enables efficient extraction of highly suspicious entity\ngroups, and demonstrate its practicality in production, in terms of strong\ndetection performance and discoveries on Snapchat's large advertiser ecosystem\n(89% precision and numerous discoveries of real fraud rings), marked\noutperformance of baselines (over 97% precision/recall in simulated settings)\nand linear scalability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 22:09:10 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 16:51:08 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 22:15:18 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Nilforoshan", "Hamed", ""], ["Shah", "Neil", ""]]}, {"id": "1908.07088", "submitter": "Ethan Gordon", "authors": "Ethan K. Gordon, Xiang Meng, Matt Barnes, Tapomayukh Bhattacharjee,\n  Siddhartha S. Srinivasa", "title": "Adaptive Robot-Assisted Feeding: An Online Learning Framework for\n  Acquiring Previously Unseen Food Items", "comments": "To appear in IROS 2020; 8 pages incl. references, 8 figures; Abstract\n  presented in IJCAI 2019 AIxFood Workshop; v3: Added simulation and\n  experimental results for conference submission; v4: Added extra results to\n  Experiment 2 for camera-ready submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A successful robot-assisted feeding system requires bite acquisition of a\nwide variety of food items. It must adapt to changing user food preferences\nunder uncertain visual and physical environments. Different food items in\ndifferent environmental conditions require different manipulation strategies\nfor successful bite acquisition. Therefore, a key challenge is how to handle\npreviously unseen food items with very different success rate distributions\nover strategy. Combining low-level controllers and planners into discrete\naction trajectories, we show that the problem can be represented using a linear\ncontextual bandit setting. We construct a simulated environment using a doubly\nrobust loss estimate from previously seen food items, which we use to tune the\nparameters of off-the-shelf contextual bandit algorithms. Finally, we\ndemonstrate empirically on a robot-assisted feeding system that, even starting\nwith a model trained on thousands of skewering attempts on dissimilar\npreviously seen food items, $\\epsilon$-greedy and LinUCB algorithms can quickly\nconverge to the most successful manipulation strategy.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 22:36:45 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 19:38:07 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 22:48:32 GMT"}, {"version": "v4", "created": "Sat, 1 Aug 2020 00:47:21 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gordon", "Ethan K.", ""], ["Meng", "Xiang", ""], ["Barnes", "Matt", ""], ["Bhattacharjee", "Tapomayukh", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "1908.07107", "submitter": "Debanjan Borthakur", "authors": "Debanjan Borthakur, Victoria Grace, Paul Batchelor, Harishchandra\n  Dubey, Kunal Mankodiya", "title": "Fuzzy C-Means Clustering and Sonification of HRV Features", "comments": "5 pages, 5 figures", "journal-ref": "2019 the IEEE/ACM 4th International Conference on Connected\n  Health: Applications, Systems and Engineering Technologies: EdgeDL\n  WorkshopAt: Washington, D.C, sep- 25-27", "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear and non-linear measures of heart rate variability (HRV) are widely\ninvestigated as non-invasive indicators of health. Stress has a profound impact\non heart rate, and different meditation techniques have been found to modulate\nheartbeat rhythm. This paper aims to explore the process of identifying\nappropriate metrices from HRV analysis for sonification. Sonification is a type\nof auditory display involving the process of mapping data to acoustic\nparameters. This work explores the use of auditory display in aiding the\nanalysis of HRV leveraged by unsupervised machine learning techniques.\nUnsupervised clustering helps select the appropriate features to improve the\nsonification interpretability. Vocal synthesis sonification techniques are\nemployed to increase comprehension and learnability of the processed data\ndisplayed through sound. These analyses are early steps in building a real-time\nsound-based biofeedback training system.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 23:44:01 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 21:47:27 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Borthakur", "Debanjan", ""], ["Grace", "Victoria", ""], ["Batchelor", "Paul", ""], ["Dubey", "Harishchandra", ""], ["Mankodiya", "Kunal", ""]]}, {"id": "1908.07110", "submitter": "Yichuan Li", "authors": "Kaize Ding, Yichuan Li, Jundong Li, Chenghao Liu and Huan Liu", "title": "Feature Interaction-aware Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the immense success of deep learning, graph neural networks\n(GNNs) are widely used to learn powerful node representations and have\ndemonstrated promising performance on different graph learning tasks. However,\nmost real-world graphs often come with high-dimensional and sparse node\nfeatures, rendering the learned node representations from existing GNN\narchitectures less expressive. In this paper, we propose \\textit{Feature\nInteraction-aware Graph Neural Networks (FI-GNNs)}, a plug-and-play GNN\nframework for learning node representations encoded with informative feature\ninteractions. Specifically, the proposed framework is able to highlight\ninformative feature interactions in a personalized manner and further learn\nhighly expressive node representations on feature-sparse graphs. Extensive\nexperiments on various datasets demonstrate the superior capability of FI-GNNs\nfor graph learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 23:54:28 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 22:13:07 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Ding", "Kaize", ""], ["Li", "Yichuan", ""], ["Li", "Jundong", ""], ["Liu", "Chenghao", ""], ["Liu", "Huan", ""]]}, {"id": "1908.07116", "submitter": "Xiao Wang", "authors": "Xiao Wang, Siyue Wang, Pin-Yu Chen, Yanzhi Wang, Brian Kulis, Xue Lin\n  and Peter Chin", "title": "Protecting Neural Networks with Hierarchical Random Switching: Towards\n  Better Robustness-Accuracy Trade-off for Stochastic Defenses", "comments": "Published as Conference Paper @ IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite achieving remarkable success in various domains, recent studies have\nuncovered the vulnerability of deep neural networks to adversarial\nperturbations, creating concerns on model generalizability and new threats such\nas prediction-evasive misclassification or stealthy reprogramming. Among\ndifferent defense proposals, stochastic network defenses such as random neuron\nactivation pruning or random perturbation to layer inputs are shown to be\npromising for attack mitigation. However, one critical drawback of current\ndefenses is that the robustness enhancement is at the cost of noticeable\nperformance degradation on legitimate data, e.g., large drop in test accuracy.\nThis paper is motivated by pursuing for a better trade-off between adversarial\nrobustness and test accuracy for stochastic network defenses. We propose\nDefense Efficiency Score (DES), a comprehensive metric that measures the gain\nin unsuccessful attack attempts at the cost of drop in test accuracy of any\ndefense. To achieve a better DES, we propose hierarchical random switching\n(HRS), which protects neural networks through a novel randomization scheme. A\nHRS-protected model contains several blocks of randomly switching channels to\nprevent adversaries from exploiting fixed model structures and parameters for\ntheir malicious purposes. Extensive experiments show that HRS is superior in\ndefending against state-of-the-art white-box and adaptive adversarial\nmisclassification attacks. We also demonstrate the effectiveness of HRS in\ndefending adversarial reprogramming, which is the first defense against\nadversarial programs. Moreover, in most settings the average DES of HRS is at\nleast 5X higher than current stochastic network defenses, validating its\nsignificantly improved robustness-accuracy trade-off.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 00:29:23 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Wang", "Xiao", ""], ["Wang", "Siyue", ""], ["Chen", "Pin-Yu", ""], ["Wang", "Yanzhi", ""], ["Kulis", "Brian", ""], ["Lin", "Xue", ""], ["Chin", "Peter", ""]]}, {"id": "1908.07121", "submitter": "Chengchao Shen", "authors": "Chengchao Shen, Mengqi Xue, Xinchao Wang, Jie Song, Li Sun, Mingli\n  Song", "title": "Customizing Student Networks From Heterogeneous Teachers via Adaptive\n  Knowledge Amalgamation", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A massive number of well-trained deep networks have been released by\ndevelopers online. These networks may focus on different tasks and in many\ncases are optimized for different datasets. In this paper, we study how to\nexploit such heterogeneous pre-trained networks, known as teachers, so as to\ntrain a customized student network that tackles a set of selective tasks\ndefined by the user. We assume no human annotations are available, and each\nteacher may be either single- or multi-task. To this end, we introduce a\ndual-step strategy that first extracts the task-specific knowledge from the\nheterogeneous teachers sharing the same sub-task, and then amalgamates the\nextracted knowledge to build the student network. To facilitate the training,\nwe employ a selective learning scheme where, for each unlabelled sample, the\nstudent learns adaptively from only the teacher with the least prediction\nambiguity. We evaluate the proposed approach on several datasets and\nexperimental results demonstrate that the student, learned by such adaptive\nknowledge amalgamation, achieves performances even better than those of the\nteachers.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 01:13:26 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Shen", "Chengchao", ""], ["Xue", "Mengqi", ""], ["Wang", "Xinchao", ""], ["Song", "Jie", ""], ["Sun", "Li", ""], ["Song", "Mingli", ""]]}, {"id": "1908.07124", "submitter": "Akinari Onishi", "authors": "Akinari Onishi", "title": "Landmark Map: An Extension of the Self-Organizing Map for a\n  User-Intended Nonlinear Projection", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2019.12.125", "report-no": null, "categories": "cs.NE cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The self-organizing map (SOM) is an unsupervised artificial neural network\nthat is widely used in, e.g., data mining and visualization. Supervised and\nsemi-supervised learning methods have been proposed for the SOM. However, their\nteacher labels do not describe the relationship between the data and the\nlocation of nodes. This study proposes a landmark map (LAMA), which is an\nextension of the SOM that utilizes several landmarks, e.g., pairs of nodes and\ndata points. LAMA is designed to obtain a user-intended nonlinear projection to\nachieve, e.g., the landmark-oriented data visualization. To reveal the learning\nproperties of LAMA, the Zoo dataset from the UCI Machine Learning Repository\nand an artificial formant dataset were analyzed. The analysis results of the\nZoo dataset indicated that LAMA could provide a new data view such as the\nlandmark-centered data visualization. Furthermore, the artificial formant data\nanalysis revealed that LAMA successfully provided the intended nonlinear\nprojection associating articular movement with vertical and horizontal movement\nof a computer cursor. Potential applications of LAMA include data mining,\nrecommendation systems, and human-computer interaction.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 01:51:14 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Onishi", "Akinari", ""]]}, {"id": "1908.07125", "submitter": "Eric Wallace", "authors": "Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, Sameer Singh", "title": "Universal Adversarial Triggers for Attacking and Analyzing NLP", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples highlight model vulnerabilities and are useful for\nevaluation and interpretation. We define universal adversarial triggers:\ninput-agnostic sequences of tokens that trigger a model to produce a specific\nprediction when concatenated to any input from a dataset. We propose a\ngradient-guided search over tokens which finds short trigger sequences (e.g.,\none word for classification and four words for language modeling) that\nsuccessfully trigger the target prediction. For example, triggers cause SNLI\nentailment accuracy to drop from 89.94% to 0.55%, 72% of \"why\" questions in\nSQuAD to be answered \"to kill american people\", and the GPT-2 language model to\nspew racist output even when conditioned on non-racial contexts. Furthermore,\nalthough the triggers are optimized using white-box access to a specific model,\nthey transfer to other models for all tasks we consider. Finally, since\ntriggers are input-agnostic, they provide an analysis of global model behavior.\nFor instance, they confirm that SNLI models exploit dataset biases and help to\ndiagnose heuristics learned by reading comprehension models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 01:51:40 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 20:39:20 GMT"}, {"version": "v3", "created": "Sun, 3 Jan 2021 19:58:55 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Wallace", "Eric", ""], ["Feng", "Shi", ""], ["Kandpal", "Nikhil", ""], ["Gardner", "Matt", ""], ["Singh", "Sameer", ""]]}, {"id": "1908.07136", "submitter": "Yixiao Li", "authors": "Yixiao Li, Gloria Lin, Thomas Lau, Ruochen Zeng", "title": "A Review of Changepoint Detection Models", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the change-point detection is to discover the abrupt\nproperty changes lying behind the time-series data. In this paper, we firstly\nsummarize the definition and in-depth implication of the changepoint detection.\nThe next stage is to elaborate traditional and some alternative model-based\nchangepoint detection algorithms. Finally, we try to go a bit further in the\ntheory and look into future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 02:58:49 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Li", "Yixiao", ""], ["Lin", "Gloria", ""], ["Lau", "Thomas", ""], ["Zeng", "Ruochen", ""]]}, {"id": "1908.07147", "submitter": "Zhiyuan Ma", "authors": "Liang Zhao, Zhiyuan Ma, Yangming Zhou, Kai Wang, Shengping Liu, Ju Gao", "title": "CBOWRA: A Representation Learning Approach for Medication Anomaly\n  Detection", "comments": "8 pages, 6 figures, submitted to BIBM 2019, accepted in workshop BHI\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health record is an important source for clinical researches and\napplications, and errors inevitably occur in the data, which could lead to\nsevere damages to both patients and hospital services. One of such error is the\nmismatches between diagnoses and prescriptions, which we address as 'medication\nanomaly' in the paper, and clinicians used to manually identify and correct\nthem. With the development of machine learning techniques, researchers are able\nto train specific model for the task, but the process still requires expert\nknowledge to construct proper features, and few semantic relations are\nconsidered. In this paper, we propose a simple, yet effective detection method\nthat tackles the problem by detecting the semantic inconsistency between\ndiagnoses and prescriptions. Unlike traditional outlier or anomaly detection,\nthe scheme uses continuous bag of words to construct the semantic connection\nbetween specific central words and their surrounding context. The detection of\nmedication anomaly is transformed into identifying the least possible central\nword based on given context. To help distinguish the anomaly from normal\ncontext, we also incorporate a ranking accumulation strategy. The experiments\nwere conducted on two real hospital electronic medical records, and the topN\naccuracy of the proposed method increased by 3.91 to 10.91% and 0.68 to 2.13%\non the datasets, respectively, which is highly competitive to other traditional\nmachine learning-based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 03:40:39 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 08:39:30 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Zhao", "Liang", ""], ["Ma", "Zhiyuan", ""], ["Zhou", "Yangming", ""], ["Wang", "Kai", ""], ["Liu", "Shengping", ""], ["Gao", "Ju", ""]]}, {"id": "1908.07181", "submitter": "Raphael Shu", "authors": "Raphael Shu, Jason Lee, Hideki Nakayama, Kyunghyun Cho", "title": "Latent-Variable Non-Autoregressive Neural Machine Translation with\n  Deterministic Inference Using a Delta Posterior", "comments": "This paper was accepted to AAAI 2020, the copyright is transferred to\n  AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural machine translation models reached high translation quality,\nthe autoregressive nature makes inference difficult to parallelize and leads to\nhigh translation latency. Inspired by recent refinement-based approaches, we\npropose LaNMT, a latent-variable non-autoregressive model with continuous\nlatent variables and deterministic inference procedure. In contrast to existing\napproaches, we use a deterministic inference algorithm to find the target\nsequence that maximizes the lowerbound to the log-probability. During\ninference, the length of translation automatically adapts itself. Our\nexperiments show that the lowerbound can be greatly increased by running the\ninference algorithm, resulting in significantly improved translation quality.\nOur proposed model closes the performance gap between non-autoregressive and\nautoregressive approaches on ASPEC Ja-En dataset with 8.6x faster decoding. On\nWMT'14 En-De dataset, our model narrows the gap with autoregressive baseline to\n2.0 BLEU points with 12.5x speedup. By decoding multiple initial latent\nvariables in parallel and rescore using a teacher model, the proposed model\nfurther brings the gap down to 1.0 BLEU point on WMT'14 En-De task with 6.8x\nspeedup.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 06:14:18 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 05:17:44 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 01:35:11 GMT"}, {"version": "v4", "created": "Sat, 5 Oct 2019 07:03:22 GMT"}, {"version": "v5", "created": "Thu, 21 Nov 2019 05:49:25 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shu", "Raphael", ""], ["Lee", "Jason", ""], ["Nakayama", "Hideki", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1908.07190", "submitter": "Srikanth Tamilselvam", "authors": "Srikanth G Tamilselvam, Ankush Gupta, Arvind Agarwal", "title": "Compliance Change Tracking in Business Process Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regulatory compliance is an organization's adherence to laws, regulations,\nguidelines and specifications relevant to its business. Compliance officers\nresponsible for maintaining adherence constantly struggle to keep up with the\nlarge amount of changes in regulatory requirements. Keeping up with the changes\nentail two main tasks: fetching the regulatory announcements that actually\ncontain changes of interest, and incorporating those changes in the business\nprocess. In this paper we focus on the first task, and present a Compliance\nChange Tracking System, that gathers regulatory announcements from government\nsites, news sites, email subscriptions; classifies their importance i.e\nActionability through a hierarchical classifier, and business process\napplicability through a multi-class classifier. For these classifiers, we\nexperiment with several approaches such as vanilla classification methods (e.g.\nNaive Bayes, logistic regression etc.), hierarchical classification methods,\nrule based approach, hybrid approach with various preprocessing and feature\nselection methods; and show that despite the richness of other models, a simple\nhierarchical classification with bag-of-words features works the best for\nActionability classifier and multi-class logistic regression works the best for\nApplicability classifier. The system has been deployed in global delivery\ncenters, and has received positive feedback from payroll compliance officers.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 06:49:06 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Tamilselvam", "Srikanth G", ""], ["Gupta", "Ankush", ""], ["Agarwal", "Arvind", ""]]}, {"id": "1908.07193", "submitter": "Nicolo Colombo", "authors": "Nicolo Colombo, Ricardo Silva, Soong M Kang, Arthur Gretton", "title": "Counterfactual Distribution Regression for Structured Inference", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider problems in which a system receives external \\emph{perturbations}\nfrom time to time. For instance, the system can be a train network in which\nparticular lines are repeatedly disrupted without warning, having an effect on\npassenger behavior. The goal is to predict changes in the behavior of the\nsystem at particular points of interest, such as passenger traffic around\nstations at the affected rails. We assume that the data available provides\nrecords of the system functioning at its \"natural regime\" (e.g., the train\nnetwork without disruptions) and data on cases where perturbations took place.\nThe inference problem is how information concerning perturbations, with\nparticular covariates such as location and time, can be generalized to predict\nthe effect of novel perturbations. We approach this problem from the point of\nview of a mapping from the counterfactual distribution of the system behavior\nwithout disruptions to the distribution of the disrupted system. A variant on\n\\emph{distribution regression} is developed for this setup.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 07:13:01 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Colombo", "Nicolo", ""], ["Silva", "Ricardo", ""], ["Kang", "Soong M", ""], ["Gretton", "Arthur", ""]]}, {"id": "1908.07195", "submitter": "Pei Ke", "authors": "Pei Ke, Fei Huang, Minlie Huang, Xiaoyan Zhu", "title": "ARAML: A Stable Adversarial Training Framework for Text Generation", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing generative adversarial networks (GAN) for text\ngeneration suffer from the instability of reinforcement learning training\nalgorithms such as policy gradient, leading to unstable performance. To tackle\nthis problem, we propose a novel framework called Adversarial Reward Augmented\nMaximum Likelihood (ARAML). During adversarial training, the discriminator\nassigns rewards to samples which are acquired from a stationary distribution\nnear the data rather than the generator's distribution. The generator is\noptimized with maximum likelihood estimation augmented by the discriminator's\nrewards instead of policy gradient. Experiments show that our model can\noutperform state-of-the-art text GANs with a more stable training process.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 07:25:14 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Ke", "Pei", ""], ["Huang", "Fei", ""], ["Huang", "Minlie", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1908.07209", "submitter": "Jianxing Hu Mr", "authors": "Yibo Li, Jianxing Hu, Yanxing Wang, Jielong Zhou, Liangren Zhang and\n  Zhenming Liu", "title": "DeepScaffold: a comprehensive tool for scaffold-based de novo drug\n  discovery using deep learning", "comments": "Updates to this version 1. Add supporting information (aux.pdf) 2.\n  Improvements to Section 2.2 3. Resolve grammar issues", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ultimate goal of drug design is to find novel compounds with desirable\npharmacological properties. Designing molecules retaining particular scaffolds\nas the core structures of the molecules is one of the efficient ways to obtain\npotential drug candidates with desirable properties. We proposed a\nscaffold-based molecular generative model for scaffold-based drug discovery,\nwhich performs molecule generation based on a wide spectrum of scaffold\ndefinitions, including BM-scaffolds, cyclic skeletons, as well as scaffolds\nwith specifications on side-chain properties. The model can generalize the\nlearned chemical rules of adding atoms and bonds to a given scaffold.\nFurthermore, the generated compounds were evaluated by molecular docking in\nDRD2 targets and the results demonstrated that this approach can be effectively\napplied to solve several drug design problems, including the generation of\ncompounds containing a given scaffold and de novo drug design of potential drug\ncandidates with specific docking scores. Finally, a command line interface is\ncreated.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 08:04:00 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 14:25:05 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 01:35:27 GMT"}, {"version": "v4", "created": "Thu, 5 Sep 2019 00:47:25 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Li", "Yibo", ""], ["Hu", "Jianxing", ""], ["Wang", "Yanxing", ""], ["Zhou", "Jielong", ""], ["Zhang", "Liangren", ""], ["Liu", "Zhenming", ""]]}, {"id": "1908.07214", "submitter": "He Wang", "authors": "He Wang, Edmond S. L. Ho, Hubert P. H. Shum and Zhanxing Zhu", "title": "Spatio-temporal Manifold Learning for Human Motions via Long-horizon\n  Modeling", "comments": "12 pages, Accepted in IEEE Transaction on Visualization and Computer\n  Graphics", "journal-ref": "IEEE Transaction on Visualization and Computer Graphics, 2019", "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven modeling of human motions is ubiquitous in computer graphics and\ncomputer vision applications, such as synthesizing realistic motions or\nrecognizing actions. Recent research has shown that such problems can be\napproached by learning a natural motion manifold using deep learning to address\nthe shortcomings of traditional data-driven approaches. However, previous\nmethods can be sub-optimal for two reasons. First, the skeletal information has\nnot been fully utilized for feature extraction. Unlike images, it is difficult\nto define spatial proximity in skeletal motions in the way that deep networks\ncan be applied. Second, motion is time-series data with strong multi-modal\ntemporal correlations. A frame could be followed by several candidate frames\nleading to different motions; long-range dependencies exist where a number of\nframes in the beginning correlate to a number of frames later. Ineffective\nmodeling would either under-estimate the multi-modality and variance, resulting\nin featureless mean motion or over-estimate them resulting in jittery motions.\nIn this paper, we propose a new deep network to tackle these challenges by\ncreating a natural motion manifold that is versatile for many applications. The\nnetwork has a new spatial component for feature extraction. It is also equipped\nwith a new batch prediction model that predicts a large number of frames at\nonce, such that long-term temporally-based objective functions can be employed\nto correctly learn the motion multi-modality and variances. With our system,\nlong-duration motions can be predicted/synthesized using an open-loop setup\nwhere the motion retains the dynamics accurately. It can also be used for\ndenoising corrupted motions and synthesizing new motions with given control\nsignals. We demonstrate that our system can create superior results comparing\nto existing work in multiple applications.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 08:18:58 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Wang", "He", ""], ["Ho", "Edmond S. L.", ""], ["Shum", "Hubert P. H.", ""], ["Zhu", "Zhanxing", ""]]}, {"id": "1908.07220", "submitter": "Ingvild Margrethe Helg{\\o}y", "authors": "Ingvild M. Helg{\\o}y and Yushu Li", "title": "A Noise-Robust Fast Sparse Bayesian Learning Model", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper utilizes the hierarchical model structure from the Bayesian Lasso\nin the Sparse Bayesian Learning process to develop a new type of probabilistic\nsupervised learning approach. The hierarchical model structure in this Bayesian\nframework is designed such that the priors do not only penalize the unnecessary\ncomplexity of the model but will also be conditioned on the variance of the\nrandom noise in the data. The hyperparameters in the model are estimated by the\nFast Marginal Likelihood Maximization algorithm which can achieve sparsity, low\ncomputational cost and faster learning process. We compare our methodology with\ntwo other popular learning models; the Relevance Vector Machine and the\nBayesian Lasso. We test our model on examples involving both simulated and\nempirical data, and the results show that this approach has several performance\nadvantages, such as being fast, sparse and also robust to the variance in\nrandom noise. In addition, our method can give out a more stable estimation of\nvariance of random error, compared with the other methods in the study.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 08:36:14 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 10:06:26 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Helg\u00f8y", "Ingvild M.", ""], ["Li", "Yushu", ""]]}, {"id": "1908.07235", "submitter": "Tiago Ramalho", "authors": "Tiago Ramalho, Miguel Miranda", "title": "Density estimation in representation space to predict model uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models frequently make incorrect predictions with high\nconfidence when presented with test examples that are not well represented in\ntheir training dataset. We propose a novel and straightforward approach to\nestimate prediction uncertainty in a pre-trained neural network model. Our\nmethod estimates the training data density in representation space for a novel\ninput. A neural network model then uses this information to determine whether\nwe expect the pre-trained model to make a correct prediction. This uncertainty\nmodel is trained by predicting in-distribution errors, but can detect\nout-of-distribution data without having seen any such example. We test our\nmethod for a state-of-the art image classification model in the settings of\nboth in-distribution uncertainty estimation as well as out-of-distribution\ndetection.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 09:21:14 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 06:27:40 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Ramalho", "Tiago", ""], ["Miranda", "Miguel", ""]]}, {"id": "1908.07253", "submitter": "Michel Moukari", "authors": "Michel Moukari, Lo\\\"ic Simon, Sylvaine Picard, Fr\\'ed\\'eric Jurie", "title": "n-MeRCI: A new Metric to Evaluate the Correlation Between Predictive\n  Uncertainty and True Error", "comments": null, "journal-ref": "IEEE/RJS International Conference on Intelligent Robots and\n  Systems (IROS), In press", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning applications are becoming more and more pervasive in\nrobotics, the question of evaluating the reliability of inferences becomes a\ncentral question in the robotics community. This domain, known as predictive\nuncertainty, has come under the scrutiny of research groups developing Bayesian\napproaches adapted to deep learning such as Monte Carlo Dropout. Unfortunately,\nfor the time being, the real goal of predictive uncertainty has been swept\nunder the rug. Indeed, these approaches are solely evaluated in terms of raw\nperformance of the network prediction, while the quality of their estimated\nuncertainty is not assessed. Evaluating such uncertainty prediction quality is\nespecially important in robotics, as actions shall depend on the confidence in\nperceived information. In this context, the main contribution of this article\nis to propose a novel metric that is adapted to the evaluation of relative\nuncertainty assessment and directly applicable to regression with deep neural\nnetworks. To experimentally validate this metric, we evaluate it on a toy\ndataset and then apply it to the task of monocular depth estimation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 09:51:08 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Moukari", "Michel", ""], ["Simon", "Lo\u00efc", ""], ["Picard", "Sylvaine", ""], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1908.07263", "submitter": "Leonel Rozo", "authors": "Leonel Rozo", "title": "Interactive Trajectory Adaptation through Force-guided Bayesian\n  Optimization", "comments": "To appear at IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flexible manufacturing processes demand robots to easily adapt to changes in\nthe environment and interact with humans. In such dynamic scenarios, robotic\ntasks may be programmed through learning-from-demonstration approaches, where a\nnominal plan of the task is learned by the robot. However, the learned plan may\nneed to be adapted in order to fulfill additional requirements or overcome\nunexpected environment changes. When the required adaptation occurs at the\nend-effector trajectory level, a human operator may want to intuitively show\nthe robot the desired changes by physically interacting with it. In this\nscenario, the robot needs to understand the human intended changes from noisy\nhaptic data, quickly adapt accordingly and execute the nominal task plan when\nno further adaptation is needed. This paper addresses the aforementioned\nchallenges by leveraging LfD and Bayesian optimization to endow the robot with\ndata-efficient adaptation capabilities. Our approach exploits the sensed\ninteraction forces to guide the robot adaptation, and speeds up the\noptimization process by defining local search spaces extracted from the learned\ntask model. We show how our framework quickly adapts the learned\nspatial-temporal patterns of the task, leading to deformed trajectory\ndistributions that are consistent with the nominal plan and the changes\nintroduced by the human.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 10:28:51 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Rozo", "Leonel", ""]]}, {"id": "1908.07307", "submitter": "Gang Hu", "authors": "Gang Hu, Lingbo Liu, Dacheng Tao, Jie Song, and K.C.S. Kwok", "title": "Investigation of wind pressures on tall building under interference\n  effects using machine learning techniques", "comments": "15 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interference effects of tall buildings have attracted numerous studies due to\nthe boom of clusters of tall buildings in megacities. To fully understand the\ninterference effects of buildings, it often requires a substantial amount of\nwind tunnel tests. Limited wind tunnel tests that only cover part of\ninterference scenarios are unable to fully reveal the interference effects.\nThis study used machine learning techniques to resolve the conflicting\nrequirement between limited wind tunnel tests that produce unreliable results\nand a completed investigation of the interference effects that is costly and\ntime-consuming. Four machine learning models including decision tree, random\nforest, XGBoost, generative adversarial networks (GANs), were trained based on\n30% of a dataset to predict both mean and fluctuating pressure coefficients on\nthe principal building. The GANs model exhibited the best performance in\npredicting these pressure coefficients. A number of GANs models were then\ntrained based on different portions of the dataset ranging from 10% to 90%. It\nwas found that the GANs model based on 30% of the dataset is capable of\npredicting both mean and fluctuating pressure coefficients under unseen\ninterference conditions accurately. By using this GANs model, 70% of the wind\ntunnel test cases can be saved, largely alleviating the cost of this kind of\nwind tunnel testing study.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 12:46:27 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Hu", "Gang", ""], ["Liu", "Lingbo", ""], ["Tao", "Dacheng", ""], ["Song", "Jie", ""], ["Kwok", "K. C. S.", ""]]}, {"id": "1908.07319", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Accurate and interpretable evaluation of surgical skills from kinematic\n  data using fully convolutional neural networks", "comments": "Accepted at IJCARS Special Issue for MICCAI 2018", "journal-ref": null, "doi": "10.1007/s11548-019-02039-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Manual feedback from senior surgeons observing less experienced\ntrainees is a laborious task that is very expensive, time-consuming and prone\nto subjectivity. With the number of surgical procedures increasing annually,\nthere is an unprecedented need to provide an accurate, objective and automatic\nevaluation of trainees' surgical skills in order to improve surgical practice.\nMethods: In this paper, we designed a convolutional neural network (CNN) to\nclassify surgical skills by extracting latent patterns in the trainees' motions\nperformed during robotic surgery. The method is validated on the JIGSAWS\ndataset for two surgical skills evaluation tasks: classification and\nregression. Results: Our results show that deep neural networks constitute\nrobust machine learning models that are able to reach new competitive\nstate-of-the-art performance on the JIGSAWS dataset. While we leveraged from\nCNNs' efficiency, we were able to minimize its black-box effect using the class\nactivation map technique. Conclusions: This characteristic allowed our method\nto automatically pinpoint which parts of the surgery influenced the skill\nevaluation the most, thus allowing us to explain a surgical skill\nclassification and provide surgeons with a novel personalized feedback\ntechnique. We believe this type of interpretable machine learning model could\nintegrate within \"Operation Room 2.0\" and support novice surgeons in improving\ntheir skills to eventually become experts.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 13:04:05 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1908.07329", "submitter": "Daniel Canedo", "authors": "Daniel Rosa Can\\^edo and Alexandre Ricardo Soares Romariz", "title": "Data Analysis of Wireless Networks Using Classification Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last decade, there has been a great technological advance in the\ninfrastructure of mobile technologies. The increase in the use of wireless\nlocal area networks and the use of satellite services are also noticed. The\nhigh utilization rate of mobile devices for various purposes makes clear the\nneed to track wireless networks to ensure the integrity and confidentiality of\nthe information transmitted. Therefore, it is necessary to quickly and\nefficiently identify the normal and abnormal traffic of such networks, so that\nadministrators can take action. This work aims to analyze classification\ntechniques in relation to data from Wireless Networks, using some classes of\nanomalies pre-established according to some defined criteria of the MAC layer.\nFor data analysis, WEKA Data Mining software (Waikato Environment for Knowledge\nAnalysis) is used. The classification algorithms present a success rate in the\nclassification of viable data, being indicated in the use of intrusion\ndetection systems for wireless networks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:16:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Can\u00eado", "Daniel Rosa", ""], ["Romariz", "Alexandre Ricardo Soares", ""]]}, {"id": "1908.07344", "submitter": "Chen Chen", "authors": "Chen Chen, Cheng Ouyang, Giacomo Tarroni, Jo Schlemper, Huaqi Qiu,\n  Wenjia Bai, Daniel Rueckert", "title": "Unsupervised Multi-modal Style Transfer for Cardiac MR Segmentation", "comments": "STACOM 2019 camera-ready. Winner of Multi-sequence Cardiac MR\n  Segmentation Challenge (MS-CMRSeg 2019) https://zmiclab.github.io/mscmrseg19/", "journal-ref": null, "doi": "10.1007/978-3-030-39074-7_22", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we present a fully automatic method to segment cardiac\nstructures from late-gadolinium enhanced (LGE) images without using labelled\nLGE data for training, but instead by transferring the anatomical knowledge and\nfeatures learned on annotated balanced steady-state free precession (bSSFP)\nimages, which are easier to acquire. Our framework mainly consists of two\nneural networks: a multi-modal image translation network for style transfer and\na cascaded segmentation network for image segmentation. The multi-modal image\ntranslation network generates realistic and diverse synthetic LGE images\nconditioned on a single annotated bSSFP image, forming a synthetic LGE training\nset. This set is then utilized to fine-tune the segmentation network\npre-trained on labelled bSSFP images, achieving the goal of unsupervised LGE\nimage segmentation. In particular, the proposed cascaded segmentation network\nis able to produce accurate segmentation by taking both shape prior and image\nappearance into account, achieving an average Dice score of 0.92 for the left\nventricle, 0.83 for the myocardium, and 0.88 for the right ventricle on the\ntest set.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 13:47:42 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 07:37:25 GMT"}, {"version": "v3", "created": "Sat, 9 Nov 2019 15:32:08 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Chen", "Chen", ""], ["Ouyang", "Cheng", ""], ["Tarroni", "Giacomo", ""], ["Schlemper", "Jo", ""], ["Qiu", "Huaqi", ""], ["Bai", "Wenjia", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1908.07355", "submitter": "Mauricio Orbes Arteaga", "authors": "Mauricio Orbes-Arteaga and Jorge Cardoso and Lauge S{\\o}rensen and\n  Christian Igel and Sebastien Ourselin and Marc Modat and Mads Nielsen and\n  Akshay Pai", "title": "Knowledge distillation for semi-supervised domain adaptation", "comments": "MLCN MICCAI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the absence of sufficient data variation (e.g., scanner and protocol\nvariability) in annotated data, deep neural networks (DNNs) tend to overfit\nduring training. As a result, their performance is significantly lower on data\nfrom unseen sources compared to the performance on data from the same source as\nthe training data. Semi-supervised domain adaptation methods can alleviate this\nproblem by tuning networks to new target domains without the need for annotated\ndata from these domains. Adversarial domain adaptation (ADA) methods are a\npopular choice that aim to train networks in such a way that the features\ngenerated are domain agnostic. However, these methods require careful\ndataset-specific selection of hyperparameters such as the complexity of the\ndiscriminator in order to achieve a reasonable performance. We propose to use\nknowledge distillation (KD) -- an efficient way of transferring knowledge\nbetween different DNNs -- for semi-supervised domain adaption of DNNs. It does\nnot require dataset-specific hyperparameter tuning, making it generally\napplicable. The proposed method is compared to ADA for segmentation of white\nmatter hyperintensities (WMH) in magnetic resonance imaging (MRI) scans\ngenerated by scanners that are not a part of the training set. Compared with\nboth the baseline DNN (trained on source domain only and without any adaption\nto target domain) and with using ADA for semi-supervised domain adaptation, the\nproposed method achieves significantly higher WMH dice scores.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 11:39:49 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Orbes-Arteaga", "Mauricio", ""], ["Cardoso", "Jorge", ""], ["S\u00f8rensen", "Lauge", ""], ["Igel", "Christian", ""], ["Ourselin", "Sebastien", ""], ["Modat", "Marc", ""], ["Nielsen", "Mads", ""], ["Pai", "Akshay", ""]]}, {"id": "1908.07370", "submitter": "Tahsina Farah Sanam", "authors": "Tahsina Farah Sanam, Hana Godrich", "title": "A Multi-View Discriminant Learning Approach for Indoor Localization\n  Using Bimodal Features of CSI", "comments": "12 pages,12 figures, Journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of location-based services, indoor localization is attracting\ngreat interests as it facilitates further ubiquitous environments.\nSpecifically, device free localization using wireless signals is getting\nincreased attention as human location is estimated using its impact on the\nsurrounding wireless signals without any active device tagged with subject. In\nthis paper, we propose MuDLoc, the first multi-view discriminant learning\napproach for device free indoor localization using both amplitude and phase\nfeatures of Channel State Information (CSI) from multiple APs. Multi-view\nlearning is an emerging technique in machine learning which improve performance\nby utilizing diversity from different view data. In MuDLoc, the localization is\nmodeled as a pattern matching problem, where the target location is predicted\nbased on similarity measure of CSI features of an unknown location with those\nof the training locations. MuDLoc implements Generalized Inter-view and\nIntra-view Discriminant Correlation Analysis (GI$^{2}$DCA), a discriminative\nfeature extraction approach using multi-view CSIs. It incorporates inter-view\nand intra-view class associations while maximizing pairwise correlations across\nmulti-view data sets. A similarity measure is performed to find the best match\nto localize a subject. Experimental results from two cluttered environments\nshow that MuDLoc can estimate location with high accuracy which outperforms\nother benchmark approaches.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 18:49:25 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Sanam", "Tahsina Farah", ""], ["Godrich", "Hana", ""]]}, {"id": "1908.07371", "submitter": "Zitao Liu", "authors": "Zitao Liu, Zhexuan Xu, Yan Yan", "title": "Hierarchical Bayesian Personalized Recommendation: A Case Study and\n  Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Items in modern recommender systems are often organized in hierarchical\nstructures. These hierarchical structures and the data within them provide\nvaluable information for building personalized recommendation systems. In this\npaper, we propose a general hierarchical Bayesian learning framework, i.e.,\n\\emph{HBayes}, to learn both the structures and associated latent factors.\nFurthermore, we develop a variational inference algorithm that is able to learn\nmodel parameters with fast empirical convergence rate. The proposed HBayes is\nevaluated on two real-world datasets from different domains. The results\ndemonstrate the benefits of our approach on item recommendation tasks, and show\nthat it can outperform the state-of-the-art models in terms of precision,\nrecall, and normalized discounted cumulative gain. To encourage the\nreproducible results, we make our code public on a git repo:\n\\url{https://tinyurl.com/ycruhk4t}.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 14:10:17 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Liu", "Zitao", ""], ["Xu", "Zhexuan", ""], ["Yan", "Yan", ""]]}, {"id": "1908.07377", "submitter": "David Eklund", "authors": "David Eklund, S{\\o}ren Hauberg", "title": "Expected path length on random manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning seeks a low dimensional representation that faithfully\ncaptures the essence of data. Current methods can successfully learn such\nrepresentations, but do not provide a meaningful set of operations that are\nassociated with the representation. Working towards operational representation\nlearning, we endow the latent space of a large class of generative models with\na random Riemannian metric, which provides us with elementary operators. As\ncomputational tools are unavailable for random Riemannian manifolds, we study\ndeterministic approximations and derive tight error bounds on expected\ndistances.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 14:14:43 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Eklund", "David", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "1908.07380", "submitter": "Omar Rivasplata", "authors": "Omar Rivasplata, Vikram M Tankasali, Csaba Szepesvari", "title": "PAC-Bayes with Backprop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the family of methods \"PAC-Bayes with Backprop\" (PBB) to train\nprobabilistic neural networks by minimizing PAC-Bayes bounds. We present two\ntraining objectives, one derived from a previously known PAC-Bayes bound, and a\nsecond one derived from a novel PAC-Bayes bound. Both training objectives are\nevaluated on MNIST and on various UCI data sets. Our experiments show two\nstriking observations: we obtain competitive test set error estimates (~1.4% on\nMNIST) and at the same time we compute non-vacuous bounds with much tighter\nvalues (~2.3% on MNIST) than previous results. These observations suggest that\nneural nets trained by PBB may lead to self-bounding learning, where the\navailable data can be used to simultaneously learn a predictor and certify its\nrisk, with no need to follow a data-splitting protocol.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 13:27:08 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 10:18:05 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 08:16:40 GMT"}, {"version": "v4", "created": "Mon, 30 Sep 2019 12:32:30 GMT"}, {"version": "v5", "created": "Fri, 4 Oct 2019 17:23:16 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Rivasplata", "Omar", ""], ["Tankasali", "Vikram M", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1908.07387", "submitter": "Youngdong Kim", "authors": "Youngdong Kim, Junho Yim, Juseung Yun, Junmo Kim", "title": "NLNL: Negative Learning for Noisy Labels", "comments": "ICCV 2019, Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) provide excellent performance when used\nfor image classification. The classical method of training CNNs is by labeling\nimages in a supervised manner as in \"input image belongs to this label\"\n(Positive Learning; PL), which is a fast and accurate method if the labels are\nassigned correctly to all images. However, if inaccurate labels, or noisy\nlabels, exist, training with PL will provide wrong information, thus severely\ndegrading performance. To address this issue, we start with an indirect\nlearning method called Negative Learning (NL), in which the CNNs are trained\nusing a complementary label as in \"input image does not belong to this\ncomplementary label.\" Because the chances of selecting a true label as a\ncomplementary label are low, NL decreases the risk of providing incorrect\ninformation. Furthermore, to improve convergence, we extend our method by\nadopting PL selectively, termed as Selective Negative Learning and Positive\nLearning (SelNLPL). PL is used selectively to train upon expected-to-be-clean\ndata, whose choices become possible as NL progresses, thus resulting in\nsuperior performance of filtering out noisy data. With simple semi-supervised\ntraining technique, our method achieves state-of-the-art accuracy for noisy\ndata classification, proving the superiority of SelNLPL's noisy data filtering\nability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 06:22:37 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Kim", "Youngdong", ""], ["Yim", "Junho", ""], ["Yun", "Juseung", ""], ["Kim", "Junmo", ""]]}, {"id": "1908.07388", "submitter": "Guoxian Yu", "authors": "Xuanwu Liu, Zhao Li, Jun Wang, Guoxian Yu, Carlotta Domeniconi,\n  Xiangliang Zhang", "title": "Cross-modal Zero-shot Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hashing has been widely studied for big data retrieval due to its low storage\ncost and fast query speed. Zero-shot hashing (ZSH) aims to learn a hashing\nmodel that is trained using only samples from seen categories, but can\ngeneralize well to samples of unseen categories. ZSH generally uses category\nattributes to seek a semantic embedding space to transfer knowledge from seen\ncategories to unseen ones. As a result, it may perform poorly when labeled data\nare insufficient. ZSH methods are mainly designed for single-modality data,\nwhich prevents their application to the widely spread multi-modal data. On the\nother hand, existing cross-modal hashing solutions assume that all the\nmodalities share the same category labels, while in practice the labels of\ndifferent data modalities may be different. To address these issues, we propose\na general Cross-modal Zero-shot Hashing (CZHash) solution to effectively\nleverage unlabeled and labeled multi-modality data with different label spaces.\nCZHash first quantifies the composite similarity between instances using label\nand feature information. It then defines an objective function to achieve deep\nfeature learning compatible with the composite similarity preserving, category\nattribute space learning, and hashing coding function learning. CZHash further\nintroduces an alternative optimization procedure to jointly optimize these\nlearning objectives. Experiments on benchmark multi-modal datasets show that\nCZHash significantly outperforms related representative hashing approaches both\non effectiveness and adaptability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 07:14:41 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Liu", "Xuanwu", ""], ["Li", "Zhao", ""], ["Wang", "Jun", ""], ["Yu", "Guoxian", ""], ["Domeniconi", "Carlotta", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1908.07414", "submitter": "Rishabh Misra", "authors": "Rishabh Misra, Prahal Arora", "title": "Sarcasm Detection using Hybrid Neural Network", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.32427.39204", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Sarcasm Detection has enjoyed great interest from the research community,\nhowever the task of predicting sarcasm in a text remains an elusive problem for\nmachines. Past studies mostly make use of twitter datasets collected using\nhashtag based supervision but such datasets are noisy in terms of labels and\nlanguage. To overcome these shortcoming, we introduce a new dataset which\ncontains news headlines from a sarcastic news website and a real news website.\nNext, we propose a hybrid Neural Network architecture with attention mechanism\nwhich provides insights about what actually makes sentences sarcastic. Through\nexperiments, we show that the proposed model improves upon the baseline by ~ 5%\nin terms of classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:10:31 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Misra", "Rishabh", ""], ["Arora", "Prahal", ""]]}, {"id": "1908.07420", "submitter": "Antonio Ferrara", "authors": "Vito Walter Anelli, Yashar Deldjoo, Tommaso Di Noia, Antonio Ferrara", "title": "Towards Effective Device-Aware Federated Learning", "comments": "12 pages, AIIA 2019, 18th International Conference of the Italian\n  Association for Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wealth of information produced by social networks, smartphones,\nmedical or financial applications, speculations have been raised about the\nsensitivity of such data in terms of users' personal privacy and data security.\nTo address the above issues, Federated Learning (FL) has been recently proposed\nas a means to leave data and computational resources distributed over a large\nnumber of nodes (clients) where a central coordinating server aggregates only\nlocally computed updates without knowing the original data. In this work, we\nextend the FL framework by pushing forward the state the art in the field on\nseveral dimensions: (i) unlike the original FedAvg approach relying solely on\nsingle criteria (i.e., local dataset size), a suite of domain- and\nclient-specific criteria constitute the basis to compute each local client's\ncontribution, (ii) the multi-criteria contribution of each device is computed\nin a prioritized fashion by leveraging a priority-aware aggregation operator\nused in the field of information retrieval, and (iii) a mechanism is proposed\nfor online-adjustment of the aggregation operator parameters via a local search\nstrategy with backtracking. Extensive experiments on a publicly available\ndataset indicate the merits of the proposed approach compared to standard\nFedAvg baseline.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:12:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Deldjoo", "Yashar", ""], ["Di Noia", "Tommaso", ""], ["Ferrara", "Antonio", ""]]}, {"id": "1908.07428", "submitter": "Gautam Kumar", "authors": "Benjamin Plaster and Gautam Kumar", "title": "Data-Driven Predictive Modeling of Neuronal Dynamics using Long\n  Short-Term Memory", "comments": "35 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling brain dynamics to better understand and control complex behaviors\nunderlying various cognitive brain functions are of interests to engineers,\nmathematicians, and physicists from the last several decades. With a motivation\nof developing computationally efficient models of brain dynamics to use in\ndesigning control-theoretic neurostimulation strategies, we have developed a\nnovel data-driven approach in a long short-term memory (LSTM) neural network\narchitecture to predict the temporal dynamics of complex systems over an\nextended long time-horizon in future. In contrast to recent LSTM-based\ndynamical modeling approaches that make use of multi-layer perceptrons or\nlinear combination layers as output layers, our architecture uses a single\nfully connected output layer and reversed-order sequence-to-sequence mapping to\nimprove short time-horizon prediction accuracy and to make multi-timestep\npredictions of dynamical behaviors. We demonstrate the efficacy of our approach\nin reconstructing the regular spiking to bursting dynamics exhibited by an\nexperimentally-validated 9-dimensional Hodgkin-Huxley model of hippocampal CA1\npyramidal neurons. Through simulations, we show that our LSTM neural network\ncan predict the multi-time scale temporal dynamics underlying various spiking\npatterns with reasonable accuracy. Moreover, our results show that the\npredictions improve with increasing predictive time-horizon in the\nmulti-timestep deep LSTM neural network.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 17:36:46 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Plaster", "Benjamin", ""], ["Kumar", "Gautam", ""]]}, {"id": "1908.07442", "submitter": "Sercan Arik", "authors": "Sercan O. Arik and Tomas Pfister", "title": "TabNet: Attentive Interpretable Tabular Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel high-performance and interpretable canonical deep tabular\ndata learning architecture, TabNet. TabNet uses sequential attention to choose\nwhich features to reason from at each decision step, enabling interpretability\nand more efficient learning as the learning capacity is used for the most\nsalient features. We demonstrate that TabNet outperforms other neural network\nand decision tree variants on a wide range of non-performance-saturated tabular\ndatasets and yields interpretable feature attributions plus insights into the\nglobal model behavior. Finally, for the first time to our knowledge, we\ndemonstrate self-supervised learning for tabular data, significantly improving\nperformance with unsupervised representation learning when unlabeled data is\nabundant.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:46:53 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 20:37:43 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 00:59:17 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 18:37:55 GMT"}, {"version": "v5", "created": "Wed, 9 Dec 2020 05:00:33 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Arik", "Sercan O.", ""], ["Pfister", "Tomas", ""]]}, {"id": "1908.07463", "submitter": "Kobi Cohen", "authors": "Tomer Sery and Kobi Cohen", "title": "On Analog Gradient Descent Learning over Multiple Access Fading Channels", "comments": "32 pages, 6 figures", "journal-ref": null, "doi": "10.1109/TSP.2020.2989580", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed learning problem over multiple access channel (MAC)\nusing a large wireless network. The computation is made by the network edge and\nis based on received data from a large number of distributed nodes which\ntransmit over a noisy fading MAC. The objective function is a sum of the nodes'\nlocal loss functions. This problem has attracted a growing interest in\ndistributed sensing systems, and more recently in federated learning. We\ndevelop a novel Gradient-Based Multiple Access (GBMA) algorithm to solve the\ndistributed learning problem over MAC. Specifically, the nodes transmit an\nanalog function of the local gradient using common shaping waveforms and the\nnetwork edge receives a superposition of the analog transmitted signals used\nfor updating the estimate. GBMA does not require power control or beamforming\nto cancel the fading effect as in other algorithms, and operates directly with\nnoisy distorted gradients. We analyze the performance of GBMA theoretically,\nand prove that it can approach the convergence rate of the centralized gradient\ndescent (GD) algorithm in large networks. Specifically, we establish a\nfinite-sample bound of the error for both convex and strongly convex loss\nfunctions with Lipschitz gradient. Furthermore, we provide energy scaling laws\nfor approaching the centralized convergence rate as the number of nodes\nincreases. Finally, experimental results support the theoretical findings, and\ndemonstrate strong performance of GBMA using synthetic and real data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 16:03:23 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Sery", "Tomer", ""], ["Cohen", "Kobi", ""]]}, {"id": "1908.07465", "submitter": "Sean Yang", "authors": "Sean Yang, Po-shen Lee, Jevin D. West, Bill Howe", "title": "Delineating Knowledge Domains in the Scientific Literature Using Visual\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Figures are an important channel for scientific communication, used to\nexpress complex ideas, models and data in ways that words cannot. However, this\nvisual information is mostly ignored in analyses of the scientific literature.\nIn this paper, we demonstrate the utility of using scientific figures as\nmarkers of knowledge domains in science, which can be used for classification,\nrecommender systems, and studies of scientific information exchange. We encode\nsets of images into a visual signature, then use distances between these\nsignatures to understand how patterns of visual communication compare with\npatterns of jargon and citation structures. We find that figures can be as\neffective for differentiating communities of practice as text or citation\npatterns. We then consider where these metrics disagree to understand how\ndifferent disciplines use visualization to express ideas. Finally, we further\nconsider how specific figure types propagate through the literature, suggesting\na new mechanism for understanding the flow of ideas apart from conventional\nchannels of text and citations. Our ultimate aim is to better leverage these\ninformation-dense objects to improve scientific communication across\ndisciplinary boundaries.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 17:21:48 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Yang", "Sean", ""], ["Lee", "Po-shen", ""], ["West", "Jevin D.", ""], ["Howe", "Bill", ""]]}, {"id": "1908.07483", "submitter": "Cheng Wan", "authors": "Cheng Wan, Andrew W. McHill, Elizabeth Klerman, Akane Sano", "title": "Sensor-Based Estimation of Dim Light Melatonin Onset (DLMO) Using\n  Features of Two Time Scales", "comments": "16 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Circadian rhythms influence multiple essential biological activities\nincluding sleep, performance, and mood. The dim light melatonin onset (DLMO) is\nthe gold standard for measuring human circadian phase (i.e., timing). The\ncollection of DLMO is expensive and time-consuming since multiple saliva or\nblood samples are required overnight in special conditions, and the samples\nmust then be assayed for melatonin. Recently, several computational approaches\nhave been designed for estimating DLMO. These methods collect daily sampled\ndata (e.g., sleep onset/offset times) or frequently sampled data (e.g., light\nexposure/skin temperature/physical activity collected every minute) to train\nlearning models for estimating DLMO. One limitation of these studies is that\nthey only leverage one time-scale data. We propose a two-step framework for\nestimating DLMO using data from both time scales. The first step summarizes\ndata from before the current day, while the second step combines this summary\nwith frequently sampled data of the current day. We evaluate three moving\naverage models that input sleep timing data as the first step and use recurrent\nneural network models as the second step. The results using data from 207\nundergraduates show that our two-step model with two time-scale features has\nstatistically significantly lower root-mean-square errors than models that use\neither daily sampled data or frequently sampled data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 16:39:59 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 22:12:07 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 02:25:11 GMT"}, {"version": "v4", "created": "Sun, 7 Feb 2021 03:09:24 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Wan", "Cheng", ""], ["McHill", "Andrew W.", ""], ["Klerman", "Elizabeth", ""], ["Sano", "Akane", ""]]}, {"id": "1908.07490", "submitter": "Hao Tan", "authors": "Hao Tan, Mohit Bansal", "title": "LXMERT: Learning Cross-Modality Encoder Representations from\n  Transformers", "comments": "EMNLP 2019 (14 pages; with new attention visualizations)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-and-language reasoning requires an understanding of visual concepts,\nlanguage semantics, and, most importantly, the alignment and relationships\nbetween these two modalities. We thus propose the LXMERT (Learning\nCross-Modality Encoder Representations from Transformers) framework to learn\nthese vision-and-language connections. In LXMERT, we build a large-scale\nTransformer model that consists of three encoders: an object relationship\nencoder, a language encoder, and a cross-modality encoder. Next, to endow our\nmodel with the capability of connecting vision and language semantics, we\npre-train the model with large amounts of image-and-sentence pairs, via five\ndiverse representative pre-training tasks: masked language modeling, masked\nobject prediction (feature regression and label classification), cross-modality\nmatching, and image question answering. These tasks help in learning both\nintra-modality and cross-modality relationships. After fine-tuning from our\npre-trained parameters, our model achieves the state-of-the-art results on two\nvisual question answering datasets (i.e., VQA and GQA). We also show the\ngeneralizability of our pre-trained cross-modality model by adapting it to a\nchallenging visual-reasoning task, NLVR2, and improve the previous best result\nby 22% absolute (54% to 76%). Lastly, we demonstrate detailed ablation studies\nto prove that both our novel model components and pre-training strategies\nsignificantly contribute to our strong results; and also present several\nattention visualizations for the different encoders. Code and pre-trained\nmodels publicly available at: https://github.com/airsplay/lxmert\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 17:05:18 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 17:54:29 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 19:30:19 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "1908.07498", "submitter": "Rishabh Misra", "authors": "Aditi A. Mavalankar, Ajitesh Gupta, Chetan Gandotra, Rishabh Misra", "title": "Hotel Recommendation System", "comments": "arXiv admin note: text overlap with arXiv:1703.02915 by other authors", "journal-ref": null, "doi": "10.13140/RG.2.2.27394.22728/1", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  One of the first things to do while planning a trip is to book a good place\nto stay. Booking a hotel online can be an overwhelming task with thousands of\nhotels to choose from, for every destination. Motivated by the importance of\nthese situations, we decided to work on the task of recommending hotels to\nusers. We used Expedia's hotel recommendation dataset, which has a variety of\nfeatures that helped us achieve a deep understanding of the process that makes\na user choose certain hotels over others. The aim of this hotel recommendation\ntask is to predict and recommend five hotel clusters to a user that he/she is\nmore likely to book given hundred distinct clusters.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 17:20:41 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 04:05:14 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Mavalankar", "Aditi A.", ""], ["Gupta", "Ajitesh", ""], ["Gandotra", "Chetan", ""], ["Misra", "Rishabh", ""]]}, {"id": "1908.07517", "submitter": "Zhongwei Cheng", "authors": "Yuan Liu, Zhongwei Cheng, Jie Liu, Bourhan Yassin, Zhe Nan, Jiebo Luo", "title": "AI for Earth: Rainforest Conservation by Acoustic Surveillance", "comments": "Accepted to KDD2019 Workshop on Data Mining and AI for Conservation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.DB cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saving rainforests is a key to halting adverse climate changes. In this\npaper, we introduce an innovative solution built on acoustic surveillance and\nmachine learning technologies to help rainforest conservation. In particular,\nWe propose new convolutional neural network (CNN) models for environmental\nsound classification and achieved promising preliminary results on two\ndatasets, including a public audio dataset and our real rainforest sound\ndataset. The proposed audio classification models can be easily extended in an\nautomated machine learning paradigm and integrated in cloud-based services for\nreal world deployment.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 03:50:57 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Liu", "Yuan", ""], ["Cheng", "Zhongwei", ""], ["Liu", "Jie", ""], ["Yassin", "Bourhan", ""], ["Nan", "Zhe", ""], ["Luo", "Jiebo", ""]]}, {"id": "1908.07519", "submitter": "Wenjin Tao", "authors": "Wenjin Tao, Ming C. Leu, Zhaozheng Yin", "title": "Multi-Modal Recognition of Worker Activity for Human-Centered\n  Intelligent Manufacturing", "comments": "17 pages, 8 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a human-centered intelligent manufacturing system, sensing and\nunderstanding of the worker's activity are the primary tasks. In this paper, we\npropose a novel multi-modal approach for worker activity recognition by\nleveraging information from different sensors and in different modalities.\nSpecifically, a smart armband and a visual camera are applied to capture\nInertial Measurement Unit (IMU) signals and videos, respectively. For the IMU\nsignals, we design two novel feature transform mechanisms, in both frequency\nand spatial domains, to assemble the captured IMU signals as images, which\nallow using convolutional neural networks to learn the most discriminative\nfeatures. Along with the above two modalities, we propose two other modalities\nfor the video data, at the video frame and video clip levels, respectively.\nEach of the four modalities returns a probability distribution on activity\nprediction. Then, these probability distributions are fused to output the\nworker activity classification result. A worker activity dataset of 6\nactivities is established, which at present contains 6 common activities in\nassembly tasks, i.e., grab a tool/part, hammer a nail, use a power-screwdriver,\nrest arms, turn a screwdriver, and use a wrench. The developed multi-modal\napproach is evaluated on this dataset and achieves recognition accuracies as\nhigh as 97% and 100% in the leave-one-out and half-half experiments,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:46:07 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Tao", "Wenjin", ""], ["Leu", "Ming C.", ""], ["Yin", "Zhaozheng", ""]]}, {"id": "1908.07553", "submitter": "Josiah Wang", "authors": "Josiah Wang, Lucia Specia", "title": "Phrase Localization Without Paired Training Examples", "comments": "Accepted for oral presentation at the IEEE/CVF International\n  Conference on Computer Vision (ICCV) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localizing phrases in images is an important part of image understanding and\ncan be useful in many applications that require mappings between textual and\nvisual information. Existing work attempts to learn these mappings from\nexamples of phrase-image region correspondences (strong supervision) or from\nphrase-image pairs (weak supervision). We postulate that such paired\nannotations are unnecessary, and propose the first method for the phrase\nlocalization problem where neither training procedure nor paired, task-specific\ndata is required. Our method is simple but effective: we use off-the-shelf\napproaches to detect objects, scenes and colours in images, and explore\ndifferent approaches to measure semantic similarity between the categories of\ndetected visual elements and words in phrases. Experiments on two well-known\nphrase localization datasets show that this approach surpasses all weakly\nsupervised methods by a large margin and performs very competitively to\nstrongly supervised methods, and can thus be considered a strong baseline to\nthe task. The non-paired nature of our method makes it applicable to any domain\nand where no paired phrase localization annotation is available.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 18:07:37 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Wang", "Josiah", ""], ["Specia", "Lucia", ""]]}, {"id": "1908.07558", "submitter": "Xianfeng Tang", "authors": "Xianfeng Tang, Yandong Li, Yiwei Sun, Huaxiu Yao, Prasenjit Mitra,\n  Suhang Wang", "title": "Transferring Robustness for Graph Neural Network Against Poisoning\n  Attacks", "comments": "Accepted by WSDM 2020. Code and data:\n  https://github.com/tangxianfeng/PA-GNN", "journal-ref": null, "doi": "10.1145/3336191.3371851", "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are widely used in many applications. However,\ntheir robustness against adversarial attacks is criticized. Prior studies show\nthat using unnoticeable modifications on graph topology or nodal features can\nsignificantly reduce the performances of GNNs. It is very challenging to design\nrobust graph neural networks against poisoning attack and several efforts have\nbeen taken. Existing work aims at reducing the negative impact from adversarial\nedges only with the poisoned graph, which is sub-optimal since they fail to\ndiscriminate adversarial edges from normal ones. On the other hand, clean\ngraphs from similar domains as the target poisoned graph are usually available\nin the real world. By perturbing these clean graphs, we create supervised\nknowledge to train the ability to detect adversarial edges so that the\nrobustness of GNNs is elevated. However, such potential for clean graphs is\nneglected by existing work. To this end, we investigate a novel problem of\nimproving the robustness of GNNs against poisoning attacks by exploring clean\ngraphs. Specifically, we propose PA-GNN, which relies on a penalized\naggregation mechanism that directly restrict the negative impact of adversarial\nedges by assigning them lower attention coefficients. To optimize PA-GNN for a\npoisoned graph, we design a meta-optimization algorithm that trains PA-GNN to\npenalize perturbations using clean graphs and their adversarial counterparts,\nand transfers such ability to improve the robustness of PA-GNN on the poisoned\ngraph. Experimental results on four real-world datasets demonstrate the\nrobustness of PA-GNN against poisoning attacks on graphs. Code and data are\navailable here: https://github.com/tangxianfeng/PA-GNN.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 18:24:32 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 20:33:08 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 17:00:28 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Tang", "Xianfeng", ""], ["Li", "Yandong", ""], ["Sun", "Yiwei", ""], ["Yao", "Huaxiu", ""], ["Mitra", "Prasenjit", ""], ["Wang", "Suhang", ""]]}, {"id": "1908.07585", "submitter": "Jun Yang", "authors": "Jun Yang and Shengyang Sun and Daniel M. Roy", "title": "Fast-rate PAC-Bayes Generalization Bounds via Shifted Rademacher\n  Processes", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The developments of Rademacher complexity and PAC-Bayesian theory have been\nlargely independent. One exception is the PAC-Bayes theorem of Kakade,\nSridharan, and Tewari (2008), which is established via Rademacher complexity\ntheory by viewing Gibbs classifiers as linear operators. The goal of this paper\nis to extend this bridge between Rademacher complexity and state-of-the-art\nPAC-Bayesian theory. We first demonstrate that one can match the fast rate of\nCatoni's PAC-Bayes bounds (Catoni, 2007) using shifted Rademacher processes\n(Wegkamp, 2003; Lecu\\'{e} and Mitchell, 2012; Zhivotovskiy and Hanneke, 2018).\nWe then derive a new fast-rate PAC-Bayes bound in terms of the \"flatness\" of\nthe empirical risk surface on which the posterior concentrates. Our analysis\nestablishes a new framework for deriving fast-rate PAC-Bayes bounds and yields\nnew insights on PAC-Bayesian theory.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 19:46:14 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 16:12:50 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Yang", "Jun", ""], ["Sun", "Shengyang", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1908.07587", "submitter": "Songwei Ge", "authors": "Songwei Ge, Austin Dill, Eunsu Kang, Chun-Liang Li, Lingyao Zhang,\n  Manzil Zaheer, Barnabas Poczos", "title": "Developing Creative AI to Generate Sculptural Objects", "comments": "In the Proceedings of International Symposium on Electronic Art (ISEA\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the intersection of human and machine creativity by generating\nsculptural objects through machine learning. This research raises questions\nabout both the technical details of automatic art generation and the\ninteraction between AI and people, as both artists and the audience of art. We\nintroduce two algorithms for generating 3D point clouds and then discuss their\nactualization as sculpture and incorporation into a holistic art installation.\nSpecifically, the Amalgamated DeepDream (ADD) algorithm solves the sparsity\nproblem caused by the naive DeepDream-inspired approach and generates creative\nand printable point clouds. The Partitioned DeepDream (PDD) algorithm further\nallows us to explore more diverse 3D object creation by combining point cloud\nclustering algorithms and ADD.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:00:25 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Ge", "Songwei", ""], ["Dill", "Austin", ""], ["Kang", "Eunsu", ""], ["Li", "Chun-Liang", ""], ["Zhang", "Lingyao", ""], ["Zaheer", "Manzil", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1908.07599", "submitter": "Santosh Kesiraju", "authors": "Santosh Kesiraju, Old\\v{r}ich Plchot, Luk\\'a\\v{s} Burget, and\n  Suryakanth V Gangashetty", "title": "Learning document embeddings along with their uncertainties", "comments": null, "journal-ref": null, "doi": "10.1109/TASLP.2020.3012062", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Majority of the text modelling techniques yield only point-estimates of\ndocument embeddings and lack in capturing the uncertainty of the estimates.\nThese uncertainties give a notion of how well the embeddings represent a\ndocument. We present Bayesian subspace multinomial model (Bayesian SMM), a\ngenerative log-linear model that learns to represent documents in the form of\nGaussian distributions, thereby encoding the uncertainty in its co-variance.\nAdditionally, in the proposed Bayesian SMM, we address a commonly encountered\nproblem of intractability that appears during variational inference in\nmixed-logit models. We also present a generative Gaussian linear classifier for\ntopic identification that exploits the uncertainty in document embeddings. Our\nintrinsic evaluation using perplexity measure shows that the proposed Bayesian\nSMM fits the data better as compared to the state-of-the-art neural variational\ndocument model on Fisher speech and 20Newsgroups text corpora. Our topic\nidentification experiments show that the proposed systems are robust to\nover-fitting on unseen test data. The topic ID results show that the proposed\nmodel is outperforms state-of-the-art unsupervised topic models and achieve\ncomparable results to the state-of-the-art fully supervised discriminative\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:31:51 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 12:09:18 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 09:31:42 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Kesiraju", "Santosh", ""], ["Plchot", "Old\u0159ich", ""], ["Burget", "Luk\u00e1\u0161", ""], ["Gangashetty", "Suryakanth V", ""]]}, {"id": "1908.07607", "submitter": "Tomer Lancewicki Ph.D.", "authors": "Tomer Lancewicki, Selcuk Kopru", "title": "Automatic and Simultaneous Adjustment of Learning Rate and Momentum for\n  Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) methods are prominent for training machine\nlearning and deep learning models. The performance of these techniques depends\non their hyperparameter tuning over time and varies for different models and\nproblems. Manual adjustment of hyperparameters is very costly and\ntime-consuming, and even if done correctly, it lacks theoretical justification\nwhich inevitably leads to \"rule of thumb\" settings. In this paper, we propose a\ngeneric approach that utilizes the statistics of an unbiased gradient estimator\nto automatically and simultaneously adjust two paramount hyperparameters: the\nlearning rate and momentum. We deploy the proposed general technique for\nvarious SGD methods to train Convolutional Neural Networks (CNN's). The results\nmatch the performance of the best settings obtained through an exhaustive\nsearch and therefore, removes the need for a tedious manual tuning.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:56:41 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Lancewicki", "Tomer", ""], ["Kopru", "Selcuk", ""]]}, {"id": "1908.07617", "submitter": "Mauricio Gonzalez-Soto", "authors": "Mauricio Gonzalez-Soto and Felipe Orihuela Espina", "title": "Reinforcement Learning is not a Causal problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use an analogy between non-isomorphic mathematical structures defined over\nthe same set and the algebras induced by associative and causal levels of\ninformation in order to argue that Reinforcement Learning, in its current\nformulation, is not a causal problem, independently if the motivation behind it\nhas to do with an agent taking actions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 21:30:13 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 12:16:45 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gonzalez-Soto", "Mauricio", ""], ["Espina", "Felipe Orihuela", ""]]}, {"id": "1908.07619", "submitter": "Diaa Badawi", "authors": "Diaa Badawi, Tuba Ayhan, Sule Ozev, Chengmo Yang, Alex Orailoglu, A.\n  Enis \\c{C}etin", "title": "Detecting Gas Vapor Leaks Using Uncalibrated Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Chemical and infra-red sensors generate distinct responses under similar\nconditions because of sensor drift, noise or resolution errors. In this work,\nwe use different time-series data sets obtained by infra-red and E-nose sensors\nin order to detect Volatile Organic Compounds (VOCs) and Ammonia vapor leaks.\nWe process time-series sensor signals using deep neural networks (DNN). Three\nneural network algorithms are utilized for this purpose. Additive neural\nnetworks (termed AddNet) are based on a multiplication-devoid operator and\nconsequently exhibit energy-efficiency compared to regular neural networks. The\nsecond algorithm uses generative adversarial neural networks so as to expose\nthe classifying neural network to more realistic data points in order to help\nthe classifier network to deliver improved generalization. Finally, we use\nconventional convolutional neural networks as a baseline method and compare\ntheir performance with the two aforementioned deep neural network algorithms in\norder to evaluate their effectiveness empirically.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 21:38:48 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Badawi", "Diaa", ""], ["Ayhan", "Tuba", ""], ["Ozev", "Sule", ""], ["Yang", "Chengmo", ""], ["Orailoglu", "Alex", ""], ["\u00c7etin", "A. Enis", ""]]}, {"id": "1908.07630", "submitter": "Parijat Dube", "authors": "Bishwaranjan Bhattacharjee, John R. Kender, Matthew Hill, Parijat\n  Dube, Siyu Huo, Michael R. Glass, Brian Belgodere, Sharath Pankanti, Noel\n  Codella, Patrick Watson", "title": "P2L: Predicting Transfer Learning for Images and Semantic Relations", "comments": "10 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning enhances learning across tasks, by leveraging previously\nlearned representations -- if they are properly chosen. We describe an\nefficient method to accurately estimate the appropriateness of a previously\ntrained model for use in a new learning task. We use this measure, which we\ncall \"Predict To Learn\" (\"P2L\"), in the two very different domains of images\nand semantic relations, where it predicts, from a set of \"source\" models, the\none model most likely to produce effective transfer for training a given\n\"target\" model. We validate our approach thoroughly, by assembling a collection\nof candidate source models, then fine-tuning each candidate to perform each of\na collection of target tasks, and finally measuring how well transfer has been\nenhanced. Across 95 tasks within multiple domains (images classification and\nsemantic relations), the P2L approach was able to select the best transfer\nlearning model on average, while the heuristic of choosing model trained with\nthe largest data set selected the best model in only 55 cases. These results\nsuggest that P2L captures important information in common between source and\ntarget tasks, and that this shared informational structure contributes to\nsuccessful transfer learning more than simple data size.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 22:09:40 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 20:08:59 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Bhattacharjee", "Bishwaranjan", ""], ["Kender", "John R.", ""], ["Hill", "Matthew", ""], ["Dube", "Parijat", ""], ["Huo", "Siyu", ""], ["Glass", "Michael R.", ""], ["Belgodere", "Brian", ""], ["Pankanti", "Sharath", ""], ["Codella", "Noel", ""], ["Watson", "Patrick", ""]]}, {"id": "1908.07636", "submitter": "Valeriy Avanesov", "authors": "Valeriy Avanesov", "title": "How to gamble with non-stationary $\\mathcal{X}$-armed bandits and have\n  no regrets", "comments": "The algorithm is optimized, the theoretical result is more detailed\n  now", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In $\\mathcal{X}$-armed bandit problem an agent sequentially interacts with\nenvironment which yields a reward based on the vector input the agent provides.\nThe agent's goal is to maximise the sum of these rewards across some number of\ntime steps. The problem and its variations have been a subject of numerous\nstudies, suggesting sub-linear and some times optimal strategies. The given\npaper introduces a novel variation of the problem. We consider an environment,\nwhich can abruptly change its behaviour an unknown number of times. To that end\nwe propose a novel strategy and prove it attains sub-linear cumulative regret.\nMoreover, in case of highly smooth relation between an action and the\ncorresponding reward, the method is nearly optimal. The theoretical result are\nsupported by experimental study.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 22:33:02 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 08:52:27 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 13:04:07 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Avanesov", "Valeriy", ""]]}, {"id": "1908.07643", "submitter": "Venkatadheeraj Pichapati", "authors": "Venkatadheeraj Pichapati and Ananda Theertha Suresh and Felix X. Yu\n  and Sashank J. Reddi and Sanjiv Kumar", "title": "AdaCliP: Adaptive Clipping for Private SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy preserving machine learning algorithms are crucial for learning\nmodels over user data to protect sensitive information. Motivated by this,\ndifferentially private stochastic gradient descent (SGD) algorithms for\ntraining machine learning models have been proposed. At each step, these\nalgorithms modify the gradients and add noise proportional to the sensitivity\nof the modified gradients. Under this framework, we propose AdaCliP, a\ntheoretically motivated differentially private SGD algorithm that provably adds\nless noise compared to the previous methods, by using coordinate-wise adaptive\nclipping of the gradient. We empirically demonstrate that AdaCliP reduces the\namount of added noise and produces models with better accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 23:19:21 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 19:02:00 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Pichapati", "Venkatadheeraj", ""], ["Suresh", "Ananda Theertha", ""], ["Yu", "Felix X.", ""], ["Reddi", "Sashank J.", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1908.07644", "submitter": "Gamaleldin Elsayed", "authors": "Gamaleldin F. Elsayed and Simon Kornblith and Quoc V. Le", "title": "Saccader: Improving Accuracy of Hard Attention Models for Vision", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep convolutional neural networks achieve state-of-the-art\nperformance across nearly all image classification tasks, their decisions are\ndifficult to interpret. One approach that offers some level of interpretability\nby design is \\textit{hard attention}, which uses only relevant portions of the\nimage. However, training hard attention models with only class label\nsupervision is challenging, and hard attention has proved difficult to scale to\ncomplex datasets. Here, we propose a novel hard attention model, which we term\nSaccader. Key to Saccader is a pretraining step that requires only class labels\nand provides initial attention locations for policy gradient optimization. Our\nbest models narrow the gap to common ImageNet baselines, achieving $75\\%$ top-1\nand $91\\%$ top-5 while attending to less than one-third of the image.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 23:40:21 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 22:45:26 GMT"}, {"version": "v3", "created": "Sat, 7 Dec 2019 00:34:57 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Elsayed", "Gamaleldin F.", ""], ["Kornblith", "Simon", ""], ["Le", "Quoc V.", ""]]}, {"id": "1908.07653", "submitter": "Hazrat Ali", "authors": "Kashif Sultan, Hazrat Ali, Haris Anwaar, Kabo Poloko Nkabiti, Adeel\n  Ahamd, Zhongshan Zhang", "title": "Understanding and Partitioning Mobile Traffic using Internet Activity\n  Records Data -- A Spatiotemporal Approach", "comments": "2019 28th Wireless and Optical Communications Conference (WOCC)", "journal-ref": null, "doi": "10.1109/WOCC.2019.8770653", "report-no": null, "categories": "cs.NI cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The internet activity records (IARs) of a mobile cellular network posses\nsignificant information which can be exploited to identify the network's\nefficacy and the mobile users' behavior. In this work, we extract useful\ninformation from the IAR data and identify a healthy predictability of\nspatio-temporal pattern within the network traffic. The information extracted\nis helpful for network operators to plan effective network configuration and\nperform management and optimization of network's resources. We report\nexperimentation on spatiotemporal analysis of IAR data of the Telecom Italia.\nBased on this, we present mobile traffic partitioning scheme. Experimental\nresults of the proposed model is helpful in modelling and partitioning of\nnetwork traffic patterns.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 06:29:44 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Sultan", "Kashif", ""], ["Ali", "Hazrat", ""], ["Anwaar", "Haris", ""], ["Nkabiti", "Kabo Poloko", ""], ["Ahamd", "Adeel", ""], ["Zhang", "Zhongshan", ""]]}, {"id": "1908.07656", "submitter": "Alexander Glandon", "authors": "Mahbubul Alam, Manar D. Samad, Lasitha Vidyaratne, Alexander Glandon,\n  and Khan M. Iftekharuddin", "title": "Survey on Deep Neural Networks in Speech and Vision Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE cs.SD eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey presents a review of state-of-the-art deep neural network\narchitectures, algorithms, and systems in vision and speech applications.\nRecent advances in deep artificial neural network algorithms and architectures\nhave spurred rapid innovation and development of intelligent vision and speech\nsystems. With availability of vast amounts of sensor data and cloud computing\nfor processing and training of deep neural networks, and with increased\nsophistication in mobile and embedded technology, the next-generation\nintelligent systems are poised to revolutionize personal and commercial\ncomputing. This survey begins by providing background and evolution of some of\nthe most successful deep learning models for intelligent vision and speech\nsystems to date. An overview of large-scale industrial research and development\nefforts is provided to emphasize future trends and prospects of intelligent\nvision and speech systems. Robust and efficient intelligent systems demand\nlow-latency and high fidelity in resource-constrained hardware platforms such\nas mobile devices, robots, and automobiles. Therefore, this survey also\nprovides a summary of key challenges and recent successes in running deep\nneural networks on hardware-restricted platforms, i.e. within limited memory,\nbattery life, and processing capabilities. Finally, emerging applications of\nvision and speech across disciplines such as affective computing, intelligent\ntransportation, and precision medicine are discussed. To our knowledge, this\npaper provides one of the most comprehensive surveys on the latest developments\nin intelligent vision and speech applications from the perspectives of both\nsoftware and hardware systems. Many of these emerging technologies using deep\nneural networks show tremendous promise to revolutionize research and\ndevelopment for future vision and speech systems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 16:40:49 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 03:30:37 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Alam", "Mahbubul", ""], ["Samad", "Manar D.", ""], ["Vidyaratne", "Lasitha", ""], ["Glandon", "Alexander", ""], ["Iftekharuddin", "Khan M.", ""]]}, {"id": "1908.07667", "submitter": "Ka-Ho Chow", "authors": "Ka-Ho Chow, Wenqi Wei, Yanzhao Wu, Ling Liu", "title": "Denoising and Verification Cross-Layer Ensemble Against Black-box\n  Adversarial Attacks", "comments": "To appear in IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have demonstrated impressive performance on many\nchallenging machine learning tasks. However, DNNs are vulnerable to adversarial\ninputs generated by adding maliciously crafted perturbations to the benign\ninputs. As a growing number of attacks have been reported to generate\nadversarial inputs of varying sophistication, the defense-attack arms race has\nbeen accelerated. In this paper, we present MODEF, a cross-layer model\ndiversity ensemble framework. MODEF intelligently combines unsupervised model\ndenoising ensemble with supervised model verification ensemble by quantifying\nmodel diversity, aiming to boost the robustness of the target model against\nadversarial examples. Evaluated using eleven representative attacks on popular\nbenchmark datasets, we show that MODEF achieves remarkable defense success\nrates, compared with existing defense methods, and provides a superior\ncapability of repairing adversarial inputs and making correct predictions with\nhigh accuracy in the presence of black-box attacks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 01:34:08 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 06:23:58 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Chow", "Ka-Ho", ""], ["Wei", "Wenqi", ""], ["Wu", "Yanzhao", ""], ["Liu", "Ling", ""]]}, {"id": "1908.07678", "submitter": "Zhen Zhu", "authors": "Zhen Zhu, Mengde Xu, Song Bai, Tengteng Huang, Xiang Bai", "title": "Asymmetric Non-local Neural Networks for Semantic Segmentation", "comments": "To appear in ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The non-local module works as a particularly useful technique for semantic\nsegmentation while criticized for its prohibitive computation and GPU memory\noccupation. In this paper, we present Asymmetric Non-local Neural Network to\nsemantic segmentation, which has two prominent components: Asymmetric Pyramid\nNon-local Block (APNB) and Asymmetric Fusion Non-local Block (AFNB). APNB\nleverages a pyramid sampling module into the non-local block to largely reduce\nthe computation and memory consumption without sacrificing the performance.\nAFNB is adapted from APNB to fuse the features of different levels under a\nsufficient consideration of long range dependencies and thus considerably\nimproves the performance. Extensive experiments on semantic segmentation\nbenchmarks demonstrate the effectiveness and efficiency of our work. In\nparticular, we report the state-of-the-art performance of 81.3 mIoU on the\nCityscapes test set. For a 256x128 input, APNB is around 6 times faster than a\nnon-local block on GPU while 28 times smaller in GPU running memory occupation.\nCode is available at: https://github.com/MendelXu/ANN.git.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 02:26:44 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 14:59:28 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 03:10:45 GMT"}, {"version": "v4", "created": "Wed, 28 Aug 2019 13:35:01 GMT"}, {"version": "v5", "created": "Thu, 29 Aug 2019 13:31:38 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Zhu", "Zhen", ""], ["Xu", "Mengde", ""], ["Bai", "Song", ""], ["Huang", "Tengteng", ""], ["Bai", "Xiang", ""]]}, {"id": "1908.07701", "submitter": "Chin-Yu Sun", "authors": "Chin-Yu Sun, Allen C.-H. Wu, TingTing Hwang", "title": "A Novel Privacy-Preserving Deep Learning Scheme without Using\n  Cryptography Component", "comments": "Submit to CAEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning, which uses Deep Neural Networks (DNN), plays an\nimportant role in many fields. A secure neural network model with a secure\ntraining/inference scheme is indispensable to many applications. To accomplish\nsuch a task usually needs one of the entities (the customer or the service\nprovider) to provide private information (customer's data or the model) to the\nother. Without a secure scheme and the mutual trust between the service\nproviders and their customers, it will be an impossible mission. In this paper,\nwe propose a novel privacy-preserving deep learning model and a secure\ntraining/inference scheme to protect the input, the output, and the model in\nthe application of the neural network. We utilize the innate properties of a\ndeep neural network to design a secure mechanism without using any complicated\ncryptography component. The security analysis shows our proposed scheme is\nsecure and the experimental results also demonstrate that our method is very\nefficient and suitable for real applications.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 03:55:59 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 11:31:09 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Sun", "Chin-Yu", ""], ["Wu", "Allen C. -H.", ""], ["Hwang", "TingTing", ""]]}, {"id": "1908.07723", "submitter": "Rojeh Hayek", "authors": "Rojeh Hayek and Oded Shmueli", "title": "Improved Cardinality Estimation by Learning Queries Containment Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The containment rate of query Q1 in query Q2 over database D is the\npercentage of Q1's result tuples over D that are also in Q2's result over D. We\ndirectly estimate containment rates between pairs of queries over a specific\ndatabase. For this, we use a specialized deep learning scheme, CRN, which is\ntailored to representing pairs of SQL queries. Result-cardinality estimation is\na core component of query optimization. We describe a novel approach for\nestimating queries result-cardinalities using estimated containment rates among\nqueries. This containment rate estimation may rely on CRN or embed, unchanged,\nknown cardinality estimation methods. Experimentally, our novel approach for\nestimating cardinalities, using containment rates between queries, on a\nchallenging real-world database, realizes significant improvements to state of\nthe art cardinality estimation methods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 07:07:27 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Hayek", "Rojeh", ""], ["Shmueli", "Oded", ""]]}, {"id": "1908.07724", "submitter": "Enmao Diao", "authors": "Enmao Diao, Jie Ding, Vahid Tarokh", "title": "Restricted Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/BigData47090.2019.9006257", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network (RNN) and its variations such as Long Short-Term\nMemory (LSTM) and Gated Recurrent Unit (GRU), have become standard building\nblocks for learning online data of sequential nature in many research areas,\nincluding natural language processing and speech data analysis. In this paper,\nwe present a new methodology to significantly reduce the number of parameters\nin RNNs while maintaining performance that is comparable or even better than\nclassical RNNs. The new proposal, referred to as Restricted Recurrent Neural\nNetwork (RRNN), restricts the weight matrices corresponding to the input data\nand hidden states at each time step to share a large proportion of parameters.\nThe new architecture can be regarded as a compression of its classical\ncounterpart, but it does not require pre-training or sophisticated parameter\nfine-tuning, both of which are major issues in most existing compression\ntechniques. Experiments on natural language modeling show that compared with\nits classical counterpart, the restricted recurrent architecture generally\nproduces comparable results at about 50\\% compression rate. In particular, the\nRestricted LSTM can outperform classical RNN with even less number of\nparameters.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 07:12:31 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 19:53:20 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 09:25:22 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2019 21:52:34 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Diao", "Enmao", ""], ["Ding", "Jie", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1908.07749", "submitter": "Binh Nguyen-Thai", "authors": "ThaiBinh Nguyen, Atsuhiro Takasu", "title": "Boosting the Rating Prediction with Click Data and Textual Contents", "comments": "arXiv admin note: substantial text overlap with arXiv:1705.02085", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization (MF) is one of the most efficient methods for rating\npredictions. MF learns user and item representations by factorizing the\nuser-item rating matrix. Further, textual contents are integrated to\nconventional MF to address the cold-start problem. However, the textual\ncontents do not reflect all aspects of the items. In this paper, we propose a\nmodel that leverages the information hidden in the item co-click (i.e., items\nthat are often clicked together by a user) into learning item representations.\nWe develop TCMF (Textual Co Matrix Factorization) that learns the user and item\nrepresentations jointly from the user-item matrix, textual contents and item\nco-click matrix built from click data. Item co-click information captures the\nrelationships between items which are not captured via textual contents. The\nexperiments on two real-world datasets MovieTweetings, and Bookcrossing)\ndemonstrate that our method outperforms competing methods in terms of rating\nprediction. Further, we show that the proposed model can learn effective item\nrepresentations by comparing with state-of-the-art methods in classification\ntask which uses the item representations as input vectors.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 08:33:21 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 01:48:58 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Nguyen", "ThaiBinh", ""], ["Takasu", "Atsuhiro", ""]]}, {"id": "1908.07782", "submitter": "Chenghao Hu", "authors": "Chenghao Hu, Jingyan Jiang, Zhi Wang", "title": "Decentralized Federated Learning: A Segmented Gossip Approach", "comments": "Accepted to the 1st International Workshop on Federated Machine\n  Learning for User Privacy and Data Confidentiality (FML'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging concern about data privacy and security has motivated the\nproposal of federated learning, which allows nodes to only synchronize the\nlocally-trained models instead their own original data. Conventional federated\nlearning architecture, inherited from the parameter server design, relies on\nhighly centralized topologies and the assumption of large nodes-to-server\nbandwidths. However, in real-world federated learning scenarios the network\ncapacities between nodes are highly uniformly distributed and smaller than that\nin a datacenter. It is of great challenges for conventional federated learning\napproaches to efficiently utilize network capacities between nodes. In this\npaper, we propose a model segment level decentralized federated learning to\ntackle this problem. In particular, we propose a segmented gossip approach,\nwhich not only makes full utilization of node-to-node bandwidth, but also has\ngood training convergence. The experimental results show that even the training\ntime can be highly reduced as compared to centralized federated learning.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 10:21:43 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Hu", "Chenghao", ""], ["Jiang", "Jingyan", ""], ["Wang", "Zhi", ""]]}, {"id": "1908.07795", "submitter": "Yichun Yin", "authors": "Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Qun Liu", "title": "Dialog State Tracking with Reinforced Data Augmentation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dialog state trackers are generally limited due to the lack of\nquantity and diversity of annotated training data. In this paper, we address\nthis difficulty by proposing a reinforcement learning (RL) based framework for\ndata augmentation that can generate high-quality data to improve the neural\nstate tracker. Specifically, we introduce a novel contextual bandit generator\nto learn fine-grained augmentation policies that can generate new effective\ninstances by choosing suitable replacements for the specific context. Moreover,\nby alternately learning between the generator and the state tracker, we can\nkeep refining the generative policies to generate more high-quality training\ndata for neural state tracker. Experimental results on the WoZ and MultiWoZ\n(restaurant) datasets demonstrate that the proposed framework significantly\nimproves the performance over the state-of-the-art models, especially with\nlimited training data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 11:07:14 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 03:21:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yin", "Yichun", ""], ["Shang", "Lifeng", ""], ["Jiang", "Xin", ""], ["Chen", "Xiao", ""], ["Liu", "Qun", ""]]}, {"id": "1908.07805", "submitter": "Hanna Meyer", "authors": "Hanna Meyer, Christoph Reudenbach, Stephan W\\\"ollauer, Thomas Nauss", "title": "Importance of spatial predictor variable selection in machine learning\n  applications -- Moving from data reproduction to spatial prediction", "comments": "under review in Ecological Modelling", "journal-ref": "Ecological Modelling, 411, 2019, 108815", "doi": "10.1016/j.ecolmodel.2019.108815", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning algorithms find frequent application in spatial prediction\nof biotic and abiotic environmental variables. However, the characteristics of\nspatial data, especially spatial autocorrelation, are widely ignored. We\nhypothesize that this is problematic and results in models that can reproduce\ntraining data but are unable to make spatial predictions beyond the locations\nof the training samples. We assume that not only spatial validation strategies\nbut also spatial variable selection is essential for reliable spatial\npredictions. We introduce two case studies that use remote sensing to predict\nland cover and the leaf area index for the \"Marburg Open Forest\", an open\nresearch and education site of Marburg University, Germany. We use the machine\nlearning algorithm Random Forests to train models using non-spatial and spatial\ncross-validation strategies to understand how spatial variable selection\naffects the predictions. Our findings confirm that spatial cross-validation is\nessential in preventing overoptimistic model performance. We further show that\nhighly autocorrelated predictors (such as geolocation variables, e.g. latitude,\nlongitude) can lead to considerable overfitting and result in models that can\nreproduce the training data but fail in making spatial predictions. The problem\nbecomes apparent in the visual assessment of the spatial predictions that show\nclear artefacts that can be traced back to a misinterpretation of the spatially\nautocorrelated predictors by the algorithm. Spatial variable selection could\nautomatically detect and remove such variables that lead to overfitting,\nresulting in reliable spatial prediction patterns and improved statistical\nspatial model performance. We conclude that in addition to spatial validation,\na spatial variable selection must be considered in spatial predictions of\necological data to produce reliable predictions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 11:47:38 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Meyer", "Hanna", ""], ["Reudenbach", "Christoph", ""], ["W\u00f6llauer", "Stephan", ""], ["Nauss", "Thomas", ""]]}, {"id": "1908.07808", "submitter": "Jules Kruijswijk", "authors": "Jules Kruijswijk, Petri Parvinen, Maurits Kaptein", "title": "Exploring Offline Policy Evaluation for the Continuous-Armed Bandit\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (contextual) multi-armed bandit problem (MAB) provides a formalization of\nsequential decision-making which has many applications. However, validly\nevaluating MAB policies is challenging; we either resort to simulations which\ninherently include debatable assumptions, or we resort to expensive field\ntrials. Recently an offline evaluation method has been suggested that is based\non empirical data, thus relaxing the assumptions, and can be used to evaluate\nmultiple competing policies in parallel. This method is however not directly\nsuited for the continuous armed (CAB) problem; an often encountered version of\nthe MAB problem in which the action set is continuous instead of discrete. We\npropose and evaluate an extension of the existing method such that it can be\nused to evaluate CAB policies. We empirically demonstrate that our method\nprovides a relatively consistent ranking of policies. Furthermore, we detail\nhow our method can be used to select policies in a real-life CAB problem.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 12:11:03 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Kruijswijk", "Jules", ""], ["Parvinen", "Petri", ""], ["Kaptein", "Maurits", ""]]}, {"id": "1908.07817", "submitter": "Zhengxuan Wu", "authors": "Zhengxuan Wu and Yueyi Jiang", "title": "Disentangling Latent Emotions of Word Embeddings on Complex Emotional\n  Narratives", "comments": "9 pages, submitted and accepted by NLP conference 2019", "journal-ref": "NLPCC2019", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding models such as GloVe are widely used in natural language\nprocessing (NLP) research to convert words into vectors. Here, we provide a\npreliminary guide to probe latent emotions in text through GloVe word vectors.\nFirst, we trained a neural network model to predict continuous emotion valence\nratings by taking linguistic inputs from Stanford Emotional Narratives Dataset\n(SEND). After interpreting the weights in the model, we found that only a few\ndimensions of the word vectors contributed to expressing emotions in text, and\nwords were clustered on the basis of their emotional polarities. Furthermore,\nwe performed a linear transformation that projected high dimensional embedded\nvectors into an emotion space. Based on NRC Emotion Lexicon (EmoLex), we\nvisualized the entanglement of emotions in the lexicon by using both projected\nand raw GloVe word vectors. We showed that, in the proposed emotion space, we\nwere able to better disentangle emotions than using raw GloVe vectors alone. In\naddition, we found that the sum vectors of different pairs of emotion words\nsuccessfully captured expressed human feelings in the EmoLex. For example, the\nsum of two embedded word vectors expressing Joy and Trust which express Love\nshared high similarity (similarity score .62) with the embedded vector\nexpressing Optimism. On the contrary, this sum vector was dissimilar\n(similarity score -.19) with the the embedded vector expressing Remorse. In\nthis paper, we argue that through the proposed emotion space, arithmetic of\nemotions is preserved in the word vectors. The affective representation\nuncovered in emotion vector space could shed some light on how to help machines\nto disentangle emotion expressed in word embeddings.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 11:05:45 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Wu", "Zhengxuan", ""], ["Jiang", "Yueyi", ""]]}, {"id": "1908.07819", "submitter": "Mahsa Shafaei", "authors": "Mahsa Shafaei and Niloofar Safi Samghabadi and Sudipta Kar and Thamar\n  Solorio", "title": "Rating for Parents: Predicting Children Suitability Rating for Movies\n  Based on Language of the Movies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The film culture has grown tremendously in recent years. The large number of\nstreaming services put films as one of the most convenient forms of\nentertainment in today's world. Films can help us learn and inspire societal\nchange. But they can also negatively affect viewers. In this paper, our goal is\nto predict the suitability of the movie content for children and young adults\nbased on scripts. The criterion that we use to measure suitability is the MPAA\nrating that is specifically designed for this purpose. We propose an RNN based\narchitecture with attention that jointly models the genre and the emotions in\nthe script to predict the MPAA rating. We achieve 78% weighted F1-score for the\nclassification model that outperforms the traditional machine learning method\nby 6%.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 15:18:10 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 02:00:11 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Shafaei", "Mahsa", ""], ["Samghabadi", "Niloofar Safi", ""], ["Kar", "Sudipta", ""], ["Solorio", "Thamar", ""]]}, {"id": "1908.07820", "submitter": "XiaoKang Liu", "authors": "Jianquan Li, Xiaokang Liu, Wenpeng Yin, Min Yang, Liqun Ma, Yaohong\n  Jin", "title": "Empirical Evaluation of Multi-task Learning in Deep Neural Networks for\n  Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Task Learning (MTL) aims at boosting the overall performance of each\nindividual task by leveraging useful information contained in multiple related\ntasks. It has shown great success in natural language processing (NLP).\nCurrently, a number of MLT architectures and learning mechanisms have been\nproposed for various NLP tasks. However, there is no systematic exploration and\ncomparison of different MLT architectures and learning mechanisms for their\nstrong performance in-depth. In this paper, we conduct a thorough examination\nof typical MTL methods on a broad range of representative NLP tasks. Our\nprimary goal is to understand the merits and demerits of existing MTL methods\nin NLP tasks, thus devising new hybrid architectures intended to combine their\nstrengths.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 03:16:40 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 08:06:18 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Li", "Jianquan", ""], ["Liu", "Xiaokang", ""], ["Yin", "Wenpeng", ""], ["Yang", "Min", ""], ["Ma", "Liqun", ""], ["Jin", "Yaohong", ""]]}, {"id": "1908.07822", "submitter": "Shining Liang", "authors": "Shining Liang, Wanli Zuo, Zhenkun Shi, Sen Wang, Junhu Wang, Xianglin\n  Zuo", "title": "A Multi-level Neural Network for Implicit Causality Detection in Web\n  Texts", "comments": "31 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mining causality from text is a complex and crucial natural language\nunderstanding task corresponding to the human cognition. Existing studies at\nits solution can be grouped into two primary categories: feature engineering\nbased and neural model based methods. In this paper, we find that the former\nhas incomplete coverage and inherent errors but provide prior knowledge; while\nthe latter leverages context information but causal inference of which is\ninsufficiency. To handle the limitations, we propose a novel causality\ndetection model named MCDN to explicitly model causal reasoning process, and\nfurthermore, to exploit the advantages of both methods. Specifically, we adopt\nmulti-head self-attention to acquire semantic feature at word level and develop\nthe SCRN to infer causality at segment level. To the best of our knowledge,\nwith regards to the causality tasks, this is the first time that the Relation\nNetwork is applied. The experimental results show that: 1) the proposed\napproach performs prominent performance on causality detection; 2) further\nanalysis manifests the effectiveness and robustness of MCDN.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 10:34:59 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 02:29:09 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 16:33:15 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Liang", "Shining", ""], ["Zuo", "Wanli", ""], ["Shi", "Zhenkun", ""], ["Wang", "Sen", ""], ["Wang", "Junhu", ""], ["Zuo", "Xianglin", ""]]}, {"id": "1908.07832", "submitter": "Ahmed El-Kishky", "authors": "Ahmed El-Kishky, Frank Xu, Aston Zhang, Jiawei Han", "title": "Parsimonious Morpheme Segmentation with an Application to Enriching Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, many text-mining tasks treat individual word-tokens as the\nfinest meaningful semantic granularity. However, in many languages and\nspecialized corpora, words are composed by concatenating semantically\nmeaningful subword structures. Word-level analysis cannot leverage the semantic\ninformation present in such subword structures. With regard to word embedding\ntechniques, this leads to not only poor embeddings for infrequent words in\nlong-tailed text corpora but also weak capabilities for handling\nout-of-vocabulary words. In this paper we propose MorphMine for unsupervised\nmorpheme segmentation. MorphMine applies a parsimony criterion to\nhierarchically segment words into the fewest number of morphemes at each level\nof the hierarchy. This leads to longer shared morphemes at each level of\nsegmentation. Experiments show that MorphMine segments words in a variety of\nlanguages into human-verified morphemes. Additionally, we experimentally\ndemonstrate that utilizing MorphMine morphemes to enrich word embeddings\nconsistently improves embedding quality on a variety of of embedding\nevaluations and a downstream language modeling task.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 00:45:16 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 22:18:44 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["El-Kishky", "Ahmed", ""], ["Xu", "Frank", ""], ["Zhang", "Aston", ""], ["Han", "Jiawei", ""]]}, {"id": "1908.07842", "submitter": "Mohammadreza Baharani", "authors": "Mohammadreza Baharani, Shrey Mohan, Hamed Tabkhi", "title": "Real-time Person Re-identification at the Edge: A Mixed Precision\n  Approach", "comments": "This is a pre-print of an article published in International\n  Conference on Image Analysis and Recognition (ICIAR 2019), Lecture Notes in\n  Computer Science. The final authenticated version is available online at\n  https://doi.org/10.1007/978-3-030-27272-2_3", "journal-ref": "International Conference on Image Analysis and Recognition (ICIAR\n  2019), Lecture Notes in Computer Science", "doi": "10.1007/978-3-030-27272-2_3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical part of multi-person multi-camera tracking is person\nre-identification (re-ID) algorithm, which recognizes and retains identities of\nall detected unknown people throughout the video stream. Many re-ID algorithms\ntoday exemplify state of the art results, but not much work has been done to\nexplore the deployment of such algorithms for computation and power constrained\nreal-time scenarios. In this paper, we study the effect of using a light-weight\nmodel, MobileNet-v2 for re-ID and investigate the impact of single (FP32)\nprecision versus half (FP16) precision for training on the server and inference\non the edge nodes. We further compare the results with the baseline model which\nuses ResNet-50 on state of the art benchmarks including CUHK03, Market-1501,\nand Duke-MTMC. The MobileNet-V2 mixed precision training method can improve\nboth inference throughput on the edge node, and training time on server\n$3.25\\times$ reaching to 27.77fps and $1.75\\times$, respectively and decreases\npower consumption on the edge node by $1.45\\times$, while it deteriorates\naccuracy only 5.6\\% in respect to ResNet-50 single precision on the average for\nthree different datasets. The code and pre-trained networks are publicly\navailable at https://github.com/TeCSAR-UNCC/person-reid.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 23:38:53 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Baharani", "Mohammadreza", ""], ["Mohan", "Shrey", ""], ["Tabkhi", "Hamed", ""]]}, {"id": "1908.07844", "submitter": "Benedikt Boenninghoff", "authors": "Benedikt Boenninghoff, Robert M. Nickel, Steffen Zeiler, Dorothea\n  Kolossa", "title": "Similarity Learning for Authorship Verification in Social Media", "comments": "5 pages, 3 figures, 1 table, presented on ICASSP 2019 in Brighton, UK", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8683405", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship verification tries to answer the question if two documents with\nunknown authors were written by the same author or not. A range of successful\ntechnical approaches has been proposed for this task, many of which are based\non traditional linguistic features such as n-grams. These algorithms achieve\ngood results for certain types of written documents like books and novels.\nForensic authorship verification for social media, however, is a much more\nchallenging task since messages tend to be relatively short, with a large\nvariety of different genres and topics. At this point, traditional methods\nbased on features like n-grams have had limited success. In this work, we\npropose a new neural network topology for similarity learning that\nsignificantly improves the performance on the author verification task with\nsuch challenging data sets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 04:08:58 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Boenninghoff", "Benedikt", ""], ["Nickel", "Robert M.", ""], ["Zeiler", "Steffen", ""], ["Kolossa", "Dorothea", ""]]}, {"id": "1908.07846", "submitter": "Stephen Petrie Dr", "authors": "Stephen M. Petrie and T'Mir D. Julius", "title": "Representing text as abstract images enables image classifiers to also\n  simultaneously classify text", "comments": "Minor changes in order to submit paper to a different conference\n  (e.g. made minor changes to writing in several places and added extra data to\n  Table 3 in order to make it clearer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method for converting text data into abstract image\nrepresentations, which allows image-based processing techniques (e.g. image\nclassification networks) to be applied to text-based comparison problems. We\napply the technique to entity disambiguation of inventor names in US patents.\nThe method involves converting text from each pairwise comparison between two\ninventor name records into a 2D RGB (stacked) image representation. We then\ntrain an image classification neural network to discriminate between such\npairwise comparison images, and use the trained network to label each pair of\nrecords as either matched (same inventor) or non-matched (different inventors),\nobtaining highly accurate results. Our new text-to-image representation method\ncould also be used more broadly for other NLP comparison problems, such as\ndisambiguation of academic publications, or for problems that require\nsimultaneous classification of both text and image datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:28:29 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 08:39:41 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 07:28:03 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Petrie", "Stephen M.", ""], ["Julius", "T'Mir D.", ""]]}, {"id": "1908.07847", "submitter": "Sterling Ramroach", "authors": "Sterling Ramroach, Andrew Dhanoo, Brian Cockburn, and Ajay Joshi", "title": "CUDA optimized Neural Network predicts blood glucose control from\n  quantified joint mobility and anthropometrics", "comments": "5 pages, 6 figures, conference paper: International Conference on\n  Information System and Data Mining, published at\n  https://dl.acm.org/citation.cfm?id=3325940", "journal-ref": null, "doi": "10.1145/3325917.3325940", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network training entails heavy computation with obvious bottlenecks.\nThe Compute Unified Device Architecture (CUDA) programming model allows us to\naccelerate computation by passing the processing workload from the CPU to the\ngraphics processing unit (GPU). In this paper, we leveraged the power of Nvidia\nGPUs to parallelize all of the computation involved in training, to accelerate\na backpropagation feed-forward neural network with one hidden layer using CUDA\nand C++. This optimized neural network was tasked with predicting the level of\nglycated hemoglobin (HbA1c) from non-invasive markers. The rate of increase in\nthe prevalence of Diabetes Mellitus has resulted in an urgent need for early\ndetection and accurate diagnosis. However, due to the invasiveness and\nlimitations of conventional tests, alternate means are being considered.\nLimited Joint Mobility (LJM) has been reported as an indicator for poor\nglycemic control. LJM of the fingers is quantified and its link to HbA1c is\ninvestigated along with other potential non-invasive markers of HbA1c. We\ncollected readings of 33 potential markers from 120 participants at a clinic in\nsouth Trinidad. Our neural network achieved 95.65% accuracy on the training and\n86.67% accuracy on the testing set for male participants and 97.73% and 66.67%\naccuracy on the training and testing sets for female participants. Using 960\nCUDA cores from a Nvidia GeForce GTX 660, our parallelized neural network was\ntrained 50 times faster on both subsets, than its corresponding CPU\nimplementation on an Intel Core (TM) i7-3630QM 2.40 GHz CPU.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:39:54 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Ramroach", "Sterling", ""], ["Dhanoo", "Andrew", ""], ["Cockburn", "Brian", ""], ["Joshi", "Ajay", ""]]}, {"id": "1908.07849", "submitter": "Motaz Alfarraj", "authors": "Motaz Alfarraj and Ghassan AlRegib", "title": "Semi-supervised Sequence Modeling for Elastic Impedance Inversion", "comments": "A manuscript in Interpretation. arXiv admin note: text overlap with\n  arXiv:1905.13412", "journal-ref": null, "doi": "10.1190/INT-2018-0250.1", "report-no": null, "categories": "physics.geo-ph cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent applications of machine learning algorithms in the seismic domain have\nshown great potential in different areas such as seismic inversion and\ninterpretation. However, such algorithms rarely enforce geophysical constraints\n- the lack of which might lead to undesirable results. To overcome this issue,\nwe have developed a semi-supervised sequence modeling framework based on\nrecurrent neural networks for elastic impedance inversion from multi-angle\nseismic data. Specifically, seismic traces and elastic impedance (EI) traces\nare modeled as a time series. Then, a neural-network-based inversion model\ncomprising convolutional and recurrent neural layers is used to invert seismic\ndata for EI. The proposed workflow uses well-log data to guide the inversion.\nIn addition, it uses seismic forward modeling to regularize the training and to\nserve as a geophysical constraint for the inversion. The proposed workflow\nachieves an average correlation of 98% between the estimated and target EI\nusing 10 well logs for training on a synthetic data set.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:17:10 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Alfarraj", "Motaz", ""], ["AlRegib", "Ghassan", ""]]}, {"id": "1908.07857", "submitter": "Sayantan Sengupta", "authors": "Sayantan Sengupta and Sudip Sanyal", "title": "Multi-hypothesis classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accuracy is the most important parameter among few others which defines the\neffectiveness of a machine learning algorithm. Higher accuracy is always\ndesirable. Now, there is a vast number of well established learning algorithms\nalready present in the scientific domain. Each one of them has its own merits\nand demerits. Merits and demerits are evaluated in terms of accuracy, speed of\nconvergence, complexity of the algorithm, generalization property, and\nrobustness among many others. Also the learning algorithms are\ndata-distribution dependent. Each learning algorithm is suitable for a\nparticular distribution of data. Unfortunately, no dominant classifier exists\nfor all the data distribution, and the data distribution task at hand is\nusually unknown. Not one classifier can be discriminative well enough if the\nnumber of classes are huge. So the underlying problem is that a single\nclassifier is not enough to classify the whole sample space correctly. This\nthesis is about exploring the different techniques of combining the classifiers\nso as to obtain the optimal accuracy. Three classifiers are implemented namely\nplain old nearest neighbor on raw pixels, a structural feature extracted\nneighbor and Gabor feature extracted nearest neighbor. Five different\ncombination strategies are devised and tested on Tibetan character images and\nanalyzed\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 14:28:28 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Sengupta", "Sayantan", ""], ["Sanyal", "Sudip", ""]]}, {"id": "1908.07873", "submitter": "Tian Li", "authors": "Tian Li, Anit Kumar Sahu, Ameet Talwalkar, Virginia Smith", "title": "Federated Learning: Challenges, Methods, and Future Directions", "comments": null, "journal-ref": null, "doi": "10.1109/MSP.2020.2975749", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning involves training statistical models over remote devices\nor siloed data centers, such as mobile phones or hospitals, while keeping data\nlocalized. Training in heterogeneous and potentially massive networks\nintroduces novel challenges that require a fundamental departure from standard\napproaches for large-scale machine learning, distributed optimization, and\nprivacy-preserving data analysis. In this article, we discuss the unique\ncharacteristics and challenges of federated learning, provide a broad overview\nof current approaches, and outline several directions of future work that are\nrelevant to a wide range of research communities.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 13:53:23 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Li", "Tian", ""], ["Sahu", "Anit Kumar", ""], ["Talwalkar", "Ameet", ""], ["Smith", "Virginia", ""]]}, {"id": "1908.07878", "submitter": "Zhao Zhang", "authors": "Zhao Zhang, Yulin Sun, Zheng Zhang, Yang Wang, Guangcan Liu and Meng\n  Wang", "title": "Learning Structured Twin-Incoherent Twin-Projective Latent Dictionary\n  Pairs for Classification", "comments": "Accepted by ICDM 2019 as a regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend the popular dictionary pair learning (DPL) into the\nscenario of twin-projective latent flexible DPL under a structured\ntwin-incoherence. Technically, a novel framework called Twin-Projective Latent\nFlexible DPL (TP-DPL) is proposed, which minimizes the twin-incoherence\nconstrained flexibly-relaxed reconstruction error to avoid the possible\nover-fitting issue and produce accurate reconstruction. In this setting, our\nTP-DPL integrates the twin-incoherence based latent flexible DPL and the joint\nembedding of codes as well as salient features by twin-projection into a\nunified model in an adaptive neighborhood-preserving manner. As a result,\nTP-DPL unifies the salient feature extraction, representation and\nclassification. The twin-incoherence constraint on codes and features can\nexplicitly ensure high intra-class compactness and inter-class separation over\nthem. TP-DPL also integrates the adaptive weighting to preserve the local\nneighborhood of the coefficients and salient features within each class\nexplicitly. For efficiency, TP-DPL uses Frobenius-norm and abandons the costly\nl0/l1-norm for group sparse representation. Another byproduct is that TP-DPL\ncan directly apply the class-specific twin-projective reconstruction residual\nto compute the label of data. Extensive results on public databases show that\nTP-DPL can deliver the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 13:59:00 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Zhang", "Zhao", ""], ["Sun", "Yulin", ""], ["Zhang", "Zheng", ""], ["Wang", "Yang", ""], ["Liu", "Guangcan", ""], ["Wang", "Meng", ""]]}, {"id": "1908.07882", "submitter": "Shiwan Zhao Mr", "authors": "Bingzhe Wu, Shiwan Zhao, ChaoChao Chen, Haoyang Xu, Li Wang, Xiaolu\n  Zhang, Guangyu Sun, Jun Zhou", "title": "Generalization in Generative Adversarial Networks: A Novel Perspective\n  from Privacy Protection", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to understand the generalization properties of\ngenerative adversarial networks (GANs) from a new perspective of privacy\nprotection. Theoretically, we prove that a differentially private learning\nalgorithm used for training the GAN does not overfit to a certain degree, i.e.,\nthe generalization gap can be bounded. Moreover, some recent works, such as the\nBayesian GAN, can be re-interpreted based on our theoretical insight from\nprivacy protection. Quantitatively, to evaluate the information leakage of\nwell-trained GAN models, we perform various membership attacks on these models.\nThe results show that previous Lipschitz regularization techniques are\neffective in not only reducing the generalization gap but also alleviating the\ninformation leakage of the training dataset.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 14:09:32 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 03:31:06 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 03:40:13 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wu", "Bingzhe", ""], ["Zhao", "Shiwan", ""], ["Chen", "ChaoChao", ""], ["Xu", "Haoyang", ""], ["Wang", "Li", ""], ["Zhang", "Xiaolu", ""], ["Sun", "Guangyu", ""], ["Zhou", "Jun", ""]]}, {"id": "1908.07885", "submitter": "Qingjie Meng", "authors": "Qingjie Meng and Nick Pawlowski and Daniel Rueckert and Bernhard Kainz", "title": "Representation Disentanglement for Multi-task Learning with application\n  to Fetal Ultrasound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges for deep learning algorithms in medical image\nanalysis is the indiscriminate mixing of image properties, e.g. artifacts and\nanatomy. These entangled image properties lead to a semantically redundant\nfeature encoding for the relevant task and thus lead to poor generalization of\ndeep learning algorithms. In this paper we propose a novel representation\ndisentanglement method to extract semantically meaningful and generalizable\nfeatures for different tasks within a multi-task learning framework. Deep\nneural networks are utilized to ensure that the encoded features are maximally\ninformative with respect to relevant tasks, while an adversarial regularization\nencourages these features to be disentangled and minimally informative about\nirrelevant tasks. We aim to use the disentangled representations to generalize\nthe applicability of deep neural networks. We demonstrate the advantages of the\nproposed method on synthetic data as well as fetal ultrasound images. Our\nexperiments illustrate that our method is capable of learning disentangled\ninternal representations. It outperforms baseline methods in multiple tasks,\nespecially on images with new properties, e.g. previously unseen artifacts in\nfetal ultrasound.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 14:14:44 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Meng", "Qingjie", ""], ["Pawlowski", "Nick", ""], ["Rueckert", "Daniel", ""], ["Kainz", "Bernhard", ""]]}, {"id": "1908.07896", "submitter": "Mohammad Reza Keshtkaran", "authors": "Mohammad Reza Keshtkaran and Chethan Pandarinath", "title": "Enabling hyperparameter optimization in sequential autoencoders for\n  spiking neural data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuing advances in neural interfaces have enabled simultaneous monitoring\nof spiking activity from hundreds to thousands of neurons. To interpret these\nlarge-scale data, several methods have been proposed to infer latent dynamic\nstructure from high-dimensional datasets. One recent line of work uses\nrecurrent neural networks in a sequential autoencoder (SAE) framework to\nuncover dynamics. SAEs are an appealing option for modeling nonlinear dynamical\nsystems, and enable a precise link between neural activity and behavior on a\nsingle-trial basis. However, the very large parameter count and complexity of\nSAEs relative to other models has caused concern that SAEs may only perform\nwell on very large training sets. We hypothesized that with a method to\nsystematically optimize hyperparameters (HPs), SAEs might perform well even in\ncases of limited training data. Such a breakthrough would greatly extend their\napplicability. However, we find that SAEs applied to spiking neural data are\nprone to a particular form of overfitting that cannot be detected using\nstandard validation metrics, which prevents standard HP searches. We develop\nand test two potential solutions: an alternate validation method (\"sample\nvalidation\") and a novel regularization method (\"coordinated dropout\"). These\ninnovations prevent overfitting quite effectively, and allow us to test whether\nSAEs can achieve good performance on limited data through large-scale HP\noptimization. When applied to data from motor cortex recorded while monkeys\nmade reaches in various directions, large-scale HP optimization allowed SAEs to\nbetter maintain performance for small dataset sizes. Our results should greatly\nextend the applicability of SAEs in extracting latent dynamics from sparse,\nmultidimensional data, such as neural population spiking activity.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 14:40:14 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 15:21:31 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Keshtkaran", "Mohammad Reza", ""], ["Pandarinath", "Chethan", ""]]}, {"id": "1908.07899", "submitter": "Tobias Hinz", "authors": "Marcus Soll, Tobias Hinz, Sven Magg, Stefan Wermter", "title": "Evaluating Defensive Distillation For Defending Text Processing Neural\n  Networks Against Adversarial Examples", "comments": "Published at the International Conference on Artificial Neural\n  Networks (ICANN) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are artificially modified input samples which lead to\nmisclassifications, while not being detectable by humans. These adversarial\nexamples are a challenge for many tasks such as image and text classification,\nespecially as research shows that many adversarial examples are transferable\nbetween different classifiers. In this work, we evaluate the performance of a\npopular defensive strategy for adversarial examples called defensive\ndistillation, which can be successful in hardening neural networks against\nadversarial examples in the image domain. However, instead of applying\ndefensive distillation to networks for image classification, we examine, for\nthe first time, its performance on text classification tasks and also evaluate\nits effect on the transferability of adversarial text examples. Our results\nindicate that defensive distillation only has a minimal impact on text\nclassifying neural networks and does neither help with increasing their\nrobustness against adversarial examples nor prevent the transferability of\nadversarial examples between neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 14:50:13 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Soll", "Marcus", ""], ["Hinz", "Tobias", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1908.07918", "submitter": "Sudhakar Singh", "authors": "Sudhakar Singh, Pankaj Singh, Rakhi Garg, P. K. Mishra", "title": "Mining Association Rules in Various Computing Environments: A Survey", "comments": "14 pages", "journal-ref": "International Journal of Applied Engineering Research 2016; 11(8):\n  5629-5640", "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Association Rule Mining (ARM) is one of the well know and most researched\ntechnique of data mining. There are so many ARM algorithms have been designed\nthat their counting is a large number. In this paper we have surveyed the\nvarious ARM algorithms in four computing environments. The considered computing\nenvironments are sequential computing, parallel and distributed computing, grid\ncomputing and cloud computing. With the emergence of new computing paradigm,\nARM algorithms have been designed by many researchers to improve the efficiency\nby utilizing the new paradigm. This paper represents the journey of ARM\nalgorithms started from sequential algorithms, and through parallel and\ndistributed, and grid based algorithms to the current state-of-the-art, along\nwith the motives for adopting new machinery.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 11:13:50 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Singh", "Sudhakar", ""], ["Singh", "Pankaj", ""], ["Garg", "Rakhi", ""], ["Mishra", "P. K.", ""]]}, {"id": "1908.07924", "submitter": "Babak Salimi", "authors": "Babak Salimi, Bill Howe, Dan Suciu", "title": "Data Management for Causal Algorithmic Fairness", "comments": "arXiv admin note: text overlap with arXiv:1902.08283", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is increasingly recognized as a critical component of machine\nlearning systems. However, it is the underlying data on which these systems are\ntrained that often reflects discrimination, suggesting a data management\nproblem. In this paper, we first make a distinction between associational and\ncausal definitions of fairness in the literature and argue that the concept of\nfairness requires causal reasoning. We then review existing works and identify\nfuture opportunities for applying data management techniques to causal\nalgorithmic fairness.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 17:23:00 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 05:24:37 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 02:07:32 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Salimi", "Babak", ""], ["Howe", "Bill", ""], ["Suciu", "Dan", ""]]}, {"id": "1908.07931", "submitter": "Marko Ilievski", "authors": "Marko Ilievski, Sean Sedwards, Ashish Gaurav, Aravind Balakrishnan,\n  Atrisha Sarkar, Jaeyoung Lee, Fr\\'ed\\'eric Bouchard, Ryan De Iaco, and\n  Krzysztof Czarnecki", "title": "Design Space of Behaviour Planning for Autonomous Driving", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the complex design space of behaviour planning for autonomous\ndriving. Design choices that successfully address one aspect of behaviour\nplanning can critically constrain others. To aid the design process, in this\nwork we decompose the design space with respect to important choices arising\nfrom the current state of the art approaches, and describe the resulting\ntrade-offs. In doing this, we also identify interesting directions of future\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 15:39:51 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Ilievski", "Marko", ""], ["Sedwards", "Sean", ""], ["Gaurav", "Ashish", ""], ["Balakrishnan", "Aravind", ""], ["Sarkar", "Atrisha", ""], ["Lee", "Jaeyoung", ""], ["Bouchard", "Fr\u00e9d\u00e9ric", ""], ["De Iaco", "Ryan", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1908.07934", "submitter": "Xiangyi Li", "authors": "Xiangyi Li and Huaming Wu", "title": "Spatio-Temporal Representation with Deep Neural Recurrent Network in\n  MIMO CSI Feedback", "comments": "5pages, 6figures, 14conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiple-input multiple-output (MIMO) systems, it is crucial of utilizing\nthe available channel state information (CSI) at the transmitter for precoding\nto improve the performance of frequency division duplex (FDD) networks. One of\nthe mainchallenges is to compress a large amount of CSI in CSI feedback\ntransmission in massive MIMO systems. In this paper, we propose a deep learning\n(DL)-based approach that uses a deep recurrent neural network (RNN) to learn\ntemporal correlation and adopts depthwise separable convolution to shrink the\nmodel. The feature extraction module is also elaborately devised by\nstudyingdecoupled spatio-temporal feature representations in different\nstructures. Experimental results demonstrate that the proposed approach\noutperforms existing DL-based methods in terms of recovery quality and\naccuracy, which can also achieve remarkable robustness at low compression ratio\n(CR).\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 10:28:53 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 08:16:37 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Li", "Xiangyi", ""], ["Wu", "Huaming", ""]]}, {"id": "1908.07957", "submitter": "Elke Kirschbaum", "authors": "Elke Kirschbaum, Alberto Bailoni, Fred A. Hamprecht", "title": "DISCo: Deep learning, Instance Segmentation, and Correlations for cell\n  segmentation in calcium imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calcium imaging is one of the most important tools in neurophysiology as it\nenables the observation of neuronal activity for hundreds of cells in parallel\nand at single-cell resolution. In order to use the data gained with calcium\nimaging, it is necessary to extract individual cells and their activity from\nthe recordings. We present DISCo, a novel approach for the cell segmentation in\ncalcium imaging videos. We use temporal information from the recordings in a\ncomputationally efficient way by computing correlations between pixels and\ncombine it with shape-based information to identify active as well as\nnon-active cells. We first learn to predict whether two pixels belong to the\nsame cell; this information is summarized in an undirected, edge-weighted grid\ngraph which we then partition. In so doing, we approximately solve the NP-hard\ncorrelation clustering problem with a recently proposed greedy algorithm.\nEvaluating our method on the Neurofinder public benchmark shows that DISCo\noutperforms all existing models trained on these datasets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 16:04:10 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 05:57:30 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 19:02:13 GMT"}, {"version": "v4", "created": "Sat, 4 Apr 2020 11:52:54 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kirschbaum", "Elke", ""], ["Bailoni", "Alberto", ""], ["Hamprecht", "Fred A.", ""]]}, {"id": "1908.07962", "submitter": "Siavash Haghiri", "authors": "Siavash Haghiri, Felix Wichmann, Ulrike von Luxburg", "title": "Estimation of perceptual scales using ordinal embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of measuring and analysing sensation,\nthe subjective magnitude of one's experience. We do this in the context of the\nmethod of triads: the sensation of the stimulus is evaluated via relative\njudgments of the form: \"Is stimulus S_i more similar to stimulus S_j or to\nstimulus S_k?\". We propose to use ordinal embedding methods from machine\nlearning to estimate the scaling function from the relative judgments. We\nreview two relevant and well-known methods in psychophysics which are partially\napplicable in our setting: non-metric multi-dimensional scaling (NMDS) and the\nmethod of maximum likelihood difference scaling (MLDS). We perform an extensive\nset of simulations, considering various scaling functions, to demonstrate the\nperformance of the ordinal embedding methods. We show that in contrast to\nexisting approaches our ordinal embedding approach allows, first, to obtain\nreasonable scaling function from comparatively few relative judgments, second,\nthe estimation of non-monotonous scaling functions, and, third,\nmulti-dimensional perceptual scales. In addition to the simulations, we analyse\ndata from two real psychophysics experiments using ordinal embedding methods.\nOur results show that in the one-dimensional, monotonically increasing\nperceptual scale our ordinal embedding approach works as well as MLDS, while in\nhigher dimensions, only our ordinal embedding methods can produce a desirable\nscaling function. To make our methods widely accessible, we provide an\nR-implementation and general rules of thumb on how to use ordinal embedding in\nthe context of psychophysics.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 16:12:27 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Haghiri", "Siavash", ""], ["Wichmann", "Felix", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1908.07968", "submitter": "Felice Antonio Merra", "authors": "Yashar Deldjoo, Tommaso Di Noia and Felice Antonio Merra", "title": "Assessing the Impact of a User-Item Collaborative Attack on Class of\n  Users", "comments": "5 pages, RecSys2019, The 1st Workshop on the Impact of Recommender\n  Systems with ACM RecSys 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaborative Filtering (CF) models lie at the core of most recommendation\nsystems due to their state-of-the-art accuracy. They are commonly adopted in\ne-commerce and online services for their impact on sales volume and/or\ndiversity, and their impact on companies' outcome. However, CF models are only\nas good as the interaction data they work with. As these models rely on outside\nsources of information, counterfeit data such as user ratings or reviews can be\ninjected by attackers to manipulate the underlying data and alter the impact of\nresulting recommendations, thus implementing a so-called shilling attack. While\nprevious works have focused on evaluating shilling attack strategies from a\nglobal perspective paying particular attention to the effect of the size of\nattacks and attacker's knowledge, in this work we explore the effectiveness of\nshilling attacks under novel aspects. First, we investigate the effect of\nattack strategies crafted on a target user in order to push the recommendation\nof a low-ranking item to a higher position, referred to as user-item attack.\nSecond, we evaluate the effectiveness of attacks in altering the impact of\ndifferent CF models by contemplating the class of the target user, from the\nperspective of the richness of her profile (i.e., cold v.s. warm user).\nFinally, similar to previous work we contemplate the size of attack (i.e., the\namount of fake profiles injected) in examining their success. The results of\nexperiments on two widely used datasets in business and movie domains, namely\nYelp and MovieLens, suggest that warm and cold users exhibit contrasting\nbehaviors in datasets with different characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 16:20:54 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Deldjoo", "Yashar", ""], ["Di Noia", "Tommaso", ""], ["Merra", "Felice Antonio", ""]]}, {"id": "1908.07978", "submitter": "G\\'abor Petneh\\'azi", "authors": "G\\'abor Petneh\\'azi", "title": "Quantile Convolutional Neural Networks for Value at Risk Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a new method for forecasting Value at Risk.\nConvolutional neural networks can do time series forecasting, since they can\nlearn local patterns in time. A simple modification enables them to forecast\nnot the mean, but arbitrary quantiles of the distribution, and thus allows them\nto be applied to VaR-forecasting. The proposed model can learn from the price\nhistory of different assets, and it seems to produce fairly accurate forecasts.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 16:37:08 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 19:06:18 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 10:40:32 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 14:58:09 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Petneh\u00e1zi", "G\u00e1bor", ""]]}, {"id": "1908.07980", "submitter": "Matthew West", "authors": "Chenchao Shou and Matthew West", "title": "A tree-based radial basis function method for noisy parallel surrogate\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel surrogate optimization algorithms have proven to be efficient\nmethods for solving expensive noisy optimization problems. In this work we\ndevelop a new parallel surrogate optimization algorithm (ProSRS), using a novel\ntree-based \"zoom strategy\" to improve the efficiency of the algorithm. We prove\nthat if ProSRS is run for sufficiently long, with probability converging to one\nthere will be at least one point among all the evaluations that will be\narbitrarily close to the global minimum. We compare our algorithm to several\nstate-of-the-art Bayesian optimization algorithms on a suite of standard\nbenchmark functions and two real machine learning hyperparameter-tuning\nproblems. We find that our algorithm not only achieves significantly faster\noptimization convergence, but is also 1-4 orders of magnitude cheaper in\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 16:43:54 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Shou", "Chenchao", ""], ["West", "Matthew", ""]]}, {"id": "1908.08005", "submitter": "No\\\"elie Cherrier", "authors": "No\\\"elie Cherrier, Jean-Philippe Poli, Maxime Defurne and Franck\n  Sabati\\'e", "title": "Consistent Feature Construction with Constrained Genetic Programming for\n  Experimental Physics", "comments": "Accepted in this version to CEC 2019", "journal-ref": "Proceedings of 2019 IEEE Congress on Evolutionary Computation\n  (CEC), Wellington, New Zealand, 2019, pp. 1650-1658", "doi": "10.1109/CEC.2019.8789937", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good feature representation is a determinant factor to achieve high\nperformance for many machine learning algorithms in terms of classification.\nThis is especially true for techniques that do not build complex internal\nrepresentations of data (e.g. decision trees, in contrast to deep neural\nnetworks). To transform the feature space, feature construction techniques\nbuild new high-level features from the original ones. Among these techniques,\nGenetic Programming is a good candidate to provide interpretable features\nrequired for data analysis in high energy physics. Classically, original\nfeatures or higher-level features based on physics first principles are used as\ninputs for training. However, physicists would benefit from an automatic and\ninterpretable feature construction for the classification of particle collision\nevents.\n  Our main contribution consists in combining different aspects of Genetic\nProgramming and applying them to feature construction for experimental physics.\nIn particular, to be applicable to physics, dimensional consistency is enforced\nusing grammars.\n  Results of experiments on three physics datasets show that the constructed\nfeatures can bring a significant gain to the classification accuracy. To the\nbest of our knowledge, it is the first time a method is proposed for\ninterpretable feature construction with units of measurement, and that experts\nin high-energy physics validate the overall approach as well as the\ninterpretability of the built features.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 10:55:15 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Cherrier", "No\u00eblie", ""], ["Poli", "Jean-Philippe", ""], ["Defurne", "Maxime", ""], ["Sabati\u00e9", "Franck", ""]]}, {"id": "1908.08006", "submitter": "Farid Ghareh Mohammadi", "authors": "Farid Ghareh Mohammadi, M. Hadi Amini, and Hamid R. Arabnia", "title": "Evolutionary Computation, Optimization and Learning Algorithms for Data\n  Science", "comments": "40 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large number of engineering, science and computational problems have yet to\nbe solved in a computationally efficient way. One of the emerging challenges is\nhow evolving technologies grow towards autonomy and intelligent decision\nmaking. This leads to collection of large amounts of data from various sensing\nand measurement technologies, e.g., cameras, smart phones, health sensors,\nsmart electricity meters, and environment sensors. Hence, it is imperative to\ndevelop efficient algorithms for generation, analysis, classification, and\nillustration of data. Meanwhile, data is structured purposefully through\ndifferent representations, such as large-scale networks and graphs. We focus on\ndata science as a crucial area, specifically focusing on a curse of\ndimensionality (CoD) which is due to the large amount of\ngenerated/sensed/collected data. This motivates researchers to think about\noptimization and to apply nature-inspired algorithms, such as evolutionary\nalgorithms (EAs) to solve optimization problems. Although these algorithms look\nun-deterministic, they are robust enough to reach an optimal solution.\nResearchers do not adopt evolutionary algorithms unless they face a problem\nwhich is suffering from placement in local optimal solution, rather than global\noptimal solution. In this chapter, we first develop a clear and formal\ndefinition of the CoD problem, next we focus on feature extraction techniques\nand categories, then we provide a general overview of meta-heuristic\nalgorithms, its terminology, and desirable properties of evolutionary\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:16:16 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Mohammadi", "Farid Ghareh", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "1908.08015", "submitter": "Jiyang Bai", "authors": "Jiyang Bai and Yuxiang Ren and Jiawei Zhang", "title": "BGADAM: Boosting based Genetic-Evolutionary ADAM for Neural Network\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For various optimization methods, gradient descent-based algorithms can\nachieve outstanding performance and have been widely used in various tasks.\nAmong those commonly used algorithms, ADAM owns many advantages such as fast\nconvergence with both the momentum term and the adaptive learning rate.\nHowever, since the loss functions of most deep neural networks are non-convex,\nADAM also shares the drawback of getting stuck in local optima easily. To\nresolve such a problem, the idea of combining genetic algorithm with base\nlearners is introduced to rediscover the best solutions. Nonetheless, from our\nanalysis, the idea of combining genetic algorithm with a batch of base learners\nstill has its shortcomings. The effectiveness of genetic algorithm can hardly\nbe guaranteed if the unit models converge to close or the same solutions. To\nresolve this problem and further maximize the advantages of genetic algorithm\nwith base learners, we propose to implement the boosting strategy for input\nmodel training, which can subsequently improve the effectiveness of genetic\nalgorithm. In this paper, we introduce a novel optimization algorithm, namely\nBoosting based Genetic ADAM (BGADAM). With both theoretic analysis and\nempirical experiments, we will show that adding the boosting strategy into the\nBGADAM model can help models jump out the local optima and converge to better\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 02:44:33 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 16:09:00 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Bai", "Jiyang", ""], ["Ren", "Yuxiang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1908.08016", "submitter": "Yi Sun", "authors": "Daniel Kang, Yi Sun, Dan Hendrycks, Tom Brown, Jacob Steinhardt", "title": "Testing Robustness Against Unforeseen Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing adversarial defenses only measure robustness to L_p adversarial\nattacks. Not only are adversaries unlikely to exclusively create small L_p\nperturbations, adversaries are unlikely to remain fixed. Adversaries adapt and\nevolve their attacks; hence adversarial defenses must be robust to a broad\nrange of unforeseen attacks. We address this discrepancy between research and\nreality by proposing a new evaluation framework called ImageNet-UA. Our\nframework enables the research community to test ImageNet model robustness\nagainst attacks not encountered during training. To create ImageNet-UA's\ndiverse attack suite, we introduce a total of four novel adversarial attacks.\nWe also demonstrate that, in comparison to ImageNet-UA, prevailing L_inf\nrobustness assessments give a narrow account of model robustness. By evaluating\ncurrent defenses with ImageNet-UA, we find they provide little robustness to\nunforeseen attacks. We hope the greater variety and realism of ImageNet-UA\nenables development of more robust defenses which can generalize beyond attacks\nseen during training.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 17:36:48 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 05:17:48 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Kang", "Daniel", ""], ["Sun", "Yi", ""], ["Hendrycks", "Dan", ""], ["Brown", "Tom", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "1908.08018", "submitter": "Jesus L. Lobo", "authors": "Jesus L. Lobo, Izaskun Oregi, Albert Bifet, Javier Del Ser", "title": "Exploiting a Stimuli Encoding Scheme of Spiking Neural Networks for\n  Stream Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream data processing has gained progressive momentum with the arriving of\nnew stream applications and big data scenarios. One of the most promising\ntechniques in stream learning is the Spiking Neural Network, and some of them\nuse an interesting population encoding scheme to transform the incoming stimuli\ninto spikes. This study sheds lights on the key issue of this encoding scheme,\nthe Gaussian receptive fields, and focuses on applying them as a pre-processing\ntechnique to any dataset in order to gain representativeness, and to boost the\npredictive performance of the stream learning methods. Experiments with\nsynthetic and real data sets are presented, and lead to confirm that our\napproach can be applied successfully as a general pre-processing technique in\nmany real cases.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 09:48:50 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Lobo", "Jesus L.", ""], ["Oregi", "Izaskun", ""], ["Bifet", "Albert", ""], ["Del Ser", "Javier", ""]]}, {"id": "1908.08019", "submitter": "Jesus L. Lobo", "authors": "Jesus L. Lobo, Javier Del Ser, Albert Bifet, Nikola Kasabov", "title": "Spiking Neural Networks and Online Learning: An Overview and\n  Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications that generate huge amounts of data in the form of fast streams\nare becoming increasingly prevalent, being therefore necessary to learn in an\nonline manner. These conditions usually impose memory and processing time\nrestrictions, and they often turn into evolving environments where a change may\naffect the input data distribution. Such a change causes that predictive models\ntrained over these stream data become obsolete and do not adapt suitably to new\ndistributions. Specially in these non-stationary scenarios, there is a pressing\nneed for new algorithms that adapt to these changes as fast as possible, while\nmaintaining good performance scores. Unfortunately, most off-the-shelf\nclassification models need to be retrained if they are used in changing\nenvironments, and fail to scale properly. Spiking Neural Networks have revealed\nthemselves as one of the most successful approaches to model the behavior and\nlearning potential of the brain, and exploit them to undertake practical online\nlearning tasks. Besides, some specific flavors of Spiking Neural Networks can\novercome the necessity of retraining after a drift occurs. This work intends to\nmerge both fields by serving as a comprehensive overview, motivating further\ndevelopments that embrace Spiking Neural Networks for online learning\nscenarios, and being a friendly entry point for non-experts.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 09:18:28 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Lobo", "Jesus L.", ""], ["Del Ser", "Javier", ""], ["Bifet", "Albert", ""], ["Kasabov", "Nikola", ""]]}, {"id": "1908.08021", "submitter": "Xavier Porte", "authors": "Xavier Porte, Louis Andreoli, Maxime Jacquot, Laurent Larger, Daniel\n  Brunner", "title": "Reservoir-size dependent learning in analogue neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of artificial neural networks in hardware substrates is a\nmajor interdisciplinary enterprise. Well suited candidates for physical\nimplementations must combine nonlinear neurons with dedicated and efficient\nhardware solutions for both connectivity and training. Reservoir computing\naddresses the problems related with the network connectivity and training in an\nelegant and efficient way. However, important questions regarding impact of\nreservoir size and learning routines on the convergence-speed during learning\nremain unaddressed. Here, we study in detail the learning process of a recently\ndemonstrated photonic neural network based on a reservoir. We use a greedy\nalgorithm to train our neural network for the task of chaotic signals\nprediction and analyze the learning-error landscape. Our results unveil\nfundamental properties of the system's optimization hyperspace. Particularly,\nwe determine the convergence speed of learning as a function of reservoir size\nand find exceptional, close to linear scaling. This linear dependence, together\nwith our parallel diffractive coupling, represent optimal scaling conditions\nfor our photonic neural network scheme.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 14:56:03 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Porte", "Xavier", ""], ["Andreoli", "Louis", ""], ["Jacquot", "Maxime", ""], ["Larger", "Laurent", ""], ["Brunner", "Daniel", ""]]}, {"id": "1908.08024", "submitter": "Anup Das", "authors": "Anup Das and Yuefeng Wu and Khanh Huynh and Francesco Dell'Anna and\n  Francky Catthoor and Siebren Schaafsma", "title": "Mapping of Local and Global Synapses on Spiking Neuromorphic Hardware", "comments": "17 pages, 7 figures, published in 2018 Design, Automation & Test in\n  Europe Conference & Exhibition (DATE)", "journal-ref": null, "doi": "10.23919/DATE.2018.8342201", "report-no": null, "categories": "q-bio.NC cs.ET cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking Neural Networks (SNNs) are widely deployed to solve complex pattern\nrecognition, function approximation and image classification tasks. With the\ngrowing size and complexity of these networks, hardware implementation becomes\nchallenging because scaling up the size of a single array (crossbar) of fully\nconnected neurons is no longer feasible due to strict energy budget. Modern\nneromorphic hardware integrates small-sized crossbars with time-multiplexed\ninterconnects. Partitioning SNNs becomes essential in order to map them on\nneuromorphic hardware with the major aim to reduce the global communication\nlatency and energy overhead. To achieve this goal, we propose our instantiation\nof particle swarm optimization, which partitions SNNs into local synapses\n(mapped on crossbars) and global synapses (mapped on time-multiplexed\ninterconnects), with the objective of reducing spike communication on the\ninterconnect. This improves latency, power consumption as well as application\nperformance by reducing inter-spike interval distortion and spike disorders.\nOur framework is implemented in Python, interfacing CARLsim, a GPU-accelerated\napplication-level spiking neural network simulator with an extended version of\nNoxim, for simulating time-multiplexed interconnects. Experiments are conducted\nwith realistic and synthetic SNN-based applications with different computation\nmodels, topologies and spike coding schemes. Using power numbers from in-house\nneuromorphic chips, we demonstrate significant reductions in energy consumption\nand spike latency over PACMAN, the widely-used partitioning technique for SNNs\non SpiNNaker.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 23:28:35 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Das", "Anup", ""], ["Wu", "Yuefeng", ""], ["Huynh", "Khanh", ""], ["Dell'Anna", "Francesco", ""], ["Catthoor", "Francky", ""], ["Schaafsma", "Siebren", ""]]}, {"id": "1908.08026", "submitter": "David Shriver", "authors": "David Shriver, Dong Xu, Sebastian Elbaum, Matthew B. Dwyer", "title": "Refactoring Neural Networks for Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are growing in capability and applicability. Their\neffectiveness has led to their use in safety critical and autonomous systems,\nyet there is a dearth of cost-effective methods available for reasoning about\nthe behavior of a DNN. In this paper, we seek to expand the applicability and\nscalability of existing DNN verification techniques through DNN refactoring. A\nDNN refactoring defines (a) the transformation of the DNN's architecture, i.e.,\nthe number and size of its layers, and (b) the distillation of the learned\nrelationships between the input features and function outputs of the original\nto train the transformed network. Unlike with traditional code refactoring, DNN\nrefactoring does not guarantee functional equivalence of the two networks, but\nrather it aims to preserve the accuracy of the original network while producing\na simpler network that is amenable to more efficient property verification. We\npresent an automated framework for DNN refactoring, and demonstrate its\npotential effectiveness through three case studies on networks used in\nautonomous systems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 21:51:05 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Shriver", "David", ""], ["Xu", "Dong", ""], ["Elbaum", "Sebastian", ""], ["Dwyer", "Matthew B.", ""]]}, {"id": "1908.08035", "submitter": "Yunguan Fu", "authors": "Yunguan Fu, Maria R. Robu, Bongjin Koo, Crispin Schneider, Stijn van\n  Laarhoven, Danail Stoyanov, Brian Davidson, Matthew J. Clarkson, Yipeng Hu", "title": "More unlabelled data or label more data? A study on semi-supervised\n  laparoscopic image segmentation", "comments": "Accepted to MICCAI MIL3ID 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving a semi-supervised image segmentation task has the option of adding\nmore unlabelled images, labelling the unlabelled images or combining both, as\nneither image acquisition nor expert labelling can be considered trivial in\nmost clinical applications. With a laparoscopic liver image segmentation\napplication, we investigate the performance impact by altering the quantities\nof labelled and unlabelled training data, using a semi-supervised segmentation\nalgorithm based on the mean teacher learning paradigm. We first report a\nsignificantly higher segmentation accuracy, compared with supervised learning.\nInterestingly, this comparison reveals that the training strategy adopted in\nthe semi-supervised algorithm is also responsible for this observed\nimprovement, in addition to the added unlabelled data. We then compare\ndifferent combinations of labelled and unlabelled data set sizes for training\nsemi-supervised segmentation networks, to provide a quantitative example of the\npractically useful trade-off between the two data planning strategies in this\nsurgical guidance application.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:54:58 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Fu", "Yunguan", ""], ["Robu", "Maria R.", ""], ["Koo", "Bongjin", ""], ["Schneider", "Crispin", ""], ["van Laarhoven", "Stijn", ""], ["Stoyanov", "Danail", ""], ["Davidson", "Brian", ""], ["Clarkson", "Matthew J.", ""], ["Hu", "Yipeng", ""]]}, {"id": "1908.08036", "submitter": "Yun-Cheng Tsai", "authors": "Yun-Cheng Tsai, Chun-Chieh Wang", "title": "Deep Reinforcement Learning for Foreign Exchange Trading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning can interact with the environment and is suitable for\napplications in decision control systems. Therefore, we used the reinforcement\nlearning method to establish a foreign exchange transaction, avoiding the\nlong-standing problem of unstable trends in deep learning predictions. In the\nsystem design, we optimized the Sure-Fire statistical arbitrage policy, set\nthree different actions, encoded the continuous price over a period of time\ninto a heat-map view of the Gramian Angular Field (GAF) and compared the Deep Q\nLearning (DQN) and Proximal Policy Optimization (PPO) algorithms. To test\nfeasibility, we analyzed three currency pairs, namely EUR/USD, GBP/USD, and\nAUD/USD. We trained the data in units of four hours from 1 August 2018 to 30\nNovember 2018 and tested model performance using data between 1 December 2018\nand 31 December 2018. The test results of the various models indicated that\nfavorable investment performance was achieved as long as the model was able to\nhandle complex and random processes and the state was able to describe the\nenvironment, validating the feasibility of reinforcement learning in the\ndevelopment of trading strategies.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 01:55:36 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 12:54:33 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Tsai", "Yun-Cheng", ""], ["Wang", "Chun-Chieh", ""]]}, {"id": "1908.08037", "submitter": "Shalin Shah", "authors": "Shalin Shah, Venkataramana Kini", "title": "Hebbian Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning has recently been successfully used to create vector\nrepresentations of entities in language learning, recommender systems and in\nsimilarity learning. Graph embeddings exploit the locality structure of a graph\nand generate embeddings for nodes which could be words in a language, products\nof a retail website; and the nodes are connected based on a context window. In\nthis paper, we consider graph embeddings with an error-free associative\nlearning update rule, which models the embedding vector of node as a non-convex\nGaussian mixture of the embeddings of the nodes in its immediate vicinity with\nsome constant variance that is reduced as iterations progress. It is very easy\nto parallelize our algorithm without any form of shared memory, which makes it\npossible to use it on very large graphs with a much higher dimensionality of\nthe embeddings. We study the efficacy of proposed method on several benchmark\ndata sets and favorably compare with state of the art methods. Further,\nproposed method is applied to generate relevant recommendations for a large\nretailer.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 02:45:43 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 20:55:07 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 23:28:36 GMT"}, {"version": "v4", "created": "Thu, 20 Feb 2020 21:25:36 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Shah", "Shalin", ""], ["Kini", "Venkataramana", ""]]}, {"id": "1908.08044", "submitter": "Jian Yao", "authors": "Jian Yao and Ahmad Al-Dahle", "title": "Coarse-to-fine Optimization for Speech Enhancement", "comments": null, "journal-ref": "Interspeech 2019", "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the coarse-to-fine optimization for the task of\nspeech enhancement. Cosine similarity loss [1] has proven to be an effective\nmetric to measure similarity of speech signals. However, due to the large\nvariance of the enhanced speech with even the same cosine similarity loss in\nhigh dimensional space, a deep neural network learnt with this loss might not\nbe able to predict enhanced speech with good quality. Our coarse-to-fine\nstrategy optimizes the cosine similarity loss for different granularities so\nthat more constraints are added to the prediction from high dimension to\nrelatively low dimension. In this way, the enhanced speech will better resemble\nthe clean speech. Experimental results show the effectiveness of our proposed\ncoarse-to-fine optimization in both discriminative models and generative\nmodels. Moreover, we apply the coarse-to-fine strategy to the adversarial loss\nin generative adversarial network (GAN) and propose dynamic perceptual loss,\nwhich dynamically computes the adversarial loss from coarse resolution to fine\nresolution. Dynamic perceptual loss further improves the accuracy and achieves\nstate-of-the-art results compared with other generative models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 17:51:29 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Yao", "Jian", ""], ["Al-Dahle", "Ahmad", ""]]}, {"id": "1908.08045", "submitter": "Miles Cranmer", "authors": "Miles D. Cranmer, Richard Galvez, Lauren Anderson, David N. Spergel,\n  Shirley Ho", "title": "Modeling the Gaia Color-Magnitude Diagram with Bayesian Neural Flows to\n  Constrain Distance Estimates", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate an algorithm for learning a flexible color-magnitude diagram\nfrom noisy parallax and photometry measurements using a normalizing flow, a\ndeep neural network capable of learning an arbitrary multi-dimensional\nprobability distribution. We present a catalog of 640M photometric distance\nposteriors to nearby stars derived from this data-driven model using Gaia DR2\nphotometry and parallaxes. Dust estimation and dereddening is done iteratively\ninside the model and without prior distance information, using the Bayestar\nmap. The signal-to-noise (precision) of distance measurements improves on\naverage by more than 48% over the raw Gaia data, and we also demonstrate how\nthe accuracy of distances have improved over other models, especially in the\nnoisy-parallax regime. Applications are discussed, including significantly\nimproved Milky Way disk separation and substructure detection. We conclude with\na discussion of future work, which exploits the normalizing flow architecture\nto allow us to exactly marginalize over missing photometry, enabling the\ninclusion of many surveys without losing coverage.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 18:00:00 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Cranmer", "Miles D.", ""], ["Galvez", "Richard", ""], ["Anderson", "Lauren", ""], ["Spergel", "David N.", ""], ["Ho", "Shirley", ""]]}, {"id": "1908.08054", "submitter": "Keri McKiernan", "authors": "Keri A. McKiernan, Erik Davis, M. Sohaib Alam, Chad Rigetti", "title": "Automated quantum programming via reinforcement learning for\n  combinatorial optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general method for incentive-based programming of hybrid\nquantum-classical computing systems using reinforcement learning, and apply\nthis to solve combinatorial optimization problems on both simulated and real\ngate-based quantum computers. Relative to a set of randomly generated problem\ninstances, agents trained through reinforcement learning techniques are capable\nof producing short quantum programs which generate high quality solutions on\nboth types of quantum resources. We observe generalization to problems outside\nof the training set, as well as generalization from the simulated quantum\nresource to the physical quantum resource.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 18:00:03 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["McKiernan", "Keri A.", ""], ["Davis", "Erik", ""], ["Alam", "M. Sohaib", ""], ["Rigetti", "Chad", ""]]}, {"id": "1908.08071", "submitter": "Ali Hatamizadeh", "authors": "Ali Hatamizadeh, Demetri Terzopoulos and Andriy Myronenko", "title": "End-to-End Boundary Aware Networks for Medical Image Segmentation", "comments": "Accepted to MICCAI Machine Learning in Medical Imaging (MLMI 2019)", "journal-ref": "MLMI 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully convolutional neural networks (CNNs) have proven to be effective at\nrepresenting and classifying textural information, thus transforming image\nintensity into output class masks that achieve semantic image segmentation. In\nmedical image analysis, however, expert manual segmentation often relies on the\nboundaries of anatomical structures of interest. We propose boundary aware CNNs\nfor medical image segmentation. Our networks are designed to account for organ\nboundary information, both by providing a special network edge branch and\nedge-aware loss terms, and they are trainable end-to-end. We validate their\neffectiveness on the task of brain tumor segmentation using the BraTS 2018\ndataset. Our experiments reveal that our approach yields more accurate\nsegmentation results, which makes it promising for more extensive application\nto medical image segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 18:10:48 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 20:41:57 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Hatamizadeh", "Ali", ""], ["Terzopoulos", "Demetri", ""], ["Myronenko", "Andriy", ""]]}, {"id": "1908.08082", "submitter": "Tim Capes", "authors": "Tim Capes, Vishal Raheja, Mete Kemertas, Iqbal Mohomed", "title": "Dynamic Scheduling of MPI-based Distributed Deep Learning Training Jobs", "comments": null, "journal-ref": "Published at MLSys Workshop @ NeurIPS 2018\n  (https://nips.cc/Conferences/2018/Schedule?showEvent=10919) December 7th,\n  2018", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a general trend towards solving problems suited to deep learning\nwith more complex deep learning architectures trained on larger training sets.\nThis requires longer compute times and greater data parallelization or model\nparallelization. Both data and model parallelism have been historically faster\nin parameter server architectures, but data parallelism is starting to be\nfaster in ring architectures due to algorithmic improvements. In this paper, we\nanalyze the math behind ring architectures and make an informed adaptation of\ndynamic scheduling to ring architectures. To do so, we formulate a non-convex,\nnon-linear, NP-hard integer programming problem and a new efficient doubling\nheuristic for its solution. We build upon Horovod: an open source ring\narchitecture framework over TensorFlow. We show that Horovod jobs have a low\ncost to stop and restart and that stopping and restarting ring architecture\njobs leads to faster completion times. These two facts make dynamic scheduling\nof ring architecture jobs feasible. Lastly, we simulate a scheduler using these\nruns and show a more than halving of average job time on some workload\npatterns.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 18:49:26 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Capes", "Tim", ""], ["Raheja", "Vishal", ""], ["Kemertas", "Mete", ""], ["Mohomed", "Iqbal", ""]]}, {"id": "1908.08098", "submitter": "Waheed Bajwa", "authors": "Zhixiong Yang and Waheed U. Bajwa", "title": "BRIDGE: Byzantine-resilient Decentralized Gradient Descent", "comments": "18 pages, 1 figure, 1 table; preprint of a conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized optimization techniques are increasingly being used to learn\nmachine learning models from data distributed over multiple locations without\ngathering the data at any one location. Unfortunately, methods that are\ndesigned for faultless networks typically fail in the presence of node\nfailures. In particular, Byzantine failures---corresponding to the scenario in\nwhich faulty/compromised nodes are allowed to arbitrarily deviate from an\nagreed-upon protocol---are the hardest to safeguard against in decentralized\nsettings. This paper introduces a Byzantine-resilient decentralized gradient\ndescent (BRIDGE) method for decentralized learning that, when compared to\nexisting works, is more efficient and scalable in higher-dimensional settings\nand that is deployable in networks having topologies that go beyond the star\ntopology. The main contributions of this work include theoretical analysis of\nBRIDGE for strongly convex learning objectives and numerical experiments\ndemonstrating the efficacy of BRIDGE for both convex and nonconvex learning\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 19:49:56 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Yang", "Zhixiong", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1908.08118", "submitter": "Yang Li", "authors": "Yang Li, Shihao Ji", "title": "Neural Plasticity Networks", "comments": "Published as a conference paper at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural plasticity is an important functionality of human brain, in which\nnumber of neurons and synapses can shrink or expand in response to stimuli\nthroughout the span of life. We model this dynamic learning process as an\n$L_0$-norm regularized binary optimization problem, in which each unit of a\nneural network (e.g., weight, neuron or channel, etc.) is attached with a\nstochastic binary gate, whose parameters determine the level of activity of a\nunit in the network. At the beginning, only a small portion of binary gates\n(therefore the corresponding neurons) are activated, while the remaining\nneurons are in a hibernation mode. As the learning proceeds, some neurons might\nbe activated or deactivated if doing so can be justified by the cost-benefit\ntradeoff measured by the $L_0$-norm regularized objective. As the training gets\nmature, the probability of transition between activation and deactivation will\ndiminish until a final hardening stage. We demonstrate that all of these\nlearning dynamics can be modulated by a single parameter $k$ seamlessly. Our\nneural plasticity network (NPN) can prune or expand a network depending on the\ninitial capacity of network provided by the user; it also unifies dropout (when\n$k=0$), traditional training of DNNs (when $k=\\infty$) and interpolates between\nthese two. To the best of our knowledge, this is the first learning framework\nthat unifies network sparsification and network expansion in an end-to-end\ntraining pipeline. Extensive experiments on synthetic dataset and multiple\nimage classification benchmarks demonstrate the superior performance of NPN. We\nshow that both network sparsification and network expansion can yield compact\nmodels of similar architectures, while retaining competitive accuracies of the\noriginal networks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 18:57:30 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 17:45:55 GMT"}, {"version": "v3", "created": "Sun, 2 May 2021 03:23:16 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Li", "Yang", ""], ["Ji", "Shihao", ""]]}, {"id": "1908.08142", "submitter": "Cuong Nguyen", "authors": "Anh T. Tran, Cuong V. Nguyen, Tal Hassner", "title": "Transferability and Hardness of Supervised Classification Tasks", "comments": "This paper is published at the International Conference on Computer\n  Vision (ICCV) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for estimating the difficulty and transferability\nof supervised classification tasks. Unlike previous work, our approach is\nsolution agnostic and does not require or assume trained models. Instead, we\nestimate these values using an information theoretic approach: treating\ntraining labels as random variables and exploring their statistics. When\ntransferring from a source to a target task, we consider the conditional\nentropy between two such variables (i.e., label assignments of the two tasks).\nWe show analytically and empirically that this value is related to the loss of\nthe transferred model. We further show how to use this value to estimate task\nhardness. We test our claims extensively on three large scale data sets --\nCelebA (40 tasks), Animals with Attributes 2 (85 tasks), and Caltech-UCSD Birds\n200 (312 tasks) -- together representing 437 classification tasks. We provide\nresults showing that our hardness and transferability estimates are strongly\ncorrelated with empirical hardness and transferability. As a case study, we\ntransfer a learned face recognition model to CelebA attribute classification\ntasks, showing state of the art accuracy for tasks estimated to be highly\ntransferable.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 23:35:48 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Tran", "Anh T.", ""], ["Nguyen", "Cuong V.", ""], ["Hassner", "Tal", ""]]}, {"id": "1908.08145", "submitter": "Anirvan M. Sengupta", "authors": "Alexander Genkin, Anirvan M. Sengupta and Dmitri Chklovskii", "title": "A Neural Network for Semi-Supervised Learning on Manifolds", "comments": "12 pages, 4 figures, accepted in ICANN 2019", "journal-ref": "Artificial Neural Networks and Machine Learning - ICANN 2019 (pp.\n  375-386). Springer International Publishing", "doi": "10.1007/978-3-030-30487-4_30", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning algorithms typically construct a weighted graph of\ndata points to represent a manifold. However, an explicit graph representation\nis problematic for neural networks operating in the online setting. Here, we\npropose a feed-forward neural network capable of semi-supervised learning on\nmanifolds without using an explicit graph representation. Our algorithm uses\nchannels that represent localities on the manifold such that correlations\nbetween channels represent manifold structure. The proposed neural network has\ntwo layers. The first layer learns to build a representation of low-dimensional\nmanifolds in the input data as proposed recently in [8]. The second learns to\nclassify data using both occasional supervision and similarity of the manifold\nrepresentation of the data. The channel carrying label information for the\nsecond layer is assumed to be \"silent\" most of the time. Learning in both\nlayers is Hebbian, making our network design biologically plausible. We\nexperimentally demonstrate the effect of semi-supervised learning on\nnon-trivial manifolds.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 23:43:30 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Genkin", "Alexander", ""], ["Sengupta", "Anirvan M.", ""], ["Chklovskii", "Dmitri", ""]]}, {"id": "1908.08168", "submitter": "Tucker Hybinette Balch", "authors": "David Byrd and Tucker Hybinette Balch", "title": "Intra-day Equity Price Prediction using Deep Learning as a Measure of\n  Market Efficiency", "comments": "In journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In finance, the weak form of the Efficient Market Hypothesis asserts that\nhistoric stock price and volume data cannot inform predictions of future\nprices. In this paper we show that, to the contrary, future intra-day stock\nprices could be predicted effectively until 2009. We demonstrate this using two\ndifferent profitable machine learning-based trading strategies. However, the\neffectiveness of both approaches diminish over time, and neither of them are\nprofitable after 2009. We present our implementation and results in detail for\nthe period 2003-2017 and propose a novel idea: the use of such flexible machine\nlearning methods as an objective measure of relative market efficiency. We\nconclude with a candidate explanation, comparing our returns over time with\nhigh-frequency trading volume, and suggest concrete steps for further\ninvestigation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 02:06:27 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Byrd", "David", ""], ["Balch", "Tucker Hybinette", ""]]}, {"id": "1908.08169", "submitter": "Yayong Li", "authors": "Yayong Li, Jie Yin, Ling Chen", "title": "SEAL: Semi-supervised Adversarial Active Learning on Attributed Graphs", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.3009682", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) on attributed graphs has received increasing attention\nwith the prevalence of graph-structured data. Although AL has been widely\nstudied for alleviating label sparsity issues with the conventional non-related\ndata, how to make it effective over attributed graphs remains an open research\nquestion. Existing AL algorithms on graphs attempt to reuse the classic AL\nquery strategies designed for non-related data. However, they suffer from two\nmajor limitations. First, different AL query strategies calculated in distinct\nscoring spaces are often naively combined to determine which nodes to be\nlabelled. Second, the AL query engine and the learning of the classifier are\ntreated as two separating processes, resulting in unsatisfactory performance.\nIn this paper, we propose a SEmi-supervised Adversarial active Learning (SEAL)\nframework on attributed graphs, which fully leverages the representation power\nof deep neural networks and devises a novel AL query strategy in an adversarial\nway. Our framework learns two adversarial components: a graph embedding network\nthat encodes both the unlabelled and labelled nodes into a latent space,\nexpecting to trick the discriminator to regard all nodes as already labelled,\nand a semi-supervised discriminator network that distinguishes the unlabelled\nfrom the existing labelled nodes in the latent space. The divergence score,\ngenerated by the discriminator in a unified latent space, serves as the\ninformativeness measure to actively select the most informative node to be\nlabelled by an oracle. The two adversarial components form a closed loop to\nmutually and simultaneously reinforce each other towards enhancing the active\nlearning performance. Extensive experiments on four real-world networks\nvalidate the effectiveness of the SEAL framework with superior performance\nimprovements to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 02:07:32 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 02:38:14 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Li", "Yayong", ""], ["Yin", "Jie", ""], ["Chen", "Ling", ""]]}, {"id": "1908.08176", "submitter": "Yuren Zhou", "authors": "Yuren Zhou, Clement Lork, Wen-Tai Li, Chau Yuen, Yeong Ming Keow", "title": "Benchmarking air-conditioning energy performance of residential rooms\n  based on regression and clustering techniques", "comments": "38 pages (single column), 7 figures, 6 tables. This manuscript is\n  accepted for publication in Applied Energy 253 (2019): 113548. Please refer\n  to the published version at\n  https://www.sciencedirect.com/science/article/pii/S030626191931222X", "journal-ref": "Applied Energy 253 (2019): 113548", "doi": "10.1016/j.apenergy.2019.113548", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air conditioning (AC) accounts for a critical portion of the global energy\nconsumption. To improve its energy performance, it is important to fairly\nbenchmark its energy performance and provide the evaluation feedback to users.\nHowever, this task has not been well tackled in the residential sector. In this\npaper, we propose a data-driven approach to fairly benchmark the AC energy\nperformance of residential rooms. First, regression model is built for each\nbenchmarked room so that its power consumption can be predicted given different\nweather conditions and AC settings. Then, all the rooms are clustered based on\ntheir areas and usual AC temperature set points. Lastly, within each cluster,\nrooms are benchmarked based on their predicted power consumption under uniform\nweather conditions and AC settings. A real-world case study was conducted with\ndata collected from 44 residential rooms. Results show that the constructed\nregression models have an average prediction accuracy of 85.1% in\ncross-validation tests, and support vector regression with Gaussian kernel is\nthe overall most suitable model structure for building the regression model. In\nthe clustering step, 44 rooms are successfully clustered into seven clusters.\nBy comparing the benchmarking scores generated by the proposed approach with\ntwo sets of scores computed from historical power consumption data, we\ndemonstrate that the proposed approach is able to eliminate the influences of\nroom areas, weather conditions, and AC settings on the benchmarking results.\nTherefore, the proposed benchmarking approach is valid and fair. As a\nby-product, the approach is also shown to be useful to investigate how room\nareas, weather conditions, and AC settings affect the AC power consumption of\nrooms in real life.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 02:39:35 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 08:59:20 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Zhou", "Yuren", ""], ["Lork", "Clement", ""], ["Li", "Wen-Tai", ""], ["Yuen", "Chau", ""], ["Keow", "Yeong Ming", ""]]}, {"id": "1908.08184", "submitter": "Takahiro Kawamura Dr.", "authors": "Takahiro Kawamura, Shusaku Egami, Koutarou Tamura, Yasunori Hokazono,\n  Takanori Ugai, Yusuke Koyanagi, Fumihito Nishino, Seiji Okajima, Katsuhiko\n  Murakami, Kunihiko Takamatsu, Aoi Sugiura, Shun Shiramatsu, Shawn Zhang, and\n  Kouji Kozaki", "title": "Report on the First Knowledge Graph Reasoning Challenge 2018 -- Toward\n  the eXplainable AI System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A new challenge for knowledge graph reasoning started in 2018. Deep learning\nhas promoted the application of artificial intelligence (AI) techniques to a\nwide variety of social problems. Accordingly, being able to explain the reason\nfor an AI decision is becoming important to ensure the secure and safe use of\nAI techniques. Thus, we, the Special Interest Group on Semantic Web and\nOntology of the Japanese Society for AI, organized a challenge calling for\ntechniques that reason and/or estimate which characters are criminals while\nproviding a reasonable explanation based on an open knowledge graph of a\nwell-known Sherlock Holmes mystery story. This paper presents a summary report\nof the first challenge held in 2018, including the knowledge graph\nconstruction, the techniques proposed for reasoning and/or estimation, the\nevaluation metrics, and the results. The first prize went to an approach that\nformalized the problem as a constraint satisfaction problem and solved it using\na lightweight formal method; the second prize went to an approach that used\nSPARQL and rules; the best resource prize went to a submission that constructed\nword embedding of characters from all sentences of Sherlock Holmes novels; and\nthe best idea prize went to a discussion multi-agents model. We conclude this\npaper with the plans and issues for the next challenge in 2019.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 03:27:48 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Kawamura", "Takahiro", ""], ["Egami", "Shusaku", ""], ["Tamura", "Koutarou", ""], ["Hokazono", "Yasunori", ""], ["Ugai", "Takanori", ""], ["Koyanagi", "Yusuke", ""], ["Nishino", "Fumihito", ""], ["Okajima", "Seiji", ""], ["Murakami", "Katsuhiko", ""], ["Takamatsu", "Kunihiko", ""], ["Sugiura", "Aoi", ""], ["Shiramatsu", "Shun", ""], ["Zhang", "Shawn", ""], ["Kozaki", "Kouji", ""]]}, {"id": "1908.08187", "submitter": "Daniel Sonntag", "authors": "Fabrizio Nunnari and Daniel Sonntag", "title": "A CNN toolbox for skin cancer classification", "comments": "DFKI Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a software toolbox for the configuration of deep neural networks\nin the domain of skin cancer classification. The implemented software\narchitecture allows developers to quickly set up new convolutional neural\nnetwork (CNN) architectures and hyper-parameter configurations. At the same\ntime, the user interface, manageable as a simple spreadsheet, allows\nnon-technical users to explore different configuration settings that need to be\nexplored when switching to different data sets. In future versions, meta\nleaning frameworks can be added, or AutoML systems that continuously improve\nover time. Preliminary results, conducted with two CNNs in the context melanoma\ndetection on dermoscopic images, quantify the impact of image augmentation,\nimage resolution, and rescaling filter on the overall detection performance and\ntraining time.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 13:27:58 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Nunnari", "Fabrizio", ""], ["Sonntag", "Daniel", ""]]}, {"id": "1908.08200", "submitter": "Prathamesh Mayekar", "authors": "Prathamesh Mayekar and Himanshu Tyagi", "title": "RATQ: A Universal Fixed-Length Quantizer for Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Rotated Adaptive Tetra-iterated Quantizer (RATQ), a fixed-length\nquantizer for gradients in first order stochastic optimization. RATQ is easy to\nimplement and involves only a Hadamard transform computation and adaptive\nuniform quantization with appropriately chosen dynamic ranges. For noisy\ngradients with almost surely bounded Euclidean norms, we establish an\ninformation theoretic lower bound for optimization accuracy using finite\nprecision gradients and show that RATQ almost attains this lower bound.\n  For mean square bounded noisy gradients, we use a gain-shape quantizer which\nseparately quantizes the Euclidean norm and uses RATQ to quantize the\nnormalized unit norm vector. We establish lower bounds for performance of any\noptimization procedure and shape quantizer, when used with a uniform gain\nquantizer. Finally, we propose an adaptive quantizer for gain which when used\nwith RATQ for shape quantizer outperforms uniform gain quantization and is, in\nfact, close to optimal.\n  As a by-product, we show that our fixed-length quantizer RATQ has almost the\nsame performance as the optimal variable-length quantizers for distributed mean\nestimation. Also, we obtain an efficient quantizer for Gaussian vectors which\nattains a rate very close to the Gaussian rate-distortion function and is, in\nfact, universal for subgaussian input vectors.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 04:57:22 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 04:56:31 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 16:26:36 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Mayekar", "Prathamesh", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "1908.08204", "submitter": "Yong-Ho Yoo", "authors": "Yong-Ho Yoo, Ue-Hwan Kim, and Jong-Hwan Kim", "title": "Convolutional Recurrent Reconstructive Network for Spatiotemporal\n  Anomaly Detection in Solder Paste Inspection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface mount technology (SMT) is a process for producing printed circuit\nboards. Solder paste printer (SPP), package mounter, and solder reflow oven are\nused for SMT. The board on which the solder paste is deposited from the SPP is\nmonitored by solder paste inspector (SPI). If SPP malfunctions due to the\nprinter defects, the SPP produces defective products, and then abnormal\npatterns are detected by SPI. In this paper, we propose a convolutional\nrecurrent reconstructive network (CRRN), which decomposes the anomaly patterns\ngenerated by the printer defects, from SPI data. CRRN learns only normal data\nand detects anomaly pattern through reconstruction error. CRRN consists of a\nspatial encoder (S-Encoder), a spatiotemporal encoder and decoder\n(ST-Encoder-Decoder), and a spatial decoder (S-Decoder). The ST-Encoder-Decoder\nconsists of multiple convolutional spatiotemporal memories (CSTMs) with\nST-Attention mechanism. CSTM is developed to extract spatiotemporal patterns\nefficiently. Additionally, a spatiotemporal attention (ST-Attention) mechanism\nis designed to facilitate transmitting information from the ST-Encoder to the\nST-Decoder, which can solve the long-term dependency problem. We demonstrate\nthe proposed CRRN outperforms the other conventional models in anomaly\ndetection. Moreover, we show the discriminative power of the anomaly map\ndecomposed by the proposed CRRN through the printer defect classification.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 05:18:41 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Yoo", "Yong-Ho", ""], ["Kim", "Ue-Hwan", ""], ["Kim", "Jong-Hwan", ""]]}, {"id": "1908.08223", "submitter": "Junghoon Seo", "authors": "Yooseung Wang, Junghoon Seo, and Taegyun Jeon", "title": "NL-LinkNet: Toward Lighter but More Accurate Road Extraction with\n  Non-Local Operations", "comments": "IEEE Geoscience and Remote Sensing Letters (2020, to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road extraction from very high resolution satellite (VHR) images is one of\nthe most important topics in the field of remote sensing. In this paper, we\npropose an efficient Non-Local LinkNet with non-local blocks that can grasp\nrelations between global features. This enables each spatial feature point to\nrefer to all other contextual information and results in more accurate road\nsegmentation. In detail, our single model without any post-processing like CRF\nrefinement, performed better than any other published state-of-the-art ensemble\nmodel in the official DeepGlobe Challenge. Moreover, our NL-LinkNet beat the\nD-LinkNet, the winner of the DeepGlobe challenge, with 43 \\% less parameters,\nless giga floating-point operations per seconds (GFLOPs) and shorter training\nconvergence time. We also present empirical analyses on the proper usages of\nnon-local blocks for the baseline model.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 06:56:57 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 06:29:12 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 10:25:37 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Wang", "Yooseung", ""], ["Seo", "Junghoon", ""], ["Jeon", "Taegyun", ""]]}, {"id": "1908.08227", "submitter": "Mahashweta Das", "authors": "Manoj Reddy Dareddy, Mahashweta Das, Hao Yang", "title": "motif2vec: Motif Aware Node Representation Learning for Heterogeneous\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a surge of interest in machine learning on graphs\nand networks with applications ranging from vehicular network design to IoT\ntraffic management to social network recommendations. Supervised machine\nlearning tasks in networks such as node classification and link prediction\nrequire us to perform feature engineering that is known and agreed to be the\nkey to success in applied machine learning. Research efforts dedicated to\nrepresentation learning, especially representation learning using deep\nlearning, has shown us ways to automatically learn relevant features from vast\namounts of potentially noisy, raw data. However, most of the methods are not\nadequate to handle heterogeneous information networks which pretty much\nrepresents most real-world data today. The methods cannot preserve the\nstructure and semantic of multiple types of nodes and links well enough,\ncapture higher-order heterogeneous connectivity patterns, and ensure coverage\nof nodes for which representations are generated. We propose a novel efficient\nalgorithm, motif2vec that learns node representations or embeddings for\nheterogeneous networks. Specifically, we leverage higher-order, recurring, and\nstatistically significant network connectivity patterns in the form of motifs\nto transform the original graph to motif graph(s), conduct biased random walk\nto efficiently explore higher order neighborhoods, and then employ\nheterogeneous skip-gram model to generate the embeddings. Unlike previous\nefforts that uses different graph meta-structures to guide the random walk, we\nuse graph motifs to transform the original network and preserve the\nheterogeneity. We evaluate the proposed algorithm on multiple real-world\nnetworks from diverse domains and against existing state-of-the-art methods on\nmulti-class node classification and link prediction tasks, and demonstrate its\nconsistent superiority over prior work.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 07:08:32 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Dareddy", "Manoj Reddy", ""], ["Das", "Mahashweta", ""], ["Yang", "Hao", ""]]}, {"id": "1908.08245", "submitter": "Tao Li", "authors": "Jiexiang Wang, Tao Li, Xiwei Zhang", "title": "Decentralized Cooperative Online Estimation With Random Observation\n  Matrices, Communication Graphs and Time Delays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze convergence of decentralized cooperative online estimation\nalgorithms by a network of multiple nodes via information exchanging in an\nuncertain environment. Each node has a linear observation of an unknown\nparameter with randomly time-varying observation matrices. The underlying\ncommunication network is modeled by a sequence of random digraphs and is\nsubjected to nonuniform random time-varying delays in channels. Each node runs\nan online estimation algorithm consisting of a consensus term taking a weighted\nsum of its own estimate and neighbours' delayed estimates, and an innovation\nterm processing its own new measurement at each time step. By stochastic\ntime-varying system, martingale convergence theories and the binomial expansion\nof random matrix products, we transform the convergence analysis of the\nalgorithm into that of the mathematical expectation of random matrix products.\nFirstly, for the delay-free case, we show that the algorithm gains can be\ndesigned properly such that all nodes' estimates converge to the true parameter\nin mean square and almost surely if the observation matrices and communication\ngraphs satisfy the stochastic spatiotemporal persistence of excitation\ncondition. Secondly, for the case with time delays, we introduce delay matrices\nto model the random time-varying communication delays between nodes. It is\nshown that under the stochastic spatio-temporal persistence of excitation\ncondition, for any given boundeddelays, proper algorithm gains can be designed\nto guarantee mean square convergence for the case with conditionally balanced\ndigraphs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 08:10:36 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 03:06:10 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 02:24:33 GMT"}, {"version": "v4", "created": "Sat, 30 Nov 2019 05:23:10 GMT"}, {"version": "v5", "created": "Wed, 18 Dec 2019 03:16:54 GMT"}, {"version": "v6", "created": "Mon, 7 Dec 2020 06:08:17 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wang", "Jiexiang", ""], ["Li", "Tao", ""], ["Zhang", "Xiwei", ""]]}, {"id": "1908.08258", "submitter": "Favour Mandanji Nyikosa", "authors": "Favour M. Nyikosa, Michael A. Osborne, Stephen J. Roberts", "title": "Adaptive Configuration Oracle for Online Portfolio Selection Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial markets are complex environments that produce enormous amounts of\nnoisy and non-stationary data. One fundamental problem is online portfolio\nselection, the goal of which is to exploit this data to sequentially select\nportfolios of assets to achieve positive investment outcomes while managing\nrisks. Various algorithms have been proposed for solving this problem in fields\nsuch as finance, statistics and machine learning, among others. Most of the\nmethods have parameters that are estimated from backtests for good performance.\nSince these algorithms operate on non-stationary data that reflects the\ncomplexity of financial markets, we posit that adaptively tuning these\nparameters in an intelligent manner is a remedy for dealing with this\ncomplexity. In this paper, we model the mapping between the parameter space and\nthe space of performance metrics using a Gaussian process prior. We then\npropose an oracle based on adaptive Bayesian optimization for automatically and\nadaptively configuring online portfolio selection methods. We test the efficacy\nof our solution on algorithms operating on equity and index data from various\nmarkets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 08:46:55 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Nyikosa", "Favour M.", ""], ["Osborne", "Michael A.", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1908.08284", "submitter": "Jose Antonio Sanchez", "authors": "Jos\\'e Antonio S\\'anchez Rodr\\'iguez, Jui-Chieh Wu, Mustafa\n  Khandwawala", "title": "Two-Stage Session-based Recommendations with Candidate Rank Embeddings", "comments": "Accepted in the Fashion RECSYS workshop recsysXfashion'19, September\n  20, 2019, Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in Session-based recommender systems have gained attention\ndue to their potential of providing real-time personalized recommendations with\nhigh recall, especially when compared to traditional methods like matrix\nfactorization and item-based collaborative filtering. Nowadays, two of the most\nrecent methods are Short-Term Attention/Memory Priority Model for Session-based\nRecommendation (STAMP) and Neural Attentive Session-based Recommendation\n(NARM). However, when these two methods were applied in the similar-item\nrecommendation dataset of Zalando (Fashion-Similar), they did not work\nout-of-the-box compared to a simple Collaborative-Filtering approach. Aiming\nfor improving the similar-item recommendation, we propose to concentrate\nefforts on enhancing the rank of the few most relevant items from the original\nrecommendations, by employing the information of the session of the user\nencoded by an attention network. The efficacy of this strategy was confirmed\nwhen using a novel Candidate Rank Embedding that encodes the global ranking\ninformation of each candidate in the re-ranking process. Experimental results\nin Fashion-Similar show significant improvements over the baseline on Recall\nand MRR at 20, as well as improvements in Click Through Rate based on an online\ntest. Additionally, it is important to point out from the evaluation that was\nperformed the potential of this method on the next click prediction problem\nbecause when applied to STAMP and NARM, it improves the Recall and MRR at 20 on\ntwo publicly available real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 09:48:34 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Rodr\u00edguez", "Jos\u00e9 Antonio S\u00e1nchez", ""], ["Wu", "Jui-Chieh", ""], ["Khandwawala", "Mustafa", ""]]}, {"id": "1908.08286", "submitter": "Hao Ni", "authors": "Shujian Liao, Terry Lyons, Weixin Yang, and Hao Ni", "title": "Learning stochastic differential equations using RNN with log signature\n  features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes to the challenge of learning a function on streamed\nmultimodal data through evaluation. The core of the result of our paper is the\ncombination of two quite different approaches to this problem. One comes from\nthe mathematically principled technology of signatures and log-signatures as\nrepresentations for streamed data, while the other draws on the techniques of\nrecurrent neural networks (RNN). The ability of the former to manage high\nsample rate streams and the latter to manage large scale nonlinear interactions\nallows hybrid algorithms that are easy to code, quicker to train, and of lower\ncomplexity for a given accuracy.\n  We illustrate the approach by approximating the unknown functional as a\ncontrolled differential equation. Linear functionals on solutions of controlled\ndifferential equations are the natural universal class of functions on data\nstreams. Following this approach, we propose a hybrid Logsig-RNN algorithm that\nlearns functionals on streamed data. By testing on various datasets, i.e.\nsynthetic data, NTU RGB+D 120 skeletal action data, and Chalearn2013 gesture\ndata, our algorithm achieves the outstanding accuracy with superior efficiency\nand robustness.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 09:58:58 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 18:10:13 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Liao", "Shujian", ""], ["Lyons", "Terry", ""], ["Yang", "Weixin", ""], ["Ni", "Hao", ""]]}, {"id": "1908.08314", "submitter": "Benjamin Donnot", "authors": "Benjamin Donnot (TAU), Balthazar Donon (TAU), Isabelle Guyon (TAU),\n  Zhengying Liu (TAU), Antoine Marot, Patrick Panciatici, Marc Schoenauer (TAU)", "title": "LEAP nets for power grid perturbations", "comments": null, "journal-ref": "ESANN, Apr 2019, Bruges, Belgium", "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural network embedding approach to model power\ntransmission grids, in which high voltage lines are disconnected and\nreconnected with one-another from time to time, either accidentally or\nwillfully. We call our architeture LEAP net, for Latent Encoding of Atypical\nPerturbation. Our method implements a form of transfer learning, permitting to\ntrain on a few source domains, then generalize to new target domains, without\nlearning on any example of that domain. We evaluate the viability of this\ntechnique to rapidly assess cu-rative actions that human operators take in\nemergency situations, using real historical data, from the French high voltage\npower grid.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 11:16:32 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Donnot", "Benjamin", "", "TAU"], ["Donon", "Balthazar", "", "TAU"], ["Guyon", "Isabelle", "", "TAU"], ["Liu", "Zhengying", "", "TAU"], ["Marot", "Antoine", "", "TAU"], ["Panciatici", "Patrick", "", "TAU"], ["Schoenauer", "Marc", "", "TAU"]]}, {"id": "1908.08328", "submitter": "Dietmar Jannach", "authors": "Dietmar Jannach and Michael Jugovac", "title": "Measuring the Business Value of Recommender Systems", "comments": null, "journal-ref": null, "doi": "10.1145/3370082", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender Systems are nowadays successfully used by all major web sites\n(from e-commerce to social media) to filter content and make suggestions in a\npersonalized way. Academic research largely focuses on the value of\nrecommenders for consumers, e.g., in terms of reduced information overload. To\nwhat extent and in which ways recommender systems create business value is,\nhowever, much less clear, and the literature on the topic is scattered. In this\nresearch commentary, we review existing publications on field tests of\nrecommender systems and report which business-related performance measures were\nused in such real-world deployments. We summarize common challenges of\nmeasuring the business value in practice and critically discuss the value of\nalgorithmic improvements and offline experiments as commonly done in academic\nenvironments. Overall, our review indicates that various open questions remain\nboth regarding the realistic quantification of the business effects of\nrecommenders and the performance assessment of recommendation algorithms in\nacademia.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 11:52:09 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 12:05:24 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 17:37:30 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Jannach", "Dietmar", ""], ["Jugovac", "Michael", ""]]}, {"id": "1908.08331", "submitter": "Dominique Beaini", "authors": "Dominique Beaini, Sofiane Achiche, Alexandre Duperr\\'e, Maxime Raison", "title": "Deep Green Function Convolution for Improving Saliency in Convolutional\n  Neural Networks", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": "10.1007/s00371-020-01795-8", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current saliency methods require to learn large scale regional features using\nsmall convolutional kernels, which is not possible with a simple feed-forward\nnetwork. Some methods solve this problem by using segmentation into superpixels\nwhile others downscale the image through the network and rescale it back to its\noriginal size. The objective of this paper is to show that saliency\nconvolutional neural networks (CNN) can be improved by using a Green's function\nconvolution (GFC) to extrapolate edges features into salient regions. The GFC\nacts as a gradient integrator, allowing to produce saliency features by filling\nthin edges directly inside the CNN. Hence, we propose the gradient integration\nand sum (GIS) layer that combines the edges features with the saliency\nfeatures. Using the HED and DSS architecture, we demonstrated that adding a GIS\nlayer near the network's output allows to reduce the sensitivity to the\nparameter initialization, to reduce the overfitting and to improve the\nrepeatability of the training. By simply adding a GIS layer to the\nstate-of-the-art DSS model, there is an absolute increase of 1.6% for the\nF-measure on the DUT-OMRON dataset, with only 10ms of additional computation\ntime. The GIS layer further allows the network to perform significantly better\nin the case of highly noisy images or low-brightness images. In fact, we\nobserved an F-measure improvement of 5.2% when noise was added to the dataset\nand 2.8% when the brightness was reduced. Since the GIS layer is model\nagnostic, it can be implemented into different fully convolutional networks. A\nmajor contribution of the current work is the first implementation of Green's\nfunction convolution inside a neural network, which allows the network to\noperate in the feature domain and in the gradient domain at the same time, thus\nimproving the regional representation via edge filling.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:14:26 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 04:07:46 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Beaini", "Dominique", ""], ["Achiche", "Sofiane", ""], ["Duperr\u00e9", "Alexandre", ""], ["Raison", "Maxime", ""]]}, {"id": "1908.08338", "submitter": "Tania Panayiotou", "authors": "Tania Panayiotou, Giannis Savva, Ioannis Tomkos, Georgios Ellinas", "title": "Centralized and Distributed Machine Learning-Based QoT Estimation for\n  Sliceable Optical Networks", "comments": "accepted for presentation at the IEEE GLOBECOM 2019", "journal-ref": null, "doi": "10.1109/GLOBECOM38437.2019.9013962", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic network slicing has emerged as a promising and fundamental framework\nfor meeting 5G's diverse use cases. As machine learning (ML) is expected to\nplay a pivotal role in the efficient control and management of these networks,\nin this work we examine the ML-based Quality-of-Transmission (QoT) estimation\nproblem under the dynamic network slicing context, where each slice has to meet\na different QoT requirement. We examine ML-based QoT frameworks with the aim of\nfinding QoT model/s that are fine-tuned according to the diverse QoT\nrequirements. Centralized and distributed frameworks are examined and compared\naccording to their accuracy and training time. We show that the distributed QoT\nmodels outperform the centralized QoT model, especially as the number of\ndiverse QoT requirements increases.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:38:54 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 11:22:57 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Panayiotou", "Tania", ""], ["Savva", "Giannis", ""], ["Tomkos", "Ioannis", ""], ["Ellinas", "Georgios", ""]]}, {"id": "1908.08339", "submitter": "Wei Lu", "authors": "Guoliang Feng, Wei Lu, Witold Pedrycz, Jianhua Yang, and Xiaodong Liu", "title": "The Learning of Fuzzy Cognitive Maps With Noisy Data: A Rapid and Robust\n  Learning Method With Maximum Entropy", "comments": "The manuscript has been published on IEEE Transactions on Cybernetics", "journal-ref": null, "doi": "10.1109/TCYB.2019.2933438", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous learning methods for fuzzy cognitive maps (FCMs), such as the\nHebbian-based and the population-based learning methods, have been developed\nfor modeling and simulating dynamic systems. However, these methods are faced\nwith several obvious limitations. Most of these models are extremely time\nconsuming when learning the large-scale FCMs with hundreds of nodes.\nFurthermore, the FCMs learned by those algorithms lack robustness when the\nexperimental data contain noise. In addition, reasonable distribution of the\nweights is rarely considered in these algorithms, which could result in the\nreduction of the performance of the resulting FCM. In this article, a\nstraightforward, rapid, and robust learning method is proposed to learn FCMs\nfrom noisy data, especially, to learn large-scale FCMs. The crux of the\nproposed algorithm is to equivalently transform the learning problem of FCMs to\na classic-constrained convex optimization problem in which the least-squares\nterm ensures the robustness of the well-learned FCM and the maximum entropy\nterm regularizes the distribution of the weights of the well-learned FCM. A\nseries of experiments covering two frequently used activation functions (the\nsigmoid and hyperbolic tangent functions) are performed on both synthetic\ndatasets with noise and real-world datasets. The experimental results show that\nthe proposed method is rapid and robust against data containing noise and that\nthe well-learned weights have better distribution. In addition, the FCMs\nlearned by the proposed method also exhibit superior performance in comparison\nwith the existing methods. Index Terms-Fuzzy cognitive maps (FCMs), maximum\nentropy, noisy data, rapid and robust learning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:39:37 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Feng", "Guoliang", ""], ["Lu", "Wei", ""], ["Pedrycz", "Witold", ""], ["Yang", "Jianhua", ""], ["Liu", "Xiaodong", ""]]}, {"id": "1908.08340", "submitter": "Hongyu Li", "authors": "Hongyu Li and Tianqi Han", "title": "An End-to-End Encrypted Neural Network for Gradient Updates Transmission\n  in Federated Learning", "comments": "8 pages, 3 figures", "journal-ref": "This paper is an extended version of a summary published in the\n  Proc. of 2019 Data Compression Conference (DCC). The 1-page summary in the\n  DCC proceedings can be found at: https://ieeexplore.ieee.org/document/8712695", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed learning method to train a shared model\nby aggregating the locally-computed gradient updates. In federated learning,\nbandwidth and privacy are two main concerns of gradient updates transmission.\nThis paper proposes an end-to-end encrypted neural network for gradient updates\ntransmission. This network first encodes the input gradient updates to a\nlower-dimension space in each client, which significantly mitigates the\npressure of data communication in federated learning. The encoded gradient\nupdates are directly recovered as a whole, i.e. the aggregated gradient updates\nof the trained model, in the decoding layers of the network on the server. In\nthis way, gradient updates encrypted in each client are not only prevented from\ninterception during communication, but also unknown to the server. Based on the\nencrypted neural network, a novel federated learning framework is designed in\nreal applications. Experimental results show that the proposed network can\neffectively achieve two goals, privacy protection and data compression, under a\nlittle sacrifice of the model accuracy in federated learning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:41:32 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Li", "Hongyu", ""], ["Han", "Tianqi", ""]]}, {"id": "1908.08342", "submitter": "Runzhe Yang", "authors": "Runzhe Yang, Xingyuan Sun, Karthik Narasimhan", "title": "A Generalized Algorithm for Multi-Objective Reinforcement Learning and\n  Policy Adaptation", "comments": "Accepted in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new algorithm for multi-objective reinforcement learning\n(MORL) with linear preferences, with the goal of enabling few-shot adaptation\nto new tasks. In MORL, the aim is to learn policies over multiple competing\nobjectives whose relative importance (preferences) is unknown to the agent.\nWhile this alleviates dependence on scalar reward design, the expected return\nof a policy can change significantly with varying preferences, making it\nchallenging to learn a single model to produce optimal policies under different\npreference conditions. We propose a generalized version of the Bellman equation\nto learn a single parametric representation for optimal policies over the space\nof all possible preferences. After an initial learning phase, our agent can\nexecute the optimal policy under any given preference, or automatically infer\nan underlying preference with very few samples. Experiments across four\ndifferent domains demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 17:54:14 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 06:36:07 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Yang", "Runzhe", ""], ["Sun", "Xingyuan", ""], ["Narasimhan", "Karthik", ""]]}, {"id": "1908.08345", "submitter": "Yang Liu", "authors": "Yang Liu and Mirella Lapata", "title": "Text Summarization with Pretrained Encoders", "comments": "fix typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidirectional Encoder Representations from Transformers (BERT) represents the\nlatest incarnation of pretrained language models which have recently advanced a\nwide range of natural language processing tasks. In this paper, we showcase how\nBERT can be usefully applied in text summarization and propose a general\nframework for both extractive and abstractive models. We introduce a novel\ndocument-level encoder based on BERT which is able to express the semantics of\na document and obtain representations for its sentences. Our extractive model\nis built on top of this encoder by stacking several inter-sentence Transformer\nlayers. For abstractive summarization, we propose a new fine-tuning schedule\nwhich adopts different optimizers for the encoder and the decoder as a means of\nalleviating the mismatch between the two (the former is pretrained while the\nlatter is not). We also demonstrate that a two-staged fine-tuning approach can\nfurther boost the quality of the generated summaries. Experiments on three\ndatasets show that our model achieves state-of-the-art results across the board\nin both extractive and abstractive settings. Our code is available at\nhttps://github.com/nlpyang/PreSumm\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:59:40 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 12:04:19 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Liu", "Yang", ""], ["Lapata", "Mirella", ""]]}, {"id": "1908.08346", "submitter": "Saptarshi Bej", "authors": "Saptarshi Bej, Narek Davtyan, Markus Wolfien, Mariam Nassar, Olaf\n  Wolkenhauer", "title": "LoRAS: An oversampling approach for imbalanced datasets", "comments": "2 figures, Supplementary data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Synthetic Minority Oversampling TEchnique (SMOTE) is widely-used for the\nanalysis of imbalanced datasets. It is known that SMOTE frequently\nover-generalizes the minority class, leading to misclassifications for the\nmajority class, and effecting the overall balance of the model.\n  In this article, we present an approach that overcomes this limitation of\nSMOTE, employing Localized Random Affine Shadowsampling (LoRAS) to oversample\nfrom an approximated data manifold of the minority class.\n  We benchmarked our algorithm with 14 publicly available imbalanced datasets\nusing three different Machine Learning (ML) algorithms and compared the\nperformance of LoRAS, SMOTE and several SMOTE extensions that share the concept\nof using convex combinations of minority class data points for oversampling\nwith LoRAS. We observed that LoRAS, on average generates better ML models in\nterms of F1-Score and Balanced accuracy. Another key observation is that while\nmost of the extensions of SMOTE we have tested, improve the F1-Score with\nrespect to SMOTE on an average, they compromise on the Balanced accuracy of a\nclassification model. LoRAS on the contrary, improves both F1 Score and the\nBalanced accuracy thus produces better classification models.\n  Moreover, to explain the success of the algorithm, we have constructed a\nmathematical framework to prove that LoRAS oversampling technique provides a\nbetter estimate for the mean of the underlying local data distribution of the\nminority class data space.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:00:35 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 08:46:37 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 18:09:26 GMT"}, {"version": "v4", "created": "Sat, 15 Aug 2020 11:26:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Bej", "Saptarshi", ""], ["Davtyan", "Narek", ""], ["Wolfien", "Markus", ""], ["Nassar", "Mariam", ""], ["Wolkenhauer", "Olaf", ""]]}, {"id": "1908.08351", "submitter": "Dieuwke Hupkes", "authors": "Dieuwke Hupkes, Verna Dankers, Mathijs Mul, Elia Bruni", "title": "Compositionality decomposed: how do neural networks generalise?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a multitude of empirical studies, little consensus exists on whether\nneural networks are able to generalise compositionally, a controversy that, in\npart, stems from a lack of agreement about what it means for a neural model to\nbe compositional. As a response to this controversy, we present a set of tests\nthat provide a bridge between, on the one hand, the vast amount of linguistic\nand philosophical theory about compositionality of language and, on the other,\nthe successful neural models of language. We collect different interpretations\nof compositionality and translate them into five theoretically grounded tests\nfor models that are formulated on a task-independent level. In particular, we\nprovide tests to investigate (i) if models systematically recombine known parts\nand rules (ii) if models can extend their predictions beyond the length they\nhave seen in the training data (iii) if models' composition operations are\nlocal or global (iv) if models' predictions are robust to synonym substitutions\nand (v) if models favour rules or exceptions during training. To demonstrate\nthe usefulness of this evaluation paradigm, we instantiate these five tests on\na highly compositional data set which we dub PCFG SET and apply the resulting\ntests to three popular sequence-to-sequence models: a recurrent, a\nconvolution-based and a transformer model. We provide an in-depth analysis of\nthe results, which uncover the strengths and weaknesses of these three\narchitectures and point to potential areas of improvement.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:08:26 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 15:42:10 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hupkes", "Dieuwke", ""], ["Dankers", "Verna", ""], ["Mul", "Mathijs", ""], ["Bruni", "Elia", ""]]}, {"id": "1908.08368", "submitter": "Hongzhi Wang", "authors": "Hongzhi Wang, Yijie Yang and Yang Song", "title": "A General Data Renewal Model for Prediction Algorithms in Industrial\n  Data Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In industrial data analytics, one of the fundamental problems is to utilize\nthe temporal correlation of the industrial data to make timely predictions in\nthe production process, such as fault prediction and yield prediction. However,\nthe traditional prediction models are fixed while the conditions of the\nmachines change over time, thus making the errors of predictions increase with\nthe lapse of time. In this paper, we propose a general data renewal model to\ndeal with it. Combined with the similarity function and the loss function, it\nestimates the time of updating the existing prediction model, then updates it\naccording to the evaluation function iteratively and adaptively. We have\napplied the data renewal model to two prediction algorithms. The experiments\ndemonstrate that the data renewal model can effectively identify the changes of\ndata, update and optimize the prediction model so as to improve the accuracy of\nprediction.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:38:22 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Wang", "Hongzhi", ""], ["Yang", "Yijie", ""], ["Song", "Yang", ""]]}, {"id": "1908.08379", "submitter": "Joel Oren", "authors": "Dotan Di Castro, Joel Oren, Shie Mannor", "title": "Practical Risk Measures in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practical application of Reinforcement Learning (RL) often involves risk\nconsiderations. We study a generalized approximation scheme for risk measures,\nbased on Monte-Carlo simulations, where the risk measures need not necessarily\nbe \\emph{coherent}. We demonstrate that, even in simple problems, measures such\nas the variance of the reward-to-go do not capture the risk in a satisfactory\nmanner. In addition, we show how a risk measure can be derived from model's\nrealizations. We propose a neural architecture for estimating the risk and\nsuggest the risk critic architecture that can be use to optimize a policy under\ngeneral risk measures. We conclude our work with experiments that demonstrate\nthe efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:50:31 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Di Castro", "Dotan", ""], ["Oren", "Joel", ""], ["Mannor", "Shie", ""]]}, {"id": "1908.08380", "submitter": "Zachariah Carmichael", "authors": "Zachariah Carmichael, Humza Syed, Dhireesha Kudithipudi", "title": "Analysis of Wide and Deep Echo State Networks for Multiscale\n  Spatiotemporal Time Series Forecasting", "comments": "10 pages, 10 figures, Proceedings of the Neuro-inspired Computational\n  Elements Workshop (NICE '19), March 26-28, 2019, Albany, NY, USA", "journal-ref": null, "doi": "10.1145/3320288.3320303", "report-no": null, "categories": "eess.SP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo state networks are computationally lightweight reservoir models inspired\nby the random projections observed in cortical circuitry. As interest in\nreservoir computing has grown, networks have become deeper and more intricate.\nWhile these networks are increasingly applied to nontrivial forecasting tasks,\nthere is a need for comprehensive performance analysis of deep reservoirs. In\nthis work, we study the influence of partitioning neurons given a budget and\nthe effect of parallel reservoir pathways across different datasets exhibiting\nmulti-scale and nonlinear dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:39:08 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Carmichael", "Zachariah", ""], ["Syed", "Humza", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1908.08381", "submitter": "Xiangyun Lei", "authors": "Xiangyun Lei, Fred Hohman, Duen Horng Chau, Andrew J. Medford", "title": "ElectroLens: Understanding Atomistic Simulations Through\n  Spatially-resolved Visualization of High-dimensional Features", "comments": "accepted to IEEE visualization 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG physics.chem-ph physics.comp-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, machine learning (ML) has gained significant popularity in\nthe field of chemical informatics and electronic structure theory. These\ntechniques often require researchers to engineer abstract \"features\" that\nencode chemical concepts into a mathematical form compatible with the input to\nmachine-learning models. However, there is no existing tool to connect these\nabstract features back to the actual chemical system, making it difficult to\ndiagnose failures and to build intuition about the meaning of the features. We\npresent ElectroLens, a new visualization tool for high-dimensional\nspatially-resolved features to tackle this problem. The tool visualizes\nhigh-dimensional data sets for atomistic and electron environment features by a\nseries of linked 3D views and 2D plots. The tool is able to connect different\nderived features and their corresponding regions in 3D via interactive\nselection. It is built to be scalable, and integrate with existing\ninfrastructure.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 19:48:31 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 01:27:16 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Lei", "Xiangyun", ""], ["Hohman", "Fred", ""], ["Chau", "Duen Horng", ""], ["Medford", "Andrew J.", ""]]}, {"id": "1908.08389", "submitter": "Shujaat Khan Engr", "authors": "Alishba Sadiq, Muhammad Sohail Ibrahim, Muhammad Usman, Muhammad\n  Zubair and Shujaat Khan", "title": "Chaotic Time Series Prediction using Spatio-Temporal RBF Neural Networks", "comments": "Published in: 2018 3rd International Conference on Emerging Trends in\n  Engineering, Sciences and Technology (ICEEST). arXiv admin note: substantial\n  text overlap with arXiv:1908.01321", "journal-ref": null, "doi": "10.1109/ICEEST.2018.8643321", "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the dynamic nature, chaotic time series are difficult predict. In\nconventional signal processing approaches signals are treated either in time or\nin space domain only. Spatio-temporal analysis of signal provides more\nadvantages over conventional uni-dimensional approaches by harnessing the\ninformation from both the temporal and spatial domains. Herein, we propose an\nspatio-temporal extension of RBF neural networks for the prediction of chaotic\ntime series. The proposed algorithm utilizes the concept of time-space\northogonality and separately deals with the temporal dynamics and spatial\nnon-linearity(complexity) of the chaotic series. The proposed RBF architecture\nis explored for the prediction of Mackey-Glass time series and results are\ncompared with the standard RBF. The spatio-temporal RBF is shown to out perform\nthe standard RBFNN by achieving significantly reduced estimation error.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 08:49:42 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Sadiq", "Alishba", ""], ["Ibrahim", "Muhammad Sohail", ""], ["Usman", "Muhammad", ""], ["Zubair", "Muhammad", ""], ["Khan", "Shujaat", ""]]}, {"id": "1908.08394", "submitter": "Guangzeng Xie", "authors": "Guangzeng Xie, Luo Luo, Zhihua Zhang", "title": "A General Analysis Framework of Lower Complexity Bounds for Finite-Sum\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the lower bound complexity for the optimization problem\nwhose objective function is the average of $n$ individual smooth convex\nfunctions. We consider the algorithm which gets access to gradient and proximal\noracle for each individual component. For the strongly-convex case, we prove\nsuch an algorithm can not reach an $\\varepsilon$-suboptimal point in fewer than\n$\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\varepsilon))$ iterations, where $\\kappa$ is\nthe condition number of the objective function. This lower bound is tighter\nthan previous results and perfectly matches the upper bound of the existing\nproximal incremental first-order oracle algorithm Point-SAGA. We develop a\nnovel construction to show the above result, which partitions the tridiagonal\nmatrix of classical examples into $n$ groups. This construction is friendly to\nthe analysis of proximal oracle and also could be used to general convex and\naverage smooth cases naturally.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 14:02:46 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Xie", "Guangzeng", ""], ["Luo", "Luo", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1908.08401", "submitter": "Chen Zhong", "authors": "Chen Zhong, Ziyang Lu, M. Cenk Gursoy, and Senem Velipasalar", "title": "A Deep Actor-Critic Reinforcement Learning Framework for Dynamic\n  Multichannel Access", "comments": "14 figures. arXiv admin note: text overlap with arXiv:1810.03695", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make efficient use of limited spectral resources, we in this work propose\na deep actor-critic reinforcement learning based framework for dynamic\nmultichannel access. We consider both a single-user case and a scenario in\nwhich multiple users attempt to access channels simultaneously. We employ the\nproposed framework as a single agent in the single-user case, and extend it to\na decentralized multi-agent framework in the multi-user scenario. In both\ncases, we develop algorithms for the actor-critic deep reinforcement learning\nand evaluate the proposed learning policies via experiments and numerical\nresults. In the single-user model, in order to evaluate the performance of the\nproposed channel access policy and the framework's tolerance against\nuncertainty, we explore different channel switching patterns and different\nswitching probabilities. In the case of multiple users, we analyze the\nprobabilities of each user accessing channels with favorable channel conditions\nand the probability of collision. We also address a time-varying environment to\nidentify the adaptive ability of the proposed framework. Additionally, we\nprovide comparisons (in terms of both the average reward and time efficiency)\nbetween the proposed actor-critic deep reinforcement learning framework, Deep-Q\nnetwork (DQN) based approach, random access, and the optimal policy when the\nchannel dynamics are known.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:19:35 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Zhong", "Chen", ""], ["Lu", "Ziyang", ""], ["Gursoy", "M. Cenk", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1908.08416", "submitter": "Jonas Schuff", "authors": "Jonas Schuff, Lukas J. Fiderer, Daniel Braun", "title": "Improving the dynamics of quantum sensors with reinforcement learning", "comments": null, "journal-ref": "New Journal of Physics (2020), Volume 22, 035001", "doi": "10.1088/1367-2630/ab6f1f", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed quantum-chaotic sensors achieve quantum enhancements in\nmeasurement precision by applying nonlinear control pulses to the dynamics of\nthe quantum sensor while using classical initial states that are easy to\nprepare. Here, we use the cross-entropy method of reinforcement learning to\noptimize the strength and position of control pulses. Compared to the\nquantum-chaotic sensors with periodic control pulses in the presence of\nsuperradiant damping, we find that decoherence can be fought even better and\nmeasurement precision can be enhanced further by optimizing the control. In\nsome examples, we find enhancements in sensitivity by more than an order of\nmagnitude. By visualizing the evolution of the quantum state, the mechanism\nexploited by the reinforcement learning method is identified as a kind of\nspin-squeezing strategy that is adapted to the superradiant damping.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 14:48:28 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 14:32:01 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Schuff", "Jonas", ""], ["Fiderer", "Lukas J.", ""], ["Braun", "Daniel", ""]]}, {"id": "1908.08431", "submitter": "Kerstin Kl\\\"aser", "authors": "Kerstin Kl\\\"aser, Thomas Varsavsky, Pawel Markiewicz, Tom Vercauteren,\n  David Atkinson, Kris Thielemans, Brian Hutton, M Jorge Cardoso, Sebastien\n  Ourselin", "title": "Improved MR to CT synthesis for PET/MR attenuation correction using\n  Imitation Learning", "comments": "Aceppted at SASHIMI2019", "journal-ref": null, "doi": "10.1007/978-3-030-32778-1_2", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to synthesise Computed Tomography images - commonly known as\npseudo CT, or pCT - from MRI input data is commonly assessed using an\nintensity-wise similarity, such as an L2-norm between the ground truth CT and\nthe pCT. However, given that the ultimate purpose is often to use the pCT as an\nattenuation map ($\\mu$-map) in Positron Emission Tomography Magnetic Resonance\nImaging (PET/MRI), minimising the error between pCT and CT is not necessarily\noptimal. The main objective should be to predict a pCT that, when used as\n$\\mu$-map, reconstructs a pseudo PET (pPET) which is as close as possible to\nthe gold standard PET. To this end, we propose a novel multi-hypothesis deep\nlearning framework that generates pCTs by minimising a combination of the\npixel-wise error between pCT and CT and a proposed metric-loss that itself is\nrepresented by a convolutional neural network (CNN) and aims to minimise\nsubsequent PET residuals. The model is trained on a database of 400 paired\nMR/CT/PET image slices. Quantitative results show that the network generates\npCTs that seem less accurate when evaluating the Mean Absolute Error on the pCT\n(69.68HU) compared to a baseline CNN (66.25HU), but lead to significant\nimprovement in the PET reconstruction - 115a.u. compared to baseline 140a.u.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 12:47:29 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 19:27:40 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Kl\u00e4ser", "Kerstin", ""], ["Varsavsky", "Thomas", ""], ["Markiewicz", "Pawel", ""], ["Vercauteren", "Tom", ""], ["Atkinson", "David", ""], ["Thielemans", "Kris", ""], ["Hutton", "Brian", ""], ["Cardoso", "M Jorge", ""], ["Ourselin", "Sebastien", ""]]}, {"id": "1908.08450", "submitter": "Mantas Luko\\v{s}evi\\v{c}ius", "authors": "Mantas Luko\\v{s}evi\\v{c}ius (1) and Arnas Uselis (1) ((1) Kaunas\n  University of Technology)", "title": "Efficient Cross-Validation of Echo State Networks", "comments": "Accepted in ICANN'19 Workshop on Reservoir Computing", "journal-ref": "Artificial Neural Networks and Machine Learning - ICANN 2019:\n  Workshop and Special Sessions. ICANN 2019., pp. 121-133", "doi": "10.1007/978-3-030-30493-5_12", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo State Networks (ESNs) are known for their fast and precise one-shot\nlearning of time series. But they often need good hyper-parameter tuning for\nbest performance. For this good validation is key, but usually, a single\nvalidation split is used. In this rather practical contribution we suggest\nseveral schemes for cross-validating ESNs and introduce an efficient algorithm\nfor implementing them. The component that dominates the time complexity of the\nalready quite fast ESN training remains constant (does not scale up with $k$)\nin our proposed method of doing $k$-fold cross-validation. The component that\ndoes scale linearly with $k$ starts dominating only in some not very common\nsituations. Thus in many situations $k$-fold cross-validation of ESNs can be\ndone for virtually the same time complexity as a simple single split\nvalidation. Space complexity can also remain the same. We also discuss when the\nproposed validation schemes for ESNs could be beneficial and empirically\ninvestigate them on several different real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 15:26:04 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Luko\u0161evi\u010dius", "Mantas", ""], ["Uselis", "Arnas", ""]]}, {"id": "1908.08453", "submitter": "Abdelrahman Abdelhamed", "authors": "Abdelrahman Abdelhamed, Marcus A. Brubaker, and Michael S. Brown", "title": "Noise Flow: Noise Modeling with Conditional Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modeling and synthesizing image noise is an important aspect in many computer\nvision applications. The long-standing additive white Gaussian and\nheteroscedastic (signal-dependent) noise models widely used in the literature\nprovide only a coarse approximation of real sensor noise. This paper introduces\nNoise Flow, a powerful and accurate noise model based on recent normalizing\nflow architectures. Noise Flow combines well-established basic parametric noise\nmodels (e.g., signal-dependent noise) with the flexibility and expressiveness\nof normalizing flow networks. The result is a single, comprehensive, compact\nnoise model containing fewer than 2500 parameters yet able to represent\nmultiple cameras and gain factors. Noise Flow dramatically outperforms existing\nnoise models, with 0.42 nats/pixel improvement over the camera-calibrated noise\nlevel functions, which translates to 52% improvement in the likelihood of\nsampled noise. Noise Flow represents the first serious attempt to go beyond\nsimple parametric models to one that leverages the power of deep learning and\ndata-driven noise distributions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 15:30:32 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Abdelhamed", "Abdelrahman", ""], ["Brubaker", "Marcus A.", ""], ["Brown", "Michael S.", ""]]}, {"id": "1908.08465", "submitter": "Yu-Guan Hsieh", "authors": "Yu-Guan Hsieh and Franck Iutzeler and J\\'er\\^ome Malick and Panayotis\n  Mertikopoulos", "title": "On the convergence of single-call stochastic extra-gradient methods", "comments": "In Advances in Neural Information Processing Systems 32 (NeurIPS\n  2019); 24 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inequalities have recently attracted considerable interest in\nmachine learning as a flexible paradigm for models that go beyond ordinary loss\nfunction minimization (such as generative adversarial networks and related deep\nlearning systems). In this setting, the optimal $\\mathcal{O}(1/t)$ convergence\nrate for solving smooth monotone variational inequalities is achieved by the\nExtra-Gradient (EG) algorithm and its variants. Aiming to alleviate the cost of\nan extra gradient step per iteration (which can become quite substantial in\ndeep learning applications), several algorithms have been proposed as\nsurrogates to Extra-Gradient with a \\emph{single} oracle call per iteration. In\nthis paper, we develop a synthetic view of such algorithms, and we complement\nthe existing literature by showing that they retain a $\\mathcal{O}(1/t)$\nergodic convergence rate in smooth, deterministic problems. Subsequently,\nbeyond the monotone deterministic case, we also show that the last iterate of\nsingle-call, \\emph{stochastic} extra-gradient methods still enjoys a\n$\\mathcal{O}(1/t)$ local convergence rate to solutions of \\emph{non-monotone}\nvariational inequalities that satisfy a second-order sufficient condition.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 15:50:32 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 10:31:22 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Hsieh", "Yu-Guan", ""], ["Iutzeler", "Franck", ""], ["Malick", "J\u00e9r\u00f4me", ""], ["Mertikopoulos", "Panayotis", ""]]}, {"id": "1908.08466", "submitter": "Xiao-Yun Zhou", "authors": "Xiao-Yun Zhou, Peichao Li, Zhao-Yang Wang, Guang-Zhong Yang", "title": "U-Net Training with Instance-Layer Normalization", "comments": "8 pages, 3 figures, accepted by MICCAI-MMMI 2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization layers are essential in a Deep Convolutional Neural Network\n(DCNN). Various normalization methods have been proposed. The statistics used\nto normalize the feature maps can be computed at batch, channel, or instance\nlevel. However, in most of existing methods, the normalization for each layer\nis fixed. Batch-Instance Normalization (BIN) is one of the first proposed\nmethods that combines two different normalization methods and achieve diverse\nnormalization for different layers. However, two potential issues exist in BIN:\nfirst, the Clip function is not differentiable at input values of 0 and 1;\nsecond, the combined feature map is not with a normalized distribution which is\nharmful for signal propagation in DCNN. In this paper, an Instance-Layer\nNormalization (ILN) layer is proposed by using the Sigmoid function for the\nfeature map combination, and cascading group normalization. The performance of\nILN is validated on image segmentation of the Right Ventricle (RV) and Left\nVentricle (LV) using U-Net as the network architecture. The results show that\nthe proposed ILN outperforms previous traditional and popular normalization\nmethods with noticeable accuracy improvements for most validations, supporting\nthe effectiveness of the proposed ILN.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 11:24:25 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 14:18:15 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Zhou", "Xiao-Yun", ""], ["Li", "Peichao", ""], ["Wang", "Zhao-Yang", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "1908.08469", "submitter": "Hyunsik Jeon", "authors": "Hyunsik Jeon, Bonhun Koo, U Kang", "title": "Data Context Adaptation for Accurate Recommendation with Additional\n  Information", "comments": "10 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sparse rating matrix and an auxiliary matrix of users or items, how\ncan we accurately predict missing ratings considering different data contexts\nof entities? Many previous studies proved that utilizing the additional\ninformation with rating data is helpful to improve the performance. However,\nexisting methods are limited in that 1) they ignore the fact that data contexts\nof rating and auxiliary matrices are different, 2) they have restricted\ncapability of expressing independence information of users or items, and 3)\nthey assume the relation between a user and an item is linear. We propose\nDaConA, a neural network based method for recommendation with a rating matrix\nand an auxiliary matrix. DaConA is designed with the following three main\nideas. First, we propose a data context adaptation layer to extract pertinent\nfeatures for different data contexts. Second, DaConA represents each entity\nwith latent interaction vector and latent independence vector. Unlike previous\nmethods, both of the two vectors are not limited in size. Lastly, while\nprevious matrix factorization based methods predict missing values through the\ninner-product of latent vectors, DaConA learns a non-linear function of them\nvia a neural network. We show that DaConA is a generalized algorithm including\nthe standard matrix factorization and the collective matrix factorization as\nspecial cases. Through comprehensive experiments on real-world datasets, we\nshow that DaConA provides the state-of-the-art accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 16:02:17 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Jeon", "Hyunsik", ""], ["Koo", "Bonhun", ""], ["Kang", "U", ""]]}, {"id": "1908.08474", "submitter": "Mukund Sundararajan", "authors": "Mukund Sundararajan and Amir Najmi", "title": "The many Shapley values for model explanation", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Shapley value has become a popular method to attribute the prediction of\na machine-learning model on an input to its base features. The use of the\nShapley value is justified by citing [16] showing that it is the \\emph{unique}\nmethod that satisfies certain good properties (\\emph{axioms}).\n  There are, however, a multiplicity of ways in which the Shapley value is\noperationalized in the attribution problem. These differ in how they reference\nthe model, the training data, and the explanation context. These give very\ndifferent results, rendering the uniqueness result meaningless. Furthermore, we\nfind that previously proposed approaches can produce counterintuitive\nattributions in theory and in practice---for instance, they can assign non-zero\nattributions to features that are not even referenced by the model.\n  In this paper, we use the axiomatic approach to study the differences between\nsome of the many operationalizations of the Shapley value for attribution, and\npropose a technique called Baseline Shapley (BShap) that is backed by a proper\nuniqueness result. We also contrast BShap with Integrated Gradients, another\nextension of Shapley value to the continuous setting.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 16:13:10 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 17:43:11 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Sundararajan", "Mukund", ""], ["Najmi", "Amir", ""]]}, {"id": "1908.08484", "submitter": "Teemu Roos", "authors": "Peter Gr\\\"unwald and Teemu Roos", "title": "Minimum Description Length Revisited", "comments": "to appear in International Journal of Mathematics for Industry", "journal-ref": null, "doi": "10.1142/S2661335219300018", "report-no": null, "categories": "stat.ME cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an up-to-date introduction to and overview of the Minimum Description\nLength (MDL) Principle, a theory of inductive inference that can be applied to\ngeneral problems in statistics, machine learning and pattern recognition. While\nMDL was originally based on data compression ideas, this introduction can be\nread without any knowledge thereof. It takes into account all major\ndevelopments since 2007, the last time an extensive overview was written. These\ninclude new methods for model selection and averaging and hypothesis testing,\nas well as the first completely general definition of {\\em MDL estimators}.\nIncorporating these developments, MDL can be seen as a powerful extension of\nboth penalized likelihood and Bayesian approaches, in which penalization\nfunctions and prior distributions are replaced by more general luckiness\nfunctions, average-case methodology is replaced by a more robust worst-case\napproach, and in which methods classically viewed as highly distinct, such as\nAIC vs BIC and cross-validation vs Bayes can, to a large extent, be viewed from\na unified perspective.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 11:42:56 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 13:54:57 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Gr\u00fcnwald", "Peter", ""], ["Roos", "Teemu", ""]]}, {"id": "1908.08489", "submitter": "Sasan Barak Dr", "authors": "Sasan Barak, Mahdi Nasiri, Mehrdad Rostamzadeh", "title": "Time series model selection with a meta-learning approach; evidence from\n  a pool of forecasting algorithms", "comments": "30 pages, 10 tables, and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  One of the challenging questions in time series forecasting is how to find\nthe best algorithm. In recent years, a recommender system scheme has been\ndeveloped for time series analysis using a meta-learning approach. This system\nselects the best forecasting method with consideration of the time series\ncharacteristics. In this paper, we propose a novel approach to focusing on some\nof the unanswered questions resulting from the use of meta-learning in time\nseries forecasting. Therefore, three main gaps in previous works are addressed\nincluding, analyzing various subsets of top forecasters as inputs for\nmeta-learners; evaluating the effect of forecasting error measures; and\nassessing the role of the dimensionality of the feature space on the\nforecasting errors of meta-learners. All of these objectives are achieved with\nthe help of a diverse state-of-the-art pool of forecasters and meta-learners.\nFor this purpose, first, a pool of forecasting algorithms is implemented on the\nNN5 competition dataset and ranked based on the two error measures. Then, six\nmachine-learning classifiers known as meta-learners, are trained on the\nextracted features of the time series in order to assign the most suitable\nforecasting method for the various subsets of the pool of forecasters.\nFurthermore, two-dimensionality reduction methods are implemented in order to\ninvestigate the role of feature space dimension on the performance of\nmeta-learners. In general, it was found that meta-learners were able to defeat\nall of the individual benchmark forecasters; this performance was improved even\nafter applying the feature selection method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 16:49:30 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Barak", "Sasan", ""], ["Nasiri", "Mahdi", ""], ["Rostamzadeh", "Mehrdad", ""]]}, {"id": "1908.08497", "submitter": "Yuyang Gao", "authors": "Yuyang Gao, Lingfei Wu, Houman Homayoun, Liang Zhao", "title": "DynGraph2Seq: Dynamic-Graph-to-Sequence Interpretable Learning for\n  Health Stage Prediction in Online Health Forums", "comments": "6 pages. Accepted as ICDM 2019 Short Paper. Final Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online health communities such as the online breast cancer forum enable\npatients (i.e., users) to interact and help each other within various\nsubforums, which are subsections of the main forum devoted to specific health\ntopics. The changing nature of the users' activities in different subforums can\nbe strong indicators of their health status changes. This additional\ninformation could allow health-care organizations to respond promptly and\nprovide additional help for the patient. However, modeling complex transitions\nof an individual user's activities among different subforums over time and\nlearning how these correspond to his/her health stage are extremely\nchallenging. In this paper, we first formulate the transition of user\nactivities as a dynamic graph with multi-attributed nodes, then formalize the\nhealth stage inference task as a dynamic graph-to-sequence learning problem,\nand hence propose a novel dynamic graph-to-sequence neural networks\narchitecture (DynGraph2Seq) to address all the challenges. Our proposed\nDynGraph2Seq model consists of a novel dynamic graph encoder and an\ninterpretable sequence decoder that learn the mapping between a sequence of\ntime-evolving user activity graphs and a sequence of target health stages. We\ngo on to propose dynamic graph hierarchical attention mechanisms to facilitate\nthe necessary multi-level interpretability. A comprehensive experimental\nanalysis of its use for a health stage prediction task demonstrates both the\neffectiveness and the interpretability of the proposed models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:06:59 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Gao", "Yuyang", ""], ["Wu", "Lingfei", ""], ["Homayoun", "Houman", ""], ["Zhao", "Liang", ""]]}, {"id": "1908.08505", "submitter": "Aakanksha Rana", "authors": "Emin Zerman, Aakanksha Rana, Aljosa Smolic", "title": "ColorNet -- Estimating Colorfulness in Natural Images", "comments": "Accepted to IEEE International Conference on Image Processing (ICIP)\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the colorfulness of a natural or virtual scene is critical for many\napplications in image processing field ranging from capturing to display. In\nthis paper, we propose the first deep learning-based colorfulness estimation\nmetric. For this purpose, we develop a color rating model which simultaneously\nlearns to extracts the pertinent characteristic color features and the mapping\nfrom feature space to the ideal colorfulness scores for a variety of natural\ncolored images. Additionally, we propose to overcome the lack of adequate\nannotated dataset problem by combining/aligning two publicly available\ncolorfulness databases using the results of a new subjective test which employs\na common subset of both databases. Using the obtained subjectively annotated\ndataset with 180 colored images, we finally demonstrate the efficacy of our\nproposed model over the traditional methods, both quantitatively and\nqualitatively.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:24:37 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Zerman", "Emin", ""], ["Rana", "Aakanksha", ""], ["Smolic", "Aljosa", ""]]}, {"id": "1908.08507", "submitter": "Ningyu Zhang", "authors": "Ningyu Zhang, Shumin Deng, Zhanlin Sun, Jiaoyan Chen, Wei Zhang,\n  Huajun Chen", "title": "Transfer Learning for Relation Extraction via Relation-Gated Adversarial\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction aims to extract relational facts from sentences. Previous\nmodels mainly rely on manually labeled datasets, seed instances or\nhuman-crafted patterns, and distant supervision. However, the human annotation\nis expensive, while human-crafted patterns suffer from semantic drift and\ndistant supervision samples are usually noisy. Domain adaptation methods enable\nleveraging labeled data from a different but related domain. However, different\ndomains usually have various textual relation descriptions and different label\nspace (the source label space is usually a superset of the target label space).\nTo solve these problems, we propose a novel model of relation-gated adversarial\nlearning for relation extraction, which extends the adversarial based domain\nadaptation. Experimental results have shown that the proposed approach\noutperforms previous domain adaptation methods regarding partial domain\nadaptation and can improve the accuracy of distance supervised relation\nextraction through fine-tuning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:27:54 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Zhang", "Ningyu", ""], ["Deng", "Shumin", ""], ["Sun", "Zhanlin", ""], ["Chen", "Jiaoyan", ""], ["Zhang", "Wei", ""], ["Chen", "Huajun", ""]]}, {"id": "1908.08520", "submitter": "Zhiqiang Shen", "authors": "Zhiqiang Shen and Zhankui He and Wanyun Cui and Jiahui Yu and Yutong\n  Zheng and Chenchen Zhu and Marios Savvides", "title": "Adversarial-Based Knowledge Distillation for Multi-Model Ensemble and\n  Noisy Data Refinement", "comments": "This is an extended version of our previous conference paper\n  arXiv:1812.02425", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic Image recognition is a fundamental and fairly important visual\nproblem in computer vision. One of the major challenges of this task lies in\nthe fact that single image usually has multiple objects inside while the labels\nare still one-hot, another one is noisy and sometimes missing labels when\nannotated by humans. In this paper, we focus on tackling these challenges\naccompanying with two different image recognition problems: multi-model\nensemble and noisy data recognition with a unified framework. As is well-known,\nusually the best performing deep neural models are ensembles of multiple\nbase-level networks, as it can mitigate the variation or noise containing in\nthe dataset. Unfortunately, the space required to store these many networks,\nand the time required to execute them at runtime, prohibit their use in\napplications where test sets are large (e.g., ImageNet). In this paper, we\npresent a method for compressing large, complex trained ensembles into a single\nnetwork, where the knowledge from a variety of trained deep neural networks\n(DNNs) is distilled and transferred to a single DNN. In order to distill\ndiverse knowledge from different trained (teacher) models, we propose to use\nadversarial-based learning strategy where we define a block-wise training loss\nto guide and optimize the predefined student network to recover the knowledge\nin teacher models, and to promote the discriminator network to distinguish\nteacher vs. student features simultaneously. Extensive experiments on\nCIFAR-10/100, SVHN, ImageNet and iMaterialist Challenge Dataset demonstrate the\neffectiveness of our MEAL method. On ImageNet, our ResNet-50 based MEAL\nachieves top-1/5 21.79%/5.99% val error, which outperforms the original model\nby 2.06%/1.14%. On iMaterialist Challenge Dataset, our MEAL obtains a\nremarkable improvement of top-3 1.15% (official evaluation metric) on a strong\nbaseline model of ResNet-101.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:51:16 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Shen", "Zhiqiang", ""], ["He", "Zhankui", ""], ["Cui", "Wanyun", ""], ["Yu", "Jiahui", ""], ["Zheng", "Yutong", ""], ["Zhu", "Chenchen", ""], ["Savvides", "Marios", ""]]}, {"id": "1908.08526", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Masatoshi Uehara", "title": "Double Reinforcement Learning for Efficient Off-Policy Evaluation in\n  Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation (OPE) in reinforcement learning allows one to evaluate\nnovel decision policies without needing to conduct exploration, which is often\ncostly or otherwise infeasible. We consider for the first time the\nsemiparametric efficiency limits of OPE in Markov decision processes (MDPs),\nwhere actions, rewards, and states are memoryless. We show existing OPE\nestimators may fail to be efficient in this setting. We develop a new estimator\nbased on cross-fold estimation of $q$-functions and marginalized density\nratios, which we term double reinforcement learning (DRL). We show that DRL is\nefficient when both components are estimated at fourth-root rates and is also\ndoubly robust when only one component is consistent. We investigate these\nproperties empirically and demonstrate the performance benefits due to\nharnessing memorylessness.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:57:19 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 07:59:07 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 09:58:10 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Kallus", "Nathan", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "1908.08529", "submitter": "Jyoti Aneja", "authors": "Jyoti Aneja, Harsh Agrawal, Dhruv Batra, Alexander Schwing", "title": "Sequential Latent Spaces for Modeling the Intention During Diverse Image\n  Captioning", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse and accurate vision+language modeling is an important goal to retain\ncreative freedom and maintain user engagement. However, adequately capturing\nthe intricacies of diversity in language models is challenging. Recent works\ncommonly resort to latent variable models augmented with more or less\nsupervision from object detectors or part-of-speech tags. Common to all those\nmethods is the fact that the latent variable either only initializes the\nsentence generation process or is identical across the steps of generation.\nBoth methods offer no fine-grained control. To address this concern, we propose\nSeq-CVAE which learns a latent space for every word position. We encourage this\ntemporal latent space to capture the 'intention' about how to complete the\nsentence by mimicking a representation which summarizes the future. We\nillustrate the efficacy of the proposed approach to anticipate the sentence\ncontinuation on the challenging MSCOCO dataset, significantly improving\ndiversity metrics compared to baselines while performing on par w.r.t sentence\nquality.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:59:08 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Aneja", "Jyoti", ""], ["Agrawal", "Harsh", ""], ["Batra", "Dhruv", ""], ["Schwing", "Alexander", ""]]}, {"id": "1908.08530", "submitter": "Yue Cao", "authors": "Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, Jifeng Dai", "title": "VL-BERT: Pre-training of Generic Visual-Linguistic Representations", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new pre-trainable generic representation for visual-linguistic\ntasks, called Visual-Linguistic BERT (VL-BERT for short). VL-BERT adopts the\nsimple yet powerful Transformer model as the backbone, and extends it to take\nboth visual and linguistic embedded features as input. In it, each element of\nthe input is either of a word from the input sentence, or a region-of-interest\n(RoI) from the input image. It is designed to fit for most of the\nvisual-linguistic downstream tasks. To better exploit the generic\nrepresentation, we pre-train VL-BERT on the massive-scale Conceptual Captions\ndataset, together with text-only corpus. Extensive empirical analysis\ndemonstrates that the pre-training procedure can better align the\nvisual-linguistic clues and benefit the downstream tasks, such as visual\ncommonsense reasoning, visual question answering and referring expression\ncomprehension. It is worth noting that VL-BERT achieved the first place of\nsingle model on the leaderboard of the VCR benchmark. Code is released at\n\\url{https://github.com/jackroos/VL-BERT}.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:59:30 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 11:18:38 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 09:42:53 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 02:59:17 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Su", "Weijie", ""], ["Zhu", "Xizhou", ""], ["Cao", "Yue", ""], ["Li", "Bin", ""], ["Lu", "Lewei", ""], ["Wei", "Furu", ""], ["Dai", "Jifeng", ""]]}, {"id": "1908.08563", "submitter": "Farid Ghareh Mohammadi", "authors": "Farid Ghareh Mohammadi, M. Hadi Amini, and Hamid R. Arabnia", "title": "Applications of Nature-Inspired Algorithms for Dimension Reduction:\n  Enabling Efficient Data Analytics", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In [1], we have explored the theoretical aspects of feature selection and\nevolutionary algorithms. In this chapter, we focus on optimization algorithms\nfor enhancing data analytic process, i.e., we propose to explore applications\nof nature-inspired algorithms in data science. Feature selection optimization\nis a hybrid approach leveraging feature selection techniques and evolutionary\nalgorithms process to optimize the selected features. Prior works solve this\nproblem iteratively to converge to an optimal feature subset. Feature selection\noptimization is a non-specific domain approach. Data scientists mainly attempt\nto find an advanced way to analyze data n with high computational efficiency\nand low time complexity, leading to efficient data analytics. Thus, by\nincreasing generated/measured/sensed data from various sources, analysis,\nmanipulation and illustration of data grow exponentially. Due to the large\nscale data sets, Curse of dimensionality (CoD) is one of the NP-hard problems\nin data science. Hence, several efforts have been focused on leveraging\nevolutionary algorithms (EAs) to address the complex issues in large scale data\nanalytics problems. Dimension reduction, together with EAs, lends itself to\nsolve CoD and solve complex problems, in terms of time complexity, efficiently.\nIn this chapter, we first provide a brief overview of previous studies that\nfocused on solving CoD using feature extraction optimization process. We then\ndiscuss practical examples of research studies are successfully tackled some\napplication domains, such as image processing, sentiment analysis, network\ntraffics / anomalies analysis, credit score analysis and other benchmark\nfunctions/data sets analysis.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:01:09 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Mohammadi", "Farid Ghareh", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "1908.08564", "submitter": "Saurav Manchanda", "authors": "Saurav Manchanda, Mohit Sharma and George Karypis", "title": "Intent term selection and refinement in e-commerce queries", "comments": "Extended version of paper \"Intent term weighing in e-commerce\n  queries\" to appear in CIKM'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce, a user tends to search for the desired product by issuing a\nquery to the search engine and examining the retrieved results. If the search\nengine was successful in correctly understanding the user's query, it will\nreturn results that correspond to the products whose attributes match the terms\nin the query that are representative of the query's product intent. However,\nthe search engine may fail to retrieve results that satisfy the query's product\nintent and thus degrading user experience due to different issues in query\nprocessing: (i) when multiple terms are present in a query it may fail to\ndetermine the relevant terms that are representative of the query's product\nintent, and (ii) it may suffer from vocabulary gap between the terms in the\nquery and the product's description, i.e., terms used in the query are\nsemantically similar but different from the terms in the product description.\nHence, identifying the terms that describe the query's product intent and\npredicting additional terms that describe the query's product intent better\nthan the existing query terms to the search engine is an essential task in\ne-commerce search. In this paper, we leverage the historical query\nreformulation logs of a major e-commerce retailer to develop distant-supervised\napproaches to solve both these problems. Our approaches exploit the fact that\nthe significance of a term is dependent upon the context (other terms in the\nneighborhood) in which it is used in order to learn the importance of the term\ntowards the query's product intent. We show that identifying and emphasizing\nthe terms that define the query's product intent leads to a 3% improvement in\nranking. Moreover, for the tasks of identifying the important terms in a query\nand for predicting the additional terms that represent product intent,\nexperiments illustrate that our approaches outperform the non-contextual\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:04:24 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Manchanda", "Saurav", ""], ["Sharma", "Mohit", ""], ["Karypis", "George", ""]]}, {"id": "1908.08572", "submitter": "Ryan Rossi", "authors": "Ryan A. Rossi, Di Jin, Sungchul Kim, Nesreen K. Ahmed, Danai Koutra\n  and John Boaz Lee", "title": "On Proximity and Structural Role-based Embeddings in Networks:\n  Misconceptions, Techniques, and Applications", "comments": null, "journal-ref": "ACM Transactions on Knowledge Discovery from Data (TKDD), Vol. 14,\n  No. 5, Article 63 (August 2020), 37 pages", "doi": "10.1145/3397191", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural roles define sets of structurally similar nodes that are more\nsimilar to nodes inside the set than outside, whereas communities define sets\nof nodes with more connections inside the set than outside. Roles based on\nstructural similarity and communities based on proximity are fundamentally\ndifferent but important complementary notions. Recently, the notion of\nstructural roles has become increasingly important and has gained a lot of\nattention due to the proliferation of work on learning representations\n(node/edge embeddings) from graphs that preserve the notion of roles.\nUnfortunately, recent work has sometimes confused the notion of structural\nroles and communities (based on proximity) leading to misleading or incorrect\nclaims about the capabilities of network embedding methods. As such, this paper\nseeks to clarify the misconceptions and key differences between structural\nroles and communities, and formalize the general mechanisms (e.g., random\nwalks, feature diffusion) that give rise to community or role-based structural\nembeddings. We theoretically prove that embedding methods based on these\nmechanisms result in either community or role-based structural embeddings.\nThese mechanisms are typically easy to identify and can help researchers\nquickly determine whether a method preserves community or role-based\nembeddings. Furthermore, they also serve as a basis for developing new and\nimproved methods for community or role-based structural embeddings. Finally, we\nanalyze and discuss applications and data characteristics where community or\nrole-based embeddings are most appropriate.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:27:34 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 17:56:04 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Rossi", "Ryan A.", ""], ["Jin", "Di", ""], ["Kim", "Sungchul", ""], ["Ahmed", "Nesreen K.", ""], ["Koutra", "Danai", ""], ["Lee", "John Boaz", ""]]}, {"id": "1908.08574", "submitter": "Anil Kag", "authors": "Anil Kag, Ziming Zhang, Venkatesh Saligrama", "title": "RNNs Evolving on an Equilibrium Manifold: A Panacea for Vanishing and\n  Exploding Gradients?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are particularly well-suited for modeling\nlong-term dependencies in sequential data, but are notoriously hard to train\nbecause the error backpropagated in time either vanishes or explodes at an\nexponential rate. While a number of works attempt to mitigate this effect\nthrough gated recurrent units, well-chosen parametric constraints, and\nskip-connections, we develop a novel perspective that seeks to evolve the\nhidden state on the equilibrium manifold of an ordinary differential equation\n(ODE). We propose a family of novel RNNs, namely {\\em Equilibriated Recurrent\nNeural Networks} (ERNNs) that overcome the gradient decay or explosion effect\nand lead to recurrent models that evolve on the equilibrium manifold. We show\nthat equilibrium points are stable, leading to fast convergence of the\ndiscretized ODE to fixed points. Furthermore, ERNNs account for long-term\ndependencies, and can efficiently recall informative aspects of data from the\ndistant past. We show that ERNNs achieve state-of-the-art accuracy on many\nchallenging data sets with 3-10x speedups, 1.5-3x model size reduction, and\nwith similar prediction cost relative to vanilla RNNs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:35:13 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 21:20:39 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Kag", "Anil", ""], ["Zhang", "Ziming", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1908.08576", "submitter": "Yu Ye", "authors": "Yu Ye, Ming Xiao, Mikael Skoglund", "title": "Mobility-aware Content Preference Learning in Decentralized Caching\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the drastic increase of mobile traffic, wireless caching is proposed\nto serve repeated requests for content download. To determine the caching\nscheme for decentralized caching networks, the content preference learning\nproblem based on mobility prediction is studied. We first formulate preference\nprediction as a decentralized regularized multi-task learning (DRMTL) problem\nwithout considering the mobility of mobile terminals (MTs). The problem is\nsolved by a hybrid Jacobian and Gauss-Seidel proximal multi-block alternating\ndirection method (ADMM) based algorithm, which is proven to conditionally\nconverge to the optimal solution with a rate $O(1/k)$. Then we use the tool of\n\\textit{Markov renewal process} to predict the moving path and sojourn time for\nMTs, and integrate the mobility pattern with the DRMTL model by reweighting the\ntraining samples and introducing a transfer penalty in the objective. We solve\nthe problem and prove that the developed algorithm has the same convergence\nproperty but with different conditions. Through simulation we show the\nconvergence analysis on proposed algorithms. Our real trace driven experiments\nillustrate that the mobility-aware DRMTL model can provide a more accurate\nprediction on geography preference than DRMTL model. Besides, the hit ratio\nachieved by most popular proactive caching (MPC) policy with preference\npredicted by mobility-aware DRMTL outperforms the MPC with preference from\nDRMTL and random caching (RC) schemes.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:52:17 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Ye", "Yu", ""], ["Xiao", "Ming", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1908.08578", "submitter": "Tao Li", "authors": "Tao Li and Quanyan Zhu", "title": "On Convergence Rate of Adaptive Multiscale Value Function Approximation\n  For Reinforcement Learning", "comments": "submitted to 2019 IEEE International Workshop MLSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a generic framework for devising an adaptive\napproximation scheme for value function approximation in reinforcement\nlearning, which introduces multiscale approximation. The two basic ingredients\nare multiresolution analysis as well as tree approximation. Starting from\nsimple refinable functions, multiresolution analysis enables us to construct a\nwavelet system from which the basis functions are selected adaptively,\nresulting in a tree structure. Furthermore, we present the convergence rate of\nour multiscale approximation which does not depend on the regularity of basis\nfunctions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:56:26 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Li", "Tao", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1908.08593", "submitter": "Olga Kovaleva", "authors": "Olga Kovaleva, Alexey Romanov, Anna Rogers, Anna Rumshisky", "title": "Revealing the Dark Secrets of BERT", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT-based architectures currently give state-of-the-art performance on many\nNLP tasks, but little is known about the exact mechanisms that contribute to\nits success. In the current work, we focus on the interpretation of\nself-attention, which is one of the fundamental underlying components of BERT.\nUsing a subset of GLUE tasks and a set of handcrafted features-of-interest, we\npropose the methodology and carry out a qualitative and quantitative analysis\nof the information encoded by the individual BERT's heads. Our findings suggest\nthat there is a limited set of attention patterns that are repeated across\ndifferent heads, indicating the overall model overparametrization. While\ndifferent heads consistently use the same attention patterns, they have varying\nimpact on performance across different tasks. We show that manually disabling\nattention in certain heads leads to a performance improvement over the regular\nfine-tuned BERT models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 04:27:38 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 16:26:37 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kovaleva", "Olga", ""], ["Romanov", "Alexey", ""], ["Rogers", "Anna", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1908.08600", "submitter": "Caio Waisman", "authors": "Caio Waisman, Harikesh S. Nair, Carlos Carrion, Nan Xu", "title": "Online Causal Inference for Advertising in Real-Time Bidding Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time bidding (RTB) systems, which leverage auctions to programmatically\nallocate user impressions to multiple competing advertisers, continue to enjoy\nwidespread success in digital advertising. Assessing the effectiveness of such\nadvertising remains a lingering challenge in research and practice. This paper\npresents a new experimental design to perform causal inference on advertising\nbought through such mechanisms. Our method leverages the economic structure of\nfirst- and second-price auctions, which are ubiquitous in RTB systems, embedded\nwithin a multi-armed bandit (MAB) setup for online adaptive experimentation. We\nimplement it via a modified Thompson sampling (TS) algorithm that estimates\ncausal effects of advertising while minimizing the costs of experimentation to\nthe advertiser by simultaneously learning the optimal bidding policy that\nmaximizes her expected payoffs from auction participation. Simulations show\nthat not only the proposed method successfully accomplishes the advertiser's\ngoals, but also does so at a much lower cost than more conventional\nexperimentation policies aimed at performing causal inference.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 21:13:03 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 21:14:43 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Waisman", "Caio", ""], ["Nair", "Harikesh S.", ""], ["Carrion", "Carlos", ""], ["Xu", "Nan", ""]]}, {"id": "1908.08609", "submitter": "Kai Middlebrook", "authors": "Kai Middlebrook, Kian Sheik", "title": "Song Hit Prediction: Predicting Billboard Hits Using Spotify Data", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we attempt to solve the Hit Song Science problem, which aims to\npredict which songs will become chart-topping hits. We constructed a dataset\nwith approximately 1.8 million hit and non-hit songs and extracted their audio\nfeatures using the Spotify Web API. We test four models on our dataset. Our\nbest model was random forest, which was able to predict Billboard song success\nwith 88% accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 22:10:08 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 18:39:45 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Middlebrook", "Kai", ""], ["Sheik", "Kian", ""]]}, {"id": "1908.08610", "submitter": "Muhammad Maaz", "authors": "Muhammad Maaz (Faculty of Health Sciences, McMaster University)", "title": "Viability of machine learning to reduce workload in systematic review\n  screenings in the health sciences: a working paper", "comments": "10 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic reviews, which summarize and synthesize all the current research\nin a specific topic, are a crucial component to academia. They are especially\nimportant in the biomedical and health sciences, where they synthesize the\nstate of medical evidence and conclude the best course of action for various\ndiseases, pathologies, and treatments. Due to the immense amount of literature\nthat exists, as well as the output rate of research, reviewing abstracts can be\na laborious process. Automation may be able to significantly reduce this\nworkload. Of course, such classifications are not easily automated due to the\npeculiar nature of written language. Machine learning may be able to help. This\npaper explored the viability and effectiveness of using machine learning\nmodelling to classify abstracts according to specific exclusion/inclusion\ncriteria, as would be done in the first stage of a systematic review. The\nspecific task was performing the classification of deciding whether an abstract\nis a randomized control trial (RCT) or not, a very common classification made\nin systematic reviews in the healthcare field. Random training/testing splits\nof an n=2042 dataset of labelled abstracts were repeatedly created (1000 times\nin total), with a model trained and tested on each of these instances. A Bayes\nclassifier as well as an SVM classifier were used, and compared to non-machine\nlearning, simplistic approaches to textual classification. An SVM classifier\nwas seen to be highly effective, yielding a 90% accuracy, as well as an F1\nscore of 0.84, and yielded a potential workload reduction of 70%. This shows\nthat machine learning has the potential to significantly revolutionize the\nabstract screening process in healthcare systematic reviews.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 22:13:32 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Maaz", "Muhammad", "", "Faculty of Health Sciences, McMaster University"]]}, {"id": "1908.08612", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Tiered Graph Autoencoders with PyTorch Geometric for Molecular Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tiered latent representations and latent spaces for molecular graphs provide\na simple but effective way to explicitly represent and utilize groups (e.g.,\nfunctional groups), which consist of the atom (node) tier, the group tier and\nthe molecule (graph) tier. They can be learned using the tiered graph\nautoencoder architecture. In this paper we discuss adapting tiered graph\nautoencoders for use with PyTorch Geometric, for both the deterministic tiered\ngraph autoencoder model and the probabilistic tiered variational graph\nautoencoder model. We also discuss molecular structure information sources that\ncan be accessed to extract training data for molecular graphs. To support\ntransfer learning, a critical consideration is that the information must\nutilize standard unique molecule and constituent atom identifiers. As a result\nof using tiered graph autoencoders for deep learning, each molecular graph\npossesses tiered latent representations. At each tier, the latent\nrepresentation consists of: node features, edge indices, edge features,\nmembership matrix, and node embeddings. This enables the utilization and\nexploration of tiered molecular latent spaces, either individually (the node\ntier, the group tier, or the graph tier) or jointly, as well as navigation\nacross the tiers.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 22:23:24 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "1908.08616", "submitter": "Ahmad Mousavi", "authors": "Ahmad Mousavi, Zheming Gao, Lanshan Han, and Alvin Lim", "title": "Quadratic Surface Support Vector Machine with L1 Norm Regularization", "comments": null, "journal-ref": null, "doi": "10.3934/jimo.2021046", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose $\\ell_1$ norm regularized quadratic surface support vector machine\nmodels for binary classification in supervised learning. We establish their\ndesired theoretical properties, including the existence and uniqueness of the\noptimal solution, reduction to the standard SVMs over (almost) linearly\nseparable data sets, and detection of true sparsity pattern over (almost)\nquadratically separable data sets if the penalty parameter of $\\ell_1$ norm is\nlarge enough. We also demonstrate their promising practical efficiency by\nconducting various numerical experiments on both synthetic and publicly\navailable benchmark data sets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 23:00:28 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 21:58:16 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Mousavi", "Ahmad", ""], ["Gao", "Zheming", ""], ["Han", "Lanshan", ""], ["Lim", "Alvin", ""]]}, {"id": "1908.08619", "submitter": "Ruoxi Jia", "authors": "Ruoxi Jia, David Dao, Boxin Wang, Frances Ann Hubis, Nezihe Merve\n  Gurel, Bo Li, Ce Zhang, Costas J. Spanos, Dawn Song", "title": "Efficient Task-Specific Data Valuation for Nearest Neighbor Algorithms", "comments": null, "journal-ref": "PVLDB, 12(11): 1610-1623, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a data set $\\mathcal{D}$ containing millions of data points and a data\nconsumer who is willing to pay for \\$$X$ to train a machine learning (ML) model\nover $\\mathcal{D}$, how should we distribute this \\$$X$ to each data point to\nreflect its \"value\"? In this paper, we define the \"relative value of data\" via\nthe Shapley value, as it uniquely possesses properties with appealing\nreal-world interpretations, such as fairness, rationality and\ndecentralizability. For general, bounded utility functions, the Shapley value\nis known to be challenging to compute: to get Shapley values for all $N$ data\npoints, it requires $O(2^N)$ model evaluations for exact computation and\n$O(N\\log N)$ for $(\\epsilon, \\delta)$-approximation. In this paper, we focus on\none popular family of ML models relying on $K$-nearest neighbors ($K$NN). The\nmost surprising result is that for unweighted $K$NN classifiers and regressors,\nthe Shapley value of all $N$ data points can be computed, exactly, in $O(N\\log\nN)$ time -- an exponential improvement on computational complexity! Moreover,\nfor $(\\epsilon, \\delta)$-approximation, we are able to develop an algorithm\nbased on Locality Sensitive Hashing (LSH) with only sublinear complexity\n$O(N^{h(\\epsilon,K)}\\log N)$ when $\\epsilon$ is not too small and $K$ is not\ntoo large. We empirically evaluate our algorithms on up to $10$ million data\npoints and even our exact algorithm is up to three orders of magnitude faster\nthan the baseline approximation algorithm. The LSH-based approximation\nalgorithm can accelerate the value calculation process even further. We then\nextend our algorithms to other scenarios such as (1) weighed $K$NN classifiers,\n(2) different data points are clustered by different data curators, and (3)\nthere are data analysts providing computation who also requires proper\nvaluation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 23:09:27 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 02:45:43 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 04:46:57 GMT"}, {"version": "v4", "created": "Sun, 29 Mar 2020 06:05:56 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Jia", "Ruoxi", ""], ["Dao", "David", ""], ["Wang", "Boxin", ""], ["Hubis", "Frances Ann", ""], ["Gurel", "Nezihe Merve", ""], ["Li", "Bo", ""], ["Zhang", "Ce", ""], ["Spanos", "Costas J.", ""], ["Song", "Dawn", ""]]}, {"id": "1908.08623", "submitter": "Surjyendu Ray", "authors": "Surjyendu Ray, Bei Jia, Sam Safavi, Tim van Opijnen, Ralph Isberg,\n  Jason Rosch and Jos\\'e Bento", "title": "Exact inference under the perfect phylogeny model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Motivation: Many inference tools use the Perfect Phylogeny Model (PPM) to\nlearn trees from noisy variant allele frequency (VAF) data. Learning in this\nsetting is hard, and existing tools use approximate or heuristic algorithms. An\nalgorithmic improvement is important to help disentangle the limitations of the\nPPM's assumptions from the limitations in our capacity to learn under it.\nResults: We make such improvement in the scenario, where the mutations that are\nrelevant for evolution can be clustered into a small number of groups, and the\ntrees to be reconstructed have a small number of nodes. We use a careful\ncombination of algorithms, software, and hardware, to develop EXACT: a tool\nthat can explore the space of all possible phylogenetic trees, and performs\nexact inference under the PPM with noisy data. EXACT allows users to obtain not\njust the most-likely tree for some input data, but exact statistics about the\ndistribution of trees that might explain the data. We show that EXACT\noutperforms several existing tools for this same task. Availability:\nhttps://github.com/surjray-repos/EXACT\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 23:50:31 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Ray", "Surjyendu", ""], ["Jia", "Bei", ""], ["Safavi", "Sam", ""], ["van Opijnen", "Tim", ""], ["Isberg", "Ralph", ""], ["Rosch", "Jason", ""], ["Bento", "Jos\u00e9", ""]]}, {"id": "1908.08649", "submitter": "Waheed Bajwa", "authors": "Zhixiong Yang, Arpita Gang, and Waheed U. Bajwa", "title": "Adversary-resilient Distributed and Decentralized Statistical Inference\n  and Machine Learning: An Overview of Recent Advances Under the Byzantine\n  Threat Model", "comments": "24 pages, 6 figures, 2 tables; Published in IEEE Signal Processing\n  Magazine, May 2020 (Special Issue on \"Machine Learning From Distributed,\n  Streaming Data\")", "journal-ref": "IEEE Signal Processing Mag., vol. 37, no. 3, pp. 146-159, May 2020", "doi": "10.1109/MSP.2020.2973345", "report-no": null, "categories": "stat.ML cs.CR cs.DC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the last few decades have witnessed a huge body of work devoted to\ninference and learning in distributed and decentralized setups, much of this\nwork assumes a non-adversarial setting in which individual nodes---apart from\noccasional statistical failures---operate as intended within the algorithmic\nframework. In recent years, however, cybersecurity threats from malicious\nnon-state actors and rogue entities have forced practitioners and researchers\nto rethink the robustness of distributed and decentralized algorithms against\nadversarial attacks. As a result, we now have a plethora of algorithmic\napproaches that guarantee robustness of distributed and/or decentralized\ninference and learning under different adversarial threat models. Driven in\npart by the world's growing appetite for data-driven decision making, however,\nsecuring of distributed/decentralized frameworks for inference and learning\nagainst adversarial threats remains a rapidly evolving research area. In this\narticle, we provide an overview of some of the most recent developments in this\narea under the threat model of Byzantine attacks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 03:23:49 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 17:39:59 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 02:21:10 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Yang", "Zhixiong", ""], ["Gang", "Arpita", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1908.08652", "submitter": "Suraj Tripathi", "authors": "Abhay Kumar, Nishant Jain, Suraj Tripathi, Chirag Singh, Kamal Krishna", "title": "MTCNET: Multi-task Learning Paradigm for Crowd Count Estimation", "comments": "5 pages, 3 figures, Accepted in IEEE AVSS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Multi-Task Learning (MTL) paradigm based deep neural network\narchitecture, called MTCNet (Multi-Task Crowd Network) for crowd density and\ncount estimation. Crowd count estimation is challenging due to the non-uniform\nscale variations and the arbitrary perspective of an individual image. The\nproposed model has two related tasks, with Crowd Density Estimation as the main\ntask and Crowd-Count Group Classification as the auxiliary task. The auxiliary\ntask helps in capturing the relevant scale-related information to improve the\nperformance of the main task. The main task model comprises two blocks: VGG-16\nfront-end for feature extraction and a dilated Convolutional Neural Network for\ndensity map generation. The auxiliary task model shares the same front-end as\nthe main task, followed by a CNN classifier. Our proposed network achieves 5.8%\nand 14.9% lower Mean Absolute Error (MAE) than the state-of-the-art methods on\nShanghaiTech dataset without using any data augmentation. Our model also\noutperforms with 10.5% lower MAE on UCF_CC_50 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 03:30:53 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Kumar", "Abhay", ""], ["Jain", "Nishant", ""], ["Tripathi", "Suraj", ""], ["Singh", "Chirag", ""], ["Krishna", "Kamal", ""]]}, {"id": "1908.08655", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia", "title": "Spiking Neural Predictive Coding for Continual Learning from Data\n  Streams", "comments": "Revised version of manuscript -- includes updated experimental\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For energy-efficient computation in specialized neuromorphic hardware, we\npresent the Spiking Neural Coding Network, an instantiation of a family of\nartificial neural models strongly motivated by the theory of predictive coding.\nThe model, in essence, works by operating in a never-ending process of\n\"guess-and-check\", where neurons predict the activity values of one another and\nthen immediately adjust their own activities to make better future predictions.\nThe interactive, iterative nature of our neural system fits well into the\ncontinuous time formulation of data sensory stream prediction and, as we show,\nthe model's structure yields a simple, local synaptic update rule, which could\nbe used to complement or replace online spike-timing dependent plasticity. In\nthis article, we experiment with an instantiation of our model that consists of\nleaky integrate-and-fire units. However, the general framework within which our\nmodel is situated can naturally incorporate more complex, formal neurons such\nas the Hodgkin-Huxley model. Our experimental results in pattern recognition\ndemonstrate the potential of the proposed model when binary spike trains are\nthe primary paradigm for inter-neuron communication. Notably, our model is\ncompetitive in terms of classification performance, can conduct online\nsemi-supervised learning, naturally experiences less forgetting when learning\nfrom a sequence of tasks, and is more computationally economical and\nbiologically-plausible than popular artificial neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 03:44:27 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 20:30:45 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Ororbia", "Alexander", ""]]}, {"id": "1908.08659", "submitter": "Lev Grossman", "authors": "Patrick Varin, Lev Grossman, and Scott Kuindersma", "title": "A Comparison of Action Spaces for Learning Manipulation Tasks", "comments": "Accepted as a conference paper at IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing reinforcement learning (RL) problems that can produce delicate and\nprecise manipulation policies requires careful choice of the reward function,\nstate, and action spaces. Much prior work on applying RL to manipulation tasks\nhas defined the action space in terms of direct joint torques or reference\npositions for a joint-space proportional derivative (PD) controller. In\npractice, it is often possible to add additional structure by taking advantage\nof model-based controllers that support both accurate positioning and control\nof the dynamic response of the manipulator. In this paper, we evaluate how the\nchoice of action space for dynamic manipulation tasks affects the sample\ncomplexity as well as the final quality of learned policies. We compare\nlearning performance across three tasks (peg insertion, hammering, and\npushing), four action spaces (torque, joint PD, inverse dynamics, and impedance\ncontrol), and using two modern reinforcement learning algorithms (Proximal\nPolicy Optimization and Soft Actor-Critic). Our results lend support to the\nhypothesis that learning references for a task-space impedance controller\nsignificantly reduces the number of samples needed to achieve good performance\nacross all tasks and algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 04:26:26 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Varin", "Patrick", ""], ["Grossman", "Lev", ""], ["Kuindersma", "Scott", ""]]}, {"id": "1908.08674", "submitter": "Debabrata Paul", "authors": "Debabrata Paul and Bidyut Baran Chaudhuri", "title": "A BLSTM Network for Printed Bengali OCR System with High Accuracy", "comments": "6 pages, 6 figures, This OCR system is available online at\n  https://banglaocr.nltr.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a printed Bengali and English text OCR system developed\nby us using a single hidden BLSTM-CTC architecture having 128 units. Here, we\ndid not use any peephole connection and dropout in the BLSTM, which helped us\nin getting better accuracy. This architecture was trained by 47,720 text lines\nthat include English words also. When tested over 20 different Bengali fonts,\nit has produced character level accuracy of 99.32% and word level accuracy of\n96.65%. A good Indic multi script OCR system is also developed by Google. It\nsometimes recognizes a character of Bengali into the same character of a\nnon-Bengali script, especially Assamese, which has no distinction from Bengali,\nexcept for a few characters. For example, Bengali character for 'RA' is\nsometimes recognized as that of Assamese, mainly in conjunct consonant forms.\nOur OCR is free from such errors. This OCR system is available online at\nhttps://banglaocr.nltr.org\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 05:45:27 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Paul", "Debabrata", ""], ["Chaudhuri", "Bidyut Baran", ""]]}, {"id": "1908.08681", "submitter": "Diganta Misra", "authors": "Diganta Misra", "title": "Mish: A Self Regularized Non-Monotonic Activation Function", "comments": "Accepted to BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose $\\textit{Mish}$, a novel self-regularized non-monotonic activation\nfunction which can be mathematically defined as: $f(x)=x\\tanh(softplus(x))$. As\nactivation functions play a crucial role in the performance and training\ndynamics in neural networks, we validated experimentally on several well-known\nbenchmarks against the best combinations of architectures and activation\nfunctions. We also observe that data augmentation techniques have a favorable\neffect on benchmarks like ImageNet-1k and MS-COCO across multiple\narchitectures. For example, Mish outperformed Leaky ReLU on YOLOv4 with a\nCSP-DarkNet-53 backbone on average precision ($AP_{50}^{val}$) by 2.1$\\%$ in\nMS-COCO object detection and ReLU on ResNet-50 on ImageNet-1k in Top-1 accuracy\nby $\\approx$1$\\%$ while keeping all other network parameters and\nhyperparameters constant. Furthermore, we explore the mathematical formulation\nof Mish in relation with the Swish family of functions and propose an intuitive\nunderstanding on how the first derivative behavior may be acting as a\nregularizer helping the optimization of deep neural networks. Code is publicly\navailable at https://github.com/digantamisra98/Mish.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 06:22:06 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 16:59:14 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 05:42:12 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Misra", "Diganta", ""]]}, {"id": "1908.08704", "submitter": "Shunkai Li", "authors": "Shunkai Li, Fei Xue, Xin Wang, Zike Yan, Hongbin Zha", "title": "Sequential Adversarial Learning for Self-Supervised Deep Visual Odometry", "comments": "Accept to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a self-supervised learning framework for visual odometry (VO) that\nincorporates correlation of consecutive frames and takes advantage of\nadversarial learning. Previous methods tackle self-supervised VO as a local\nstructure from motion (SfM) problem that recovers depth from single image and\nrelative poses from image pairs by minimizing photometric loss between warped\nand captured images. As single-view depth estimation is an ill-posed problem,\nand photometric loss is incapable of discriminating distortion artifacts of\nwarped images, the estimated depth is vague and pose is inaccurate. In contrast\nto previous methods, our framework learns a compact representation of\nframe-to-frame correlation, which is updated by incorporating sequential\ninformation. The updated representation is used for depth estimation. Besides,\nwe tackle VO as a self-supervised image generation task and take advantage of\nGenerative Adversarial Networks (GAN). The generator learns to estimate depth\nand pose to generate a warped target image. The discriminator evaluates the\nquality of generated image with high-level structural perception that overcomes\nthe problem of pixel-wise loss in previous methods. Experiments on KITTI and\nCityscapes datasets show that our method obtains more accurate depth with\ndetails preserved and predicted pose outperforms state-of-the-art\nself-supervised methods significantly.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 07:53:35 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Li", "Shunkai", ""], ["Xue", "Fei", ""], ["Wang", "Xin", ""], ["Yan", "Zike", ""], ["Zha", "Hongbin", ""]]}, {"id": "1908.08713", "submitter": "Valentin Emiya", "authors": "Luc Giffon, Valentin Emiya, Liva Ralaivola, Hachem Kadri", "title": "QuicK-means: Acceleration of K-means by learning a fast transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-means -- and the celebrated Lloyd algorithm -- is more than the clustering\nmethod it was originally designed to be. It has indeed proven pivotal to help\nincrease the speed of many machine learning and data analysis techniques such\nas indexing, nearest-neighbor search and prediction, data compression; its\nbeneficial use has been shown to carry over to the acceleration of kernel\nmachines (when using the Nystr\\\"om method). Here, we propose a fast extension\nof K-means, dubbed QuicK-means, that rests on the idea of expressing the matrix\nof the $K$ centroids as a product of sparse matrices, a feat made possible by\nrecent results devoted to find approximations of matrices as a product of\nsparse factors. Using such a decomposition squashes the complexity of the\nmatrix-vector product between the factorized $K \\times D$ centroid matrix\n$\\mathbf{U}$ and any vector from $\\mathcal{O}(K D)$ to $\\mathcal{O}(A \\log\nA+B)$, with $A=\\min (K, D)$ and $B=\\max (K, D)$, where $D$ is the dimension of\nthe training data. This drastic computational saving has a direct impact in the\nassignment process of a point to a cluster, meaning that it is not only\ntangible at prediction time, but also at training time, provided the\nfactorization procedure is performed during Lloyd's algorithm. We precisely\nshow that resorting to a factorization step at each iteration does not impair\nthe convergence of the optimization scheme and that, depending on the context,\nit may entail a reduction of the training time. Finally, we provide discussions\nand numerical simulations that show the versatility of our\ncomputationally-efficient QuicK-means algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 08:20:53 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Giffon", "Luc", ""], ["Emiya", "Valentin", ""], ["Ralaivola", "Liva", ""], ["Kadri", "Hachem", ""]]}, {"id": "1908.08729", "submitter": "Viet Anh Nguyen", "authors": "Daniel Kuhn, Peyman Mohajerin Esfahani, Viet Anh Nguyen, Soroosh\n  Shafieezadeh-Abadeh", "title": "Wasserstein Distributionally Robust Optimization: Theory and\n  Applications in Machine Learning", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many decision problems in science, engineering and economics are affected by\nuncertain parameters whose distribution is only indirectly observable through\nsamples. The goal of data-driven decision-making is to learn a decision from\nfinitely many training samples that will perform well on unseen test samples.\nThis learning task is difficult even if all training and test samples are drawn\nfrom the same distribution---especially if the dimension of the uncertainty is\nlarge relative to the training sample size. Wasserstein distributionally robust\noptimization seeks data-driven decisions that perform well under the most\nadverse distribution within a certain Wasserstein distance from a nominal\ndistribution constructed from the training samples. In this tutorial we will\nargue that this approach has many conceptual and computational benefits. Most\nprominently, the optimal decisions can often be computed by solving tractable\nconvex optimization problems, and they enjoy rigorous out-of-sample and\nasymptotic consistency guarantees. We will also show that Wasserstein\ndistributionally robust optimization has interesting ramifications for\nstatistical learning and motivates new approaches for fundamental learning\ntasks such as classification, regression, maximum likelihood estimation or\nminimum mean square error estimation, among others.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 09:28:21 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Kuhn", "Daniel", ""], ["Esfahani", "Peyman Mohajerin", ""], ["Nguyen", "Viet Anh", ""], ["Shafieezadeh-Abadeh", "Soroosh", ""]]}, {"id": "1908.08733", "submitter": "Fei Wang", "authors": "Fei Wang, Qi Liu, Enhong Chen, Zhenya Huang, Yuying Chen, Yu Yin, Zai\n  Huang, Shijin Wang", "title": "Neural Cognitive Diagnosis for Intelligent Education Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive diagnosis is a fundamental issue in intelligent education, which\naims to discover the proficiency level of students on specific knowledge\nconcepts. Existing approaches usually mine linear interactions of student\nexercising process by manual-designed function (e.g., logistic function), which\nis not sufficient for capturing complex relations between students and\nexercises. In this paper, we propose a general Neural Cognitive Diagnosis\n(NeuralCD) framework, which incorporates neural networks to learn the complex\nexercising interactions, for getting both accurate and interpretable diagnosis\nresults. Specifically, we project students and exercises to factor vectors and\nleverage multi neural layers for modeling their interactions, where the\nmonotonicity assumption is applied to ensure the interpretability of both\nfactors. Furthermore, we propose two implementations of NeuralCD by\nspecializing the required concepts of each exercise, i.e., the NeuralCDM with\ntraditional Q-matrix and the improved NeuralCDM+ exploring the rich text\ncontent. Extensive experimental results on real-world datasets show the\neffectiveness of NeuralCD framework with both accuracy and interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 09:38:13 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 13:36:38 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 15:27:57 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Wang", "Fei", ""], ["Liu", "Qi", ""], ["Chen", "Enhong", ""], ["Huang", "Zhenya", ""], ["Chen", "Yuying", ""], ["Yin", "Yu", ""], ["Huang", "Zai", ""], ["Wang", "Shijin", ""]]}, {"id": "1908.08734", "submitter": "Christoph Schran", "authors": "Christoph Schran, J\\\"org Behler, Dominik Marx", "title": "Automated Fitting of Neural Network Potentials at Coupled Cluster\n  Accuracy: Protonated Water Clusters as Testing Ground", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jctc.9b00805", "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly accurate potential energy surfaces are of key interest for the\ndetailed understanding and predictive modeling of chemical systems. In recent\nyears, several new types of force fields, which are based on machine learning\nalgorithms and fitted to ab initio reference calculations, have been introduced\nto meet this requirement. Here we show how high-dimensional neural network\npotentials can be employed to automatically generate the potential energy\nsurface of finite sized clusters at coupled cluster accuracy, namely\nCCSD(T*)-F12a/aug-cc-pVTZ. The developed automated procedure utilizes the\nestablished intrinsic properties of the model such that the configurations for\nthe training set are selected in an unbiased and efficient way to minimize the\ncomputational effort of expensive reference calculations. These ideas are\napplied to protonated water clusters from the hydronium cation, H$_3$O$^+$, up\nto the tetramer, H$_9$O$_{4}^{+}$, and lead to a single potential energy\nsurface that describes all these systems at essentially converged coupled\ncluster accuracy with a fitting error of 0.06 kJ/mol per atom. The fit is\nvalidated in detail for all clusters up to the tetramer and yields reliable\nresults not only for stationary points, but also for reaction pathways,\nintermediate configurations, as well as different sampling techniques. Per\ndesign the NNPs constructed in this fashion can handle very different\nconditions including the quantum nature of the nuclei and enhanced sampling\ntechniques covering very low as well as high temperatures. This enables fast\nand exhaustive exploration of the targeted protonated water clusters with\nessentially converged interactions. In addition, the automated process will\nallow one to tackle finite systems much beyond the present case.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 09:38:29 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 13:41:42 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Schran", "Christoph", ""], ["Behler", "J\u00f6rg", ""], ["Marx", "Dominik", ""]]}, {"id": "1908.08740", "submitter": "Maximilian Felde", "authors": "Maximilian Felde and Gerd Stumme", "title": "Interactive Collaborative Exploration using Incomplete Contexts", "comments": "38 pages (31 pages + 7 pages appendix), 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-known knowledge acquisition method in the field of Formal Concept\nAnalysis (FCA) is attribute exploration. It is used to reveal dependencies in a\nset of attributes with help of a domain expert. In most applications no single\nexpert is capable (time- and knowledge-wise) of exploring the knowledge domain\nalone. However, there is up to now no theory that models the interaction of\nmultiple experts for the task of attribute exploration with incomplete\nknowledge. To this end, we to develop a theoretical framework that allows\nmultiple experts to explore domains together. We use a representation of\nincomplete knowledge as three-valued contexts. We then adapt the corresponding\nversion of attribute exploration to fit the setting of multiple experts. We\nsuggest formalizations for key components like expert knowledge, interaction\nand collaboration strategy. In particular, we define an order that allows to\ncompare the results of different exploration strategies on the same task with\nrespect to their information completeness. Furthermore we discuss other ways of\ncomparing collaboration strategies and suggest avenues for future research.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 09:49:43 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 10:50:53 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Felde", "Maximilian", ""], ["Stumme", "Gerd", ""]]}, {"id": "1908.08750", "submitter": "Alexej Klushyn", "authors": "Alexej Klushyn, Nutan Chen, Botond Cseke, Justin Bayer, Patrick van\n  der Smagt", "title": "Increasing the Generalisation Capacity of Conditional VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of one-to-many mappings in supervised learning, where\na single instance has many different solutions of possibly equal cost. The\nframework of conditional variational autoencoders describes a class of methods\nto tackle such structured-prediction tasks by means of latent variables. We\npropose to incentivise informative latent representations for increasing the\ngeneralisation capacity of conditional variational autoencoders. To this end,\nwe modify the latent variable model by defining the likelihood as a function of\nthe latent variable only and introduce an expressive multimodal prior to enable\nthe model for capturing semantically meaningful features of the data. To\nvalidate our approach, we train our model on the Cornell Robot Grasping\ndataset, and modified versions of MNIST and Fashion-MNIST obtaining results\nthat show a significantly higher generalisation capability.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 10:28:59 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 07:37:06 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Klushyn", "Alexej", ""], ["Chen", "Nutan", ""], ["Cseke", "Botond", ""], ["Bayer", "Justin", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1908.08769", "submitter": "Dittaya Wanvarie", "authors": "Kawisorn Kamtue, Kasina Euchukanonchai, Dittaya Wanvarie and Naruemon\n  Pratanwanich", "title": "Lukthung Classification Using Neural Networks on Lyrics and Audios", "comments": "ICSEC 2019 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music genre classification is a widely researched topic in music information\nretrieval (MIR). Being able to automatically tag genres will benefit music\nstreaming service providers such as JOOX, Apple Music, and Spotify for their\ncontent-based recommendation. However, most studies on music classification\nhave been done on western songs which differ from Thai songs. Lukthung, a\ndistinctive and long-established type of Thai music, is one of the most popular\nmusic genres in Thailand and has a specific group of listeners. In this paper,\nwe develop neural networks to classify such Lukthung genre from others using\nboth lyrics and audios. Words used in Lukthung songs are particularly poetical,\nand their musical styles are uniquely composed of traditional Thai instruments.\nWe leverage these two main characteristics by building a lyrics model based on\nbag-of-words (BoW), and an audio model using a convolutional neural network\n(CNN) architecture. We then aggregate the intermediate features learned from\nboth models to build a final classifier. Our results show that the proposed\nthree models outperform all of the standard classifiers where the combined\nmodel yields the best $F_1$ score of 0.86, allowing Lukthung classification to\nbe applicable to personalized recommendation for Thai audience.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 11:55:13 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 09:43:51 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Kamtue", "Kawisorn", ""], ["Euchukanonchai", "Kasina", ""], ["Wanvarie", "Dittaya", ""], ["Pratanwanich", "Naruemon", ""]]}, {"id": "1908.08771", "submitter": "Sakira Hassan", "authors": "Syeda Sakira Hassan, Heikki Huttunen, Jari Niemi and Jussi Tohka", "title": "Bayesian Receiver Operating Characteristic Metric for Linear Classifiers", "comments": "Accepted in Pattern Recognition Letters", "journal-ref": null, "doi": "10.1016/j.patrec.2019.07.016", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel classifier accuracy metric: the Bayesian Area Under the\nReceiver Operating Characteristic Curve (CBAUC). The method estimates the area\nunder the ROC curve and is related to the recently proposed Bayesian Error\nEstimator. The metric can assess the quality of a classifier using only the\ntraining dataset without the need for computationally expensive\ncross-validation. We derive a closed-form solution of the proposed accuracy\nmetric for any linear binary classifier under the Gaussianity assumption, and\nstudy the accuracy of the proposed estimator using simulated and real-world\ndata. These experiments confirm that the closed-form CBAUC is both faster and\nmore accurate than conventional AUC estimators.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 11:58:42 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Hassan", "Syeda Sakira", ""], ["Huttunen", "Heikki", ""], ["Niemi", "Jari", ""], ["Tohka", "Jussi", ""]]}, {"id": "1908.08773", "submitter": "Victor Gallego", "authors": "Victor Gallego, Roi Naveiro, David Rios Insua, David Gomez-Ullate\n  Oteiza", "title": "Opponent Aware Reinforcement Learning", "comments": "Substantially extends the previous work:\n  https://www.aaai.org/ojs/index.php/AAAI/article/view/5106. This article draws\n  heavily from arXiv arXiv:1809.01560", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Threatened Markov Decision Processes (TMDPs) as an extension of\nthe classical Markov Decision Process framework for Reinforcement Learning\n(RL). TMDPs allow suporting a decision maker against potential opponents in a\nRL context. We also propose a level-k thinking scheme resulting in a novel\nlearning approach to deal with TMDPs. After introducing our framework and\nderiving theoretical results, relevant empirical evidence is given via\nextensive experiments, showing the benefits of accounting for adversaries in RL\nwhile the agent learns\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 04:19:12 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 14:20:44 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Gallego", "Victor", ""], ["Naveiro", "Roi", ""], ["Insua", "David Rios", ""], ["Oteiza", "David Gomez-Ullate", ""]]}, {"id": "1908.08783", "submitter": "Shantanu Mandal", "authors": "Shantanu Mandal, Todd A. Anderson, Javier S. Turek, Justin\n  Gottschlich, Shengtian Zhou, Abdullah Muzahid", "title": "Learning Fitness Functions for Machine Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of automatic software generation is known as Machine Programming.\nIn this work, we propose a framework based on genetic algorithms to solve this\nproblem. Although genetic algorithms have been used successfully for many\nproblems, one criticism is that hand-crafting its fitness function, the test\nthat aims to effectively guide its evolution, can be notably challenging. Our\nframework presents a novel approach to learn the fitness function using neural\nnetworks to predict values of ideal fitness functions. We also augment the\nevolutionary process with a minimally intrusive search heuristic. This\nheuristic improves the framework's ability to discover correct programs from\nones that are approximately correct and does so with negligible computational\noverhead. We compare our approach with several state-of-the-art program\nsynthesis methods and demonstrate that it finds more correct programs with\nfewer candidate program generations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:47:34 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 09:24:21 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 17:11:08 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 00:03:58 GMT"}, {"version": "v5", "created": "Sat, 23 Jan 2021 21:48:02 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Mandal", "Shantanu", ""], ["Anderson", "Todd A.", ""], ["Turek", "Javier S.", ""], ["Gottschlich", "Justin", ""], ["Zhou", "Shengtian", ""], ["Muzahid", "Abdullah", ""]]}, {"id": "1908.08796", "submitter": "Chao Yu", "authors": "Chao Yu, Jiming Liu and Shamim Nemati", "title": "Reinforcement Learning in Healthcare: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a subfield of machine learning, reinforcement learning (RL) aims at\nempowering one's capabilities in behavioural decision making by using\ninteraction experience with the world and an evaluative feedback. Unlike\ntraditional supervised learning methods that usually rely on one-shot,\nexhaustive and supervised reward signals, RL tackles with sequential decision\nmaking problems with sampled, evaluative and delayed feedback simultaneously.\nSuch distinctive features make RL technique a suitable candidate for developing\npowerful solutions in a variety of healthcare domains, where diagnosing\ndecisions or treatment regimes are usually characterized by a prolonged and\nsequential procedure. This survey discusses the broad applications of RL\ntechniques in healthcare domains, in order to provide the research community\nwith systematic understanding of theoretical foundations, enabling methods and\ntechniques, existing challenges, and new insights of this emerging paradigm. By\nfirst briefly examining theoretical foundations and key techniques in RL\nresearch from efficient and representational directions, we then provide an\noverview of RL applications in healthcare domains ranging from dynamic\ntreatment regimes in chronic diseases and critical care, automated medical\ndiagnosis from both unstructured and structured clinical data, as well as many\nother control or scheduling domains that have infiltrated many aspects of a\nhealthcare system. Finally, we summarize the challenges and open issues in\ncurrent research, and point out some potential solutions and directions for\nfuture research.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 08:32:49 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 10:48:59 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 14:47:41 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2020 14:45:14 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Yu", "Chao", ""], ["Liu", "Jiming", ""], ["Nemati", "Shamim", ""]]}, {"id": "1908.08807", "submitter": "Badong Chen", "authors": "Hao Wu, Ziyu Zhu, Jiayi Wang, Nanning Zheng, Badong Chen", "title": "An encoding framework with brain inner state for natural image\n  identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural encoding and decoding, which aim to characterize the relationship\nbetween stimuli and brain activities, have emerged as an important area in\ncognitive neuroscience. Traditional encoding models, which focus on feature\nextraction and mapping, consider the brain as an input-output mapper without\ninner states. In this work, inspired by the fact that human brain acts like a\nstate machine, we proposed a novel encoding framework that combines information\nfrom both the external world and the inner state to predict brain activity. The\nframework comprises two parts: forward encoding model that deals with visual\nstimuli and inner state model that captures influence from intrinsic\nconnections in the brain. The forward model can be any traditional encoding\nmodel, making the framework flexible. The inner state model is a linear model\nto utilize information in the prediction residuals of the forward model. The\nproposed encoding framework can achieve much better performance on natural\nimage identification from fMRI response than forwardonly models. The\nidentification accuracy will decrease slightly with the dataset size\nincreasing, but remain relatively stable with different identification methods.\nThe results confirm that the new encoding framework is effective and robust\nwhen used for brain decoding.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:41:49 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Wu", "Hao", ""], ["Zhu", "Ziyu", ""], ["Wang", "Jiayi", ""], ["Zheng", "Nanning", ""], ["Chen", "Badong", ""]]}, {"id": "1908.08810", "submitter": "Jannik Fischbach", "authors": "Jannik Fischbach, Maximilian Junker, Andreas Vogelsang, Dietmar\n  Freudenstein", "title": "Automated Generation of Test Models from Semi-Structured Requirements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  [Context:] Model-based testing is an instrument for automated generation of\ntest cases. It requires identifying requirements in documents, understanding\nthem syntactically and semantically, and then translating them into a test\nmodel. One light-weight language for these test models are Cause-Effect-Graphs\n(CEG) that can be used to derive test cases. [Problem:] The creation of test\nmodels is laborious and we lack an automated solution that covers the entire\nprocess from requirement detection to test model creation. In addition, the\nmajority of requirements is expressed in natural language (NL), which is hard\nto translate to test models automatically. [Principal Idea:] We build on the\nfact that not all NL requirements are equally unstructured. We found that 14 %\nof the lines in requirements documents of our industry partner contain\n\"pseudo-code\"-like descriptions of business rules. We apply Machine Learning to\nidentify such semi-structured requirements descriptions and propose a\nrule-based approach for their translation into CEGs. [Contribution:] We make\nthree contributions: (1) an algorithm for the automatic detection of\nsemi-structured requirements descriptions in documents, (2) an algorithm for\nthe automatic translation of the identified requirements into a CEG and (3) a\nstudy demonstrating that our proposed solution leads to 86 % time savings for\ntest model creation without loss of quality.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:02:20 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Fischbach", "Jannik", ""], ["Junker", "Maximilian", ""], ["Vogelsang", "Andreas", ""], ["Freudenstein", "Dietmar", ""]]}, {"id": "1908.08840", "submitter": "Joseph Antony A", "authors": "Joseph Antony, Kevin McGuinness, Kieran Moran, and Noel E O' Connor", "title": "Feature Learning to Automatically Assess Radiographic Knee\n  Osteoarthritis Severity", "comments": "Book Chapter preprint :: Deep Learners and Deep Learner Descriptors\n  for Medical Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This chapter presents the investigations and the results of feature learning\nusing convolutional neural networks to automatically assess knee osteoarthritis\n(OA) severity and the associated clinical and diagnostic features of knee OA\nfrom X-ray images. Also, this chapter demonstrates that feature learning in a\nsupervised manner is more effective than using conventional handcrafted\nfeatures for automatic detection of knee joints and fine-grained knee OA image\nclassification. In the general machine learning approach to automatically\nassess knee OA severity, the first step is to localize the region of interest\nthat is to detect and extract the knee joint regions from the radiographs, and\nthe next step is to classify the localized knee joints based on a radiographic\nclassification scheme such as Kellgren and Lawrence grades. First, the existing\napproaches for detecting (or localizing) the knee joint regions based on\nhandcrafted features are reviewed and outlined. Next, three new approaches are\nintroduced: 1) to automatically detect the knee joint region using a fully\nconvolutional network, 2) to automatically assess the radiographic knee OA\nusing CNNs trained from scratch for classification and regression of knee joint\nimages to predict KL grades in ordinal and continuous scales, and 3) to\nquantify the knee OA severity optimizing a weighted ratio of two loss\nfunctions: categorical cross entropy and mean-squared error using\nmulti-objective convolutional learning and ordinal regression. Two public\ndatasets: the OAI and the MOST are used to evaluate the approaches with\npromising results that outperform existing approaches. In summary, this work\nprimarily contributes to the field of automated methods for localization\n(automatic detection) and quantification (image classification) of radiographic\nknee OA.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 14:23:35 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Antony", "Joseph", ""], ["McGuinness", "Kevin", ""], ["Moran", "Kieran", ""], ["Connor", "Noel E O'", ""]]}, {"id": "1908.08843", "submitter": "Mengnan Du", "authors": "Mengnan Du, Fan Yang, Na Zou, Xia Hu", "title": "Fairness in Deep Learning: A Computational Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is increasingly being used in high-stake decision making\napplications that affect individual lives. However, deep learning models might\nexhibit algorithmic discrimination behaviors with respect to protected groups,\npotentially posing negative impacts on individuals and society. Therefore,\nfairness in deep learning has attracted tremendous attention recently. We\nprovide a review covering recent progresses to tackle algorithmic fairness\nproblems of deep learning from the computational perspective. Specifically, we\nshow that interpretability can serve as a useful ingredient to diagnose the\nreasons that lead to algorithmic discrimination. We also discuss fairness\nmitigation approaches categorized according to three stages of deep learning\nlife-cycle, aiming to push forward the area of fairness in deep learning and\nbuild genuinely fair and reliable deep learning systems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 14:38:07 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 02:33:17 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Du", "Mengnan", ""], ["Yang", "Fan", ""], ["Zou", "Na", ""], ["Hu", "Xia", ""]]}, {"id": "1908.08847", "submitter": "G\\\"okhan Yildirim", "authors": "G\\\"okhan Yildirim, Nikolay Jetchev, Roland Vollgraf, Urs Bergmann", "title": "Generating High-Resolution Fashion Model Images Wearing Custom Outfits", "comments": "Accepted to the International Conference on Computer Vision, ICCV\n  2019, Workshop on Computer Vision for Fashion, Art and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing an outfit is an essential part of shopping for clothes. Due to\nthe combinatorial aspect of combining fashion articles, the available images\nare limited to a pre-determined set of outfits. In this paper, we broaden these\nvisualizations by generating high-resolution images of fashion models wearing a\ncustom outfit under an input body pose. We show that our approach can not only\ntransfer the style and the pose of one generated outfit to another, but also\ncreate realistic images of human bodies and garments.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 14:46:41 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Yildirim", "G\u00f6khan", ""], ["Jetchev", "Nikolay", ""], ["Vollgraf", "Roland", ""], ["Bergmann", "Urs", ""]]}, {"id": "1908.08854", "submitter": "Yuxing Xie", "authors": "Yuxing Xie, Jiaojiao Tian, Xiao Xiang Zhu", "title": "Linking Points With Labels in 3D: A Review of Point Cloud Semantic\n  Segmentation", "comments": "The title of published version was modified to \"Linking Points With\n  Labels in 3D: A Review of Point Cloud Semantic Segmentation\". To read its\n  final version please go to IEEE Geoscience and Remote Sensing Magazine on\n  IEEE XPlore: https://ieeexplore.ieee.org/document/9028090", "journal-ref": null, "doi": "10.1109/MGRS.2019.2937630", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D Point Cloud Semantic Segmentation (PCSS) is attracting increasing\ninterest, due to its applicability in remote sensing, computer vision and\nrobotics, and due to the new possibilities offered by deep learning techniques.\nIn order to provide a needed up-to-date review of recent developments in PCSS,\nthis article summarizes existing studies on this topic. Firstly, we outline the\nacquisition and evolution of the 3D point cloud from the perspective of remote\nsensing and computer vision, as well as the published benchmarks for PCSS\nstudies. Then, traditional and advanced techniques used for Point Cloud\nSegmentation (PCS) and PCSS are reviewed and compared. Finally, important\nissues and open questions in PCSS studies are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 14:55:11 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 13:31:00 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 00:24:30 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Xie", "Yuxing", ""], ["Tian", "Jiaojiao", ""], ["Zhu", "Xiao Xiang", ""]]}, {"id": "1908.08855", "submitter": "Francesco Cursi", "authors": "Francesco Cursi, Guang-Zhong Yang", "title": "A Robust Regression Approach for Robot Model Learning", "comments": "5 pages; 4 figures; to be presented at IROS 2019, Nov 4-8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and data analysis have been used in many robotics fields,\nespecially for modelling. Data are usually the result of sensor measurements\nand, as such, they might be subjected to noise and outliers. The presence of\noutliers has a huge impact on modelling the acquired data, resulting in\ninappropriate models. In this work a novel approach for outlier detection and\nrejection for input/output mapping in regression problems is presented. The\nrobustness of the method is shown both through simulated data for linear and\nnonlinear regression, and real sensory data. Despite being validated by using\nartificial neural networks, the method can be generalized to any other\nregression method\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 14:57:46 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Cursi", "Francesco", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "1908.08856", "submitter": "Joseph Antony A", "authors": "Marc G\\'orriz, Joseph Antony, Kevin McGuinness, Xavier Gir\\'o-i-Nieto,\n  Noel E. O'Connor", "title": "Assessing Knee OA Severity with CNN attention-based end-to-end\n  architectures", "comments": "Proceedings of the 2nd International Conference on Medical Imaging\n  with Deep Learning", "journal-ref": "Proceedings of The 2nd International Conference on Medical Imaging\n  with Deep Learning, PMLR 102:197-214, 2019", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work proposes a novel end-to-end convolutional neural network (CNN)\narchitecture to automatically quantify the severity of knee osteoarthritis (OA)\nusing X-Ray images, which incorporates trainable attention modules acting as\nunsupervised fine-grained detectors of the region of interest (ROI). The\nproposed attention modules can be applied at different levels and scales across\nany CNN pipeline helping the network to learn relevant attention patterns over\nthe most informative parts of the image at different resolutions. We test the\nproposed attention mechanism on existing state-of-the-art CNN architectures as\nour base models, achieving promising results on the benchmark knee OA datasets\nfrom the osteoarthritis initiative (OAI) and multicenter osteoarthritis study\n(MOST). All code from our experiments will be publicly available on the github\nrepository: https://github.com/marc-gorriz/KneeOA-CNNAttention\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 14:59:52 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["G\u00f3rriz", "Marc", ""], ["Antony", "Joseph", ""], ["McGuinness", "Kevin", ""], ["Gir\u00f3-i-Nieto", "Xavier", ""], ["O'Connor", "Noel E.", ""]]}, {"id": "1908.08870", "submitter": "Nick Byrne", "authors": "Nick Byrne, James R. Clough, Isra Valverde, Giovanni Montana, Andrew\n  P. King", "title": "Topology-preserving augmentation for CNN-based segmentation of\n  congenital heart defects from 3D paediatric CMR", "comments": "To be published at MICCAI PIPPI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patient-specific 3D printing of congenital heart anatomy demands an accurate\nsegmentation of the thin tissue interfaces which characterise these diagnoses.\nEven when a label set has a high spatial overlap with the ground truth,\ninaccurate delineation of these interfaces can result in topological errors.\nThese compromise the clinical utility of such models due to the anomalous\nappearance of defects. CNNs have achieved state-of-the-art performance in\nsegmentation tasks. Whilst data augmentation has often played an important\nrole, we show that conventional image resampling schemes used therein can\nintroduce topological changes in the ground truth labelling of augmented\nsamples. We present a novel pipeline to correct for these changes, using a\nfast-marching algorithm to enforce the topology of the ground truth labels\nwithin their augmented representations. In so doing, we invoke the idea of\ncardiac contiguous topology to describe an arbitrary combination of congenital\nheart defects and develop an associated, clinically meaningful metric to\nmeasure the topological correctness of segmentations. In a series of five-fold\ncross-validations, we demonstrate the performance gain produced by this\npipeline and the relevance of topological considerations to the segmentation of\ncongenital heart defects. We speculate as to the applicability of this approach\nto any segmentation task involving morphologically complex targets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 15:34:09 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Byrne", "Nick", ""], ["Clough", "James R.", ""], ["Valverde", "Isra", ""], ["Montana", "Giovanni", ""], ["King", "Andrew P.", ""]]}, {"id": "1908.08873", "submitter": "Joseph Antony A", "authors": "Jaynal Abedin, Joseph Antony, Kevin McGuinness, Kieran Moran, Noel E\n  O'Connor, Dietrich Rebholz-Schuhmann, and John Newell", "title": "Predicting knee osteoarthritis severity: comparative modeling based on\n  patient's data and plain X-ray images", "comments": "Published in Nature Scientific Reports, 2019", "journal-ref": "Scientific reports 9, no. 1 (2019): 5761", "doi": "10.1038/s41598-019-42215-9", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knee osteoarthritis (KOA) is a disease that impairs knee function and causes\npain. A radiologist reviews knee X-ray images and grades the severity level of\nthe impairments according to the Kellgren and Lawrence grading scheme; a\nfive-point ordinal scale (0--4). In this study, we used Elastic Net (EN) and\nRandom Forests (RF) to build predictive models using patient assessment data\n(i.e. signs and symptoms of both knees and medication use) and a convolution\nneural network (CNN) trained using X-ray images only. Linear mixed effect\nmodels (LMM) were used to model the within subject correlation between the two\nknees. The root mean squared error for the CNN, EN, and RF models was 0.77,\n0.97, and 0.94 respectively. The LMM shows similar overall prediction accuracy\nas the EN regression but correctly accounted for the hierarchical structure of\nthe data resulting in more reliable inference. Useful explanatory variables\nwere identified that could be used for patient monitoring before X-ray imaging.\nOur analyses suggest that the models trained for predicting the KOA severity\nlevels achieve comparable results when modeling X-ray images and patient data.\nThe subjectivity in the KL grade is still a primary concern.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 15:38:59 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Abedin", "Jaynal", ""], ["Antony", "Joseph", ""], ["McGuinness", "Kevin", ""], ["Moran", "Kieran", ""], ["O'Connor", "Noel E", ""], ["Rebholz-Schuhmann", "Dietrich", ""], ["Newell", "John", ""]]}, {"id": "1908.08898", "submitter": "Sunwoo Kim", "authors": "Sunwoo Kim, Mrinmoy Maity, Minje Kim", "title": "Incremental Binarization On Recurrent Neural Networks For Single-Channel\n  Source Separation", "comments": "5 pages, 1 figure, 2019 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP 2019)", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682595", "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Bitwise Gated Recurrent Unit (BGRU) network for the\nsingle-channel source separation task. Recurrent Neural Networks (RNN) require\nseveral sets of weights within its cells, which significantly increases the\ncomputational cost compared to the fully-connected networks. To mitigate this\nincreased computation, we focus on the GRU cells and quantize the feedforward\nprocedure with binarized values and bitwise operations. The BGRU network is\ntrained in two stages. The real-valued weights are pretrained and transferred\nto the bitwise network, which are then incrementally binarized to minimize the\npotential loss that can occur from a sudden introduction of quantization. As\nthe proposed binarization technique turns only a few randomly chosen parameters\ninto their binary versions, it gives the network training procedure a chance to\ngently adapt to the partly quantized version of the network. It eventually\nachieves the full binarization by incrementally increasing the amount of\nbinarization over the iterations. Our experiments show that the proposed BGRU\nmethod produces source separation results greater than that of a real-valued\nfully connected network, with 11-12 dB mean Signal-to-Distortion Ratio (SDR). A\nfully binarized BGRU still outperforms a Bitwise Neural Network (BNN) by 1-2 dB\neven with less number of layers.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 16:38:02 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Kim", "Sunwoo", ""], ["Maity", "Mrinmoy", ""], ["Kim", "Minje", ""]]}, {"id": "1908.08906", "submitter": "Dong Liu", "authors": "Dong Liu, Nima N. Moghadam, Lars K. Rasmussen, Jinliang Huang, Saikat\n  Chatterjee", "title": "$\\alpha$ Belief Propagation as Fully Factorized Approximation", "comments": "GlobalSIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief propagation (BP) can do exact inference in loop-free graphs, but its\nperformance could be poor in graphs with loops, and the understanding of its\nsolution is limited. This work gives an interpretable belief propagation rule\nthat is actually minimization of a localized $\\alpha$-divergence. We term this\nalgorithm as $\\alpha$ belief propagation ($\\alpha$-BP). The performance of\n$\\alpha$-BP is tested in MAP (maximum a posterior) inference problems, where\n$\\alpha$-BP can outperform (loopy) BP by a significant margin even in\nfully-connected graphs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 17:18:29 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Liu", "Dong", ""], ["Moghadam", "Nima N.", ""], ["Rasmussen", "Lars K.", ""], ["Huang", "Jinliang", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "1908.08909", "submitter": "Hsin-Yuan Huang", "authors": "Hsin-Yuan Huang and Richard Kueng", "title": "Predicting Features of Quantum Systems from Very Few Measurements", "comments": "8 pages, 6 figures + 10 page appendix and one reference to Norse\n  mythology", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CL cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting features of complex, large-scale quantum systems is essential to\nthe characterization and engineering of quantum architectures. We present an\nefficient approach for constructing an approximate classical description,\ncalled the classical shadow, of a quantum system from very few quantum\nmeasurements that can later be used to predict a large collection of features.\nThis approach is guaranteed to accurately predict M linear functions with\nbounded Hilbert-Schmidt norm from only order of log(M) measurements. This is\ncompletely independent of the system size and saturates fundamental lower\nbounds from information theory. We support our theoretical findings with\nnumerical experiments over a wide range of problem sizes (2 to 162 qubits).\nThese highlight advantages compared to existing machine learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 17:32:39 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 19:20:43 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Huang", "Hsin-Yuan", ""], ["Kueng", "Richard", ""]]}, {"id": "1908.08919", "submitter": "Vandad Davoodnia", "authors": "Vandad Davoodnia, Saeed Ghorbani, Ali Etemad", "title": "In-bed Pressure-based Pose Estimation using Image Space Representation\n  Learning", "comments": "\\c{opyright}2021 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "2021 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP) (pp. 3965-3969). IEEE", "doi": "10.1109/ICASSP39728.2021.9413516", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep pose estimation models have proven to be effective in\na wide range of applications such as health monitoring, sports, animations, and\nrobotics. However, pose estimation models fail to generalize when facing images\nacquired from in-bed pressure sensing systems. In this paper, we address this\nchallenge by presenting a novel end-to-end framework capable of accurately\nlocating body parts from vague pressure data. Our method exploits the idea of\nequipping an off-the-shelf pose estimator with a deep trainable neural network,\nwhich pre-processes and prepares the pressure data for subsequent pose\nestimation. Our model transforms the ambiguous pressure maps to images\ncontaining shapes and structures similar to the common input domain of the\npre-existing pose estimation methods. As a result, we show that our model is\nable to reconstruct unclear body parts, which in turn enables pose estimators\nto accurately and robustly estimate the pose. We train and test our method on a\nmanually annotated public pressure map dataset using a combination of loss\nfunctions. Results confirm the effectiveness of our method by the high visual\nquality in the generated images and the high pose estimation rates achieved.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 01:52:54 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 03:41:41 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 19:15:25 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Davoodnia", "Vandad", ""], ["Ghorbani", "Saeed", ""], ["Etemad", "Ali", ""]]}, {"id": "1908.08930", "submitter": "Shahin Mahdizadehaghdam", "authors": "Shahin Mahdizadehaghdam, Ashkan Panahi, Hamid Krim", "title": "Sparse Generative Adversarial Network", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to Generative Adversarial Networks (GANs) to\nachieve an improved performance with additional robustness to its so-called and\nwell recognized mode collapse. We first proceed by mapping the desired data\nonto a frame-based space for a sparse representation to lift any limitation of\nsmall support features prior to learning the structure. To that end we start by\ndividing an image into multiple patches and modifying the role of the\ngenerative network from producing an entire image, at once, to creating a\nsparse representation vector for each image patch. We synthesize an entire\nimage by multiplying generated sparse representations to a pre-trained\ndictionary and assembling the resulting patches. This approach restricts the\noutput of the generator to a particular structure, obtained by imposing a Union\nof Subspaces (UoS) model to the original training data, leading to more\nrealistic images, while maintaining a desired diversity. To further regularize\nGANs in generating high-quality images and to avoid the notorious mode-collapse\nproblem, we introduce a third player in GANs, called reconstructor. This player\nutilizes an auto-encoding scheme to ensure that first, the input-output\nrelation in the generator is injective and second each real image corresponds\nto some input noise. We present a number of experiments, where the proposed\nalgorithm shows a remarkably higher inception score compared to the equivalent\nconventional GANs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 23:35:41 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Mahdizadehaghdam", "Shahin", ""], ["Panahi", "Ashkan", ""], ["Krim", "Hamid", ""]]}, {"id": "1908.08936", "submitter": "Daisuke Moriwaki", "authors": "Daisuke Moriwaki, Komei Fujita, Shota Yasui, Takahiro Hoshino", "title": "Fatigue-Aware Ad Creative Selection", "comments": "The previous version was uploaded under the title of \"A Contextual\n  Bandit for Ad Creative Selection under Ad Fatigue\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online display advertising, selecting the most effective ad creative (ad\nimage) for each impression is a crucial task for DSPs (Demand-Side Platforms)\nto fulfill their goals (click-through rate, number of conversions, revenue, and\nbrand improvement). As widely recognized in the marketing literature, the\neffect of ad creative changes with the number of repetitive ad exposures. In\nthis study, we propose an efficient and easy-to-implement ad creative selection\nalgorithm that explicitly considers user's psychological status when selecting\nad creatives. The proposed system was deployed in a real-world production\nenvironment and tested against the baseline algorithms. The results show\nsuperiority of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 03:56:49 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 08:56:23 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Moriwaki", "Daisuke", ""], ["Fujita", "Komei", ""], ["Yasui", "Shota", ""], ["Hoshino", "Takahiro", ""]]}, {"id": "1908.08937", "submitter": "Stephan Sloth Lorenzen", "authors": "Stephan Lorenzen and Niklas Hjuler and Stephen Alstrup", "title": "Tracking Behavioral Patterns among Students in an Online Educational\n  System", "comments": null, "journal-ref": "In Proceedings of the 11'th International Conference on\n  Educational Data Mining (EDM), p. 280-285. 2018", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of log data generated by online educational systems is an essential\ntask to better the educational systems and increase our understanding of how\nstudents learn. In this study we investigate previously unseen data from Clio\nOnline, the largest provider of digital learning content for primary schools in\nDenmark. We consider data for 14,810 students with 3 million sessions in the\nperiod 2015-2017. We analyze student activity in periods of one week. By using\nnon-negative matrix factorization techniques, we obtain soft clusterings,\nrevealing dependencies among time of day, subject, activity type, activity\ncomplexity (measured by Bloom's taxonomy), and performance. Furthermore, our\nmethod allows for tracking behavioral changes of individual students over time,\nas well as general behavioral changes in the educational system. Based on the\nresults, we give suggestions for behavioral changes, in order to optimize the\nlearning experience and improve performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 13:36:26 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Lorenzen", "Stephan", ""], ["Hjuler", "Niklas", ""], ["Alstrup", "Stephen", ""]]}, {"id": "1908.08961", "submitter": "Max Tegmark", "authors": "Max Tegmark (MIT), Tailin Wu (MIT)", "title": "Pareto-optimal data compression for binary classification tasks", "comments": "Replaced to match version published in Entropy. 17 pages, 9 figs;\n  improved discussion, comparison with Blahut-Arimoto method", "journal-ref": "Entropy (2020), 22, 7", "doi": "10.3390/e22010007", "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of lossy data compression is to reduce the storage cost of a data\nset $X$ while retaining as much information as possible about something ($Y$)\nthat you care about. For example, what aspects of an image $X$ contain the most\ninformation about whether it depicts a cat? Mathematically, this corresponds to\nfinding a mapping $X\\to Z\\equiv f(X)$ that maximizes the mutual information\n$I(Z,Y)$ while the entropy $H(Z)$ is kept below some fixed threshold. We\npresent a method for mapping out the Pareto frontier for classification tasks,\nreflecting the tradeoff between retained entropy and class information. We\nfirst show how a random variable $X$ (an image, say) drawn from a class\n$Y\\in\\{1,...,n\\}$ can be distilled into a vector $W=f(X)\\in \\mathbb{R}^{n-1}$\nlosslessly, so that $I(W,Y)=I(X,Y)$; for example, for a binary classification\ntask of cats and dogs, each image $X$ is mapped into a single real number $W$\nretaining all information that helps distinguish cats from dogs. For the $n=2$\ncase of binary classification, we then show how $W$ can be further compressed\ninto a discrete variable $Z=g_\\beta(W)\\in\\{1,...,m_\\beta\\}$ by binning $W$ into\n$m_\\beta$ bins, in such a way that varying the parameter $\\beta$ sweeps out the\nfull Pareto frontier, solving a generalization of the Discrete Information\nBottleneck (DIB) problem. We argue that the most interesting points on this\nfrontier are \"corners\" maximizing $I(Z,Y)$ for a fixed number of bins\n$m=2,3...$ which can be conveniently be found without multiobjective\noptimization. We apply this method to the CIFAR-10, MNIST and Fashion-MNIST\ndatasets, illustrating how it can be interpreted as an\ninformation-theoretically optimal image clustering algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 18:00:40 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 18:43:57 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Tegmark", "Max", "", "MIT"], ["Wu", "Tailin", "", "MIT"]]}, {"id": "1908.08972", "submitter": "Juan Maro\\~nas", "authors": "Juan Maro\\~nas and Roberto Paredes and Daniel Ramos", "title": "Calibration of Deep Probabilistic Models with Decoupled Bayesian Neural\n  Networks", "comments": "Submit to Neurocomputing", "journal-ref": null, "doi": "10.1016/j.neucom.2020.04.103", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep Neural Networks (DNNs) have achieved state-of-the-art accuracy\nperformance in many tasks. However, recent works have pointed out that the\noutputs provided by these models are not well-calibrated, seriously limiting\ntheir use in critical decision scenarios. In this work, we propose to use a\ndecoupled Bayesian stage, implemented with a Bayesian Neural Network (BNN), to\nmap the uncalibrated probabilities provided by a DNN to calibrated ones,\nconsistently improving calibration. Our results evidence that incorporating\nuncertainty provides more reliable probabilistic models, a critical condition\nfor achieving good calibration. We report a generous collection of experimental\nresults using high-accuracy DNNs in standardized image classification\nbenchmarks, showing the good performance, flexibility and robust behavior of\nour approach with respect to several state-of-the-art calibration methods. Code\nfor reproducibility is provided.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 18:35:48 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 13:18:52 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 15:18:08 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Maro\u00f1as", "Juan", ""], ["Paredes", "Roberto", ""], ["Ramos", "Daniel", ""]]}, {"id": "1908.08979", "submitter": "Mimansa Jaiswal", "authors": "Mimansa Jaiswal, Zakaria Aldeneh, Emily Mower Provost", "title": "Controlling for Confounders in Multimodal Emotion Classification via\n  Adversarial Learning", "comments": "10 pages, ICMI 2019", "journal-ref": null, "doi": "10.1145/3340555.3353731", "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various psychological factors affect how individuals express emotions. Yet,\nwhen we collect data intended for use in building emotion recognition systems,\nwe often try to do so by creating paradigms that are designed just with a focus\non eliciting emotional behavior. Algorithms trained with these types of data\nare unlikely to function outside of controlled environments because our\nemotions naturally change as a function of these other factors. In this work,\nwe study how the multimodal expressions of emotion change when an individual is\nunder varying levels of stress. We hypothesize that stress produces modulations\nthat can hide the true underlying emotions of individuals and that we can make\nemotion recognition algorithms more generalizable by controlling for variations\nin stress. To this end, we use adversarial networks to decorrelate stress\nmodulations from emotion representations. We study how stress alters acoustic\nand lexical emotional predictions, paying special attention to how modulations\ndue to stress affect the transferability of learned emotion recognition models\nacross domains. Our results show that stress is indeed encoded in trained\nemotion classifiers and that this encoding varies across levels of emotions and\nacross the lexical and acoustic modalities. Our results also show that emotion\nrecognition models that control for stress during training have better\ngeneralizability when applied to new domains, compared to models that do not\ncontrol for stress during training. We conclude that is is necessary to\nconsider the effect of extraneous psychological factors when building and\ntesting emotion recognition models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 19:00:18 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Jaiswal", "Mimansa", ""], ["Aldeneh", "Zakaria", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1908.08984", "submitter": "Venkatesh Umaashankar Mr", "authors": "Venkatesh Umaashankar, Girish Shanmugam S and Aditi Prakash", "title": "Atlas: A Dataset and Benchmark for E-commerce Clothing Product\n  Categorization", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In E-commerce, it is a common practice to organize the product catalog using\nproduct taxonomy. This enables the buyer to easily locate the item they are\nlooking for and also to explore various items available under a category.\nProduct taxonomy is a tree structure with 3 or more levels of depth and several\nleaf nodes. Product categorization is a large scale classification task that\nassigns a category path to a particular product. Research in this area is\nrestricted by the unavailability of good real-world datasets and the variations\nin taxonomy due to the absence of a standard across the different e-commerce\nstores. In this paper, we introduce a high-quality product taxonomy dataset\nfocusing on clothing products which contain 186,150 images under clothing\ncategory with 3 levels and 52 leaf nodes in the taxonomy. We explain the\nmethodology used to collect and label this dataset. Further, we establish the\nbenchmark by comparing image classification and Attention based Sequence models\nfor predicting the category path. Our benchmark model reaches a micro f-score\nof 0.92 on the test set. The dataset, code and pre-trained models are publicly\navailable at \\url{https://github.com/vumaasha/atlas}. We invite the community\nto improve upon these baselines.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 16:46:00 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Umaashankar", "Venkatesh", ""], ["S", "Girish Shanmugam", ""], ["Prakash", "Aditi", ""]]}, {"id": "1908.08986", "submitter": "Elad Hoffer", "authors": "Elad Hoffer, Berry Weinstein, Itay Hubara, Tal Ben-Nun, Torsten\n  Hoefler, Daniel Soudry", "title": "Mix & Match: training convnets with mixed image sizes for improved\n  accuracy, speed and scale resiliency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are commonly trained using a fixed\nspatial image size predetermined for a given model. Although trained on images\nof aspecific size, it is well established that CNNs can be used to evaluate a\nwide range of image sizes at test time, by adjusting the size of intermediate\nfeature maps. In this work, we describe and evaluate a novel mixed-size\ntraining regime that mixes several image sizes at training time. We demonstrate\nthat models trained using our method are more resilient to image size changes\nand generalize well even on small images. This allows faster inference by using\nsmaller images attest time. For instance, we receive a 76.43% top-1 accuracy\nusing ResNet50 with an image size of 160, which matches the accuracy of the\nbaseline model with 2x fewer computations. Furthermore, for a given image size\nused at test time, we show this method can be exploited either to accelerate\ntraining or the final test accuracy. For example, we are able to reach a 79.27%\naccuracy with a model evaluated at a 288 spatial size for a relative\nimprovement of 14% over the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 08:27:49 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hoffer", "Elad", ""], ["Weinstein", "Berry", ""], ["Hubara", "Itay", ""], ["Ben-Nun", "Tal", ""], ["Hoefler", "Torsten", ""], ["Soudry", "Daniel", ""]]}, {"id": "1908.08988", "submitter": "Xiang Li", "authors": "Xiang Li, Shihao Ji", "title": "Neural Image Compression and Explanation", "comments": "Published as a journal paper at IEEE Access 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining the prediction of deep neural networks (DNNs) and semantic image\ncompression are two active research areas of deep learning with a numerous of\napplications in decision-critical systems, such as surveillance cameras, drones\nand self-driving cars, where interpretable decision is critical and\nstorage/network bandwidth is limited. In this paper, we propose a novel\nend-to-end Neural Image Compression and Explanation (NICE) framework that\nlearns to (1) explain the predictions of convolutional neural networks (CNNs),\nand (2) subsequently compress the input images for efficient storage or\ntransmission. Specifically, NICE generates a sparse mask over an input image by\nattaching a stochastic binary gate to each pixel of the image, whose parameters\nare learned through the interaction with the CNN classifier to be explained.\nThe generated mask is able to capture the saliency of each pixel measured by\nits influence to the final prediction of CNN; it can also be used to produce a\nmixed-resolution image, where important pixels maintain their original high\nresolution and insignificant background pixels are subsampled to a low\nresolution. The produced images achieve a high compression rate (e.g., about\n0.6x of original image file size), while retaining a similar classification\naccuracy. Extensive experiments across multiple image classification benchmarks\ndemonstrate the superior performance of NICE compared to the state-of-the-art\nmethods in terms of explanation quality and semantic image compression rate.\nOur code is available at: https://github.com/lxuniverse/NICE.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 15:39:20 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 03:01:50 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Li", "Xiang", ""], ["Ji", "Shihao", ""]]}, {"id": "1908.08989", "submitter": "Maren Awiszus", "authors": "Maren Awiszus, Hanno Ackermann and Bodo Rosenhahn", "title": "Learning Disentangled Representations via Independent Subspaces", "comments": "Accepted at ICCV 2019 Workshop on Robust Subspace Learning and\n  Applications in Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image generating neural networks are mostly viewed as black boxes, where any\nchange in the input can have a number of globally effective changes on the\noutput. In this work, we propose a method for learning disentangled\nrepresentations to allow for localized image manipulations. We use face images\nas our example of choice. Depending on the image region, identity and other\nfacial attributes can be modified. The proposed network can transfer parts of a\nface such as shape and color of eyes, hair, mouth, etc.~directly between\npersons while all other parts of the face remain unchanged. The network allows\nto generate modified images which appear like realistic images. Our model\nlearns disentangled representations by weak supervision. We propose a localized\nresnet autoencoder optimized using several loss functions including a loss\nbased on the semantic segmentation, which we interpret as masks, and a loss\nwhich enforces disentanglement by decomposition of the latent space into\nstatistically independent subspaces. We evaluate the proposed solution w.r.t.\ndisentanglement and generated image quality. Convincing results are\ndemonstrated using the CelebA dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 09:08:12 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Awiszus", "Maren", ""], ["Ackermann", "Hanno", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "1908.08990", "submitter": "Sebastian Agethen", "authors": "Sebastian Agethen, Winston H. Hsu", "title": "Deep Multi-Kernel Convolutional LSTM Networks and an Attention-Based\n  Mechanism for Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action recognition greatly benefits motion understanding in video analysis.\nRecurrent networks such as long short-term memory (LSTM) networks are a popular\nchoice for motion-aware sequence learning tasks. Recently, a convolutional\nextension of LSTM was proposed, in which input-to-hidden and hidden-to-hidden\ntransitions are modeled through convolution with a single kernel. This implies\nan unavoidable trade-off between effectiveness and efficiency. Herein, we\npropose a new enhancement to convolutional LSTM networks that supports\naccommodation of multiple convolutional kernels and layers. This resembles a\nNetwork-in-LSTM approach, which improves upon the aforementioned concern. In\naddition, we propose an attention-based mechanism that is specifically designed\nfor our multi-kernel extension. We evaluated our proposed extensions in a\nsupervised classification setting on the UCF-101 and Sports-1M datasets, with\nthe findings showing that our enhancements improve accuracy. We also undertook\nqualitative analysis to reveal the characteristics of our system and the\nconvolutional LSTM baseline.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 05:51:20 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Agethen", "Sebastian", ""], ["Hsu", "Winston H.", ""]]}, {"id": "1908.08992", "submitter": "Anjana Wijekoon", "authors": "Anjana Wijekoon, Nirmalie Wiratunga, Kay Cooper", "title": "MEx: Multi-modal Exercises Dataset for Human Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MEx: Multi-modal Exercises Dataset is a multi-sensor, multi-modal dataset,\nimplemented to benchmark Human Activity Recognition(HAR) and Multi-modal Fusion\nalgorithms. Collection of this dataset was inspired by the need for recognising\nand evaluating quality of exercise performance to support patients with\nMusculoskeletal Disorders(MSD). We select 7 exercises regularly recommended for\nMSD patients by physiotherapists and collected data with four sensors a\npressure mat, a depth camera and two accelerometers. The dataset contains three\ndata modalities; numerical time-series data, video data and pressure sensor\ndata posing interesting research challenges when reasoning for HAR and Exercise\nQuality Assessment. This paper presents our evaluation of the dataset on number\nof standard classification algorithms for the HAR task by comparing different\nfeature representation algorithms for each sensor. These results set a\nreference performance for each individual sensor that expose their strengths\nand weaknesses for the future tasks. In addition we visualise pressure mat data\nto explore the potential of the sensor to capture exercise performance quality.\nWith the recent advancement in multi-modal fusion, we also believe MEx is a\nsuitable dataset to benchmark not only HAR algorithms, but also fusion\nalgorithms of heterogeneous data types in multiple application domains.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:09:53 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wijekoon", "Anjana", ""], ["Wiratunga", "Nirmalie", ""], ["Cooper", "Kay", ""]]}, {"id": "1908.08993", "submitter": "Dmitry Krotov", "authors": "Leopold Grinberg, John Hopfield, Dmitry Krotov", "title": "Local Unsupervised Learning for Image Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Hebbian learning is believed to be inferior in performance to\nend-to-end training using a backpropagation algorithm. We question this popular\nbelief by designing a local algorithm that can learn convolutional filters at\nscale on large image datasets. These filters combined with patch normalization\nand very steep non-linearities result in a good classification accuracy for\nshallow networks trained locally, as opposed to end-to-end. The filters learned\nby our algorithm contain both orientation selective units and unoriented color\nunits, resembling the responses of pyramidal neurons located in the cytochrome\noxidase 'interblob' and 'blob' regions in the primary visual cortex of\nprimates. It is shown that convolutional networks with patch normalization\nsignificantly outperform standard convolutional networks on the task of\nrecovering the original classes when shadows are superimposed on top of\nstandard CIFAR-10 images. Patch normalization approximates the retinal\nadaptation to the mean light intensity, important for human vision. We also\ndemonstrate a successful transfer of learned representations between CIFAR-10\nand ImageNet 32x32 datasets. All these results taken together hint at the\npossibility that local unsupervised training might be a powerful tool for\nlearning general representations (without specifying the task) directly from\nunlabeled data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:42:11 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Grinberg", "Leopold", ""], ["Hopfield", "John", ""], ["Krotov", "Dmitry", ""]]}, {"id": "1908.08996", "submitter": "Hongxin Lin", "authors": "Hongxin Lin, Zelin Xiao, Yang Tan, Hongyang Chao, Shengyong Ding", "title": "Justlookup: One Millisecond Deep Feature Extraction for Point Clouds By\n  Lookup Tables", "comments": "Accepted by ICME2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models are capable of fitting complex high dimensional functions while\nusually yielding large computation load. There is no way to speed up the\ninference process by classical lookup tables due to the high-dimensional input\nand limited memory size. Recently, a novel architecture (PointNet) for point\nclouds has demonstrated that it is possible to obtain a complicated deep\nfunction from a set of 3-variable functions. In this paper, we exploit this\nproperty and apply a lookup table to encode these 3-variable functions. This\nmethod ensures that the inference time is only determined by the memory access\nno matter how complicated the deep function is. We conduct extensive\nexperiments on ModelNet and ShapeNet datasets and demonstrate that we can\ncomplete the inference process in 1.5 ms on an Intel i7-8700 CPU (single core\nmode), 32x speedup over the PointNet architecture without any performance\ndegradation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 07:07:26 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Lin", "Hongxin", ""], ["Xiao", "Zelin", ""], ["Tan", "Yang", ""], ["Chao", "Hongyang", ""], ["Ding", "Shengyong", ""]]}, {"id": "1908.08997", "submitter": "Thomas Hartley", "authors": "Thomas Hartley, Kirill Sidorov, Christopher Willis and David Marshall", "title": "Gradient Weighted Superpixels for Interpretability in CNNs", "comments": "Presented at BMVC 2019: Workshop on Interpretable and Explainable\n  Machine Vision, Cardiff, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Convolutional Neural Networks embed themselves into our everyday lives,\nthe need for them to be interpretable increases. However, there is often a\ntrade-off between methods that are efficient to compute but produce an\nexplanation that is difficult to interpret, and those that are slow to compute\nbut provide a more interpretable result. This is particularly challenging in\nproblem spaces that require a large input volume, especially video which\ncombines both spatial and temporal dimensions. In this work we introduce the\nidea of scoring superpixels through the use of gradient based pixel scoring\ntechniques. We show qualitatively and quantitatively that this is able to\napproximate LIME, in a fraction of the time. We investigate our techniques\nusing both image classification, and action recognition networks on large scale\ndatasets (ImageNet and Kinetics-400 respectively).\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 12:02:25 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hartley", "Thomas", ""], ["Sidorov", "Kirill", ""], ["Willis", "Christopher", ""], ["Marshall", "David", ""]]}, {"id": "1908.09002", "submitter": "Chris Xiaoxuan Lu", "authors": "Chris Xiaoxuan Lu, Xuan Kan, Bowen Du, Changhao Chen, Hongkai Wen,\n  Andrew Markham, Niki Trigoni and John Stankovic", "title": "Autonomous Learning for Face Recognition in the Wild via Ambient\n  Wireless Cues", "comments": "11 pages, accepted in the Web Conference (WWW'2019)", "journal-ref": null, "doi": "10.1145/3308558.3313398", "report-no": null, "categories": "cs.CV cs.LG cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Facial recognition is a key enabling component for emerging Internet of\nThings (IoT) services such as smart homes or responsive offices. Through the\nuse of deep neural networks, facial recognition has achieved excellent\nperformance. However, this is only possibly when trained with hundreds of\nimages of each user in different viewing and lighting conditions. Clearly, this\nlevel of effort in enrolment and labelling is impossible for wide-spread\ndeployment and adoption. Inspired by the fact that most people carry smart\nwireless devices with them, e.g. smartphones, we propose to use this wireless\nidentifier as a supervisory label. This allows us to curate a dataset of facial\nimages that are unique to a certain domain e.g. a set of people in a particular\noffice. This custom corpus can then be used to finetune existing pre-trained\nmodels e.g. FaceNet. However, due to the vagaries of wireless propagation in\nbuildings, the supervisory labels are noisy and weak.We propose a novel\ntechnique, AutoTune, which learns and refines the association between a face\nand wireless identifier over time, by increasing the inter-cluster separation\nand minimizing the intra-cluster distance. Through extensive experiments with\nmultiple users on two sites, we demonstrate the ability of AutoTune to design\nan environment-specific, continually evolving facial recognition system with\nentirely no user effort.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 18:39:09 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Lu", "Chris Xiaoxuan", ""], ["Kan", "Xuan", ""], ["Du", "Bowen", ""], ["Chen", "Changhao", ""], ["Wen", "Hongkai", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""], ["Stankovic", "John", ""]]}, {"id": "1908.09006", "submitter": "Siddharth Samsi", "authors": "Jeffrey Liu, David Strohschein, Siddharth Samsi, Andrew Weinert", "title": "Large Scale Organization and Inference of an Imagery Dataset for Public\n  Safety", "comments": "Accepted for publication IEEE HPEC 2019", "journal-ref": null, "doi": "10.1109/HPEC.2019.8916437", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video applications and analytics are routinely projected as a stressing and\nsignificant service of the Nationwide Public Safety Broadband Network. As part\nof a NIST PSCR funded effort, the New Jersey Office of Homeland Security and\nPreparedness and MIT Lincoln Laboratory have been developing a computer vision\ndataset of operational and representative public safety scenarios. The scale\nand scope of this dataset necessitates a hierarchical organization approach for\nefficient compute and storage. We overview architectural considerations using\nthe Lincoln Laboratory Supercomputing Cluster as a test architecture. We then\ndescribe how we intelligently organized the dataset across LLSC and evaluated\nit with large scale imagery inference across terabytes of data.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 18:20:01 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Liu", "Jeffrey", ""], ["Strohschein", "David", ""], ["Samsi", "Siddharth", ""], ["Weinert", "Andrew", ""]]}, {"id": "1908.09007", "submitter": "Maroua Mehri Ph.D.", "authors": "Walid Elhedda, Maroua Mehri and Mohamed Ali Mahjoub", "title": "A Comparative Study of Filtering Approaches Applied to Color Archival\n  Document Images", "comments": null, "journal-ref": null, "doi": null, "report-no": "W. Elhedda, M. Mehri and M. A. Mahjoub, A Comparative Study of\n  Filtering Approaches Applied to Color Archival Document Images. In\n  Proceedings of the 18th International Arab Conference on Information\n  Technology (ACIT), Hammamet, Tunisia, 2017", "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current systems used by the Tunisian national archives for the automatic\ntranscription of archival documents are hindered by many issues related to the\nperformance of the optical character recognition (OCR) tools. Indeed, using a\nclassical OCR system to transcribe and index ancient Arabic documents is not a\nstraightforward task due to the idiosyncrasies of this category of documents,\nsuch as noise and degradation. Thus, applying an enhancement method or a\ndenoising technique remains an essential prerequisite step to ease the archival\ndocument image analysis task. The state-of-the-art methods addressing the use\nof degraded document image enhancement and denoising are mainly based on\napplying filters. The most common filtering techniques applied to color images\nin the literature may be categorized into four approaches: scalar, marginal,\nvector and hybrid. To provide a set of comprehensive guidelines on the\nstrengths and weaknesses of these filtering approaches, a thorough comparative\nstudy is proposed in this article. Numerical experiments are carried out in\nthis study on color archival document images to show and quantify the\nperformance of each assessed filtering approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 12:05:14 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Elhedda", "Walid", ""], ["Mehri", "Maroua", ""], ["Mahjoub", "Mohamed Ali", ""]]}, {"id": "1908.09008", "submitter": "Apratim Bhattacharyya", "authors": "Apratim Bhattacharyya, Michael Hanselmann, Mario Fritz, Bernt Schiele,\n  Christoph-Nikolas Straehle", "title": "Conditional Flow Variational Autoencoders for Structured Sequence\n  Prediction", "comments": "To appear at Bayesian Deep Learning and Machine Learning for\n  Autonomous Driving @NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of future states of the environment and interacting agents is a\nkey competence required for autonomous agents to operate successfully in the\nreal world. Prior work for structured sequence prediction based on latent\nvariable models imposes a uni-modal standard Gaussian prior on the latent\nvariables. This induces a strong model bias which makes it challenging to fully\ncapture the multi-modality of the distribution of the future states. In this\nwork, we introduce Conditional Flow Variational Autoencoders (CF-VAE) using our\nnovel conditional normalizing flow based prior to capture complex multi-modal\nconditional distributions for effective structured sequence prediction.\nMoreover, we propose two novel regularization schemes which stabilizes training\nand deals with posterior collapse for stable training and better fit to the\ntarget data distribution. Our experiments on three multi-modal structured\nsequence prediction datasets -- MNIST Sequences, Stanford Drone and HighD --\nshow that the proposed method obtains state of art results across different\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 08:02:34 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 10:44:50 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 09:55:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Bhattacharyya", "Apratim", ""], ["Hanselmann", "Michael", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""], ["Straehle", "Christoph-Nikolas", ""]]}, {"id": "1908.09021", "submitter": "Sizhong Lan", "authors": "Sizhong Lan", "title": "Geometrical Regret Matching", "comments": "11 pages, 22 figures; https://github.com/lansiz/eqpt with code and\n  hands-on demos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the existing regret matchings for Nash equilibrium\napproximation conduct \"jumpy\" strategy updating when the probabilities of\nfuture plays are set to be proportional to positive regret measures. We propose\na geometrical regret matching which features \"smooth\" strategy updating. Our\napproach is simple, intuitive and natural. The analytical and numerical results\nshow that, continuously and \"smoothly\" suppressing \"unprofitable\" pure\nstrategies is sufficient for the game to evolve towards Nash equilibrium,\nsuggesting that in reality the tendency for equilibrium could be pervasive and\nirresistible. Technically, iterative regret matching gives rise to a sequence\nof adjusted mixed strategies for our study its approximation to the true\nequilibrium point. The sequence can be studied in metric space and visualized\nnicely as a clear path towards an equilibrium point. Our theory has limitations\nin optimizing the approximation accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 10:34:36 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 13:09:40 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 07:26:43 GMT"}, {"version": "v4", "created": "Mon, 9 Sep 2019 15:17:48 GMT"}, {"version": "v5", "created": "Mon, 23 Sep 2019 12:56:01 GMT"}, {"version": "v6", "created": "Mon, 14 Oct 2019 17:39:49 GMT"}, {"version": "v7", "created": "Tue, 31 Dec 2019 04:26:20 GMT"}, {"version": "v8", "created": "Thu, 23 Jan 2020 05:31:43 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Lan", "Sizhong", ""]]}, {"id": "1908.09031", "submitter": "Jiachen Li", "authors": "Jiachen Li and Wei Zhan and Yeping Hu and Masayoshi Tomizuka", "title": "Generic Tracking and Probabilistic Prediction Framework and Its\n  Application in Autonomous Driving", "comments": "IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2019.2930310", "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately tracking and predicting behaviors of surrounding objects are key\nprerequisites for intelligent systems such as autonomous vehicles to achieve\nsafe and high-quality decision making and motion planning. However, there still\nremain challenges for multi-target tracking due to object number fluctuation\nand occlusion. To overcome these challenges, we propose a constrained mixture\nsequential Monte Carlo (CMSMC) method in which a mixture representation is\nincorporated in the estimated posterior distribution to maintain\nmulti-modality. Multiple targets can be tracked simultaneously within a unified\nframework without explicit data association between observations and tracking\ntargets. The framework can incorporate an arbitrary prediction model as the\nimplicit proposal distribution of the CMSMC method. An example in this paper is\na learning-based model for hierarchical time-series prediction, which consists\nof a behavior recognition module and a state evolution module. Both modules in\nthe proposed model are generic and flexible so as to be applied to a class of\ntime-series prediction problems where behaviors can be separated into different\nlevels. Finally, the proposed framework is applied to a numerical case study as\nwell as a task of on-road vehicle tracking, behavior recognition, and\nprediction in highway scenarios. Instead of only focusing on forecasting\ntrajectory of a single entity, we jointly predict continuous motions for\ninteractive entities simultaneously. The proposed approaches are evaluated from\nmultiple aspects, which demonstrate great potential for intelligent vehicular\nsystems and traffic surveillance systems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 20:34:53 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Li", "Jiachen", ""], ["Zhan", "Wei", ""], ["Hu", "Yeping", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1908.09038", "submitter": "Tom Velez PhD", "authors": "Tom Velez, Tony Wang, Ioannis Koutroulis, James Chamberlain, Amit\n  Uppal, Seife Yohannes, Tim Tschampel, Emilia Apostolova", "title": "Identification of Pediatric Sepsis Subphenotypes for Enhanced Machine\n  Learning Predictive Performance: A Latent Profile Analysis", "comments": "Keywords: Pediatric Sepsis, Mortality, Latent Profile Analysis,\n  Machine Learning, Subphenotypes 15 pages including Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: While machine learning (ML) models are rapidly emerging as\npromising screening tools in critical care medicine, the identification of\nhomogeneous subphenotypes within populations with heterogeneous conditions such\nas pediatric sepsis may facilitate attainment of high-predictive performance of\nthese prognostic algorithms. This study is aimed to identify subphenotypes of\npediatric sepsis and demonstrate the potential value of partitioned\ndata/subtyping-based training. Methods: This was a retrospective study of\nclinical data extracted from medical records of 6,446 pediatric patients that\nwere admitted at a major hospital system in the DC area. Vitals and labs\nassociated with patients meeting the diagnostic criteria for sepsis were used\nto perform latent profile analysis. Modern ML algorithms were used to explore\nthe predictive performance benefits of reduced training data heterogeneity via\nlabel profiling. Results: In total 134 (2.1%) patients met the diagnostic\ncriteria for sepsis in this cohort and latent profile analysis identified four\nprofiles/subphenotypes of pediatric sepsis. Profiles 1 and 3 had the lowest\nmortality and included pediatric patients from different age groups. Profile 2\nwere characterized by respiratory dysfunction; profile 4 by neurological\ndysfunction and highest mortality rate (22.2%). Machine learning experiments\ncomparing the predictive performance of models derived without training data\nprofiling against profile targeted models suggest statistically significant\nimproved performance of prediction can be obtained. For example, area under ROC\ncurve (AUC) obtained to predict profile 4 with 24-hour data (AUC = .998, p <\n.0001) compared favorably with the AUC obtained from the model considering all\nprofiles as a single homogeneous group (AUC = .918) with 24-hour data.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 20:59:42 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Velez", "Tom", ""], ["Wang", "Tony", ""], ["Koutroulis", "Ioannis", ""], ["Chamberlain", "James", ""], ["Uppal", "Amit", ""], ["Yohannes", "Seife", ""], ["Tschampel", "Tim", ""], ["Apostolova", "Emilia", ""]]}, {"id": "1908.09041", "submitter": "Neil Lutz", "authors": "Christopher Jung, Sampath Kannan, Neil Lutz", "title": "A Center in Your Neighborhood: Fairness in Facility Location", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When selecting locations for a set of facilities, standard clustering\nalgorithms may place unfair burden on some individuals and neighborhoods. We\nformulate a fairness concept that takes local population densities into\naccount. In particular, given $k$ facilities to locate and a population of size\n$n$, we define the \"neighborhood radius\" of an individual $i$ as the minimum\nradius of a ball centered at $i$ that contains at least $n/k$ individuals. Our\nobjective is to ensure that each individual has a facility within at most a\nsmall constant factor of her neighborhood radius. We present several\ntheoretical results:\n  We show that optimizing this factor is NP-hard; we give an approximation\nalgorithm that guarantees a factor of at most 2 in all metric spaces; and we\nprove matching lower bounds in some metric spaces. We apply a variant of this\nalgorithm to real-world address data, showing that it is quite different from\nstandard clustering algorithms and outperforms them on our objective function\nand balances the load between facilities more evenly.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 22:04:57 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 15:42:36 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Jung", "Christopher", ""], ["Kannan", "Sampath", ""], ["Lutz", "Neil", ""]]}, {"id": "1908.09043", "submitter": "Mihailo Jovanovic", "authors": "Sepideh Hassan-Moghaddam and Mihailo R. Jovanovi\\'c", "title": "Proximal gradient flow and Douglas-Rachford splitting dynamics: global\n  exponential stability via integral quadratic constraints", "comments": "8 pages; 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many large-scale and distributed optimization problems can be brought into a\ncomposite form in which the objective function is given by the sum of a smooth\nterm and a nonsmooth regularizer. Such problems can be solved via a proximal\ngradient method and its variants, thereby generalizing gradient descent to a\nnonsmooth setup. In this paper, we view proximal algorithms as dynamical\nsystems and leverage techniques from control theory to study their global\nproperties. In particular, for problems with strongly convex objective\nfunctions, we utilize the theory of integral quadratic constraints to prove the\nglobal exponential stability of the equilibrium points of the differential\nequations that govern the evolution of proximal gradient and Douglas-Rachford\nsplitting flows. In our analysis, we use the fact that these algorithms can be\ninterpreted as variable-metric gradient methods on the suitable envelopes and\nexploit structural properties of the nonlinear terms that arise from the\ngradient of the smooth part of the objective function and the proximal operator\nassociated with the nonsmooth regularizer. We also demonstrate that these\nenvelopes can be obtained from the augmented Lagrangian associated with the\noriginal nonsmooth problem and establish conditions for global exponential\nconvergence even in the absence of strong convexity.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 22:21:48 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 04:47:06 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Hassan-Moghaddam", "Sepideh", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1908.09048", "submitter": "Subramaniam Venkatraman Krishnan", "authors": "Liqun Shao, Yiwen Zhu, Abhiram Eswaran, Kristin Lieber, Janhavi\n  Mahajan, Minsoo Thigpen, Sudhir Darbha, Siqi Liu, Subru Krishnan, Soundar\n  Srinivasan, Carlo Curino and Konstantinos Karanasos", "title": "Griffon: Reasoning about Job Anomalies with Unlabeled Data in\n  Cloud-based Platforms", "comments": null, "journal-ref": null, "doi": "10.1145/3357223.3362716", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Microsoft's internal big data analytics platform is comprised of hundreds of\nthousands of machines, serving over half a million jobs daily, from thousands\nof users. The majority of these jobs are recurring and are crucial for the\ncompany's operation. Although administrators spend significant effort tuning\nsystem performance, some jobs inevitably experience slowdowns, i.e., their\nexecution time degrades over previous runs. Currently, the investigation of\nsuch slowdowns is a labor-intensive and error-prone process, which costs\nMicrosoft significant human and machine resources, and negatively impacts\nseveral lines of businesses. In this work, we present Griffin, a system we\nbuilt and have deployed in production last year to automatically discover the\nroot cause of job slowdowns. Existing solutions either rely on labeled data\n(i.e., resolved incidents with labeled reasons for job slowdowns), which is in\nmost cases non-existent or non-trivial to acquire, or on time-series analysis\nof individual metrics that do not target specific jobs holistically. In\ncontrast, in Griffin we cast the problem to a corresponding regression one that\npredicts the runtime of a job, and show how the relative contributions of the\nfeatures used to train our interpretable model can be exploited to rank the\npotential causes of job slowdowns. Evaluated over historical incidents, we show\nthat Griffin discovers slowdown causes that are consistent with the ones\nvalidated by domain-expert engineers, in a fraction of the time required by\nthem.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 22:57:50 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Shao", "Liqun", ""], ["Zhu", "Yiwen", ""], ["Eswaran", "Abhiram", ""], ["Lieber", "Kristin", ""], ["Mahajan", "Janhavi", ""], ["Thigpen", "Minsoo", ""], ["Darbha", "Sudhir", ""], ["Liu", "Siqi", ""], ["Krishnan", "Subru", ""], ["Srinivasan", "Soundar", ""], ["Curino", "Carlo", ""], ["Karanasos", "Konstantinos", ""]]}, {"id": "1908.09057", "submitter": "Oluwasanmi Koyejo", "authors": "Xiaoyan Wang, Ran Li, Bowei Yan, Oluwasanmi Koyejo", "title": "Consistent Classification with Generalized Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for constructing and analyzing multiclass and\nmultioutput classification metrics, i.e., involving multiple, possibly\ncorrelated multiclass labels. Our analysis reveals novel insights on the\ngeometry of feasible confusion tensors -- including necessary and sufficient\nconditions for the equivalence between optimizing an arbitrary non-decomposable\nmetric and learning a weighted classifier. Further, we analyze averaging\nmethodologies commonly used to compute multioutput metrics and characterize the\ncorresponding Bayes optimal classifiers. We show that the plug-in estimator\nbased on this characterization is consistent and is easily implemented as a\npost-processing rule. Empirical results on synthetic and benchmark datasets\nsupport the theoretical findings.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 00:31:15 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wang", "Xiaoyan", ""], ["Li", "Ran", ""], ["Yan", "Bowei", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "1908.09060", "submitter": "Zhengyang Wu", "authors": "Zhengyang Wu, Srivignesh Rajendran, Tarrence van As, Joelle\n  Zimmermann, Vijay Badrinarayanan, Andrew Rabinovich", "title": "EyeNet: A Multi-Task Network for Off-Axis Eye Gaze Estimation and User\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye gaze estimation and simultaneous semantic understanding of a user through\neye images is a crucial component in Virtual and Mixed Reality; enabling energy\nefficient rendering, multi-focal displays and effective interaction with 3D\ncontent. In head-mounted VR/MR devices the eyes are imaged off-axis to avoid\nblocking the user's gaze, this view-point makes drawing eye related inferences\nvery challenging. In this work, we present EyeNet, the first single deep neural\nnetwork which solves multiple heterogeneous tasks related to eye gaze\nestimation and semantic user understanding for an off-axis camera setting. The\ntasks include eye segmentation, blink detection, emotive expression\nclassification, IR LED glints detection, pupil and cornea center estimation. To\ntrain EyeNet end-to-end we employ both hand labelled supervision and model\nbased supervision. We benchmark all tasks on MagicEyes, a large and new dataset\nof 587 subjects with varying morphology, gender, skin-color, make-up and\nimaging conditions.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 00:47:39 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wu", "Zhengyang", ""], ["Rajendran", "Srivignesh", ""], ["van As", "Tarrence", ""], ["Zimmermann", "Joelle", ""], ["Badrinarayanan", "Vijay", ""], ["Rabinovich", "Andrew", ""]]}, {"id": "1908.09078", "submitter": "Shujun Bi", "authors": "Shujun Bi, Ting Tao and Shaohua Pan", "title": "KL property of exponent $1/2$ of $\\ell_{2,0}$-norm and DC regularized\n  factorizations for low-rank matrix recovery", "comments": "29 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the factorization form of the rank regularized\nloss minimization problem. To cater for the scenario in which only a coarse\nestimation is available for the rank of the true matrix, an $\\ell_{2,0}$-norm\nregularized term is added to the factored loss function to reduce the rank\nadaptively; and account for the ambiguities in the factorization, a balanced\nterm is then introduced. For the least squares loss, under a restricted\ncondition number assumption on the sampling operator, we establish the KL\nproperty of exponent $1/2$ of the nonsmooth factored composite function and its\nequivalent DC reformulations in the set of their global minimizers. We also\nconfirm the theoretical findings by applying a proximal linearized alternating\nminimization method to the regularized factorizations.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 02:56:17 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Bi", "Shujun", ""], ["Tao", "Ting", ""], ["Pan", "Shaohua", ""]]}, {"id": "1908.09092", "submitter": "Dylan Slack", "authors": "Dylan Slack, Sorelle Friedler, Emile Givental", "title": "Fairness Warnings and Fair-MAML: Learning Fairly with Minimal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by concerns surrounding the fairness effects of sharing and\ntransferring fair machine learning tools, we propose two algorithms: Fairness\nWarnings and Fair-MAML. The first is a model-agnostic algorithm that provides\ninterpretable boundary conditions for when a fairly trained model may not\nbehave fairly on similar but slightly different tasks within a given domain.\nThe second is a fair meta-learning approach to train models that can be quickly\nfine-tuned to specific tasks from only a few number of sample instances while\nbalancing fairness and accuracy. We demonstrate experimentally the individual\nutility of each model using relevant baselines and provide the first experiment\nto our knowledge of K-shot fairness, i.e. training a fair model on a new task\nwith only K data points. Then, we illustrate the usefulness of both algorithms\nas a combined method for training models from a few data points on new tasks\nwhile using Fairness Warnings as interpretable boundary conditions under which\nthe newly trained model may not be fair.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 05:15:41 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 05:51:42 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Slack", "Dylan", ""], ["Friedler", "Sorelle", ""], ["Givental", "Emile", ""]]}, {"id": "1908.09094", "submitter": "Sandeep Juneja", "authors": "Shubhada Agrawal, Sandeep Juneja and Peter Glynn", "title": "Optimal $\\delta$-Correct Best-Arm Selection for General Distributions", "comments": "49 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a finite set of unknown distributions, or arms, that can be sampled, we\nconsider the problem of identifying the one with the largest mean using a\ndelta-correct algorithm (an adaptive, sequential algorithm that restricts the\nprobability of error to a specified delta) that has minimum sample complexity.\nLower bounds for delta-correct algorithms are well known. Delta-correct\nalgorithms that match the lower bound asymptotically as delta reduces to zero\nhave been previously developed when arm distributions are restricted to a\nsingle parameter exponential family. In this paper, we first observe a negative\nresult that some restrictions are essential, as otherwise under a delta-correct\nalgorithm, distributions with unbounded support would require an infinite\nnumber of samples in expectation. We then propose a delta-correct algorithm\nthat matches the lower bound as delta reduces to zero under the mild\nrestriction that a known bound on the expectation of a non-negative,\ncontinuous, increasing convex function (for example, the squared moment) of the\nunderlying random variables, exists. We also propose batch processing and\nidentify near-optimal batch sizes to substantially speed up the proposed\nalgorithm. The best-arm problem has many learning applications, including\nrecommendation systems and product selection. It is also a well studied classic\nproblem in the simulation community.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 05:31:49 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 07:13:06 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Agrawal", "Shubhada", ""], ["Juneja", "Sandeep", ""], ["Glynn", "Peter", ""]]}, {"id": "1908.09102", "submitter": "Takuya Kanazawa", "authors": "Takuya Kanazawa, Akinori Asahara, Hidekazu Morita", "title": "Accelerating small-angle scattering experiments with simulation-based\n  machine learning", "comments": "19 pages, 9 figures. Accepted for publication in Journal of Physics:\n  Materials", "journal-ref": "J. Phys. Mater. 3 (2019) 015001", "doi": "10.1088/2515-7639/ab3c45", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making material experiments more efficient is a high priority for materials\nscientists who seek to discover new materials with desirable properties. In\nthis paper, we investigate how to optimize the laborious sequential\nmeasurements of materials properties with data-driven methods, taking the\nsmall-angle neutron scattering (SANS) experiment as a test case. We propose two\nmethods for optimizing sequential data sampling. These methods iteratively\nsuggest the best target for the next measurement by performing a statistical\nanalysis of the already acquired data, so that maximal information is gained at\neach step of an experiment. We conducted numerical simulations of SANS\nexperiments for virtual materials and confirmed that the proposed methods\nsignificantly outperform baselines.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 07:21:36 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Kanazawa", "Takuya", ""], ["Asahara", "Akinori", ""], ["Morita", "Hidekazu", ""]]}, {"id": "1908.09108", "submitter": "Sagi Eppel", "authors": "Sagi Eppel, Alan Aspuru-Guzik", "title": "Generator evaluator-selector net for panoptic image segmentation and\n  splitting unfamiliar objects into parts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In machine learning and other fields, suggesting a good solution to a problem\nis usually a harder task than evaluating the quality of such a solution. This\nasymmetry is the basis for a large number of selection oriented methods that\nuse a generator system to guess a set of solutions and an evaluator system to\nrank and select the best solutions. This work examines the use of this approach\nto the problem of panoptic image segmentation and class agnostic parts\nsegmentation. The generator/evaluator approach for this case consists of two\nindependent convolutional neural nets: a generator net that suggests variety\nsegments corresponding to objects, stuff and parts regions in the image, and an\nevaluator net that chooses the best segments to be merged into the segmentation\nmap. The result is a trial and error evolutionary approach in which a generator\nthat guesses segments with low average accuracy, but with wide variability, can\nstill produce good results when coupled with an accurate evaluator. The\ngenerator consists of a Pointer net that receives an image and a point in the\nimage, and predicts the region of the segment containing the point. Generating\nand evaluating each segment separately is essential in this case since it\ndemands exponentially fewer guesses compared to a system that guesses and\nevaluates the full segmentation map in each try. The classification of the\nselected segments is done by an independent region-specific classification net.\nThis allows the segmentation to be class agnostic and hence, capable of\nsegmenting unfamiliar categories that were not part of the training set. The\nmethod was examined on the COCO Panoptic segmentation benchmark and gave\nresults comparable to those of the basic semantic segmentation and Mask-RCNN\nmethods. In addition, the system was used for the task of splitting objects of\nunseen classes (that did not appear in the training set) into parts.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 09:01:27 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 02:02:07 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 19:28:03 GMT"}, {"version": "v4", "created": "Mon, 13 Apr 2020 08:55:36 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Eppel", "Sagi", ""], ["Aspuru-Guzik", "Alan", ""]]}, {"id": "1908.09124", "submitter": "Jintao Zhang", "authors": "Jintao Zhang", "title": "SeesawFaceNets: sparse and robust face verification model for mobile\n  platform", "comments": "8 pages, 2 figures. All source code and proposed models will be\n  released publicly later", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Network (DCNNs) come to be the most widely used\nsolution for most computer vision related tasks, and one of the most important\napplication scenes is face verification. Due to its high-accuracy performance,\ndeep face verification models of which the inference stage occurs on cloud\nplatform through internet plays the key role on most prectical scenes. However,\ntwo critical issues exist: First, individual privacy may not be well protected\nsince they have to upload their personal photo and other private information to\nthe online cloud backend. Secondly, either training or inference stage is\ntime-comsuming and the latency may affect customer experience, especially when\nthe internet link speed is not so stable or in remote areas where mobile\nreception is not so good, but also in cities where building and other\nconstruction may block mobile signals. Therefore, designing lightweight\nnetworks with low memory requirement and computational cost is one of the most\npractical solutions for face verification on mobile platform. In this paper, a\nnovel mobile network named SeesawFaceNets, a simple but effective model, is\nproposed for productively deploying face recognition for mobile devices. Dense\nexperimental results have shown that our proposed model SeesawFaceNets\noutperforms the baseline MobilefaceNets, with only {\\bf66\\%}(146M VS 221M\nMAdds) computational cost, smaller batch size and less training steps, and\nSeesawFaceNets achieve comparable performance with other SOTA model e.g.\nmobiface with only {\\bf54.2\\%}(1.3M VS 2.4M) parameters and {\\bf31.6\\%}(146M VS\n462M MAdds) computational cost, It is also eventually competitive against\nlarge-scale deep-networks face recognition on all 5 listed public validation\ndatasets, with {\\bf6.5\\%}(4.2M VS 65M) parameters and {\\bf4.35\\%}(526M VS 12G\nMAdds) computational cost.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 11:21:38 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 17:54:54 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 12:52:26 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Jintao", ""]]}, {"id": "1908.09127", "submitter": "Ehsan Montahaei", "authors": "Ehsan Montahaei, Danial Alihosseini, Mahdieh Soleymani Baghshah", "title": "DGSAN: Discrete Generative Self-Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although GAN-based methods have received many achievements in the last few\nyears, they have not been entirelysuccessful in generating discrete data. The\nmost crucial challenge of these methods is the difficulty of passing the\ngradientfrom the discriminator to the generator when the generator outputs are\ndiscrete. Despite the fact that several attemptshave been made to alleviate\nthis problem, none of the existing GAN-based methods have improved the\nperformance oftext generation compared with the maximum likelihood approach in\nterms of both the quality and the diversity. In thispaper, we proposed a new\nframework for generating discrete data by an adversarial approach in which\nthere is no need topass the gradient to the generator. The proposed method has\nan iterative manner in which each new generator is definedbased on the last\ndiscriminator. It leverages the discreteness of data and the last discriminator\nto model the real datadistribution implicitly. Moreover, the method is\nsupported with theoretical guarantees, and experimental results generallyshow\nthe superiority of the proposed DGSAN method compared to the other popular or\nrecent methods in generatingdiscrete sequential data.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 11:39:50 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 10:25:10 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Montahaei", "Ehsan", ""], ["Alihosseini", "Danial", ""], ["Baghshah", "Mahdieh Soleymani", ""]]}, {"id": "1908.09128", "submitter": "Wei Wei", "authors": "Wei Wei, Zanbo Wang, Xianling Mao, Guangyou Zhou, Pan Zhou, Sheng\n  Jiang", "title": "Enhancing Neural Sequence Labeling with Position-Aware Self-Attention", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labeling is a fundamental task in natural language processing and\nhas been widely studied. Recently, RNN-based sequence labeling models have\nincreasingly gained attentions. Despite superior performance achieved by\nlearning the long short-term (i.e., successive) dependencies, the way of\nsequentially processing inputs might limit the ability to capture the\nnon-continuous relations over tokens within a sentence. To tackle the problem,\nwe focus on how to effectively model successive and discrete dependencies of\neach token for enhancing the sequence labeling performance. Specifically, we\npropose an innovative and well-designed attention-based model (called\nposition-aware self-attention, i.e., PSA) within a neural network architecture,\nto explore the positional information of an input sequence for capturing the\nlatent relations among tokens. Extensive experiments on three classical tasks\nin sequence labeling domain, i.e., part-of-speech (POS) tagging, named entity\nrecognition (NER) and phrase chunking, demonstrate our proposed model\noutperforms the state-of-the-arts without any external knowledge, in terms of\nvarious metrics.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 11:40:08 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wei", "Wei", ""], ["Wang", "Zanbo", ""], ["Mao", "Xianling", ""], ["Zhou", "Guangyou", ""], ["Zhou", "Pan", ""], ["Jiang", "Sheng", ""]]}, {"id": "1908.09137", "submitter": "Seunghyun Yoon", "authors": "Seunghyun Yoon, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Kyomin\n  Jung", "title": "Propagate-Selector: Detecting Supporting Sentences for Question\n  Answering via Graph Neural Networks", "comments": "8 pages, Accepted as a conference paper at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a novel graph neural network called\npropagate-selector (PS), which propagates information over sentences to\nunderstand information that cannot be inferred when considering sentences in\nisolation. First, we design a graph structure in which each node represents an\nindividual sentence, and some pairs of nodes are selectively connected based on\nthe text structure. Then, we develop an iterative attentive aggregation and a\nskip-combine method in which a node interacts with its neighborhood nodes to\naccumulate the necessary information. To evaluate the performance of the\nproposed approaches, we conduct experiments with the standard HotpotQA dataset.\nThe empirical results demonstrate the superiority of our proposed approach,\nwhich obtains the best performances, compared to the widely used\nanswer-selection models that do not consider the intersentential relationship.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 13:37:35 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 13:25:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Yoon", "Seunghyun", ""], ["Dernoncourt", "Franck", ""], ["Kim", "Doo Soon", ""], ["Bui", "Trung", ""], ["Jung", "Kyomin", ""]]}, {"id": "1908.09148", "submitter": "Szymon P{\\l}otka", "authors": "Tomasz W{\\l}odarczyk, Szymon P{\\l}otka, Tomasz Trzci\\'nski,\n  Przemys{\\l}aw Rokita, Nicole Sochacki-W\\'ojcicka, Micha{\\l} Lipa, Jakub\n  W\\'ojcicki", "title": "Estimation of preterm birth markers with U-Net segmentation network", "comments": "Accepted at MICCAI Workshop on Perinatal, Preterm and Paediatric\n  Image analysis (PIPPI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preterm birth is the most common cause of neonatal death. Current diagnostic\nmethods that assess the risk of preterm birth involve the collection of\nmaternal characteristics and transvaginal ultrasound imaging conducted in the\nfirst and second trimester of pregnancy. Analysis of the ultrasound data is\nbased on visual inspection of images by gynaecologist, sometimes supported by\nhand-designed image features such as cervical length. Due to the complexity of\nthis process and its subjective component, approximately 30% of spontaneous\npreterm deliveries are not correctly predicted. Moreover, 10% of the predicted\npreterm deliveries are false-positives. In this paper, we address the problem\nof predicting spontaneous preterm delivery using machine learning. To achieve\nthis goal, we propose to first use a deep neural network architecture for\nsegmenting prenatal ultrasound images and then automatically extract two\nbiophysical ultrasound markers, cervical length (CL) and anterior cervical\nangle (ACA), from the resulting images. Our method allows to estimate\nultrasound markers without human oversight. Furthermore, we show that CL and\nACA markers, when combined, allow us to decrease false-negative ratio from 30%\nto 18%. Finally, contrary to the current approaches to diagnostics methods that\nrely only on gynaecologist's expertise, our method introduce objectively\nobtained results.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 15:14:11 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["W\u0142odarczyk", "Tomasz", ""], ["P\u0142otka", "Szymon", ""], ["Trzci\u0144ski", "Tomasz", ""], ["Rokita", "Przemys\u0142aw", ""], ["Sochacki-W\u00f3jcicka", "Nicole", ""], ["Lipa", "Micha\u0142", ""], ["W\u00f3jcicki", "Jakub", ""]]}, {"id": "1908.09152", "submitter": "Jie Huang", "authors": "Jie Huang, Xin Liu, Yangqiu Song", "title": "Hyper-Path-Based Representation Learning for Hyper-Networks", "comments": "Accepted by CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3357871", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning has aroused widespread interests in recent\nyears. While most of the existing methods deal with edges as pairwise\nrelationships, only a few studies have been proposed for hyper-networks to\ncapture more complicated tuplewise relationships among multiple nodes. A\nhyper-network is a network where each edge, called hyperedge, connects an\narbitrary number of nodes. Different from conventional networks, hyper-networks\nhave certain degrees of indecomposability such that the nodes in a subset of a\nhyperedge may not possess a strong relationship. That is the main reason why\ntraditional algorithms fail in learning representations in hyper-networks by\nsimply decomposing hyperedges into pairwise relationships. In this paper, we\nfirstly define a metric to depict the degrees of indecomposability for\nhyper-networks. Then we propose a new concept called hyper-path and design\nhyper-path-based random walks to preserve the structural information of\nhyper-networks according to the analysis of the indecomposability. Then a\ncarefully designed algorithm, Hyper-gram, utilizes these random walks to\ncapture both pairwise relationships and tuplewise relationships in the whole\nhyper-networks. Finally, we conduct extensive experiments on several real-world\ndatasets covering the tasks of link prediction and hyper-network\nreconstruction, and results demonstrate the rationality, validity, and\neffectiveness of our methods compared with those existing state-of-the-art\nmodels designed for conventional networks or hyper-networks.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 15:19:29 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 19:08:21 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Huang", "Jie", ""], ["Liu", "Xin", ""], ["Song", "Yangqiu", ""]]}, {"id": "1908.09157", "submitter": "Pawe{\\l} Czy\\.z", "authors": "Albert Ziegler and Pawe{\\l} Czy\\.z", "title": "Unsupervised Recalibration", "comments": "26 pages, added comparison with standard quantification algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised recalibration (URC) is a general way to improve the accuracy of\nan already trained probabilistic classification or regression model upon\nencountering new data while deployed in the field. URC does not require any\nground truth associated with the new field data. URC merely observes the\nmodel's predictions and recognizes when the training set is not representative\nof field data, and then corrects to remove any introduced bias.\n  URC can be particularly useful when applied separately to different\nsubpopulations observed in the field that were not considered as features when\ntraining the machine learning model. This makes it possible to exploit\nsubpopulation information without retraining the model or even having ground\ntruth for some or all subpopulations available.\n  Additionally, if these subpopulations are the object of study, URC serves to\ndetermine the correct ground truth distributions for them, where naive\naggregation methods, like averaging the model's predictions, systematically\nunderestimate their differences.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 15:54:00 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 11:31:32 GMT"}, {"version": "v3", "created": "Sat, 17 Oct 2020 13:01:13 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ziegler", "Albert", ""], ["Czy\u017c", "Pawe\u0142", ""]]}, {"id": "1908.09171", "submitter": "Michael Everett", "authors": "Michael Everett and Justin Miller and Jonathan P. How", "title": "Planning Beyond the Sensing Horizon Using a Learned Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Last-mile delivery systems commonly propose the use of autonomous robotic\nvehicles to increase scalability and efficiency. The economic inefficiency of\ncollecting accurate prior maps for navigation motivates the use of planning\nalgorithms that operate in unmapped environments. However, these algorithms\ntypically waste time exploring regions that are unlikely to contain the\ndelivery destination. Context is key information about structured environments\nthat could guide exploration toward the unknown goal location, but the abstract\nidea is difficult to quantify for use in a planning algorithm. Some approaches\nspecifically consider contextual relationships between objects, but would\nperform poorly in object-sparse environments like outdoors. Recent deep\nlearning-based approaches consider context too generally, making\ntraining/transferability difficult. Therefore, this work proposes a novel\nformulation of utilizing context for planning as an image-to-image translation\nproblem, which is shown to extract terrain context from semantic gridmaps, into\na metric that an exploration-based planner can use. The proposed framework has\nthe benefit of training on a static dataset instead of requiring a\ntime-consuming simulator. Across 42 test houses with layouts from satellite\nimages, the trained algorithm enables a robot to reach its goal 189\\% faster\nthan with a context-unaware planner, and within 63\\% of the optimal path\ncomputed with a prior map. The proposed algorithm is also implemented on a\nvehicle with a forward-facing camera in a high-fidelity, Unreal simulation of\nneighborhood houses.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 17:19:50 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 15:03:43 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 21:34:05 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Everett", "Michael", ""], ["Miller", "Justin", ""], ["How", "Jonathan P.", ""]]}, {"id": "1908.09173", "submitter": "Vira Semenova", "authors": "Victor Chernozhukov, Whitney Newey, Vira Semenova", "title": "Inference on weighted average value function in high-dimensional state\n  space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a consistent, asymptotically normal estimator of the\nexpected value function when the state space is high-dimensional and the\nfirst-stage nuisance functions are estimated by modern machine learning tools.\nFirst, we show that value function is orthogonal to the conditional choice\nprobability, therefore, this nuisance function needs to be estimated only at\n$n^{-1/4}$ rate. Second, we give a correction term for the transition density\nof the state variable. The resulting orthogonal moment is robust to\nmisspecification of the transition density and does not require this nuisance\nfunction to be consistently estimated. Third, we generalize this result by\nconsidering the weighted expected value. In this case, the orthogonal moment is\ndoubly robust in the transition density and additional second-stage nuisance\nfunctions entering the correction term. We complete the asymptotic theory by\nproviding bounds on second-order asymptotic terms.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 17:34:40 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Newey", "Whitney", ""], ["Semenova", "Vira", ""]]}, {"id": "1908.09174", "submitter": "Najibesadat Sadati Jafarkalaei", "authors": "Najibesadat Sadati, Milad Zafar Nezhad, Ratna Babu Chinnam, Dongxiao\n  Zhu", "title": "Representation Learning with Autoencoders for Electronic Health Records:\n  A Comparative Study", "comments": "Reason: This submission is the extension of our other research which\n  has already submitted in arXiv (arXiv:1801.02961), therefore we decided\n  update that version and withdraw this submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing volume of Electronic Health Records (EHR) in recent years provides\ngreat opportunities for data scientists to collaborate on different aspects of\nhealthcare research by applying advanced analytics to these EHR clinical data.\nA key requirement however is obtaining meaningful insights from high\ndimensional, sparse and complex clinical data. Data science approaches\ntypically address this challenge by performing feature learning in order to\nbuild more reliable and informative feature representations from clinical data\nfollowed by supervised learning. In this paper, we propose a predictive\nmodeling approach based on deep learning based feature representations and word\nembedding techniques. Our method uses different deep architectures (stacked\nsparse autoencoders, deep belief network, adversarial autoencoders and\nvariational autoencoders) for feature representation in higher-level\nabstraction to obtain effective and robust features from EHRs, and then build\nprediction models on top of them. Our approach is particularly useful when the\nunlabeled data is abundant whereas labeled data is scarce. We investigate the\nperformance of representation learning through a supervised learning approach.\nOur focus is to present a comparative study to evaluate the performance of\ndifferent deep architectures through supervised learning and provide insights\nin the choice of deep feature representation techniques. Our experiments\ndemonstrate that for small data sets, stacked sparse autoencoder demonstrates a\nsuperior generality performance in prediction due to sparsity regularization\nwhereas variational autoencoders outperform the competing approaches for large\ndata sets due to its capability of learning the representation distribution\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 17:38:30 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 02:17:16 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Sadati", "Najibesadat", ""], ["Nezhad", "Milad Zafar", ""], ["Chinnam", "Ratna Babu", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1908.09183", "submitter": "Caroline Clark", "authors": "Josiah I. Clark, Caroline A. Clark", "title": "Deriving a Quantitative Relationship Between Resolution and Human\n  Classification Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For machine learning perception problems, human-level classification\nperformance is used as an estimate of top algorithm performance. Thus, it is\nimportant to understand as precisely as possible the factors that impact\nhuman-level performance. Knowing this 1) provides a benchmark for model\nperformance, 2) tells a project manager what type of data to obtain for human\nlabelers in order to get accurate labels, and 3) enables ground-truth\nanalysis--largely conducted by humans--to be carried out smoothly. In this\nempirical study, we explored the relationship between resolution and human\nclassification performance using the MNIST data set down-sampled to various\nresolutions. The quantitative heuristic we derived could prove useful for\npredicting machine model performance, predicting data storage requirements, and\nsaving valuable resources in the deployment of machine learning projects. It\nalso has the potential to be used in a wide variety of fields such as remote\nsensing, medical imaging, scientific imaging, and astronomy.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 18:34:13 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Clark", "Josiah I.", ""], ["Clark", "Caroline A.", ""]]}, {"id": "1908.09184", "submitter": "Hassam Sheikh", "authors": "Hassam Ullah Sheikh, Ladislau B\\\"ol\\\"oni", "title": "Universal Policies to Learn Them All", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.04500", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore a collaborative and cooperative multi-agent reinforcement learning\nsetting where a team of reinforcement learning agents attempt to solve a single\ncooperative task in a multi-scenario setting. We propose a novel multi-agent\nreinforcement learning algorithm inspired by universal value function\napproximators that not only generalizes over state space but also over a set of\ndifferent scenarios. Additionally, to prove our claim, we are introducing a\nchallenging 2D multi-agent urban security environment where the learning agents\nare trying to protect a person from nearby bystanders in a variety of\nscenarios. Our study shows that state-of-the-art multi-agent reinforcement\nlearning algorithms fail to generalize a single task over multiple scenarios\nwhile our proposed solution works equally well as scenario-dependent policies.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 18:36:17 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Sheikh", "Hassam Ullah", ""], ["B\u00f6l\u00f6ni", "Ladislau", ""]]}, {"id": "1908.09205", "submitter": "Paul Kantor", "authors": "Vladimir Menkov, Paul Kantor", "title": "Ontology alignment: A Content-Based Bayesian Approach", "comments": "29 pp. 2 figure. Research Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many legacy databases, and related stores of information that are\nmaintained by distinct organizations, and there are other organizations that\nwould like to be able to access and use those disparate sources. Among the\nexamples of current interest are such things as emergency room records, of\ninterest in tracking and interdicting illicit drugs, or social media public\nposts that indicate preparation and intention for a mass shooting incident. In\nmost cases, this information is discovered too late to be useful. While\nagencies responsible for coordination are aware of the potential value of\ncontemporaneous access to new data, the costs of establishing a connection are\nprohibitive. The problem grown even worse with the proliferation of\n``hash-tagging,'' which permits new labels and ontological relations to spring\nup overnight. While research interest has waned, the need for powerful and\ninexpensive tools enabling prompt access to multiple sources has grown ever\nmore pressing. This paper describes techniques for computing alignment matrix\ncoefficients, which relate the fields or content of one database to those of\nanother, using the Bayesian Ontology Alignment tool (BOA). Particular attention\nis given to formulas that have an easy-to-understand meaning when all cells of\nthe data sources containing values from some small set. These formulas can be\nexpressed in terms of probability estimates. The estimates themselves are given\nby a ``black box'' polytomous logistic regression model (PLRM), and thus can be\neasily generalized to the case of any arbitrary probability-generating model.\nThe specific PLRM model used in this example is the BOXER Bayesian Extensible\nOnline Regression model.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 20:54:27 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Menkov", "Vladimir", ""], ["Kantor", "Paul", ""]]}, {"id": "1908.09207", "submitter": "Qinzhe Wu", "authors": "Snehil Verma, Qinzhe Wu, Bagus Hanindhito, Gunjan Jha, Eugene B. John,\n  Ramesh Radhakrishnan, and Lizy K. John", "title": "Demystifying the MLPerf Benchmark Suite", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  MLPerf, an emerging machine learning benchmark suite strives to cover a broad\nrange of applications of machine learning. We present a study on its\ncharacteristics and how the MLPerf benchmarks differ from some of the previous\ndeep learning benchmarks like DAWNBench and DeepBench. We find that application\nbenchmarks such as MLPerf (although rich in kernels) exhibit different features\ncompared to kernel benchmarks such as DeepBench. MLPerf benchmark suite\ncontains a diverse set of models which allows unveiling various bottlenecks in\nthe system. Based on our findings, dedicated low latency interconnect between\nGPUs in multi-GPU systems is required for optimal distributed deep learning\ntraining. We also observe variation in scaling efficiency across the MLPerf\nmodels. The variation exhibited by the different models highlight the\nimportance of smart scheduling strategies for multi-GPU training. Another\nobservation is that CPU utilization increases with increase in number of GPUs\nused for training. Corroborating prior work we also observe and quantify\nimprovements possible by compiler optimizations, mixed-precision training and\nuse of Tensor Cores.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 20:55:10 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Verma", "Snehil", ""], ["Wu", "Qinzhe", ""], ["Hanindhito", "Bagus", ""], ["Jha", "Gunjan", ""], ["John", "Eugene B.", ""], ["Radhakrishnan", "Ramesh", ""], ["John", "Lizy K.", ""]]}, {"id": "1908.09213", "submitter": "Alicja Gosiewska", "authors": "Alicja Gosiewska and Mateusz Bakala and Katarzyna Woznica and Maciej\n  Zwolinski and Przemyslaw Biecek", "title": "EPP: interpretable score of model predictive power", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most important part of model selection and hyperparameter tuning is the\nevaluation of model performance. The most popular measures, such as AUC, F1,\nACC for binary classification, or RMSE, MAD for regression, or cross-entropy\nfor multilabel classification share two common weaknesses. First is, that they\nare not on an interval scale. It means that the difference in performance for\nthe two models has no direct interpretation. It makes no sense to compare such\ndifferences between datasets. Second is, that for k-fold cross-validation, the\nmodel performance is in most cases calculated as an average performance from\nparticular folds, which neglects the information how stable is the performance\nfor different folds.\n  In this talk, we introduce a new EPP rating system for predictive models. We\nalso demonstrate numerous advantages for this system, First, differences in EPP\nscores have probabilistic interpretation. Based on it we can assess the\nprobability that one model will achieve better performance than another.\nSecond, EPP scores can be directly compared between datasets. Third, they can\nbe used for navigated hyperparameter tuning and model selection. Forth, we can\ncreate embeddings for datasets based on EPP scores.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 21:24:15 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Gosiewska", "Alicja", ""], ["Bakala", "Mateusz", ""], ["Woznica", "Katarzyna", ""], ["Zwolinski", "Maciej", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "1908.09219", "submitter": "Andre Nguyen", "authors": "Andre T. Nguyen and Edward Raff", "title": "Heterogeneous Relational Kernel Learning", "comments": "MileTS '19: 5th KDD Workshop on Mining and Learning from Time Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has developed Bayesian methods for the automatic statistical\nanalysis and description of single time series as well as of homogeneous sets\nof time series data. We extend prior work to create an interpretable kernel\nembedding for heterogeneous time series. Our method adds practically no\ncomputational cost compared to prior results by leveraging previously discarded\nintermediate results. We show the practical utility of our method by leveraging\nthe learned embeddings for clustering, pattern discovery, and anomaly\ndetection. These applications are beyond the ability of prior relational kernel\nlearning approaches.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 22:00:39 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Nguyen", "Andre T.", ""], ["Raff", "Edward", ""]]}, {"id": "1908.09222", "submitter": "Vishwali Mhasawade", "authors": "Vishwali Mhasawade, Nabeel Abdur Rehman, Rumi Chunara", "title": "Population-aware Hierarchical Bayesian Domain Adaptation via\n  Multiple-component Invariant Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3368555.3384451", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning is rapidly being developed and deployed in health\nsettings such as influenza prediction, there are critical challenges in using\ndata from one environment in another due to variability in features; even\nwithin disease labels there can be differences (e.g. \"fever\" may mean something\ndifferent reported in a doctor's office versus in an online app). Moreover,\nmodels are often built on passive, observational data which contain different\ndistributions of population subgroups (e.g. men or women). Thus, there are two\nforms of instability between environments in this observational transport\nproblem. We first harness knowledge from health to conceptualize the underlying\ncausal structure of this problem in a health outcome prediction task. Based on\nsources of stability in the model, we posit that for human-sourced data and\nhealth prediction tasks we can combine environment and population information\nin a novel population-aware hierarchical Bayesian domain adaptation framework\nthat harnesses multiple invariant components through population attributes when\nneeded. We study the conditions under which invariant learning fails, leading\nto reliance on the environment-specific attributes. Experimental results for an\ninfluenza prediction task on four datasets gathered from different contexts\nshow the model can improve prediction in the case of largely unlabelled target\ndata from a new environment and different constituent population, by harnessing\nboth environment and population invariant information. This work represents a\nnovel, principled way to address a critical challenge by blending domain\n(health) knowledge and algorithmic innovation. The proposed approach will have\na significant impact in many social settings wherein who and where the data\ncomes from matters.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 22:14:11 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 14:04:58 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 16:40:18 GMT"}, {"version": "v4", "created": "Fri, 13 Sep 2019 13:07:43 GMT"}, {"version": "v5", "created": "Mon, 9 Mar 2020 15:55:16 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Mhasawade", "Vishwali", ""], ["Rehman", "Nabeel Abdur", ""], ["Chunara", "Rumi", ""]]}, {"id": "1908.09238", "submitter": "Weizhong Yan", "authors": "Weizhong Yan and Lijie Yu", "title": "On Accurate and Reliable Anomaly Detection for Gas Turbine Combustors: A\n  Deep Learning Approach", "comments": "8 pages", "journal-ref": "PHM 2015 Conference", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring gas turbine combustors health, in particular, early detecting\nabnormal behaviors and incipient faults, is critical in ensuring gas turbines\noperating efficiently and in preventing costly unplanned maintenance. One\npopular means of detecting combustor abnormalities is through continuously\nmonitoring exhaust gas temperature profiles. Over the years many anomaly\ndetection technologies have been explored for detecting combustor faults,\nhowever, the performance (detection rate) of anomaly detection solutions\nfielded is still inadequate. Advanced technologies that can improve detection\nperformance are in great need. Aiming for improving anomaly detection\nperformance, in this paper we introduce recently-developed deep learning (DL)\nin machine learning into the combustors anomaly detection application.\nSpecifically, we use deep learning to hierarchically learn features from the\nsensor measurements of exhaust gas temperatures. And we then use the learned\nfeatures as the input to a neural network classifier for performing combustor\nanomaly detection. Since such deep learned features potentially better capture\ncomplex relations among all sensor measurements and the underlying combustor\nbehavior than handcrafted features do, we expect the learned features can lead\nto a more accurate and robust anomaly detection. Using the data collected from\na real-world gas turbine combustion system, we demonstrated that the proposed\ndeep learning based anomaly detection significantly indeed improved combustor\nanomaly detection performance.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 00:11:34 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Yan", "Weizhong", ""], ["Yu", "Lijie", ""]]}, {"id": "1908.09246", "submitter": "Rui Wang", "authors": "Rui Wang and Deyu Zhou and Yulan He", "title": "Open Event Extraction from Online Text using a Generative Adversarial\n  Network", "comments": "Accepted by EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To extract the structured representations of open-domain events, Bayesian\ngraphical models have made some progress. However, these approaches typically\nassume that all words in a document are generated from a single event. While\nthis may be true for short text such as tweets, such an assumption does not\ngenerally hold for long text such as news articles. Moreover, Bayesian\ngraphical models often rely on Gibbs sampling for parameter inference which may\ntake long time to converge. To address these limitations, we propose an event\nextraction model based on Generative Adversarial Nets, called\nAdversarial-neural Event Model (AEM). AEM models an event with a Dirichlet\nprior and uses a generator network to capture the patterns underlying latent\nevents. A discriminator is used to distinguish documents reconstructed from the\nlatent events and the original documents. A byproduct of the discriminator is\nthat the features generated by the learned discriminator network allow the\nvisualization of the extracted events. Our model has been evaluated on two\nTwitter datasets and a news article dataset. Experimental results show that our\nmodel outperforms the baseline approaches on all the datasets, with more\nsignificant improvements observed on the news article dataset where an increase\nof 15\\% is observed in F-measure.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 03:17:38 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wang", "Rui", ""], ["Zhou", "Deyu", ""], ["He", "Yulan", ""]]}, {"id": "1908.09251", "submitter": "Robert Gniadecki", "authors": "Sepideh Emam, Amy X. Du, Philip Surmanowicz, Simon F. Thomsen, Russ\n  Greiner, Robert Gniadecki", "title": "Predicting the Long-Term Outcomes of Biologics in Psoriasis Patients\n  Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. Real-world data show that approximately 50% of psoriasis patients\ntreated with a biologic agent will discontinue the drug because of loss of\nefficacy. History of previous therapy with another biologic, female sex and\nobesity were identified as predictors of drug discontinuations, but their\nindividual predictive value is low. Objectives. To determine whether machine\nlearning algorithms can produce models that can accurately predict outcomes of\nbiologic therapy in psoriasis on individual patient level. Results. All tested\nmachine learning algorithms could accurately predict the risk of drug\ndiscontinuation and its cause (e.g. lack of efficacy vs adverse event). The\nlearned generalized linear model achieved diagnostic accuracy of 82%, requiring\nunder 2 seconds per patient using the psoriasis patients dataset. Input\noptimization analysis established a profile of a patient who has best chances\nof long-term treatment success: biologic-naive patient under 49 years,\nearly-onset plaque psoriasis without psoriatic arthritis, weight < 100 kg, and\nmoderate-to-severe psoriasis activity (DLQI $\\geq$ 16; PASI $\\geq$ 10).\nMoreover, a different generalized linear model is used to predict the length of\ntreatment for each patient with mean absolute error (MAE) of 4.5 months.\nHowever Pearson Correlation Coefficient indicates 0.935 linear dependencies\nbetween the actual treatment lengths and predicted ones. Conclusions. Machine\nlearning algorithms predict the risk of drug discontinuation and treatment\nduration with accuracy exceeding 80%, based on a small set of predictive\nvariables. This approach can be used as a decision-making tool, communicating\nexpected outcomes to the patient, and development of evidence-based guidelines.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 05:07:49 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Emam", "Sepideh", ""], ["Du", "Amy X.", ""], ["Surmanowicz", "Philip", ""], ["Thomsen", "Simon F.", ""], ["Greiner", "Russ", ""], ["Gniadecki", "Robert", ""]]}, {"id": "1908.09257", "submitter": "Ivan Kobyzev", "authors": "Ivan Kobyzev and Simon J.D. Prince and Marcus A. Brubaker", "title": "Normalizing Flows: An Introduction and Review of Current Methods", "comments": "This paper appears in: IEEE Transactions on Pattern Analysis and\n  Machine Intelligence On page(s): 1-16 Print ISSN: 0162-8828 Online ISSN:\n  0162-8828", "journal-ref": null, "doi": "10.1109/TPAMI.2020.2992934", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing Flows are generative models which produce tractable distributions\nwhere both sampling and density evaluation can be efficient and exact. The goal\nof this survey article is to give a coherent and comprehensive review of the\nliterature around the construction and use of Normalizing Flows for\ndistribution learning. We aim to provide context and explanation of the models,\nreview current state-of-the-art literature, and identify open questions and\npromising future directions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 06:14:08 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 05:49:57 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 01:45:47 GMT"}, {"version": "v4", "created": "Sat, 6 Jun 2020 00:24:11 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kobyzev", "Ivan", ""], ["Prince", "Simon J. D.", ""], ["Brubaker", "Marcus A.", ""]]}, {"id": "1908.09258", "submitter": "Bahareh Tolooshams", "authors": "Thomas Chang, Bahareh Tolooshams, Demba Ba", "title": "RandNet: deep learning with compressed measurements of images", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis, dictionary learning, and auto-encoders are all\nunsupervised methods for learning representations from a large amount of\ntraining data. In all these methods, the higher the dimensions of the input\ndata, the longer it takes to learn. We introduce a class of neural networks,\ntermed RandNet, for learning representations using compressed random\nmeasurements of data of interest, such as images. RandNet extends the\nconvolutional recurrent sparse auto-encoder architecture to dense networks and,\nmore importantly, to the case when the input data are compressed random\nmeasurements of the original data. Compressing the input data makes it possible\nto fit a larger number of batches in memory during training. Moreover, in the\ncase of sparse measurements,training is more efficient computationally. We\ndemonstrate that, in unsupervised settings, RandNet performs dictionary\nlearning using compressed data. In supervised settings, we show that RandNet\ncan classify MNIST images with minimal loss in accuracy, despite being trained\nwith random projections of the images that result in a 50% reduction in size.\nOverall, our results provide a general principled framework for training neural\nnetworks using compressed data.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 06:19:15 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Chang", "Thomas", ""], ["Tolooshams", "Bahareh", ""], ["Ba", "Demba", ""]]}, {"id": "1908.09260", "submitter": "Lucas Bechberger", "authors": "Lucas Bechberger and Kai-Uwe K\\\"uhnberger", "title": "Generalizing Psychological Similarity Spaces to Unseen Stimuli", "comments": "Submitted to the edited volume \"Concepts in Action: Representation,\n  Learning, and Application\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cognitive framework of conceptual spaces proposes to represent concepts\nas regions in psychological similarity spaces. These similarity spaces are\ntypically obtained through multidimensional scaling (MDS), which converts human\ndissimilarity ratings for a fixed set of stimuli into a spatial representation.\nOne can distinguish metric MDS (which assumes that the dissimilarity ratings\nare interval or ratio scaled) from nonmetric MDS (which only assumes an ordinal\nscale). In our first study, we show that despite its additional assumptions,\nmetric MDS does not necessarily yield better solutions than nonmetric MDS. In\nthis chapter, we furthermore propose to learn a mapping from raw stimuli into\nthe similarity space using artificial neural networks (ANNs) in order to\ngeneralize the similarity space to unseen inputs. In our second study, we show\nthat a linear regression from the activation vectors of a convolutional ANN to\nsimilarity spaces obtained by MDS can be successful and that the results are\nsensitive to the number of dimensions of the similarity space.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 06:49:52 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 12:49:29 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Bechberger", "Lucas", ""], ["K\u00fchnberger", "Kai-Uwe", ""]]}, {"id": "1908.09282", "submitter": "Taeuk Kim", "authors": "Kang Min Yoo, Taeuk Kim, Sang-goo Lee", "title": "Don't Just Scratch the Surface: Enhancing Word Representations for\n  Korean with Hanja", "comments": "7 pages (5 main pages, 2 appendix pages), 1 figure, accepted in EMNLP\n  2019 (Conference on Empirical Methods in Natural Language Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet effective approach for improving Korean word\nrepresentations using additional linguistic annotation (i.e. Hanja). We employ\ncross-lingual transfer learning in training word representations by leveraging\nthe fact that Hanja is closely related to Chinese. We evaluate the intrinsic\nquality of representations learned through our approach using the word analogy\nand similarity tests. In addition, we demonstrate their effectiveness on\nseveral downstream tasks, including a novel Korean news headline generation\ntask.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 08:57:50 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 06:35:15 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 01:47:24 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Yoo", "Kang Min", ""], ["Kim", "Taeuk", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1908.09287", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Principal Component Analysis Using Structural Similarity Index for\n  Images", "comments": "Paper for the methods named \"Image Structural Component Analysis\n  (ISCA)\" and \"Kernel Image Structural Component Analysis (Kernel ISCA)\"", "journal-ref": "International Conference on Image Analysis and Recognition,\n  Springer, pp. 77-88, 2019", "doi": "10.1007/978-3-030-27202-9_7", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the advances of deep learning in specific tasks using images, the\nprincipled assessment of image fidelity and similarity is still a critical\nability to develop. As it has been shown that Mean Squared Error (MSE) is\ninsufficient for this task, other measures have been developed with one of the\nmost effective being Structural Similarity Index (SSIM). Such measures can be\nused for subspace learning but existing methods in machine learning, such as\nPrincipal Component Analysis (PCA), are based on Euclidean distance or MSE and\nthus cannot properly capture the structural features of images. In this paper,\nwe define an image structure subspace which discriminates different types of\nimage distortions. We propose Image Structural Component Analysis (ISCA) and\nalso kernel ISCA by using SSIM, rather than Euclidean distance, in the\nformulation of PCA. This paper provides a bridge between image quality\nassessment and manifold learning opening a broad new area for future research.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 09:18:03 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1908.09288", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Locally Linear Image Structural Embedding for Image Structure Manifold\n  Learning", "comments": "This is the paper for the methods named \"Locally Linear Image\n  Structural Embedding (LLISE)\" and \"Kernel Locally Linear Image Structural\n  Embedding (Kernel LLISE)\"", "journal-ref": "International Conference on Image Analysis and Recognition,\n  Springer, pp. 126-138, 2019", "doi": "10.1007/978-3-030-27202-9_11", "report-no": null, "categories": "stat.ML cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of existing manifold learning methods rely on Mean Squared Error (MSE)\nor $\\ell_2$ norm. However, for the problem of image quality assessment, these\nare not promising measure. In this paper, we introduce the concept of an image\nstructure manifold which captures image structure features and discriminates\nimage distortions. We propose a new manifold learning method, Locally Linear\nImage Structural Embedding (LLISE), and kernel LLISE for learning this\nmanifold. The LLISE is inspired by Locally Linear Embedding (LLE) but uses SSIM\nrather than MSE. This paper builds a bridge between manifold learning and image\nfidelity assessment and it can open a new area for future investigations.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 09:32:45 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1908.09296", "submitter": "Sun-Yu Gordon Chi", "authors": "Sun-Yu Gordon Chi", "title": "Exploring the Performance of Deep Residual Networks in Crazyhouse Chess", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crazyhouse is a chess variant that incorporates all of the classical chess\nrules, but allows users to drop pieces captured from the opponent as a normal\nmove. Until 2018, all competitive computer engines for this board game made use\nof an alpha-beta pruning algorithm with a hand-crafted evaluation function for\neach position. Previous machine learning-based algorithms for just regular\nchess, such as NeuroChess and Giraffe, took hand-crafted evaluation features as\ninput rather than a raw board representation. More recent projects, such as\nAlphaZero, reached massive success but required massive computational resources\nin order to reach its final strength.\n  This paper describes the development of SixtyFour, an engine designed to\ncompete in the chess variant of Crazyhouse with limited hardware. This specific\nvariant poses a multitude of significant challenges due to its large branching\nfactor, state-space complexity, and the multiple move types a player can make.\nWe propose the novel creation of a neural network-based evaluation function for\nCrazyhouse. More importantly, we evaluate the effectiveness of an ensemble\nmodel, which allows the training time and datasets to be easily distributed on\nregular CPU hardware commodity. Early versions of the network have attained a\nplaying level comparable to a strong amateur on online servers.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 10:18:02 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Chi", "Sun-Yu Gordon", ""]]}, {"id": "1908.09324", "submitter": "Xu Tan", "authors": "Xu Tan, Jiale Chen, Di He, Yingce Xia, Tao Qin and Tie-Yan Liu", "title": "Multilingual Neural Machine Translation with Language Clustering", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual neural machine translation (NMT), which translates multiple\nlanguages using a single model, is of great practical importance due to its\nadvantages in simplifying the training process, reducing online maintenance\ncosts, and enhancing low-resource and zero-shot translation. Given there are\nthousands of languages in the world and some of them are very different, it is\nextremely burdensome to handle them all in a single model or use a separate\nmodel for each language pair. Therefore, given a fixed resource budget, e.g.,\nthe number of models, how to determine which languages should be supported by\none model is critical to multilingual NMT, which, unfortunately, has been\nignored by previous work. In this work, we develop a framework that clusters\nlanguages into different groups and trains one multilingual model for each\ncluster. We study two methods for language clustering: (1) using prior\nknowledge, where we cluster languages according to language family, and (2)\nusing language embedding, in which we represent each language by an embedding\nvector and cluster them in the embedding space. In particular, we obtain the\nembedding vectors of all the languages by training a universal neural machine\ntranslation model. Our experiments on 23 languages show that the first\nclustering method is simple and easy to understand but leading to suboptimal\ntranslation accuracy, while the second method sufficiently captures the\nrelationship among languages well and improves the translation accuracy for\nalmost all the languages over baseline methods\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 13:27:57 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Tan", "Xu", ""], ["Chen", "Jiale", ""], ["He", "Di", ""], ["Xia", "Yingce", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1908.09329", "submitter": "Xu Tan", "authors": "Xu Tan, Yingce Xia, Lijun Wu and Tao Qin", "title": "Efficient Bidirectional Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The encoder-decoder based neural machine translation usually generates a\ntarget sequence token by token from left to right. Due to error propagation,\nthe tokens in the right side of the generated sequence are usually of poorer\nquality than those in the left side. In this paper, we propose an efficient\nmethod to generate a sequence in both left-to-right and right-to-left manners\nusing a single encoder and decoder, combining the advantages of both generation\ndirections. Experiments on three translation tasks show that our method\nachieves significant improvements over conventional unidirectional approach.\nCompared with ensemble methods that train and combine two models with different\ngeneration directions, our method saves 50% model parameters and about 40%\ntraining time, and also improve inference speed.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 13:59:03 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Tan", "Xu", ""], ["Xia", "Yingce", ""], ["Wu", "Lijun", ""], ["Qin", "Tao", ""]]}, {"id": "1908.09341", "submitter": "Artem Artemov", "authors": "Artem Artemov, Boris Alekseev", "title": "A Method for Estimating the Proximity of Vector Representation Groups in\n  Multidimensional Space. On the Example of the Paraphrase Task", "comments": "8 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The following paper presents a method of comparing two sets of vectors. The\nmethod can be applied in all tasks, where it is necessary to measure the\ncloseness of two objects presented as sets of vectors. It may be applicable\nwhen we compare the meanings of two sentences as part of the problem of\nparaphrasing. This is the problem of measuring semantic similarity of two\nsentences (group of words). The existing methods are not sensible for the word\norder or syntactic connections in the considered sentences. The method appears\nto be advantageous because it neither presents a group of words as one scalar\nvalue, nor does it try to show the closeness through an aggregation vector,\nwhich is mean for the set of vectors. Instead of that we measure the cosine of\nthe angle as the mean for the first group vectors projections (the context) on\none side and each vector of the second group on the other side. The similarity\nof two sentences defined by these means does not lose any semantic\ncharacteristics and takes account of the words traits. The method was verified\non the comparison of sentence pairs in Russian.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 14:54:49 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 13:22:14 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Artemov", "Artem", ""], ["Alekseev", "Boris", ""]]}, {"id": "1908.09345", "submitter": "Bingcong Li", "authors": "Bingcong Li, Lingda Wang, Georgios B. Giannakis", "title": "Almost Tune-Free Variance Reduction", "comments": null, "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variance reduction class of algorithms including the representative ones,\nSVRG and SARAH, have well documented merits for empirical risk minimization\nproblems. However, they require grid search to tune parameters (step size and\nthe number of iterations per inner loop) for optimal performance. This work\nintroduces `almost tune-free' SVRG and SARAH schemes equipped with i)\nBarzilai-Borwein (BB) step sizes; ii) averaging; and, iii) the inner loop\nlength adjusted to the BB step sizes. In particular, SVRG, SARAH, and their BB\nvariants are first reexamined through an `estimate sequence' lens to enable new\naveraging methods that tighten their convergence rates theoretically, and\nimprove their performance empirically when the step size or the inner loop\nlength is chosen large. Then a simple yet effective means to adjust the number\nof iterations per inner loop is developed to enhance the merits of the proposed\naveraging schemes and BB step sizes. Numerical tests corroborate the proposed\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 15:24:04 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 12:14:42 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Li", "Bingcong", ""], ["Wang", "Lingda", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1908.09354", "submitter": "Kun Cao", "authors": "Kun Cao, James Fairbanks", "title": "Unsupervised Construction of Knowledge Graphs From Text and Code", "comments": "25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,\n  15th International Workshop On Mining and Learning with Graphs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scientific literature is a rich source of information for data mining\nwith conceptual knowledge graphs; the open science movement has enriched this\nliterature with complementary source code that implements scientific models. To\nexploit this new resource, we construct a knowledge graph using unsupervised\nlearning methods to identify conceptual entities. We associate source code\nentities to these natural language concepts using word embedding and clustering\ntechniques. Practical naming conventions for methods and functions tend to\nreflect the concept(s) they implement. We take advantage of this specificity by\npresenting a novel process for joint clustering text concepts that combines\nword-embeddings, nonlinear dimensionality reduction, and clustering techniques\nto assist in understanding, organizing, and comparing software in the open\nscience ecosystem. With our pipeline, we aim to assist scientists in building\non existing models in their discipline when making novel models for new\nphenomena. By combining source code and conceptual information, our knowledge\ngraph enhances corpus-wide understanding of scientific literature.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 16:10:31 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Cao", "Kun", ""], ["Fairbanks", "James", ""]]}, {"id": "1908.09355", "submitter": "Zhe Gan", "authors": "Siqi Sun, Yu Cheng, Zhe Gan, Jingjing Liu", "title": "Patient Knowledge Distillation for BERT Model Compression", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models such as BERT have proven to be highly effective\nfor natural language processing (NLP) tasks. However, the high demand for\ncomputing resources in training such models hinders their application in\npractice. In order to alleviate this resource hunger in large-scale model\ntraining, we propose a Patient Knowledge Distillation approach to compress an\noriginal large model (teacher) into an equally-effective lightweight shallow\nnetwork (student). Different from previous knowledge distillation methods,\nwhich only use the output from the last layer of the teacher network for\ndistillation, our student model patiently learns from multiple intermediate\nlayers of the teacher model for incremental knowledge extraction, following two\nstrategies: ($i$) PKD-Last: learning from the last $k$ layers; and ($ii$)\nPKD-Skip: learning from every $k$ layers. These two patient distillation\nschemes enable the exploitation of rich information in the teacher's hidden\nlayers, and encourage the student model to patiently learn from and imitate the\nteacher through a multi-layer distillation process. Empirically, this\ntranslates into improved results on multiple NLP tasks with significant gain in\ntraining efficiency, without sacrificing model accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 16:13:24 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Sun", "Siqi", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Liu", "Jingjing", ""]]}, {"id": "1908.09357", "submitter": "William Whitney", "authors": "William Whitney, Rajat Agarwal, Kyunghyun Cho, and Abhinav Gupta", "title": "Dynamics-aware Embeddings", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider self-supervised representation learning to improve\nsample efficiency in reinforcement learning (RL). We propose a forward\nprediction objective for simultaneously learning embeddings of states and\naction sequences. These embeddings capture the structure of the environment's\ndynamics, enabling efficient policy learning. We demonstrate that our action\nembeddings alone improve the sample efficiency and peak performance of\nmodel-free RL on control from low-dimensional states. By combining state and\naction embeddings, we achieve efficient learning of high-quality policies on\ngoal-conditioned continuous control from pixel observations in only 1-2 million\nenvironment steps.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 16:22:04 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 13:08:05 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 14:50:13 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Whitney", "William", ""], ["Agarwal", "Rajat", ""], ["Cho", "Kyunghyun", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1908.09362", "submitter": "Ziyu Liu", "authors": "Ziyu Liu, Guolin Ke, Jiang Bian, Tieyan Liu", "title": "LightMC: A Dynamic and Efficient Multiclass Decomposition Algorithm", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiclass decomposition splits a multiclass classification problem into a\nseries of independent binary learners and recomposes them by combining their\noutputs to reconstruct the multiclass classification results. Three widely-used\nrealizations of such decomposition methods are One-Versus-All (OVA),\nOne-Versus-One (OVO), and Error-Correcting-Output-Code (ECOC). While OVA and\nOVO are quite simple, both of them assume all classes are orthogonal which\nneglect the latent correlation between classes in real-world.\nError-Correcting-Output-Code (ECOC) based decomposition methods, on the other\nhand, are more preferable due to its integration of the correlation among\nclasses. However, the performance of existing ECOC-based methods highly depends\non the design of coding matrix and decoding strategy. Unfortunately, it is\nquite uncertain and time-consuming to discover an effective coding matrix with\nappropriate decoding strategy. To address this problem, we propose LightMC, an\nefficient dynamic multiclass decomposition algorithm. Instead of using fixed\ncoding matrix and decoding strategy, LightMC uses a differentiable decoding\nstrategy, which enables it to dynamically optimize the coding matrix and\ndecoding strategy, toward increasing the overall accuracy of multiclass\nclassification, via back propagation jointly with the training of base learners\nin an iterative way. Empirical experimental results on several public\nlarge-scale multiclass classification datasets have demonstrated the\neffectiveness of LightMC in terms of both good accuracy and high efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 17:12:01 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Liu", "Ziyu", ""], ["Ke", "Guolin", ""], ["Bian", "Jiang", ""], ["Liu", "Tieyan", ""]]}, {"id": "1908.09364", "submitter": "Benjamin Paassen", "authors": "Benjamin Paa{\\ss}en", "title": "Adversarial Edit Attacks for Tree Data", "comments": "accepted at the 20th International Conference on Intelligent Data\n  Engineering and Automated Learning (IDEAL)", "journal-ref": "Proc. IDEAL 20 (2019) 359-366", "doi": "10.1007/978-3-030-33607-3_39", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning models can be attacked with adversarial examples, i.e.\ninputs close to correctly classified examples that are classified incorrectly.\nHowever, most research on adversarial attacks to date is limited to vectorial\ndata, in particular image data. In this contribution, we extend the field by\nintroducing adversarial edit attacks for tree-structured data with potential\napplications in medicine and automated program analysis. Our approach solely\nrelies on the tree edit distance and a logarithmic number of black-box queries\nto the attacked classifier without any need for gradient information. We\nevaluate our approach on two programming and two biomedical data sets and show\nthat many established tree classifiers, like tree-kernel-SVMs and recursive\nneural networks, can be attacked effectively.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 17:20:15 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 07:53:03 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Paa\u00dfen", "Benjamin", ""]]}, {"id": "1908.09368", "submitter": "Akhilesh Sudhakar", "authors": "Akhilesh Sudhakar, Bhargav Upadhyay, Arjun Maheswaran", "title": "Transforming Delete, Retrieve, Generate Approach for Controlled Text\n  Style Transfer", "comments": "11 pages, 6 Tables, 2 Figures, Accepted at 2019 Conference on\n  Empirical Methods in Natural Language Processing (EMNLP - 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer is the task of transferring the style of text having\ncertain stylistic attributes, while preserving non-stylistic or content\ninformation. In this work we introduce the Generative Style Transformer (GST) -\na new approach to rewriting sentences to a target style in the absence of\nparallel style corpora. GST leverages the power of both, large unsupervised\npre-trained language models as well as the Transformer. GST is a part of a\nlarger `Delete Retrieve Generate' framework, in which we also propose a novel\nmethod of deleting style attributes from the source sentence by exploiting the\ninner workings of the Transformer. Our models outperform state-of-art systems\nacross 5 datasets on sentiment, gender and political slant transfer. We also\npropose the use of the GLEU metric as an automatic metric of evaluation of\nstyle transfer, which we found to compare better with human ratings than the\npredominantly used BLEU score.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 17:34:40 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Sudhakar", "Akhilesh", ""], ["Upadhyay", "Bhargav", ""], ["Maheswaran", "Arjun", ""]]}, {"id": "1908.09369", "submitter": "Sunipa Dev", "authors": "Sunipa Dev, Tao Li, Jeff Phillips, Vivek Srikumar", "title": "On Measuring and Mitigating Biased Inferences of Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings carry stereotypical connotations from the text they are\ntrained on, which can lead to invalid inferences in downstream models that rely\non them. We use this observation to design a mechanism for measuring\nstereotypes using the task of natural language inference. We demonstrate a\nreduction in invalid inferences via bias mitigation strategies on static word\nembeddings (GloVe). Further, we show that for gender bias, these techniques\nextend to contextualized embeddings when applied selectively only to the static\ncomponents of contextualized embeddings (ELMo, BERT).\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 17:50:18 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 23:20:40 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 17:13:38 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Dev", "Sunipa", ""], ["Li", "Tao", ""], ["Phillips", "Jeff", ""], ["Srikumar", "Vivek", ""]]}, {"id": "1908.09375", "submitter": "Qianli Liao", "authors": "Tomaso Poggio, Andrzej Banburski, Qianli Liao", "title": "Theoretical Issues in Deep Networks: Approximation, Optimization and\n  Generalization", "comments": "arXiv admin note: text overlap with arXiv:1611.00740", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning is successful in a number of applications, it is not yet\nwell understood theoretically. A satisfactory theoretical characterization of\ndeep learning however, is beginning to emerge. It covers the following\nquestions: 1) representation power of deep networks 2) optimization of the\nempirical risk 3) generalization properties of gradient descent techniques ---\nwhy the expected error does not suffer, despite the absence of explicit\nregularization, when the networks are overparametrized? In this review we\ndiscuss recent advances in the three areas. In approximation theory both\nshallow and deep networks have been shown to approximate any continuous\nfunctions on a bounded domain at the expense of an exponential number of\nparameters (exponential in the dimensionality of the function). However, for a\nsubset of compositional functions, deep networks of the convolutional type can\nhave a linear dependence on dimensionality, unlike shallow networks. In\noptimization we discuss the loss landscape for the exponential loss function\nand show that stochastic gradient descent will find with high probability the\nglobal minima. To address the question of generalization for classification\ntasks, we use classical uniform convergence results to justify minimizing a\nsurrogate exponential-type loss function under a unit norm constraint on the\nweight matrix at each layer -- since the interesting variables for\nclassification are the weight directions rather than the weights. Our approach,\nwhich is supported by several independent new results, offers a solution to the\npuzzle about generalization performance of deep overparametrized ReLU networks,\nuncovering the origin of the underlying hidden complexity control.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 19:12:56 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Poggio", "Tomaso", ""], ["Banburski", "Andrzej", ""], ["Liao", "Qianli", ""]]}, {"id": "1908.09381", "submitter": "Xudong Sun", "authors": "Xudong Sun and Bernd Bischl", "title": "Tutorial and Survey on Probabilistic Graphical Model and Variational\n  Inference in Deep Reinforcement Learning", "comments": "2019 IEEE Symposium on Computational Intelligence, Symposium on\n  Adaptive Dynamic Programming and Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Aiming at a comprehensive and concise tutorial survey, recap of variational\ninference and reinforcement learning with Probabilistic Graphical Models are\ngiven with detailed derivations. Reviews and comparisons on recent advances in\ndeep reinforcement learning are made from various aspects. We offer detailed\nderivations to a taxonomy of Probabilistic Graphical Model and Variational\nInference methods in deep reinforcement learning, which serves as a\ncomplementary material on top of the original contributions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 19:36:36 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 20:10:41 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 21:33:38 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 23:28:17 GMT"}, {"version": "v5", "created": "Sun, 8 Dec 2019 11:44:35 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Sun", "Xudong", ""], ["Bischl", "Bernd", ""]]}, {"id": "1908.09393", "submitter": "Jonathan Strahl", "authors": "Jonathan Strahl and Jaakko Peltonen and Hiroshi Mamitsuka and Samuel\n  Kaski", "title": "Scalable Probabilistic Matrix Factorization with Graph-Based Priors", "comments": "Under review", "journal-ref": "AAAI 2020", "doi": "10.1609/aaai.v34i04.6043", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In matrix factorization, available graph side-information may not be well\nsuited for the matrix completion problem, having edges that disagree with the\nlatent-feature relations learnt from the incomplete data matrix. We show that\nremoving these $\\textit{contested}$ edges improves prediction accuracy and\nscalability. We identify the contested edges through a highly-efficient\ngraphical lasso approximation. The identification and removal of contested\nedges adds no computational complexity to state-of-the-art graph-regularized\nmatrix factorization, remaining linear with respect to the number of non-zeros.\nComputational load even decreases proportional to the number of edges removed.\nFormulating a probabilistic generative model and using expectation maximization\nto extend graph-regularised alternating least squares (GRALS) guarantees\nconvergence. Rich simulated experiments illustrate the desired properties of\nthe resulting algorithm. On real data experiments we demonstrate improved\nprediction accuracy with fewer graph edges (empirical evidence that graph\nside-information is often inaccurate). A 300 thousand dimensional graph with\nthree million edges (Yahoo music side-information) can be analyzed in under ten\nminutes on a standard laptop computer demonstrating the efficiency of our graph\nupdate.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 21:21:18 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 12:26:43 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Strahl", "Jonathan", ""], ["Peltonen", "Jaakko", ""], ["Mamitsuka", "Hiroshi", ""], ["Kaski", "Samuel", ""]]}, {"id": "1908.09414", "submitter": "Jong Chul Ye", "authors": "Sungjun Lim, Hyoungjun Park, Sang-Eun Lee, Sunghoe Chang, and Jong\n  Chul Ye", "title": "CycleGAN with a Blur Kernel for Deconvolution Microscopy: Optimal\n  Transport Geometry", "comments": "This paper is accepted for IEEE Trans. Computational Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deconvolution microscopy has been extensively used to improve the resolution\nof the wide-field fluorescent microscopy, but the performance of classical\napproaches critically depends on the accuracy of a model and optimization\nalgorithms. Recently, the convolutional neural network (CNN) approaches have\nbeen studied as a fast and high performance alternative. Unfortunately, the CNN\napproaches usually require matched high resolution images for supervised\ntraining. In this paper, we present a novel unsupervised cycle-consistent\ngenerative adversarial network (cycleGAN) with a linear blur kernel, which can\nbe used for both blind- and non-blind image deconvolution. In contrast to the\nconventional cycleGAN approaches that require two deep generators, the proposed\ncycleGAN approach needs only a single deep generator and a linear blur kernel,\nwhich significantly improves the robustness and efficiency of network training.\nWe show that the proposed architecture is indeed a dual formulation of an\noptimal transport problem that uses a special form of the penalized least\nsquares cost as a transport cost. Experimental results using simulated and real\nexperimental data confirm the efficacy of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 00:34:16 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 07:25:41 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 05:05:59 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Lim", "Sungjun", ""], ["Park", "Hyoungjun", ""], ["Lee", "Sang-Eun", ""], ["Chang", "Sunghoe", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1908.09419", "submitter": "Junghoon Seo", "authors": "Junghoon Seo, Jamyoung Koo, Taegyun Jeon", "title": "Deep Closed-Form Subspace Clustering", "comments": "Accepted at the 2019 ICCV Workshop on Robust Subspace Learning and\n  Applications in Computer Vision (RSL-CV 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Deep Closed-Form Subspace Clustering (DCFSC), a new embarrassingly\nsimple model for subspace clustering with learning non-linear mapping. Compared\nwith the previous deep subspace clustering (DSC) techniques, our DCFSC does not\nhave any parameters at all for the self-expressive layer. Instead, DCFSC\nutilizes the implicit data-driven self-expressive layer derived from\nclosed-form shallow auto-encoder. Moreover, DCFSC also has no complicated\noptimization scheme, unlike the other subspace clustering methods. With its\nextreme simplicity, DCFSC has significant memory-related benefits over the\nexisting DSC method, especially on the large dataset. Several experiments\nshowed that our DCFSC model had enough potential to be a new reference model\nfor subspace clustering on large-scale high-dimensional dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 00:52:04 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Seo", "Junghoon", ""], ["Koo", "Jamyoung", ""], ["Jeon", "Taegyun", ""]]}, {"id": "1908.09428", "submitter": "Saeed Anwar", "authors": "Hafeez Anwar, Saeed Anwar, Sebastian Zambanini, Fatih Porikli", "title": "Deep Ancient Roman Republican Coin Classification via Feature Fusion and\n  Attention", "comments": "in Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform the classification of ancient Roman Republican coins via\nrecognizing their reverse motifs where various objects, faces, scenes, animals,\nand buildings are minted along with legends. Most of these coins are eroded due\nto their age and varying degrees of preservation, thereby affecting their\ninformative attributes for visual recognition. Changes in the positions of\nprincipal symbols on the reverse motifs also cause huge variations among the\ncoin types. Lastly, in-plane orientations, uneven illumination, and a moderate\nbackground clutter further make the classification task non-trivial and\nchallenging.\n  To this end, we present a novel network model, CoinNet, that employs compact\nbilinear pooling, residual groups, and feature attention layers. Furthermore,\nwe gathered the largest and most diverse image dataset of the Roman Republican\ncoins that contains more than 18,000 images belonging to 228 different reverse\nmotifs. On this dataset, our model achieves a classification accuracy of more\nthan \\textbf{98\\%} and outperforms the conventional bag-of-visual-words based\napproaches and more recent state-of-the-art deep learning methods. We also\nprovide a detailed ablation study of our network and its generalization\ncapability. Models and Datasets available at\nhttps://github.com/saeed-anwar/CoinNet\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 01:28:57 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 06:18:16 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Anwar", "Hafeez", ""], ["Anwar", "Saeed", ""], ["Zambanini", "Sebastian", ""], ["Porikli", "Fatih", ""]]}, {"id": "1908.09451", "submitter": "Huanru Henry Mao", "authors": "Huanru Henry Mao, Bodhisattwa Prasad Majumder, Julian McAuley,\n  Garrison W. Cottrell", "title": "Improving Neural Story Generation by Targeted Common Sense Grounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stories generated with neural language models have shown promise in\ngrammatical and stylistic consistency. However, the generated stories are still\nlacking in common sense reasoning, e.g., they often contain sentences deprived\nof world knowledge. We propose a simple multi-task learning scheme to achieve\nquantitatively better common sense reasoning in language models by leveraging\nauxiliary training signals from datasets designed to provide common sense\ngrounding. When combined with our two-stage fine-tuning pipeline, our method\nachieves improved common sense reasoning and state-of-the-art perplexity on the\nWriting Prompts (Fan et al., 2018) story generation dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 03:29:21 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 04:55:09 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Mao", "Huanru Henry", ""], ["Majumder", "Bodhisattwa Prasad", ""], ["McAuley", "Julian", ""], ["Cottrell", "Garrison W.", ""]]}, {"id": "1908.09453", "submitter": "Marc Lanctot", "authors": "Marc Lanctot, Edward Lockhart, Jean-Baptiste Lespiau, Vinicius\n  Zambaldi, Satyaki Upadhyay, Julien P\\'erolat, Sriram Srinivasan, Finbarr\n  Timbers, Karl Tuyls, Shayegan Omidshafiei, Daniel Hennes, Dustin Morrill,\n  Paul Muller, Timo Ewalds, Ryan Faulkner, J\\'anos Kram\\'ar, Bart De Vylder,\n  Brennan Saeta, James Bradbury, David Ding, Sebastian Borgeaud, Matthew Lai,\n  Julian Schrittwieser, Thomas Anthony, Edward Hughes, Ivo Danihelka, Jonah\n  Ryan-Davis", "title": "OpenSpiel: A Framework for Reinforcement Learning in Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenSpiel is a collection of environments and algorithms for research in\ngeneral reinforcement learning and search/planning in games. OpenSpiel supports\nn-player (single- and multi- agent) zero-sum, cooperative and general-sum,\none-shot and sequential, strictly turn-taking and simultaneous-move, perfect\nand imperfect information games, as well as traditional multiagent environments\nsuch as (partially- and fully- observable) grid worlds and social dilemmas.\nOpenSpiel also includes tools to analyze learning dynamics and other common\nevaluation metrics. This document serves both as an overview of the code base\nand an introduction to the terminology, core concepts, and algorithms across\nthe fields of reinforcement learning, computational game theory, and search.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 03:31:35 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 20:57:01 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 04:26:51 GMT"}, {"version": "v4", "created": "Thu, 10 Oct 2019 17:06:01 GMT"}, {"version": "v5", "created": "Tue, 31 Dec 2019 05:55:04 GMT"}, {"version": "v6", "created": "Sat, 26 Sep 2020 11:49:05 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lanctot", "Marc", ""], ["Lockhart", "Edward", ""], ["Lespiau", "Jean-Baptiste", ""], ["Zambaldi", "Vinicius", ""], ["Upadhyay", "Satyaki", ""], ["P\u00e9rolat", "Julien", ""], ["Srinivasan", "Sriram", ""], ["Timbers", "Finbarr", ""], ["Tuyls", "Karl", ""], ["Omidshafiei", "Shayegan", ""], ["Hennes", "Daniel", ""], ["Morrill", "Dustin", ""], ["Muller", "Paul", ""], ["Ewalds", "Timo", ""], ["Faulkner", "Ryan", ""], ["Kram\u00e1r", "J\u00e1nos", ""], ["De Vylder", "Bart", ""], ["Saeta", "Brennan", ""], ["Bradbury", "James", ""], ["Ding", "David", ""], ["Borgeaud", "Sebastian", ""], ["Lai", "Matthew", ""], ["Schrittwieser", "Julian", ""], ["Anthony", "Thomas", ""], ["Hughes", "Edward", ""], ["Danihelka", "Ivo", ""], ["Ryan-Davis", "Jonah", ""]]}, {"id": "1908.09471", "submitter": "Yang Lou Dr", "authors": "Yang Lou and Yaodong He and Lin Wang and Guanrong Chen", "title": "Predicting Network Controllability Robustness: A Convolutional Neural\n  Network Approach", "comments": "11 pages, 7 figures", "journal-ref": "IEEE Transactions on Cybernetics, 2020", "doi": "10.1109/TCYB.2020.3013251", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network controllability measures how well a networked system can be\ncontrolled to a target state, and its robustness reflects how well the system\ncan maintain the controllability against malicious attacks by means of\nnode-removals or edge-removals. The measure of network controllability is\nquantified by the number of external control inputs needed to recover or to\nretain the controllability after the occurrence of an unexpected attack. The\nmeasure of the network controllability robustness, on the other hand, is\nquantified by a sequence of values that record the remaining controllability of\nthe network after a sequence of attacks. Traditionally, the controllability\nrobustness is determined by attack simulations, which is computationally time\nconsuming. In this paper, a method to predict the controllability robustness\nbased on machine learning using a convolutional neural network is proposed,\nmotivated by the observations that 1) there is no clear correlation between the\ntopological features and the controllability robustness of a general network,\n2) the adjacency matrix of a network can be regarded as a gray-scale image, and\n3) the convolutional neural network technique has proved successful in image\nprocessing without human intervention. Under the new framework, a fairly large\nnumber of training data generated by simulations are used to train a\nconvolutional neural network for predicting the controllability robustness\naccording to the input network-adjacency matrices, without performing\nconventional attack simulations. Extensive experimental studies were carried\nout, which demonstrate that the proposed framework for predicting\ncontrollability robustness of different network configurations is accurate and\nreliable with very low overheads.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 05:06:28 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 13:49:47 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Lou", "Yang", ""], ["He", "Yaodong", ""], ["Wang", "Lin", ""], ["Chen", "Guanrong", ""]]}, {"id": "1908.09484", "submitter": "Hsiao-Tzu Hung", "authors": "Hsiao-Tzu Hung, Chung-Yang Wang, Yi-Hsuan Yang, Hsin-Min Wang", "title": "Improving Automatic Jazz Melody Generation by Transfer Learning\n  Techniques", "comments": "8 pages, Accepted to APSIPA ASC(Asia-Pacific Signal and Information\n  Processing Association Annual Summit and Conference ) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of transfer learning for Jazz automatic\ngeneration. Jazz is one of representative types of music, but the lack of Jazz\ndata in the MIDI format hinders the construction of a generative model for\nJazz. Transfer learning is an approach aiming to solve the problem of data\ninsufficiency, so as to transfer the common feature from one domain to another.\nIn view of its success in other machine learning problems, we investigate\nwhether, and how much, it can help improve automatic music generation for\nunder-resourced musical genres. Specifically, we use a recurrent variational\nautoencoder as the generative model, and use a genre-unspecified dataset as the\nsource dataset and a Jazz-only dataset as the target dataset. Two transfer\nlearning methods are evaluated using six levels of source-to-target data\nratios. The first method is to train the model on the source dataset, and then\nfine-tune the resulting model parameters on the target dataset. The second\nmethod is to train the model on both the source and target datasets at the same\ntime, but add genre labels to the latent vectors and use a genre classifier to\nimprove Jazz generation. The evaluation results show that the second method\nseems to perform better overall, but it cannot take full advantage of the\ngenre-unspecified dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 05:57:21 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hung", "Hsiao-Tzu", ""], ["Wang", "Chung-Yang", ""], ["Yang", "Yi-Hsuan", ""], ["Wang", "Hsin-Min", ""]]}, {"id": "1908.09487", "submitter": "Mihailo Jovanovic", "authors": "Armin Zare, Tryphon T. Georgiou, Mihailo R. Jovanovi\\'c", "title": "Stochastic dynamical modeling of turbulent flows", "comments": "To appear in the Annual Review of Control, Robotics, and Autonomous\n  Systems", "journal-ref": "Annu. Rev. Control Robot. Auton. Syst., vol. 3, pp. 195-219, May\n  2020", "doi": "10.1146/annurev-control-053018-023843", "report-no": null, "categories": "physics.flu-dyn cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced measurement techniques and high performance computing have made\nlarge data sets available for a wide range of turbulent flows that arise in\nengineering applications. Drawing on this abundance of data, dynamical models\ncan be constructed to reproduce structural and statistical features of\nturbulent flows, opening the way to the design of effective model-based flow\ncontrol strategies. This review describes a framework for completing\nsecond-order statistics of turbulent flows by models that are based on the\nNavier-Stokes equations linearized around the turbulent mean velocity. Systems\ntheory and convex optimization are combined to address the inherent uncertainty\nin the dynamics and the statistics of the flow by seeking a suitable\nparsimonious correction to the prior linearized model. Specifically, dynamical\ncouplings between states of the linearized model dictate structural constraints\non the statistics of flow fluctuations. Thence, colored-in-time stochastic\nforcing that drives the linearized model is sought to account for and reconcile\ndynamics with available data (i.e., partially known second order statistics).\nThe number of dynamical degrees of freedom that are directly affected by\nstochastic excitation is minimized as a measure of model parsimony. The\nspectral content of the resulting colored-in-time stochastic contribution can\nalternatively be seen to arise from a low-rank structural perturbation of the\nlinearized dynamical generator, pointing to suitable dynamical corrections that\nmay account for the absence of the nonlinear interactions in the linearized\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 06:13:10 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Zare", "Armin", ""], ["Georgiou", "Tryphon T.", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1908.09493", "submitter": "Tobias Kuhn", "authors": "Tobias Kuhn, Steven Bourke, Levin Brinkmann, Tobias Buchwald, Conor\n  Digan, Hendrik Hache, Sebastian Jaeger, Patrick Lehmann, Oskar Maier, Stefan\n  Matting, Yura Okulovsky", "title": "Supporting stylists by recommending fashion style", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outfittery is an online personalized styling service targeted at men. We have\nhundreds of stylists who create thousands of bespoke outfits for our customers\nevery day. A critical challenge faced by our stylists when creating these\noutfits is selecting an appropriate item of clothing that makes sense in the\ncontext of the outfit being created, otherwise known as style fit. Another\nsignificant challenge is knowing if the item is relevant to the customer based\non their tastes, physical attributes and price sensitivity. At Outfittery we\nleverage machine learning extensively and combine it with human domain\nexpertise to tackle these challenges. We do this by surfacing relevant items of\nclothing during the outfit building process based on what our stylist is doing\nand what the preferences of our customer are. In this paper we describe one way\nin which we help our stylists to tackle style fit for a particular item of\nclothing and its relevance to an outfit. A thorough qualitative and\nquantitative evaluation highlights the method's ability to recommend fashion\nitems by style fit.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 06:34:05 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Kuhn", "Tobias", ""], ["Bourke", "Steven", ""], ["Brinkmann", "Levin", ""], ["Buchwald", "Tobias", ""], ["Digan", "Conor", ""], ["Hache", "Hendrik", ""], ["Jaeger", "Sebastian", ""], ["Lehmann", "Patrick", ""], ["Maier", "Oskar", ""], ["Matting", "Stefan", ""], ["Okulovsky", "Yura", ""]]}, {"id": "1908.09507", "submitter": "Lesly Miculicich Werlen", "authors": "Lesly Miculicich, James Henderson", "title": "Partially-supervised Mention Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to detect entity mentions without using syntactic information can be\nuseful for integration and joint optimization with other tasks. However, it is\ncommon to have partially annotated data for this problem. Here, we investigate\ntwo approaches to deal with partial annotation of mentions: weighted loss and\nsoft-target classification. We also propose two neural mention detection\napproaches: a sequence tagging, and an exhaustive search. We evaluate our\nmethods with coreference resolution as a downstream task, using multitask\nlearning. The results show that the recall and F1 score improve for all\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 07:40:33 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Miculicich", "Lesly", ""], ["Henderson", "James", ""]]}, {"id": "1908.09515", "submitter": "Olivier Verdier", "authors": "Ozan \\\"Oktem, Camille Pouchol, Olivier Verdier", "title": "Spatiotemporal PET reconstruction using ML-EM with learned diffeomorphic\n  deformation", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-33843-5_14", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patient movement in emission tomography deteriorates reconstruction quality\nbecause of motion blur. Gating the data improves the situation somewhat: each\ngate contains a movement phase which is approximately stationary. A standard\nmethod is to use only the data from a few gates, with little movement between\nthem. However, the corresponding loss of data entails an increase of noise.\nMotion correction algorithms have been implemented to take into account all the\ngated data, but they do not scale well, especially not in 3D. We propose a\nnovel motion correction algorithm which addresses the scalability issue. Our\napproach is to combine an enhanced ML-EM algorithm with deep learning based\nmovement registration. The training is unsupervised, and with artificial data.\nWe expect this approach to scale very well to higher resolutions and to 3D, as\nthe overall cost of our algorithm is only marginally greater than that of a\nstandard ML-EM algorithm. We show that we can significantly decrease the noise\ncorresponding to a limited number of gates.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 08:04:49 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["\u00d6ktem", "Ozan", ""], ["Pouchol", "Camille", ""], ["Verdier", "Olivier", ""]]}, {"id": "1908.09572", "submitter": "Fatemeh Hadaeghi", "authors": "Fatemeh Hadaeghi", "title": "Neuromorphic Electronic Systems for Reservoir Computing", "comments": "This chapter is a contribution to a Springer book project titled\n  Reservoir Computing: Theory, Physical Implementations and Applications. This\n  pre-print is an updated version of the one submitted in 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This chapter provides a comprehensive survey of the researches and\nmotivations for hardware implementation of reservoir computing (RC) on\nneuromorphic electronic systems. Due to its computational efficiency and the\nfact that training amounts to a simple linear regression, both spiking and\nnon-spiking implementations of reservoir computing on neuromorphic hardware\nhave been developed. Here, a review of these experimental studies is provided\nto illustrate the progress in this area and to address the technical challenges\nwhich arise from this specific hardware implementation. Moreover, to deal with\nchallenges of computation on such unconventional substrates, several lines of\npotential solutions are presented based on advances in other computational\napproaches in machine learning. Keywords: Analog Microchips, FPGA, Memristors,\nNeuromorphic Architectures, Reservoir Computing\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 09:56:19 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 09:28:55 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Hadaeghi", "Fatemeh", ""]]}, {"id": "1908.09574", "submitter": "Alexander Mey", "authors": "Alexander Mey and Marco Loog", "title": "Improvability Through Semi-Supervised Learning: A Survey of Theoretical\n  Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning is a setting in which one has labeled and unlabeled\ndata available. In this survey we explore different types of theoretical\nresults when one uses unlabeled data in classification and regression tasks.\nMost methods that use unlabeled data rely on certain assumptions about the data\ndistribution. When those assumptions are not met in reality, including\nunlabeled data may actually decrease performance. Studying such methods, it\ntherefore is particularly important to have an understanding of the underlying\ntheory. In this review we gather results about the possible gains one can\nachieve when using semi-supervised learning as well as results about the limits\nof such methods. More precisely, this review collects the answers to the\nfollowing questions: What are, in terms of improving supervised methods, the\nlimits of semi-supervised learning? What are the assumptions of different\nmethods? What can we achieve if the assumptions are true? Finally, we also\ndiscuss the biggest bottleneck of semi-supervised learning, namely the\nassumptions they make.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 10:03:15 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 13:14:46 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 14:48:55 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Mey", "Alexander", ""], ["Loog", "Marco", ""]]}, {"id": "1908.09577", "submitter": "Leonardo Aniello Dr.", "authors": "Michael O'Sullivan, Leonardo Aniello, Vladimiro Sassone", "title": "A Methodology to Select Topology Generators for WANET Simulations\n  (Extended Version)", "comments": "18 pages (2 pages of references), 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many academic and industrial research works on WANETs rely on simulations, at\nleast in the first stages, to obtain preliminary results to be subsequently\nvalidated in real settings. Topology generators (TG) are commonly used to\ngenerate the initial placement of nodes in artificial WANET topologies, where\nthose simulations take place. The significance of these experiments heavily\ndepends on the representativeness of artificial topologies. Indeed, if they\nwere not drawn fairly, obtained results would apply only to a subset of\npossible configurations, hence they would lack of the appropriate generality\nrequired to port them to the real world. Although using many TGs could mitigate\nthis issue by generating topologies in several different ways, that would\nentail a significant additional effort. Hence, the problem arises of what TGs\nto choose, among a number of available generators, to maximise the\nrepresentativeness of generated topologies and reduce the number of TGs to use.\n  In this paper, we address that problem by investigating the presence of bias\nin the initial placement of nodes in artificial WANET topologies produced by\ndifferent TGs. We propose a methodology to assess such bias and introduce two\nmetrics to quantify the diversity of the topologies generated by a TG with\nrespect to all the available TGs, which can be used to select what TGs to use.\nWe carry out experiments on three well-known TGs, namely BRITE, NPART and\nGT-ITM. Obtained results show that using the artificial networks produced by a\nsingle TG can introduce bias.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 10:07:00 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["O'Sullivan", "Michael", ""], ["Aniello", "Leonardo", ""], ["Sassone", "Vladimiro", ""]]}, {"id": "1908.09597", "submitter": "Felix Bragman", "authors": "Felix J.S. Bragman, Ryutaro Tanno, Sebastien Ourselin, Daniel C.\n  Alexander, M. Jorge Cardoso", "title": "Stochastic Filter Groups for Multi-Task CNNs: Learning Specialist and\n  Generalist Convolution Kernels", "comments": "Accepted for oral presentation at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of multi-task learning in Convolutional Neural Networks\n(CNNs) hinges on the design of feature sharing between tasks within the\narchitecture. The number of possible sharing patterns are combinatorial in the\ndepth of the network and the number of tasks, and thus hand-crafting an\narchitecture, purely based on the human intuitions of task relationships can be\ntime-consuming and suboptimal. In this paper, we present a probabilistic\napproach to learning task-specific and shared representations in CNNs for\nmulti-task learning. Specifically, we propose \"stochastic filter groups''\n(SFG), a mechanism to assign convolution kernels in each layer to \"specialist''\nor \"generalist'' groups, which are specific to or shared across different\ntasks, respectively. The SFG modules determine the connectivity between layers\nand the structures of task-specific and shared representations in the network.\nWe employ variational inference to learn the posterior distribution over the\npossible grouping of kernels and network parameters. Experiments demonstrate\nthat the proposed method generalises across multiple tasks and shows improved\nperformance over baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 11:09:44 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Bragman", "Felix J. S.", ""], ["Tanno", "Ryutaro", ""], ["Ourselin", "Sebastien", ""], ["Alexander", "Daniel C.", ""], ["Cardoso", "M. Jorge", ""]]}, {"id": "1908.09625", "submitter": "Martin Mundt", "authors": "Martin Mundt, Iuliia Pliushch, Sagnik Majumder, Visvanathan Ramesh", "title": "Open Set Recognition Through Deep Neural Network Uncertainty: Does\n  Out-of-Distribution Detection Require Generative Classifiers?", "comments": "Accepted at the first workshop on Statistical Deep Learning for\n  Computer Vision (SDL-CV) at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analysis of predictive uncertainty based out-of-distribution\ndetection for different approaches to estimate various models' epistemic\nuncertainty and contrast it with extreme value theory based open set\nrecognition. While the former alone does not seem to be enough to overcome this\nchallenge, we demonstrate that uncertainty goes hand in hand with the latter\nmethod. This seems to be particularly reflected in a generative model approach,\nwhere we show that posterior based open set recognition outperforms\ndiscriminative models and predictive uncertainty based outlier rejection,\nraising the question of whether classifiers need to be generative in order to\nknow what they have not seen.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 12:19:53 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Mundt", "Martin", ""], ["Pliushch", "Iuliia", ""], ["Majumder", "Sagnik", ""], ["Ramesh", "Visvanathan", ""]]}, {"id": "1908.09635", "submitter": "Ninareh Mehrabi", "authors": "Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman,\n  Aram Galstyan", "title": "A Survey on Bias and Fairness in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of AI systems and applications in our everyday lives,\nit is important to take fairness issues into consideration while designing and\nengineering these types of systems. Such systems can be used in many sensitive\nenvironments to make important and life-changing decisions; thus, it is crucial\nto ensure that the decisions do not reflect discriminatory behavior toward\ncertain groups or populations. We have recently seen work in machine learning,\nnatural language processing, and deep learning that addresses such challenges\nin different subdomains. With the commercialization of these systems,\nresearchers are becoming aware of the biases that these applications can\ncontain and have attempted to address them. In this survey we investigated\ndifferent real-world applications that have shown biases in various ways, and\nwe listed different sources of biases that can affect AI applications. We then\ncreated a taxonomy for fairness definitions that machine learning researchers\nhave defined in order to avoid the existing bias in AI systems. In addition to\nthat, we examined different domains and subdomains in AI showing what\nresearchers have observed with regard to unfair outcomes in the\nstate-of-the-art methods and how they have tried to address them. There are\nstill many future directions and solutions that can be taken to mitigate the\nproblem of bias in AI systems. We are hoping that this survey will motivate\nresearchers to tackle these issues in the near future by observing existing\nwork in their respective fields.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 01:22:04 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 20:50:52 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Mehrabi", "Ninareh", ""], ["Morstatter", "Fred", ""], ["Saxena", "Nripsuta", ""], ["Lerman", "Kristina", ""], ["Galstyan", "Aram", ""]]}, {"id": "1908.09637", "submitter": "Dongrui Wu", "authors": "Zihan Liu, Bo Huang, Yuqi Cui, Yifan Xu, Bo Zhang, Lixia Zhu, Yang\n  Wang, Lei Jin and Dongrui Wu", "title": "Multi-Task Deep Learning with Dynamic Programming for Embryo Early\n  Development Stage Classification from Time-Lapse Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-lapse is a technology used to record the development of embryos during\nin-vitro fertilization (IVF). Accurate classification of embryo early\ndevelopment stages can provide embryologists valuable information for assessing\nthe embryo quality, and hence is critical to the success of IVF. This paper\nproposes a multi-task deep learning with dynamic programming (MTDL-DP) approach\nfor this purpose. It first uses MTDL to pre-classify each frame in the\ntime-lapse video to an embryo development stage, and then DP to optimize the\nstage sequence so that the stage number is monotonically non-decreasing, which\nusually holds in practice. Different MTDL frameworks, e.g., one-to-many,\nmany-to-one, and many-to-many, are investigated. It is shown that the\none-to-many MTDL framework achieved the best compromise between performance and\ncomputational cost. To our knowledge, this is the first study that applies MTDL\nto embryo early development stage classification from time-lapse videos.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 22:18:25 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Liu", "Zihan", ""], ["Huang", "Bo", ""], ["Cui", "Yuqi", ""], ["Xu", "Yifan", ""], ["Zhang", "Bo", ""], ["Zhu", "Lixia", ""], ["Wang", "Yang", ""], ["Jin", "Lei", ""], ["Wu", "Dongrui", ""]]}, {"id": "1908.09641", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti", "title": "Semi-supervised Learning for Word Sense Disambiguation", "comments": "This work was awarded the Third Place in the EST 2013 Contest (ISSN\n  1850-2946) at the 42nd JAIIO (Annals of 42nd JAIIO - Argentine Journals of\n  Informatics - ISSN 1850-2776)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is a study of the impact of multiple aspects in a classic\nunsupervised word sense disambiguation algorithm. We identify relevant factors\nin a decision rule algorithm, including the initial labeling of examples, the\nformalization of the rule confidence, and the criteria for accepting a decision\nrule. Some of these factors are only implicitly considered in the original\nliterature. We then propose a lightly supervised version of the algorithm, and\nemploy a pseudo-word-based strategy to evaluate the impact of these factors.\nThe obtained performances are comparable with those of highly optimized\nformulations of the word sense disambiguation method.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 12:35:28 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""]]}, {"id": "1908.09651", "submitter": "Christopher Blake", "authors": "Christopher G. Blake and Giuseppe Castiglione and Christopher\n  Srinivasa and Marcus Brubaker", "title": "Parity Partition Coding for Sharp Multi-Label Classification", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of efficiently training and evaluating image classifiers that can\ndistinguish between a large number of object categories is considered. A novel\nmetric, sharpness, is proposed which is defined as the fraction of object\ncategories that are above a threshold accuracy. To estimate sharpness (along\nwith a confidence value), a technique called fraction-accurate estimation is\nintroduced which samples categories and samples instances from these\ncategories. In addition, a technique called parity partition coding, a special\ntype of error correcting output code, is introduced, increasing sharpness,\nwhile reducing the multi-class problem to a multi-label one with exponentially\nfewer outputs. We demonstrate that this approach outperforms the baseline model\nfor both MultiMNIST and CelebA, while requiring fewer parameters and exceeding\nstate of the art accuracy on individual labels.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 17:23:17 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Blake", "Christopher G.", ""], ["Castiglione", "Giuseppe", ""], ["Srinivasa", "Christopher", ""], ["Brubaker", "Marcus", ""]]}, {"id": "1908.09652", "submitter": "Thiago Miranda", "authors": "Thiago Zafalon Miranda, Diorge Brognara Sardinha, Ricardo Cerri", "title": "Preventing the Generation of Inconsistent Sets of Classification Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the interest in interpretable classification models has\ngrown. One of the proposed ways to improve the interpretability of a rule-based\nclassification model is to use sets (unordered collections) of rules, instead\nof lists (ordered collections) of rules. One of the problems associated with\nsets is that multiple rules may cover a single instance, but predict different\nclasses for it, thus requiring a conflict resolution strategy. In this work, we\npropose two algorithms capable of finding feature-space regions inside which\nany created rule would be consistent with the already existing rules,\npreventing inconsistencies from arising. Our algorithms do not generate\nclassification models, but are instead meant to enhance algorithms that do so,\nsuch as Learning Classifier Systems. Both algorithms are described and analyzed\nexclusively from a theoretical perspective, since we have not modified a\nmodel-generating algorithm to incorporate our proposed solutions yet. This work\npresents the novelty of using conflict avoidance strategies instead of conflict\nresolution strategies.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 17:26:35 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 13:04:17 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Miranda", "Thiago Zafalon", ""], ["Sardinha", "Diorge Brognara", ""], ["Cerri", "Ricardo", ""]]}, {"id": "1908.09653", "submitter": "Yipeng Song", "authors": "Yipeng Song", "title": "Fusing heterogeneous data sets", "comments": "PhD thesis, 173 pages, 60 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In systems biology, it is common to measure biochemical entities at different\nlevels of the same biological system. One of the central problems for the data\nfusion of such data sets is the heterogeneity of the data. This thesis\ndiscusses two types of heterogeneity. The first one is the type of data, such\nas metabolomics, proteomics and RNAseq data in genomics. These different omics\ndata reflect the properties of the studied biological system from different\nperspectives. The second one is the type of scale, which indicates the\nmeasurements obtained at different scales, such as binary, ordinal, interval\nand ratio-scaled variables. In this thesis, we developed several statistical\nmethods capable to fuse data sets of these two types of heterogeneity. The\nadvantages of the proposed methods in comparison with other approaches are\nassessed using comprehensive simulations as well as the analysis of real\nbiological data sets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 12:20:04 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Song", "Yipeng", ""]]}, {"id": "1908.09705", "submitter": "Ido Freeman", "authors": "Alessandro Cennamo, Ido Freeman, Anton Kummert", "title": "A Statistical Defense Approach for Detecting Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are maliciously modified inputs created to fool deep\nneural networks (DNN). The discovery of such inputs presents a major issue to\nthe expansion of DNN-based solutions. Many researchers have already contributed\nto the topic, providing both cutting edge-attack techniques and various\ndefensive strategies. In this work, we focus on the development of a system\ncapable of detecting adversarial samples by exploiting statistical information\nfrom the training-set. Our detector computes several distorted replicas of the\ntest input, then collects the classifier's prediction vectors to build a\nmeaningful signature for the detection task. Then, the signature is projected\nonto the class-specific statistic vector to infer the input's nature. The\nclassification output of the original input is used to select the\nclass-statistic vector. We show that our method reliably detects malicious\ninputs, outperforming state-of-the-art approaches in various settings, while\nbeing complementary to other defensive solutions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 14:26:07 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Cennamo", "Alessandro", ""], ["Freeman", "Ido", ""], ["Kummert", "Anton", ""]]}, {"id": "1908.09710", "submitter": "Ehsan Hajiramezanali", "authors": "Ehsan Hajiramezanali, Arman Hasanzadeh, Nick Duffield, Krishna R\n  Narayanan, Mingyuan Zhou, Xiaoning Qian", "title": "Variational Graph Recurrent Neural Networks", "comments": "Accepted to Neural Information Processing Systems (NeurIPS2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning over graph structured data has been mostly studied in\nstatic graph settings while efforts for modeling dynamic graphs are still\nscant. In this paper, we develop a novel hierarchical variational model that\nintroduces additional latent random variables to jointly model the hidden\nstates of a graph recurrent neural network (GRNN) to capture both topology and\nnode attribute changes in dynamic graphs. We argue that the use of high-level\nlatent random variables in this variational GRNN (VGRNN) can better capture\npotential variability observed in dynamic graphs as well as the uncertainty of\nnode latent representation. With semi-implicit variational inference developed\nfor this new VGRNN architecture (SI-VGRNN), we show that flexible non-Gaussian\nlatent representations can further help dynamic graph analytic tasks. Our\nexperiments with multiple real-world dynamic graph datasets demonstrate that\nSI-VGRNN and VGRNN consistently outperform the existing baseline and\nstate-of-the-art methods by a significant margin in dynamic link prediction.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 14:44:47 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 19:46:08 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 03:03:40 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Hajiramezanali", "Ehsan", ""], ["Hasanzadeh", "Arman", ""], ["Duffield", "Nick", ""], ["Narayanan", "Krishna R", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1908.09712", "submitter": "Louis Falissard", "authors": "Louis Falissard, Claire Morgand, Sylvie Roussel, Claire Imbaud, Walid\n  Ghosn, Karim Bounebache, Gr\\'egoire Rey", "title": "A deep artificial neural network based model for underlying cause of\n  death prediction from death certificates", "comments": "25 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Underlying cause of death coding from death certificates is a process that is\nnowadays undertaken mostly by humans with a potential assistance from expert\nsystems such as the Iris software. It is as a consequence an expensive process\nthat can in addition suffer from geospatial discrepancies, thus severely\nimpairing the comparability of death statistics at the international level. The\nrecent advances in artificial intelligence, specifically the raise of deep\nlearning methods, has enabled computers to make efficient decisions on a number\nof complex problem that were typically considered as out of reach without human\nassistance. They however require a considerable amount of data to learn from,\nwhich is typically their main limiting factor. However, the C\\'epiDc stores an\nexhaustive database of death certificate at the French national scale,\namounting to several millions training example available for the machine\nlearning practitioner. This article presents a deep learning based tool for\nautomated coding of the underlying cause of death from the data contained in\ndeath certificates with 97.8% accuracy, a substantial achievement compared to\nthe Iris software and its 75% accuracy assessed on the same test examples. Such\nan improvement opens a whole field of new applications, from nosologist-level\nbatch automated coding to international and temporal harmonization of cause of\ndeath statistics.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 14:46:36 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Falissard", "Louis", ""], ["Morgand", "Claire", ""], ["Roussel", "Sylvie", ""], ["Imbaud", "Claire", ""], ["Ghosn", "Walid", ""], ["Bounebache", "Karim", ""], ["Rey", "Gr\u00e9goire", ""]]}, {"id": "1908.09720", "submitter": "Marcin Pietron", "authors": "Anna Aniol and Marcin Pietron", "title": "Ensemble approach for natural language question answering problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine comprehension, answering a question depending on a given context\nparagraph is a typical task of Natural Language Understanding. It requires to\nmodel complex dependencies existing between the question and the context\nparagraph. There are many neural network models attempting to solve the problem\nof question answering. The best models have been selected, studied and compared\nwith each other. All the selected models are based on the neural attention\nmechanism concept. Additionally, studies on a SQUAD dataset were performed. The\nsubsets of queries were extracted and then each model was analyzed how it deals\nwith specific group of queries. Based on these three model ensemble model was\ncreated and tested on SQUAD dataset. It outperforms the best Mnemonic Reader\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:01:24 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 10:14:45 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Aniol", "Anna", ""], ["Pietron", "Marcin", ""]]}, {"id": "1908.09736", "submitter": "Yicheng Cheng", "authors": "Yicheng Cheng, Bartek Rajwa, Murat Dundar", "title": "Bayesian Nonparametrics for Non-exhaustive Learning", "comments": "Published in BNP NIPS workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-exhaustive learning (NEL) is an emerging machine-learning paradigm\ndesigned to confront the challenge of non-stationary environments characterized\nby anon-exhaustive training sets lacking full information about the available\nclasses.Unlike traditional supervised learning that relies on fixed models, NEL\nutilizes self-adjusting machine learning to better accommodate the\nnon-stationary nature of the real-world problem, which is at the root of many\nrecently discovered limitations of deep learning. Some of these hurdles led to\na surge of interest in several research areas relevant to NEL such as open set\nclassification or zero-shot learning. The presented study which has been\nmotivated by two important applications proposes a NEL algorithm built on a\nhighly flexible, doubly non-parametric Bayesian Gaussian mixture model that can\ngrow arbitrarily large in terms of the number of classes and their components.\nWe report several experiments that demonstrate the promising performance of the\nintroduced model for NEL.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:31:06 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Cheng", "Yicheng", ""], ["Rajwa", "Bartek", ""], ["Dundar", "Murat", ""]]}, {"id": "1908.09738", "submitter": "Ernest Pusateri", "authors": "Ernest Pusateri, Christophe Van Gysel, Rami Botros, Sameer Badaskar,\n  Mirko Hannemann, Youssef Oualil, Ilya Oparin", "title": "Connecting and Comparing Language Model Interpolation Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we uncover a theoretical connection between two language model\ninterpolation techniques, count merging and Bayesian interpolation. We compare\nthese techniques as well as linear interpolation in three scenarios with\nabundant training data per component model. Consistent with prior work, we show\nthat both count merging and Bayesian interpolation outperform linear\ninterpolation. We include the first (to our knowledge) published comparison of\ncount merging and Bayesian interpolation, showing that the two techniques\nperform similarly. Finally, we argue that other considerations will make\nBayesian interpolation the preferred approach in most circumstances.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:32:44 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Pusateri", "Ernest", ""], ["Van Gysel", "Christophe", ""], ["Botros", "Rami", ""], ["Badaskar", "Sameer", ""], ["Hannemann", "Mirko", ""], ["Oualil", "Youssef", ""], ["Oparin", "Ilya", ""]]}, {"id": "1908.09744", "submitter": "Victor Gallego", "authors": "Victor Gallego and David Rios Insua", "title": "Variationally Inferred Sampling Through a Refined Bound for\n  Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework to boost the efficiency of Bayesian inference in probabilistic\nprograms is introduced by embedding a sampler inside a variational posterior\napproximation. We call it the refined variational approximation. Its strength\nlies both in ease of implementation and automatically tuning of the sampler\nparameters to speed up mixing time using automatic differentiation. Several\nstrategies to approximate \\emph{evidence lower bound} (ELBO) computation are\nintroduced.\n  Experimental evidence of its efficient performance is shown solving an\ninfluence diagram in a high-dimensional space using a conditional variational\nautoencoder (cVAE) as a deep Bayes classifier; an unconditional VAE on density\nestimation tasks; and state-space models for time-series data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:38:30 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 13:47:08 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2019 14:07:28 GMT"}, {"version": "v4", "created": "Sat, 22 Feb 2020 13:26:21 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gallego", "Victor", ""], ["Insua", "David Rios", ""]]}, {"id": "1908.09747", "submitter": "Shiv Ram Dubey", "authors": "Yash Srivastava and Vaishnav Murali and Shiv Ram Dubey", "title": "Hard-Mining Loss based Convolutional Neural Network for Face Recognition", "comments": "Accepted in Fifth IAPR International Conference on Computer Vision\n  and Image Processing (CVIP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face Recognition is one of the prominent problems in the computer vision\ndomain. Witnessing advances in deep learning, significant work has been\nobserved in face recognition, which touched upon various parts of the\nrecognition framework like Convolutional Neural Network (CNN), Layers, Loss\nfunctions, etc. Various loss functions such as Cross-Entropy, Angular-Softmax\nand ArcFace have been introduced to learn the weights of network for face\nrecognition. However, these loss functions do not give high priority to the\nhard samples as compared to the easy samples. Moreover, their learning process\nis biased due to a number of easy examples compared to hard examples. In this\npaper, we address this issue by considering hard examples with more priority.\nIn order to do so, We propose a Hard-Mining loss by increasing the loss for\nharder examples and decreasing the loss for easy examples. The proposed concept\nis generic and can be used with any existing loss function. We test the\nHard-Mining loss with different losses such as Cross-Entropy, Angular-Softmax\nand ArcFace. The proposed Hard-Mining loss is tested over widely used Labeled\nFaces in the Wild (LFW) and YouTube Faces (YTF) datasets. The training is\nperformed over CASIA-WebFace and MS-Celeb-1M datasets. We use the residual\nnetwork (i.e., ResNet18) for the experimental analysis. The experimental\nresults suggest that the performance of existing loss functions is boosted when\nused in the framework of the proposed Hard-Mining loss.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 06:55:45 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 00:49:00 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Srivastava", "Yash", ""], ["Murali", "Vaishnav", ""], ["Dubey", "Shiv Ram", ""]]}, {"id": "1908.09756", "submitter": "Ting Chen", "authors": "Ting Chen and Lala Li and Yizhou Sun", "title": "Differentiable Product Quantization for End-to-End Embedding Compression", "comments": "ICML'2020. Code at\n  https://github.com/chentingpc/dpq_embedding_compression", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding layers are commonly used to map discrete symbols into continuous\nembedding vectors that reflect their semantic meanings. Despite their\neffectiveness, the number of parameters in an embedding layer increases\nlinearly with the number of symbols and poses a critical challenge on memory\nand storage constraints. In this work, we propose a generic and end-to-end\nlearnable compression framework termed differentiable product quantization\n(DPQ). We present two instantiations of DPQ that leverage different\napproximation techniques to enable differentiability in end-to-end learning.\nOur method can readily serve as a drop-in alternative for any existing\nembedding layer. Empirically, DPQ offers significant compression ratios\n(14-238$\\times$) at negligible or no performance cost on 10 datasets across\nthree different language tasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:56:10 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 03:23:48 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 23:36:28 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Chen", "Ting", ""], ["Li", "Lala", ""], ["Sun", "Yizhou", ""]]}, {"id": "1908.09772", "submitter": "Xinjie Lan", "authors": "Xinjie Lan, Kenneth E. Barner", "title": "A Probabilistic Representation of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a novel probabilistic representation of deep\nlearning, which provides an explicit explanation for the Deep Neural Networks\n(DNNs) in three aspects: (i) neurons define the energy of a Gibbs distribution;\n(ii) the hidden layers of DNNs formulate Gibbs distributions; and (iii) the\nwhole architecture of DNNs can be interpreted as a Bayesian neural network.\nBased on the proposed probabilistic representation, we investigate two\nfundamental properties of deep learning: hierarchy and generalization. First,\nwe explicitly formulate the hierarchy property from the Bayesian perspective,\nnamely that some hidden layers formulate a prior distribution and the remaining\nlayers formulate a likelihood distribution. Second, we demonstrate that DNNs\nhave an explicit regularization by learning a prior distribution and the\nlearning algorithm is one reason for decreasing the generalization ability of\nDNNs. Moreover, we clarify two empirical phenomena of DNNs that cannot be\nexplained by traditional theories of generalization. Simulation results\nvalidate the proposed probabilistic representation and the insights into these\nproperties of deep learning based on a synthetic dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:18:22 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Lan", "Xinjie", ""], ["Barner", "Kenneth E.", ""]]}, {"id": "1908.09775", "submitter": "Dedimuni De Silva", "authors": "D.D.N. De Silva, H.W.M.K. Vithanage, K.S.D. Fernando, I.T.S.\n  Piyatilake", "title": "Multi-Path Learnable Wavelet Neural Network for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the remarkable success of deep learning in pattern recognition, deep\nnetwork models face the problem of training a large number of parameters. In\nthis paper, we propose and evaluate a novel multi-path wavelet neural network\narchitecture for image classification with far less number of trainable\nparameters. The model architecture consists of a multi-path layout with several\nlevels of wavelet decompositions performed in parallel followed by fully\nconnected layers. These decomposition operations comprise wavelet neurons with\nlearnable parameters, which are updated during the training phase using the\nback-propagation algorithm. We evaluate the performance of the introduced\nnetwork using common image datasets without data augmentation except for SVHN\nand compare the results with influential deep learning models. Our findings\nsupport the possibility of reducing the number of parameters significantly in\ndeep neural networks without compromising its accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:21:56 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["De Silva", "D. D. N.", ""], ["Vithanage", "H. W. M. K.", ""], ["Fernando", "K. S. D.", ""], ["Piyatilake", "I. T. S.", ""]]}, {"id": "1908.09788", "submitter": "Farid Ghareh Mohammadi", "authors": "Farid Ghareh Mohammadi, M. Hadi Amini, and Hamid R. Arabnia", "title": "An Introduction to Advanced Machine Learning : Meta Learning Algorithms,\n  Applications and Promises", "comments": "17 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1902.08438 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In [1, 2], we have explored the theoretical aspects of feature extraction\noptimization processes for solving largescale problems and overcoming machine\nlearning limitations. Majority of optimization algorithms that have been\nintroduced in [1, 2] guarantee the optimal performance of supervised learning,\ngiven offline and discrete data, to deal with curse of dimensionality (CoD)\nproblem. These algorithms, however, are not tailored for solving emerging\nlearning problems. One of the important issues caused by online data is lack of\nsufficient samples per class. Further, traditional machine learning algorithms\ncannot achieve accurate training based on limited distributed data, as data has\nproliferated and dispersed significantly. Machine learning employs a strict\nmodel or embedded engine to train and predict which still fails to learn unseen\nclasses and sufficiently use online data. In this chapter, we introduce these\nchallenges elaborately. We further investigate Meta-Learning (MTL) algorithm,\nand their application and promises to solve the emerging problems by answering\nhow autonomous agents can learn to learn?.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:42:33 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Mohammadi", "Farid Ghareh", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "1908.09791", "submitter": "Han Cai", "authors": "Han Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang, Song Han", "title": "Once-for-All: Train One Network and Specialize it for Efficient\n  Deployment", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the challenging problem of efficient inference across many devices\nand resource constraints, especially on edge devices. Conventional approaches\neither manually design or use neural architecture search (NAS) to find a\nspecialized neural network and train it from scratch for each case, which is\ncomputationally prohibitive (causing $CO_2$ emission as much as 5 cars'\nlifetime) thus unscalable. In this work, we propose to train a once-for-all\n(OFA) network that supports diverse architectural settings by decoupling\ntraining and search, to reduce the cost. We can quickly get a specialized\nsub-network by selecting from the OFA network without additional training. To\nefficiently train OFA networks, we also propose a novel progressive shrinking\nalgorithm, a generalized pruning method that reduces the model size across many\nmore dimensions than pruning (depth, width, kernel size, and resolution). It\ncan obtain a surprisingly large number of sub-networks ($> 10^{19}$) that can\nfit different hardware platforms and latency constraints while maintaining the\nsame level of accuracy as training independently. On diverse edge devices, OFA\nconsistently outperforms state-of-the-art (SOTA) NAS methods (up to 4.0%\nImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x\nfaster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency)\nwhile reducing many orders of magnitude GPU hours and $CO_2$ emission. In\nparticular, OFA achieves a new SOTA 80.0% ImageNet top-1 accuracy under the\nmobile setting ($<$600M MACs). OFA is the winning solution for the 3rd Low\nPower Computer Vision Challenge (LPCVC), DSP classification track and the 4th\nLPCVC, both classification track and detection track. Code and 50 pre-trained\nmodels (for many devices & many latency constraints) are released at\nhttps://github.com/mit-han-lab/once-for-all.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:46:23 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 20:26:58 GMT"}, {"version": "v3", "created": "Sun, 8 Mar 2020 18:18:22 GMT"}, {"version": "v4", "created": "Sun, 26 Apr 2020 23:02:50 GMT"}, {"version": "v5", "created": "Wed, 29 Apr 2020 20:49:05 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Cai", "Han", ""], ["Gan", "Chuang", ""], ["Wang", "Tianzhe", ""], ["Zhang", "Zhekai", ""], ["Han", "Song", ""]]}, {"id": "1908.09822", "submitter": "Zhiding Yu", "authors": "Yang Zou, Zhiding Yu, Xiaofeng Liu, B. V. K. Vijaya Kumar, Jinsong\n  Wang", "title": "Confidence Regularized Self-Training", "comments": "Accepted to ICCV 2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in domain adaptation show that deep self-training presents a\npowerful means for unsupervised domain adaptation. These methods often involve\nan iterative process of predicting on target domain and then taking the\nconfident predictions as pseudo-labels for retraining. However, since\npseudo-labels can be noisy, self-training can put overconfident label belief on\nwrong classes, leading to deviated solutions with propagated errors. To address\nthe problem, we propose a confidence regularized self-training (CRST)\nframework, formulated as regularized self-training. Our method treats\npseudo-labels as continuous latent variables jointly optimized via alternating\noptimization. We propose two types of confidence regularization: label\nregularization (LR) and model regularization (MR). CRST-LR generates soft\npseudo-labels while CRST-MR encourages the smoothness on network output.\nExtensive experiments on image classification and semantic segmentation show\nthat CRSTs outperform their non-regularized counterpart with state-of-the-art\nperformance. The code and models of this work are available at\nhttps://github.com/yzou2/CRST.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 17:56:13 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 05:26:12 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 10:57:38 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Zou", "Yang", ""], ["Yu", "Zhiding", ""], ["Liu", "Xiaofeng", ""], ["Kumar", "B. V. K. Vijaya", ""], ["Wang", "Jinsong", ""]]}, {"id": "1908.09853", "submitter": "Maximilian Pichler", "authors": "Maximilian Pichler, Virginie Boreux, Alexandra-Maria Klein, Matthias\n  Schleuning, Florian Hartig", "title": "Machine learning algorithms to infer trait-matching and predict species\n  interactions in ecological networks", "comments": "48 pages, 5 figures", "journal-ref": null, "doi": "10.1111/2041-210X.13329", "report-no": null, "categories": "q-bio.PE cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ecologists have long suspected that species are more likely to interact if\ntheir traits match in a particular way. For example, a pollination interaction\nmay be more likely if the proportions of a bee's tongue fit a plant's flower\nshape. Empirical estimates of the importance of trait-matching for determining\nspecies interactions, however, vary significantly among different types of\necological networks. Here, we show that ambiguity among empirical\ntrait-matching studies may have arisen at least in parts from using overly\nsimple statistical models. Using simulated and real data, we contrast\nconventional generalized linear models (GLM) with more flexible Machine\nLearning (ML) models (Random Forest, Boosted Regression Trees, Deep Neural\nNetworks, Convolutional Neural Networks, Support Vector Machines, naive Bayes,\nand k-Nearest-Neighbor), testing their ability to predict species interactions\nbased on traits, and infer trait combinations causally responsible for species\ninteractions. We find that the best ML models can successfully predict species\ninteractions in plant-pollinator networks, outperforming GLMs by a substantial\nmargin. Our results also demonstrate that ML models can better identify the\ncausally responsible trait-matching combinations than GLMs. In two case\nstudies, the best ML models successfully predicted species interactions in a\nglobal plant-pollinator database and inferred ecologically plausible\ntrait-matching rules for a plant-hummingbird network, without any prior\nassumptions. We conclude that flexible ML models offer many advantages over\ntraditional regression models for understanding interaction networks. We\nanticipate that these results extrapolate to other ecological network types.\nMore generally, our results highlight the potential of machine learning and\nartificial intelligence for inference in ecology, beyond standard tasks such as\nimage or pattern recognition.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 18:00:09 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 18:58:36 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Pichler", "Maximilian", ""], ["Boreux", "Virginie", ""], ["Klein", "Alexandra-Maria", ""], ["Schleuning", "Matthias", ""], ["Hartig", "Florian", ""]]}, {"id": "1908.09873", "submitter": "Marc G\\'orriz Blanch", "authors": "Marc G\\'orriz, Marta Mrak, Alan F. Smeaton, Noel E. O'Connor", "title": "End-to-End Conditional GAN-based Architectures for Image Colourisation", "comments": "IEEE 21st International Workshop on Multimedia Signal Processing,\n  27-29 Sept 2019, Kuala Lumpur, Malaysia", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work recent advances in conditional adversarial networks are\ninvestigated to develop an end-to-end architecture based on Convolutional\nNeural Networks (CNNs) to directly map realistic colours to an input greyscale\nimage. Observing that existing colourisation methods sometimes exhibit a lack\nof colourfulness, this paper proposes a method to improve colourisation\nresults. In particular, the method uses Generative Adversarial Neural Networks\n(GANs) and focuses on improvement of training stability to enable better\ngeneralisation in large multi-class image datasets. Additionally, the\nintegration of instance and batch normalisation layers in both generator and\ndiscriminator is introduced to the popular U-Net architecture, boosting the\nnetwork capabilities to generalise the style changes of the content. The method\nhas been tested using the ILSVRC 2012 dataset, achieving improved automatic\ncolourisation results compared to other methods based on GANs.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 18:29:22 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 12:05:53 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["G\u00f3rriz", "Marc", ""], ["Mrak", "Marta", ""], ["Smeaton", "Alan F.", ""], ["O'Connor", "Noel E.", ""]]}, {"id": "1908.09874", "submitter": "Vitor Baisi Hadad", "authors": "Jonathan Johannemann, Vitor Hadad, Susan Athey, Stefan Wager", "title": "Sufficient Representations for Categorical Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many learning algorithms require categorical data to be transformed into real\nvectors before it can be used as input. Often, categorical variables are\nencoded as one-hot (or dummy) vectors. However, this mode of representation can\nbe wasteful since it adds many low-signal regressors, especially when the\nnumber of unique categories is large. In this paper, we investigate simple\nalternative solutions for universally consistent estimators that rely on\nlower-dimensional real-valued representations of categorical variables that are\n\"sufficient\" in the sense that no predictive information is lost. We then\ncompare preexisting and proposed methods on simulated and observational\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 18:41:29 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 20:28:32 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Johannemann", "Jonathan", ""], ["Hadad", "Vitor", ""], ["Athey", "Susan", ""], ["Wager", "Stefan", ""]]}, {"id": "1908.09876", "submitter": "Jacson Barbosa", "authors": "Jacson Rodrigues Barbosa, Ricardo Marcondes Marcacini, Ricardo Britto,\n  Frederico Soares, Solange Rezende, Auri M. R. Vincenzi, Marcio E. Delamaro", "title": "BULNER: BUg Localization with word embeddings and NEtwork Regularization", "comments": "VII Workshop on Software Visualization, Evolution and Maintenance\n  (VEM '19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bug localization (BL) from the bug report is the strategic activity of the\nsoftware maintaining process. Because BL is a costly and tedious activity, BL\ntechniques information retrieval-based and machine learning-based could aid\nsoftware engineers. We propose a method for BUg Localization with word\nembeddings and Network Regularization (BULNER). The preliminary results suggest\nthat BULNER has better performance than two state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 18:52:30 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Barbosa", "Jacson Rodrigues", ""], ["Marcacini", "Ricardo Marcondes", ""], ["Britto", "Ricardo", ""], ["Soares", "Frederico", ""], ["Rezende", "Solange", ""], ["Vincenzi", "Auri M. R.", ""], ["Delamaro", "Marcio E.", ""]]}, {"id": "1908.09880", "submitter": "Hrushikesh Mhaskar", "authors": "Hrushikesh N. Mhaskar", "title": "Dimension independent bounds for general shallow networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proves an abstract theorem addressing in a unified manner two\nimportant problems in function approximation: avoiding curse of dimensionality\nand estimating the degree of approximation for out-of-sample extension in\nmanifold learning. We consider an abstract (shallow) network that includes, for\nexample, neural networks, radial basis function networks, and kernels on data\ndefined manifolds used for function approximation in various settings. A deep\nnetwork is obtained by a composition of the shallow networks according to a\ndirected acyclic graph, representing the architecture of the deep network.\n  In this paper, we prove dimension independent bounds for approximation by\nshallow networks in the very general setting of what we have called\n$G$-networks on a compact metric measure space, where the notion of dimension\nis defined in terms of the cardinality of maximal distinguishable sets,\ngeneralizing the notion of dimension of a cube or a manifold. Our techniques\ngive bounds that improve without saturation with the smoothness of the kernel\ninvolved in an integral representation of the target function. In the context\nof manifold learning, our bounds provide estimates on the degree of\napproximation for an out-of-sample extension of the target function to the\nambient space.\n  One consequence of our theorem is that without the requirement of robust\nparameter selection, deep networks using a non-smooth activation function such\nas the ReLU, do not provide any significant advantage over shallow networks in\nterms of the degree of approximation alone.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 19:03:19 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 17:56:05 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Mhaskar", "Hrushikesh N.", ""]]}, {"id": "1908.09888", "submitter": "Jing Ma", "authors": "Jing Ma, Qiuchen Zhang, Jian Lou, Joyce C. Ho, Li Xiong, Xiaoqian\n  Jiang", "title": "Privacy-Preserving Tensor Factorization for Collaborative Health Data\n  Analysis", "comments": null, "journal-ref": null, "doi": "10.1145/3357384.3357878", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor factorization has been demonstrated as an efficient approach for\ncomputational phenotyping, where massive electronic health records (EHRs) are\nconverted to concise and meaningful clinical concepts. While distributing the\ntensor factorization tasks to local sites can avoid direct data sharing, it\nstill requires the exchange of intermediary results which could reveal\nsensitive patient information. Therefore, the challenge is how to jointly\ndecompose the tensor under rigorous and principled privacy constraints, while\nstill support the model's interpretability. We propose DPFact, a\nprivacy-preserving collaborative tensor factorization method for computational\nphenotyping using EHR. It embeds advanced privacy-preserving mechanisms with\ncollaborative learning. Hospitals can keep their EHR database private but also\ncollaboratively learn meaningful clinical concepts by sharing differentially\nprivate intermediary results. Moreover, DPFact solves the heterogeneous patient\npopulation using a structured sparsity term. In our framework, each hospital\ndecomposes its local tensors, and sends the updated intermediary results with\noutput perturbation every several iterations to a semi-trusted server which\ngenerates the phenotypes. The evaluation on both real-world and synthetic\ndatasets demonstrated that under strict privacy constraints, our method is more\naccurate and communication-efficient than state-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 19:31:54 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 15:50:54 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Ma", "Jing", ""], ["Zhang", "Qiuchen", ""], ["Lou", "Jian", ""], ["Ho", "Joyce C.", ""], ["Xiong", "Li", ""], ["Jiang", "Xiaoqian", ""]]}, {"id": "1908.09890", "submitter": "Shikib Mehri", "authors": "Shikib Mehri and Maxine Eskenazi", "title": "Multi-Granularity Representations of Dialog", "comments": "Accepted as a long paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models of dialog rely on generalized latent representations of\nlanguage. This paper introduces a novel training procedure which explicitly\nlearns multiple representations of language at several levels of granularity.\nThe multi-granularity training algorithm modifies the mechanism by which\nnegative candidate responses are sampled in order to control the granularity of\nlearned latent representations. Strong performance gains are observed on the\nnext utterance retrieval task using both the MultiWOZ dataset and the Ubuntu\ndialog corpus. Analysis significantly demonstrates that multiple granularities\nof representation are being learned, and that multi-granularity training\nfacilitates better transfer to downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 19:41:21 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Mehri", "Shikib", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1908.09891", "submitter": "Alexandre Cunha", "authors": "Fidel A. Guerrero-Pe\\~na and Pedro D. Marrero Fernandez and Tsang Ing\n  Ren and Alexandre Cunha", "title": "A Weakly Supervised Method for Instance Segmentation of Biological Cells", "comments": "Accepted at MICCAI Worshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a weakly supervised deep learning method to perform instance\nsegmentation of cells present in microscopy images. Annotation of biomedical\nimages in the lab can be scarce, incomplete, and inaccurate. This is of concern\nwhen supervised learning is used for image analysis as the discriminative power\nof a learning model might be compromised in these situations. To overcome the\ncurse of poor labeling, our method focuses on three aspects to improve\nlearning: i) we propose a loss function operating in three classes to\nfacilitate separating adjacent cells and to drive the optimizer to properly\nclassify underrepresented regions; ii) a contour-aware weight map model is\nintroduced to strengthen contour detection while improving the network\ngeneralization capacity; and iii) we augment data by carefully modulating local\nintensities on edges shared by adjoining regions and to account for possibly\nweak signals on these edges. Generated probability maps are segmented using\ndifferent methods, with the watershed based one generally offering the best\nsolutions, specially in those regions where the prevalence of a single class is\nnot clear. The combination of these contributions allows segmenting individual\ncells on challenging images. We demonstrate our methods in sparse and crowded\ncell images, showing improvements in the learning process for a fixed network\narchitecture.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 19:42:14 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Guerrero-Pe\u00f1a", "Fidel A.", ""], ["Fernandez", "Pedro D. Marrero", ""], ["Ren", "Tsang Ing", ""], ["Cunha", "Alexandre", ""]]}, {"id": "1908.09899", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier, Aman Singh, Gaston Ormazabal, Radu State, Henning\n  Schulzrinne", "title": "SynGAN: Towards Generating Synthetic Network Attacks using GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid digital transformation without security considerations has resulted\nin the rise of global-scale cyberattacks. The first line of defense against\nthese attacks are Network Intrusion Detection Systems (NIDS). Once deployed,\nhowever, these systems work as blackboxes with a high rate of false positives\nwith no measurable effectiveness. There is a need to continuously test and\nimprove these systems by emulating real-world network attack mutations. We\npresent SynGAN, a framework that generates adversarial network attacks using\nthe Generative Adversial Networks (GAN). SynGAN generates malicious packet flow\nmutations using real attack traffic, which can improve NIDS attack detection\nrates. As a first step, we compare two public datasets, NSL-KDD and CICIDS2017,\nfor generating synthetic Distributed Denial of Service (DDoS) network attacks.\nWe evaluate the attack quality (real vs. synthetic) using a gradient boosting\nclassifier.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 20:06:31 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Charlier", "Jeremy", ""], ["Singh", "Aman", ""], ["Ormazabal", "Gaston", ""], ["State", "Radu", ""], ["Schulzrinne", "Henning", ""]]}, {"id": "1908.09915", "submitter": "Sohail Bahmani", "authors": "Sohail Bahmani and Justin Romberg", "title": "Convex Programming for Estimation in Nonlinear Recurrent Models", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formulation for nonlinear recurrent models that includes simple\nparametric models of recurrent neural networks as a special case. The proposed\nformulation leads to a natural estimator in the form of a convex program. We\nprovide a sample complexity for this estimator in the case of stable dynamics,\nwhere the nonlinear recursion has a certain contraction property, and under\ncertain regularity conditions on the input distribution. We evaluate the\nperformance of the estimator by simulation on synthetic data. These numerical\nexperiments also suggest the extent at which the imposed theoretical\nassumptions may be relaxed.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 20:50:26 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Bahmani", "Sohail", ""], ["Romberg", "Justin", ""]]}, {"id": "1908.09919", "submitter": "Erhan Sezerer", "authors": "Erhan Sezerer, Ozan Polatbilek, Selma Tekir", "title": "Gender Prediction from Tweets: Improving Neural Representations with\n  Hand-Crafted Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Author profiling is the characterization of an author through some key\nattributes such as gender, age, and language. In this paper, a RNN model with\nAttention (RNNwA) is proposed to predict the gender of a twitter user using\ntheir tweets. Both word level and tweet level attentions are utilized to learn\n'where to look'. This model\n(https://github.com/Darg-Iztech/gender-prediction-from-tweets) is improved by\nconcatenating LSA-reduced n-gram features with the learned neural\nrepresentation of a user. Both models are tested on three languages: English,\nSpanish, Arabic. The improved version of the proposed model (RNNwA + n-gram)\nachieves state-of-the-art performance on English and has competitive results on\nSpanish and Arabic.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 07:36:48 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 10:27:36 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Sezerer", "Erhan", ""], ["Polatbilek", "Ozan", ""], ["Tekir", "Selma", ""]]}, {"id": "1908.09928", "submitter": "Mansi Ranjit Mane", "authors": "Mansi Ranjit Mane, Stephen Guo, Kannan Achan", "title": "Complementary-Similarity Learning using Quadruplet Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel learning framework to answer questions such as \"if a user\nis purchasing a shirt, what other items will (s)he need with the shirt?\" Our\nframework learns distributed representations for items from available textual\ndata, with the learned representations representing items in a latent space\nexpressing functional complementarity as well similarity. In particular, our\nframework places functionally similar items close together in the latent space,\nwhile also placing complementary items closer than non-complementary items, but\nfarther away than similar items. In this study, we introduce a new dataset of\nsimilar, complementary, and negative items derived from the Amazon co-purchase\ndataset. For evaluation purposes, we focus our approach on clothing and fashion\nverticals. As per our knowledge, this is the first attempt to learn similar and\ncomplementary relationships simultaneously through just textual title metadata.\nOur framework is applicable across a broad set of items in the product catalog\nand can generate quality complementary item recommendations at scale.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 21:29:19 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 21:42:27 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Mane", "Mansi Ranjit", ""], ["Guo", "Stephen", ""], ["Achan", "Kannan", ""]]}, {"id": "1908.09931", "submitter": "Xiaojie Guo", "authors": "Xiaojie Guo, Amir Alipour-Fanid, Lingfei Wu, Hemant Purohit, Xiang\n  Chen, Kai Zeng, Liang Zhao", "title": "Multi-stage Deep Classifier Cascades for Open World Recognition", "comments": "This paper has been accepted by CIKM 2019", "journal-ref": "In Proceedings of the 28th ACM International Conference on\n  Information and Knowledge Management (pp. 179-188), 2019", "doi": "10.1145/3357384.3357981", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, object recognition studies are mostly conducted in a closed lab\nsetting with classes in test phase typically in training phase. However,\nreal-world problem is far more challenging because: i) new classes unseen in\nthe training phase can appear when predicting; ii) discriminative features need\nto evolve when new classes emerge in real time; and iii) instances in new\nclasses may not follow the \"independent and identically distributed\" (iid)\nassumption. Most existing work only aims to detect the unknown classes and is\nincapable of continuing to learn newer classes. Although a few methods consider\nboth detecting and including new classes, all are based on the predefined\nhandcrafted features that cannot evolve and are out-of-date for characterizing\nemerging classes. Thus, to address the above challenges, we propose a novel\ngeneric end-to-end framework consisting of a dynamic cascade of classifiers\nthat incrementally learn their dynamic and inherent features. The proposed\nmethod injects dynamic elements into the system by detecting instances from\nunknown classes, while at the same time incrementally updating the model to\ninclude the new classes. The resulting cascade tree grows by adding a new leaf\nnode classifier once a new class is detected, and the discriminative features\nare updated via an end-to-end learning strategy. Experiments on two real-world\ndatasets demonstrate that our proposed method outperforms existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 21:31:20 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Guo", "Xiaojie", ""], ["Alipour-Fanid", "Amir", ""], ["Wu", "Lingfei", ""], ["Purohit", "Hemant", ""], ["Chen", "Xiang", ""], ["Zeng", "Kai", ""], ["Zhao", "Liang", ""]]}, {"id": "1908.09936", "submitter": "Adrian De Wynter", "authors": "Adrian de Wynter and Lambert Mathias", "title": "Leveraging External Knowledge for Out-Of-Vocabulary Entity Labeling", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with previously unseen slots is a challenging problem in a real-world\nmulti-domain dialogue state tracking task. Other approaches rely on predefined\nmappings to generate candidate slot keys, as well as their associated values.\nThis, however, may fail when the key, the value, or both, are not seen during\ntraining. To address this problem we introduce a neural network that leverages\nexternal knowledge bases (KBs) to better classify out-of-vocabulary slot keys\nand values. This network projects the slot into an attribute space derived from\nthe KB, and, by leveraging similarities in this space, we propose candidate\nslot keys and values to the dialogue state tracker. We provide extensive\nexperiments that demonstrate that our stratagem can improve upon a previous\napproach, which relies on predefined candidate mappings. In particular, we\nevaluate this approach by training a state-of-the-art model with candidates\ngenerated from our network, and obtained relative increases of 57.7% and 82.7%\nin F1 score and accuracy, respectively, for the aforementioned model, when\ncompared to the current candidate generation strategy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:08:55 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["de Wynter", "Adrian", ""], ["Mathias", "Lambert", ""]]}, {"id": "1908.09941", "submitter": "Yan Yan", "authors": "Yan Yan, Yi Xu, Lijun Zhang, Xiaoyu Wang, Tianbao Yang", "title": "Stochastic Optimization for Non-convex Inf-Projection Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a family of non-convex and possibly non-smooth\ninf-projection minimization problems, where the target objective function is\nequal to minimization of a joint function over another variable. This problem\ninclude difference of convex (DC) functions and a family of bi-convex functions\nas special cases. We develop stochastic algorithms and establish their\nfirst-order convergence for finding a (nearly) stationary solution of the\ntarget non-convex function under different conditions of the component\nfunctions. To the best of our knowledge, this is the first work that\ncomprehensively studies stochastic optimization of non-convex inf-projection\nminimization problems with provable convergence guarantee. Our algorithms\nenable efficient stochastic optimization of a family of non-decomposable DC\nfunctions and a family of bi-convex functions. To demonstrate the power of the\nproposed algorithms we consider an important application in variance-based\nregularization. Experiments verify the effectiveness of our inf-projection\nbased formulation and the proposed stochastic algorithm in comparison with\nprevious stochastic algorithms based on the min-max formulation for achieving\nthe same effect.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:28:53 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 20:16:48 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Yan", "Yan", ""], ["Xu", "Yi", ""], ["Zhang", "Lijun", ""], ["Wang", "Xiaoyu", ""], ["Yang", "Tianbao", ""]]}, {"id": "1908.09942", "submitter": "Adrian De Wynter", "authors": "Adrian de Wynter", "title": "On the Bounds of Function Approximations", "comments": "Accepted as a full paper at ICANN 2019. The final, authenticated\n  publication will be available at https://doi.org/10.1007/978-3-030-30487-4_32", "journal-ref": "In: Tetko, I. V. et al. (eds.) ICANN 2019. LNCS, vol 11727.\n  Springer, Heidelberg, pp. 401-417", "doi": "10.1007/978-3-030-30487-4_32", "report-no": null, "categories": "cs.LG cs.CC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within machine learning, the subfield of Neural Architecture Search (NAS) has\nrecently garnered research attention due to its ability to improve upon\nhuman-designed models. However, the computational requirements for finding an\nexact solution to this problem are often intractable, and the design of the\nsearch space still requires manual intervention. In this paper we attempt to\nestablish a formalized framework from which we can better understand the\ncomputational bounds of NAS in relation to its search space. For this, we first\nreformulate the function approximation problem in terms of sequences of\nfunctions, and we call it the Function Approximation (FA) problem; then we show\nthat it is computationally infeasible to devise a procedure that solves FA for\nall functions to zero error, regardless of the search space. We show also that\nsuch error will be minimal if a specific class of functions is present in the\nsearch space. Subsequently, we show that machine learning as a mathematical\nproblem is a solution strategy for FA, albeit not an effective one, and further\ndescribe a stronger version of this approach: the Approximate Architectural\nSearch Problem (a-ASP), which is the mathematical equivalent of NAS. We\nleverage the framework from this paper and results from the literature to\ndescribe the conditions under which a-ASP can potentially solve FA as well as\nan exhaustive search, but in polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:32:33 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["de Wynter", "Adrian", ""]]}, {"id": "1908.09943", "submitter": "Furkan K{\\i}nl{\\i}", "authors": "Furkan K{\\i}nl{\\i} and Bar{\\i}\\c{s} \\\"Ozcan and Furkan K{\\i}ra\\c{c}", "title": "Fashion Image Retrieval with Capsule Networks", "comments": "Accepted to the International Conference on Computer Vision, ICCV\n  2019, Workshop on Computer Vision for Fashion, Art and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we investigate in-shop clothing retrieval performance of\ndensely-connected Capsule Networks with dynamic routing. To achieve this, we\npropose Triplet-based design of Capsule Network architecture with two different\nfeature extraction methods. In our design, Stacked-convolutional (SC) and\nResidual-connected (RC) blocks are used to form the input of capsule layers.\nExperimental results show that both of our designs outperform all variants of\nthe baseline study, namely FashionNet, without relying on the landmark\ninformation. Moreover, when compared to the SOTA architectures on clothing\nretrieval, our proposed Triplet Capsule Networks achieve comparable recall\nrates only with half of parameters used in the SOTA architectures.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:33:14 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["K\u0131nl\u0131", "Furkan", ""], ["\u00d6zcan", "Bar\u0131\u015f", ""], ["K\u0131ra\u00e7", "Furkan", ""]]}, {"id": "1908.09946", "submitter": "Avgoustinos Vouros", "authors": "Avgoustinos Vouros (1), Stephen Langdell (2), Mike Croucher (2), Eleni\n  Vasilaki (1) ((1) Department of Computer Science, University of Sheffield,\n  (2) Numerical Algorithms Group (NAG))", "title": "An empirical comparison between stochastic and deterministic centroid\n  initialisation for K-Means variations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-Means is one of the most used algorithms for data clustering and the usual\nclustering method for benchmarking. Despite its wide application it is\nwell-known that it suffers from a series of disadvantages; it is only able to\nfind local minima and the positions of the initial clustering centres\n(centroids) can greatly affect the clustering solution. Over the years many\nK-Means variations and initialisation techniques have been proposed with\ndifferent degrees of complexity. In this study we focus on common K-Means\nvariations along with a range of deterministic and stochastic initialisation\ntechniques. We show that, on average, more sophisticated initialisation\ntechniques alleviate the need for complex clustering methods. Furthermore,\ndeterministic methods perform better than stochastic methods. However, there is\na trade-off: less sophisticated stochastic methods, executed multiple times,\ncan result in better clustering. Factoring in execution time, deterministic\nmethods can be competitive and result in a good clustering solution. These\nconclusions are obtained through extensive benchmarking using a range of\nsynthetic model generators and real-world data sets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:37:57 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 21:33:34 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 09:55:30 GMT"}, {"version": "v4", "created": "Wed, 9 Oct 2019 10:21:24 GMT"}, {"version": "v5", "created": "Thu, 16 Jul 2020 06:36:38 GMT"}, {"version": "v6", "created": "Sat, 27 Feb 2021 22:11:05 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Vouros", "Avgoustinos", ""], ["Langdell", "Stephen", ""], ["Croucher", "Mike", ""], ["Vasilaki", "Eleni", ""]]}, {"id": "1908.09948", "submitter": "Hossein Sadeghi Esfahani", "authors": "Hossein Sadeghi, Evgeny Andriyash, Walter Vinci, Lorenzo Buffoni,\n  Mohammad H. Amin", "title": "PixelVAE++: Improved PixelVAE with Discrete Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing powerful generative models for natural images is a challenging\ntask. PixelCNN models capture details and local information in images very well\nbut have limited receptive field. Variational autoencoders with a factorial\ndecoder can capture global information easily, but they often fail to\nreconstruct details faithfully. PixelVAE combines the best features of the two\nmodels and constructs a generative model that is able to learn local and global\nstructures. Here we introduce PixelVAE++, a VAE with three types of latent\nvariables and a PixelCNN++ for the decoder. We introduce a novel architecture\nthat reuses a part of the decoder as an encoder. We achieve the state of the\nart performance on binary data sets such as MNIST and Omniglot and achieve the\nstate of the art performance on CIFAR-10 among latent variable models while\nkeeping the latent variables informative.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:40:55 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Sadeghi", "Hossein", ""], ["Andriyash", "Evgeny", ""], ["Vinci", "Walter", ""], ["Buffoni", "Lorenzo", ""], ["Amin", "Mohammad H.", ""]]}, {"id": "1908.09961", "submitter": "Kien Do", "authors": "Kien Do and Truyen Tran", "title": "Theory and Evaluation Metrics for Learning Disentangled Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make two theoretical contributions to disentanglement learning by (a)\ndefining precise semantics of disentangled representations, and (b)\nestablishing robust metrics for evaluation. First, we characterize the concept\n\"disentangled representations\" used in supervised and unsupervised methods\nalong three dimensions-informativeness, separability and interpretability -\nwhich can be expressed and quantified explicitly using information-theoretic\nconstructs. This helps explain the behaviors of several well-known\ndisentanglement learning models. We then propose robust metrics for measuring\ninformativeness, separability and interpretability. Through a comprehensive\nsuite of experiments, we show that our metrics correctly characterize the\nrepresentations learned by different methods and are consistent with\nqualitative (visual) results. Thus, the metrics allow disentanglement learning\nmethods to be compared on a fair ground. We also empirically uncovered new\ninteresting properties of VAE-based methods and interpreted them with our\nformulation. These findings are promising and hopefully will encourage the\ndesign of more theoretically driven models for learning disentangled\nrepresentations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 23:55:11 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 21:08:15 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 22:59:04 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Do", "Kien", ""], ["Tran", "Truyen", ""]]}, {"id": "1908.09967", "submitter": "Timothy Coleman", "authors": "Tim Coleman, Kimberly Kaufeld, Mary Frances Dorn, Lucas Mentch", "title": "Locally Optimized Random Forests", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard supervised learning procedures are validated against a test set that\nis assumed to have come from the same distribution as the training data.\nHowever, in many problems, the test data may have come from a different\ndistribution. We consider the case of having many labeled observations from one\ndistribution, $P_1$, and making predictions at unlabeled points that come from\n$P_2$. We combine the high predictive accuracy of random forests (Breiman,\n2001) with an importance sampling scheme, where the splits and predictions of\nthe base-trees are done in a weighted manner, which we call Locally Optimized\nRandom Forests. These weights correspond to a non-parametric estimate of the\nlikelihood ratio between the training and test distributions. To estimate these\nratios with an unlabeled test set, we make the covariate shift assumption,\nwhere the differences in distribution are only a function of the training\ndistributions (Shimodaira, 2000.) This methodology is motivated by the problem\nof forecasting power outages during hurricanes. The extreme nature of the most\ndevastating hurricanes means that typical validation set ups will overly favor\nless extreme storms. Our method provides a data-driven means of adapting a\nmachine learning method to deal with extreme events.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 00:42:56 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Coleman", "Tim", ""], ["Kaufeld", "Kimberly", ""], ["Dorn", "Mary Frances", ""], ["Mentch", "Lucas", ""]]}, {"id": "1908.09970", "submitter": "Raef Bassily", "authors": "Raef Bassily, Vitaly Feldman, Kunal Talwar, Abhradeep Thakurta", "title": "Private Stochastic Convex Optimization with Optimal Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study differentially private (DP) algorithms for stochastic convex\noptimization (SCO). In this problem the goal is to approximately minimize the\npopulation loss given i.i.d. samples from a distribution over convex and\nLipschitz loss functions. A long line of existing work on private convex\noptimization focuses on the empirical loss and derives asymptotically tight\nbounds on the excess empirical loss. However a significant gap exists in the\nknown bounds for the population loss. We show that, up to logarithmic factors,\nthe optimal excess population loss for DP algorithms is equal to the larger of\nthe optimal non-private excess population loss, and the optimal excess\nempirical loss of DP algorithms. This implies that, contrary to intuition based\non private ERM, private SCO has asymptotically the same rate of $1/\\sqrt{n}$ as\nnon-private SCO in the parameter regime most common in practice. The best\nprevious result in this setting gives rate of $1/n^{1/4}$. Our approach builds\non existing differentially private algorithms and relies on the analysis of\nalgorithmic stability to ensure generalization.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 00:50:27 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Bassily", "Raef", ""], ["Feldman", "Vitaly", ""], ["Talwar", "Kunal", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "1908.09972", "submitter": "An Yan", "authors": "An Yan, Shuo Cheng, Wang-Cheng Kang, Mengting Wan, Julian McAuley", "title": "CosRec: 2D Convolutional Neural Networks for Sequential Recommendation", "comments": "To appear in CIKM-2019, code at https://github.com/zzxslp/CosRec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential patterns play an important role in building modern recommender\nsystems. To this end, several recommender systems have been built on top of\nMarkov Chains and Recurrent Models (among others). Although these sequential\nmodels have proven successful at a range of tasks, they still struggle to\nuncover complex relationships nested in user purchase histories. In this paper,\nwe argue that modeling pairwise relationships directly leads to an efficient\nrepresentation of sequential features and captures complex item correlations.\nSpecifically, we propose a 2D convolutional network for sequential\nrecommendation (CosRec). It encodes a sequence of items into a three-way\ntensor; learns local features using 2D convolutional filters; and aggregates\nhigh-order interactions in a feedforward manner. Quantitative results on two\npublic datasets show that our method outperforms both conventional methods and\nrecent sequence-based approaches, achieving state-of-the-art performance on\nvarious evaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 01:08:18 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Yan", "An", ""], ["Cheng", "Shuo", ""], ["Kang", "Wang-Cheng", ""], ["Wan", "Mengting", ""], ["McAuley", "Julian", ""]]}, {"id": "1908.09979", "submitter": "Huanrui Yang", "authors": "Huanrui Yang, Wei Wen, Hai Li", "title": "DeepHoyer: Learning Sparser Neural Network with Differentiable\n  Scale-Invariant Sparsity Measures", "comments": "To be appeared in ICLR 2020 (poster presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In seeking for sparse and efficient neural network models, many previous\nworks investigated on enforcing L1 or L0 regularizers to encourage weight\nsparsity during training. The L0 regularizer measures the parameter sparsity\ndirectly and is invariant to the scaling of parameter values, but it cannot\nprovide useful gradients, and therefore requires complex optimization\ntechniques. The L1 regularizer is almost everywhere differentiable and can be\neasily optimized with gradient descent. Yet it is not scale-invariant, causing\nthe same shrinking rate to all parameters, which is inefficient in increasing\nsparsity. Inspired by the Hoyer measure (the ratio between L1 and L2 norms)\nused in traditional compressed sensing problems, we present DeepHoyer, a set of\nsparsity-inducing regularizers that are both differentiable almost everywhere\nand scale-invariant. Our experiments show that enforcing DeepHoyer regularizers\ncan produce even sparser neural network models than previous works, under the\nsame accuracy level. We also show that DeepHoyer can be applied to both\nelement-wise and structural pruning.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 01:34:25 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 18:04:11 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yang", "Huanrui", ""], ["Wen", "Wei", ""], ["Li", "Hai", ""]]}, {"id": "1908.09980", "submitter": "Chang Liu", "authors": "Eddie S.J. Du, Chang Liu, David H. Wayne", "title": "Automated Fashion Size Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately predict the fit of fashion items and recommend the\ncorrect size is key to reducing merchandise returns in e-commerce. A critical\nprerequisite of fit prediction is size normalization, the mapping of product\nsizes across brands to a common space in which sizes can be compared. At\npresent, size normalization is usually a time-consuming manual process. We\npropose a method to automate size normalization through the use of salesdata.\nThe size mappings generated from our automated approaches are comparable to\nhuman-generated mappings.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 01:43:43 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Du", "Eddie S. J.", ""], ["Liu", "Chang", ""], ["Wayne", "David H.", ""]]}, {"id": "1908.09993", "submitter": "Min Xu", "authors": "Ziqian Luo, Xiangrui Zeng, Zhipeng Bao, Min Xu", "title": "Deep Learning-Based Strategy for Macromolecules Classification with\n  Imbalanced Data from Cellular Electron Cryotomography", "comments": "13 pages. arXiv admin note: text overlap with arXiv:1710.09412,\n  arXiv:1710.05381, arXiv:1708.02002 by other authors", "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN)", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning model trained by imbalanced data may not work satisfactorily\nsince it could be determined by major classes and thus may ignore the classes\nwith small amount of data. In this paper, we apply deep learning based\nimbalanced data classification for the first time to cellular macromolecular\ncomplexes captured by Cryo-electron tomography (Cryo-ET). We adopt a range of\nstrategies to cope with imbalanced data, including data sampling, bagging,\nboosting, Genetic Programming based method and. Particularly, inspired from\nInception 3D network, we propose a multi-path CNN model combining focal loss\nand mixup on the Cryo-ET dataset to expand the dataset, where each path had its\nbest performance corresponding to each type of data and let the network learn\nthe combinations of the paths to improve the classification performance. In\naddition, extensive experiments have been conducted to show our proposed method\nis flexible enough to cope with different number of classes by adjusting the\nnumber of paths in our multi-path model. To our knowledge, this work is the\nfirst application of deep learning methods of dealing with imbalanced data to\nthe internal tissue classification of cell macromolecular complexes, which\nopened up a new path for cell classification in the field of computational\nbiology.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 02:37:42 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Luo", "Ziqian", ""], ["Zeng", "Xiangrui", ""], ["Bao", "Zhipeng", ""], ["Xu", "Min", ""]]}, {"id": "1908.10001", "submitter": "Bai Li", "authors": "Bai Li, Nanyi Jiang, Joey Sham, Henry Shi, Hussein Fazal", "title": "Real-world Conversational AI for Hotel Bookings", "comments": "Accepted to IEEE AI4I 2019 (International Conference on Artificial\n  Intelligence for Industries)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a real-world conversational AI system to search for\nand book hotels through text messaging. Our architecture consists of a\nframe-based dialogue management system, which calls machine learning models for\nintent classification, named entity recognition, and information retrieval\nsubtasks. Our chatbot has been deployed on a commercial scale, handling tens of\nthousands of hotel searches every day. We describe the various opportunities\nand challenges of developing a chatbot in the travel industry.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 03:13:53 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Li", "Bai", ""], ["Jiang", "Nanyi", ""], ["Sham", "Joey", ""], ["Shi", "Henry", ""], ["Fazal", "Hussein", ""]]}, {"id": "1908.10009", "submitter": "Peng Gao", "authors": "Peng Gao, Qiquan Zhang, Fei Wang, Liyi Xiao, Hamido Fujita, Yan Zhang", "title": "Learning Reinforced Attentional Representation for End-to-End Visual\n  Tracking", "comments": "Accepted by Information Sciences", "journal-ref": null, "doi": "10.1016/j.ins.2019.12.084", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although numerous recent tracking approaches have made tremendous advances in\nthe last decade, achieving high-performance visual tracking remains a\nchallenge. In this paper, we propose an end-to-end network model to learn\nreinforced attentional representation for accurate target object discrimination\nand localization. We utilize a novel hierarchical attentional module with long\nshort-term memory and multi-layer perceptrons to leverage both inter- and\nintra-frame attention to effectively facilitate visual pattern emphasis.\nMoreover, we incorporate a contextual attentional correlation filter into the\nbackbone network to make our model trainable in an end-to-end fashion. Our\nproposed approach not only takes full advantage of informative geometries and\nsemantics but also updates correlation filters online without fine-tuning the\nbackbone network to enable the adaptation of variations in the target object's\nappearance. Extensive experiments conducted on several popular benchmark\ndatasets demonstrate that our proposed approach is effective and\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 03:55:17 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 00:39:16 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 01:07:09 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Gao", "Peng", ""], ["Zhang", "Qiquan", ""], ["Wang", "Fei", ""], ["Xiao", "Liyi", ""], ["Fujita", "Hamido", ""], ["Zhang", "Yan", ""]]}, {"id": "1908.10010", "submitter": "Peng Gao", "authors": "Zhencai Hu, Peng Gao, Fei Wang", "title": "Research on Autonomous Maneuvering Decision of UCAV based on Approximate\n  Dynamic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aircraft systems can perform some more dangerous and difficult\nmissions than manned aircraft systems. In some highly complicated and\nchangeable tasks, such as air combat, the maneuvering decision mechanism is\nrequired to sense the combat situation accurately and make the optimal strategy\nin real-time. This paper presents a formulation of a 3-D one-on-one air combat\nmaneuvering problem and an approximate dynamic programming approach for\ncomputing an optimal policy on autonomous maneuvering decision making. The\naircraft learns combat strategies in a Reinforcement Leaning method, while\nsensing the environment, taking available maneuvering actions and getting\nfeedback reward signals. To solve the problem of dimensional explosion in the\nair combat, the proposed method is implemented through feature selection,\ntrajectory sampling, function approximation and Bellman backup operation in the\nair combat simulation environment. This approximate dynamic programming\napproach provides a fast response to a rapidly changing tactical situation,\nlearns in long-term planning, without any explicitly coded air combat rule\nbase.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 04:01:19 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 00:43:03 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Hu", "Zhencai", ""], ["Gao", "Peng", ""], ["Wang", "Fei", ""]]}, {"id": "1908.10012", "submitter": "Yuanwei Wu", "authors": "Yuanwei Wu, Ziming Zhang and Guanghui Wang", "title": "Unsupervised Deep Feature Transfer for Low Resolution Image\n  Classification", "comments": "4 pages, accepted to ICCV19 Workshop and Challenge on Real-World\n  Recognition from Low-Quality Images and Videos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple while effective unsupervised deep feature\ntransfer algorithm for low resolution image classification. No fine-tuning on\nconvenet filters is required in our method. We use pre-trained convenet to\nextract features for both high- and low-resolution images, and then feed them\ninto a two-layer feature transfer network for knowledge transfer. A SVM\nclassifier is learned directly using these transferred low resolution features.\nOur network can be embedded into the state-of-the-art deep neural networks as a\nplug-in feature enhancement module. It preserves data structures in feature\nspace for high resolution images, and transfers the distinguishing features\nfrom a well-structured source domain (high resolution features space) to a not\nwell-organized target domain (low resolution features space). Extensive\nexperiments on VOC2007 test set show that the proposed method achieves\nsignificant improvements over the baseline of using feature extraction.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 04:06:02 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 19:56:27 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Wu", "Yuanwei", ""], ["Zhang", "Ziming", ""], ["Wang", "Guanghui", ""]]}, {"id": "1908.10017", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Geng Yuan, Sheng Lin, Caiwen Ding, Fuxun Yu, Tao Liu,\n  Wujie Wen, Xiang Chen, Yanzhi Wang", "title": "Tiny but Accurate: A Pruned, Quantized and Optimized Memristor Crossbar\n  Framework for Ultra Efficient DNN Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-art DNN structures involve intensive computation and high memory\nstorage. To mitigate the challenges, the memristor crossbar array has emerged\nas an intrinsically suitable matrix computation and low-power acceleration\nframework for DNN applications. However, the high accuracy solution for extreme\nmodel compression on memristor crossbar array architecture is still waiting for\nunraveling. In this paper, we propose a memristor-based DNN framework which\ncombines both structured weight pruning and quantization by incorporating\nalternating direction method of multipliers (ADMM) algorithm for better pruning\nand quantization performance. We also discover the non-optimality of the ADMM\nsolution in weight pruning and the unused data path in a structured pruned\nmodel. Motivated by these discoveries, we design a software-hardware\nco-optimization framework which contains the first proposed Network\nPurification and Unused Path Removal algorithms targeting on post-processing a\nstructured pruned model after ADMM steps. By taking memristor hardware\nconstraints into our whole framework, we achieve extreme high compression ratio\non the state-of-art neural network structures with minimum accuracy loss. For\nquantizing structured pruned model, our framework achieves nearly no accuracy\nloss after quantizing weights to 8-bit memristor weight representation. We\nshare our models at anonymous link https://bit.ly/2VnMUy0.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 04:19:05 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ma", "Xiaolong", ""], ["Yuan", "Geng", ""], ["Lin", "Sheng", ""], ["Ding", "Caiwen", ""], ["Yu", "Fuxun", ""], ["Liu", "Tao", ""], ["Wen", "Wujie", ""], ["Chen", "Xiang", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1908.10030", "submitter": "Joe Antognini", "authors": "Joseph M. Antognini", "title": "Finite size corrections for neural network Gaussian processes", "comments": "Presented at the 2019 ICML Workshop on Theoretical Physics for Deep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent surge of interest in modeling neural networks (NNs)\nas Gaussian processes. In the limit of a NN of infinite width the NN becomes\nequivalent to a Gaussian process. Here we demonstrate that for an ensemble of\nlarge, finite, fully connected networks with a single hidden layer the\ndistribution of outputs at initialization is well described by a Gaussian\nperturbed by the fourth Hermite polynomial for weights drawn from a symmetric\ndistribution. We show that the scale of the perturbation is inversely\nproportional to the number of units in the NN and that higher order terms decay\nmore rapidly, thereby recovering the Edgeworth expansion. We conclude by\nobserving that understanding how this perturbation changes under training would\nreveal the regimes in which the Gaussian process framework is valid to model NN\nbehavior.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 04:49:23 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Antognini", "Joseph M.", ""]]}, {"id": "1908.10059", "submitter": "Mak Chihjun", "authors": "Zhijun Mai, Guosheng Hu, Dexiong Chen, Fumin Shen, Heng Tao Shen", "title": "MetaMixUp: Learning Adaptive Interpolation Policy of MixUp with\n  Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MixUp is an effective data augmentation method to regularize deep neural\nnetworks via random linear interpolations between pairs of samples and their\nlabels. It plays an important role in model regularization, semi-supervised\nlearning and domain adaption. However, despite its empirical success, its\ndeficiency of randomly mixing samples has poorly been studied. Since deep\nnetworks are capable of memorizing the entire dataset, the corrupted samples\ngenerated by vanilla MixUp with a badly chosen interpolation policy will\ndegrade the performance of networks. To overcome the underfitting by corrupted\nsamples, inspired by Meta-learning (learning to learn), we propose a novel\ntechnique of learning to mixup in this work, namely, MetaMixUp. Unlike the\nvanilla MixUp that samples interpolation policy from a predefined distribution,\nthis paper introduces a meta-learning based online optimization approach to\ndynamically learn the interpolation policy in a data-adaptive way. The\nvalidation set performance via meta-learning captures the underfitting issue,\nwhich provides more information to refine interpolation policy. Furthermore, we\nadapt our method for pseudo-label based semisupervised learning (SSL) along\nwith a refined pseudo-labeling strategy. In our experiments, our method\nachieves better performance than vanilla MixUp and its variants under\nsupervised learning configuration. In particular, extensive experiments show\nthat our MetaMixUp adapted SSL greatly outperforms MixUp and many\nstate-of-the-art methods on CIFAR-10 and SVHN benchmarks under SSL\nconfiguration.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 07:26:35 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Mai", "Zhijun", ""], ["Hu", "Guosheng", ""], ["Chen", "Dexiong", ""], ["Shen", "Fumin", ""], ["Shen", "Heng Tao", ""]]}, {"id": "1908.10063", "submitter": "Dogu Tan Araci", "authors": "Dogu Araci", "title": "FinBERT: Financial Sentiment Analysis with Pre-trained Language Models", "comments": "This thesis is submitted in partial fulfillment for the degree of\n  Master of Science in Information Studies: Data Science, University of\n  Amsterdam. June 25, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial sentiment analysis is a challenging task due to the specialized\nlanguage and lack of labeled data in that domain. General-purpose models are\nnot effective enough because of the specialized language used in a financial\ncontext. We hypothesize that pre-trained language models can help with this\nproblem because they require fewer labeled examples and they can be further\ntrained on domain-specific corpora. We introduce FinBERT, a language model\nbased on BERT, to tackle NLP tasks in the financial domain. Our results show\nimprovement in every measured metric on current state-of-the-art results for\ntwo financial sentiment analysis datasets. We find that even with a smaller\ntraining set and fine-tuning only a part of the model, FinBERT outperforms\nstate-of-the-art machine learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 07:40:48 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Araci", "Dogu", ""]]}, {"id": "1908.10088", "submitter": "Yang Liu", "authors": "Yang Liu, Runnan He, Kuanquan Wang, Qince Li, Qiang Sun, Na Zhao and\n  Henggui Zhang", "title": "Automatic Detection of ECG Abnormalities by using an Ensemble of Deep\n  Residual Networks with Attention", "comments": "8 pages, 2 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart disease is one of the most common diseases causing morbidity and\nmortality. Electrocardiogram (ECG) has been widely used for diagnosing heart\ndiseases for its simplicity and non-invasive property. Automatic ECG analyzing\ntechnologies are expected to reduce human working load and increase diagnostic\nefficacy. However, there are still some challenges to be addressed for\nachieving this goal. In this study, we develop an algorithm to identify\nmultiple abnormalities from 12-lead ECG recordings. In the algorithm pipeline,\nseveral preprocessing methods are firstly applied on the ECG data for\ndenoising, augmentation and balancing recording numbers of variant classes. In\nconsideration of efficiency and consistency of data length, the recordings are\npadded or truncated into a medium length, where the padding/truncating time\nwindows are selected randomly to sup-press overfitting. Then, the ECGs are used\nto train deep neural network (DNN) models with a novel structure that combines\na deep residual network with an attention mechanism. Finally, an ensemble model\nis built based on these trained models to make predictions on the test data\nset. Our method is evaluated based on the test set of the First China ECG\nIntelligent Competition dataset by using the F1 metric that is regarded as the\nharmonic mean between the precision and recall. The resultant overall F1 score\nof the algorithm is 0.875, showing a promising performance and potential for\npractical use.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 08:57:55 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Liu", "Yang", ""], ["He", "Runnan", ""], ["Wang", "Kuanquan", ""], ["Li", "Qince", ""], ["Sun", "Qiang", ""], ["Zhao", "Na", ""], ["Zhang", "Henggui", ""]]}, {"id": "1908.10092", "submitter": "Lantian Li Mr.", "authors": "Xueyi Wang and Lantian Li and Dong Wang", "title": "VAE-based Domain Adaptation for Speaker Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep speaker embedding has achieved satisfactory performance in speaker\nverification. By enforcing the neural model to discriminate the speakers in the\ntraining set, deep speaker embedding (called `x-vectors`) can be derived from\nthe hidden layers. Despite its good performance, the present embedding model is\nhighly domain sensitive, which means that it often works well in domains whose\nacoustic condition matches that of the training data (in-domain), but degrades\nin mismatched domains (out-of-domain). In this paper, we present a domain\nadaptation approach based on Variational Auto-Encoder (VAE). This model\ntransforms x-vectors to a regularized latent space; within this latent space, a\nsmall amount of data from the target domain is sufficient to accomplish the\nadaptation. Our experiments demonstrated that by this VAE-adaptation approach,\nspeaker embeddings can be easily transformed to the target domain, leading to\nnoticeable performance improvement.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 09:09:48 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Wang", "Xueyi", ""], ["Li", "Lantian", ""], ["Wang", "Dong", ""]]}, {"id": "1908.10118", "submitter": "Prasanna Raj Noel Dabre", "authors": "Raj Dabre and Atsushi Fujita", "title": "Multi-Layer Softmaxing during Training Neural Machine Translation for\n  Flexible Decoding with Fewer Layers", "comments": "Fixed numeric typos and corresponding explanations in the running\n  text in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper proposes a novel procedure for training an encoder-decoder based\ndeep neural network which compresses NxM models into a single model enabling us\nto dynamically choose the number of encoder and decoder layers for decoding.\nUsually, the output of the last layer of the N-layer encoder is fed to the\nM-layer decoder, and the output of the last decoder layer is used to compute\nsoftmax loss. Instead, our method computes a single loss consisting of NxM\nlosses: the softmax loss for the output of each of the M decoder layers derived\nusing the output of each of the N encoder layers. A single model trained by our\nmethod can be used for decoding with an arbitrary fewer number of encoder and\ndecoder layers. In practical scenarios, this (a) enables faster decoding with\ninsignificant losses in translation quality and (b) alleviates the need to\ntrain NxM models, thereby saving space. We take a case study of neural machine\ntranslation and show the advantage and give a cost-benefit analysis of our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 10:17:24 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 09:11:47 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Dabre", "Raj", ""], ["Fujita", "Atsushi", ""]]}, {"id": "1908.10125", "submitter": "Dimitri Ognibene", "authors": "Dimitri Ognibene, Lorenzo Mirante, Letizia Marchegiani", "title": "Proactive Intention Recognition for Joint Human-Robot Search and Rescue\n  Missions through Monte-Carlo Planning in POMDP Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proactively perceiving others' intentions is a crucial skill to effectively\ninteract in unstructured, dynamic and novel environments. This work proposes a\nfirst step towards embedding this skill in support robots for search and rescue\nmissions. Predicting the responders' intentions, indeed, will enable\nexploration approaches which will identify and prioritise areas that are more\nrelevant for the responder and, thus, for the task, leading to the development\nof safer, more robust and efficient joint exploration strategies. More\nspecifically, this paper presents an active intention recognition paradigm to\nperceive, even under sensory constraints, not only the target's position but\nalso the first responder's movements, which can provide information on his/her\nintentions (e.g. reaching the position where he/she expects the target to be).\nThis mechanism is implemented by employing an extension of Monte-Carlo-based\nplanning techniques for partially observable environments, where the reward\nfunction is augmented with an entropy reduction bonus. We test in simulation\nseveral configurations of reward augmentation, both information theoretic and\nnot, as well as belief state approximations and obtain substantial improvements\nover the basic approach.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 10:56:59 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ognibene", "Dimitri", ""], ["Mirante", "Lorenzo", ""], ["Marchegiani", "Letizia", ""]]}, {"id": "1908.10127", "submitter": "Ke Chen", "authors": "Ke Chen", "title": "Learning-Based Video Game Development in MLP@UoM: An Overview", "comments": "8 pages, 15 figures Invited paper presented as a keynote speech,\n  ICEEIE'19 in Bali, Indonesia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, video games not only prevail in entertainment but also have\nbecome an alternative methodology for knowledge learning, skill acquisition and\nassistance for medical treatment as well as health care in education,\nvocational/military training and medicine. On the other hand, video games also\nprovide an ideal test bed for AI researches. To a large extent, however, video\ngame development is still a laborious yet costly process, and there are many\ntechnical challenges ranging from game generation to intelligent agent\ncreation. Unlike traditional methodologies, in Machine Learning and Perception\nLab at the University of Manchester (MLP@UoM), we advocate applying machine\nlearning to different tasks in video game development to address several\nchallenges systematically. In this paper, we overview the main progress made in\nMLP@UoM recently and have an outlook on the future research directions in\nlearning-based video game development arising from our works.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 11:05:15 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Chen", "Ke", ""]]}, {"id": "1908.10133", "submitter": "Andres Perez-Lopez", "authors": "Andres Perez-Lopez, Eduardo Fonseca, Xavier Serra", "title": "A hybrid parametric-deep learning approach for sound event localization\n  and detection", "comments": "5 pages, 5 figures, submitted to DCASE2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work describes and discusses an algorithm submitted to the Sound Event\nLocalization and Detection Task of DCASE2019 Challenge. The proposed\nmethodology relies on parametric spatial audio analysis for source localization\nand detection, combined with a deep learning-based monophonic event classifier.\nThe evaluation of the proposed algorithm yields overall results comparable to\nthe baseline system. The main highlight is a reduction of the localization\nerror on the evaluation dataset by a factor of 2.6, compared with the baseline\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 11:20:57 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Perez-Lopez", "Andres", ""], ["Fonseca", "Eduardo", ""], ["Serra", "Xavier", ""]]}, {"id": "1908.10149", "submitter": "Michael Barz", "authors": "Michael Barz and Daniel Sonntag", "title": "Incremental Improvement of a Question Answering System by Re-ranking\n  Answer Candidates using Machine Learning", "comments": "Accepted for oral presentation at tenth International Workshop on\n  Spoken Dialogue Systems Technology (IWSDS) 2019", "journal-ref": null, "doi": "10.1007/978-981-15-9323-9_34", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a method for re-ranking top-10 results of a state-of-the-art\nquestion answering (QA) system. The goal of our re-ranking approach is to\nimprove the answer selection given the user question and the top-10 candidates.\nWe focus on improving deployed QA systems that do not allow re-training or\nre-training comes at a high cost. Our re-ranking approach learns a similarity\nfunction using n-gram based features using the query, the answer and the\ninitial system confidence as input. Our contributions are: (1) we generate a QA\ntraining corpus starting from 877 answers from the customer care domain of\nT-Mobile Austria, (2) we implement a state-of-the-art QA pipeline using neural\nsentence embeddings that encode queries in the same space than the answer\nindex, and (3) we evaluate the QA pipeline and our re-ranking approach using a\nseparately provided test set. The test set can be considered to be available\nafter deployment of the system, e.g., based on feedback of users. Our results\nshow that the system performance, in terms of top-n accuracy and the mean\nreciprocal rank, benefits from re-ranking using gradient boosted regression\ntrees. On average, the mean reciprocal rank improves by 9.15%.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 11:54:23 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Barz", "Michael", ""], ["Sonntag", "Daniel", ""]]}, {"id": "1908.10166", "submitter": "Casimiro Adays Curbelo Monta\\~nez", "authors": "Casimiro Aday Curbelo Monta\\~nez, Paul Fergus, Carl Chalmers, Nurul\n  Ahamed Hassain Malim, Basma Abdulaimma, Denis Reilly, and Francesco Falciani", "title": "SAERMA: Stacked Autoencoder Rule Mining Algorithm for the Interpretation\n  of Epistatic Interactions in GWAS for Extreme Obesity", "comments": "12 pages, 6 figures, 12 tables, 9 equations, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important challenges in the analysis of high-throughput\ngenetic data is the development of efficient computational methods to identify\nstatistically significant Single Nucleotide Polymorphisms (SNPs). Genome-wide\nassociation studies (GWAS) use single-locus analysis where each SNP is\nindependently tested for association with phenotypes. The limitation with this\napproach, however, is its inability to explain genetic variation in complex\ndiseases. Alternative approaches are required to model the intricate\nrelationships between SNPs. Our proposed approach extends GWAS by combining\ndeep learning stacked autoencoders (SAEs) and association rule mining (ARM) to\nidentify epistatic interactions between SNPs. Following traditional GWAS\nquality control and association analysis, the most significant SNPs are\nselected and used in the subsequent analysis to investigate epistasis. SAERMA\ncontrols the classification results produced in the final fully connected\nmulti-layer feedforward artificial neural network (MLP) by manipulating the\ninterestingness measures, support and confidence, in the rule generation\nprocess. The best classification results were achieved with 204 SNPs compressed\nto 100 units (77% AUC, 77% SE, 68% SP, 53% Gini, logloss=0.58, and MSE=0.20),\nalthough it was possible to achieve 73% AUC (77% SE, 63% SP, 45% Gini,\nlogloss=0.62, and MSE=0.21) with 50 hidden units - both supported by close\nmodel interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 12:49:05 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Monta\u00f1ez", "Casimiro Aday Curbelo", ""], ["Fergus", "Paul", ""], ["Chalmers", "Carl", ""], ["Malim", "Nurul Ahamed Hassain", ""], ["Abdulaimma", "Basma", ""], ["Reilly", "Denis", ""], ["Falciani", "Francesco", ""]]}, {"id": "1908.10172", "submitter": "Mert B\\\"ulent Sar{\\i}y{\\i}ld{\\i}z", "authors": "Mert B\\\"ulent Sar{\\i}y{\\i}ld{\\i}z, Ramazan G\\\"okberk Cinbi\\c{s}, Erman\n  Ayday", "title": "Key Protected Classification for Collaborative Learning", "comments": "Accepted to Pattern Recognition", "journal-ref": null, "doi": "10.1016/j.patcog.2020.107327", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale datasets play a fundamental role in training deep learning\nmodels. However, dataset collection is difficult in domains that involve\nsensitive information. Collaborative learning techniques provide a\nprivacy-preserving solution, by enabling training over a number of private\ndatasets that are not shared by their owners. However, recently, it has been\nshown that the existing collaborative learning frameworks are vulnerable to an\nactive adversary that runs a generative adversarial network (GAN) attack. In\nthis work, we propose a novel classification model that is resilient against\nsuch attacks by design. More specifically, we introduce a key-based\nclassification model and a principled training scheme that protects class\nscores by using class-specific private keys, which effectively hide the\ninformation necessary for a GAN attack. We additionally show how to utilize\nhigh dimensional keys to improve the robustness against attacks without\nincreasing the model complexity. Our detailed experiments demonstrate the\neffectiveness of the proposed technique. Source code is available at\nhttps://github.com/mbsariyildiz/key-protected-classification.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 13:00:30 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 09:31:45 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Sar\u0131y\u0131ld\u0131z", "Mert B\u00fclent", ""], ["Cinbi\u015f", "Ramazan G\u00f6kberk", ""], ["Ayday", "Erman", ""]]}, {"id": "1908.10180", "submitter": "Qizhi Zhang", "authors": "Qizhi Zhang and Yi Lin and Kangle Wu and Yongliang Li and Anxiang Zeng", "title": "Matrix embedding method in match for session-based recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session based model is widely used in recommend system. It use the user click\nsequence as input of a Recurrent Neural Network (RNN), and get the output of\nthe RNN network as the vector embedding of the session, and use the inner\nproduct of the vector embedding of session and the vector embedding of the next\nitem as the score that is the metric of the interest to the next item. This\nmethod can be used for the \"match\" stage for the recommendation system whose\nitem number is very big by using some index method like KD-Tree or Ball-Tree\nand etc.. But this method repudiate the variousness of the interest of user in\na session. We generated the model to modify the vector embedding of session to\na symmetric matrix embedding, that is equivalent to a quadratic form on the\nvector space of items. The score is builded as the value of the vector\nembedding of next item under the quadratic form. The eigenvectors of the\nsymmetric matrix embedding corresponding to the positive eigenvalues are\nconjectured to represent the interests of user in the session. This method can\nbe used for the \"match\" stage also. The experiments show that this method is\nbetter than the method of vector embedding.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 13:18:51 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Zhang", "Qizhi", ""], ["Lin", "Yi", ""], ["Wu", "Kangle", ""], ["Li", "Yongliang", ""], ["Zeng", "Anxiang", ""]]}, {"id": "1908.10187", "submitter": "M. Ricardo Carlos", "authors": "M. Ricardo Carlos", "title": "A Machine Learning Approach for Smartphone-based Sensing of Roads and\n  Driving Style", "comments": "Doctoral Dissertation. Dissertation Advisors: Luis Carlos Gonz\\'alez\n  Gurrola and Fernando Mart\\'inez", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road transportation is of critical importance for a nation, having profound\neffects in the economy, the health and life style of its people. With the\ngrowth of cities and populations come bigger demands for mobility and safety,\ncreating new problems and magnifying those of the past. New tools are needed to\nface the challenge, to keep roads in good conditions, their users safe, and\nminimize the impact on the environment.\n  This dissertation is concerned with road quality assessment and aggressive\ndriving, two important problems in road transportation, approached in the\ncontext of Intelligent Transportation Systems by using Machine Learning\ntechniques to analyze acceleration time series acquired with smartphone-based\nopportunistic sensing to automatically detect, classify, and characterize\nevents of interest.\n  Two aspects of road quality assessment are addressed: the detection and the\ncharacterization of road anomalies. For the first, the most widely cited works\nin the literature are compared and proposals capable of equal or better\nperformance are presented, removing the reliance on threshold values and\nreducing the computational cost and dimensionality of previous proposals. For\nthe second, new approaches for the estimation of pothole depth and the\nfunctional condition of speed reducers are showed. The new problem of pothole\ndepth ranking is introduced, using a learning-to-rank approach to sort\nacceleration signals by the depth of the potholes that they reflect.\n  The classification of aggressive driving maneuvers is done with automatic\nfeature extraction, finding characteristically shaped subsequences in the\nsignals as more effective discriminants than conventional descriptors\ncalculated over time windows.\n  Finally, all the previously mentioned tasks are combined to produce a robust\nroad transport evaluation platform.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 00:16:10 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Carlos", "M. Ricardo", ""]]}, {"id": "1908.10192", "submitter": "Andrei Boiarov", "authors": "Andrei Boiarov, Eduard Tyantov", "title": "Large Scale Landmark Recognition via Deep Metric Learning", "comments": "Accepted at CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3357956", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach for landmark recognition in images that\nwe've successfully deployed at Mail ru. This method enables us to recognize\nfamous places, buildings, monuments, and other landmarks in user photos. The\nmain challenge lies in the fact that it's very complicated to give a precise\ndefinition of what is and what is not a landmark. Some buildings, statues and\nnatural objects are landmarks; others are not. There's also no database with a\nfairly large number of landmarks to train a recognition model. A key feature of\nusing landmark recognition in a production environment is that the number of\nphotos containing landmarks is extremely small. This is why the model should\nhave a very low false positive rate as well as high recognition accuracy.\n  We propose a metric learning-based approach that successfully deals with\nexisting challenges and efficiently handles a large number of landmarks. Our\nmethod uses a deep neural network and requires a single pass inference that\nmakes it fast to use in production. We also describe an algorithm for cleaning\nlandmarks database which is essential for training a metric learning model. We\nprovide an in-depth description of basic components of our method like neural\nnetwork architecture, the learning strategy, and the features of our metric\nlearning approach. We show the results of proposed solutions in tests that\nemulate the distribution of photos with and without landmarks from a user\ncollection. We compare our method with others during these tests. The described\nsystem has been deployed as a part of a photo recognition solution at Cloud\nMail ru, which is the photo sharing and storage service at Mail ru Group.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 13:37:49 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 06:59:27 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 09:04:17 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Boiarov", "Andrei", ""], ["Tyantov", "Eduard", ""]]}, {"id": "1908.10198", "submitter": "Dan Work", "authors": "Yue Hu and Dan Work", "title": "Robust Tensor Recovery with Fiber Outliers for Traffic Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event detection is gaining increasing attention in smart cities research.\nLarge-scale mobility data serves as an important tool to uncover the dynamics\nof urban transportation systems, and more often than not the dataset is\nincomplete. In this article, we develop a method to detect extreme events in\nlarge traffic datasets, and to impute missing data during regular conditions.\nSpecifically, we propose a robust tensor recovery problem to recover low rank\ntensors under fiber-sparse corruptions with partial observations, and use it to\nidentify events, and impute missing data under typical conditions. Our approach\nis scalable to large urban areas, taking full advantage of the spatio-temporal\ncorrelations in traffic patterns. We develop an efficient algorithm to solve\nthe tensor recovery problem based on the alternating direction method of\nmultipliers (ADMM) framework. Compared with existing $l_1$ norm regularized\ntensor decomposition methods, our algorithm can exactly recover the values of\nuncorrupted fibers of a low rank tensor and find the positions of corrupted\nfibers under mild conditions. Numerical experiments illustrate that our\nalgorithm can exactly detect outliers even with missing data rates as high as\n40%, conditioned on the outlier corruption rate and the Tucker rank of the low\nrank tensor. Finally, we apply our method on a real traffic dataset\ncorresponding to downtown Nashville, TN, USA and successfully detect the events\nlike severe car crashes, construction lane closures, and other large events\nthat cause significant traffic disruptions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 13:51:07 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Hu", "Yue", ""], ["Work", "Dan", ""]]}, {"id": "1908.10206", "submitter": "Raul Vicente", "authors": "Raul Vicente", "title": "The many faces of deep learning", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has sparked a network of mutual interactions between different\ndisciplines and AI. Naturally, each discipline focuses and interprets the\nworkings of deep learning in different ways. This diversity of perspectives on\ndeep learning, from neuroscience to statistical physics, is a rich source of\ninspiration that fuels novel developments in the theory and applications of\nmachine learning. In this perspective, we collect and synthesize different\nintuitions scattered across several communities as for how deep learning works.\nIn particular, we will briefly discuss the different perspectives that\ndisciplines across mathematics, physics, computation, and neuroscience take on\nhow deep learning does its tricks. Our discussion on each perspective is\nnecessarily shallow due to the multiple views that had to be covered. The\ndeepness in this case should come from putting all these faces of deep learning\ntogether in the reader's mind, so that one can look at the same problem from\ndifferent angles.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 12:04:49 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Vicente", "Raul", ""]]}, {"id": "1908.10208", "submitter": "Yucheng Liu", "authors": "Yucheng Liu, Naji Khosravan, Yulin Liu, Joseph Stember, Jonathan\n  Shoag, Christopher E. Barbieri, Ulas Bagci, and Sachin Jambawalikar", "title": "Cross-modality Knowledge Transfer for Prostate Segmentation from CT\n  Scans", "comments": "9 pages, 3 figures, 2019 MICCAI-DART workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating large scale high-quality annotations is a known challenge in medical\nimaging. In this work, based on the CycleGAN algorithm, we propose leveraging\nannotations from one modality to be useful in other modalities. More\nspecifically, the proposed algorithm creates highly realistic synthetic CT\nimages (SynCT) from prostate MR images using unpaired data sets. By using SynCT\nimages (without segmentation labels) and MR images (with segmentation labels\navailable), we have trained a deep segmentation network for precise delineation\nof prostate from real CT scans. For the generator in our CycleGAN, the cycle\nconsistency term is used to guarantee that SynCT shares the identical\nmanually-drawn, high-quality masks originally delineated on MR images. Further,\nwe introduce a cost function based on structural similarity index (SSIM) to\nimprove the anatomical similarity between real and synthetic images. For\nsegmentation followed by the SynCT generation from CycleGAN, automatic\ndelineation is achieved through a 2.5D Residual U-Net. Quantitative evaluation\ndemonstrates comparable segmentation results between our SynCT and radiologist\ndrawn masks for real CT images, solving an important problem in medical image\nsegmentation field when ground truth annotations are not available for the\nmodality of interest.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 00:39:50 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 16:43:03 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Liu", "Yucheng", ""], ["Khosravan", "Naji", ""], ["Liu", "Yulin", ""], ["Stember", "Joseph", ""], ["Shoag", "Jonathan", ""], ["Barbieri", "Christopher E.", ""], ["Bagci", "Ulas", ""], ["Jambawalikar", "Sachin", ""]]}, {"id": "1908.10209", "submitter": "Sameera Ramasinghe Mr.", "authors": "Sameera Ramasinghe, Salman Khan, Nick Barnes, Stephen Gould", "title": "Blended Convolution and Synthesis for Efficient Discrimination of 3D\n  Shapes", "comments": "10 pages: corrected typos and added affiliations. The IEEE Winter\n  Conference on Applications of Computer Vision. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing networks directly learn feature representations on 3D point clouds\nfor shape analysis. We argue that 3D point clouds are highly redundant and hold\nirregular (permutation-invariant) structure, which makes it difficult to\nachieve inter-class discrimination efficiently. In this paper, we propose a\ntwo-faceted solution to this problem that is seamlessly integrated in a single\n`Blended Convolution and Synthesis' layer. This fully differentiable layer\nperforms two critical tasks in succession. In the first step, it projects the\ninput 3D point clouds into a latent 3D space to synthesize a highly compact and\nmore inter-class discriminative point cloud representation. Since, 3D point\nclouds do not follow a Euclidean topology, standard 2/3D Convolutional Neural\nNetworks offer limited representation capability. Therefore, in the second\nstep, it uses a novel 3D convolution operator functioning inside the unit ball\n($\\mathbb{B}^3$) to extract useful volumetric features. We extensively derive\nformulae to achieve both translation and rotation of our novel convolution\nkernels. Finally, using the proposed techniques we present an extremely\nlight-weight, end-to-end architecture that achieves compelling results on 3D\nshape recognition and retrieval.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 08:18:33 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 09:29:28 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ramasinghe", "Sameera", ""], ["Khan", "Salman", ""], ["Barnes", "Nick", ""], ["Gould", "Stephen", ""]]}, {"id": "1908.10218", "submitter": "Peng Xie", "authors": "Peng Xie, Tianrui Li, Jia Liu, Shengdong Du, Xin Yang, Junbo Zhang", "title": "Urban flows prediction from spatial-temporal data using machine\n  learning: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban spatial-temporal flows prediction is of great importance to traffic\nmanagement, land use, public safety, etc. Urban flows are affected by several\ncomplex and dynamic factors, such as patterns of human activities, weather,\nevents and holidays. Datasets evaluated the flows come from various sources in\ndifferent domains, e.g. mobile phone data, taxi trajectories data, metro/bus\nswiping data, bike-sharing data and so on. To summarize these methodologies of\nurban flows prediction, in this paper, we first introduce four main factors\naffecting urban flows. Second, in order to further analysis urban flows, a\npreparation process of multi-sources spatial-temporal data related with urban\nflows is partitioned into three groups. Third, we choose the spatial-temporal\ndynamic data as a case study for the urban flows prediction task. Fourth, we\nanalyze and compare some well-known and state-of-the-art flows prediction\nmethods in detail, classifying them into five categories: statistics-based,\ntraditional machine learning-based, deep learning-based, reinforcement\nlearning-based and transfer learning-based methods. Finally, we give open\nchallenges of urban flows prediction and an outlook in the future of this\nfield. This paper will facilitate researchers find suitable methods and open\ndatasets for addressing urban spatial-temporal flows forecast problems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 13:50:37 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Xie", "Peng", ""], ["Li", "Tianrui", ""], ["Liu", "Jia", ""], ["Du", "Shengdong", ""], ["Yang", "Xin", ""], ["Zhang", "Junbo", ""]]}, {"id": "1908.10219", "submitter": "Bo Li", "authors": "Bo Li, Marius de Groot, Meike Vernooij, Arfan Ikram, Wiro Niessen,\n  Esther Bron", "title": "Reproducible White Matter Tract Segmentation Using 3D U-Net on a\n  Large-scale DTI Dataset", "comments": "Machine Learning in Medical Imaging (MLMI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tract-specific diffusion measures, as derived from brain diffusion MRI, have\nbeen linked to white matter tract structural integrity and neurodegeneration.\nAs a consequence, there is a large interest in the automatic segmentation of\nwhite matter tract in diffusion tensor MRI data. Methods based on the\ntractography are popular for white matter tract segmentation. However, because\nof the limited consistency and long processing time, such methods may not be\nsuitable for clinical practice. We therefore developed a novel convolutional\nneural network based method to directly segment white matter tract trained on a\nlow-resolution dataset of 9149 DTI images. The method is optimized on input,\nloss function and network architecture selections. We evaluated both\nsegmentation accuracy and reproducibility, and reproducibility of determining\ntract-specific diffusion measures. The reproducibility of the method is higher\nthan that of the reference standard and the determined diffusion measures are\nconsistent. Therefore, we expect our method to be applicable in clinical\npractice and in longitudinal analysis of white matter microstructure.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 11:06:14 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Li", "Bo", ""], ["de Groot", "Marius", ""], ["Vernooij", "Meike", ""], ["Ikram", "Arfan", ""], ["Niessen", "Wiro", ""], ["Bron", "Esther", ""]]}, {"id": "1908.10221", "submitter": "Bo Li", "authors": "Bo Li, Wiro Niessen, Stefan Klein, Marius de Groot, Arfan Ikram, Meike\n  Vernooij, Esther Bron", "title": "A hybrid deep learning framework for integrated segmentation and\n  registration: evaluation on longitudinal white matter tract changes", "comments": "MICCAI 2019 (oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accurately analyze changes of anatomical structures in longitudinal\nimaging studies, consistent segmentation across multiple time-points is\nrequired. Existing solutions often involve independent registration and\nsegmentation components. Registration between time-points is used either as a\nprior for segmentation in a subsequent time point or to perform segmentation in\na common space. In this work, we propose a novel hybrid convolutional neural\nnetwork (CNN) that integrates segmentation and registration into a single\nprocedure. We hypothesize that the joint optimization leads to increased\nperformance on both tasks. The hybrid CNN is trained by minimizing an\nintegrated loss function composed of four different terms, measuring\nsegmentation accuracy, similarity between registered images, deformation field\nsmoothness, and segmentation consistency. We applied this method to the\nsegmentation of white matter tracts, describing functionally grouped axonal\nfibers, using N=8045 longitudinal brain MRI data of 3249 individuals. The\nproposed method was compared with two multistage pipelines using two existing\nsegmentation methods combined with a conventional deformable registration\nalgorithm. In addition, we assessed the added value of the joint optimization\nfor segmentation and registration separately. The hybrid CNN yielded\nsignificantly higher accuracy, consistency and reproducibility of segmentation\nthan the multistage pipelines, and was orders of magnitude faster. Therefore,\nwe expect it can serve as a novel tool to support clinical and epidemiological\nanalyses on understanding microstructural brain changes over time.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 10:39:30 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Li", "Bo", ""], ["Niessen", "Wiro", ""], ["Klein", "Stefan", ""], ["de Groot", "Marius", ""], ["Ikram", "Arfan", ""], ["Vernooij", "Meike", ""], ["Bron", "Esther", ""]]}, {"id": "1908.10223", "submitter": "Canyu Le", "authors": "Canyu Le, Xihan Wei, Biao Wang, Lei Zhang, Zhonggui Chen", "title": "Learning Continually from Low-shot Data Stream", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has achieved remarkable results on various applications,\nit is usually data hungry and struggles to learn over non-stationary data\nstream. To solve these two limits, the deep learning model should not only be\nable to learn from a few of data, but also incrementally learn new concepts\nfrom data stream over time without forgetting the previous knowledge. Limited\nliterature simultaneously address both problems. In this work, we propose a\nnovel approach, MetaCL, which enables neural networks to effectively learn meta\nknowledge from low-shot data stream without catastrophic forgetting. MetaCL\ntrains a model to exploit the intrinsic feature of data (i.e. meta knowledge)\nand dynamically penalize the important model parameters change to preserve\nlearned knowledge. In this way, the deep learning model can efficiently obtain\nnew knowledge from small volume of data and still keep high performance on\nprevious tasks. MetaCL is conceptually simple, easy to implement and\nmodel-agnostic. We implement our method on three recent regularization-based\nmethods. Extensive experiments show that our approach leads to state-of-the-art\nperformance on image classification benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:16:31 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 12:58:51 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Le", "Canyu", ""], ["Wei", "Xihan", ""], ["Wang", "Biao", ""], ["Zhang", "Lei", ""], ["Chen", "Zhonggui", ""]]}, {"id": "1908.10226", "submitter": "I\\~nigo Urteaga", "authors": "I\\~nigo Urteaga, Tristan Bertin, Theresa M. Hardy, David J. Albers,\n  No\\'emie Elhadad", "title": "Multi-Task Gaussian Processes and Dilated Convolutional Networks for\n  Reconstruction of Reproductive Hormonal Dynamics", "comments": "Accepted and presented in Machine Learning for Healthcare 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end statistical framework for personalized, accurate,\nand minimally invasive modeling of female reproductive hormonal patterns.\nReconstructing and forecasting the evolution of hormonal dynamics is a\nchallenging task, but a critical one to improve general understanding of the\nmenstrual cycle and personalized detection of potential health issues. Our goal\nis to infer and forecast individual hormone daily levels over time, while\naccommodating pragmatic and minimally invasive measurement settings. To that\nend, our approach combines the power of probabilistic generative models (i.e.,\nmulti-task Gaussian processes) with the flexibility of neural networks (i.e., a\ndilated convolutional architecture) to learn complex temporal mappings. To\nattain accurate hormone level reconstruction with as little data as possible,\nwe propose a sampling mechanism for optimal reconstruction accuracy with\nlimited sampling budget. Our results show the validity of our proposed hormonal\ndynamic modeling framework, as it provides accurate predictive performance\nacross different realistic sampling budgets and outperforms baselines methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:21:31 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Urteaga", "I\u00f1igo", ""], ["Bertin", "Tristan", ""], ["Hardy", "Theresa M.", ""], ["Albers", "David J.", ""], ["Elhadad", "No\u00e9mie", ""]]}, {"id": "1908.10235", "submitter": "Hessam Sokooti", "authors": "Hessam Sokooti, Bob de Vos, Floris Berendsen, Mohsen Ghafoorian, Sahar\n  Yousefi, Boudewijn P.F. Lelieveldt, Ivana Isgum, and Marius Staring", "title": "3D Convolutional Neural Networks Image Registration Based on Efficient\n  Supervised Learning from Artificial Deformations", "comments": "TMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a supervised nonrigid image registration method, trained using\nartificial displacement vector fields (DVF), for which we propose and compare\nthree network architectures. The artificial DVFs allow training in a fully\nsupervised and voxel-wise dense manner, but without the cost usually associated\nwith the creation of densely labeled data. We propose a scheme to artificially\ngenerate DVFs, and for chest CT registration augment these with simulated\nrespiratory motion. The proposed architectures are embedded in a multi-stage\napproach, to increase the capture range of the proposed networks in order to\nmore accurately predict larger displacements. The proposed method, RegNet, is\nevaluated on multiple databases of chest CT scans and achieved a target\nregistration error of 2.32 $\\pm$ 5.33 mm and 1.86 $\\pm$ 2.12 mm on SPREAD and\nDIR-Lab-4DCT studies, respectively. The average inference time of RegNet with\ntwo stages is about 2.2 s.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:34:45 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Sokooti", "Hessam", ""], ["de Vos", "Bob", ""], ["Berendsen", "Floris", ""], ["Ghafoorian", "Mohsen", ""], ["Yousefi", "Sahar", ""], ["Lelieveldt", "Boudewijn P. F.", ""], ["Isgum", "Ivana", ""], ["Staring", "Marius", ""]]}, {"id": "1908.10243", "submitter": "Robert O'Shea", "authors": "Robert O'Shea", "title": "Model Selection With Graphical Neighbour Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate model selection is a fundamental requirement for statistical\nanalysis. In many real-world applications of graphical modelling, correct model\nstructure identification is the ultimate objective. Standard model validation\nprocedures such as information theoretic scores and cross validation have\ndemonstrated poor performance in the high dimensional setting. Specialised\nmethods such as EBIC, StARS and RIC have been developed for the explicit\npurpose of high-dimensional Gaussian graphical model selection. We present a\nnovel model score criterion, Graphical Neighbour Information. This method\ndemonstrates oracle performance in high-dimensional model selection,\noutperforming the current state-of-the-art in our simulations. The Graphical\nNeighbour Information criterion has the additional advantage of efficient,\nclosed-form computability, sparing the costly inference of multiple models on\ndata subsamples. We provide a theoretical analysis of the method and benchmark\nsimulations versus the current state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:47:53 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["O'Shea", "Robert", ""]]}, {"id": "1908.10247", "submitter": "Hamza Jaffali", "authors": "Hamza Jaffali, Luke Oeding", "title": "Learning Algebraic Models of Quantum Entanglement", "comments": "22 pages. comments welcome", "journal-ref": "Quantum Inf Process 19, 279 (2020)", "doi": "10.1007/s11128-020-02785-4", "report-no": null, "categories": "cs.LG cs.ET math.AG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review supervised learning and deep neural network design for learning\nmembership on algebraic varieties. We demonstrate that these trained artificial\nneural networks can predict the entanglement type for quantum states. We give\nexamples for detecting degenerate states, as well as border rank classification\nfor up to 5 binary qubits and 3 qutrits (ternary qubits).\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:54:34 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 12:46:52 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jaffali", "Hamza", ""], ["Oeding", "Luke", ""]]}, {"id": "1908.10271", "submitter": "Han Qiu", "authors": "Yi Zeng, Zihao Qi, Wencheng Chen, Yanzhe Huang, Xingxin Zheng, Han Qiu", "title": "TEST: an End-to-End Network Traffic Examination and Identification\n  Framework Based on Spatio-Temporal Features Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With more encrypted network traffic gets involved in the Internet, how to\neffectively identify network traffic has become a top priority in the field.\nAccurate identification of the network traffic is the footstone of basic\nnetwork services, say QoE, bandwidth allocation, and IDS. Previous\nidentification methods either cannot deal with encrypted traffics or require\nexperts to select tons of features to attain a relatively decent accuracy.In\nthis paper, we present a Deep Learning based end-to-end network traffic\nidentification framework, termed TEST, to avoid the aforementioned problems.\nCNN and LSTM are combined and implemented to help the machine automatically\nextract features from both special and time-related features of the raw\ntraffic. The presented framework has two layers of structure, which made it\npossible to attain a remarkable accuracy on both encrypted traffic\nclassification and intrusion detection tasks. The experimental results\ndemonstrate that our model can outperform previous methods with a\nstate-of-the-art accuracy of 99.98%.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 13:12:16 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Zeng", "Yi", ""], ["Qi", "Zihao", ""], ["Chen", "Wencheng", ""], ["Huang", "Yanzhe", ""], ["Zheng", "Xingxin", ""], ["Qiu", "Han", ""]]}, {"id": "1908.10283", "submitter": "Marc Ru{\\ss}wurm", "authors": "Marc Ru{\\ss}wurm, Romain Tavenard, S\\'ebastien Lef\\`evre, Marco\n  K\\\"orner", "title": "Early Classification for Agricultural Monitoring from Satellite Time\n  Series", "comments": "Appeared at the International Conference on Machine Learning AI for\n  Social Good Workshop, Long Beach, United States, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we introduce a recently developed early classification\nmechanism to satellite-based agricultural monitoring. It augments existing\nclassification models by an additional stopping probability based on the\npreviously seen information. This mechanism is end-to-end trainable and derives\nits stopping decision solely from the observed satellite data. We show results\non field parcels in central Europe where sufficient ground truth data is\navailable for an empiric evaluation of the results with local phenological\ninformation obtained from authorities. We observe that the recurrent neural\nnetwork outfitted with this early classification mechanism was able to\ndistinguish the many of the crop types before the end of the vegetative period.\nFurther, we associated these stopping times with evaluated ground truth\ninformation and saw that the times of classification were related to\ncharacteristic events of the observed plants' phenology.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:43:04 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ru\u00dfwurm", "Marc", ""], ["Tavenard", "Romain", ""], ["Lef\u00e8vre", "S\u00e9bastien", ""], ["K\u00f6rner", "Marco", ""]]}, {"id": "1908.10284", "submitter": "Daniele Calandriello", "authors": "Daniele Calandriello, Lorenzo Rosasco", "title": "Statistical and Computational Trade-Offs in Kernel K-Means", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, pp. 9357-9367.\n  2018", "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the efficiency of k-means in terms of both statistical and\ncomputational requirements. More precisely, we study a Nystr\\\"om approach to\nkernel k-means. We analyze the statistical properties of the proposed method\nand show that it achieves the same accuracy of exact kernel k-means with only a\nfraction of computations. Indeed, we prove under basic assumptions that\nsampling $\\sqrt{n}$ Nystr\\\"om landmarks allows to greatly reduce computational\ncosts without incurring in any loss of accuracy. To the best of our knowledge\nthis is the first result of this kind for unsupervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:43:49 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Calandriello", "Daniele", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1908.10290", "submitter": "Zhi Cao", "authors": "Zhi Cao, Honggang Zhang, Yu Cao, Benyuan Liu", "title": "A Deep Reinforcement Learning Approach to Multi-component Job Scheduling\n  in Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the optimal scheduling of a collection of\nmulti-component application jobs in an edge computing system that consists of\ngeo-distributed edge computing nodes connected through a wide area network. The\nscheduling and placement of application jobs in an edge system is challenging\ndue to the interdependence of multiple components of each job, and the\ncommunication delays between the geographically distributed data sources and\nedge nodes and their dynamic availability. In this paper we explore the\nfeasibility of applying Deep Reinforcement Learning (DRL) based design to\naddress these challenges. We introduce a DRL actor-critic algorithm that aims\nto find an optimal scheduling policy to minimize average job slowdown in the\nedge system. We have demonstrated through simulations that our design\noutperforms a few existing algorithms, based on both synthetic data and a\nGoogle cloud data trace.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:13:18 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 04:12:47 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 04:00:16 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Cao", "Zhi", ""], ["Zhang", "Honggang", ""], ["Cao", "Yu", ""], ["Liu", "Benyuan", ""]]}, {"id": "1908.10292", "submitter": "Alexander Rakhlin", "authors": "Tengyuan Liang and Alexander Rakhlin and Xiyu Zhai", "title": "On the Multiple Descent of Minimum-Norm Interpolants and Restricted\n  Lower Isometry of Kernels", "comments": null, "journal-ref": "Proceedings of the 33rd Conference on Learning Theory 125 (2020)\n  2683-2711", "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the risk of minimum-norm interpolants of data in Reproducing Kernel\nHilbert Spaces. Our upper bounds on the risk are of a multiple-descent shape\nfor the various scalings of $d = n^{\\alpha}$, $\\alpha\\in(0,1)$, for the input\ndimension $d$ and sample size $n$. Empirical evidence supports our finding that\nminimum-norm interpolants in RKHS can exhibit this unusual non-monotonicity in\nsample size; furthermore, locations of the peaks in our experiments match our\ntheoretical predictions. Since gradient flow on appropriately initialized wide\nneural networks converges to a minimum-norm interpolant with respect to a\ncertain kernel, our analysis also yields novel estimation and generalization\nguarantees for these over-parametrized models.\n  At the heart of our analysis is a study of spectral properties of the random\nkernel matrix restricted to a filtration of eigen-spaces of the population\ncovariance operator, and may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 16:05:50 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 15:22:45 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Liang", "Tengyuan", ""], ["Rakhlin", "Alexander", ""], ["Zhai", "Xiyu", ""]]}, {"id": "1908.10310", "submitter": "Kazuyuki Shudo", "authors": "Yoshiki Takahashi, Masato Asahara, Kazuyuki Shudo", "title": "A Framework for Model Search Across Multiple Machine Learning\n  Implementations", "comments": "Proc. 15h Int'l eScience Conference (eScience 2019), September 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recently devised machine learning (ML) algorithms have shown improved\naccuracy for various predictive problems. Model searches, which explore to find\nan optimal ML algorithm and hyperparameter values for the target problem, play\na critical role in such improvements. During a model search, data scientists\ntypically use multiple ML implementations to construct several predictive\nmodels; however, it takes significant time and effort to employ multiple ML\nimplementations due to the need to learn how to use them, prepare input data in\nseveral different formats, and compare their outputs. Our proposed framework\naddresses these issues by providing simple and unified coding method. It has\nbeen designed with the following two attractive features: i) new machine\nlearning implementations can be added easily via common interfaces between the\nframework and ML implementations and ii) it can be scaled to handle large model\nconfiguration search spaces via profile-based scheduling. The results of our\nevaluation indicate that, with our framework, implementers need only write\n55-144 lines of code to add a new ML implementation. They also show that ours\nwas the fastest framework for the HIGGS dataset, and the second-fastest for the\nSECOM dataset.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 16:35:22 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Takahashi", "Yoshiki", ""], ["Asahara", "Masato", ""], ["Shudo", "Kazuyuki", ""]]}, {"id": "1908.10312", "submitter": "Kun Qian", "authors": "Kun Qian, Abduallah Mohamed and Christian Claudel", "title": "Physics Informed Data Driven model for Flood Prediction: Application of\n  Deep Learning in prediction of urban flood development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flash floods in urban areas occur with increasing frequency. Detecting these\nfloods would greatlyhelp alleviate human and economic losses. However, current\nflood prediction methods are eithertoo slow or too simplified to capture the\nflood development in details. Using Deep Neural Networks,this work aims at\nboosting the computational speed of a physics-based 2-D urban flood\npredictionmethod, governed by the Shallow Water Equation (SWE). Convolutional\nNeural Networks(CNN)and conditional Generative Adversarial Neural\nNetworks(cGANs) are applied to extract the dy-namics of flood from the data\nsimulated by a Partial Differential Equation(PDE) solver. Theperformance of the\ndata-driven model is evaluated in terms of Mean Squared Error(MSE) andPeak\nSignal to Noise Ratio(PSNR). The deep learning-based, data-driven flood\nprediction modelis shown to be able to provide precise real-time predictions of\nflood development\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 20:50:14 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Qian", "Kun", ""], ["Mohamed", "Abduallah", ""], ["Claudel", "Christian", ""]]}, {"id": "1908.10322", "submitter": "Dokook Choe", "authors": "Dokook Choe, Rami Al-Rfou, Mandy Guo, Heeyoung Lee, Noah Constant", "title": "Bridging the Gap for Tokenizer-Free Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purely character-based language models (LMs) have been lagging in quality on\nlarge scale datasets, and current state-of-the-art LMs rely on word\ntokenization. It has been assumed that injecting the prior knowledge of a\ntokenizer into the model is essential to achieving competitive results. In this\npaper, we show that contrary to this conventional wisdom, tokenizer-free LMs\nwith sufficient capacity can achieve competitive performance on a large scale\ndataset. We train a vanilla transformer network with 40 self-attention layers\non the One Billion Word (lm1b) benchmark and achieve a new state of the art for\ntokenizer-free LMs, pushing these models to be on par with their word-based\ncounterparts.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 16:53:59 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Choe", "Dokook", ""], ["Al-Rfou", "Rami", ""], ["Guo", "Mandy", ""], ["Lee", "Heeyoung", ""], ["Constant", "Noah", ""]]}, {"id": "1908.10324", "submitter": "Tengyuan Liang", "authors": "Tengyuan Liang", "title": "On the Minimax Optimality of Estimating the Wasserstein Metric", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the minimax optimal rate for estimating the Wasserstein-$1$ metric\nbetween two unknown probability measures based on $n$ i.i.d. empirical samples\nfrom them. We show that estimating the Wasserstein metric itself between\nprobability measures, is not significantly easier than estimating the\nprobability measures under the Wasserstein metric. We prove that the minimax\noptimal rates for these two problems are multiplicatively equivalent, up to a\n$\\log \\log (n)/\\log (n)$ factor.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 16:56:35 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Liang", "Tengyuan", ""]]}, {"id": "1908.10331", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Donghyeon Lee, Seonghan Ryu, Sungja Choi,\n  Inchul Hwang, Jihie Kim", "title": "Deep Reinforcement Learning for Chatbots Using Clustered Actions and\n  Human-Likeness Rewards", "comments": "In International Joint Conference of Neural Networks (IJCNN), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training chatbots using the reinforcement learning paradigm is challenging\ndue to high-dimensional states, infinite action spaces and the difficulty in\nspecifying the reward function. We address such problems using clustered\nactions instead of infinite actions, and a simple but promising reward function\nbased on human-likeness scores derived from human-human dialogue data. We train\nDeep Reinforcement Learning (DRL) agents using chitchat data in raw\ntext---without any manual annotations. Experimental results using different\nsplits of training data report the following. First, that our agents learn\nreasonable policies in the environments they get familiarised with, but their\nperformance drops substantially when they are exposed to a test set of unseen\ndialogues. Second, that the choice of sentence embedding size between 100 and\n300 dimensions is not significantly different on test data. Third, that our\nproposed human-likeness rewards are reasonable for training chatbots as long as\nthey use lengthy dialogue histories of >=10 sentences.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:06:15 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Lee", "Donghyeon", ""], ["Ryu", "Seonghan", ""], ["Choi", "Sungja", ""], ["Hwang", "Inchul", ""], ["Kim", "Jihie", ""]]}, {"id": "1908.10335", "submitter": "Raoul de Charette", "authors": "Shirsendu Sukanta Halder, Jean-Fran\\c{c}ois Lalonde, Raoul de Charette", "title": "Physics-Based Rendering for Improving Robustness to Rain", "comments": "ICCV 2019. Supplementary pdf / videos available on project page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the robustness to rain, we present a physically-based rain\nrendering pipeline for realistically inserting rain into clear weather images.\nOur rendering relies on a physical particle simulator, an estimation of the\nscene lighting and an accurate rain photometric modeling to augment images with\narbitrary amount of realistic rain or fog. We validate our rendering with a\nuser study, proving our rain is judged 40% more realistic that\nstate-of-the-art. Using our generated weather augmented Kitti and Cityscapes\ndataset, we conduct a thorough evaluation of deep object detection and semantic\nsegmentation algorithms and show that their performance decreases in degraded\nweather, on the order of 15% for object detection and 60% for semantic\nsegmentation. Furthermore, we show refining existing networks with our\naugmented images improves the robustness of both object detection and semantic\nsegmentation algorithms. We experiment on nuScenes and measure an improvement\nof 15% for object detection and 35% for semantic segmentation compared to\noriginal rainy performance. Augmented databases and code are available on the\nproject page.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:13:46 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Halder", "Shirsendu Sukanta", ""], ["Lalonde", "Jean-Fran\u00e7ois", ""], ["de Charette", "Raoul", ""]]}, {"id": "1908.10336", "submitter": "William Schoenberg", "authors": "William Schoenberg", "title": "Feedback System Neural Networks for Inferring Causality in Directed\n  Cyclic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new causal network learning algorithm (FSNN, Feedback\nSystem Neural Network) based on the construction and analysis of a non-linear\nsystem of Ordinary Differential Equations (ODEs). The constructed system\nprovides insight into the mechanisms responsible for generating the past and\npotential future behavior of dynamic systems. It is also interpretable in terms\nof real system variables, providing a wholistic, causally accurate, and\nsystemic understanding of the real-life interactions governing observed\nphenomena. This paper demonstrates the generation of an n-dimensional ordinary\ndifferential equation model that can be parameterized to fit measured data\nusing standard numerical optimization techniques. The model makes use of feed\nforward artificial neural nets to capture nonlinearity, but is a parsimonious\nand interpretable representation of the network of causal relationships in\ncomplex systems. The generated model can easily and rapidly be experimented\nwith and analyzed to determine the origins of behavior using the loops that\nmatter method (Schoenberg et. al 2019). A demonstration of the utility and\napplicability of the method is given, showing that it produces an accurate, and\ncausally correct model for a three state, non-linear, complex dynamic system of\nknown origin. Generalization to other dynamic systems with other data sources\nis then discussed.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:15:42 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 22:23:28 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Schoenberg", "William", ""]]}, {"id": "1908.10341", "submitter": "Marco Broccardo", "authors": "Ziqi Wang, Marco Broccardo", "title": "A novel active learning-based Gaussian process metamodelling strategy\n  for estimating the full probability distribution in forward UQ analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an active learning-based Gaussian process (AL-GP)\nmetamodelling method to estimate the cumulative as well as complementary\ncumulative distribution function (CDF/CCDF) for forward uncertainty\nquantification (UQ) problems. Within the field of UQ, previous studies focused\non developing AL-GP approaches for reliability (rare event probability)\nanalysis of expensive black-box solvers. A naive iteration of these algorithms\nwith respect to different CDF/CCDF threshold values would yield a discretized\nCDF/CCDF. However, this approach inevitably leads to a trade-off between\naccuracy and computational efficiency since both depend (in opposite way) on\nthe selected discretization. In this study, a specialized error measure and a\nlearning function are developed such that the resulting AL-GP method is able to\nefficiently estimate the CDF/CCDF for a specified range of interest without an\nexplicit dependency on discretization. Particularly, the proposed AL-GP method\nis able to simultaneously provide accurate CDF and CCDF estimation in their\nmedian-low probability regions. Three numerical examples are introduced to test\nand verify the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:25:01 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Wang", "Ziqi", ""], ["Broccardo", "Marco", ""]]}, {"id": "1908.10349", "submitter": "Jiunn-Kai Huang", "authors": "Jiunn-Kai Huang, Shoutian Wang, Maani Ghaffari, and Jessy W. Grizzle", "title": "LiDARTag: A Real-Time Fiducial Tag System for Point Clouds", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters, 31 March 2021", "doi": "10.1109/LRA.2021.3070302", "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image-based fiducial markers are useful in problems such as object tracking\nin cluttered or textureless environments, camera (and multi-sensor) calibration\ntasks, and vision-based simultaneous localization and mapping (SLAM). The\nstate-of-the-art fiducial marker detection algorithms rely on the consistency\nof the ambient lighting. This paper introduces LiDARTag, a novel fiducial tag\ndesign and detection algorithm suitable for light detection and ranging (LiDAR)\npoint clouds. The proposed method runs in real-time and can process data at 100\nHz, which is faster than the currently available LiDAR sensor frequencies.\nBecause of the LiDAR sensors' nature, rapidly changing ambient lighting will\nnot affect the detection of a LiDARTag; hence, the proposed fiducial marker can\noperate in a completely dark environment. In addition, the LiDARTag nicely\ncomplements and is compatible with existing visual fiducial markers, such as\nAprilTags, allowing for efficient multi-sensor fusion and calibration tasks. We\nfurther propose a concept of minimizing a fitting error between a point cloud\nand the marker's template to estimate the marker's pose. The proposed method\nachieves millimeter error in translation and a few degrees in rotation. Due to\nLiDAR returns' sparsity, the point cloud is lifted to a continuous function in\na reproducing kernel Hilbert space where the inner product can be used to\ndetermine a marker's ID. The experimental results, verified by a motion capture\nsystem, confirm that the proposed method can reliably provide a tag's pose and\nunique ID code. The rejection of false positives is validated on the Google\nCartographer indoor dataset and the Honda H3D outdoor dataset. All\nimplementations are coded in C++ and are available at:\nhttps://github.com/UMich-BipedLab/LiDARTag.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 22:10:39 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 20:07:16 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 22:33:19 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Huang", "Jiunn-Kai", ""], ["Wang", "Shoutian", ""], ["Ghaffari", "Maani", ""], ["Grizzle", "Jessy W.", ""]]}, {"id": "1908.10357", "submitter": "Bowen Cheng", "authors": "Bowen Cheng, Bin Xiao, Jingdong Wang, Honghui Shi, Thomas S. Huang,\n  and Lei Zhang", "title": "HigherHRNet: Scale-Aware Representation Learning for Bottom-Up Human\n  Pose Estimation", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bottom-up human pose estimation methods have difficulties in predicting the\ncorrect pose for small persons due to challenges in scale variation. In this\npaper, we present HigherHRNet: a novel bottom-up human pose estimation method\nfor learning scale-aware representations using high-resolution feature\npyramids. Equipped with multi-resolution supervision for training and\nmulti-resolution aggregation for inference, the proposed approach is able to\nsolve the scale variation challenge in bottom-up multi-person pose estimation\nand localize keypoints more precisely, especially for small person. The feature\npyramid in HigherHRNet consists of feature map outputs from HRNet and upsampled\nhigher-resolution outputs through a transposed convolution. HigherHRNet\noutperforms the previous best bottom-up method by 2.5% AP for medium person on\nCOCO test-dev, showing its effectiveness in handling scale variation.\nFurthermore, HigherHRNet achieves new state-of-the-art result on COCO test-dev\n(70.5% AP) without using refinement or other post-processing techniques,\nsurpassing all existing bottom-up methods. HigherHRNet even surpasses all\ntop-down methods on CrowdPose test (67.6% AP), suggesting its robustness in\ncrowded scene. The code and models are available at\nhttps://github.com/HRNet/Higher-HRNet-Human-Pose-Estimation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:54:08 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 05:51:01 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 16:13:53 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Cheng", "Bowen", ""], ["Xiao", "Bin", ""], ["Wang", "Jingdong", ""], ["Shi", "Honghui", ""], ["Huang", "Thomas S.", ""], ["Zhang", "Lei", ""]]}, {"id": "1908.10382", "submitter": "Rishit Sheth", "authors": "Rishit Sheth, Nicolo Fusi", "title": "Feature Gradients: Scalable Feature Selection via Discrete Relaxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce Feature Gradients, a gradient-based search\nalgorithm for feature selection. Our approach extends a recent result on the\nestimation of learnability in the sublinear data regime by showing that the\ncalculation can be performed iteratively (i.e., in mini-batches) and in linear\ntime and space with respect to both the number of features D and the sample\nsize N . This, along with a discrete-to-continuous relaxation of the search\ndomain, allows for an efficient, gradient-based search algorithm among feature\nsubsets for very large datasets. Crucially, our algorithm is capable of finding\nhigher-order correlations between features and targets for both the N > D and N\n< D regimes, as opposed to approaches that do not consider such interactions\nand/or only consider one regime. We provide experimental demonstration of the\nalgorithm in small and large sample-and feature-size settings.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:02:11 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Sheth", "Rishit", ""], ["Fusi", "Nicolo", ""]]}, {"id": "1908.10396", "submitter": "Ruiqi Guo", "authors": "Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix\n  Chern, Sanjiv Kumar", "title": "Accelerating Large-Scale Inference with Anisotropic Vector Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization based techniques are the current state-of-the-art for scaling\nmaximum inner product search to massive databases. Traditional approaches to\nquantization aim to minimize the reconstruction error of the database points.\nBased on the observation that for a given query, the database points that have\nthe largest inner products are more relevant, we develop a family of\nanisotropic quantization loss functions. Under natural statistical assumptions,\nwe show that quantization with these loss functions leads to a new variant of\nvector quantization that more greatly penalizes the parallel component of a\ndatapoint's residual relative to its orthogonal component. The proposed\napproach achieves state-of-the-art results on the public benchmarks available\nat \\url{ann-benchmarks.com}.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:27:17 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 20:41:46 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 20:17:08 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 22:24:16 GMT"}, {"version": "v5", "created": "Fri, 4 Dec 2020 21:29:31 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Guo", "Ruiqi", ""], ["Sun", "Philip", ""], ["Lindgren", "Erik", ""], ["Geng", "Quan", ""], ["Simcha", "David", ""], ["Chern", "Felix", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1908.10398", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl", "title": "A Data-Efficient Deep Learning Approach for Deployable Multimodal Social\n  Robots", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2018.09.104", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep supervised and reinforcement learning paradigms (among others) have\nthe potential to endow interactive multimodal social robots with the ability of\nacquiring skills autonomously. But it is still not very clear yet how they can\nbe best deployed in real world applications. As a step in this direction, we\npropose a deep learning-based approach for efficiently training a humanoid\nrobot to play multimodal games---and use the game of `Noughts & Crosses' with\ntwo variants as a case study. Its minimum requirements for learning to perceive\nand interact are based on a few hundred example images, a few example\nmultimodal dialogues and physical demonstrations of robot manipulation, and\nautomatic simulations. In addition, we propose novel algorithms for robust\nvisual game tracking and for competitive policy learning with high winning\nrates, which substantially outperform DQN-based baselines. While an automatic\nevaluation shows evidence that the proposed approach can be easily extended to\nnew games with competitive robot behaviours, a human evaluation with 130 humans\nplaying with the Pepper robot confirms that highly accurate visual perception\nis required for successful game play.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:30:49 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""]]}, {"id": "1908.10400", "submitter": "Alireza Fallah", "authors": "Alireza Fallah, Aryan Mokhtari, Asuman Ozdaglar", "title": "On the Convergence Theory of Gradient-Based Model-Agnostic Meta-Learning\n  Algorithms", "comments": "To appear in the proceedings of the $23^{rd}$ International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence of a class of gradient-based Model-Agnostic\nMeta-Learning (MAML) methods and characterize their overall complexity as well\nas their best achievable accuracy in terms of gradient norm for nonconvex loss\nfunctions. We start with the MAML method and its first-order approximation\n(FO-MAML) and highlight the challenges that emerge in their analysis. By\novercoming these challenges not only we provide the first theoretical\nguarantees for MAML and FO-MAML in nonconvex settings, but also we answer some\nof the unanswered questions for the implementation of these algorithms\nincluding how to choose their learning rate and the batch size for both tasks\nand datasets corresponding to tasks. In particular, we show that MAML can find\nan $\\epsilon$-first-order stationary point ($\\epsilon$-FOSP) for any positive\n$\\epsilon$ after at most $\\mathcal{O}(1/\\epsilon^2)$ iterations at the expense\nof requiring second-order information. We also show that FO-MAML which ignores\nthe second-order information required in the update of MAML cannot achieve any\nsmall desired level of accuracy, i.e., FO-MAML cannot find an $\\epsilon$-FOSP\nfor any $\\epsilon>0$. We further propose a new variant of the MAML algorithm\ncalled Hessian-free MAML which preserves all theoretical guarantees of MAML,\nwithout requiring access to second-order information.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:36:10 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 03:21:03 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 00:38:45 GMT"}, {"version": "v4", "created": "Sat, 16 May 2020 01:46:37 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Fallah", "Alireza", ""], ["Mokhtari", "Aryan", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "1908.10402", "submitter": "Huozhi Zhou", "authors": "Huozhi Zhou, Lingda Wang, Lav R. Varshney, Ee-Peng Lim", "title": "A Near-Optimal Change-Detection Based Algorithm for Piecewise-Stationary\n  Combinatorial Semi-Bandits", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the piecewise-stationary combinatorial semi-bandit problem.\nCompared to the original combinatorial semi-bandit problem, our setting assumes\nthe reward distributions of base arms may change in a piecewise-stationary\nmanner at unknown time steps. We propose an algorithm, \\texttt{GLR-CUCB}, which\nincorporates an efficient combinatorial semi-bandit algorithm, \\texttt{CUCB},\nwith an almost parameter-free change-point detector, the \\emph{Generalized\nLikelihood Ratio Test} (GLRT). Our analysis shows that the regret of\n\\texttt{GLR-CUCB} is upper bounded by $\\mathcal{O}(\\sqrt{NKT\\log{T}})$, where\n$N$ is the number of piecewise-stationary segments, $K$ is the number of base\narms, and $T$ is the number of time steps. As a complement, we also derive a\nnearly matching regret lower bound on the order of $\\Omega(\\sqrt{NKT}$), for\nboth piecewise-stationary multi-armed bandits and combinatorial semi-bandits,\nusing information-theoretic techniques and judiciously constructed\npiecewise-stationary bandit instances. Our lower bound is tighter than the best\navailable regret lower bound, which is $\\Omega(\\sqrt{T})$. Numerical\nexperiments on both synthetic and real-world datasets demonstrate the\nsuperiority of \\texttt{GLR-CUCB} compared to other state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:37:16 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 02:18:16 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 15:55:02 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 17:45:27 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhou", "Huozhi", ""], ["Wang", "Lingda", ""], ["Varshney", "Lav R.", ""], ["Lim", "Ee-Peng", ""]]}, {"id": "1908.10407", "submitter": "Cosmin Anitescu", "authors": "Esteban Samaniego, Cosmin Anitescu, Somdatta Goswami, Vien Minh\n  Nguyen-Thanh, Hongwei Guo, Khader Hamdia, Timon Rabczuk, Xiaoying Zhuang", "title": "An Energy Approach to the Solution of Partial Differential Equations in\n  Computational Mechanics via Machine Learning: Concepts, Implementation and\n  Applications", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2019.112790", "report-no": null, "categories": "stat.ML cs.LG math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial Differential Equations (PDE) are fundamental to model different\nphenomena in science and engineering mathematically. Solving them is a crucial\nstep towards a precise knowledge of the behaviour of natural and engineered\nsystems. In general, in order to solve PDEs that represent real systems to an\nacceptable degree, analytical methods are usually not enough. One has to resort\nto discretization methods. For engineering problems, probably the best known\noption is the finite element method (FEM). However, powerful alternatives such\nas mesh-free methods and Isogeometric Analysis (IGA) are also available. The\nfundamental idea is to approximate the solution of the PDE by means of\nfunctions specifically built to have some desirable properties. In this\ncontribution, we explore Deep Neural Networks (DNNs) as an option for\napproximation. They have shown impressive results in areas such as visual\nrecognition. DNNs are regarded here as function approximation machines. There\nis great flexibility to define their structure and important advances in the\narchitecture and the efficiency of the algorithms to implement them make DNNs a\nvery interesting alternative to approximate the solution of a PDE. We\nconcentrate in applications that have an interest for Computational Mechanics.\nMost contributions that have decided to explore this possibility have adopted a\ncollocation strategy. In this contribution, we concentrate in mechanical\nproblems and analyze the energetic format of the PDE. The energy of a\nmechanical system seems to be the natural loss function for a machine learning\nmethod to approach a mechanical problem. As proofs of concept, we deal with\nseveral problems and explore the capabilities of the method for applications in\nengineering.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:50:50 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 10:43:50 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Samaniego", "Esteban", ""], ["Anitescu", "Cosmin", ""], ["Goswami", "Somdatta", ""], ["Nguyen-Thanh", "Vien Minh", ""], ["Guo", "Hongwei", ""], ["Hamdia", "Khader", ""], ["Rabczuk", "Timon", ""], ["Zhuang", "Xiaoying", ""]]}, {"id": "1908.10408", "submitter": "Vikas Garg", "authors": "Vikas K. Garg and Inderjit S. Dhillon and Hsiang-Fu Yu", "title": "Multiresolution Transformer Networks: Recurrence is Not Essential for\n  Modeling Hierarchical Structure", "comments": "Initial version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The architecture of Transformer is based entirely on self-attention, and has\nbeen shown to outperform models that employ recurrence on sequence transduction\ntasks such as machine translation. The superior performance of Transformer has\nbeen attributed to propagating signals over shorter distances, between\npositions in the input and the output, compared to the recurrent architectures.\nWe establish connections between the dynamics in Transformer and recurrent\nnetworks to argue that several factors including gradient flow along an\nensemble of multiple weakly dependent paths play a paramount role in the\nsuccess of Transformer. We then leverage the dynamics to introduce {\\em\nMultiresolution Transformer Networks} as the first architecture that exploits\nhierarchical structure in data via self-attention. Our models significantly\noutperform state-of-the-art recurrent and hierarchical recurrent models on two\nreal-world datasets for query suggestion, namely, \\aol and \\amazon. In\nparticular, on AOL data, our model registers at least 20\\% improvement on each\nprecision score, and over 25\\% improvement on the BLEU score with respect to\nthe best performing recurrent model. We thus provide strong evidence that\nrecurrence is not essential for modeling hierarchical structure.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:51:50 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Garg", "Vikas K.", ""], ["Dhillon", "Inderjit S.", ""], ["Yu", "Hsiang-Fu", ""]]}, {"id": "1908.10417", "submitter": "Corneliu Arsene Dr", "authors": "Corneliu Arsene", "title": "Complex Deep Learning Models for Denoising of Human Heart ECG signals", "comments": "51 pages, 23 figures", "journal-ref": "EUSIPCO.2019 (Pages 11- 18)", "doi": "10.5281/zenodo.3904247", "report-no": null, "categories": "cs.LG cs.CV eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Effective and powerful methods for denoising real electrocardiogram (ECG)\nsignals are important for wearable sensors and devices. Deep Learning (DL)\nmodels have been used extensively in image processing and other domains with\ngreat success but only very recently have been used in processing ECG signals.\nThis paper presents several DL models namely Convolutional Neural Networks\n(CNNs), Long Short-Term Memory (LSTM), Restricted Boltzmann Machine (RBM)\ntogether with the more conventional filtering methods (low pass filtering, high\npass filtering, Notch filtering) and the standard wavelet-based technique for\ndenoising EEG signals. These methods are trained, tested and evaluated on\ndifferent synthetic and real ECG datasets taken from the MIT PhysioNet database\nand for different simulation conditions (i.e. various lengths of the ECG\nsignals, single or multiple records). The results show the CNN model is a\nperformant model that can be used for off-line denoising ECG applications where\nit is satisfactory to train on a clean part of an ECG signal from an ECG\nrecord, and then to test on the same ECG signal, which would have some high\nlevel of noise added to it. However, for real-time applications or near-real\ntime applications, this task becomes more cumbersome, as the clean part of an\nECG signal is very probable to be very limited in size. Therefore the solution\nput forth in this work is to train a CNN model on 1 second ECG noisy artificial\nmultiple heartbeat data (i.e. ECG at effort), which was generated in a first\ninstance based on few sequences of real signal heartbeat ECG data (i.e. ECG at\nrest). Afterwards it would be possible to use the trained CNN model in real\nlife situations to denoise the ECG signal.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 19:14:32 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 13:44:56 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 10:14:02 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Arsene", "Corneliu", ""]]}, {"id": "1908.10419", "submitter": "Yuning Mao", "authors": "Yuning Mao, Jingjing Tian, Jiawei Han, Xiang Ren", "title": "Hierarchical Text Classification with Reinforced Label Assignment", "comments": "EMNLP 2019", "journal-ref": null, "doi": "10.18653/v1/D19-1042", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While existing hierarchical text classification (HTC) methods attempt to\ncapture label hierarchies for model training, they either make local decisions\nregarding each label or completely ignore the hierarchy information during\ninference. To solve the mismatch between training and inference as well as\nmodeling label dependencies in a more principled way, we formulate HTC as a\nMarkov decision process and propose to learn a Label Assignment Policy via deep\nreinforcement learning to determine where to place an object and when to stop\nthe assignment process. The proposed method, HiLAP, explores the hierarchy\nduring both training and inference time in a consistent manner and makes\ninter-dependent decisions. As a general framework, HiLAP can incorporate\ndifferent neural encoders as base models for end-to-end training. Experiments\non five public datasets and four base models show that HiLAP yields an average\nimprovement of 33.4% in Macro-F1 over flat classifiers and outperforms\nstate-of-the-art HTC methods by a large margin. Data and code can be found at\nhttps://github.com/morningmoni/HiLAP.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 19:15:26 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Mao", "Yuning", ""], ["Tian", "Jingjing", ""], ["Han", "Jiawei", ""], ["Ren", "Xiang", ""]]}, {"id": "1908.10422", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Donghyeon Lee, Seonghan Ryu, Yongjin Cho,\n  Sungja Choi, Satish Indurthi, Seunghak Yu, Hyungtak Choi, Inchul Hwang, Jihie\n  Kim", "title": "Ensemble-Based Deep Reinforcement Learning for Chatbots", "comments": "arXiv admin note: text overlap with arXiv:1908.10331", "journal-ref": null, "doi": "10.1016/j.neucom.2019.08.007", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trainable chatbots that exhibit fluent and human-like conversations remain a\nbig challenge in artificial intelligence. Deep Reinforcement Learning (DRL) is\npromising for addressing this challenge, but its successful application remains\nan open question. This article describes a novel ensemble-based approach\napplied to value-based DRL chatbots, which use finite action sets as a form of\nmeaning representation. In our approach, while dialogue actions are derived\nfrom sentence clustering, the training datasets in our ensemble are derived\nfrom dialogue clustering. The latter aim to induce specialised agents that\nlearn to interact in a particular style. In order to facilitate neural chatbot\ntraining using our proposed approach, we assume dialogue data in raw text only\n-- without any manually-labelled data. Experimental results using chitchat data\nreveal that (1) near human-like dialogue policies can be induced, (2)\ngeneralisation to unseen data is a difficult problem, and (3) training an\nensemble of chatbot agents is essential for improved performance over using a\nsingle agent. In addition to evaluations using held-out data, our results are\nfurther supported by a human evaluation that rated dialogues in terms of\nfluency, engagingness and consistency -- which revealed that our proposed\ndialogue rewards strongly correlate with human judgements.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 19:18:09 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Lee", "Donghyeon", ""], ["Ryu", "Seonghan", ""], ["Cho", "Yongjin", ""], ["Choi", "Sungja", ""], ["Indurthi", "Satish", ""], ["Yu", "Seunghak", ""], ["Choi", "Hyungtak", ""], ["Hwang", "Inchul", ""], ["Kim", "Jihie", ""]]}, {"id": "1908.10449", "submitter": "Eric Yuan", "authors": "Xingdi Yuan, Jie Fu, Marc-Alexandre Cote, Yi Tay, Christopher Pal,\n  Adam Trischler", "title": "Interactive Machine Comprehension with Information Seeking Agents", "comments": "ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing machine reading comprehension (MRC) models do not scale effectively\nto real-world applications like web-level information retrieval and question\nanswering (QA). We argue that this stems from the nature of MRC datasets: most\nof these are static environments wherein the supporting documents and all\nnecessary information are fully observed. In this paper, we propose a simple\nmethod that reframes existing MRC datasets as interactive, partially observable\nenvironments. Specifically, we \"occlude\" the majority of a document's text and\nadd context-sensitive commands that reveal \"glimpses\" of the hidden text to a\nmodel. We repurpose SQuAD and NewsQA as an initial case study, and then show\nhow the interactive corpora can be used to train a model that seeks relevant\ninformation through sequential decision making. We believe that this setting\ncan contribute in scaling models to web-level QA scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 20:11:54 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 17:51:00 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 17:23:30 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Yuan", "Xingdi", ""], ["Fu", "Jie", ""], ["Cote", "Marc-Alexandre", ""], ["Tay", "Yi", ""], ["Pal", "Christopher", ""], ["Trischler", "Adam", ""]]}, {"id": "1908.10454", "submitter": "Nima Tajbakhsh", "authors": "Nima Tajbakhsh, Laura Jeyaseelan, Qian Li, Jeffrey Chiang, Zhihao Wu,\n  Xiaowei Ding", "title": "Embracing Imperfect Datasets: A Review of Deep Learning Solutions for\n  Medical Image Segmentation", "comments": "Accepted for publication in the journal of Medical Image Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The medical imaging literature has witnessed remarkable progress in\nhigh-performing segmentation models based on convolutional neural networks.\nDespite the new performance highs, the recent advanced segmentation models\nstill require large, representative, and high quality annotated datasets.\nHowever, rarely do we have a perfect training dataset, particularly in the\nfield of medical imaging, where data and annotations are both expensive to\nacquire. Recently, a large body of research has studied the problem of medical\nimage segmentation with imperfect datasets, tackling two major dataset\nlimitations: scarce annotations where only limited annotated data is available\nfor training, and weak annotations where the training data has only sparse\nannotations, noisy annotations, or image-level annotations. In this article, we\nprovide a detailed review of the solutions above, summarizing both the\ntechnical novelties and empirical results. We further compare the benefits and\nrequirements of the surveyed methodologies and provide our recommended\nsolutions. We hope this survey article increases the community awareness of the\ntechniques that are available to handle imperfect medical image segmentation\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 20:25:52 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 02:11:18 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Tajbakhsh", "Nima", ""], ["Jeyaseelan", "Laura", ""], ["Li", "Qian", ""], ["Chiang", "Jeffrey", ""], ["Wu", "Zhihao", ""], ["Ding", "Xiaowei", ""]]}, {"id": "1908.10479", "submitter": "Nevena Lazic", "authors": "Yasin Abbasi-Yadkori, Nevena Lazic, Csaba Szepesvari, Gellert Weisz", "title": "Exploration-Enhanced POLITEX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algorithms for average-cost reinforcement learning problems with\nvalue function approximation. Our starting point is the recently proposed\nPOLITEX algorithm, a version of policy iteration where the policy produced in\neach iteration is near-optimal in hindsight for the sum of all past value\nfunction estimates. POLITEX has sublinear regret guarantees in uniformly-mixing\nMDPs when the value estimation error can be controlled, which can be satisfied\nif all policies sufficiently explore the environment. Unfortunately, this\nassumption is often unrealistic. Motivated by the rapid growth of interest in\ndeveloping policies that learn to explore their environment in the lack of\nrewards (also known as no-reward learning), we replace the previous assumption\nthat all policies explore the environment with that a single, sufficiently\nexploring policy is available beforehand. The main contribution of the paper is\nthe modification of POLITEX to incorporate such an exploration policy in a way\nthat allows us to obtain a regret guarantee similar to the previous one but\nwithout requiring that all policies explore environment. In addition to the\nnovel theoretical guarantees, we demonstrate the benefits of our scheme on\nenvironments which are difficult to explore using simple schemes like\ndithering. While the solution we obtain may not achieve the best possible\nregret, it is the first result that shows how to control the regret in the\npresence of function approximation errors on problems where exploration is\nnontrivial. Our approach can also be seen as a way of reducing the problem of\nminimizing the regret to learning a good exploration policy. We believe that\nmodular approaches like ours can be highly beneficial in tackling harder\ncontrol problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 21:53:42 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Abbasi-Yadkori", "Yasin", ""], ["Lazic", "Nevena", ""], ["Szepesvari", "Csaba", ""], ["Weisz", "Gellert", ""]]}, {"id": "1908.10481", "submitter": "Md Rafiqul Islam Rabin", "authors": "Md Rafiqul Islam Rabin, Mohammad Amin Alipour", "title": "K-CONFIG: Using Failing Test Cases to Generate Test Cases in GCC\n  Compilers", "comments": "ASE 2019 Late Breaking Results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correctness of compilers is instrumental in the safety and reliability of\nother software systems, as bugs in compilers can produce programs that do not\nreflect the intents of programmers. Compilers are complex software systems due\nto the complexity of optimization. GCC is an optimizing C compiler that has\nbeen used in building operating systems and many other system software. In this\npaper, we describe K-CONFIG, an approach that uses the bugs reported in the GCC\nrepository to generate new test inputs. Our main insight is that the features\nappearing in the bug reports are likely to reappear in the future bugs, as the\nbugfixes can be incomplete or those features may be inherently challenging to\nimplement hence more prone to errors. Our approach first clusters the failing\ntest input extracted from the bug reports into clusters of similar test inputs.\nIt then uses these clusters to create configurations for Csmith, the most\npopular test generator for C compilers. In our experiments on two versions of\nGCC, our approach could trigger up to 36 miscompilation failures, and 179\ncrashes, while Csmith with the default configuration did not trigger any\nfailures. This work signifies the benefits of analyzing and using the reported\nbugs in the generation of new test inputs.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 22:09:00 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Rabin", "Md Rafiqul Islam", ""], ["Alipour", "Mohammad Amin", ""]]}, {"id": "1908.10489", "submitter": "Junlin Yang", "authors": "Junlin Yang, Nicha C. Dvornek, Fan Zhang, Juntang Zhuang, Julius\n  Chapiro, MingDe Lin, James S. Duncan", "title": "Domain-Agnostic Learning with Anatomy-Consistent Embedding for\n  Cross-Modality Liver Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain Adaptation (DA) has the potential to greatly help the generalization\nof deep learning models. However, the current literature usually assumes to\ntransfer the knowledge from the source domain to a specific known target\ndomain. Domain Agnostic Learning (DAL) proposes a new task of transferring\nknowledge from the source domain to data from multiple heterogeneous target\ndomains. In this work, we propose the Domain-Agnostic Learning framework with\nAnatomy-Consistent Embedding (DALACE) that works on both domain-transfer and\ntask-transfer to learn a disentangled representation, aiming to not only be\ninvariant to different modalities but also preserve anatomical structures for\nthe DA and DAL tasks in cross-modality liver segmentation. We validated and\ncompared our model with state-of-the-art methods, including CycleGAN, Task\nDriven Generative Adversarial Network (TD-GAN), and Domain Adaptation via\nDisentangled Representations (DADR). For the DA task, our DALACE model\noutperformed CycleGAN, TD-GAN ,and DADR with DSC of 0.847 compared to 0.721,\n0.793 and 0.806. For the DAL task, our model improved the performance with DSC\nof 0.794 from 0.522, 0.719 and 0.742 by CycleGAN, TD-GAN, and DADR. Further, we\nvisualized the success of disentanglement, which added human interpretability\nof the learned meaningful representations. Through ablation analysis, we\nspecifically showed the concrete benefits of disentanglement for downstream\ntasks and the role of supervision for better disentangled representation with\nsegmentation consistency to be invariant to domains with the proposed\nDomain-Agnostic Module (DAM) and to preserve anatomical information with the\nproposed Anatomy-Preserving Module (APM).\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 22:44:41 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yang", "Junlin", ""], ["Dvornek", "Nicha C.", ""], ["Zhang", "Fan", ""], ["Zhuang", "Juntang", ""], ["Chapiro", "Julius", ""], ["Lin", "MingDe", ""], ["Duncan", "James S.", ""]]}, {"id": "1908.10493", "submitter": "Zhongkui Ma", "authors": "Zhongkui Ma", "title": "The Function Representation of Artificial Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper expresses the structure of artificial neural network (ANN) as a\nfunctional form, using the activation integral concept derived from the\nactivation function. In this way, the structure of ANN can be represented by a\nsimple function, and it is possible to find the mathematical solutions of ANN.\nThus, it can be recognized that the current ANN can be placed in a more\nreasonable framework. Perhaps all questions about ANN will be eliminated.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 23:20:34 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 00:29:01 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ma", "Zhongkui", ""]]}, {"id": "1908.10498", "submitter": "George Kesidis", "authors": "Zhen Xiang, David J. Miller, George Kesidis", "title": "Detection of Backdoors in Trained Classifiers Without Access to the\n  Training Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a special type of data poisoning (DP) attack targeting Deep Neural\nNetwork (DNN) classifiers, known as a backdoor, was proposed. These attacks do\nnot seek to degrade classification accuracy, but rather to have the classifier\nlearn to classify to a target class whenever the backdoor pattern is present in\na test example. Launching backdoor attacks does not require knowledge of the\nclassifier or its training process - it only needs the ability to poison the\ntraining set with (a sufficient number of) exemplars containing a sufficiently\nstrong backdoor pattern (labeled with the target class). Here we address\npost-training detection of backdoor attacks in DNN image classifiers, seldom\nconsidered in existing works, wherein the defender does not have access to the\npoisoned training set, but only to the trained classifier itself, as well as to\nclean examples from the classification domain. This is an important scenario\nbecause a trained classifier may be the basis of e.g. a phone app that will be\nshared with many users. Detecting backdoors post-training may thus reveal a\nwidespread attack. We propose a purely unsupervised anomaly detection (AD)\ndefense against imperceptible backdoor attacks that: i) detects whether the\ntrained DNN has been backdoor-attacked; ii) infers the source and target\nclasses involved in a detected attack; iii) we even demonstrate it is possible\nto accurately estimate the backdoor pattern. We test our AD approach, in\ncomparison with alternative defenses, for several backdoor patterns, data sets,\nand attack settings and demonstrate its favorability. Our defense essentially\nrequires setting a single hyperparameter (the detection threshold), which can\ne.g. be chosen to fix the system's false positive rate.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 23:51:43 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 23:57:04 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 15:52:35 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Xiang", "Zhen", ""], ["Miller", "David J.", ""], ["Kesidis", "George", ""]]}, {"id": "1908.10506", "submitter": "Donghui Yan", "authors": "Donghui Yan, Songxiang Gu, Ying Xu and Zhiwei Qin", "title": "Similarity Kernel and Clustering via Random Projection Forests", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity plays a fundamental role in many areas, including data mining,\nmachine learning, statistics and various applied domains. Inspired by the\nsuccess of ensemble methods and the flexibility of trees, we propose to learn a\nsimilarity kernel called rpf-kernel through random projection forests\n(rpForests). Our theoretical analysis reveals a highly desirable property of\nrpf-kernel: far-away (dissimilar) points have a low similarity value while\nnearby (similar) points would have a high similarity}, and the similarities\nhave a native interpretation as the probability of points remaining in the same\nleaf nodes during the growth of rpForests. The learned rpf-kernel leads to an\neffective clustering algorithm--rpfCluster. On a wide variety of real and\nbenchmark datasets, rpfCluster compares favorably to K-means clustering,\nspectral clustering and a state-of-the-art clustering ensemble\nalgorithm--Cluster Forests. Our approach is simple to implement and readily\nadapt to the geometry of the underlying data. Given its desirable theoretical\nproperty and competitive empirical performance when applied to clustering, we\nexpect rpf-kernel to be applicable to many problems of an unsupervised nature\nor as a regularizer in some supervised or weakly supervised settings.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 00:38:53 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yan", "Donghui", ""], ["Gu", "Songxiang", ""], ["Xu", "Ying", ""], ["Qin", "Zhiwei", ""]]}, {"id": "1908.10508", "submitter": "Alex Gaudio", "authors": "Asim Smailagic, Pedro Costa, Alex Gaudio, Kartik Khandelwal, Mostafa\n  Mirshekari, Jonathon Fagert, Devesh Walawalkar, Susu Xu, Adrian Galdran, Pei\n  Zhang, Aur\\'elio Campilho, Hae Young Noh", "title": "O-MedAL: Online Active Deep Learning for Medical Image Analysis", "comments": "Code: https://github.com/adgaudio/o-medal ; Accepted and published by\n  Wiley Journal of Pattern Recognition and Knowledge Discovery ; Journal URL:\n  https://doi.org/10.1002/widm.1353", "journal-ref": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge\n  Discovery 10.4 (2020): e1353", "doi": "10.1002/widm.1353", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Learning methods create an optimized labeled training set from\nunlabeled data. We introduce a novel Online Active Deep Learning method for\nMedical Image Analysis. We extend our MedAL active learning framework to\npresent new results in this paper. Our novel sampling method queries the\nunlabeled examples that maximize the average distance to all training set\nexamples. Our online method enhances performance of its underlying baseline\ndeep network. These novelties contribute significant performance improvements,\nincluding improving the model's underlying deep network accuracy by 6.30%,\nusing only 25% of the labeled dataset to achieve baseline accuracy, reducing\nbackpropagated images during training by as much as 67%, and demonstrating\nrobustness to class imbalance in binary and multi-class tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 00:48:12 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 20:53:28 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Smailagic", "Asim", ""], ["Costa", "Pedro", ""], ["Gaudio", "Alex", ""], ["Khandelwal", "Kartik", ""], ["Mirshekari", "Mostafa", ""], ["Fagert", "Jonathon", ""], ["Walawalkar", "Devesh", ""], ["Xu", "Susu", ""], ["Galdran", "Adrian", ""], ["Zhang", "Pei", ""], ["Campilho", "Aur\u00e9lio", ""], ["Noh", "Hae Young", ""]]}, {"id": "1908.10525", "submitter": "Yuege Xie", "authors": "Yuege Xie, Xiaoxia Wu, Rachel Ward", "title": "Linear Convergence of Adaptive Stochastic Gradient Descent", "comments": null, "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics, in PMLR 108:1475-1485 (2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the norm version of the adaptive stochastic gradient method\n(AdaGrad-Norm) achieves a linear convergence rate for a subset of either\nstrongly convex functions or non-convex functions that satisfy the Polyak\nLojasiewicz (PL) inequality. The paper introduces the notion of Restricted\nUniform Inequality of Gradients (RUIG)---which is a measure of the\nbalanced-ness of the stochastic gradient norms---to depict the landscape of a\nfunction. RUIG plays a key role in proving the robustness of AdaGrad-Norm to\nits hyper-parameter tuning in the stochastic setting. On top of RUIG, we\ndevelop a two-stage framework to prove the linear convergence of AdaGrad-Norm\nwithout knowing the parameters of the objective functions. This framework can\nlikely be extended to other adaptive stepsize algorithms. The numerical\nexperiments validate the theory and suggest future directions for improvement.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 02:42:50 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 05:05:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Xie", "Yuege", ""], ["Wu", "Xiaoxia", ""], ["Ward", "Rachel", ""]]}, {"id": "1908.10530", "submitter": "Kunal Talwar", "authors": "Ilya Mironov and Kunal Talwar and Li Zhang", "title": "R\\'enyi Differential Privacy of the Sampled Gaussian Mechanism", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sampled Gaussian Mechanism (SGM)---a composition of subsampling and the\nadditive Gaussian noise---has been successfully used in a number of machine\nlearning applications. The mechanism's unexpected power is derived from privacy\namplification by sampling where the privacy cost of a single evaluation\ndiminishes quadratically, rather than linearly, with the sampling rate.\nCharacterizing the precise privacy properties of SGM motivated development of\nseveral relaxations of the notion of differential privacy.\n  This work unifies and fills in gaps in published results on SGM. We describe\na numerically stable procedure for precise computation of SGM's R\\'enyi\nDifferential Privacy and prove a nearly tight (within a small constant factor)\nclosed-form bound.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 03:03:25 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Mironov", "Ilya", ""], ["Talwar", "Kunal", ""], ["Zhang", "Li", ""]]}, {"id": "1908.10552", "submitter": "Yuan Yao", "authors": "Yuan Yao, Yu Zhang, Xutao Li, Yunming Ye", "title": "Heterogeneous Domain Adaptation via Soft Transfer Network", "comments": "Accepted by ACM Multimedia (ACM MM) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous domain adaptation (HDA) aims to facilitate the learning task in\na target domain by borrowing knowledge from a heterogeneous source domain. In\nthis paper, we propose a Soft Transfer Network (STN), which jointly learns a\ndomain-shared classifier and a domain-invariant subspace in an end-to-end\nmanner, for addressing the HDA problem. The proposed STN not only aligns the\ndiscriminative directions of domains but also matches both the marginal and\nconditional distributions across domains. To circumvent negative transfer, STN\naligns the conditional distributions by using the soft-label strategy of\nunlabeled target data, which prevents the hard assignment of each unlabeled\ntarget data to only one category that may be incorrect. Further, STN introduces\nan adaptive coefficient to gradually increase the importance of the soft-labels\nsince they will become more and more accurate as the number of iterations\nincreases. We perform experiments on the transfer tasks of image-to-image,\ntext-to-image, and text-to-text. Experimental results testify that the STN\nsignificantly outperforms several state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 05:25:12 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yao", "Yuan", ""], ["Zhang", "Yu", ""], ["Li", "Xutao", ""], ["Ye", "Yunming", ""]]}, {"id": "1908.10555", "submitter": "Shuhao Wang", "authors": "Gang Xu, Zhigang Song, Zhuo Sun, Calvin Ku, Zhe Yang, Cancheng Liu,\n  Shuhao Wang, Jianpeng Ma, Wei Xu", "title": "CAMEL: A Weakly Supervised Learning Framework for Histopathology Image\n  Segmentation", "comments": "10 pages, 9 figures, accepted by ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histopathology image analysis plays a critical role in cancer diagnosis and\ntreatment. To automatically segment the cancerous regions, fully supervised\nsegmentation algorithms require labor-intensive and time-consuming labeling at\nthe pixel level. In this research, we propose CAMEL, a weakly supervised\nlearning framework for histopathology image segmentation using only image-level\nlabels. Using multiple instance learning (MIL)-based label enrichment, CAMEL\nsplits the image into latticed instances and automatically generates\ninstance-level labels. After label enrichment, the instance-level labels are\nfurther assigned to the corresponding pixels, producing the approximate\npixel-level labels and making fully supervised training of segmentation models\npossible. CAMEL achieves comparable performance with the fully supervised\napproaches in both instance-level classification and pixel-level segmentation\non CAMELYON16 and a colorectal adenoma dataset. Moreover, the generality of the\nautomatic labeling methodology may benefit future weakly supervised learning\nstudies for histopathology image analysis.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 05:32:07 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Xu", "Gang", ""], ["Song", "Zhigang", ""], ["Sun", "Zhuo", ""], ["Ku", "Calvin", ""], ["Yang", "Zhe", ""], ["Liu", "Cancheng", ""], ["Wang", "Shuhao", ""], ["Ma", "Jianpeng", ""], ["Xu", "Wei", ""]]}, {"id": "1908.10558", "submitter": "Benjamin Zi Hao Zhao", "authors": "Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Raghav Bhaskar, Mohamed\n  Ali Kaafar", "title": "On Inferring Training Data Attributes in Machine Learning Models", "comments": "Accepted by PPML'19, a CCS workshop. Submission of 4-pages bar\n  references, and appendix V2: Update in dataset splitting, and comments on\n  related works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of recent works have demonstrated that API access to machine\nlearning models leaks information about the dataset records used to train the\nmodels. Further, the work of \\cite{somesh-overfit} shows that such membership\ninference attacks (MIAs) may be sufficient to construct a stronger breed of\nattribute inference attacks (AIAs), which given a partial view of a record can\nguess the missing attributes. In this work, we show (to the contrary) that MIA\nmay not be sufficient to build a successful AIA. This is because the latter\nrequires the ability to distinguish between similar records (differing only in\na few attributes), and, as we demonstrate, the current breed of MIA are\nunsuccessful in distinguishing member records from similar non-member records.\nWe thus propose a relaxed notion of AIA, whose goal is to only approximately\nguess the missing attributes and argue that such an attack is more likely to be\nsuccessful, if MIA is to be used as a subroutine for inferring training record\nattributes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 05:42:14 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 06:47:30 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Zhao", "Benjamin Zi Hao", ""], ["Asghar", "Hassan Jameel", ""], ["Bhaskar", "Raghav", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "1908.10577", "submitter": "Yanan Wang", "authors": "Yanan Wang, Tong Xu, Xin Niu, Chang Tan, Enhong Chen, Hui Xiong", "title": "STMARL: A Spatio-Temporal Multi-Agent Reinforcement Learning Approach\n  for Cooperative Traffic Light Control", "comments": "Accepted to IEEE Transactions on Mobile Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of intelligent traffic light control systems is essential for\nsmart transportation management. While some efforts have been made to optimize\nthe use of individual traffic lights in an isolated way, related studies have\nlargely ignored the fact that the use of multi-intersection traffic lights is\nspatially influenced and there is a temporal dependency of historical traffic\nstatus for current traffic light control. To that end, in this paper, we\npropose a novel SpatioTemporal Multi-Agent Reinforcement Learning (STMARL)\nframework for effectively capturing the spatio-temporal dependency of multiple\nrelated traffic lights and control these traffic lights in a coordinating way.\nSpecifically, we first construct the traffic light adjacency graph based on the\nspatial structure among traffic lights. Then, historical traffic records will\nbe integrated with current traffic status via Recurrent Neural Network\nstructure. Moreover, based on the temporally-dependent traffic information, we\ndesign a Graph Neural Network based model to represent relationships among\nmultiple traffic lights, and the decision for each traffic light will be made\nin a distributed way by the deep Q-learning method. Finally, the experimental\nresults on both synthetic and real-world data have demonstrated the\neffectiveness of our STMARL framework, which also provides an insightful\nunderstanding of the influence mechanism among multi-intersection traffic\nlights.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 07:16:39 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 11:45:35 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 16:39:47 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Yanan", ""], ["Xu", "Tong", ""], ["Niu", "Xin", ""], ["Tan", "Chang", ""], ["Chen", "Enhong", ""], ["Xiong", "Hui", ""]]}, {"id": "1908.10606", "submitter": "Chao-Lin Liu", "authors": "Chao-Lin Liu and Yi Chang", "title": "Classical Chinese Sentence Segmentation for Tomb Biographies of Tang\n  Dynasty", "comments": "6 pages, 3 figures, 2 tables, presented at the 2019 International\n  Conference on Digital Humanities (ADHO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tomb biographies of the Tang dynasty provide invaluable information about\nChinese history. The original biographies are classical Chinese texts which\ncontain neither word boundaries nor sentence boundaries. Relying on three\npublished books of tomb biographies of the Tang dynasty, we investigated the\neffectiveness of employing machine-learning methods for algorithmically\nidentifying the pauses and terminals of sentences in the biographies.\n  We consider the segmentation task as a classification problem. Chinese\ncharacters that are and are not followed by a punctuation mark are classified\ninto two categories. We applied a machine-learning-based mechanism, the\nconditional random fields (CRF), to classify the characters (and words) in the\ntexts, and we studied the contributions of selected types of lexical\ninformation to the resulting quality of the segmentation recommendations.\n  This proposal presented at the DH 2018 conference discussed some of the basic\nexperiments and their evaluations. By considering the contextual information\nand employing the heuristics provided by experts of Chinese literature, we\nachieved F1 measures that were better than 80%. More complex experiments that\nemploy deep neural networks helped us further improve the results in recent\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 09:33:37 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Liu", "Chao-Lin", ""], ["Chang", "Yi", ""]]}, {"id": "1908.10611", "submitter": "Yuting Ye", "authors": "Yuting Ye, Xuwu Wang, Jiangchao Yao, Kunyang Jia, Jingren Zhou,\n  Yanghua Xiao, and Hongxia Yang", "title": "Bayes EMbedding (BEM): Refining Representation by Integrating Knowledge\n  Graphs and Behavior-specific Networks", "comments": "25 pages, 5 figures, 10 tables. CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-dimensional embeddings of knowledge graphs and behavior graphs have\nproved remarkably powerful in varieties of tasks, from predicting unobserved\nedges between entities to content recommendation. The two types of graphs can\ncontain distinct and complementary information for the same entities/nodes.\nHowever, previous works focus either on knowledge graph embedding or behavior\ngraph embedding while few works consider both in a unified way. Here we present\nBEM , a Bayesian framework that incorporates the information from knowledge\ngraphs and behavior graphs. To be more specific, BEM takes as prior the\npre-trained embeddings from the knowledge graph, and integrates them with the\npre-trained embeddings from the behavior graphs via a Bayesian generative\nmodel. BEM is able to mutually refine the embeddings from both sides while\npreserving their own topological structures. To show the superiority of our\nmethod, we conduct a range of experiments on three benchmark datasets: node\nclassification, link prediction, triplet classification on two small datasets\nrelated to Freebase, and item recommendation on a large-scale e-commerce\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 09:49:15 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Ye", "Yuting", ""], ["Wang", "Xuwu", ""], ["Yao", "Jiangchao", ""], ["Jia", "Kunyang", ""], ["Zhou", "Jingren", ""], ["Xiao", "Yanghua", ""], ["Yang", "Hongxia", ""]]}, {"id": "1908.10621", "submitter": "Chao-Lin Liu", "authors": "Chao-Lin Liu", "title": "Onto Word Segmentation of the Complete Tang Poems", "comments": "5 pages, 2 tables, presented at the 2019 International Conference on\n  Digital Humanities (ADHO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim at segmenting words in the Complete Tang Poems (CTP). Although it is\npossible to do some research about CTP without doing full-scale word\nsegmentation, we must move forward to word-level analysis of CTP for conducting\nadvanced research topics. In November 2018 when we submitted the manuscript for\nDH 2019 (ADHO), we collected only 2433 poems that were segmented by trained\nexperts, and used the segmented poems to evaluate the segmenter that considered\ndomain knowledge of Chinese poetry. We trained pointwise mutual information\n(PMI) between Chinese characters based on the CTP poems (excluding the 2433\npoems, which were used exclusively only for testing) and the domain knowledge.\nThe segmenter relied on the PMI information to the recover 85.7% of words in\nthe test poems. We could segment a poem completely correct only 17.8% of the\ntime, however. When we presented our work at DH 2019, we have annotated more\nthan 20000 poems. With a much larger amount of data, we were able to apply\nbiLSTM models for this word segmentation task, and we segmented a poem\ncompletely correct above 20% of the time. In contrast, human annotators\ncompletely agreed on their annotations about 40% of the time.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 10:06:19 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Liu", "Chao-Lin", ""]]}, {"id": "1908.10623", "submitter": "Fasih Haider Dr", "authors": "Fasih Haider, Senja Pollak, Pierre Albert, Saturnino Luz", "title": "Emotion Recognition in Low-Resource Settings: An Evaluation of Automatic\n  Feature Selection Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in automatic affect recognition has seldom addressed the issue of\ncomputational resource utilization. With the advent of ambient intelligence\ntechnology which employs a variety of low-power, resource-constrained devices,\nthis issue is increasingly gaining interest. This is especially the case in the\ncontext of health and elderly care technologies, where interventions may rely\non monitoring of emotional status to provide support or alert carers as\nappropriate. This paper focuses on emotion recognition from speech data, in\nsettings where it is desirable to minimize memory and computational\nrequirements. Reducing the number of features for inductive inference is a\nroute towards this goal. In this study, we evaluate three different\nstate-of-the-art feature selection methods: Infinite Latent Feature Selection\n(ILFS), ReliefF and Fisher (generalized Fisher score), and compare them to our\nrecently proposed feature selection method named `Active Feature Selection'\n(AFS). The evaluation is performed on three emotion recognition data sets\n(EmoDB, SAVEE and EMOVO) using two standard acoustic paralinguistic feature\nsets (i.e. eGeMAPs and emobase). The results show that similar or better\naccuracy can be achieved using subsets of features substantially smaller than\nthe entire feature set. A machine learning model trained on a smaller feature\nset will reduce the memory and computational resources of an emotion\nrecognition system which can result in lowering the barriers for use of health\nmonitoring technology.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 10:14:20 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 14:39:09 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Haider", "Fasih", ""], ["Pollak", "Senja", ""], ["Albert", "Pierre", ""], ["Luz", "Saturnino", ""]]}, {"id": "1908.10645", "submitter": "Giorgio Gnecco", "authors": "Andrea Bacigalupo, Giorgio Gnecco, Marco Lepidi, Luigi Gambarotta", "title": "Machine-learning techniques for the optimal design of acoustic\n  metamaterials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, an increasing research effort has been dedicated to analyse the\ntransmission and dispersion properties of periodic acoustic metamaterials,\ncharacterized by the presence of local resonators. Within this context,\nparticular attention has been paid to the optimization of the amplitudes and\ncenter frequencies of selected stop and pass bands inside the Floquet-Bloch\nspectra of the acoustic metamaterials featured by a chiral or antichiral\nmicrostructure. Novel functional applications of such research are expected in\nthe optimal parametric design of smart tunable mechanical filters and\ndirectional waveguides. The present paper deals with the maximization of the\namplitude of low-frequency band gaps, by proposing suitable numerical\ntechniques to solve the associated optimization problems. Specifically, the\nfeasibility and effectiveness of Radial Basis Function networks and Quasi-Monte\nCarlo methods for the interpolation of the objective functions of such\noptimization problems are discussed, and their numerical application to a\nspecific acoustic metamaterial with tetrachiral microstructure is presented.\nThe discussion is motivated theoretically by the high computational effort\noften needed for an exact evaluation of the objective functions arising in band\ngap optimization problems, when iterative algorithms are used for their\napproximate solution. By replacing such functions with suitable surrogate\nobjective functions constructed applying machine-learning techniques, well\nperforming suboptimal solutions can be obtained with a smaller computational\neffort. Numerical results demonstrate the effective potential of the proposed\napproach. Current directions of research involving the use of additional\nmachine-learning techniques are also presented.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 11:14:04 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Bacigalupo", "Andrea", ""], ["Gnecco", "Giorgio", ""], ["Lepidi", "Marco", ""], ["Gambarotta", "Luigi", ""]]}, {"id": "1908.10657", "submitter": "Canwen Xu", "authors": "Canwen Xu, Feiyang Wang, Jialong Han, Chenliang Li", "title": "Exploiting Multiple Embeddings for Chinese Named Entity Recognition", "comments": "accepted at CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3358117", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the named entities mentioned in text would enrich many semantic\napplications at the downstream level. However, due to the predominant usage of\ncolloquial language in microblogs, the named entity recognition (NER) in\nChinese microblogs experience significant performance deterioration, compared\nwith performing NER in formal Chinese corpus. In this paper, we propose a\nsimple yet effective neural framework to derive the character-level embeddings\nfor NER in Chinese text, named ME-CNER. A character embedding is derived with\nrich semantic information harnessed at multiple granularities, ranging from\nradical, character to word levels. The experimental results demonstrate that\nthe proposed approach achieves a large performance improvement on Weibo dataset\nand comparable performance on MSRA news dataset with lower computational cost\nagainst the existing state-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 11:47:39 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Xu", "Canwen", ""], ["Wang", "Feiyang", ""], ["Han", "Jialong", ""], ["Li", "Chenliang", ""]]}, {"id": "1908.10661", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef, Ahmed A. Abouelkahire, Deyaaeldeen Almahallawi, Omar\n  S.Marzouk, Sameh K. Mohamed, Waleed A. Mustafa, Omar M. Osama, Ali A. Saleh,\n  Naglaa M. Abdelrazek", "title": "Method and System for Image Analysis to Detect Cancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is the most common cancer and is the leading cause of cancer\ndeath among women worldwide. Detection of breast cancer, while it is still\nsmall and confined to the breast, provides the best chance of effective\ntreatment. Computer Aided Detection (CAD) systems that detect cancer from\nmammograms will help in reducing the human errors that lead to missing breast\ncarcinoma. Literature is rich of scientific papers for methods of CAD design,\nyet with no complete system architecture to deploy those methods. On the other\nhand, commercial CADs are developed and deployed only to vendors' mammography\nmachines with no availability to public access. This paper presents a complete\nCAD; it is complete since it combines, on a hand, the rigor of algorithm design\nand assessment (method), and, on the other hand, the implementation and\ndeployment of a system architecture for public accessibility (system). (1) We\ndevelop a novel algorithm for image enhancement so that mammograms acquired\nfrom any digital mammography machine look qualitatively of the same clarity to\nradiologists' inspection; and is quantitatively standardized for the detection\nalgorithms. (2) We develop novel algorithms for masses and microcalcifications\ndetection with accuracy superior to both literature results and the majority of\napproved commercial systems. (3) We design, implement, and deploy a system\narchitecture that is computationally effective to allow for deploying these\nalgorithms to cloud for public access.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:28:47 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yousef", "Waleed A.", ""], ["Abouelkahire", "Ahmed A.", ""], ["Almahallawi", "Deyaaeldeen", ""], ["Marzouk", "Omar S.", ""], ["Mohamed", "Sameh K.", ""], ["Mustafa", "Waleed A.", ""], ["Osama", "Omar M.", ""], ["Saleh", "Ali A.", ""], ["Abdelrazek", "Naglaa M.", ""]]}, {"id": "1908.10679", "submitter": "Zhou Qin", "authors": "Ao Li, Zhou Qin, Runshi Liu, Yiqun Yang, Dong Li", "title": "Spam Review Detection with Graph Convolutional Networks", "comments": "Accepted at CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3357820", "report-no": null, "categories": "cs.IR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customers make a lot of reviews on online shopping websites every day, e.g.,\nAmazon and Taobao. Reviews affect the buying decisions of customers, meanwhile,\nattract lots of spammers aiming at misleading buyers. Xianyu, the largest\nsecond-hand goods app in China, suffering from spam reviews. The anti-spam\nsystem of Xianyu faces two major challenges: scalability of the data and\nadversarial actions taken by spammers. In this paper, we present our technical\nsolutions to address these challenges. We propose a large-scale anti-spam\nmethod based on graph convolutional networks (GCN) for detecting spam\nadvertisements at Xianyu, named GCN-based Anti-Spam (GAS) model. In this model,\na heterogeneous graph and a homogeneous graph are integrated to capture the\nlocal context and global context of a comment. Offline experiments show that\nthe proposed method is superior to our baseline model in which the information\nof reviews, features of users and items being reviewed are utilized.\nFurthermore, we deploy our system to process million-scale data daily at\nXianyu. The online performance also demonstrates the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:44:16 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Li", "Ao", ""], ["Qin", "Zhou", ""], ["Liu", "Runshi", ""], ["Yang", "Yiqun", ""], ["Li", "Dong", ""]]}, {"id": "1908.10697", "submitter": "Wenqing Lin", "authors": "Wenqing Lin, Feng He, Faqiang Zhang, Xu Cheng, Hongyun Cai", "title": "Initialization for Network Embedding: A Graph Partition Approach", "comments": "Full Research Paper accepted in the 13th ACM International Conference\n  on Web Search and Data Mining (WSDM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Network embedding has been intensively studied in the literature and widely\nused in various applications, such as link prediction and node classification.\nWhile previous work focus on the design of new algorithms or are tailored for\nvarious problem settings, the discussion of initialization strategies in the\nlearning process is often missed. In this work, we address this important issue\nof initialization for network embedding that could dramatically improve the\nperformance of the algorithms on both effectiveness and efficiency.\nSpecifically, we first exploit the graph partition technique that divides the\ngraph into several disjoint subsets, and then construct an abstract graph based\non the partitions. We obtain the initialization of the embedding for each node\nin the graph by computing the network embedding on the abstract graph, which is\nmuch smaller than the input graph, and then propagating the embedding among the\nnodes in the input graph. With extensive experiments on various datasets, we\ndemonstrate that our initialization technique significantly improves the\nperformance of the state-of-the-art algorithms on the evaluations of link\nprediction and node classification by up to 7.76% and 8.74% respectively.\nBesides, we show that the technique of initialization reduces the running time\nof the state-of-the-arts by at least 20%.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 12:53:01 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 02:46:30 GMT"}, {"version": "v3", "created": "Mon, 28 Oct 2019 03:58:43 GMT"}, {"version": "v4", "created": "Sat, 9 Nov 2019 03:42:54 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Lin", "Wenqing", ""], ["He", "Feng", ""], ["Zhang", "Faqiang", ""], ["Cheng", "Xu", ""], ["Cai", "Hongyun", ""]]}, {"id": "1908.10705", "submitter": "\\'Italo Gomes Santana", "authors": "\\'Italo Gomes Santana", "title": "Improving a State-of-the-Art Heuristic for the Minimum Latency Problem\n  with Data Mining", "comments": "This document is a dissertation file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, hybrid metaheuristics have become a trend in operations research. A\nsuccessful example combines the Greedy Randomized Adaptive Search Procedures\n(GRASP) and data mining techniques, where frequent patterns found in\nhigh-quality solutions can lead to an efficient exploration of the search\nspace, along with a significant reduction of computational time. In this work,\na GRASP-based state-of-the-art heuristic for the Minimum Latency Problem (MLP)\nis improved by means of data mining techniques for two MLP variants.\nComputational experiments showed that the approaches with data mining were able\nto match or improve the solution quality for a large number of instances,\ntogether with a substantial reduction of running time. In addition, 88 new cost\nvalues of solutions are introduced into the literature. To support our results,\ntests of statistical significance, impact of using mined patterns, equal time\ncomparisons and time-to-target plots are provided.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:12:30 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Santana", "\u00cdtalo Gomes", ""]]}, {"id": "1908.10711", "submitter": "Md Rafiqul Islam Rabin", "authors": "Md Rafiqul Islam Rabin, Ke Wang, Mohammad Amin Alipour", "title": "Testing Neural Program Analyzers", "comments": "ASE 2019 Late Breaking Results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been increasingly used in software engineering and\nprogram analysis tasks. They usually take a program and make some predictions\nabout it, e.g., bug prediction. We call these models neural program analyzers.\nThe reliability of neural programs can impact the reliability of the\nencompassing analyses. In this paper, we describe our ongoing efforts to\ndevelop effective techniques for testing neural programs. We discuss the\nchallenges involved in developing such tools and our future plans. In our\npreliminary experiment on a neural model recently proposed in the literature,\nwe found that the model is very brittle, and simple perturbations in the input\ncan cause the model to make mistakes in its prediction.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 04:55:22 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 22:27:27 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Rabin", "Md Rafiqul Islam", ""], ["Wang", "Ke", ""], ["Alipour", "Mohammad Amin", ""]]}, {"id": "1908.10713", "submitter": "Jordan Holweger", "authors": "Jordan Holweger, Marina Dorokhova, Lionel Bloch, Christophe Ballif and\n  Nicolas Wyrsch", "title": "Unsupervised algorithm for disaggregating low-sampling-rate electricity\n  consumption of households", "comments": null, "journal-ref": "Sustainable Energy, Grids and Networks, Volume 19, 2019", "doi": "10.1016/j.segan.2019.100244", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Non-intrusive load monitoring (NILM) has been extensively researched over the\nlast decade. The objective of NILM is to identify the power consumption of\nindividual appliances and to detect when particular devices are on or off from\nmeasuring the power consumption of an entire house. This information allows\nhouseholds to receive customized advice on how to better manage their\nelectrical consumption. In this paper, we present an alternative NILM method\nthat breaks down the aggregated power signal into categories of appliances. The\nultimate goal is to use this approach for demand-side management to estimate\npotential flexibility within the electricity consumption of households. Our\nmethod is implemented as an algorithm combining NILM and load profile\nsimulation. This algorithm, based on a Markov model, allocates an activity\nchain to each inhabitant of the household, deduces from the whole-house power\nmeasurement and statistical data the appliance usage, generate the power\nprofile accordingly and finally returns the share of energy consumed by each\nappliance category over time. To analyze its performance, the algorithm was\nbenchmarked against several state-of-the-art NILM algorithms and tested on\nthree public datasets. The proposed algorithm is unsupervised; hence it does\nnot require any labeled data, which are expensive to acquire. Although better\nperformance is shown for the supervised algorithms, our proposed unsupervised\nalgorithm achieves a similar range of uncertainty while saving on the cost of\nacquiring labeled data. Additionally, our method requires lower computational\npower compared to most of the tested NILM algorithms. It was designed for\nlow-sampling-rate power measurement (every 15 min), which corresponds to the\nfrequency range of most common smart meters.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:04:00 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Holweger", "Jordan", ""], ["Dorokhova", "Marina", ""], ["Bloch", "Lionel", ""], ["Ballif", "Christophe", ""], ["Wyrsch", "Nicolas", ""]]}, {"id": "1908.10714", "submitter": "Steven Abreu", "authors": "Steven Abreu", "title": "Automated Architecture Design for Deep Neural Networks", "comments": "Undergraduate Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine learning has made tremendous progress in recent years and received\nlarge amounts of public attention. Though we are still far from designing a\nfull artificially intelligent agent, machine learning has brought us many\napplications in which computers solve human learning tasks remarkably well.\nMuch of this progress comes from a recent trend within machine learning, called\ndeep learning. Deep learning models are responsible for many state-of-the-art\napplications of machine learning. Despite their success, deep learning models\nare hard to train, very difficult to understand, and often times so complex\nthat training is only possible on very large GPU clusters. Lots of work has\nbeen done on enabling neural networks to learn efficiently. However, the design\nand architecture of such neural networks is often done manually through trial\nand error and expert knowledge. This thesis inspects different approaches,\nexisting and novel, to automate the design of deep feedforward neural networks\nin an attempt to create less complex models with good performance that take\naway the burden of deciding on an architecture and make it more efficient to\ndesign and train such deep networks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 00:57:45 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Abreu", "Steven", ""]]}, {"id": "1908.10719", "submitter": "Ryuichi Takanobu", "authors": "Ryuichi Takanobu, Hanlin Zhu, Minlie Huang", "title": "Guided Dialog Policy Learning: Reward Estimation for Multi-Domain\n  Task-Oriented Dialog", "comments": "EMNLP 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog policy decides what and how a task-oriented dialog system will\nrespond, and plays a vital role in delivering effective conversations. Many\nstudies apply Reinforcement Learning to learn a dialog policy with the reward\nfunction which requires elaborate design and pre-specified user goals. With the\ngrowing needs to handle complex goals across multiple domains, such manually\ndesigned reward functions are not affordable to deal with the complexity of\nreal-world tasks. To this end, we propose Guided Dialog Policy Learning, a\nnovel algorithm based on Adversarial Inverse Reinforcement Learning for joint\nreward estimation and policy optimization in multi-domain task-oriented dialog.\nThe proposed approach estimates the reward signal and infers the user goal in\nthe dialog sessions. The reward estimator evaluates the state-action pairs so\nthat it can guide the dialog policy at each dialog turn. Extensive experiments\non a multi-domain dialog dataset show that the dialog policy guided by the\nlearned reward function achieves remarkably higher task success than\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:36:25 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Takanobu", "Ryuichi", ""], ["Zhu", "Hanlin", ""], ["Huang", "Minlie", ""]]}, {"id": "1908.10721", "submitter": "Todor Mihaylov", "authors": "Todor Mihaylov and Anette Frank", "title": "Discourse-Aware Semantic Self-Attention for Narrative Reading\n  Comprehension", "comments": "Accepted as a long conference paper to EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to use linguistic annotations as a basis for a\n\\textit{Discourse-Aware Semantic Self-Attention} encoder that we employ for\nreading comprehension on long narrative texts. We extract relations between\ndiscourse units, events and their arguments as well as coreferring mentions,\nusing available annotation tools. Our empirical evaluation shows that the\ninvestigated structures improve the overall performance, especially\nintra-sentential and cross-sentential discourse relations, sentence-internal\nsemantic role relations, and long-distance coreference relations. We show that\ndedicating self-attention heads to intra-sentential relations and relations\nconnecting neighboring sentences is beneficial for finding answers to questions\nin longer contexts. Our findings encourage the use of discourse-semantic\nannotations to enhance the generalization capacity of self-attention models for\nreading comprehension.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:40:43 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Mihaylov", "Todor", ""], ["Frank", "Anette", ""]]}, {"id": "1908.10722", "submitter": "Junya Ikemoto", "authors": "Junya Ikemoto and Toshimitsu Ushio", "title": "Networked Control of Nonlinear Systems under Partial Observation Using\n  Continuous Deep Q-Learning", "comments": "6 pages, 9 figures, Accepted for presentation in the IEEE Conference\n  on Decision and Control (CDC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a design of a model-free networked controller for a\nnonlinear plant whose mathematical model is unknown. In a networked control\nsystem, the controller and plant are located away from each other and exchange\ndata over a network, which causes network delays that may fluctuate randomly\ndue to network routing. So, in this paper, we assume that the current network\ndelay is not known but the maximum value of fluctuating network delays is known\nbeforehand. Moreover, we also assume that the sensor cannot observe all state\nvariables of the plant. Under these assumption, we apply continuous deep\nQ-learning to the design of the networked controller. Then, we introduce an\nextended state consisting of a sequence of past control inputs and outputs as\ninputs to the deep neural network. By simulation, it is shown that, using the\nextended state, the controller can learn a control policy robust to the\nfluctuation of the network delays under the partial observation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:51:08 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 03:24:18 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Ikemoto", "Junya", ""], ["Ushio", "Toshimitsu", ""]]}, {"id": "1908.10730", "submitter": "Robert J Walls", "authors": "Peter M. VanNostrand, Ioannis Kyriazis, Michelle Cheng, Tian Guo,\n  Robert J. Walls", "title": "Confidential Deep Learning: Executing Proprietary Models on Untrusted\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing deep learning on end-user devices provides fast offline inference\nresults and can help protect the user's privacy. However, running models on\nuntrusted client devices reveals model information which may be proprietary,\ni.e., the operating system or other applications on end-user devices may be\nmanipulated to copy and redistribute this information, infringing on the model\nprovider's intellectual property. We propose the use of ARM TrustZone, a\nhardware-based security feature present in most phones, to confidentially run a\nproprietary model on an untrusted end-user device. We explore the limitations\nand design challenges of using TrustZone and examine potential approaches for\nconfidential deep learning within this environment. Of particular interest is\nproviding robust protection of proprietary model information while minimizing\ntotal performance overhead.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 14:02:59 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["VanNostrand", "Peter M.", ""], ["Kyriazis", "Ioannis", ""], ["Cheng", "Michelle", ""], ["Guo", "Tian", ""], ["Walls", "Robert J.", ""]]}, {"id": "1908.10731", "submitter": "Semih Yavuz", "authors": "Semih Yavuz, Abhinav Rastogi, Guan-Lin Chao, Dilek Hakkani-Tur", "title": "DeepCopy: Grounded Response Generation with Hierarchical Pointer\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in neural sequence-to-sequence models have led to promising\nresults for several language generation-based tasks, including dialogue\nresponse generation, summarization, and machine translation. However, these\nmodels are known to have several problems, especially in the context of\nchit-chat based dialogue systems: they tend to generate short and dull\nresponses that are often too generic. Furthermore, these models do not ground\nconversational responses on knowledge and facts, resulting in turns that are\nnot accurate, informative and engaging for the users. In this paper, we propose\nand experiment with a series of response generation models that aim to serve in\nthe general scenario where in addition to the dialogue context, relevant\nunstructured external knowledge in the form of text is also assumed to be\navailable for models to harness. Our proposed approach extends\npointer-generator networks (See et al., 2017) by allowing the decoder to\nhierarchically attend and copy from external knowledge in addition to the\ndialogue context. We empirically show the effectiveness of the proposed model\ncompared to several baselines including (Ghazvininejad et al., 2018; Zhang et\nal., 2018) through both automatic evaluation metrics and human evaluation on\nCONVAI2 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 14:03:44 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yavuz", "Semih", ""], ["Rastogi", "Abhinav", ""], ["Chao", "Guan-Lin", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1908.10737", "submitter": "Shichao Li", "authors": "Shichao Li, Kwang-Ting Cheng", "title": "Facial age estimation by deep residual decision making", "comments": "Following-up work for visualizing deep neural decision forest for\n  facial age estimation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual representation learning simplifies the optimization problem of\nlearning complex functions and has been widely used by traditional\nconvolutional neural networks. However, it has not been applied to deep neural\ndecision forest (NDF). In this paper we incorporate residual learning into NDF\nand the resulting model achieves state-of-the-art level accuracy on three\npublic age estimation benchmarks while requiring less memory and computation.\nWe further employ gradient-based technique to visualize the decision-making\nprocess of NDF and understand how it is influenced by facial image inputs. The\ncode and pre-trained models will be available at\nhttps://github.com/Nicholasli1995/VisualizingNDF.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 14:12:04 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Li", "Shichao", ""], ["Cheng", "Kwang-Ting", ""]]}, {"id": "1908.10742", "submitter": "Zhengling Qi", "authors": "Zhengling Qi, Ying Cui, Yufeng Liu, Jong-Shi Pang", "title": "Estimation of Individualized Decision Rules Based on an Optimized\n  Covariate-Dependent Equivalent of Random Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent exploration of optimal individualized decision rules (IDRs) for\npatients in precision medicine has attracted a lot of attention due to the\nheterogeneous responses of patients to different treatments. In the existing\nliterature of precision medicine, an optimal IDR is defined as a decision\nfunction mapping from the patients' covariate space into the treatment space\nthat maximizes the expected outcome of each individual. Motivated by the\nconcept of Optimized Certainty Equivalent (OCE) introduced originally in\n\\cite{ben1986expected} that includes the popular conditional-value-of risk\n(CVaR) \\cite{rockafellar2000optimization}, we propose a decision-rule based\noptimized covariates dependent equivalent (CDE) for individualized decision\nmaking problems. Our proposed IDR-CDE broadens the existing expected-mean\noutcome framework in precision medicine and enriches the previous concept of\nthe OCE. Numerical experiments demonstrate that our overall approach\noutperforms existing methods in estimating optimal IDRs under heavy-tail\ndistributions of the data.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:54:46 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Qi", "Zhengling", ""], ["Cui", "Ying", ""], ["Liu", "Yufeng", ""], ["Pang", "Jong-Shi", ""]]}, {"id": "1908.10744", "submitter": "Jonathan Scarlett", "authors": "Zhaoqiang Liu and Jonathan Scarlett", "title": "Information-Theoretic Lower Bounds for Compressive Sensing with\n  Generative Models", "comments": "To appear in IEEE Journal on Selected Areas in Information Theory. In\n  this version, Theorem 7 was updated to allow for general depth/width scalings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been shown that for compressive sensing, significantly fewer\nmeasurements may be required if the sparsity assumption is replaced by the\nassumption the unknown vector lies near the range of a suitably-chosen\ngenerative model. In particular, in (Bora {\\em et al.}, 2017) it was shown\nroughly $O(k\\log L)$ random Gaussian measurements suffice for accurate recovery\nwhen the generative model is an $L$-Lipschitz function with bounded\n$k$-dimensional inputs, and $O(kd \\log w)$ measurements suffice when the\ngenerative model is a $k$-input ReLU network with depth $d$ and width $w$. In\nthis paper, we establish corresponding algorithm-independent lower bounds on\nthe sample complexity using tools from minimax statistical analysis. In\naccordance with the above upper bounds, our results are summarized as follows:\n(i) We construct an $L$-Lipschitz generative model capable of generating\ngroup-sparse signals, and show that the resulting necessary number of\nmeasurements is $\\Omega(k \\log L)$; (ii) Using similar ideas, we construct ReLU\nnetworks with high depth and/or high depth for which the necessary number of\nmeasurements scales as $\\Omega\\big( kd \\frac{\\log w}{\\log n}\\big)$ (with output\ndimension $n$), and in some cases $\\Omega(kd \\log w)$. As a result, we\nestablish that the scaling laws derived in (Bora {\\em et al.}, 2017) are\noptimal or near-optimal in the absence of further assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 14:24:03 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 06:15:58 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Liu", "Zhaoqiang", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "1908.10755", "submitter": "Chen Zhong", "authors": "Chen Zhong, M. Cenk Gursoy, and Senem Velipasalar", "title": "Deep Actor-Critic Reinforcement Learning for Anomaly Detection", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is widely applied in a variety of domains, involving for\ninstance, smart home systems, network traffic monitoring, IoT applications and\nsensor networks. In this paper, we study deep reinforcement learning based\nactive sequential testing for anomaly detection. We assume that there is an\nunknown number of abnormal processes at a time and the agent can only check\nwith one sensor in each sampling step. To maximize the confidence level of the\ndecision and minimize the stopping time concurrently, we propose a deep\nactor-critic reinforcement learning framework that can dynamically select the\nsensor based on the posterior probabilities. We provide simulation results for\nboth the training phase and testing phase, and compare the proposed framework\nwith the Chernoff test in terms of claim delay and loss.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 14:48:11 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Zhong", "Chen", ""], ["Gursoy", "M. Cenk", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1908.10761", "submitter": "Matthieu Lerasle", "authors": "Matthieu Lerasle", "title": "Lecture Notes: Selected topics on robust statistical learning theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These notes gather recent results on robust statistical learning theory. The\ngoal is to stress the main principles underlying the construction and\ntheoretical analysis of these estimators rather than provide an exhaustive\naccount on this rapidly growing field. The notes are the basis of lectures\ngiven at the conference StatMathAppli 2019.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:00:51 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Lerasle", "Matthieu", ""]]}, {"id": "1908.10771", "submitter": "Haoqian Li", "authors": "Haoqian Li and Thomas Lau", "title": "Reinforcement Learning: Prediction, Control and Value Function\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing power of computers and the rapid development of\nself-learning methodologies such as machine learning and artificial\nintelligence, the problem of constructing an automatic Financial Trading\nSystems (FTFs) becomes an increasingly attractive research topic. An intuitive\nway of developing such a trading algorithm is to use Reinforcement Learning\n(RL) algorithms, which does not require model-building. In this paper, we dive\ninto the RL algorithms and illustrate the definitions of the reward function,\nactions and policy functions in details, as well as introducing algorithms that\ncould be applied to FTFs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:17:51 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Li", "Haoqian", ""], ["Lau", "Thomas", ""]]}, {"id": "1908.10776", "submitter": "Qing Qu", "authors": "Qing Qu, Xiao Li, Zhihui Zhu", "title": "A Nonconvex Approach for Exact and Efficient Multichannel Sparse Blind\n  Deconvolution", "comments": "62 pages, 6 figures; short version accepted as a spotlight paper at\n  NeurIPS'19\n  (https://papers.nips.cc/paper/8656-a-nonconvex-approach-for-exact-and-efficient-multichannel-sparse-blind-deconvolution)\n  ; A long journal version is under revision at SIIMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-channel sparse blind deconvolution (MCS-BD) problem, whose\ntask is to simultaneously recover a kernel $\\mathbf a$ and multiple sparse\ninputs $\\{\\mathbf x_i\\}_{i=1}^p$ from their circulant convolution $\\mathbf y_i\n= \\mathbf a \\circledast \\mathbf x_i $ ($i=1,\\cdots,p$). We formulate the task\nas a nonconvex optimization problem over the sphere. Under mild statistical\nassumptions of the data, we prove that the vanilla Riemannian gradient descent\n(RGD) method, with random initializations, provably recovers both the kernel\n$\\mathbf a$ and the signals $\\{\\mathbf x_i\\}_{i=1}^p$ up to a signed shift\nambiguity. In comparison with state-of-the-art results, our work shows\nsignificant improvements in terms of sample complexity and computational\nefficiency. Our theoretical results are corroborated by numerical experiments,\nwhich demonstrate superior performance of the proposed approach over the\nprevious methods on both synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:25:54 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 14:38:53 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 02:57:22 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Qu", "Qing", ""], ["Li", "Xiao", ""], ["Zhu", "Zhihui", ""]]}, {"id": "1908.10796", "submitter": "Florian Pfisterer", "authors": "Florian Pfisterer, Stefan Coors, Janek Thomas, Bernd Bischl", "title": "Multi-Objective Automatic Machine Learning with AutoxgboostMC", "comments": "Accepted at Ecmlpkdd Workshop on Automating Data Science 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AutoML systems are currently rising in popularity, as they can build powerful\nmodels without human oversight. They often combine techniques from many\ndifferent sub-fields of machine learning in order to find a model or set of\nmodels that optimize a user-supplied criterion, such as predictive performance.\nThe ultimate goal of such systems is to reduce the amount of time spent on\nmenial tasks, or tasks that can be solved better by algorithms while leaving\ndecisions that require human intelligence to the end-user. In recent years, the\nimportance of other criteria, such as fairness and interpretability, and many\nothers have become more and more apparent. Current AutoML frameworks either do\nnot allow to optimize such secondary criteria or only do so by limiting the\nsystem's choice of models and preprocessing steps. We propose to optimize\nadditional criteria defined by the user directly to guide the search towards an\noptimal machine learning pipeline. In order to demonstrate the need and\nusefulness of our approach, we provide a simple multi-criteria AutoML system\nand showcase an exemplary application.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:52:57 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 07:01:15 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Pfisterer", "Florian", ""], ["Coors", "Stefan", ""], ["Thomas", "Janek", ""], ["Bischl", "Bernd", ""]]}, {"id": "1908.10797", "submitter": "Jia Huei Tan", "authors": "Jia Huei Tan, Chee Seng Chan, Joon Huang Chuah", "title": "Image Captioning with Sparse Recurrent Neural Network", "comments": "Corrected Eq 11, updated Table 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network (RNN) has been widely used to tackle a wide variety\nof language generation problems and are capable of attaining state-of-the-art\n(SOTA) performance. However despite its impressive results, the large number of\nparameters in the RNN model makes deployment to mobile and embedded devices\ninfeasible. Driven by this problem, many works have proposed a number of\npruning methods to reduce the sizes of the RNN model. In this work, we propose\nan end-to-end pruning method for image captioning models equipped with visual\nattention. Our proposed method is able to achieve sparsity levels up to 97.5%\nwithout significant performance loss relative to the baseline (~ 2% loss at 40x\ncompression after fine-tuning). Our method is also simple to use and tune,\nfacilitating faster development times for neural network practitioners. We\nperform extensive experiments on the popular MS-COCO dataset in order to\nempirically validate the efficacy of our proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:53:13 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 15:51:13 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Tan", "Jia Huei", ""], ["Chan", "Chee Seng", ""], ["Chuah", "Joon Huang", ""]]}, {"id": "1908.10823", "submitter": "Teawon Han", "authors": "Teawon Han, Dimitar Filev, and Umit Ozguner", "title": "An Online Evolving Framework for Modeling the Safe Autonomous Vehicle\n  Control System via Online Recognition of Latent Risks", "comments": "Under review in the Transportation Research Record: Journal of the\n  Transportation Research Board", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An online evolving framework is proposed to support modeling the safe\nAutomated Vehicle (AV) control system by making the controller able to\nrecognize unexpected situations and react appropriately by choosing a better\naction. Within the framework, the evolving Finite State Machine (e-FSM), which\nis an online model able to (1) determine states uniquely as needed, (2)\nrecognize states, and (3) identify state-transitions, is introduced.\n  In this study, the e-FSM's capabilities are explained and illustrated by\nsimulating a simple car-following scenario. As a vehicle controller, the\nIntelligent Driver Model (IDM) is implemented, and different sets of IDM\nparameters are assigned to the following vehicle for simulating various\nsituations (including the collision). While simulating the car-following\nscenario, e-FSM recognizes and determines the states and identifies the\ntransition matrices by suggested methods.\n  To verify if e-FSM can recognize and determine states uniquely, we analyze\nwhether the same state is recognized under the identical situation. The\ndifference between probability distributions of predicted and recognized states\nis measured by the Jensen-Shannon divergence (JSD) method to validate the\naccuracy of identified transition-matrices. As shown in the results, the\nDead-End state which has latent-risk of the collision is uniquely determined\nand consistently recognized. Also, the probability distributions of the\npredicted state are significantly similar to the recognized state, declaring\nthat the state-transitions are precisely identified.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 16:46:47 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Han", "Teawon", ""], ["Filev", "Dimitar", ""], ["Ozguner", "Umit", ""]]}, {"id": "1908.10828", "submitter": "Diyora Salimova", "authors": "Philipp Grohs, Arnulf Jentzen, Diyora Salimova", "title": "Deep neural network approximations for Monte Carlo algorithms", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.AP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been proposed in the literature to employ deep neural\nnetworks (DNNs) together with stochastic gradient descent methods to\napproximate solutions of PDEs. There are also a few results in the literature\nwhich prove that DNNs can approximate solutions of certain PDEs without the\ncurse of dimensionality in the sense that the number of real parameters used to\ndescribe the DNN grows at most polynomially both in the PDE dimension and the\nreciprocal of the prescribed approximation accuracy. One key argument in most\nof these results is, first, to use a Monte Carlo approximation scheme which can\napproximate the solution of the PDE under consideration at a fixed space-time\npoint without the curse of dimensionality and, thereafter, to prove that DNNs\nare flexible enough to mimic the behaviour of the used approximation scheme.\nHaving this in mind, one could aim for a general abstract result which shows\nunder suitable assumptions that if a certain function can be approximated by\nany kind of (Monte Carlo) approximation scheme without the curse of\ndimensionality, then this function can also be approximated with DNNs without\nthe curse of dimensionality. It is a key contribution of this article to make a\nfirst step towards this direction. In particular, the main result of this\npaper, essentially, shows that if a function can be approximated by means of\nsome suitable discrete approximation scheme without the curse of dimensionality\nand if there exist DNNs which satisfy certain regularity properties and which\napproximate this discrete approximation scheme without the curse of\ndimensionality, then the function itself can also be approximated with DNNs\nwithout the curse of dimensionality. As an application of this result we\nestablish that solutions of suitable Kolmogorov PDEs can be approximated with\nDNNs without the curse of dimensionality.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 16:57:17 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Grohs", "Philipp", ""], ["Jentzen", "Arnulf", ""], ["Salimova", "Diyora", ""]]}, {"id": "1908.10831", "submitter": "Mingrui Liu", "authors": "Mingrui Liu, Zhuoning Yuan, Yiming Ying, Tianbao Yang", "title": "Stochastic AUC Maximization with Deep Neural Networks", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic AUC maximization has garnered an increasing interest due to better\nfit to imbalanced data classification. However, existing works are limited to\nstochastic AUC maximization with a linear predictive model, which restricts its\npredictive power when dealing with extremely complex data. In this paper, we\nconsider stochastic AUC maximization problem with a deep neural network as the\npredictive model. Building on the saddle point reformulation of a surrogated\nloss of AUC, the problem can be cast into a {\\it non-convex concave} min-max\nproblem. The main contribution made in this paper is to make stochastic AUC\nmaximization more practical for deep neural networks and big data with\ntheoretical insights as well. In particular, we propose to explore\nPolyak-\\L{}ojasiewicz (PL) condition that has been proved and observed in deep\nlearning, which enables us to develop new stochastic algorithms with even\nfaster convergence rate and more practical step size scheme. An AdaGrad-style\nalgorithm is also analyzed under the PL condition with adaptive convergence\nrate. Our experimental results demonstrate the effectiveness of the proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:02:49 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 19:28:38 GMT"}, {"version": "v3", "created": "Thu, 26 Dec 2019 21:45:03 GMT"}, {"version": "v4", "created": "Sun, 17 May 2020 21:35:03 GMT"}, {"version": "v5", "created": "Tue, 30 Jun 2020 03:25:14 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Liu", "Mingrui", ""], ["Yuan", "Zhuoning", ""], ["Ying", "Yiming", ""], ["Yang", "Tianbao", ""]]}, {"id": "1908.10833", "submitter": "Dan Simovici", "authors": "Dan Simovici and Kaixun Hua", "title": "Data ultrametricity and clusterability", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/1334/1/012002", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing needs of clustering massive datasets and the high cost of\nrunning clustering algorithms poses difficult problems for users. In this\ncontext it is important to determine if a data set is clusterable, that is, it\nmay be partitioned efficiently into well-differentiated groups containing\nsimilar objects. We approach data clusterability from an ultrametric-based\nperspective. A novel approach to determine the ultrametricity of a dataset is\nproposed via a special type of matrix product, which allows us to evaluate the\nclusterability of the dataset. Furthermore, we show that by applying our\ntechnique to a dissimilarity space will generate the sub-dominant ultrametric\nof the dissimilarity.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:04:32 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Simovici", "Dan", ""], ["Hua", "Kaixun", ""]]}, {"id": "1908.10834", "submitter": "Ang Li", "authors": "Tong Geng, Ang Li, Runbin Shi, Chunshu Wu, Tianqi Wang, Yanfei Li,\n  Pouya Haghi, Antonino Tumeo, Shuai Che, Steve Reinhardt, Martin Herbordt", "title": "AWB-GCN: A Graph Convolutional Network Accelerator with Runtime Workload\n  Rebalancing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning systems have been successfully applied to Euclidean data such\nas images, video, and audio. In many applications, however, information and\ntheir relationships are better expressed with graphs. Graph Convolutional\nNetworks (GCNs) appear to be a promising approach to efficiently learn from\ngraph data structures, having shown advantages in many critical applications.\nAs with other deep learning modalities, hardware acceleration is critical. The\nchallenge is that real-world graphs are often extremely large and unbalanced;\nthis poses significant performance demands and design challenges.\n  In this paper, we propose Autotuning-Workload-Balancing GCN (AWB-GCN) to\naccelerate GCN inference. To address the issue of workload imbalance in\nprocessing real-world graphs, three hardware-based autotuning techniques are\nproposed: dynamic distribution smoothing, remote switching, and row remapping.\nIn particular, AWB-GCN continuously monitors the sparse graph pattern,\ndynamically adjusts the workload distribution among a large number of\nprocessing elements (up to 4K PEs), and, after converging, reuses the ideal\nconfiguration. Evaluation is performed using an Intel D5005 FPGA with five\ncommonly-used datasets. Results show that 4K-PE AWB-GCN can significantly\nelevate PE utilization by 7.7x on average and demonstrate considerable\nperformance speedups over CPUs (3255x), GPUs (80.3x), and a prior GCN\naccelerator (5.1x).\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 17:18:49 GMT"}, {"version": "v10", "created": "Fri, 11 Sep 2020 01:50:22 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 00:55:01 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 04:14:59 GMT"}, {"version": "v4", "created": "Sat, 29 Feb 2020 01:27:39 GMT"}, {"version": "v5", "created": "Thu, 30 Apr 2020 04:58:53 GMT"}, {"version": "v6", "created": "Thu, 30 Jul 2020 21:41:06 GMT"}, {"version": "v7", "created": "Fri, 14 Aug 2020 02:01:00 GMT"}, {"version": "v8", "created": "Sun, 6 Sep 2020 16:17:54 GMT"}, {"version": "v9", "created": "Thu, 10 Sep 2020 15:52:32 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Geng", "Tong", ""], ["Li", "Ang", ""], ["Shi", "Runbin", ""], ["Wu", "Chunshu", ""], ["Wang", "Tianqi", ""], ["Li", "Yanfei", ""], ["Haghi", "Pouya", ""], ["Tumeo", "Antonino", ""], ["Che", "Shuai", ""], ["Reinhardt", "Steve", ""], ["Herbordt", "Martin", ""]]}, {"id": "1908.10835", "submitter": "Wanyu Du", "authors": "Wanyu Du, Yangfeng Ji", "title": "An Empirical Comparison on Imitation Learning and Reinforcement Learning\n  for Paraphrase Generation", "comments": "9 pages, 2 figures, EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating paraphrases from given sentences involves decoding words step by\nstep from a large vocabulary. To learn a decoder, supervised learning which\nmaximizes the likelihood of tokens always suffers from the exposure bias.\nAlthough both reinforcement learning (RL) and imitation learning (IL) have been\nwidely used to alleviate the bias, the lack of direct comparison leads to only\na partial image on their benefits. In this work, we present an empirical study\non how RL and IL can help boost the performance of generating paraphrases, with\nthe pointer-generator as a base model. Experiments on the benchmark datasets\nshow that (1) imitation learning is constantly better than reinforcement\nlearning; and (2) the pointer-generator models with imitation learning\noutperform the state-of-the-art methods with a large margin.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:10:06 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Du", "Wanyu", ""], ["Ji", "Yangfeng", ""]]}, {"id": "1908.10842", "submitter": "Tong Zhang PhD", "authors": "Tong Zhang, Laurence H. Jackson, Alena Uus, James R. Clough, Lisa\n  Story, Mary A. Rutherford, Joseph V. Hajnal, Maria Deprez", "title": "Self-supervised Recurrent Neural Network for 4D Abdominal and In-utero\n  MR Imaging", "comments": "Accepted by MICCAI 2019 workshop on Machine Learning for Medical\n  Image Reconstruction", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately estimating and correcting the motion artifacts are crucial for 3D\nimage reconstruction of the abdominal and in-utero magnetic resonance imaging\n(MRI). The state-of-art methods are based on slice-to-volume registration (SVR)\nwhere multiple 2D image stacks are acquired in three orthogonal orientations.\nIn this work, we present a novel reconstruction pipeline that only needs one\norientation of 2D MRI scans and can reconstruct the full high-resolution image\nwithout masking or registration steps. The framework consists of two main\nstages: the respiratory motion estimation using a self-supervised recurrent\nneural network, which learns the respiratory signals that are naturally\nembedded in the asymmetry relationship of the neighborhood slices and cluster\nthem according to a respiratory state. Then, we train a 3D deconvolutional\nnetwork for super-resolution (SR) reconstruction of the sparsely selected 2D\nimages using integrated reconstruction and total variation loss. We evaluate\nthe classification accuracy on 5 simulated images and compare our results with\nthe SVR method in adult abdominal and in-utero MRI scans. The results show that\nthe proposed pipeline can accurately estimate the respiratory state and\nreconstruct 4D SR volumes with better or similar performance to the 3D SVR\npipeline with less than 20\\% sparsely selected slices. The method has great\npotential to transform the 4D abdominal and in-utero MRI in clinical practice.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:24:26 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Zhang", "Tong", ""], ["Jackson", "Laurence H.", ""], ["Uus", "Alena", ""], ["Clough", "James R.", ""], ["Story", "Lisa", ""], ["Rutherford", "Mary A.", ""], ["Hajnal", "Joseph V.", ""], ["Deprez", "Maria", ""]]}, {"id": "1908.10859", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Yi-An Ma, Martin J. Wainwright, Peter L. Bartlett,\n  Michael I. Jordan", "title": "High-Order Langevin Diffusion Yields an Accelerated MCMC Algorithm", "comments": "Changes from v1: improved algorithm with $O (d^{1/4} /\n  \\varepsilon^{1/2})$ mixing time", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Markov chain Monte Carlo (MCMC) algorithm based on third-order\nLangevin dynamics for sampling from distributions with log-concave and smooth\ndensities. The higher-order dynamics allow for more flexible discretization\nschemes, and we develop a specific method that combines splitting with more\naccurate integration. For a broad class of $d$-dimensional distributions\narising from generalized linear models, we prove that the resulting third-order\nalgorithm produces samples from a distribution that is at most $\\varepsilon >\n0$ in Wasserstein distance from the target distribution in\n$O\\left(\\frac{d^{1/4}}{ \\varepsilon^{1/2}} \\right)$ steps. This result requires\nonly Lipschitz conditions on the gradient. For general strongly convex\npotentials with $\\alpha$-th order smoothness, we prove that the mixing time\nscales as $O \\left(\\frac{d^{1/4}}{\\varepsilon^{1/2}} +\n\\frac{d^{1/2}}{\\varepsilon^{1/(\\alpha - 1)}} \\right)$.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:59:29 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 15:10:59 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Mou", "Wenlong", ""], ["Ma", "Yi-An", ""], ["Wainwright", "Martin J.", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1908.10887", "submitter": "Eric Moore", "authors": "Eric T. Moore, William P. Ford, Emma J. Hague, Johanna Turk", "title": "An Application of CNNs to Time Sequenced One Dimensional Data in\n  Radiation Detection", "comments": "11 pages, 9 figures, presented: SPIE Defense + Commercial Sensing,\n  16-18 Apr 2019, Baltimore, MD, United States", "journal-ref": "Proc. SPIE 10986, Algorithms, Technologies, and Applications for\n  Multispectral and Hyperspectral Imagery XXV, 109861C (14 May 2019);\n  https://doi.org/10.1117/12.2519037", "doi": null, "report-no": null, "categories": "physics.app-ph cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Convolutional Neural Network architecture was used to classify various\nisotopes of time-sequenced gamma-ray spectra, a typical output of a radiation\ndetection system of a type commonly fielded for security or environmental\nmeasurement purposes. A two-dimensional surface (waterfall plot) in time-energy\nspace is interpreted as a monochromatic image and standard image-based CNN\ntechniques are applied. This allows for the time-sequenced aspects of features\nin the data to be discovered by the network, as opposed to standard algorithms\nwhich arbitrarily time bin the data to satisfy the intuition of a human\nspectroscopist. The CNN architecture and results are presented along with a\ncomparison to conventional techniques. The results of this novel application of\nimage processing techniques to radiation data will be presented along with a\ncomparison to more conventional adaptive methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 18:03:48 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Moore", "Eric T.", ""], ["Ford", "William P.", ""], ["Hague", "Emma J.", ""], ["Turk", "Johanna", ""]]}, {"id": "1908.10896", "submitter": "Stephan Baier", "authors": "Stephan Baier", "title": "Analyzing Customer Feedback for Product Fit Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest hurdles for customers when purchasing fashion online, is\nthe difficulty of finding products with the right fit. In order to provide a\nbetter online shopping experience, platforms need to find ways to recommend the\nright product sizes and the best fitting products to their customers. These\nrecommendation systems, however, require customer feedback in order to estimate\nthe most suitable sizing options. Such feedback is rare and often only\navailable as natural text. In this paper, we examine the extraction of product\nfit feedback from customer reviews using natural language processing\ntechniques. In particular, we compare traditional methods with more recent\ntransfer learning techniques for text classification, and analyze their\nresults. Our evaluation shows, that the transfer learning approach ULMFit is\nnot only comparatively fast to train, but also achieves highest accuracy on\nthis task. The integration of the extracted information with actual size\nrecommendation systems is left for future work.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 18:22:26 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Baier", "Stephan", ""]]}, {"id": "1908.10909", "submitter": "Eric Yuan", "authors": "Xingdi Yuan, Marc-Alexandre Cote, Jie Fu, Zhouhan Lin, Christopher\n  Pal, Yoshua Bengio, Adam Trischler", "title": "Interactive Language Learning by Question Answering", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans observe and interact with the world to acquire knowledge. However,\nmost existing machine reading comprehension (MRC) tasks miss the interactive,\ninformation-seeking component of comprehension. Such tasks present models with\nstatic documents that contain all necessary information, usually concentrated\nin a single short substring. Thus, models can achieve strong performance\nthrough simple word- and phrase-based pattern matching. We address this problem\nby formulating a novel text-based question answering task: Question Answering\nwith Interactive Text (QAit). In QAit, an agent must interact with a partially\nobservable text-based environment to gather information required to answer\nquestions. QAit poses questions about the existence, location, and attributes\nof objects found in the environment. The data is built using a text-based game\ngenerator that defines the underlying dynamics of interaction with the\nenvironment. We propose and evaluate a set of baseline models for the QAit task\nthat includes deep reinforcement learning agents. Experiments show that the\ntask presents a major challenge for machine reading systems, while humans solve\nit with relative ease.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 19:10:08 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Yuan", "Xingdi", ""], ["Cote", "Marc-Alexandre", ""], ["Fu", "Jie", ""], ["Lin", "Zhouhan", ""], ["Pal", "Christopher", ""], ["Bengio", "Yoshua", ""], ["Trischler", "Adam", ""]]}, {"id": "1908.10920", "submitter": "Guan-Horng Liu", "authors": "Guan-Horng Liu, Evangelos A. Theodorou", "title": "Deep Learning Theory Review: An Optimal Control and Dynamical Systems\n  Perspective", "comments": "Under Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attempts from different disciplines to provide a fundamental understanding of\ndeep learning have advanced rapidly in recent years, yet a unified framework\nremains relatively limited. In this article, we provide one possible way to\nalign existing branches of deep learning theory through the lens of dynamical\nsystem and optimal control. By viewing deep neural networks as discrete-time\nnonlinear dynamical systems, we can analyze how information propagates through\nlayers using mean field theory. When optimization algorithms are further recast\nas controllers, the ultimate goal of training processes can be formulated as an\noptimal control problem. In addition, we can reveal convergence and\ngeneralization properties by studying the stochastic dynamics of optimization\nalgorithms. This viewpoint features a wide range of theoretical study from\ninformation bottleneck to statistical physics. It also provides a principled\nway for hyper-parameter tuning when optimal control theory is introduced. Our\nframework fits nicely with supervised learning and can be extended to other\nlearning problems, such as Bayesian learning, adversarial training, and\nspecific forms of meta learning, without efforts. The review aims to shed\nlights on the importance of dynamics and optimal control when developing deep\nlearning theory.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 19:36:23 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 20:40:02 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Liu", "Guan-Horng", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "1908.10924", "submitter": "Yuanliang Meng", "authors": "Yuanliang Meng and Anna Rumshisky", "title": "Solving Math Word Problems with Double-Decoder Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Transformer-based model to generate equations for math\nword problems. It achieves much better results than RNN models when copy and\nalign mechanisms are not used, and can outperform complex copy and align RNN\nmodels. We also show that training a Transformer jointly in a generation task\nwith two decoders, left-to-right and right-to-left, is beneficial. Such a\nTransformer performs better than the one with just one decoder not only because\nof the ensemble effect, but also because it improves the encoder training\nprocedure. We also experiment with adding reinforcement learning to our model,\nshowing improved performance compared to MLE training.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 19:42:37 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Meng", "Yuanliang", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1908.10929", "submitter": "Maruti Mudunuru", "authors": "M. K. Mudunuru and S. Karra", "title": "Physics-Informed Machine Learning Models for Predicting the Progress of\n  Reactive-Mixing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a physics-informed machine learning (ML) framework to\nconstruct reduced-order models (ROMs) for reactive-transport quantities of\ninterest (QoIs) based on high-fidelity numerical simulations. QoIs include\nspecies decay, product yield, and degree of mixing. The ROMs for QoIs are\napplied to quantify and understand how the chemical species evolve over time.\nFirst, high-resolution datasets for constructing ROMs are generated by solving\nanisotropic reaction-diffusion equations using a non-negative finite element\nformulation for different input parameters. Non-negative finite element\nformulation ensures that the species concentration is non-negative (which is\nneeded for computing QoIs) on coarse computational grids even under high\nanisotropy. The reactive-mixing model input parameters are a time-scale\nassociated with flipping of velocity, a spatial-scale controlling small/large\nvortex structures of velocity, a perturbation parameter of the vortex-based\nvelocity, anisotropic dispersion strength/contrast, and molecular diffusion.\nSecond, random forests, F-test, and mutual information criterion are used to\nevaluate the importance of model inputs/features with respect to QoIs. Third,\nSupport Vector Machines (SVM) and Support Vector Regression (SVR) are used to\nconstruct ROMs based on the model inputs. Then, SVR-ROMs are used to predict\nscaling of QoIs. Qualitatively, SVR-ROMs are able to describe the trends\nobserved in the scaling law associated with QoIs. Fourth, the scaling law's\nexponent dependence on model inputs/features are evaluated using $k$-means\nclustering. Finally, in terms of the computational cost, the proposed SVM-ROMs\nand SVR-ROMs are $\\mathcal{O}(10^7)$ times faster than running a high-fidelity\nnumerical simulation for evaluating QoIs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 20:12:04 GMT"}], "update_date": "2019-09-15", "authors_parsed": [["Mudunuru", "M. K.", ""], ["Karra", "S.", ""]]}, {"id": "1908.10940", "submitter": "Wei Wang", "authors": "Wei Wang, Ye Tian, Jiquan Ngiam, Yinfei Yang, Isaac Caswell, Zarana\n  Parekh", "title": "Learning a Multi-Domain Curriculum for Neural Machine Translation", "comments": "Accepted at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most data selection research in machine translation focuses on improving a\nsingle domain. We perform data selection for multiple domains at once. This is\nachieved by carefully introducing instance-level domain-relevance features and\nautomatically constructing a training curriculum to gradually concentrate on\nmulti-domain relevant and noise-reduced data batches. Both the choice of\nfeatures and the use of curriculum are crucial for balancing and improving all\ndomains, including out-of-domain. In large-scale experiments, the multi-domain\ncurriculum simultaneously reaches or outperforms the individual performance and\nbrings solid gains over no-curriculum training.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 20:48:05 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 00:32:41 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Wei", ""], ["Tian", "Ye", ""], ["Ngiam", "Jiquan", ""], ["Yang", "Yinfei", ""], ["Caswell", "Isaac", ""], ["Parekh", "Zarana", ""]]}, {"id": "1908.10947", "submitter": "Juliane Mueller", "authors": "Juliane Mueller, Jangho Park, Reetik Sahu, Charuleka Varadharajan,\n  Bhavna Arora, Boris Faybishenko, Deborah Agarwal", "title": "Surrogate Optimization of Deep Neural Networks for Groundwater\n  Predictions", "comments": "submitted to Journal of Global Optimization; main paper: 25 pages, 19\n  figures, 1 table; online supplement: 11 pages, 18 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": "LBNL-2001234", "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sustainable management of groundwater resources under changing climatic\nconditions require an application of reliable and accurate predictions of\ngroundwater levels. Mechanistic multi-scale, multi-physics simulation models\nare often too hard to use for this purpose, especially for groundwater managers\nwho do not have access to the complex compute resources and data. Therefore, we\nanalyzed the applicability and performance of four modern deep learning\ncomputational models for predictions of groundwater levels. We compare three\nmethods for optimizing the models' hyperparameters, including two surrogate\nmodel-based algorithms and a random sampling method. The models were tested\nusing predictions of the groundwater level in Butte County, California, USA,\ntaking into account the temporal variability of streamflow, precipitation, and\nambient temperature. Our numerical study shows that the optimization of the\nhyperparameters can lead to reasonably accurate performance of all models (root\nmean squared errors of groundwater predictions of 2 meters or less), but the\n''simplest'' network, namely a multilayer perceptron (MLP) performs overall\nbetter for learning and predicting groundwater data than the more advanced long\nshort-term memory or convolutional neural networks in terms of prediction\naccuracy and time-to-solution, making the MLP a suitable candidate for\ngroundwater prediction.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 21:18:35 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 17:22:23 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 20:47:58 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Mueller", "Juliane", ""], ["Park", "Jangho", ""], ["Sahu", "Reetik", ""], ["Varadharajan", "Charuleka", ""], ["Arora", "Bhavna", ""], ["Faybishenko", "Boris", ""], ["Agarwal", "Deborah", ""]]}, {"id": "1908.10959", "submitter": "Qing Qu", "authors": "Yenson Lau, Qing Qu, Han-Wen Kuo, Pengcheng Zhou, Yuqian Zhang, John\n  Wright", "title": "Short-and-Sparse Deconvolution -- A Geometric Approach", "comments": "*YL and QQ contributed equally to this work; 30 figures, 45 pages;\n  This version: added an experiment comparing with other methods, corrected\n  typos and added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-and-sparse deconvolution (SaSD) is the problem of extracting localized,\nrecurring motifs in signals with spatial or temporal structure. Variants of\nthis problem arise in applications such as image deblurring, microscopy, neural\nspike sorting, and more. The problem is challenging in both theory and\npractice, as natural optimization formulations are nonconvex. Moreover,\npractical deconvolution problems involve smooth motifs (kernels) whose spectra\ndecay rapidly, resulting in poor conditioning and numerical challenges. This\npaper is motivated by recent theoretical advances, which characterize the\noptimization landscape of a particular nonconvex formulation of SaSD. This is\nused to derive a $provable$ algorithm which exactly solves certain\nnon-practical instances of the SaSD problem. We leverage the key ideas from\nthis theory (sphere constraints, data-driven initialization) to develop a\n$practical$ algorithm, which performs well on data arising from a range of\napplication areas. We highlight key additional challenges posed by the\nill-conditioning of real SaSD problems, and suggest heuristics (acceleration,\ncontinuation, reweighting) to mitigate them. Experiments demonstrate both the\nperformance and generality of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 21:52:28 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 05:25:59 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Lau", "Yenson", ""], ["Qu", "Qing", ""], ["Kuo", "Han-Wen", ""], ["Zhou", "Pengcheng", ""], ["Zhang", "Yuqian", ""], ["Wright", "John", ""]]}, {"id": "1908.10962", "submitter": "Ashok Makkuva", "authors": "Ashok Vardhan Makkuva, Amirhossein Taghvaei, Sewoong Oh, Jason D. Lee", "title": "Optimal transport mapping via input convex neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a novel and principled approach to learn the\noptimal transport between two distributions, from samples. Guided by the\noptimal transport theory, we learn the optimal Kantorovich potential which\ninduces the optimal transport map. This involves learning two convex functions,\nby solving a novel minimax optimization. Building upon recent advances in the\nfield of input convex neural networks, we propose a new framework where the\ngradient of one convex function represents the optimal transport mapping.\nNumerical experiments confirm that we learn the optimal transport mapping. This\napproach ensures that the transport mapping we find is optimal independent of\nhow we initialize the neural networks. Further, target distributions from a\ndiscontinuous support can be easily captured, as gradient of a convex function\nnaturally models a {\\em discontinuous} transport mapping.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 21:59:58 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 19:44:15 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Makkuva", "Ashok Vardhan", ""], ["Taghvaei", "Amirhossein", ""], ["Oh", "Sewoong", ""], ["Lee", "Jason D.", ""]]}, {"id": "1908.10964", "submitter": "Siddharth Samsi", "authors": "Siddharth Samsi, Christopher J. Mattioli, Mark S. Veillette", "title": "Distributed Deep Learning for Precipitation Nowcasting", "comments": "IEEE HPEC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective training of Deep Neural Networks requires massive amounts of data\nand compute. As a result, longer times are needed to train complex models\nrequiring large datasets, which can severely limit research on model\ndevelopment and the exploitation of all available data. In this paper, this\nproblem is investigated in the context of precipitation nowcasting, a term used\nto describe highly detailed short-term forecasts of precipitation and other\nhazardous weather. Convolutional Neural Networks (CNNs) are a powerful class of\nmodels that are well-suited for this task; however, the high resolution input\nweather imagery combined with model complexity required to process this data\nmakes training CNNs to solve this task time consuming. To address this issue, a\ndata-parallel model is implemented where a CNN is replicated across multiple\ncompute nodes and the training batches are distributed across multiple nodes.\nBy leveraging multiple GPUs, we show that the training time for a given\nnowcasting model architecture can be reduced from 59 hours to just over 1 hour.\nThis will allow for faster iterations for improving CNN architectures and will\nfacilitate future advancement in the area of nowcasting.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 22:06:42 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Samsi", "Siddharth", ""], ["Mattioli", "Christopher J.", ""], ["Veillette", "Mark S.", ""]]}, {"id": "1908.10970", "submitter": "Zhe Zhang", "authors": "Zhe Zhang and Munindar P. Singh", "title": "Leveraging Structural and Semantic Correspondence for Attribute-Oriented\n  Aspect Sentiment Discovery", "comments": "EMNLP 2019", "journal-ref": null, "doi": "10.18653/v1/D19-1555", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinionated text often involves attributes such as authorship and location\nthat influence the sentiments expressed for different aspects. We posit that\nstructural and semantic correspondence is both prevalent in opinionated text,\nespecially when associated with attributes, and crucial in accurately revealing\nits latent aspect and sentiment structure. However, it is not recognized by\nexisting approaches.\n  We propose Trait, an unsupervised probabilistic model that discovers aspects\nand sentiments from text and associates them with different attributes. To this\nend, Trait infers and leverages structural and semantic correspondence using a\nMarkov Random Field. We show empirically that by incorporating attributes\nexplicitly Trait significantly outperforms state-of-the-art baselines both by\ngenerating attribute profiles that accord with our intuitions, as shown via\nvisualization, and yielding topics of greater semantic cohesion.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 22:18:03 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zhang", "Zhe", ""], ["Singh", "Munindar P.", ""]]}, {"id": "1908.10999", "submitter": "Kanglin Liu", "authors": "Kanglin Liu and Wenming Tang and Fei Zhou and Guoping Qiu", "title": "Spectral Regularization for Combating Mode Collapse in GANs", "comments": "24 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite excellent progress in recent years, mode collapse remains a major\nunsolved problem in generative adversarial networks (GANs).In this paper, we\npresent spectral regularization for GANs (SR-GANs), a new and robust method for\ncombating the mode collapse problem in GANs. Theoretical analysis shows that\nthe optimal solution to the discriminator has a strong relationship to the\nspectral distributions of the weight matrix.Therefore, we monitor the spectral\ndistribution in the discriminator of spectral normalized GANs (SN-GANs), and\ndiscover a phenomenon which we refer to as spectral collapse, where a large\nnumber of singular values of the weight matrices drop dramatically when mode\ncollapse occurs. We show that there are strong evidence linking mode collapse\nto spectral collapse; and based on this link, we set out to tackle spectral\ncollapse as a surrogate of mode collapse. We have developed a spectral\nregularization method where we compensate the spectral distributions of the\nweight matrices to prevent them from collapsing, which in turn successfully\nprevents mode collapse in GANs. We provide theoretical explanations for why\nSR-GANs are more stable and can provide better performances than SN-GANs. We\nalso present extensive experimental results and analysis to show that SR-GANs\nnot only always outperform SN-GANs but also always succeed in combating mode\ncollapse where SN-GANs fail. The code is available at\nhttps://github.com/max-liu-112/SRGANs-Spectral-Regularization-GANs-.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 00:56:47 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 05:21:37 GMT"}, {"version": "v3", "created": "Sat, 12 Oct 2019 07:43:51 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Liu", "Kanglin", ""], ["Tang", "Wenming", ""], ["Zhou", "Fei", ""], ["Qiu", "Guoping", ""]]}, {"id": "1908.11007", "submitter": "Tianyu Gao", "authors": "Tianyu Gao, Xu Han, Ruobing Xie, Zhiyuan Liu, Fen Lin, Leyu Lin,\n  Maosong Sun", "title": "Neural Snowball for Few-Shot Relation Learning", "comments": "Accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs typically undergo open-ended growth of new relations. This\ncannot be well handled by relation extraction that focuses on pre-defined\nrelations with sufficient training data. To address new relations with few-shot\ninstances, we propose a novel bootstrapping approach, Neural Snowball, to learn\nnew relations by transferring semantic knowledge about existing relations. More\nspecifically, we use Relational Siamese Networks (RSN) to learn the metric of\nrelational similarities between instances based on existing relations and their\nlabeled data. Afterwards, given a new relation and its few-shot instances, we\nuse RSN to accumulate reliable instances from unlabeled corpora; these\ninstances are used to train a relation classifier, which can further identify\nnew facts of the new relation. The process is conducted iteratively like a\nsnowball. Experiments show that our model can gather high-quality instances for\nbetter few-shot relation learning and achieves significant improvement compared\nto baselines. Codes and datasets are released on\nhttps://github.com/thunlp/Neural-Snowball.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 01:25:52 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 07:40:32 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Gao", "Tianyu", ""], ["Han", "Xu", ""], ["Xie", "Ruobing", ""], ["Liu", "Zhiyuan", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""], ["Sun", "Maosong", ""]]}, {"id": "1908.11033", "submitter": "Jinlong Chai", "authors": "Jinlong Chai, Jiangeng Chang, Yakun Zhao, Honggang Liu", "title": "An Auto-ML Framework Based on GBDT for Lifelong Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Machine Learning (Auto-ML) has attracted more and more attention in\nrecent years, our work is to solve the problem of data drift, which means that\nthe distribution of data will gradually change with the acquisition process,\nresulting in a worse performance of the auto-ML model. We construct our model\nbased on GBDT, Incremental learning and full learning are used to handle with\ndrift problem. Experiments show that our method performs well on the five data\nsets. Which shows that our method can effectively solve the problem of data\ndrift and has robust performance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 03:30:11 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Chai", "Jinlong", ""], ["Chang", "Jiangeng", ""], ["Zhao", "Yakun", ""], ["Liu", "Honggang", ""]]}, {"id": "1908.11051", "submitter": "Wei Cui Dr.", "authors": "Wei Cui, Teng Ma, Lin Zhao, Yaojun Ge", "title": "Data-based wind disaster climate identification algorithm and extreme\n  wind speed prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An extreme wind speed estimation method that considers wind hazard climate\ntypes is critical for design wind load calculation for building structures\naffected by mixed climates. However, it is very difficult to obtain wind hazard\nclimate types from meteorological data records, because they restrict the\napplication of extreme wind speed estimation in mixed climates. This paper\nfirst proposes a wind hazard type identification algorithm based on a numerical\npattern recognition method that utilizes feature extraction and generalization.\nNext, it compares six commonly used machine learning models using K-fold\ncross-validation. Finally, it takes meteorological data from three locations\nnear the southeast coast of China as examples to examine the algorithm\nperformance. Based on classification results, the extreme wind speeds\ncalculated based on mixed wind hazard types is compared with those obtained\nfrom conventional methods, and the effects on structural design for different\nreturn periods are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 04:58:19 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Cui", "Wei", ""], ["Ma", "Teng", ""], ["Zhao", "Lin", ""], ["Ge", "Yaojun", ""]]}, {"id": "1908.11052", "submitter": "Shuaichen Chang", "authors": "Shuaichen Chang, Pengfei Liu, Yun Tang, Jing Huang, Xiaodong He, Bowen\n  Zhou", "title": "Zero-shot Text-to-SQL Learning with Auxiliary Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen great success in the use of neural seq2seq models on\nthe text-to-SQL task. However, little work has paid attention to how these\nmodels generalize to realistic unseen data, which naturally raises a question:\ndoes this impressive performance signify a perfect generalization model, or are\nthere still some limitations?\n  In this paper, we first diagnose the bottleneck of text-to-SQL task by\nproviding a new testbed, in which we observe that existing models present poor\ngeneralization ability on rarely-seen data. The above analysis encourages us to\ndesign a simple but effective auxiliary task, which serves as a supportive\nmodel as well as a regularization term to the generation task to increase the\nmodels generalization. Experimentally, We evaluate our models on a large\ntext-to-SQL dataset WikiSQL. Compared to a strong baseline coarse-to-fine\nmodel, our models improve over the baseline by more than 3% absolute in\naccuracy on the whole dataset. More interestingly, on a zero-shot subset test\nof WikiSQL, our models achieve 5% absolute accuracy gain over the baseline,\nclearly demonstrating its superior generalizability.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 05:01:39 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Chang", "Shuaichen", ""], ["Liu", "Pengfei", ""], ["Tang", "Yun", ""], ["Huang", "Jing", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1908.11056", "submitter": "Tao Wen", "authors": "Guanjie Zheng, Mengqi Liu, Tao Wen, Hongjian Wang, Huaxiu Yao, Susan\n  L. Brantley, Zhenhui Li", "title": "Targeted Source Detection for Environmental Data", "comments": "8 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the face of growing needs for water and energy, a fundamental\nunderstanding of the environmental impacts of human activities becomes critical\nfor managing water and energy resources, remedying water pollution, and making\nregulatory policy wisely. Among activities that impact the environment, oil and\ngas production, wastewater transport, and urbanization are included. In\naddition to the occurrence of anthropogenic contamination, the presence of some\ncontaminants (e.g., methane, salt, and sulfate) of natural origin is not\nuncommon. Therefore, scientists sometimes find it difficult to identify the\nsources of contaminants in the coupled natural and human systems. In this\npaper, we propose a technique to simultaneously conduct source detection and\nprediction, which outperforms other approaches in the interdisciplinary case\nstudy of the identification of potential groundwater contamination within a\nregion of high-density shale gas development.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 05:15:53 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Zheng", "Guanjie", ""], ["Liu", "Mengqi", ""], ["Wen", "Tao", ""], ["Wang", "Hongjian", ""], ["Yao", "Huaxiu", ""], ["Brantley", "Susan L.", ""], ["Li", "Zhenhui", ""]]}, {"id": "1908.11057", "submitter": "Zenan Xu", "authors": "Zenan Xu, Qinliang Su, Xiaojun Quan, Weijia Zhang", "title": "A Deep Neural Information Fusion Architecture for Textual Network\n  Embeddings", "comments": "To appear at EMNLP-IJCNLP 2019 (Conference on Empirical Methods in\n  Natural Language Processing & International Joint Conference on Natural\n  Language Processing 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual network embeddings aim to learn a low-dimensional representation for\nevery node in the network so that both the structural and textual information\nfrom the networks can be well preserved in the representations. Traditionally,\nthe structural and textual embeddings were learned by models that rarely take\nthe mutual influences between them into account. In this paper, a deep neural\narchitecture is proposed to effectively fuse the two kinds of informations into\none representation. The novelties of the proposed architecture are manifested\nin the aspects of a newly defined objective function, the complementary\ninformation fusion method for structural and textual features, and the mutual\ngate mechanism for textual feature extraction. Experimental results show that\nthe proposed model outperforms the comparing methods on all three datasets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 05:19:53 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Xu", "Zenan", ""], ["Su", "Qinliang", ""], ["Quan", "Xiaojun", ""], ["Zhang", "Weijia", ""]]}, {"id": "1908.11071", "submitter": "Lin Yang", "authors": "Aaron Sidford, Mengdi Wang, Lin F. Yang, Yinyu Ye", "title": "Solving Discounted Stochastic Two-Player Games with Near-Optimal Time\n  and Sample Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we settle the sampling complexity of solving discounted\ntwo-player turn-based zero-sum stochastic games up to polylogarithmic factors.\nGiven a stochastic game with discount factor $\\gamma\\in(0,1)$ we provide an\nalgorithm that computes an $\\epsilon$-optimal strategy with high-probability\ngiven $\\tilde{O}((1 - \\gamma)^{-3} \\epsilon^{-2})$ samples from the transition\nfunction for each state-action-pair. Our algorithm runs in time nearly linear\nin the number of samples and uses space nearly linear in the number of\nstate-action pairs. As stochastic games generalize Markov decision processes\n(MDPs) our runtime and sample complexities are optimal due to Azar et al\n(2013). We achieve our results by showing how to generalize a near-optimal\nQ-learning based algorithms for MDP, in particular Sidford et al (2018), to\ntwo-player strategy computation algorithms. This overcomes limitations of\nstandard Q-learning and strategy iteration or alternating minimization based\napproaches and we hope will pave the way for future reinforcement learning\nresults by facilitating the extension of MDP results to multi-agent settings\nwith little loss.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 07:04:25 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Sidford", "Aaron", ""], ["Wang", "Mengdi", ""], ["Yang", "Lin F.", ""], ["Ye", "Yinyu", ""]]}, {"id": "1908.11091", "submitter": "Wenqi Wei", "authors": "Ling Liu, Wenqi Wei, Ka-Ho Chow, Margaret Loper, Emre Gursoy, Stacey\n  Truex, Yanzhao Wu", "title": "Deep Neural Network Ensembles against Deception: Ensemble Diversity,\n  Accuracy and Robustness", "comments": "To appear in IEEE MASS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning is a methodology that integrates multiple DNN learners for\nimproving prediction performance of individual learners. Diversity is greater\nwhen the errors of the ensemble prediction is more uniformly distributed.\nGreater diversity is highly correlated with the increase in ensemble accuracy.\nAnother attractive property of diversity optimized ensemble learning is its\nrobustness against deception: an adversarial perturbation attack can mislead\none DNN model to misclassify but may not fool other ensemble DNN members\nconsistently. In this paper we first give an overview of the concept of\nensemble diversity and examine the three types of ensemble diversity in the\ncontext of DNN classifiers. We then describe a set of ensemble diversity\nmeasures, a suite of algorithms for creating diversity ensembles and for\nperforming ensemble consensus (voted or learned) for generating high accuracy\nensemble output by strategically combining outputs of individual members. This\npaper concludes with a discussion on a set of open issues in quantifying\nensemble diversity for robust deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 08:22:05 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Liu", "Ling", ""], ["Wei", "Wenqi", ""], ["Chow", "Ka-Ho", ""], ["Loper", "Margaret", ""], ["Gursoy", "Emre", ""], ["Truex", "Stacey", ""], ["Wu", "Yanzhao", ""]]}, {"id": "1908.11092", "submitter": "Dong Lao", "authors": "Dong Lao and Ganesh Sundaramoorthi", "title": "Minimum Delay Object Detection From Video", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting objects, as they come into view, from\nvideos in an online fashion. We provide the first real-time solution that is\nguaranteed to minimize the delay, i.e., the time between when the object comes\nin view and the declared detection time, subject to acceptable levels of\ndetection accuracy. The method leverages modern CNN-based object detectors that\noperate on a single frame, to aggregate detection results over frames to\nprovide reliable detection at a rate, specified by the user, in guaranteed\nminimal delay. To do this, we formulate the problem as a Quickest Detection\nproblem, which provides the aforementioned guarantees. We derive our algorithms\nfrom this theory. We show in experiments, that with an overhead of just 50 fps,\nwe can increase the number of correct detections and decrease the overall\ncomputational cost compared to running a modern single-frame detector.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 08:25:40 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Lao", "Dong", ""], ["Sundaramoorthi", "Ganesh", ""]]}, {"id": "1908.11127", "submitter": "Marco Godi", "authors": "Marco Godi, Christian Joppi, Andrea Giachetti, Fabio Pellacini, Marco\n  Cristani", "title": "Texel-Att: Representing and Classifying Element-based Textures by\n  Attributes", "comments": "Accepted as oral at BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Element-based textures are a kind of texture formed by nameable elements, the\ntexels [1], distributed according to specific statistical distributions; it is\nof primary importance in many sectors, namely textile, fashion and interior\ndesign industry. State-of-theart texture descriptors fail to properly\ncharacterize element-based texture, so we present Texel-Att to fill this gap.\nTexel-Att is the first fine-grained, attribute-based representation and\nclassification framework for element-based textures. It first individuates\ntexels, characterizing them with individual attributes; subsequently, texels\nare grouped and characterized through layout attributes, which give the\nTexel-Att representation. Texels are detected by a Mask-RCNN, trained on a\nbrand-new element-based texture dataset, ElBa, containing 30K texture images\nwith 3M fully-annotated texels. Examples of individual and layout attributes\nare exhibited to give a glimpse on the level of achievable graininess. In the\nexperiments, we present detection results to show that texels can be precisely\nindividuated, even on textures \"in the wild\"; to this sake, we individuate the\nelement-based classes of the Describable Texture Dataset (DTD), where almost\n900K texels have been manually annotated, leading to the Element-based DTD\n(E-DTD). Subsequently, classification and ranking results demonstrate the\nexpressivity of Texel-Att on ElBa and E-DTD, overcoming the alternative\nfeatures and relative attributes, doubling the best performance in some cases;\nfinally, we report interactive search results on ElBa and E-DTD: with Texel-Att\non the E-DTD dataset we are able to individuate within 10 iterations the\ndesired texture in the 90% of cases, against the 71% obtained with a\ncombination of the finest existing attributes so far. Dataset and code is\navailable at https://github.com/godimarcovr/Texel-Att\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 09:50:44 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 07:14:19 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Godi", "Marco", ""], ["Joppi", "Christian", ""], ["Giachetti", "Andrea", ""], ["Pellacini", "Fabio", ""], ["Cristani", "Marco", ""]]}, {"id": "1908.11133", "submitter": "Sophie Langer", "authors": "Michael Kohler and Sophie Langer", "title": "On the rate of convergence of fully connected very deep neural network\n  regression estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results in nonparametric regression show that deep learning, i.e.,\nneural network estimates with many hidden layers, are able to circumvent the\nso-called curse of dimensionality in case that suitable restrictions on the\nstructure of the regression function hold. One key feature of the neural\nnetworks used in these results is that their network architecture has a further\nconstraint, namely the network sparsity. In this paper we show that we can get\nsimilar results also for least squares estimates based on simple fully\nconnected neural networks with ReLU activation functions. Here either the\nnumber of neurons per hidden layer is fixed and the number of hidden layers\ntends to infinity suitably fast for sample size tending to infinity, or the\nnumber of hidden layers is bounded by some logarithmic factor in the sample\nsize and the number of neurons per hidden layer tends to infinity suitably fast\nfor sample size tending to infinity. The proof is based on new approximation\nresults concerning deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 10:01:20 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 09:25:19 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 08:40:19 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 12:45:47 GMT"}, {"version": "v5", "created": "Tue, 29 Sep 2020 15:22:58 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Kohler", "Michael", ""], ["Langer", "Sophie", ""]]}, {"id": "1908.11140", "submitter": "Sophie Langer", "authors": "Michael Kohler, Adam Krzyzak and Sophie Langer", "title": "Estimation of a function of low local dimensionality by deep neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) achieve impressive results for complicated tasks\nlike object detection on images and speech recognition. Motivated by this\npractical success, there is now a strong interest in showing good theoretical\nproperties of DNNs. To describe for which tasks DNNs perform well and when they\nfail, it is a key challenge to understand their performance. The aim of this\npaper is to contribute to the current statistical theory of DNNs. We apply DNNs\non high dimensional data and we show that the least squares regression\nestimates using DNNs are able to achieve dimensionality reduction in case that\nthe regression function has locally low dimensionality. Consequently, the rate\nof convergence of the estimate does not depend on its input dimension $d$, but\non its local dimension $d^*$ and the DNNs are able to circumvent the curse of\ndimensionality in case that $d^*$ is much smaller than $d$. In our simulation\nstudy we provide numerical experiments to support our theoretical result and we\ncompare our estimate with other conventional nonparametric regression\nestimates. The performance of our estimates is also validated in experiments\nwith real data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 10:24:10 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 18:11:26 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 12:10:43 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kohler", "Michael", ""], ["Krzyzak", "Adam", ""], ["Langer", "Sophie", ""]]}, {"id": "1908.11161", "submitter": "Rafael Caba\\~nas", "authors": "Javier C\\'ozar, Rafael Caba\\~nas, Antonio Salmer\\'on, Andr\\'es R.\n  Masegosa", "title": "InferPy: Probabilistic Modeling with Deep Neural Networks Made Easy", "comments": "5 pages limit (paper submitted to an original software publication\n  track). This paper briefly describes a scientific software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  InferPy is a Python package for probabilistic modeling with deep neural\nnetworks. It defines a user-friendly API that trades-off model complexity with\nease of use, unlike other libraries whose focus is on dealing with very general\nprobabilistic models at the cost of having a more complex API. In particular,\nthis package allows to define, learn and evaluate general hierarchical\nprobabilistic models containing deep neural networks in a compact and simple\nway. InferPy is built on top of Tensorflow Probability and Keras.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 11:44:59 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 09:22:59 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 11:22:12 GMT"}, {"version": "v4", "created": "Wed, 12 Feb 2020 13:37:54 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["C\u00f3zar", "Javier", ""], ["Caba\u00f1as", "Rafael", ""], ["Salmer\u00f3n", "Antonio", ""], ["Masegosa", "Andr\u00e9s R.", ""]]}, {"id": "1908.11199", "submitter": "Theerawit Wilaiprasitporn", "authors": "Theerasarn Pianpanit, Sermkiat Lolak, Phattarapong Sawangjai, Thapanun\n  Sudhawiyangkul and Theerawit Wilaiprasitporn", "title": "Parkinson's Disease Recognition Using SPECT Image and Interpretable AI:\n  A Tutorial", "comments": null, "journal-ref": "IEEE Sensors Journal, 2021", "doi": "10.1109/JSEN.2021.3077949", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the past few years, there are several researches on Parkinson's disease\n(PD) recognition using single-photon emission computed tomography (SPECT)\nimages with deep learning (DL) approach. However, the DL model's complexity\nusually results in difficult model interpretation when used in clinical. Even\nthough there are multiple interpretation methods available for the DL model,\nthere is no evidence of which method is suitable for PD recognition\napplication. This tutorial aims to demonstrate the procedure to choose a\nsuitable interpretation method for the PD recognition model. We exhibit four\nDCNN architectures as an example and introduce six well-known interpretation\nmethods. Finally, we propose an evaluation method to measure the interpretation\nperformance and a method to use the interpreted feedback for assisting in model\nselection. The evaluation demonstrates that the guided backpropagation and SHAP\ninterpretation methods are suitable for PD recognition methods in different\naspects. Guided backpropagation has the best ability to show fine-grained\nimportance, which is proven by the highest Dice coefficient and lowest mean\nsquare error. On the other hand, SHAP can generate a better quality heatmap at\nthe uptake depletion location, which outperforms other methods in\ndiscriminating the difference between PD and NC subjects. Shortly, the\nintroduced interpretation methods can contribute to not only the PD recognition\napplication but also to sensor data processing in an AI Era (interpretable-AI)\nas feedback in constructing well-suited deep learning architectures for\nspecific applications.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 11:23:47 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 07:38:07 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 07:44:50 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 17:02:48 GMT"}, {"version": "v5", "created": "Fri, 9 Apr 2021 16:25:00 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Pianpanit", "Theerasarn", ""], ["Lolak", "Sermkiat", ""], ["Sawangjai", "Phattarapong", ""], ["Sudhawiyangkul", "Thapanun", ""], ["Wilaiprasitporn", "Theerawit", ""]]}, {"id": "1908.11200", "submitter": "Xiaohan Yang", "authors": "Xiaohan Yang and Qingyin Ge", "title": "A Concert-planning Tool for Independent Musicians by Machine Learning\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Our project aims at helping independent musicians to plan their concerts\nbased on the economies of agglomeration in the music industry. Initially, we\nplanned to design an advisory tool for both concert pricing and location\nselection. Nonetheless, after implementing SGD linear regression and support\nvector regression models, we realized that concert price does not vary\nsignificantly according to different music types, concert time, concert\nlocation and ticket venues. Therefore, to offer more useful suggestions, we\nfocus on the location choice problem by turning it to a classification task.\nThe overall performance of our classification model is pretty good. After\ntuning hyperparameters, we discovered the Random Forest gives the best\nperformance, improving the classification result by 316%. This result reveals\nthat we could help independent musicians better locate their concerts to where\nsimilar musicians would go, namely a place with higher network effects.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:13:40 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Yang", "Xiaohan", ""], ["Ge", "Qingyin", ""]]}, {"id": "1908.11211", "submitter": "G\\\"ozde Nur G\\\"une\\c{s}li", "authors": "Can Fahrettin Koyuncu, Gozde Nur Gunesli, Rengul Cetin-Atalay, Cigdem\n  Gunduz-Demir", "title": "DeepDistance: A Multi-task Deep Regression Model for Cell Detection in\n  Inverted Microscopy Images", "comments": "Preprint submitted to Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new deep regression model, which we call DeepDistance,\nfor cell detection in images acquired with inverted microscopy. This model\nconsiders cell detection as a task of finding most probable locations that\nsuggest cell centers in an image. It represents this main task with a\nregression task of learning an inner distance metric. However, different than\nthe previously reported regression based methods, the DeepDistance model\nproposes to approach its learning as a multi-task regression problem where\nmultiple tasks are learned by using shared feature representations. To this\nend, it defines a secondary metric, normalized outer distance, to represent a\ndifferent aspect of the problem and proposes to define its learning as\ncomplementary to the main cell detection task. In order to learn these two\ncomplementary tasks more effectively, the DeepDistance model designs a fully\nconvolutional network (FCN) with a shared encoder path and end-to-end trains\nthis FCN to concurrently learn the tasks in parallel. DeepDistance uses the\ninner distances estimated by this FCN in a detection algorithm to locate\nindividual cells in a given image. For further performance improvement on the\nmain task, this paper also presents an extended version of the DeepDistance\nmodel. This extended model includes an auxiliary classification task and learns\nit in parallel to the two regression tasks by sharing feature representations\nwith them. Our experiments on three different human cell lines reveal that the\nproposed multi-task learning models, the DeepDistance model and its extended\nversion, successfully identify cell locations, even for the cell line that was\nnot used in training, and improve the results of the previous deep learning\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:21:25 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Koyuncu", "Can Fahrettin", ""], ["Gunesli", "Gozde Nur", ""], ["Cetin-Atalay", "Rengul", ""], ["Gunduz-Demir", "Cigdem", ""]]}, {"id": "1908.11212", "submitter": "Kerda Varaku", "authors": "Kerda Varaku", "title": "Stock Price Forecasting and Hypothesis Testing Using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we use Recurrent Neural Networks and Multilayer Perceptrons to\npredict NYSE, NASDAQ and AMEX stock prices from historical data. We experiment\nwith different architectures and compare data normalization techniques. Then,\nwe leverage those findings to question the efficient-market hypothesis through\na formal statistical test.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 03:10:30 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Varaku", "Kerda", ""]]}, {"id": "1908.11219", "submitter": "Jivitesh Sharma", "authors": "Jivitesh Sharma, Ole-Christoffer Granmo and Morten Goodwin", "title": "Environment Sound Classification using Multiple Feature Channels and\n  Attention based Deep Convolutional Neural Network", "comments": "Re-checking results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a model for the Environment Sound Classification\nTask (ESC) that consists of multiple feature channels given as input to a Deep\nConvolutional Neural Network (CNN) with Attention mechanism. The novelty of the\npaper lies in using multiple feature channels consisting of Mel-Frequency\nCepstral Coefficients (MFCC), Gammatone Frequency Cepstral Coefficients (GFCC),\nthe Constant Q-transform (CQT) and Chromagram. Such multiple features have\nnever been used before for signal or audio processing. And, we employ a deeper\nCNN (DCNN) compared to previous models, consisting of spatially separable\nconvolutions working on time and feature domain separately. Alongside, we use\nattention modules that perform channel and spatial attention together. We use\nsome data augmentation techniques to further boost performance. Our model is\nable to achieve state-of-the-art performance on all three benchmark environment\nsound classification datasets, i.e. the UrbanSound8K (97.52%), ESC-10 (95.75%)\nand ESC-50 (88.50%). To the best of our knowledge, this is the first time that\na single environment sound classification model is able to achieve\nstate-of-the-art results on all three datasets. For ESC-10 and ESC-50 datasets,\nthe accuracy achieved by the proposed model is beyond human accuracy of 95.7%\nand 81.3% respectively.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:02:19 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 09:31:16 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 06:48:47 GMT"}, {"version": "v4", "created": "Wed, 25 Sep 2019 13:52:40 GMT"}, {"version": "v5", "created": "Wed, 4 Dec 2019 13:56:44 GMT"}, {"version": "v6", "created": "Thu, 27 Feb 2020 13:46:20 GMT"}, {"version": "v7", "created": "Thu, 2 Apr 2020 08:45:48 GMT"}, {"version": "v8", "created": "Mon, 16 Nov 2020 10:05:53 GMT"}, {"version": "v9", "created": "Tue, 8 Dec 2020 12:55:29 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Sharma", "Jivitesh", ""], ["Granmo", "Ole-Christoffer", ""], ["Goodwin", "Morten", ""]]}, {"id": "1908.11221", "submitter": "Chengqing Li", "authors": "Siwang Zhou, Yan He, Yonghe Liu, Chengqing Li", "title": "Multi-Channel Deep Networks for Block-Based Image Compressive Sensing", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating deep neural networks in image compressive sensing (CS) receives\nintensive attentions recently. As deep network approaches learn the inverse\nmapping directly from the CS measurements, a number of models have to be\ntrained, each of which corresponds to a sampling rate. This may potentially\ndegrade the performance of image CS, especially when multiple sampling rates\nare assigned to different blocks within an image. In this paper, we develop a\nmulti-channel deep network for block-based image CS with performance\nsignificantly exceeding the current state-of-the-art methods. The significant\nperformance improvement of the model is attributed to block-based sampling\nrates allocation and model-level removal of blocking artifacts. Specifically,\nthe image blocks with a variety of sampling rates can be reconstructed in a\nsingle model by exploiting inter-block correlation. At the same time, the\ninitially reconstructed blocks are reassembled into a full image to remove\nblocking artifacts within the network by unrolling a hand-designed block-based\nCS algorithm. Experimental results demonstrate that the proposed method\noutperforms the state-of-the-art CS methods by a large margin in terms of\nobjective metrics, PSNR, SSIM, and subjective visual quality.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:49:28 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Zhou", "Siwang", ""], ["He", "Yan", ""], ["Liu", "Yonghe", ""], ["Li", "Chengqing", ""]]}, {"id": "1908.11225", "submitter": "Mattia Lecci", "authors": "Paolo Testolina and Mattia Lecci and Mattia Rebato and Alberto\n  Testolin and Jonathan Gambini and Roberto Flamini and Christian Mazzucco and\n  Michele Zorzi", "title": "Enabling Simulation-Based Optimization Through Machine Learning: A Case\n  Study on Antenna Design", "comments": "6 pages, 5 figures, 1 table. Please cite it as: P. Testolina, M.\n  Lecci, M. Rebato, A. Testolin, J. Gambini, C. Mazzucco and M. Zorzi,\n  \"Enabling Simulation-Based Optimization Through Machine Learning: A Case\n  Study on Antenna Design\", in IEEE Global Communication Conference: Wireless\n  Communication (GLOBECOM WC), Waikoloa, USA, Dec. 2019", "journal-ref": null, "doi": "10.1109/GLOBECOM38437.2019.9013240", "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex phenomena are generally modeled with sophisticated simulators that,\ndepending on their accuracy, can be very demanding in terms of computational\nresources and simulation time. Their time-consuming nature, together with a\ntypically vast parameter space to be explored, make simulation-based\noptimization often infeasible. In this work, we present a method that enables\nthe optimization of complex systems through Machine Learning (ML) techniques.\nWe show how well-known learning algorithms are able to reliably emulate a\ncomplex simulator with a modest dataset obtained from it. The trained emulator\nis then able to yield values close to the simulated ones in virtually no time.\nTherefore, it is possible to perform a global numerical optimization over the\nvast multi-dimensional parameter space, in a fraction of the time that would be\nrequired by a simple brute-force search. As a testbed for the proposed\nmethodology, we used a network simulator for next-generation mmWave cellular\nsystems. After simulating several antenna configurations and collecting the\nresulting network-level statistics, we feed it into our framework. Results show\nthat, even with few data points, extrapolating a continuous model makes it\npossible to estimate the global optimum configuration almost instantaneously.\nThe very same tool can then be used to achieve any further optimization goal on\nthe same input parameters in negligible time.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:43:11 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 12:30:13 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Testolina", "Paolo", ""], ["Lecci", "Mattia", ""], ["Rebato", "Mattia", ""], ["Testolin", "Alberto", ""], ["Gambini", "Jonathan", ""], ["Flamini", "Roberto", ""], ["Mazzucco", "Christian", ""], ["Zorzi", "Michele", ""]]}, {"id": "1908.11229", "submitter": "Alexandre Sablayrolles", "authors": "Alexandre Sablayrolles, Matthijs Douze, Yann Ollivier, Cordelia\n  Schmid, Herv\\'e J\\'egou", "title": "White-box vs Black-box: Bayes Optimal Strategies for Membership\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership inference determines, given a sample and trained parameters of a\nmachine learning model, whether the sample was part of the training set. In\nthis paper, we derive the optimal strategy for membership inference with a few\nassumptions on the distribution of the parameters. We show that optimal attacks\nonly depend on the loss function, and thus black-box attacks are as good as\nwhite-box attacks. As the optimal strategy is not tractable, we provide\napproximations of it leading to several inference methods, and show that\nexisting membership inference methods are coarser approximations of this\noptimal strategy. Our membership attacks outperform the state of the art in\nvarious settings, ranging from a simple logistic regression to more complex\narchitectures and datasets, such as ResNet-101 and Imagenet.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:53:49 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Sablayrolles", "Alexandre", ""], ["Douze", "Matthijs", ""], ["Ollivier", "Yann", ""], ["Schmid", "Cordelia", ""], ["J\u00e9gou", "Herv\u00e9", ""]]}, {"id": "1908.11230", "submitter": "Bang Wu", "authors": "Bang Wu and Shuo Wang and Xingliang Yuan and Cong Wang and Carsten\n  Rudolph and Xiangwen Yang", "title": "Towards Defeating Misclassification Attacks Against Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is prevalent as a technique to efficiently generate new\nmodels (Student models) based on the knowledge transferred from a pre-trained\nmodel (Teacher model). However, Teacher models are often publicly available for\nsharing and reuse, which inevitably introduces vulnerability to trigger severe\nattacks against transfer learning systems. In this paper, we take a first step\ntowards mitigating one of the most advanced misclassification attacks in\ntransfer learning. We design a distilled differentiator via activation-based\nnetwork pruning to enervate the attack transferability while retaining\naccuracy. We adopt an ensemble structure from variant differentiators to\nimprove the defence robustness. To avoid the bloated ensemble size during\ninference, we propose two-phase defence, in which inference from the Student\nmodel is firstly performed to narrow down the candidate differentiators to be\nassembled, and later only a small, fixed number of them can be chosen to\nvalidate clean or reject adversarial inputs effectively. Our comprehensive\nevaluations on both large and small image recognition tasks confirm that the\nStudent models with our defence of only 5 differentiators immune over 90% the\nadversarial inputs with accuracy loss less than 10%. Our comparison also\ndemonstrates that our design outperforms prior problematic defences.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:54:08 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 02:37:12 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 06:27:02 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Wu", "Bang", ""], ["Wang", "Shuo", ""], ["Yuan", "Xingliang", ""], ["Wang", "Cong", ""], ["Rudolph", "Carsten", ""], ["Yang", "Xiangwen", ""]]}, {"id": "1908.11233", "submitter": "Benjamin Peherstorfer", "authors": "Benjamin Peherstorfer", "title": "Sampling low-dimensional Markovian dynamics for pre-asymptotically\n  recovering reduced models from data with operator inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a method for learning low-dimensional models from data\nof high-dimensional black-box dynamical systems. The novelty is that the\nlearned models are exactly the reduced models that are traditionally\nconstructed with model reduction techniques that require full knowledge of\ngoverning equations and operators of the high-dimensional systems. Thus, the\nlearned models are guaranteed to inherit the well-studied properties of reduced\nmodels from traditional model reduction. The key ingredient is a new data\nsampling scheme to obtain re-projected trajectories of high-dimensional systems\nthat correspond to Markovian dynamics in low-dimensional subspaces. The exact\nrecovery of reduced models from these re-projected trajectories is guaranteed\npre-asymptotically under certain conditions for finite amounts of data and for\na large class of systems with polynomial nonlinear terms. Numerical results\ndemonstrate that the low-dimensional models learned with the proposed approach\nmatch reduced models from traditional model reduction up to numerical errors in\npractice. The numerical results further indicate that low-dimensional models\nfitted to re-projected trajectories are predictive even in situations where\nmodels fitted to trajectories without re-projection are inaccurate and\nunstable.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:55:17 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Peherstorfer", "Benjamin", ""]]}, {"id": "1908.11250", "submitter": "Suraj Tripathi", "authors": "Mayank Sharma, Suraj Tripathi, Abhimanyu Dubey, Jayadeva, Sai Guruju,\n  Nihal Goalla", "title": "Smaller Models, Better Generalization", "comments": "10 pages, 3 figures, In Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing network complexity has been a major research focus in recent years\nwith the advent of mobile technology. Convolutional Neural Networks that\nperform various vision tasks without memory overhaul is the need of the hour.\nThis paper focuses on qualitative and quantitative analysis of reducing the\nnetwork complexity using an upper bound on the Vapnik-Chervonenkis dimension,\npruning, and quantization. We observe a general trend in improvement of\naccuracies as we quantize the models. We propose a novel loss function that\nhelps in achieving considerable sparsity at comparable accuracies to that of\ndense models. We compare various regularizations prevalent in the literature\nand show the superiority of our method in achieving sparser models that\ngeneralize well.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 14:17:41 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Sharma", "Mayank", ""], ["Tripathi", "Suraj", ""], ["Dubey", "Abhimanyu", ""], ["Jayadeva", "", ""], ["Guruju", "Sai", ""], ["Goalla", "Nihal", ""]]}, {"id": "1908.11262", "submitter": "Dogancan Temel", "authors": "Dogancan Temel and Min-Hung Chen and Ghassan AlRegib", "title": "Traffic Sign Detection under Challenging Conditions: A Deeper Look Into\n  Performance Variations and Spectral Characteristics", "comments": "13 pages, 9 figures, 4 tables. IEEE Transactions on Intelligent\n  Transportation Systems, 2019", "journal-ref": null, "doi": "10.1109/TITS.2019.2931429", "report-no": null, "categories": "cs.CV cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic signs are critical for maintaining the safety and efficiency of our\nroads. Therefore, we need to carefully assess the capabilities and limitations\nof automated traffic sign detection systems. Existing traffic sign datasets are\nlimited in terms of type and severity of challenging conditions. Metadata\ncorresponding to these conditions are unavailable and it is not possible to\ninvestigate the effect of a single factor because of simultaneous changes in\nnumerous conditions. To overcome the shortcomings in existing datasets, we\nintroduced the CURE-TSD-Real dataset, which is based on simulated challenging\nconditions that correspond to adversaries that can occur in real-world\nenvironments and systems. We test the performance of two benchmark algorithms\nand show that severe conditions can result in an average performance\ndegradation of 29% in precision and 68% in recall. We investigate the effect of\nchallenging conditions through spectral analysis and show that challenging\nconditions can lead to distinct magnitude spectrum characteristics. Moreover,\nwe show that mean magnitude spectrum of changes in video sequences under\nchallenging conditions can be an indicator of detection performance.\nCURE-TSD-Real dataset is available online at\nhttps://github.com/olivesgatech/CURE-TSD.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 14:37:40 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Temel", "Dogancan", ""], ["Chen", "Min-Hung", ""], ["AlRegib", "Ghassan", ""]]}, {"id": "1908.11272", "submitter": "David Gaudrie", "authors": "David Gaudrie, Rodolphe Le Riche, Victor Picheny, Benoit Enaux,\n  Vincent Herbert", "title": "Modeling and Optimization with Gaussian Processes in Reduced Eigenbases\n  -- Extended Version", "comments": null, "journal-ref": "Structural and Multidisciplinary Optimization, 2020, 61,\n  pp.2343-2361", "doi": "10.1007/s00158-019-02458-6", "report-no": null, "categories": "stat.ML cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parametric shape optimization aims at minimizing an objective function f(x)\nwhere x are CAD parameters. This task is difficult when f is the output of an\nexpensive-to-evaluate numerical simulator and the number of CAD parameters is\nlarge. Most often, the set of all considered CAD shapes resides in a manifold\nof lower effective dimension in which it is preferable to build the surrogate\nmodel and perform the optimization. In this work, we uncover the manifold\nthrough a high-dimensional shape mapping and build a new coordinate system made\nof eigenshapes. The surrogate model is learned in the space of eigenshapes: a\nregularized likelihood maximization provides the most relevant dimensions for\nthe output. The final surrogate model is detailed (anisotropic) with respect to\nthe most sensitive eigenshapes and rough (isotropic) in the remaining\ndimensions. Last, the optimization is carried out with a focus on the critical\ndimensions, the remaining ones being coarsely optimized through a random\nembedding and the manifold being accounted for through a replication strategy.\nAt low budgets, the methodology leads to a more accurate model and a faster\noptimization than the classical approach of directly working with the CAD\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 14:58:20 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 06:48:22 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Gaudrie", "David", ""], ["Riche", "Rodolphe Le", ""], ["Picheny", "Victor", ""], ["Enaux", "Benoit", ""], ["Herbert", "Vincent", ""]]}, {"id": "1908.11307", "submitter": "Yoshiaki Bando", "authors": "Yoshiaki Bando, Yoko Sasaki, Kazuyoshi Yoshii", "title": "Deep Bayesian Unsupervised Source Separation Based on a Complex Gaussian\n  Mixture Model", "comments": "6 pages, 2 figures, accepted for publication in 2019 IEEE\n  International Workshop on Machine Learning for Signal Processing (MLSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an unsupervised method that trains neural source\nseparation by using only multichannel mixture signals. Conventional neural\nseparation methods require a lot of supervised data to achieve excellent\nperformance. Although multichannel methods based on spatial information can\nwork without such training data, they are often sensitive to parameter\ninitialization and degraded with the sources located close to each other. The\nproposed method uses a cost function based on a spatial model called a complex\nGaussian mixture model (cGMM). This model has the time-frequency (TF) masks and\ndirection of arrivals (DoAs) of sources as latent variables and is used for\ntraining separation and localization networks that respectively estimate these\nvariables. This joint training solves the frequency permutation ambiguity of\nthe spatial model in a unified deep Bayesian framework. In addition, the\npre-trained network can be used not only for conducting monaural separation but\nalso for efficiently initializing a multichannel separation algorithm.\nExperimental results with simulated speech mixtures showed that our method\noutperformed a conventional initialization method.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:45:20 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Bando", "Yoshiaki", ""], ["Sasaki", "Yoko", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1908.11309", "submitter": "Radu Sibechi", "authors": "Radu Sibechi, Olaf Booij, Nora Baka, Peter Bloem", "title": "Exploiting Temporality for Semi-Supervised Video Segmentation", "comments": "Accepted as workshop paper at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been remarkable progress in supervised image\nsegmentation. Video segmentation is less explored, despite the temporal\ndimension being highly informative. Semantic labels, e.g. that cannot be\naccurately detected in the current frame, may be inferred by incorporating\ninformation from previous frames. However, video segmentation is challenging\ndue to the amount of data that needs to be processed and, more importantly, the\ncost involved in obtaining ground truth annotations for each frame. In this\npaper, we tackle the issue of label scarcity by using consecutive frames of a\nvideo, where only one frame is annotated. We propose a deep, end-to-end\ntrainable model which leverages temporal information in order to make use of\neasy to acquire unlabeled data. Our network architecture relies on a novel\ninterconnection of two components: a fully convolutional network to model\nspatial information and temporal units that are employed at intermediate levels\nof the convolutional network in order to propagate information through time.\nThe main contribution of this work is the guidance of the temporal signal\nthrough the network. We show that only placing a temporal module between the\nencoder and decoder is suboptimal (baseline). Our extensive experiments on the\nCityScapes dataset indicate that the resulting model can leverage unlabeled\ntemporal frames and significantly outperform both the frame-by-frame image\nsegmentation and the baseline approach.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:50:12 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Sibechi", "Radu", ""], ["Booij", "Olaf", ""], ["Baka", "Nora", ""], ["Bloem", "Peter", ""]]}, {"id": "1908.11317", "submitter": "Hongxiao Bai", "authors": "Hongxiao Bai, Hai Zhao, Junhan Zhao", "title": "Memorizing All for Implicit Discourse Relation Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit discourse relation recognition is a challenging task due to the\nabsence of the necessary informative clue from explicit connectives. The\nprediction of relations requires a deep understanding of the semantic meanings\nof sentence pairs. As implicit discourse relation recognizer has to carefully\ntackle the semantic similarity of the given sentence pairs and the severe data\nsparsity issue exists in the meantime, it is supposed to be beneficial from\nmastering the entire training data. Thus in this paper, we propose a novel\nmemory mechanism to tackle the challenges for further performance improvement.\nThe memory mechanism is adequately memorizing information by pairing\nrepresentations and discourse relations of all training instances, which right\nfills the slot of the data-hungry issue in the current implicit discourse\nrelation recognizer. Our experiments show that our full model with memorizing\nthe entire training set reaches new state-of-the-art against strong baselines,\nwhich especially for the first time exceeds the milestone of 60% accuracy in\nthe 4-way task.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:00:25 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Bai", "Hongxiao", ""], ["Zhao", "Hai", ""], ["Zhao", "Junhan", ""]]}, {"id": "1908.11319", "submitter": "Mi Yan", "authors": "Mi Yan, Jonathan C. MacDonald, Chris T. Reaume, Wesley Cobb, Tamas\n  Toth, Sarah S. Karthigan", "title": "Machine Learning and the Internet of Things Enable Steam Flood\n  Optimization for Improved Oil Production", "comments": "Accepted by the 1st International Workshop on Artificial Intelligence\n  of Things at KDD 2019", "journal-ref": "The 1st International Workshop on Artificial Intelligence of\n  Things at KDD 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed machine learning techniques, in association with the\nInternet of Things (IoT) allow for the implementation of a method of increasing\noil production from heavy-oil wells. Steam flood injection, a widely used\nenhanced oil recovery technique, uses thermal and gravitational potential to\nmobilize and dilute heavy oil in situ to increase oil production. In contrast\nto traditional steam flood simulations based on principles of classic physics,\nwe introduce here an approach using cutting-edge machine learning techniques\nthat have the potential to provide a better way to describe the performance of\nsteam flood. We propose a workflow to address a category of time-series data\nthat can be analyzed with supervised machine learning algorithms and IoT. We\ndemonstrate the effectiveness of the technique for forecasting oil production\nin steam flood scenarios. Moreover, we build an optimization system that\nrecommends an optimal steam allocation plan, and show that it leads to a 3%\nimprovement in oil production. We develop a minimum viable product on a cloud\nplatform that can implement real-time data collection, transfer, and storage,\nas well as the training and implementation of a cloud-based machine learning\nmodel. This workflow also offers an applicable solution to other problems with\nsimilar time-series data structures, like predictive maintenance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:04:38 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 01:08:54 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Yan", "Mi", ""], ["MacDonald", "Jonathan C.", ""], ["Reaume", "Chris T.", ""], ["Cobb", "Wesley", ""], ["Toth", "Tamas", ""], ["Karthigan", "Sarah S.", ""]]}, {"id": "1908.11326", "submitter": "Angel Daza", "authors": "Angel Daza, Anette Frank", "title": "Translate and Label! An Encoder-Decoder Approach for Cross-lingual\n  Semantic Role Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Cross-lingual Encoder-Decoder model that simultaneously\ntranslates and generates sentences with Semantic Role Labeling annotations in a\nresource-poor target language. Unlike annotation projection techniques, our\nmodel does not need parallel data during inference time. Our approach can be\napplied in monolingual, multilingual and cross-lingual settings and is able to\nproduce dependency-based and span-based SRL annotations. We benchmark the\nlabeling performance of our model in different monolingual and multilingual\nsettings using well-known SRL datasets. We then train our model in a\ncross-lingual setting to generate new SRL labeled data. Finally, we measure the\neffectiveness of our method by using the generated data to augment the training\nbasis for resource-poor languages and perform manual evaluation to show that it\nproduces high-quality sentences and assigns accurate semantic role annotations.\nOur proposed architecture offers a flexible method for leveraging SRL data in\nmultiple languages.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:17:53 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Daza", "Angel", ""], ["Frank", "Anette", ""]]}, {"id": "1908.11331", "submitter": "Xin Zhong", "authors": "Xin Zhong and Frank Y. Shih", "title": "A Robust Image Watermarking System Based on Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TMM.2020.3006415", "report-no": null, "categories": "cs.MM cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital image watermarking is the process of embedding and extracting\nwatermark covertly on a carrier image. Incorporating deep learning networks\nwith image watermarking has attracted increasing attention during recent years.\nHowever, existing deep learning-based watermarking systems cannot achieve\nrobustness, blindness, and automated embedding and extraction simultaneously.\nIn this paper, a fully automated image watermarking system based on deep neural\nnetworks is proposed to generalize the image watermarking processes. An\nunsupervised deep learning structure and a novel loss computation are proposed\nto achieve high capacity and high robustness without any prior knowledge of\npossible attacks. Furthermore, a challenging application of watermark\nextraction from camera-captured images is provided to validate the practicality\nas well as the robustness of the proposed system. Experimental results show the\nsuperiority performance of the proposed system as comparing against several\ncurrently available techniques.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:24:29 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhong", "Xin", ""], ["Shih", "Frank Y.", ""]]}, {"id": "1908.11332", "submitter": "Junde Wu", "authors": "Junde Wu", "title": "Generating adversarial examples in the harsh conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have been found vulnerable re-cently. A kind of\nwell-designed inputs, which called adver-sarial examples, can lead the networks\nto make incorrectpredictions. Depending on the different scenarios, goalsand\ncapabilities, the difficulties of the attacks are different.For example, a\ntargeted attack is more difficult than a non-targeted attack, a universal\nattack is more difficult than anon-universal attack, a transferable attack is\nmore difficultthan a nontransferable one. The question is: Is there existan\nattack that can meet all these requirements? In this pa-per, we answer this\nquestion by producing a kind of attacksunder these conditions. We learn a\nuniversal mapping tomap the sources to the adversarial examples. These\nexam-ples can fool classification networks to classify all of theminto one\ntargeted class, and also have strong transferability.Our code is released at:\nxxxxx.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:27:24 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 15:17:55 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 21:25:14 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Wu", "Junde", ""]]}, {"id": "1908.11335", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane and Pasin Manurangsi", "title": "Nearly Tight Bounds for Robust Proper Learning of Halfspaces with a\n  Margin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of {\\em properly} learning large margin halfspaces in\nthe agnostic PAC model. In more detail, we study the complexity of properly\nlearning $d$-dimensional halfspaces on the unit ball within misclassification\nerror $\\alpha \\cdot \\mathrm{OPT}_{\\gamma} + \\epsilon$, where\n$\\mathrm{OPT}_{\\gamma}$ is the optimal $\\gamma$-margin error rate and $\\alpha\n\\geq 1$ is the approximation ratio. We give learning algorithms and\ncomputational hardness results for this problem, for all values of the\napproximation ratio $\\alpha \\geq 1$, that are nearly-matching for a range of\nparameters. Specifically, for the natural setting that $\\alpha$ is any constant\nbigger than one, we provide an essentially tight complexity characterization.\nOn the positive side, we give an $\\alpha = 1.01$-approximate proper learner\nthat uses $O(1/(\\epsilon^2\\gamma^2))$ samples (which is optimal) and runs in\ntime $\\mathrm{poly}(d/\\epsilon) \\cdot 2^{\\tilde{O}(1/\\gamma^2)}$. On the\nnegative side, we show that {\\em any} constant factor approximate proper\nlearner has runtime $\\mathrm{poly}(d/\\epsilon) \\cdot 2^{(1/\\gamma)^{2-o(1)}}$,\nassuming the Exponential Time Hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:34:25 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "1908.11338", "submitter": "Siddharth Samsi", "authors": "Tao B. Schardl and Siddharth Samsi", "title": "TapirXLA: Embedding Fork-Join Parallelism into the XLA Compiler in\n  TensorFlow Using Tapir", "comments": "IEEE HPEC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces TapirXLA, a replacement for TensorFlow's XLA compiler\nthat embeds recursive fork-join parallelism into XLA's low-level representation\nof code. Machine-learning applications rely on efficient parallel processing to\nachieve performance, and they employ a variety of technologies to improve\nperformance, including compiler technology. But compilers in machine-learning\nframeworks lack a deep understanding of parallelism, causing them to lose\nperformance by missing optimizations on parallel computation. This work studies\nhow Tapir, a compiler intermediate representation (IR) that embeds parallelism\ninto a mainstream compiler IR, can be incorporated into a compiler for machine\nlearning to remedy this problem. TapirXLA modifies the XLA compiler in\nTensorFlow to employ the Tapir/LLVM compiler to optimize low-level parallel\ncomputation. TapirXLA encodes the parallelism within high-level TensorFlow\noperations using Tapir's representation of fork-join parallelism. TapirXLA also\nexposes to the compiler implementations of linear-algebra library routines\nwhose parallel operations are encoded using Tapir's representation. We compared\nthe performance of TensorFlow using TapirXLA against TensorFlow using an\nunmodified XLA compiler. On four neural-network benchmarks, TapirXLA speeds up\nthe parallel running time of the network by a geometric-mean multiplicative\nfactor of 30% to 100%, across four CPU architectures.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:42:52 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Schardl", "Tao B.", ""], ["Samsi", "Siddharth", ""]]}, {"id": "1908.11355", "submitter": "Piyawat Lertvittayakumjorn", "authors": "Piyawat Lertvittayakumjorn, Francesca Toni", "title": "Human-grounded Evaluations of Explanation Methods for Text\n  Classification", "comments": "17 pages including appendices; accepted to appear at EMNLP-IJCNLP\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the black-box nature of deep learning models, methods for explaining\nthe models' results are crucial to gain trust from humans and support\ncollaboration between AIs and humans. In this paper, we consider several\nmodel-agnostic and model-specific explanation methods for CNNs for text\nclassification and conduct three human-grounded evaluations, focusing on\ndifferent purposes of explanations: (1) revealing model behavior, (2)\njustifying model predictions, and (3) helping humans investigate uncertain\npredictions. The results highlight dissimilar qualities of the various\nexplanation methods we consider and show the degree to which these methods\ncould serve for each purpose.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 17:12:04 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Lertvittayakumjorn", "Piyawat", ""], ["Toni", "Francesca", ""]]}, {"id": "1908.11358", "submitter": "Noah Golowich", "authors": "Badih Ghazi, Noah Golowich, Ravi Kumar, Rasmus Pagh, Ameya Velingker", "title": "On the Power of Multiple Anonymous Messages", "comments": "70 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An exciting new development in differential privacy is the shuffled model, in\nwhich an anonymous channel enables non-interactive, differentially private\nprotocols with error much smaller than what is possible in the local model,\nwhile relying on weaker trust assumptions than in the central model. In this\npaper, we study basic counting problems in the shuffled model and establish\nseparations between the error that can be achieved in the single-message\nshuffled model and in the shuffled model with multiple messages per user.\n  For the problem of frequency estimation for $n$ users and a domain of size\n$B$, we obtain:\n  - A nearly tight lower bound of $\\tilde{\\Omega}( \\min(\\sqrt[4]{n},\n\\sqrt{B}))$ on the error in the single-message shuffled model. This implies\nthat the protocols obtained from the amplification via shuffling work of\nErlingsson et al. (SODA 2019) and Balle et al. (Crypto 2019) are essentially\noptimal for single-message protocols. A key ingredient in the proof is a lower\nbound on the error of locally-private frequency estimation in the low-privacy\n(aka high $\\epsilon$) regime.\n  - Protocols in the multi-message shuffled model with $poly(\\log{B}, \\log{n})$\nbits of communication per user and $poly\\log{B}$ error, which provide an\nexponential improvement on the error compared to what is possible with\nsingle-message algorithms.\n  For the related selection problem on a domain of size $B$, we prove:\n  - A nearly tight lower bound of $\\Omega(B)$ on the number of users in the\nsingle-message shuffled model. This significantly improves on the\n$\\Omega(B^{1/17})$ lower bound obtained by Cheu et al. (Eurocrypt 2019), and\nwhen combined with their $\\tilde{O}(\\sqrt{B})$-error multi-message protocol,\nimplies the first separation between single-message and multi-message protocols\nfor this problem.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 17:26:23 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 16:40:51 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 20:42:51 GMT"}, {"version": "v4", "created": "Tue, 19 May 2020 05:53:03 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ghazi", "Badih", ""], ["Golowich", "Noah", ""], ["Kumar", "Ravi", ""], ["Pagh", "Rasmus", ""], ["Velingker", "Ameya", ""]]}, {"id": "1908.11399", "submitter": "Andrey Kormilitzin", "authors": "Andrey Kormilitzin, Xinyu Yang, William H. Stone, Caroline Woffindale,\n  Francesca Nicholls, Elena Ribe, Alejo Nevado-Holgado, Noel Buckley", "title": "Deep Learning for Estimating Synaptic Health of Primary Neuronal Cell\n  Culture", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the morphological changes of primary neuronal cells induced by\nchemical compounds is essential for drug discovery. Using the data from a\nsingle high-throughput imaging assay, a classification model for predicting the\nbiological activity of candidate compounds was introduced. The image\nrecognition model which is based on deep convolutional neural network (CNN)\narchitecture with residual connections achieved accuracy of 99.6$\\%$ on a\nbinary classification task of distinguishing untreated and treated rodent\nprimary neuronal cells with Amyloid-$\\beta_{(25-35)}$.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 18:03:07 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Kormilitzin", "Andrey", ""], ["Yang", "Xinyu", ""], ["Stone", "William H.", ""], ["Woffindale", "Caroline", ""], ["Nicholls", "Francesca", ""], ["Ribe", "Elena", ""], ["Nevado-Holgado", "Alejo", ""], ["Buckley", "Noel", ""]]}, {"id": "1908.11404", "submitter": "Xi Chen", "authors": "Xi C. Chen, Adithya Sagar, Justine T. Kao, Tony Y. Li, Christopher\n  Klein, Stephen Pulman, Ashish Garg, Jason D. Williams", "title": "Active Learning for Domain Classification in a Commercial Spoken\n  Personal Assistant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for selecting relevant new training data for the\nLSTM-based domain selection component of our personal assistant system. Adding\nmore annotated training data for any ML system typically improves accuracy, but\nonly if it provides examples not already adequately covered in the existing\ndata. However, obtaining, selecting, and labeling relevant data is expensive.\nThis work presents a simple technique that automatically identifies new helpful\nexamples suitable for human annotation. Our experimental results show that the\nproposed method, compared with random-selection and entropy-based methods,\nleads to higher accuracy improvements given a fixed annotation budget. Although\ndeveloped and tested in the setting of a commercial intelligent assistant, the\ntechnique is of wider applicability.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 18:14:46 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Chen", "Xi C.", ""], ["Sagar", "Adithya", ""], ["Kao", "Justine T.", ""], ["Li", "Tony Y.", ""], ["Klein", "Christopher", ""], ["Pulman", "Stephen", ""], ["Garg", "Ashish", ""], ["Williams", "Jason D.", ""]]}, {"id": "1908.11406", "submitter": "Sercan Arik", "authors": "Linchao Zhu, Sercan O. Arik, Yi Yang and Tomas Pfister", "title": "Learning to Transfer Learn: Reinforcement Learning-Based Selection for\n  Adaptive Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adaptive transfer learning framework, learning to transfer\nlearn (L2TL), to improve performance on a target dataset by careful extraction\nof the related information from a source dataset. Our framework considers\ncooperative optimization of shared weights between models for source and target\ntasks, and adjusts the constituent loss weights adaptively. The adaptation of\nthe weights is based on a reinforcement learning (RL) selection policy, guided\nwith a performance metric on the target validation set. We demonstrate that\nL2TL outperforms fine-tuning baselines and other adaptive transfer learning\nmethods on eight datasets. In the regimes of small-scale target datasets and\nsignificant label mismatch between source and target datasets, L2TL shows\nparticularly large benefits.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 18:16:24 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:39:01 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Zhu", "Linchao", ""], ["Arik", "Sercan O.", ""], ["Yang", "Yi", ""], ["Pfister", "Tomas", ""]]}, {"id": "1908.11415", "submitter": "Zelun Wang", "authors": "Zelun Wang, Jyh-Charn Liu", "title": "Translating Math Formula Images to LaTeX Sequences Using Deep Neural\n  Networks with Sequence-level Training", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a deep neural network model with an encoder-decoder\narchitecture that translates images of math formulas into their LaTeX markup\nsequences. The encoder is a convolutional neural network (CNN) that transforms\nimages into a group of feature maps. To better capture the spatial\nrelationships of math symbols, the feature maps are augmented with 2D\npositional encoding before being unfolded into a vector. The decoder is a\nstacked bidirectional long short-term memory (LSTM) model integrated with the\nsoft attention mechanism, which works as a language model to translate the\nencoder output into a sequence of LaTeX tokens. The neural network is trained\nin two steps. The first step is token-level training using the\nMaximum-Likelihood Estimation (MLE) as the objective function. At completion of\nthe token-level training, the sequence-level training objective function is\nemployed to optimize the overall model based on the policy gradient algorithm\nfrom reinforcement learning. Our design also overcomes the exposure bias\nproblem by closing the feedback loop in the decoder during sequence-level\ntraining, i.e., feeding in the predicted token instead of the ground truth\ntoken at every time step. The model is trained and evaluated on the\nIM2LATEX-100K dataset and shows state-of-the-art performance on both\nsequence-based and image-based evaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 18:33:21 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 19:09:42 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wang", "Zelun", ""], ["Liu", "Jyh-Charn", ""]]}, {"id": "1908.11435", "submitter": "Dou Goodman", "authors": "Dou Goodman and Xingjian Li and Jun Huan and Tao Wei", "title": "Improving Adversarial Robustness via Attention and Adversarial Logit\n  Pairing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though deep neural networks have achieved the state of the art performance in\nvisual classification, recent studies have shown that they are all vulnerable\nto the attack of adversarial examples. In this paper, we develop improved\ntechniques for defending against adversarial examples.First, we introduce\nenhanced defense using a technique we call \\textbf{Attention and Adversarial\nLogit Pairing(AT+ALP)}, a method that encourages both attention map and logit\nfor pairs of examples to be similar. When applied to clean examples and their\nadversarial counterparts, \\textbf{AT+ALP} improves accuracy on adversarial\nexamples over adversarial training.Next,We show that our \\textbf{AT+ALP} can\neffectively increase the average activations of adversarial examples in the key\narea and demonstrate that it focuse on more discriminate features to improve\nthe robustness of the model.Finally,we conducte extensive experiments using a\nwide range of datasets and the experiment results show that our \\textbf{AT+ALP}\nachieves \\textbf{the state of the art} defense.For example,on \\textbf{17 Flower\nCategory Database}, under strong 200-iteration \\textbf{PGD} gray-box and\nblack-box attacks where prior art has 34\\% and 39\\% accuracy, our method\nachieves \\textbf{50\\%} and \\textbf{51\\%}.Compared with previous work,our work\nis evaluated under highly challenging PGD attack:the maximum perturbation\n$\\epsilon \\in \\{0.25,0.5\\}$ i.e. $L_\\infty \\in \\{0.25,0.5\\}$ with 10 to 200\nattack iterations.To our knowledge, such a strong attack has not been\npreviously explored on a wide range of datasets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 13:40:06 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Goodman", "Dou", ""], ["Li", "Xingjian", ""], ["Huan", "Jun", ""], ["Wei", "Tao", ""]]}, {"id": "1908.11450", "submitter": "Siqi Wang", "authors": "Siqi Wang, Anuj Pathania, Tulika Mitra", "title": "Neural Network Inference on Mobile SoCs", "comments": "Accepted to IEEE Design & Test", "journal-ref": "in IEEE Design & Test, vol. 37, no. 5, pp. 50-57, Oct. 2020", "doi": "10.1109/MDAT.2020.2968258", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing demand from mobile Machine Learning (ML) applications\ncalls for evermore powerful on-chip computing resources. Mobile devices are\nempowered with heterogeneous multi-processor Systems-on-Chips (SoCs) to process\nML workloads such as Convolutional Neural Network (CNN) inference. Mobile SoCs\nhouse several different types of ML capable components on-die, such as CPU,\nGPU, and accelerators. These different components are capable of independently\nperforming inference but with very different power-performance characteristics.\nIn this article, we provide a quantitative evaluation of the inference\ncapabilities of the different components on mobile SoCs. We also present\ninsights behind their respective power-performance behavior. Finally, we\nexplore the performance limit of the mobile SoCs by synergistically engaging\nall the components concurrently. We observe that a mobile SoC provides up to 2x\nimprovement with parallel inference when all its components are engaged, as\nopposed to engaging only one component.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 07:13:57 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 16:03:15 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Wang", "Siqi", ""], ["Pathania", "Anuj", ""], ["Mitra", "Tulika", ""]]}, {"id": "1908.11462", "submitter": "Liu Yang", "authors": "Liu Yang and George Em Karniadakis", "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a potential flow generator with $L_2$ optimal transport\nregularity, which can be easily integrated into a wide range of generative\nmodels including different versions of GANs and flow-based models. We show the\ncorrectness and robustness of the potential flow generator in several 2D\nproblems, and illustrate the concept of \"proximity\" due to the $L_2$ optimal\ntransport regularity. Subsequently, we demonstrate the effectiveness of the\npotential flow generator in image translation tasks with unpaired training data\nfrom the MNIST dataset and the CelebA dataset.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 22:00:49 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Yang", "Liu", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1908.11472", "submitter": "Jean Mercat", "authors": "Jean Mercat, Nicole El Zoghby, Guillaume Sandou, Dominique Beauvois,\n  and Guillermo Pita Gil", "title": "Kinematic Single Vehicle Trajectory Prediction Baselines and\n  Applications with the NGSIM Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent vehicle trajectory prediction literature, the most common\nbaselines are briefly introduced without the necessary information to reproduce\nit. In this article we produce reproducible vehicle prediction results from\nsimple models. For that purpose, the process is explicit, and the code is\navailable. Those baseline models are a constant velocity model and a\nsingle-vehicle prediction model. They are applied on the NGSIM US-101 and I-80\ndatasets using only relative positions. Thus, the process can be reproduced\nwith any database containing tracking of vehicle positions. The evaluation\nreports Root Mean Squared Error (RMSE), Final Displacement Error (FDE),\nNegative Log-Likelihood (NLL), and Miss Rate (MR). The NLL estimation needs a\ncareful definition because several formulations that differ from the\nmathematical definition are used in other works. This article is meant to be\nused along with the published code to establish baselines for further work. An\nextension is proposed to replace the constant velocity assumption with a\nlearned model using a recurrent neural network. This brings good improvements\nin accuracy and uncertainty estimation and opens possibilities for both complex\nand interpretable models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 22:38:28 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 14:46:48 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 12:39:15 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 12:44:17 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Mercat", "Jean", ""], ["Zoghby", "Nicole El", ""], ["Sandou", "Guillaume", ""], ["Beauvois", "Dominique", ""], ["Gil", "Guillermo Pita", ""]]}, {"id": "1908.11479", "submitter": "Hamidreza Tavafoghi", "authors": "Hamidreza Tavafoghi, Kameshwar Poolla, and Pravin Varaiya", "title": "A Queuing Approach to Parking: Modeling, Verification, and Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a queuing model of parking dynamics and a model-based prediction\nmethod to provide real-time probabilistic forecasts of future parking\noccupancy. The queuing model has a non-homogeneous arrival rate and\ntime-varying service time distribution. All statistical assumptions of the\nmodel are verified using data from 29 truck parking locations, each with\nbetween 55 and 299 parking spots. For each location and each spot the data\nspecifies the arrival and departure times of a truck, for 16 months of\noperation. The modeling framework presented in this paper provides empirical\nsupport for queuing models adopted in many theoretical studies and policy\ndesigns. We discuss how our framework can be used to study parking problems in\ndifferent environments. Based on the queuing model, we propose two prediction\nmethods, a microscopic method and a macroscopic method, that provide a\nreal-time probabilistic forecast of parking occupancy for an arbitrary forecast\nhorizon. These model-based methods convert a probabilistic forecast problem\ninto a parameter estimation problem that can be tackled using classical\nestimation methods such as regressions or pure machine learning algorithms. We\ncharacterize a lower bound for an arbitrary real-time prediction algorithm. We\nevaluate the performance of these methods using the truck data comparing the\noutcomes of their implementations with other model-based and model-free methods\nproposed in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 23:29:44 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Tavafoghi", "Hamidreza", ""], ["Poolla", "Kameshwar", ""], ["Varaiya", "Pravin", ""]]}, {"id": "1908.11486", "submitter": "Qiao Li", "authors": "Qiao Li, David Wenzhong Gao", "title": "Fast Scenario Reduction for Power Systems by Deep Learning", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario reduction is an important topic in stochastic programming problems.\nDue to the random behavior of load and renewable energy, stochastic programming\nbecomes a useful technique to optimize power systems. Thus, scenario reduction\ngets more attentions in recent years. Many scenario reduction methods have been\nproposed to reduce the scenario set in a fast speed. However, the speed of\nscenario reduction is still very slow, in which it takes at least several\nseconds to several minutes to finish the reduction. This limitation of speed\nprevents stochastic programming to be implemented in real-time optimal control\nproblems. In this paper, a fast scenario reduction method based on deep\nlearning is proposed to solve this problem. Inspired by the deep learning based\nimage process, recognition and generation methods, the scenario data are\ntransformed into a 2D image-like data and then to be fed into a deep\nconvolutional neural network (DCNN). The output of the DCNN will be an \"image\"\nof the reduced scenario set. Since images can be processed in a very high speed\nby neural networks, the scenario reduction by neural network can also be very\nfast. The results of the simulation show that the scenario reduction with the\nproposed DCNN method can be completed in very high speed.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 00:05:17 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Li", "Qiao", ""], ["Gao", "David Wenzhong", ""]]}, {"id": "1908.11498", "submitter": "Domonkos Vamossy", "authors": "Stefania Albanesi and Domonkos F. Vamossy", "title": "Predicting Consumer Default: A Deep Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.LG q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a model to predict consumer default based on deep learning. We\nshow that the model consistently outperforms standard credit scoring models,\neven though it uses the same data. Our model is interpretable and is able to\nprovide a score to a larger class of borrowers relative to standard credit\nscoring models while accurately tracking variations in systemic risk. We argue\nthat these properties can provide valuable insights for the design of policies\ntargeted at reducing consumer default and alleviating its burden on borrowers\nand lenders, as well as macroprudential regulation.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 01:06:02 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 19:50:35 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Albanesi", "Stefania", ""], ["Vamossy", "Domonkos F.", ""]]}, {"id": "1908.11503", "submitter": "Chenrui Zhang", "authors": "Chenrui Zhang, Xiaoqing Lyu, Zhi Tang", "title": "TGG: Transferable Graph Generation for Zero-shot and Few-shot Learning", "comments": "ACM Multimedia 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Zero-shot and few-shot learning aim to improve generalization to unseen\nconcepts, which are promising in many realistic scenarios. Due to the lack of\ndata in unseen domain, relation modeling between seen and unseen domains is\nvital for knowledge transfer in these tasks. Most existing methods capture\nseen-unseen relation implicitly via semantic embedding or feature generation,\nresulting in inadequate use of relation and some issues remain (e.g. domain\nshift). To tackle these challenges, we propose a Transferable Graph Generation\n(TGG) approach, in which the relation is modeled and utilized explicitly via\ngraph generation. Specifically, our proposed TGG contains two main components:\n(1) Graph generation for relation modeling. An attention-based aggregate\nnetwork and a relation kernel are proposed, which generate instance-level graph\nbased on a class-level prototype graph and visual features. Proximity\ninformation aggregating is guided by a multi-head graph attention mechanism,\nwhere seen and unseen features synthesized by GAN are revised as node\nembeddings. The relation kernel further generates edges with GCN and graph\nkernel method, to capture instance-level topological structure while tackling\ndata imbalance and noise. (2) Relation propagation for relation utilization. A\ndual relation propagation approach is proposed, where relations captured by the\ngenerated graph are separately propagated from the seen and unseen subgraphs.\nThe two propagations learn from each other in a dual learning fashion, which\nperforms as an adaptation way for mitigating domain shift. All components are\njointly optimized with a meta-learning strategy, and our TGG acts as an\nend-to-end framework unifying conventional zero-shot, generalized zero-shot and\nfew-shot learning. Extensive experiments demonstrate that it consistently\nsurpasses existing methods of the above three fields by a significant margin.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 01:47:24 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Zhang", "Chenrui", ""], ["Lyu", "Xiaoqing", ""], ["Tang", "Zhi", ""]]}, {"id": "1908.11512", "submitter": "Haochen Chen", "authors": "Haochen Chen, Syed Fahad Sultan, Yingtao Tian, Muhao Chen, Steven\n  Skiena", "title": "Fast and Accurate Network Embeddings via Very Sparse Random Projection", "comments": "CIKM 2019 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FastRP, a scalable and performant algorithm for learning\ndistributed node representations in a graph. FastRP is over 4,000 times faster\nthan state-of-the-art methods such as DeepWalk and node2vec, while achieving\ncomparable or even better performance as evaluated on several real-world\nnetworks on various downstream tasks. We observe that most network embedding\nmethods consist of two components: construct a node similarity matrix and then\napply dimension reduction techniques to this matrix. We show that the success\nof these methods should be attributed to the proper construction of this\nsimilarity matrix, rather than the dimension reduction method employed.\n  FastRP is proposed as a scalable algorithm for network embeddings. Two key\nfeatures of FastRP are: 1) it explicitly constructs a node similarity matrix\nthat captures transitive relationships in a graph and normalizes matrix entries\nbased on node degrees; 2) it utilizes very sparse random projection, which is a\nscalable optimization-free method for dimension reduction. An extra benefit\nfrom combining these two design choices is that it allows the iterative\ncomputation of node embeddings so that the similarity matrix need not be\nexplicitly constructed, which further speeds up FastRP. FastRP is also\nadvantageous for its ease of implementation, parallelization and hyperparameter\ntuning. The source code is available at https://github.com/GTmac/FastRP.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 02:31:15 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Chen", "Haochen", ""], ["Sultan", "Syed Fahad", ""], ["Tian", "Yingtao", ""], ["Chen", "Muhao", ""], ["Skiena", "Steven", ""]]}, {"id": "1908.11513", "submitter": "Xin Lv", "authors": "Xin Lv, Yuxian Gu, Xu Han, Lei Hou, Juanzi Li, Zhiyuan Liu", "title": "Adapting Meta Knowledge Graph Information for Multi-Hop Reasoning over\n  Few-Shot Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop knowledge graph (KG) reasoning is an effective and explainable\nmethod for predicting the target entity via reasoning paths in query answering\n(QA) task. Most previous methods assume that every relation in KGs has enough\ntraining triples, regardless of those few-shot relations which cannot provide\nsufficient triples for training robust reasoning models. In fact, the\nperformance of existing multi-hop reasoning methods drops significantly on\nfew-shot relations. In this paper, we propose a meta-based multi-hop reasoning\nmethod (Meta-KGR), which adopts meta-learning to learn effective meta\nparameters from high-frequency relations that could quickly adapt to few-shot\nrelations. We evaluate Meta-KGR on two public datasets sampled from Freebase\nand NELL, and the experimental results show that Meta-KGR outperforms the\ncurrent state-of-the-art methods in few-shot scenarios. Our code and datasets\ncan be obtained from https://github.com/ THU-KEG/MetaKGR.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 02:44:44 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Lv", "Xin", ""], ["Gu", "Yuxian", ""], ["Han", "Xu", ""], ["Hou", "Lei", ""], ["Li", "Juanzi", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1908.11514", "submitter": "Quanyu Dai", "authors": "Quanyu Dai, Xiao Shen, Liang Zhang, Qiang Li and Dan Wang", "title": "Adversarial Training Methods for Network Embedding", "comments": "The World Wide Web Conference 2019, WWW'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Embedding is the task of learning continuous node representations for\nnetworks, which has been shown effective in a variety of tasks such as link\nprediction and node classification. Most of existing works aim to preserve\ndifferent network structures and properties in low-dimensional embedding\nvectors, while neglecting the existence of noisy information in many real-world\nnetworks and the overfitting issue in the embedding learning process. Most\nrecently, generative adversarial networks (GANs) based regularization methods\nare exploited to regularize embedding learning process, which can encourage a\nglobal smoothness of embedding vectors. These methods have very complicated\narchitecture and suffer from the well-recognized non-convergence problem of\nGANs. In this paper, we aim to introduce a more succinct and effective local\nregularization method, namely adversarial training, to network embedding so as\nto achieve model robustness and better generalization performance. Firstly, the\nadversarial training method is applied by defining adversarial perturbations in\nthe embedding space with an adaptive $L_2$ norm constraint that depends on the\nconnectivity pattern of node pairs. Though effective as a regularizer, it\nsuffers from the interpretability issue which may hinder its application in\ncertain real-world scenarios. To improve this strategy, we further propose an\ninterpretable adversarial training method by enforcing the reconstruction of\nthe adversarial examples in the discrete graph domain. These two regularization\nmethods can be applied to many existing embedding models, and we take DeepWalk\nas the base model for illustration in the paper. Empirical evaluations in both\nlink prediction and node classification demonstrate the effectiveness of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 02:48:52 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Dai", "Quanyu", ""], ["Shen", "Xiao", ""], ["Zhang", "Liang", ""], ["Li", "Qiang", ""], ["Wang", "Dan", ""]]}, {"id": "1908.11515", "submitter": "Tianhao Wang", "authors": "Tianhao Wang, Bolin Ding, Min Xu, Zhicong Huang, Cheng Hong, Jingren\n  Zhou, Ninghui Li, Somesh Jha", "title": "Improving Utility and Security of the Shuffler-based Differential\n  Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When collecting information, local differential privacy (LDP) alleviates\nprivacy concerns of users because their private information is randomized\nbefore being sent it to the central aggregator. LDP imposes large amount of\nnoise as each user executes the randomization independently. To address this\nissue, recent work introduced an intermediate server with the assumption that\nthis intermediate server does not collude with the aggregator. Under this\nassumption, less noise can be added to achieve the same privacy guarantee as\nLDP, thus improving utility for the data collection task.\n  This paper investigates this multiple-party setting of LDP. We analyze the\nsystem model and identify potential adversaries. We then make two improvements:\na new algorithm that achieves a better privacy-utility tradeoff; and a novel\nprotocol that provides better protection against various attacks. Finally, we\nperform experiments to compare different methods and demonstrate the benefits\nof using our proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 03:02:04 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 03:06:01 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 14:54:55 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Wang", "Tianhao", ""], ["Ding", "Bolin", ""], ["Xu", "Min", ""], ["Huang", "Zhicong", ""], ["Hong", "Cheng", ""], ["Zhou", "Jingren", ""], ["Li", "Ninghui", ""], ["Jha", "Somesh", ""]]}, {"id": "1908.11521", "submitter": "Deng Cai", "authors": "Huajie Chen and Deng Cai and Wei Dai and Zehui Dai and Yadong Ding", "title": "Charge-Based Prison Term Prediction with Deep Gating Network", "comments": "EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Judgment prediction for legal cases has attracted much research efforts for\nits practice use, of which the ultimate goal is prison term prediction. While\nexisting work merely predicts the total prison term, in reality a defendant is\noften charged with multiple crimes. In this paper, we argue that charge-based\nprison term prediction (CPTP) not only better fits realistic needs, but also\nmakes the total prison term prediction more accurate and interpretable. We\ncollect the first large-scale structured data for CPTP and evaluate several\ncompetitive baselines. Based on the observation that fine-grained feature\nselection is the key to achieving good performance, we propose the Deep Gating\nNetwork (DGN) for charge-specific feature selection and aggregation.\nExperiments show that DGN achieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 03:44:10 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Chen", "Huajie", ""], ["Cai", "Deng", ""], ["Dai", "Wei", ""], ["Dai", "Zehui", ""], ["Ding", "Yadong", ""]]}, {"id": "1908.11522", "submitter": "Junru Zhou", "authors": "Junru Zhou, Zuchao Li, Hai Zhao", "title": "Parsing All: Syntax and Semantics, Dependencies and Spans", "comments": "EMNLP 2020, ACL Findings. arXiv admin note: text overlap with\n  arXiv:1907.02684", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both syntactic and semantic structures are key linguistic contextual clues,\nin which parsing the latter has been well shown beneficial from parsing the\nformer. However, few works ever made an attempt to let semantic parsing help\nsyntactic parsing. As linguistic representation formalisms, both syntax and\nsemantics may be represented in either span (constituent/phrase) or dependency,\non both of which joint learning was also seldom explored. In this paper, we\npropose a novel joint model of syntactic and semantic parsing on both span and\ndependency representations, which incorporates syntactic information\neffectively in the encoder of neural network and benefits from two\nrepresentation formalisms in a uniform way. The experiments show that semantics\nand syntax can benefit each other by optimizing joint objectives. Our single\nmodel achieves new state-of-the-art or competitive results on both span and\ndependency semantic parsing on Propbank benchmarks and both dependency and\nconstituent syntactic parsing on Penn Treebank.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 03:49:19 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 05:52:11 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 03:30:01 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Zhou", "Junru", ""], ["Li", "Zuchao", ""], ["Zhao", "Hai", ""]]}, {"id": "1908.11527", "submitter": "Le Fang", "authors": "Le Fang, Chunyuan Li, Jianfeng Gao, Wen Dong and Changyou Chen", "title": "Implicit Deep Latent Variable Models for Text Generation", "comments": "13 pages, 8 Tables, 1 Figure, Accepted at 2019 Conference on\n  Empirical Methods in Natural Language Processing (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models (LVM) such as variational auto-encoder (VAE) have\nrecently played an important role in text generation. One key factor is the\nexploitation of smooth latent structures to guide the generation. However, the\nrepresentation power of VAEs is limited due to two reasons: (1) the Gaussian\nassumption is often made on the variational posteriors; and meanwhile (2) a\nnotorious \"posterior collapse\" issue occurs. In this paper, we advocate\nsample-based representations of variational distributions for natural language,\nleading to implicit latent features, which can provide flexible representation\npower compared with Gaussian-based posteriors. We further develop an LVM to\ndirectly match the aggregated posterior to the prior. It can be viewed as a\nnatural extension of VAEs with a regularization of maximizing mutual\ninformation, mitigating the \"posterior collapse\" issue. We demonstrate the\neffectiveness and versatility of our models in various text generation\nscenarios, including language modeling, unaligned style transfer, and dialog\nresponse generation. The source code to reproduce our experimental results is\navailable on GitHub.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 04:12:08 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 05:48:05 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 19:53:57 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Fang", "Le", ""], ["Li", "Chunyuan", ""], ["Gao", "Jianfeng", ""], ["Dong", "Wen", ""], ["Chen", "Changyou", ""]]}, {"id": "1908.11538", "submitter": "Rourab Paul", "authors": "Rourab Paul, Nimisha Ghosh, Suman Sau, Amlan Chakrabarti, Prasant\n  Mahapatra", "title": "IoT based Smart Access Controlled Secure Smart City Architecture Using\n  Blockchain", "comments": "Manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Standard security protocols like SSL, TLS, IPSec etc. have high memory and\nprocessor consumption which makes all these security protocols unsuitable for\nresource constrained platforms such as Internet of Things (IoT). Blockchain\n(BC) finds its efficient application in IoT platform to preserve the five basic\ncryptographic primitives, such as confidentiality, authenticity, integrity,\navailability and non-repudiation. Conventional adoption of BC in IoT platform\ncauses high energy consumption, delay and computational overhead which are not\nappropriate for various resource constrained IoT devices. This work proposes a\nmachine learning (ML) based smart access control framework in a public and a\nprivate BC for a smart city application which makes it more efficient as\ncompared to the existing IoT applications. The proposed IoT based smart city\narchitecture adopts BC technology for preserving all the cryptographic security\nand privacy issues. Moreover, BC has very minimal overhead on IoT platform as\nwell. This work investigates the existing threat models and critical access\ncontrol issues which handle multiple permissions of various nodes and detects\nrelevant inconsistencies to notify the corresponding nodes. Comparison in terms\nof all security issues with existing literature shows that the proposed\narchitecture is competitively efficient in terms of security access control.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 05:37:05 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 07:03:29 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 08:55:21 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Paul", "Rourab", ""], ["Ghosh", "Nimisha", ""], ["Sau", "Suman", ""], ["Chakrabarti", "Amlan", ""], ["Mahapatra", "Prasant", ""]]}, {"id": "1908.11540", "submitter": "Soujanya Poria", "authors": "Deepanway Ghosal, Navonil Majumder, Soujanya Poria, Niyati Chhaya and\n  Alexander Gelbukh", "title": "DialogueGCN: A Graph Convolutional Neural Network for Emotion\n  Recognition in Conversation", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Emotion recognition in conversation (ERC) has received much attention,\nlately, from researchers due to its potential widespread applications in\ndiverse areas, such as health-care, education, and human resources. In this\npaper, we present Dialogue Graph Convolutional Network (DialogueGCN), a graph\nneural network based approach to ERC. We leverage self and inter-speaker\ndependency of the interlocutors to model conversational context for emotion\nrecognition. Through the graph network, DialogueGCN addresses context\npropagation issues present in the current RNN-based methods. We empirically\nshow that this method alleviates such issues, while outperforming the current\nstate of the art on a number of benchmark emotion classification datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 05:44:24 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Ghosal", "Deepanway", ""], ["Majumder", "Navonil", ""], ["Poria", "Soujanya", ""], ["Chhaya", "Niyati", ""], ["Gelbukh", "Alexander", ""]]}, {"id": "1908.11550", "submitter": "Junyi Zou", "authors": "Junyi Zou, Jinliang Zhang, Ludi Wang", "title": "Handwritten Chinese Character Recognition by Convolutional Neural\n  Network and Similarity Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Convolution Neural Networks (CNN) have recently achieved state-of-the art\nperformance on handwritten Chinese character recognition (HCCR). However, most\nof CNN models employ the SoftMax activation function and minimize cross entropy\nloss, which may cause loss of inter-class information. To cope with this\nproblem, we propose to combine cross entropy with similarity ranking function\nand use it as loss function. The experiments results show that the combination\nloss functions produce higher accuracy in HCCR. This report briefly reviews\ncross entropy loss function, a typical similarity ranking function: Euclidean\ndistance, and also propose a new similarity ranking function: Average variance\nsimilarity. Experiments are done to compare the performances of a CNN model\nwith three different loss functions. In the end, SoftMax cross entropy with\nAverage variance similarity produce the highest accuracy on handwritten Chinese\ncharacters recognition.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 06:21:52 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Zou", "Junyi", ""], ["Zhang", "Jinliang", ""], ["Wang", "Ludi", ""]]}, {"id": "1908.11553", "submitter": "Junyi Zou", "authors": "Junyi Zou, Jinliang Zhang, Ping Jiang", "title": "Credit Card Fraud Detection Using Autoencoder Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Imbalanced data classification problem has always been a popular topic in the\nfield of machine learning research. In order to balance the samples between\nmajority and minority class. Oversampling algorithm is used to synthesize new\nminority class samples, but it could bring in noise. Pointing to the noise\nproblems, this paper proposed a denoising autoencoder neural network (DAE)\nalgorithm which can not only oversample minority class sample through\nmisclassification cost, but it can denoise and classify the sampled dataset.\nThrough experiments, compared with the denoising autoencoder neural network\n(DAE) with oversampling process and traditional fully connected neural\nnetworks, the results showed the proposed algorithm improves the classification\naccuracy of minority class of imbalanced datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 06:25:26 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Zou", "Junyi", ""], ["Zhang", "Jinliang", ""], ["Jiang", "Ping", ""]]}, {"id": "1908.11567", "submitter": "Tobias Skovgaard Jepsen", "authors": "Tobias Skovgaard Jepsen, Christian S. Jensen, Thomas Dyhre Nielsen", "title": "Graph Convolutional Networks for Road Networks", "comments": "Ten-page pre-print version of a four-page ACM SIGSPATIAL 2019 poster\n  paper", "journal-ref": null, "doi": "10.1145/3347146.3359094", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques for road networks hold the potential to\nfacilitate many important transportation applications. Graph Convolutional\nNetworks (GCNs) are neural networks that are capable of leveraging the\nstructure of a road network by utilizing information of, e.g., adjacent road\nsegments. While state-of-the-art GCNs target node classification tasks in\nsocial, citation, and biological networks, machine learning tasks in road\nnetworks differ substantially from such tasks. In road networks, prediction\ntasks concern edges representing road segments, and many tasks involve\nregression. In addition, road networks differ substantially from the networks\nassumed in the GCN literature in terms of the attribute information available\nand the network characteristics. Many implicit assumptions of GCNs do therefore\nnot apply. We introduce the notion of Relational Fusion Network (RFN), a novel\ntype of GCN designed specifically for machine learning on road networks. In\nparticular, we propose methods that outperform state-of-the-art GCNs on both a\nroad segment regression task and a road segment classification task by 32-40%\nand 21-24%, respectively. In addition, we provide experimental evidence of the\nshort-comings of state-of-the-art GCNs in the context of road networks: unlike\nour method, they cannot effectively leverage the road network structure for\nroad segment classification and fail to outperform a regular multi-layer\nperceptron.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 07:08:51 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 09:44:40 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 14:50:54 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Jepsen", "Tobias Skovgaard", ""], ["Jensen", "Christian S.", ""], ["Nielsen", "Thomas Dyhre", ""]]}, {"id": "1908.11571", "submitter": "Xiang Lin", "authors": "Linlin Liu, Xiang Lin, Shafiq Joty, Simeng Han, Lidong Bing", "title": "Hierarchical Pointer Net Parsing", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transition-based top-down parsing with pointer networks has achieved\nstate-of-the-art results in multiple parsing tasks, while having a linear time\ncomplexity. However, the decoder of these parsers has a sequential structure,\nwhich does not yield the most appropriate inductive bias for deriving tree\nstructures. In this paper, we propose hierarchical pointer network parsers, and\napply them to dependency and sentence-level discourse parsing tasks. Our\nresults on standard benchmark datasets demonstrate the effectiveness of our\napproach, outperforming existing methods and setting a new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 07:22:43 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Liu", "Linlin", ""], ["Lin", "Xiang", ""], ["Joty", "Shafiq", ""], ["Han", "Simeng", ""], ["Bing", "Lidong", ""]]}, {"id": "1908.11598", "submitter": "Adam Richardson", "authors": "Adam Richardson, Aris Filos-Ratsikas, Boi Faltings", "title": "Rewarding High-Quality Data via Influence Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a crowdsourcing data acquisition scenario, such as federated\nlearning, where a Center collects data points from a set of rational Agents,\nwith the aim of training a model. For linear regression models, we show how a\npayment structure can be designed to incentivize the agents to provide\nhigh-quality data as early as possible, based on a characterization of the\ninfluence that data points have on the loss function of the model. Our\ncontributions can be summarized as follows: (a) we prove theoretically that\nthis scheme ensures truthful data reporting as a game-theoretic equilibrium and\nfurther demonstrate its robustness against mixtures of truthful and heuristic\ndata reports, (b) we design a procedure according to which the influence\ncomputation can be efficiently approximated and processed sequentially in\nbatches over time, (c) we develop a theory that allows correcting the\ndifference between the influence and the overall change in loss and (d) we\nevaluate our approach on real datasets, confirming our theoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 08:57:18 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Richardson", "Adam", ""], ["Filos-Ratsikas", "Aris", ""], ["Faltings", "Boi", ""]]}, {"id": "1908.11658", "submitter": "Florian Schmidt", "authors": "Florian Schmidt, Stephan Mandt, Thomas Hofmann", "title": "Autoregressive Text Generation Beyond Feedback Loops", "comments": "emnlp camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive state transitions, where predictions are conditioned on past\npredictions, are the predominant choice for both deterministic and stochastic\nsequential models. However, autoregressive feedback exposes the evolution of\nthe hidden state trajectory to potential biases from well-known train-test\ndiscrepancies. In this paper, we combine a latent state space model with a CRF\nobservation model. We argue that such autoregressive observation models form an\ninteresting middle ground that expresses local correlations on the word level\nbut keeps the state evolution non-autoregressive. On unconditional sentence\ngeneration we show performance improvements compared to RNN and GAN baselines\nwhile avoiding some prototypical failure modes of autoregressive models.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 11:31:07 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Schmidt", "Florian", ""], ["Mandt", "Stephan", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1908.11682", "submitter": "Panagiotis Mandros", "authors": "Panagiotis Mandros, Mario Boley, Jilles Vreeken", "title": "Discovering Reliable Correlations in Categorical Data", "comments": "Accepted to the IEEE International Conference on Data Mining 2019\n  (ICDM'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In many scientific tasks we are interested in discovering whether there exist\nany correlations in our data. This raises many questions, such as how to\nreliably and interpretably measure correlation between a multivariate set of\nattributes, how to do so without having to make assumptions on distribution of\nthe data or the type of correlation, and, how to efficiently discover the\ntop-most reliably correlated attribute sets from data. In this paper we answer\nthese questions for discovery tasks in categorical data.\n  In particular, we propose a corrected-for-chance, consistent, and efficient\nestimator for normalized total correlation, by which we obtain a reliable,\nnaturally interpretable, non-parametric measure for correlation over\nmultivariate sets. For the discovery of the top-k correlated sets, we derive an\neffective algorithmic framework based on a tight bounding function. This\nframework offers exact, approximate, and heuristic search. Empirical evaluation\nshows that already for small sample sizes the estimator leads to low-regret\noptimization outcomes, while the algorithms are shown to be highly effective\nfor both large and high-dimensional data. Through two case studies we confirm\nthat our discovery framework identifies interesting and meaningful\ncorrelations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 12:18:29 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Mandros", "Panagiotis", ""], ["Boley", "Mario", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1908.11691", "submitter": "Geng Yuan", "authors": "Geng Yuan, Xiaolong Ma, Caiwen Ding, Sheng Lin, Tianyun Zhang, Zeinab\n  S. Jalali, Yilong Zhao, Li Jiang, Sucheta Soundarajan, Yanzhi Wang", "title": "An Ultra-Efficient Memristor-Based DNN Framework with Structured Weight\n  Pruning and Quantization Using ADMM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high computation and memory storage of large deep neural networks (DNNs)\nmodels pose intensive challenges to the conventional Von-Neumann architecture,\nincurring substantial data movements in the memory hierarchy. The memristor\ncrossbar array has emerged as a promising solution to mitigate the challenges\nand enable low-power acceleration of DNNs. Memristor-based weight pruning and\nweight quantization have been seperately investigated and proven effectiveness\nin reducing area and power consumption compared to the original DNN model.\nHowever, there has been no systematic investigation of memristor-based\nneuromorphic computing (NC) systems considering both weight pruning and weight\nquantization. In this paper, we propose an unified and systematic\nmemristor-based framework considering both structured weight pruning and weight\nquantization by incorporating alternating direction method of multipliers\n(ADMM) into DNNs training. We consider hardware constraints such as crossbar\nblocks pruning, conductance range, and mismatch between weight value and real\ndevices, to achieve high accuracy and low power and small area footprint. Our\nframework is mainly integrated by three steps, i.e., memristor-based ADMM\nregularized optimization, masked mapping and retraining. Experimental results\nshow that our proposed framework achieves 29.81X (20.88X) weight compression\nratio, with 98.38% (96.96%) and 98.29% (97.47%) power and area reduction on\nVGG-16 (ResNet-18) network where only have 0.5% (0.76%) accuracy loss, compared\nto the original DNN models. We share our models at link http://bit.ly/2Jp5LHJ.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 03:32:41 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Yuan", "Geng", ""], ["Ma", "Xiaolong", ""], ["Ding", "Caiwen", ""], ["Lin", "Sheng", ""], ["Zhang", "Tianyun", ""], ["Jalali", "Zeinab S.", ""], ["Zhao", "Yilong", ""], ["Jiang", "Li", ""], ["Soundarajan", "Sucheta", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1908.11694", "submitter": "Adam Pantanowitz", "authors": "Adam Pantanowitz, Emmanuel Cohen, Philippe Gradidge, Nigel Crowther,\n  Vered Aharonson, Benjamin Rosman, David M Rubin", "title": "Estimation of Body Mass Index from Photographs using Deep Convolutional\n  Neural Networks", "comments": "7 pages, 4 figures, preprint journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obesity is an important concern in public health, and Body Mass Index is one\nof the useful (and proliferant) measures. We use Convolutional Neural Networks\nto determine Body Mass Index from photographs in a study with 161 participants.\nLow data, a common problem in medicine, is addressed by reducing the\ninformation in the photographs by generating silhouette images. Results present\nwith high correlation when tested on unseen data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 10:33:26 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Pantanowitz", "Adam", ""], ["Cohen", "Emmanuel", ""], ["Gradidge", "Philippe", ""], ["Crowther", "Nigel", ""], ["Aharonson", "Vered", ""], ["Rosman", "Benjamin", ""], ["Rubin", "David M", ""]]}, {"id": "1908.11708", "submitter": "Loc Tran H", "authors": "Loc Tran, Tuan Tran, Linh Tran, An Mai", "title": "Solve fraud detection problem by using graph based learning methods", "comments": "9 pages. arXiv admin note: substantial text overlap with\n  arXiv:1811.02986", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The credit cards' fraud transactions detection is the important problem in\nmachine learning field. To detect the credit cards's fraud transactions help\nreduce the significant loss of the credit cards' holders and the banks. To\ndetect the credit cards' fraud transactions, data scientists normally employ\nthe unsupervised learning techniques and supervised learning techniques. In\nthis paper, we employ the graph p-Laplacian based semi-supervised learning\nmethods combined with the undersampling techniques such as Cluster Centroids to\nsolve the credit cards' fraud transactions detection problem. Experimental\nresults show that the graph p-Laplacian semi-supervised learning methods\noutperform the current state of the art graph Laplacian based semi-supervised\nlearning method (p=2).\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 04:04:56 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Tran", "Loc", ""], ["Tran", "Tuan", ""], ["Tran", "Linh", ""], ["Mai", "An", ""]]}, {"id": "1908.11757", "submitter": "Javad Zolfaghari Bengar", "authors": "Javad Zolfaghari Bengar, Abel Gonzalez-Garcia, Gabriel Villalonga,\n  Bogdan Raducanu, Hamed H. Aghdam, Mikhail Mozerov, Antonio M. Lopez, Joost\n  van de Weijer", "title": "Temporal Coherence for Active Learning in Videos", "comments": "Accepted at ICCVW 2019 (CVRSUAD-Road Scene Understanding and\n  Autonomous Driving)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving systems require huge amounts of data to train. Manual\nannotation of this data is time-consuming and prohibitively expensive since it\ninvolves human resources. Therefore, active learning emerged as an alternative\nto ease this effort and to make data annotation more manageable. In this paper,\nwe introduce a novel active learning approach for object detection in videos by\nexploiting temporal coherence. Our active learning criterion is based on the\nestimated number of errors in terms of false positives and false negatives. The\ndetections obtained by the object detector are used to define the nodes of a\ngraph and tracked forward and backward to temporally link the nodes. Minimizing\nan energy function defined on this graphical model provides estimates of both\nfalse positives and false negatives. Additionally, we introduce a synthetic\nvideo dataset, called SYNTHIA-AL, specially designed to evaluate active\nlearning for video object detection in road scenes. Finally, we show that our\napproach outperforms active learning baselines tested on two datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 14:20:36 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Bengar", "Javad Zolfaghari", ""], ["Gonzalez-Garcia", "Abel", ""], ["Villalonga", "Gabriel", ""], ["Raducanu", "Bogdan", ""], ["Aghdam", "Hamed H.", ""], ["Mozerov", "Mikhail", ""], ["Lopez", "Antonio M.", ""], ["van de Weijer", "Joost", ""]]}, {"id": "1908.11762", "submitter": "Travis Scholten", "authors": "Travis L. Scholten, Yi-Kai Liu, Kevin Young, Robin Blume-Kohout", "title": "Classifying single-qubit noise using machine learning", "comments": "20 pages (15 main, 5 supplemental), 11 figures, and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum characterization, validation, and verification (QCVV) techniques are\nused to probe, characterize, diagnose, and detect errors in quantum information\nprocessors (QIPs). An important component of any QCVV protocol is a mapping\nfrom experimental data to an estimate of a property of a QIP. Machine learning\n(ML) algorithms can help automate the development of QCVV protocols, creating\nsuch maps by learning them from training data. We identify the critical\ncomponents of \"machine-learned\" QCVV techniques, and present a rubric for\ndeveloping them. To demonstrate this approach, we focus on the problem of\ndetermining whether noise affecting a single qubit is coherent or stochastic\n(incoherent) using the data sets originally proposed for gate set tomography.\nWe leverage known ML algorithms to train a classifier distinguishing these two\nkinds of noise. The accuracy of the classifier depends on how well it can\napproximate the \"natural\" geometry of the training data. We find GST data sets\ngenerated by a noisy qubit can reliably be separated by linear surfaces,\nalthough feature engineering can be necessary. We also show the classifier\nlearned by a support vector machine (SVM) is robust under finite-sample noise.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 14:37:05 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Scholten", "Travis L.", ""], ["Liu", "Yi-Kai", ""], ["Young", "Kevin", ""], ["Blume-Kohout", "Robin", ""]]}, {"id": "1908.11775", "submitter": "Yao-Hung Tsai", "authors": "Yao-Hung Hubert Tsai and Shaojie Bai and Makoto Yamada and\n  Louis-Philippe Morency and Ruslan Salakhutdinov", "title": "Transformer Dissection: A Unified Understanding of Transformer's\n  Attention via the Lens of Kernel", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer is a powerful architecture that achieves superior performance on\nvarious sequence learning tasks, including neural machine translation, language\nunderstanding, and sequence prediction. At the core of the Transformer is the\nattention mechanism, which concurrently processes all inputs in the streams. In\nthis paper, we present a new formulation of attention via the lens of the\nkernel. To be more precise, we realize that the attention can be seen as\napplying kernel smoother over the inputs with the kernel scores being the\nsimilarities between inputs. This new formulation gives us a better way to\nunderstand individual components of the Transformer's attention, such as the\nbetter way to integrate the positional embedding. Another important advantage\nof our kernel-based formulation is that it paves the way to a larger space of\ncomposing Transformer's attention. As an example, we propose a new variant of\nTransformer's attention which models the input as a product of symmetric\nkernels. This approach achieves competitive performance to the current state of\nthe art model with less computation. In our experiments, we empirically study\ndifferent kernel construction strategies on two widely used tasks: neural\nmachine translation and sequence prediction.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 15:05:02 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 21:16:58 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 16:40:11 GMT"}, {"version": "v4", "created": "Mon, 11 Nov 2019 21:51:11 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Bai", "Shaojie", ""], ["Yamada", "Makoto", ""], ["Morency", "Louis-Philippe", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1908.11799", "submitter": "Qinghui Liu", "authors": "Qinghui Liu, Michael Kampffmeyer, Robert Jenssen, Arnt-B{\\o}rre\n  Salberg", "title": "Dense Dilated Convolutions Merging Network for Semantic Mapping of\n  Remote Sensing Images", "comments": "JURSE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a network for semantic mapping called the Dense Dilated\nConvolutions Merging Network (DDCM-Net) to provide a deep learning approach\nthat can recognize multi-scale and complex shaped objects with similar color\nand textures, such as buildings, surfaces/roads, and trees in very high\nresolution remote sensing images. The proposed DDCM-Net consists of dense\ndilated convolutions merged with varying dilation rates. This can effectively\nenlarge the kernels' receptive fields, and, more importantly, obtain fused\nlocal and global context information to promote surrounding discriminative\ncapability. We demonstrate the effectiveness of the proposed DDCM-Net on the\npublicly available ISPRS Potsdam dataset and achieve a performance of 92.3%\nF1-score and 86.0% mean intersection over union accuracy by only using the RGB\nbands, without any post-processing. We also show results on the ISPRS Vaihingen\ndataset, where the DDCM-Net trained with IRRG bands, also obtained better\nmapping accuracy (89.8% F1-score) than previous state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 15:47:15 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Liu", "Qinghui", ""], ["Kampffmeyer", "Michael", ""], ["Jenssen", "Robert", ""], ["Salberg", "Arnt-B\u00f8rre", ""]]}, {"id": "1908.11809", "submitter": "Sudarshan Srinivasan", "authors": "Sudarshan Srinivasan, Pradeep Janedula, Saurabh Dhoble, Sasikanth\n  Avancha, Dipankar Das, Naveen Mellempudi, Bharat Daga, Martin Langhammer,\n  Gregg Baeckler, Bharat Kaul", "title": "High Performance Scalable FPGA Accelerator for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-precision is the first order knob for achieving higher Artificial\nIntelligence Operations (AI-TOPS). However the algorithmic space for sub-8-bit\nprecision compute is diverse, with disruptive changes happening frequently,\nmaking FPGAs a natural choice for Deep Neural Network inference, In this work\nwe present an FPGA-based accelerator for CNN inference acceleration. We use\n{\\it INT-8-2} compute (with {\\it 8 bit} activation and {2 bit} weights) which\nis recently showing promise in the literature, and which no known ASIC, CPU or\nGPU natively supports today. Using a novel Adaptive Logic Module (ALM) based\ndesign, as a departure from traditional DSP based designs, we are able to\nachieve high performance measurement of 5 AI-TOPS for {\\it Arria10} and project\na performance of 76 AI-TOPS at 0.7 TOPS/W for {\\it Stratix10}. This exceeds\nknown CPU, GPU performance and comes close to best known ASIC (TPU) numbers,\nwhile retaining the versatility of the FPGA platform for other applications.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 07:13:53 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Srinivasan", "Sudarshan", ""], ["Janedula", "Pradeep", ""], ["Dhoble", "Saurabh", ""], ["Avancha", "Sasikanth", ""], ["Das", "Dipankar", ""], ["Mellempudi", "Naveen", ""], ["Daga", "Bharat", ""], ["Langhammer", "Martin", ""], ["Baeckler", "Gregg", ""], ["Kaul", "Bharat", ""]]}, {"id": "1908.11820", "submitter": "Mohammadreza Mostajabi", "authors": "Mohammadreza Mostajabi", "title": "Learning Rich Representations For Structured Visual Prediction Tasks", "comments": "PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an approach to learning rich representations for images, that\nenables simple and effective predictors in a range of vision tasks involving\nspatially structured maps. Our key idea is to map small image elements to\nfeature representations extracted from a sequence of nested regions of\nincreasing spatial extent. These regions are obtained by \"zooming out\" from the\npixel/superpixel all the way to scene-level resolution, and hence we call these\nzoom-out features. Applied to semantic segmentation and other structured\nprediction tasks, our approach exploits statistical structure in the image and\nin the label space without setting up explicit structured prediction\nmechanisms, and thus avoids complex and expensive inference. Instead image\nelements are classified by a feedforward multilayer network with skip-layer\nconnections spanning the zoom-out levels. When used in conjunction with modern\nneural architectures such as ResNet, DenseNet and NASNet (to which it is\ncomplementary) our approach achieves competitive accuracy on segmentation\nbenchmarks.\n  In addition, we propose an approach for learning category-level semantic\nsegmentation purely from image-level classification tag. It exploits\nlocalization cues that emerge from training a modified zoom-out architecture\ntailored for classification tasks, to drive a weakly supervised process that\nautomatically labels a sparse, diverse training set of points likely to belong\nto classes of interest. Finally, we introduce data-driven regularization\nfunctions for the supervised training of CNNs. Our innovation takes the form of\na regularizer derived by learning an autoencoder over the set of annotations.\nThis approach leverages an improved representation of label space to inform\nextraction of features from images\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 16:18:26 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Mostajabi", "Mohammadreza", ""]]}, {"id": "1908.11823", "submitter": "Alexander Mey", "authors": "Alexander Mey and Marco Loog", "title": "Consistency and Finite Sample Behavior of Binary Class Probability\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate to which extent one can recover class\nprobabilities within the empirical risk minimization (ERM) paradigm. The main\naim of our paper is to extend existing results and emphasize the tight\nrelations between empirical risk minimization and class probability estimation.\nBased on existing literature on excess risk bounds and proper scoring rules, we\nderive a class probability estimator based on empirical risk minimization. We\nthen derive fairly general conditions under which this estimator will converge,\nin the L1-norm and in probability, to the true class probabilities. Our main\ncontribution is to present a way to derive finite sample L1-convergence rates\nof this estimator for different surrogate loss functions. We also study in\ndetail which commonly used loss functions are suitable for this estimation\nproblem and finally discuss the setting of model-misspecification as well as a\npossible extension to asymmetric loss functions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 16:22:19 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 11:29:35 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 07:55:05 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Mey", "Alexander", ""], ["Loog", "Marco", ""]]}, {"id": "1908.11833", "submitter": "Avinash Barnwal", "authors": "Avinash Barnwal", "title": "Network Elastic Net for Identifying Smoking specific gene expression for\n  lung cancer", "comments": "Published on Proceedings of IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival month for non-small lung cancer patients depend upon which stage of\nlung cancer is present. Our aim is to identify smoking specific gene expression\nbiomarkers in the prognosis of lung cancer patients. In this paper, we\nintroduce the network elastic net, a generalization of network lasso that\nallows for simultaneous clustering and regression on graphs. In Network elastic\nnet, we consider similar patients based on smoking cigarettes per year to form\nthe network. We then further find the suitable cluster among patients based on\ncoefficients of genes having different survival month structures and showed the\nefficacy of the clusters using stage enrichment. This can be used to identify\nthe stage of cancer using gene expression and smoking behavior of patients\nwithout doing any tests.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 16:46:35 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Barnwal", "Avinash", ""]]}, {"id": "1908.11834", "submitter": "Shangbang Long", "authors": "Shangbang Long, Yushuo Guan, Bingxuan Wang, Kaigui Bian, Cong Yao", "title": "Rethinking Irregular Scene Text Recognition", "comments": "Technical report for participation in ICDAR2019-ArT recognition track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading text from natural images is challenging due to the great variety in\ntext font, color, size, complex background and etc.. The perspective distortion\nand non-linear spatial arrangement of characters make it further difficult.\nWhile rectification based method is intuitively grounded and has pushed the\nenvelope by far, its potential is far from being well exploited. In this paper,\nwe present a bag of tricks that prove to significantly improve the performance\nof rectification based method. On curved text dataset, our method achieves an\naccuracy of 89.6% on CUTE-80 and 76.3% on Total-Text, an improvement over\nprevious state-of-the-art by 6.3% and 14.7% respectively. Furthermore, our\ncombination of tricks helps us win the ICDAR 2019 Arbitrary-Shaped Text\nChallenge (Latin script), achieving an accuracy of 74.3% on the held-out test\nset. We release our code as well as data samples for further exploration at\nhttps://github.com/Jyouhou/ICDAR2019-ArT-Recognition-Alchemy\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 16:47:08 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 17:25:43 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Long", "Shangbang", ""], ["Guan", "Yushuo", ""], ["Wang", "Bingxuan", ""], ["Bian", "Kaigui", ""], ["Yao", "Cong", ""]]}, {"id": "1908.11843", "submitter": "Tiffany Vlaar", "authors": "Benedict Leimkuhler, Charles Matthews and Tiffany Vlaar", "title": "Partitioned integrators for thermodynamic parameterization of neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, neural networks are parameterized using optimization\nprocedures such as stochastic gradient descent, RMSProp and ADAM. These\nprocedures tend to drive the parameters of the network toward a local minimum.\nIn this article, we employ alternative \"sampling\" algorithms (referred to here\nas \"thermodynamic parameterization methods\") which rely on discretized\nstochastic differential equations for a defined target distribution on\nparameter space. We show that the thermodynamic perspective already improves\nneural network training. Moreover, by partitioning the parameters based on\nnatural layer structure we obtain schemes with very rapid convergence for data\nsets with complicated loss landscapes.\n  We describe easy-to-implement hybrid partitioned numerical algorithms, based\non discretized stochastic differential equations, which are adapted to\nfeed-forward neural networks, including a multi-layer Langevin algorithm,\nAdLaLa (combining the adaptive Langevin and Langevin algorithms) and LOL\n(combining Langevin and Overdamped Langevin); we examine the convergence of\nthese methods using numerical studies and compare their performance among\nthemselves and in relation to standard alternatives such as stochastic gradient\ndescent and ADAM. We present evidence that thermodynamic parameterization\nmethods can be (i) faster, (ii) more accurate, and (iii) more robust than\nstandard algorithms used within machine learning frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 17:12:56 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 21:15:43 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Leimkuhler", "Benedict", ""], ["Matthews", "Charles", ""], ["Vlaar", "Tiffany", ""]]}, {"id": "1908.11848", "submitter": "Bao Xin Chen", "authors": "Xing Zhao and Aijun An and Junfeng Liu and Bao Xin Chen", "title": "Dynamic Stale Synchronous Parallel Distributed Training for Deep\n  Learning", "comments": null, "journal-ref": "2019 IEEE 39th International Conference on Distributed Computing\n  Systems (ICDCS)", "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a popular machine learning technique and has been applied to\nmany real-world problems. However, training a deep neural network is very\ntime-consuming, especially on big data. It has become difficult for a single\nmachine to train a large model over large datasets. A popular solution is to\ndistribute and parallelize the training process across multiple machines using\nthe parameter server framework. In this paper, we present a distributed\nparadigm on the parameter server framework called Dynamic Stale Synchronous\nParallel (DSSP) which improves the state-of-the-art Stale Synchronous Parallel\n(SSP) paradigm by dynamically determining the staleness threshold at the run\ntime. Conventionally to run distributed training in SSP, the user needs to\nspecify a particular staleness threshold as a hyper-parameter. However, a user\ndoes not usually know how to set the threshold and thus often finds a threshold\nvalue through trial and error, which is time-consuming. Based on workers'\nrecent processing time, our approach DSSP adaptively adjusts the threshold per\niteration at running time to reduce the waiting time of faster workers for\nsynchronization of the globally shared parameters, and consequently increases\nthe frequency of parameters updates (increases iteration throughput), which\nspeedups the convergence rate. We compare DSSP with other paradigms such as\nBulk Synchronous Parallel (BSP), Asynchronous Parallel (ASP), and SSP by\nrunning deep neural networks (DNN) models over GPU clusters in both homogeneous\nand heterogeneous environments. The results show that in a heterogeneous\nenvironment where the cluster consists of mixed models of GPUs, DSSP converges\nto a higher accuracy much earlier than SSP and BSP and performs similarly to\nASP. In a homogeneous distributed cluster, DSSP has more stable and slightly\nbetter performance than SSP and ASP, and converges much faster than BSP.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 23:03:45 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhao", "Xing", ""], ["An", "Aijun", ""], ["Liu", "Junfeng", ""], ["Chen", "Bao Xin", ""]]}, {"id": "1908.11853", "submitter": "Evgenii Egorov", "authors": "Anna Kuzina, Evgenii Egorov, Evgeny Burnaev", "title": "BooVAE: Boosting Approach for Continual Learning of VAE", "comments": "14 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoder (VAE) is a deep generative model for unsupervised\nlearning, allowing to encode observations into the meaningful latent space. VAE\nis prone to catastrophic forgetting when tasks arrive sequentially, and only\nthe data for the current one is available. We address this problem of continual\nlearning for VAEs. It is known that the choice of the prior distribution over\nthe latent space is crucial for VAE in the non-continual setting. We argue that\nit can also be helpful to avoid catastrophic forgetting. We learn the\napproximation of the aggregated posterior as a prior for each task. This\napproximation is parametrised as an additive mixture of distributions induced\nby encoder evaluated at trainable pseudo-inputs. We use a greedy boosting-like\napproach with entropy regularisation to learn the components. This method\nencourages components diversity, which is essential as we aim at memorising the\ncurrent task with the fewest components possible. Based on the learnable prior,\nwe introduce an end-to-end approach for continual learning of VAEs and provide\nempirical studies on commonly used benchmarks (MNIST, Fashion MNIST, NotMNIST)\nand CelebA datasets. For each dataset, the proposed method avoids catastrophic\nforgetting in a fully automatic way.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 17:26:03 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 19:26:50 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kuzina", "Anna", ""], ["Egorov", "Evgenii", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1908.11863", "submitter": "Rohan Akut Mr", "authors": "Rohan Akut, Sumukh Marathe, Rucha Apte, Ishan Joshi, Siddhivinayak\n  Kulkarni", "title": "Systematic Analysis of Image Generation using GANs", "comments": "Accepted in IEEE ICMLDS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks have been crucial in the developments made in\nunsupervised learning in recent times. Exemplars of image synthesis from text\nor other images, these networks have shown remarkable improvements over\nconventional methods in terms of performance. Trained on the adversarial\ntraining philosophy, these networks aim to estimate the potential distribution\nfrom the real data and then use this as input to generate the synthetic data.\nBased on this fundamental principle, several frameworks can be generated that\nare paragon implementations in several real-life applications such as art\nsynthesis, generation of high resolution outputs and synthesis of images from\nhuman drawn sketches, to name a few. While theoretically GANs present better\nresults and prove to be an improvement over conventional methods in many\nfactors, the implementation of these frameworks for dedicated applications\nremains a challenge. This study explores and presents a taxonomy of these\nframeworks and their use in various image to image synthesis and text to image\nsynthesis applications. The basic GANs, as well as a variety of different niche\nframeworks, are critically analyzed. The advantages of GANs for image\ngeneration over conventional methods as well their disadvantages amongst other\nframeworks are presented. The future applications of GANs in industries such as\nhealthcare, art and entertainment are also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 17:48:05 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Akut", "Rohan", ""], ["Marathe", "Sumukh", ""], ["Apte", "Rucha", ""], ["Joshi", "Ishan", ""], ["Kulkarni", "Siddhivinayak", ""]]}]